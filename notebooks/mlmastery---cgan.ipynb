{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN from Mlmastery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/nisnab/miniconda3/envs/tf_gpu_copy/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/home/nisnab/miniconda3/envs/tf_gpu_copy/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/nisnab/miniconda3/envs/tf_gpu_copy/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/home/nisnab/miniconda3/envs/tf_gpu_copy/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 1/468, d1=0.676, d2=0.696 g=0.691\n",
      ">1, 2/468, d1=0.601, d2=0.699 g=0.687\n",
      ">1, 3/468, d1=0.539, d2=0.707 g=0.681\n",
      ">1, 4/468, d1=0.479, d2=0.719 g=0.671\n",
      ">1, 5/468, d1=0.411, d2=0.737 g=0.656\n",
      ">1, 6/468, d1=0.370, d2=0.763 g=0.641\n",
      ">1, 7/468, d1=0.337, d2=0.792 g=0.626\n",
      ">1, 8/468, d1=0.307, d2=0.810 g=0.623\n",
      ">1, 9/468, d1=0.264, d2=0.806 g=0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nisnab/miniconda3/envs/tf_gpu_copy/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 10/468, d1=0.300, d2=0.757 g=0.700\n",
      ">1, 11/468, d1=0.285, d2=0.698 g=0.783\n",
      ">1, 12/468, d1=0.303, d2=0.624 g=0.858\n",
      ">1, 13/468, d1=0.345, d2=0.589 g=0.882\n",
      ">1, 14/468, d1=0.300, d2=0.596 g=0.849\n",
      ">1, 15/468, d1=0.266, d2=0.630 g=0.808\n",
      ">1, 16/468, d1=0.253, d2=0.677 g=0.753\n",
      ">1, 17/468, d1=0.224, d2=0.726 g=0.707\n",
      ">1, 18/468, d1=0.258, d2=0.771 g=0.684\n",
      ">1, 19/468, d1=0.208, d2=0.776 g=0.688\n",
      ">1, 20/468, d1=0.147, d2=0.779 g=0.693\n",
      ">1, 21/468, d1=0.132, d2=0.803 g=0.686\n",
      ">1, 22/468, d1=0.148, d2=0.827 g=0.683\n",
      ">1, 23/468, d1=0.124, d2=0.808 g=0.735\n",
      ">1, 24/468, d1=0.094, d2=0.700 g=0.853\n",
      ">1, 25/468, d1=0.087, d2=0.562 g=1.004\n",
      ">1, 26/468, d1=0.078, d2=0.489 g=1.080\n",
      ">1, 27/468, d1=0.065, d2=0.504 g=1.033\n",
      ">1, 28/468, d1=0.071, d2=0.545 g=0.913\n",
      ">1, 29/468, d1=0.053, d2=0.616 g=0.817\n",
      ">1, 30/468, d1=0.047, d2=0.682 g=0.742\n",
      ">1, 31/468, d1=0.051, d2=0.750 g=0.696\n",
      ">1, 32/468, d1=0.076, d2=0.789 g=0.652\n",
      ">1, 33/468, d1=0.063, d2=0.825 g=0.631\n",
      ">1, 34/468, d1=0.050, d2=0.837 g=0.628\n",
      ">1, 35/468, d1=0.089, d2=0.831 g=0.636\n",
      ">1, 36/468, d1=0.070, d2=0.812 g=0.669\n",
      ">1, 37/468, d1=0.101, d2=0.774 g=0.719\n",
      ">1, 38/468, d1=0.092, d2=0.700 g=0.803\n",
      ">1, 39/468, d1=0.150, d2=0.641 g=0.900\n",
      ">1, 40/468, d1=0.162, d2=0.567 g=0.993\n",
      ">1, 41/468, d1=0.193, d2=0.509 g=1.058\n",
      ">1, 42/468, d1=0.215, d2=0.495 g=1.084\n",
      ">1, 43/468, d1=0.214, d2=0.494 g=1.030\n",
      ">1, 44/468, d1=0.201, d2=0.512 g=0.986\n",
      ">1, 45/468, d1=0.178, d2=0.541 g=0.952\n",
      ">1, 46/468, d1=0.184, d2=0.525 g=0.933\n",
      ">1, 47/468, d1=0.120, d2=0.540 g=0.923\n",
      ">1, 48/468, d1=0.118, d2=0.542 g=0.905\n",
      ">1, 49/468, d1=0.112, d2=0.552 g=0.890\n",
      ">1, 50/468, d1=0.104, d2=0.578 g=0.858\n",
      ">1, 51/468, d1=0.090, d2=0.595 g=0.829\n",
      ">1, 52/468, d1=0.063, d2=0.611 g=0.809\n",
      ">1, 53/468, d1=0.055, d2=0.652 g=0.772\n",
      ">1, 54/468, d1=0.063, d2=0.669 g=0.738\n",
      ">1, 55/468, d1=0.059, d2=0.708 g=0.719\n",
      ">1, 56/468, d1=0.083, d2=0.758 g=0.696\n",
      ">1, 57/468, d1=0.086, d2=0.777 g=0.679\n",
      ">1, 58/468, d1=0.090, d2=0.800 g=0.682\n",
      ">1, 59/468, d1=0.111, d2=0.788 g=0.686\n",
      ">1, 60/468, d1=0.114, d2=0.760 g=0.729\n",
      ">1, 61/468, d1=0.165, d2=0.774 g=0.730\n",
      ">1, 62/468, d1=0.179, d2=0.785 g=0.722\n",
      ">1, 63/468, d1=0.164, d2=0.782 g=0.748\n",
      ">1, 64/468, d1=0.193, d2=0.722 g=0.834\n",
      ">1, 65/468, d1=0.327, d2=0.678 g=0.847\n",
      ">1, 66/468, d1=0.225, d2=0.689 g=0.903\n",
      ">1, 67/468, d1=0.261, d2=0.693 g=0.905\n",
      ">1, 68/468, d1=0.294, d2=0.655 g=0.917\n",
      ">1, 69/468, d1=0.301, d2=0.675 g=0.932\n",
      ">1, 70/468, d1=0.333, d2=0.714 g=0.941\n",
      ">1, 71/468, d1=0.329, d2=0.714 g=0.984\n",
      ">1, 72/468, d1=0.428, d2=0.732 g=0.939\n",
      ">1, 73/468, d1=0.571, d2=0.786 g=0.893\n",
      ">1, 74/468, d1=0.535, d2=0.864 g=0.872\n",
      ">1, 75/468, d1=0.570, d2=0.836 g=0.858\n",
      ">1, 76/468, d1=0.635, d2=0.837 g=0.789\n",
      ">1, 77/468, d1=0.626, d2=0.846 g=0.807\n",
      ">1, 78/468, d1=0.633, d2=0.820 g=0.849\n",
      ">1, 79/468, d1=0.652, d2=0.838 g=0.872\n",
      ">1, 80/468, d1=0.684, d2=0.907 g=0.879\n",
      ">1, 81/468, d1=0.660, d2=0.966 g=0.957\n",
      ">1, 82/468, d1=0.835, d2=0.867 g=1.294\n",
      ">1, 83/468, d1=1.077, d2=0.452 g=1.586\n",
      ">1, 84/468, d1=1.067, d2=0.364 g=1.630\n",
      ">1, 85/468, d1=0.864, d2=0.335 g=1.650\n",
      ">1, 86/468, d1=0.806, d2=0.354 g=1.483\n",
      ">1, 87/468, d1=0.601, d2=0.448 g=1.427\n",
      ">1, 88/468, d1=0.695, d2=0.789 g=0.968\n",
      ">1, 89/468, d1=0.612, d2=1.826 g=0.430\n",
      ">1, 90/468, d1=0.801, d2=2.325 g=0.317\n",
      ">1, 91/468, d1=0.745, d2=1.140 g=0.891\n",
      ">1, 92/468, d1=0.544, d2=0.351 g=1.674\n",
      ">1, 93/468, d1=0.398, d2=0.295 g=1.621\n",
      ">1, 94/468, d1=0.338, d2=0.543 g=1.036\n",
      ">1, 95/468, d1=0.284, d2=1.166 g=0.650\n",
      ">1, 96/468, d1=0.362, d2=1.618 g=0.505\n",
      ">1, 97/468, d1=0.561, d2=1.318 g=0.713\n",
      ">1, 98/468, d1=0.886, d2=0.733 g=1.077\n",
      ">1, 99/468, d1=1.075, d2=0.488 g=1.260\n",
      ">1, 100/468, d1=1.104, d2=0.442 g=1.262\n",
      ">1, 101/468, d1=1.044, d2=0.444 g=1.204\n",
      ">1, 102/468, d1=0.901, d2=0.460 g=1.190\n",
      ">1, 103/468, d1=0.850, d2=0.469 g=1.207\n",
      ">1, 104/468, d1=0.738, d2=0.433 g=1.206\n",
      ">1, 105/468, d1=0.760, d2=0.465 g=1.209\n",
      ">1, 106/468, d1=0.655, d2=0.464 g=1.139\n",
      ">1, 107/468, d1=0.722, d2=0.510 g=1.050\n",
      ">1, 108/468, d1=0.698, d2=0.552 g=1.055\n",
      ">1, 109/468, d1=0.718, d2=0.611 g=0.924\n",
      ">1, 110/468, d1=0.720, d2=0.621 g=0.928\n",
      ">1, 111/468, d1=0.680, d2=0.644 g=0.901\n",
      ">1, 112/468, d1=0.739, d2=0.703 g=0.845\n",
      ">1, 113/468, d1=0.739, d2=0.709 g=0.845\n",
      ">1, 114/468, d1=0.652, d2=0.743 g=0.846\n",
      ">1, 115/468, d1=0.637, d2=0.674 g=0.915\n",
      ">1, 116/468, d1=0.603, d2=0.644 g=0.953\n",
      ">1, 117/468, d1=0.530, d2=0.540 g=1.090\n",
      ">1, 118/468, d1=0.503, d2=0.478 g=1.160\n",
      ">1, 119/468, d1=0.469, d2=0.539 g=1.248\n",
      ">1, 120/468, d1=0.572, d2=0.532 g=1.060\n",
      ">1, 121/468, d1=0.477, d2=0.660 g=0.997\n",
      ">1, 122/468, d1=0.590, d2=0.709 g=0.890\n",
      ">1, 123/468, d1=0.553, d2=0.867 g=0.784\n",
      ">1, 124/468, d1=0.723, d2=0.912 g=0.758\n",
      ">1, 125/468, d1=0.784, d2=0.875 g=0.789\n",
      ">1, 126/468, d1=0.871, d2=0.715 g=0.952\n",
      ">1, 127/468, d1=0.822, d2=0.551 g=1.073\n",
      ">1, 128/468, d1=0.871, d2=0.481 g=1.136\n",
      ">1, 129/468, d1=0.806, d2=0.437 g=1.197\n",
      ">1, 130/468, d1=0.813, d2=0.396 g=1.251\n",
      ">1, 131/468, d1=0.788, d2=0.411 g=1.259\n",
      ">1, 132/468, d1=0.692, d2=0.390 g=1.321\n",
      ">1, 133/468, d1=0.613, d2=0.355 g=1.355\n",
      ">1, 134/468, d1=0.647, d2=0.366 g=1.377\n",
      ">1, 135/468, d1=0.656, d2=0.359 g=1.285\n",
      ">1, 136/468, d1=0.597, d2=0.419 g=1.255\n",
      ">1, 137/468, d1=0.572, d2=0.452 g=1.210\n",
      ">1, 138/468, d1=0.603, d2=0.502 g=1.097\n",
      ">1, 139/468, d1=0.511, d2=0.579 g=1.084\n",
      ">1, 140/468, d1=0.542, d2=0.585 g=0.945\n",
      ">1, 141/468, d1=0.679, d2=0.665 g=0.907\n",
      ">1, 142/468, d1=0.647, d2=0.801 g=0.816\n",
      ">1, 143/468, d1=0.644, d2=0.856 g=0.724\n",
      ">1, 144/468, d1=0.637, d2=0.859 g=0.706\n",
      ">1, 145/468, d1=0.658, d2=0.901 g=0.723\n",
      ">1, 146/468, d1=0.659, d2=0.746 g=0.848\n",
      ">1, 147/468, d1=0.598, d2=0.576 g=1.064\n",
      ">1, 148/468, d1=0.572, d2=0.473 g=1.260\n",
      ">1, 149/468, d1=0.521, d2=0.385 g=1.346\n",
      ">1, 150/468, d1=0.433, d2=0.421 g=1.328\n",
      ">1, 151/468, d1=0.439, d2=0.433 g=1.201\n",
      ">1, 152/468, d1=0.396, d2=0.596 g=1.093\n",
      ">1, 153/468, d1=0.491, d2=0.709 g=0.938\n",
      ">1, 154/468, d1=0.510, d2=0.846 g=0.834\n",
      ">1, 155/468, d1=0.644, d2=0.793 g=0.768\n",
      ">1, 156/468, d1=0.718, d2=0.781 g=0.797\n",
      ">1, 157/468, d1=0.726, d2=0.753 g=0.822\n",
      ">1, 158/468, d1=0.793, d2=0.655 g=0.915\n",
      ">1, 159/468, d1=0.751, d2=0.579 g=1.006\n",
      ">1, 160/468, d1=0.759, d2=0.529 g=1.081\n",
      ">1, 161/468, d1=0.778, d2=0.502 g=1.133\n",
      ">1, 162/468, d1=0.700, d2=0.441 g=1.207\n",
      ">1, 163/468, d1=0.744, d2=0.416 g=1.177\n",
      ">1, 164/468, d1=0.705, d2=0.428 g=1.151\n",
      ">1, 165/468, d1=0.644, d2=0.451 g=1.196\n",
      ">1, 166/468, d1=0.611, d2=0.517 g=1.073\n",
      ">1, 167/468, d1=0.584, d2=0.567 g=1.048\n",
      ">1, 168/468, d1=0.662, d2=0.624 g=0.928\n",
      ">1, 169/468, d1=0.640, d2=0.660 g=0.816\n",
      ">1, 170/468, d1=0.663, d2=0.831 g=0.708\n",
      ">1, 171/468, d1=0.703, d2=0.931 g=0.642\n",
      ">1, 172/468, d1=0.736, d2=0.963 g=0.605\n",
      ">1, 173/468, d1=0.741, d2=0.911 g=0.652\n",
      ">1, 174/468, d1=0.777, d2=0.889 g=0.700\n",
      ">1, 175/468, d1=0.766, d2=0.728 g=0.816\n",
      ">1, 176/468, d1=0.731, d2=0.636 g=0.883\n",
      ">1, 177/468, d1=0.676, d2=0.591 g=0.979\n",
      ">1, 178/468, d1=0.623, d2=0.551 g=0.990\n",
      ">1, 179/468, d1=0.588, d2=0.593 g=0.948\n",
      ">1, 180/468, d1=0.571, d2=0.595 g=0.892\n",
      ">1, 181/468, d1=0.556, d2=0.670 g=0.871\n",
      ">1, 182/468, d1=0.575, d2=0.664 g=0.850\n",
      ">1, 183/468, d1=0.592, d2=0.678 g=0.860\n",
      ">1, 184/468, d1=0.639, d2=0.658 g=0.936\n",
      ">1, 185/468, d1=0.595, d2=0.584 g=0.962\n",
      ">1, 186/468, d1=0.625, d2=0.586 g=0.986\n",
      ">1, 187/468, d1=0.632, d2=0.589 g=1.009\n",
      ">1, 188/468, d1=0.654, d2=0.552 g=0.979\n",
      ">1, 189/468, d1=0.684, d2=0.593 g=0.976\n",
      ">1, 190/468, d1=0.627, d2=0.619 g=0.975\n",
      ">1, 191/468, d1=0.708, d2=0.670 g=0.875\n",
      ">1, 192/468, d1=0.731, d2=0.763 g=0.789\n",
      ">1, 193/468, d1=0.767, d2=0.858 g=0.675\n",
      ">1, 194/468, d1=0.710, d2=0.942 g=0.595\n",
      ">1, 195/468, d1=0.770, d2=0.993 g=0.591\n",
      ">1, 196/468, d1=0.743, d2=1.038 g=0.607\n",
      ">1, 197/468, d1=0.829, d2=0.918 g=0.662\n",
      ">1, 198/468, d1=0.795, d2=0.913 g=0.701\n",
      ">1, 199/468, d1=0.743, d2=0.769 g=0.776\n",
      ">1, 200/468, d1=0.715, d2=0.685 g=0.907\n",
      ">1, 201/468, d1=0.664, d2=0.602 g=0.984\n",
      ">1, 202/468, d1=0.685, d2=0.578 g=0.959\n",
      ">1, 203/468, d1=0.588, d2=0.647 g=0.925\n",
      ">1, 204/468, d1=0.558, d2=0.717 g=0.773\n",
      ">1, 205/468, d1=0.536, d2=0.914 g=0.690\n",
      ">1, 206/468, d1=0.519, d2=0.944 g=0.664\n",
      ">1, 207/468, d1=0.597, d2=0.949 g=0.628\n",
      ">1, 208/468, d1=0.664, d2=0.881 g=0.666\n",
      ">1, 209/468, d1=0.703, d2=0.808 g=0.719\n",
      ">1, 210/468, d1=0.670, d2=0.800 g=0.750\n",
      ">1, 211/468, d1=0.740, d2=0.813 g=0.747\n",
      ">1, 212/468, d1=0.743, d2=0.777 g=0.771\n",
      ">1, 213/468, d1=0.820, d2=0.763 g=0.793\n",
      ">1, 214/468, d1=0.803, d2=0.761 g=0.755\n",
      ">1, 215/468, d1=0.787, d2=0.729 g=0.809\n",
      ">1, 216/468, d1=0.785, d2=0.708 g=0.863\n",
      ">1, 217/468, d1=0.778, d2=0.635 g=0.887\n",
      ">1, 218/468, d1=0.772, d2=0.588 g=0.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 219/468, d1=0.780, d2=0.564 g=0.990\n",
      ">1, 220/468, d1=0.712, d2=0.532 g=1.005\n",
      ">1, 221/468, d1=0.711, d2=0.539 g=1.045\n",
      ">1, 222/468, d1=0.692, d2=0.515 g=1.043\n",
      ">1, 223/468, d1=0.645, d2=0.515 g=1.029\n",
      ">1, 224/468, d1=0.609, d2=0.567 g=0.996\n",
      ">1, 225/468, d1=0.675, d2=0.627 g=0.927\n",
      ">1, 226/468, d1=0.645, d2=0.721 g=0.794\n",
      ">1, 227/468, d1=0.616, d2=0.769 g=0.744\n",
      ">1, 228/468, d1=0.670, d2=0.791 g=0.702\n",
      ">1, 229/468, d1=0.663, d2=0.806 g=0.678\n",
      ">1, 230/468, d1=0.719, d2=0.840 g=0.645\n",
      ">1, 231/468, d1=0.747, d2=0.792 g=0.662\n",
      ">1, 232/468, d1=0.773, d2=0.814 g=0.642\n",
      ">1, 233/468, d1=0.776, d2=0.838 g=0.652\n",
      ">1, 234/468, d1=0.784, d2=0.801 g=0.676\n",
      ">1, 235/468, d1=0.788, d2=0.816 g=0.672\n",
      ">1, 236/468, d1=0.777, d2=0.822 g=0.670\n",
      ">1, 237/468, d1=0.797, d2=0.787 g=0.701\n",
      ">1, 238/468, d1=0.786, d2=0.749 g=0.707\n",
      ">1, 239/468, d1=0.758, d2=0.725 g=0.736\n",
      ">1, 240/468, d1=0.760, d2=0.713 g=0.744\n",
      ">1, 241/468, d1=0.784, d2=0.697 g=0.768\n",
      ">1, 242/468, d1=0.765, d2=0.694 g=0.802\n",
      ">1, 243/468, d1=0.760, d2=0.688 g=0.811\n",
      ">1, 244/468, d1=0.729, d2=0.646 g=0.849\n",
      ">1, 245/468, d1=0.691, d2=0.631 g=0.854\n",
      ">1, 246/468, d1=0.728, d2=0.614 g=0.843\n",
      ">1, 247/468, d1=0.689, d2=0.640 g=0.842\n",
      ">1, 248/468, d1=0.667, d2=0.659 g=0.817\n",
      ">1, 249/468, d1=0.700, d2=0.668 g=0.801\n",
      ">1, 250/468, d1=0.655, d2=0.661 g=0.767\n",
      ">1, 251/468, d1=0.629, d2=0.677 g=0.770\n",
      ">1, 252/468, d1=0.635, d2=0.687 g=0.765\n",
      ">1, 253/468, d1=0.676, d2=0.699 g=0.764\n",
      ">1, 254/468, d1=0.685, d2=0.710 g=0.755\n",
      ">1, 255/468, d1=0.651, d2=0.693 g=0.731\n",
      ">1, 256/468, d1=0.688, d2=0.716 g=0.736\n",
      ">1, 257/468, d1=0.666, d2=0.725 g=0.731\n",
      ">1, 258/468, d1=0.708, d2=0.699 g=0.738\n",
      ">1, 259/468, d1=0.651, d2=0.727 g=0.731\n",
      ">1, 260/468, d1=0.641, d2=0.715 g=0.726\n",
      ">1, 261/468, d1=0.679, d2=0.712 g=0.720\n",
      ">1, 262/468, d1=0.696, d2=0.698 g=0.748\n",
      ">1, 263/468, d1=0.659, d2=0.689 g=0.701\n",
      ">1, 264/468, d1=0.665, d2=0.716 g=0.712\n",
      ">1, 265/468, d1=0.655, d2=0.716 g=0.729\n",
      ">1, 266/468, d1=0.628, d2=0.702 g=0.746\n",
      ">1, 267/468, d1=0.677, d2=0.709 g=0.744\n",
      ">1, 268/468, d1=0.693, d2=0.702 g=0.750\n",
      ">1, 269/468, d1=0.672, d2=0.698 g=0.755\n",
      ">1, 270/468, d1=0.728, d2=0.705 g=0.743\n",
      ">1, 271/468, d1=0.654, d2=0.697 g=0.760\n",
      ">1, 272/468, d1=0.714, d2=0.716 g=0.740\n",
      ">1, 273/468, d1=0.672, d2=0.724 g=0.743\n",
      ">1, 274/468, d1=0.672, d2=0.693 g=0.742\n",
      ">1, 275/468, d1=0.702, d2=0.720 g=0.713\n",
      ">1, 276/468, d1=0.691, d2=0.700 g=0.710\n",
      ">1, 277/468, d1=0.633, d2=0.760 g=0.725\n",
      ">1, 278/468, d1=0.663, d2=0.732 g=0.735\n",
      ">1, 279/468, d1=0.696, d2=0.740 g=0.725\n",
      ">1, 280/468, d1=0.718, d2=0.724 g=0.721\n",
      ">1, 281/468, d1=0.690, d2=0.745 g=0.716\n",
      ">1, 282/468, d1=0.685, d2=0.751 g=0.715\n",
      ">1, 283/468, d1=0.695, d2=0.772 g=0.710\n",
      ">1, 284/468, d1=0.699, d2=0.744 g=0.701\n",
      ">1, 285/468, d1=0.683, d2=0.702 g=0.713\n",
      ">1, 286/468, d1=0.713, d2=0.700 g=0.709\n",
      ">1, 287/468, d1=0.673, d2=0.747 g=0.732\n",
      ">1, 288/468, d1=0.694, d2=0.719 g=0.734\n",
      ">1, 289/468, d1=0.684, d2=0.755 g=0.736\n",
      ">1, 290/468, d1=0.682, d2=0.725 g=0.709\n",
      ">1, 291/468, d1=0.694, d2=0.726 g=0.713\n",
      ">1, 292/468, d1=0.688, d2=0.736 g=0.709\n",
      ">1, 293/468, d1=0.691, d2=0.739 g=0.708\n",
      ">1, 294/468, d1=0.677, d2=0.739 g=0.708\n",
      ">1, 295/468, d1=0.671, d2=0.719 g=0.728\n",
      ">1, 296/468, d1=0.701, d2=0.745 g=0.724\n",
      ">1, 297/468, d1=0.676, d2=0.709 g=0.720\n",
      ">1, 298/468, d1=0.668, d2=0.718 g=0.743\n",
      ">1, 299/468, d1=0.677, d2=0.697 g=0.738\n",
      ">1, 300/468, d1=0.671, d2=0.695 g=0.751\n",
      ">1, 301/468, d1=0.633, d2=0.686 g=0.759\n",
      ">1, 302/468, d1=0.679, d2=0.688 g=0.741\n",
      ">1, 303/468, d1=0.673, d2=0.684 g=0.747\n",
      ">1, 304/468, d1=0.734, d2=0.689 g=0.736\n",
      ">1, 305/468, d1=0.659, d2=0.703 g=0.723\n",
      ">1, 306/468, d1=0.682, d2=0.730 g=0.709\n",
      ">1, 307/468, d1=0.652, d2=0.743 g=0.687\n",
      ">1, 308/468, d1=0.629, d2=0.735 g=0.689\n",
      ">1, 309/468, d1=0.675, d2=0.743 g=0.684\n",
      ">1, 310/468, d1=0.661, d2=0.751 g=0.679\n",
      ">1, 311/468, d1=0.665, d2=0.756 g=0.693\n",
      ">1, 312/468, d1=0.637, d2=0.728 g=0.709\n",
      ">1, 313/468, d1=0.603, d2=0.751 g=0.740\n",
      ">1, 314/468, d1=0.658, d2=0.730 g=0.753\n",
      ">1, 315/468, d1=0.660, d2=0.691 g=0.773\n",
      ">1, 316/468, d1=0.645, d2=0.684 g=0.759\n",
      ">1, 317/468, d1=0.682, d2=0.686 g=0.765\n",
      ">1, 318/468, d1=0.658, d2=0.677 g=0.773\n",
      ">1, 319/468, d1=0.665, d2=0.688 g=0.770\n",
      ">1, 320/468, d1=0.653, d2=0.717 g=0.726\n",
      ">1, 321/468, d1=0.666, d2=0.703 g=0.747\n",
      ">1, 322/468, d1=0.683, d2=0.780 g=0.689\n",
      ">1, 323/468, d1=0.663, d2=0.798 g=0.664\n",
      ">1, 324/468, d1=0.664, d2=0.809 g=0.668\n",
      ">1, 325/468, d1=0.671, d2=0.812 g=0.671\n",
      ">1, 326/468, d1=0.705, d2=0.770 g=0.682\n",
      ">1, 327/468, d1=0.705, d2=0.744 g=0.697\n",
      ">1, 328/468, d1=0.711, d2=0.736 g=0.733\n",
      ">1, 329/468, d1=0.684, d2=0.695 g=0.761\n",
      ">1, 330/468, d1=0.696, d2=0.654 g=0.785\n",
      ">1, 331/468, d1=0.694, d2=0.654 g=0.810\n",
      ">1, 332/468, d1=0.659, d2=0.619 g=0.826\n",
      ">1, 333/468, d1=0.669, d2=0.611 g=0.824\n",
      ">1, 334/468, d1=0.703, d2=0.650 g=0.810\n",
      ">1, 335/468, d1=0.696, d2=0.684 g=0.786\n",
      ">1, 336/468, d1=0.710, d2=0.721 g=0.735\n",
      ">1, 337/468, d1=0.662, d2=0.738 g=0.687\n",
      ">1, 338/468, d1=0.658, d2=0.801 g=0.646\n",
      ">1, 339/468, d1=0.655, d2=0.885 g=0.599\n",
      ">1, 340/468, d1=0.673, d2=0.873 g=0.622\n",
      ">1, 341/468, d1=0.721, d2=0.903 g=0.619\n",
      ">1, 342/468, d1=0.706, d2=0.797 g=0.656\n",
      ">1, 343/468, d1=0.706, d2=0.791 g=0.716\n",
      ">1, 344/468, d1=0.729, d2=0.735 g=0.782\n",
      ">1, 345/468, d1=0.729, d2=0.649 g=0.851\n",
      ">1, 346/468, d1=0.746, d2=0.604 g=0.903\n",
      ">1, 347/468, d1=0.702, d2=0.574 g=0.906\n",
      ">1, 348/468, d1=0.715, d2=0.573 g=0.877\n",
      ">1, 349/468, d1=0.678, d2=0.613 g=0.877\n",
      ">1, 350/468, d1=0.691, d2=0.658 g=0.843\n",
      ">1, 351/468, d1=0.718, d2=0.717 g=0.757\n",
      ">1, 352/468, d1=0.720, d2=0.719 g=0.710\n",
      ">1, 353/468, d1=0.719, d2=0.750 g=0.678\n",
      ">1, 354/468, d1=0.696, d2=0.821 g=0.621\n",
      ">1, 355/468, d1=0.727, d2=0.839 g=0.617\n",
      ">1, 356/468, d1=0.726, d2=0.846 g=0.638\n",
      ">1, 357/468, d1=0.711, d2=0.792 g=0.648\n",
      ">1, 358/468, d1=0.731, d2=0.773 g=0.681\n",
      ">1, 359/468, d1=0.743, d2=0.721 g=0.709\n",
      ">1, 360/468, d1=0.738, d2=0.715 g=0.734\n",
      ">1, 361/468, d1=0.759, d2=0.679 g=0.758\n",
      ">1, 362/468, d1=0.748, d2=0.661 g=0.780\n",
      ">1, 363/468, d1=0.722, d2=0.642 g=0.814\n",
      ">1, 364/468, d1=0.741, d2=0.647 g=0.798\n",
      ">1, 365/468, d1=0.703, d2=0.614 g=0.821\n",
      ">1, 366/468, d1=0.697, d2=0.607 g=0.831\n",
      ">1, 367/468, d1=0.720, d2=0.616 g=0.819\n",
      ">1, 368/468, d1=0.723, d2=0.652 g=0.798\n",
      ">1, 369/468, d1=0.735, d2=0.630 g=0.770\n",
      ">1, 370/468, d1=0.724, d2=0.703 g=0.746\n",
      ">1, 371/468, d1=0.701, d2=0.709 g=0.708\n",
      ">1, 372/468, d1=0.721, d2=0.740 g=0.697\n",
      ">1, 373/468, d1=0.717, d2=0.771 g=0.677\n",
      ">1, 374/468, d1=0.690, d2=0.771 g=0.667\n",
      ">1, 375/468, d1=0.743, d2=0.794 g=0.662\n",
      ">1, 376/468, d1=0.698, d2=0.763 g=0.677\n",
      ">1, 377/468, d1=0.738, d2=0.738 g=0.702\n",
      ">1, 378/468, d1=0.712, d2=0.725 g=0.729\n",
      ">1, 379/468, d1=0.724, d2=0.697 g=0.766\n",
      ">1, 380/468, d1=0.730, d2=0.675 g=0.799\n",
      ">1, 381/468, d1=0.733, d2=0.641 g=0.821\n",
      ">1, 382/468, d1=0.737, d2=0.628 g=0.844\n",
      ">1, 383/468, d1=0.742, d2=0.594 g=0.854\n",
      ">1, 384/468, d1=0.745, d2=0.595 g=0.853\n",
      ">1, 385/468, d1=0.704, d2=0.592 g=0.831\n",
      ">1, 386/468, d1=0.755, d2=0.621 g=0.808\n",
      ">1, 387/468, d1=0.754, d2=0.654 g=0.806\n",
      ">1, 388/468, d1=0.739, d2=0.666 g=0.782\n",
      ">1, 389/468, d1=0.712, d2=0.681 g=0.761\n",
      ">1, 390/468, d1=0.712, d2=0.707 g=0.726\n",
      ">1, 391/468, d1=0.745, d2=0.720 g=0.708\n",
      ">1, 392/468, d1=0.747, d2=0.708 g=0.712\n",
      ">1, 393/468, d1=0.703, d2=0.719 g=0.731\n",
      ">1, 394/468, d1=0.713, d2=0.701 g=0.730\n",
      ">1, 395/468, d1=0.719, d2=0.682 g=0.749\n",
      ">1, 396/468, d1=0.688, d2=0.679 g=0.756\n",
      ">1, 397/468, d1=0.700, d2=0.664 g=0.761\n",
      ">1, 398/468, d1=0.688, d2=0.667 g=0.770\n",
      ">1, 399/468, d1=0.708, d2=0.639 g=0.784\n",
      ">1, 400/468, d1=0.709, d2=0.638 g=0.793\n",
      ">1, 401/468, d1=0.682, d2=0.624 g=0.794\n",
      ">1, 402/468, d1=0.679, d2=0.629 g=0.782\n",
      ">1, 403/468, d1=0.697, d2=0.645 g=0.801\n",
      ">1, 404/468, d1=0.696, d2=0.629 g=0.792\n",
      ">1, 405/468, d1=0.673, d2=0.643 g=0.805\n",
      ">1, 406/468, d1=0.741, d2=0.640 g=0.781\n",
      ">1, 407/468, d1=0.675, d2=0.659 g=0.761\n",
      ">1, 408/468, d1=0.684, d2=0.673 g=0.771\n",
      ">1, 409/468, d1=0.665, d2=0.667 g=0.747\n",
      ">1, 410/468, d1=0.703, d2=0.728 g=0.740\n",
      ">1, 411/468, d1=0.696, d2=0.681 g=0.740\n",
      ">1, 412/468, d1=0.701, d2=0.694 g=0.742\n",
      ">1, 413/468, d1=0.717, d2=0.719 g=0.719\n",
      ">1, 414/468, d1=0.694, d2=0.696 g=0.745\n",
      ">1, 415/468, d1=0.684, d2=0.670 g=0.775\n",
      ">1, 416/468, d1=0.726, d2=0.667 g=0.793\n",
      ">1, 417/468, d1=0.689, d2=0.636 g=0.805\n",
      ">1, 418/468, d1=0.724, d2=0.621 g=0.832\n",
      ">1, 419/468, d1=0.702, d2=0.596 g=0.847\n",
      ">1, 420/468, d1=0.720, d2=0.597 g=0.867\n",
      ">1, 421/468, d1=0.723, d2=0.585 g=0.865\n",
      ">1, 422/468, d1=0.686, d2=0.581 g=0.880\n",
      ">1, 423/468, d1=0.673, d2=0.605 g=0.865\n",
      ">1, 424/468, d1=0.718, d2=0.615 g=0.827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 425/468, d1=0.715, d2=0.637 g=0.791\n",
      ">1, 426/468, d1=0.693, d2=0.660 g=0.768\n",
      ">1, 427/468, d1=0.682, d2=0.660 g=0.735\n",
      ">1, 428/468, d1=0.686, d2=0.685 g=0.734\n",
      ">1, 429/468, d1=0.691, d2=0.702 g=0.723\n",
      ">1, 430/468, d1=0.686, d2=0.696 g=0.730\n",
      ">1, 431/468, d1=0.659, d2=0.687 g=0.737\n",
      ">1, 432/468, d1=0.674, d2=0.674 g=0.744\n",
      ">1, 433/468, d1=0.655, d2=0.690 g=0.727\n",
      ">1, 434/468, d1=0.695, d2=0.667 g=0.747\n",
      ">1, 435/468, d1=0.685, d2=0.676 g=0.751\n",
      ">1, 436/468, d1=0.683, d2=0.671 g=0.761\n",
      ">1, 437/468, d1=0.661, d2=0.656 g=0.764\n",
      ">1, 438/468, d1=0.664, d2=0.651 g=0.771\n",
      ">1, 439/468, d1=0.677, d2=0.635 g=0.783\n",
      ">1, 440/468, d1=0.675, d2=0.646 g=0.784\n",
      ">1, 441/468, d1=0.646, d2=0.645 g=0.793\n",
      ">1, 442/468, d1=0.681, d2=0.656 g=0.795\n",
      ">1, 443/468, d1=0.650, d2=0.639 g=0.783\n",
      ">1, 444/468, d1=0.650, d2=0.645 g=0.787\n",
      ">1, 445/468, d1=0.647, d2=0.644 g=0.804\n",
      ">1, 446/468, d1=0.656, d2=0.652 g=0.800\n",
      ">1, 447/468, d1=0.663, d2=0.664 g=0.777\n",
      ">1, 448/468, d1=0.663, d2=0.679 g=0.781\n",
      ">1, 449/468, d1=0.677, d2=0.665 g=0.777\n",
      ">1, 450/468, d1=0.647, d2=0.676 g=0.753\n",
      ">1, 451/468, d1=0.683, d2=0.708 g=0.738\n",
      ">1, 452/468, d1=0.661, d2=0.717 g=0.768\n",
      ">1, 453/468, d1=0.720, d2=0.676 g=0.771\n",
      ">1, 454/468, d1=0.669, d2=0.670 g=0.783\n",
      ">1, 455/468, d1=0.660, d2=0.660 g=0.806\n",
      ">1, 456/468, d1=0.699, d2=0.615 g=0.842\n",
      ">1, 457/468, d1=0.706, d2=0.607 g=0.854\n",
      ">1, 458/468, d1=0.686, d2=0.593 g=0.861\n",
      ">1, 459/468, d1=0.697, d2=0.595 g=0.871\n",
      ">1, 460/468, d1=0.696, d2=0.587 g=0.859\n",
      ">1, 461/468, d1=0.704, d2=0.608 g=0.892\n",
      ">1, 462/468, d1=0.697, d2=0.596 g=0.879\n",
      ">1, 463/468, d1=0.694, d2=0.582 g=0.883\n",
      ">1, 464/468, d1=0.698, d2=0.582 g=0.887\n",
      ">1, 465/468, d1=0.656, d2=0.582 g=0.887\n",
      ">1, 466/468, d1=0.692, d2=0.587 g=0.858\n",
      ">1, 467/468, d1=0.672, d2=0.626 g=0.837\n",
      ">1, 468/468, d1=0.663, d2=0.603 g=0.830\n",
      ">2, 1/468, d1=0.646, d2=0.647 g=0.793\n",
      ">2, 2/468, d1=0.640, d2=0.665 g=0.778\n",
      ">2, 3/468, d1=0.672, d2=0.678 g=0.766\n",
      ">2, 4/468, d1=0.630, d2=0.667 g=0.753\n",
      ">2, 5/468, d1=0.670, d2=0.670 g=0.750\n",
      ">2, 6/468, d1=0.655, d2=0.663 g=0.757\n",
      ">2, 7/468, d1=0.620, d2=0.657 g=0.762\n",
      ">2, 8/468, d1=0.662, d2=0.669 g=0.778\n",
      ">2, 9/468, d1=0.642, d2=0.657 g=0.775\n",
      ">2, 10/468, d1=0.669, d2=0.644 g=0.782\n",
      ">2, 11/468, d1=0.637, d2=0.659 g=0.782\n",
      ">2, 12/468, d1=0.632, d2=0.656 g=0.783\n",
      ">2, 13/468, d1=0.639, d2=0.672 g=0.768\n",
      ">2, 14/468, d1=0.624, d2=0.675 g=0.724\n",
      ">2, 15/468, d1=0.605, d2=0.746 g=0.727\n",
      ">2, 16/468, d1=0.644, d2=0.736 g=0.728\n",
      ">2, 17/468, d1=0.651, d2=0.768 g=0.687\n",
      ">2, 18/468, d1=0.643, d2=0.799 g=0.674\n",
      ">2, 19/468, d1=0.686, d2=0.841 g=0.683\n",
      ">2, 20/468, d1=0.676, d2=0.793 g=0.677\n",
      ">2, 21/468, d1=0.693, d2=0.757 g=0.709\n",
      ">2, 22/468, d1=0.729, d2=0.741 g=0.712\n",
      ">2, 23/468, d1=0.711, d2=0.711 g=0.772\n",
      ">2, 24/468, d1=0.708, d2=0.684 g=0.785\n",
      ">2, 25/468, d1=0.723, d2=0.667 g=0.824\n",
      ">2, 26/468, d1=0.701, d2=0.637 g=0.860\n",
      ">2, 27/468, d1=0.702, d2=0.592 g=0.901\n",
      ">2, 28/468, d1=0.733, d2=0.564 g=0.885\n",
      ">2, 29/468, d1=0.726, d2=0.603 g=0.825\n",
      ">2, 30/468, d1=0.667, d2=0.624 g=0.801\n",
      ">2, 31/468, d1=0.700, d2=0.700 g=0.754\n",
      ">2, 32/468, d1=0.689, d2=0.741 g=0.679\n",
      ">2, 33/468, d1=0.719, d2=0.773 g=0.661\n",
      ">2, 34/468, d1=0.680, d2=0.780 g=0.644\n",
      ">2, 35/468, d1=0.693, d2=0.804 g=0.639\n",
      ">2, 36/468, d1=0.703, d2=0.801 g=0.633\n",
      ">2, 37/468, d1=0.701, d2=0.763 g=0.644\n",
      ">2, 38/468, d1=0.693, d2=0.767 g=0.655\n",
      ">2, 39/468, d1=0.705, d2=0.756 g=0.690\n",
      ">2, 40/468, d1=0.688, d2=0.726 g=0.688\n",
      ">2, 41/468, d1=0.688, d2=0.734 g=0.715\n",
      ">2, 42/468, d1=0.656, d2=0.709 g=0.725\n",
      ">2, 43/468, d1=0.673, d2=0.681 g=0.752\n",
      ">2, 44/468, d1=0.670, d2=0.692 g=0.745\n",
      ">2, 45/468, d1=0.662, d2=0.695 g=0.744\n",
      ">2, 46/468, d1=0.679, d2=0.679 g=0.748\n",
      ">2, 47/468, d1=0.659, d2=0.695 g=0.740\n",
      ">2, 48/468, d1=0.671, d2=0.696 g=0.728\n",
      ">2, 49/468, d1=0.647, d2=0.704 g=0.731\n",
      ">2, 50/468, d1=0.669, d2=0.705 g=0.718\n",
      ">2, 51/468, d1=0.657, d2=0.705 g=0.707\n",
      ">2, 52/468, d1=0.676, d2=0.724 g=0.718\n",
      ">2, 53/468, d1=0.658, d2=0.718 g=0.723\n",
      ">2, 54/468, d1=0.670, d2=0.732 g=0.726\n",
      ">2, 55/468, d1=0.668, d2=0.690 g=0.725\n",
      ">2, 56/468, d1=0.687, d2=0.699 g=0.726\n",
      ">2, 57/468, d1=0.649, d2=0.669 g=0.744\n",
      ">2, 58/468, d1=0.667, d2=0.678 g=0.742\n",
      ">2, 59/468, d1=0.663, d2=0.656 g=0.755\n",
      ">2, 60/468, d1=0.646, d2=0.684 g=0.751\n",
      ">2, 61/468, d1=0.655, d2=0.660 g=0.756\n",
      ">2, 62/468, d1=0.655, d2=0.678 g=0.748\n",
      ">2, 63/468, d1=0.638, d2=0.680 g=0.742\n",
      ">2, 64/468, d1=0.663, d2=0.681 g=0.744\n",
      ">2, 65/468, d1=0.660, d2=0.700 g=0.720\n",
      ">2, 66/468, d1=0.641, d2=0.709 g=0.721\n",
      ">2, 67/468, d1=0.641, d2=0.717 g=0.713\n",
      ">2, 68/468, d1=0.651, d2=0.700 g=0.706\n",
      ">2, 69/468, d1=0.662, d2=0.699 g=0.713\n",
      ">2, 70/468, d1=0.665, d2=0.699 g=0.722\n",
      ">2, 71/468, d1=0.651, d2=0.691 g=0.724\n",
      ">2, 72/468, d1=0.643, d2=0.693 g=0.737\n",
      ">2, 73/468, d1=0.659, d2=0.685 g=0.734\n",
      ">2, 74/468, d1=0.667, d2=0.675 g=0.746\n",
      ">2, 75/468, d1=0.648, d2=0.670 g=0.748\n",
      ">2, 76/468, d1=0.651, d2=0.661 g=0.763\n",
      ">2, 77/468, d1=0.663, d2=0.667 g=0.755\n",
      ">2, 78/468, d1=0.651, d2=0.666 g=0.766\n",
      ">2, 79/468, d1=0.641, d2=0.667 g=0.754\n",
      ">2, 80/468, d1=0.645, d2=0.667 g=0.747\n",
      ">2, 81/468, d1=0.628, d2=0.670 g=0.750\n",
      ">2, 82/468, d1=0.636, d2=0.697 g=0.740\n",
      ">2, 83/468, d1=0.662, d2=0.690 g=0.747\n",
      ">2, 84/468, d1=0.642, d2=0.702 g=0.729\n",
      ">2, 85/468, d1=0.669, d2=0.720 g=0.723\n",
      ">2, 86/468, d1=0.640, d2=0.721 g=0.719\n",
      ">2, 87/468, d1=0.635, d2=0.705 g=0.725\n",
      ">2, 88/468, d1=0.670, d2=0.713 g=0.736\n",
      ">2, 89/468, d1=0.634, d2=0.690 g=0.737\n",
      ">2, 90/468, d1=0.672, d2=0.691 g=0.763\n",
      ">2, 91/468, d1=0.666, d2=0.691 g=0.781\n",
      ">2, 92/468, d1=0.673, d2=0.647 g=0.784\n",
      ">2, 93/468, d1=0.675, d2=0.645 g=0.803\n",
      ">2, 94/468, d1=0.681, d2=0.627 g=0.810\n",
      ">2, 95/468, d1=0.679, d2=0.632 g=0.812\n",
      ">2, 96/468, d1=0.687, d2=0.644 g=0.800\n",
      ">2, 97/468, d1=0.689, d2=0.646 g=0.772\n",
      ">2, 98/468, d1=0.663, d2=0.668 g=0.748\n",
      ">2, 99/468, d1=0.702, d2=0.693 g=0.746\n",
      ">2, 100/468, d1=0.703, d2=0.717 g=0.729\n",
      ">2, 101/468, d1=0.701, d2=0.719 g=0.712\n",
      ">2, 102/468, d1=0.685, d2=0.709 g=0.709\n",
      ">2, 103/468, d1=0.671, d2=0.710 g=0.715\n",
      ">2, 104/468, d1=0.684, d2=0.701 g=0.730\n",
      ">2, 105/468, d1=0.692, d2=0.691 g=0.729\n",
      ">2, 106/468, d1=0.700, d2=0.677 g=0.752\n",
      ">2, 107/468, d1=0.679, d2=0.672 g=0.776\n",
      ">2, 108/468, d1=0.691, d2=0.640 g=0.794\n",
      ">2, 109/468, d1=0.671, d2=0.635 g=0.799\n",
      ">2, 110/468, d1=0.676, d2=0.620 g=0.814\n",
      ">2, 111/468, d1=0.675, d2=0.618 g=0.817\n",
      ">2, 112/468, d1=0.688, d2=0.618 g=0.800\n",
      ">2, 113/468, d1=0.682, d2=0.642 g=0.812\n",
      ">2, 114/468, d1=0.693, d2=0.645 g=0.785\n",
      ">2, 115/468, d1=0.665, d2=0.666 g=0.754\n",
      ">2, 116/468, d1=0.667, d2=0.697 g=0.730\n",
      ">2, 117/468, d1=0.667, d2=0.703 g=0.706\n",
      ">2, 118/468, d1=0.664, d2=0.741 g=0.702\n",
      ">2, 119/468, d1=0.665, d2=0.731 g=0.717\n",
      ">2, 120/468, d1=0.661, d2=0.729 g=0.718\n",
      ">2, 121/468, d1=0.637, d2=0.689 g=0.753\n",
      ">2, 122/468, d1=0.688, d2=0.671 g=0.787\n",
      ">2, 123/468, d1=0.660, d2=0.643 g=0.810\n",
      ">2, 124/468, d1=0.672, d2=0.623 g=0.864\n",
      ">2, 125/468, d1=0.662, d2=0.584 g=0.874\n",
      ">2, 126/468, d1=0.670, d2=0.578 g=0.862\n",
      ">2, 127/468, d1=0.690, d2=0.588 g=0.853\n",
      ">2, 128/468, d1=0.648, d2=0.608 g=0.826\n",
      ">2, 129/468, d1=0.630, d2=0.653 g=0.786\n",
      ">2, 130/468, d1=0.642, d2=0.695 g=0.750\n",
      ">2, 131/468, d1=0.663, d2=0.715 g=0.713\n",
      ">2, 132/468, d1=0.703, d2=0.751 g=0.704\n",
      ">2, 133/468, d1=0.661, d2=0.754 g=0.704\n",
      ">2, 134/468, d1=0.671, d2=0.745 g=0.700\n",
      ">2, 135/468, d1=0.685, d2=0.727 g=0.715\n",
      ">2, 136/468, d1=0.701, d2=0.718 g=0.728\n",
      ">2, 137/468, d1=0.670, d2=0.699 g=0.744\n",
      ">2, 138/468, d1=0.686, d2=0.662 g=0.757\n",
      ">2, 139/468, d1=0.662, d2=0.673 g=0.785\n",
      ">2, 140/468, d1=0.671, d2=0.626 g=0.801\n",
      ">2, 141/468, d1=0.666, d2=0.645 g=0.820\n",
      ">2, 142/468, d1=0.686, d2=0.636 g=0.802\n",
      ">2, 143/468, d1=0.663, d2=0.650 g=0.803\n",
      ">2, 144/468, d1=0.645, d2=0.636 g=0.786\n",
      ">2, 145/468, d1=0.659, d2=0.669 g=0.762\n",
      ">2, 146/468, d1=0.662, d2=0.696 g=0.736\n",
      ">2, 147/468, d1=0.649, d2=0.724 g=0.701\n",
      ">2, 148/468, d1=0.677, d2=0.757 g=0.685\n",
      ">2, 149/468, d1=0.665, d2=0.780 g=0.644\n",
      ">2, 150/468, d1=0.652, d2=0.802 g=0.671\n",
      ">2, 151/468, d1=0.685, d2=0.774 g=0.689\n",
      ">2, 152/468, d1=0.682, d2=0.721 g=0.706\n",
      ">2, 153/468, d1=0.691, d2=0.731 g=0.740\n",
      ">2, 154/468, d1=0.705, d2=0.664 g=0.776\n",
      ">2, 155/468, d1=0.688, d2=0.645 g=0.831\n",
      ">2, 156/468, d1=0.676, d2=0.622 g=0.838\n",
      ">2, 157/468, d1=0.647, d2=0.652 g=0.849\n",
      ">2, 158/468, d1=0.698, d2=0.642 g=0.826\n",
      ">2, 159/468, d1=0.666, d2=0.645 g=0.818\n",
      ">2, 160/468, d1=0.652, d2=0.671 g=0.794\n",
      ">2, 161/468, d1=0.666, d2=0.680 g=0.779\n",
      ">2, 162/468, d1=0.676, d2=0.701 g=0.738\n",
      ">2, 163/468, d1=0.651, d2=0.722 g=0.734\n",
      ">2, 164/468, d1=0.675, d2=0.723 g=0.713\n",
      ">2, 165/468, d1=0.695, d2=0.729 g=0.698\n",
      ">2, 166/468, d1=0.663, d2=0.730 g=0.706\n",
      ">2, 167/468, d1=0.683, d2=0.712 g=0.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">2, 168/468, d1=0.674, d2=0.697 g=0.747\n",
      ">2, 169/468, d1=0.689, d2=0.656 g=0.781\n",
      ">2, 170/468, d1=0.682, d2=0.653 g=0.785\n",
      ">2, 171/468, d1=0.687, d2=0.636 g=0.815\n",
      ">2, 172/468, d1=0.682, d2=0.635 g=0.825\n",
      ">2, 173/468, d1=0.696, d2=0.641 g=0.827\n",
      ">2, 174/468, d1=0.712, d2=0.614 g=0.807\n",
      ">2, 175/468, d1=0.697, d2=0.664 g=0.779\n",
      ">2, 176/468, d1=0.671, d2=0.690 g=0.748\n",
      ">2, 177/468, d1=0.705, d2=0.745 g=0.708\n",
      ">2, 178/468, d1=0.673, d2=0.740 g=0.689\n",
      ">2, 179/468, d1=0.726, d2=0.760 g=0.673\n",
      ">2, 180/468, d1=0.707, d2=0.770 g=0.675\n",
      ">2, 181/468, d1=0.721, d2=0.763 g=0.702\n",
      ">2, 182/468, d1=0.696, d2=0.744 g=0.707\n",
      ">2, 183/468, d1=0.690, d2=0.760 g=0.717\n",
      ">2, 184/468, d1=0.703, d2=0.694 g=0.734\n",
      ">2, 185/468, d1=0.708, d2=0.693 g=0.752\n",
      ">2, 186/468, d1=0.699, d2=0.681 g=0.779\n",
      ">2, 187/468, d1=0.691, d2=0.668 g=0.824\n",
      ">2, 188/468, d1=0.681, d2=0.629 g=0.861\n",
      ">2, 189/468, d1=0.714, d2=0.654 g=0.835\n",
      ">2, 190/468, d1=0.720, d2=0.627 g=0.842\n",
      ">2, 191/468, d1=0.708, d2=0.625 g=0.799\n",
      ">2, 192/468, d1=0.712, d2=0.654 g=0.775\n",
      ">2, 193/468, d1=0.727, d2=0.706 g=0.762\n",
      ">2, 194/468, d1=0.728, d2=0.720 g=0.734\n",
      ">2, 195/468, d1=0.704, d2=0.740 g=0.695\n",
      ">2, 196/468, d1=0.724, d2=0.735 g=0.697\n",
      ">2, 197/468, d1=0.748, d2=0.747 g=0.707\n",
      ">2, 198/468, d1=0.746, d2=0.739 g=0.712\n",
      ">2, 199/468, d1=0.694, d2=0.720 g=0.716\n",
      ">2, 200/468, d1=0.713, d2=0.706 g=0.746\n",
      ">2, 201/468, d1=0.724, d2=0.676 g=0.765\n",
      ">2, 202/468, d1=0.742, d2=0.651 g=0.779\n",
      ">2, 203/468, d1=0.741, d2=0.636 g=0.797\n",
      ">2, 204/468, d1=0.740, d2=0.624 g=0.813\n",
      ">2, 205/468, d1=0.735, d2=0.603 g=0.836\n",
      ">2, 206/468, d1=0.711, d2=0.622 g=0.834\n",
      ">2, 207/468, d1=0.696, d2=0.617 g=0.843\n",
      ">2, 208/468, d1=0.704, d2=0.616 g=0.846\n",
      ">2, 209/468, d1=0.702, d2=0.614 g=0.829\n",
      ">2, 210/468, d1=0.696, d2=0.606 g=0.836\n",
      ">2, 211/468, d1=0.673, d2=0.619 g=0.814\n",
      ">2, 212/468, d1=0.709, d2=0.628 g=0.798\n",
      ">2, 213/468, d1=0.660, d2=0.656 g=0.794\n",
      ">2, 214/468, d1=0.741, d2=0.650 g=0.765\n",
      ">2, 215/468, d1=0.700, d2=0.675 g=0.769\n",
      ">2, 216/468, d1=0.709, d2=0.684 g=0.783\n",
      ">2, 217/468, d1=0.671, d2=0.647 g=0.804\n",
      ">2, 218/468, d1=0.693, d2=0.659 g=0.783\n",
      ">2, 219/468, d1=0.690, d2=0.638 g=0.816\n",
      ">2, 220/468, d1=0.687, d2=0.624 g=0.831\n",
      ">2, 221/468, d1=0.726, d2=0.636 g=0.819\n",
      ">2, 222/468, d1=0.693, d2=0.595 g=0.823\n",
      ">2, 223/468, d1=0.686, d2=0.606 g=0.825\n",
      ">2, 224/468, d1=0.693, d2=0.619 g=0.831\n",
      ">2, 225/468, d1=0.704, d2=0.601 g=0.829\n",
      ">2, 226/468, d1=0.706, d2=0.612 g=0.828\n",
      ">2, 227/468, d1=0.674, d2=0.611 g=0.825\n",
      ">2, 228/468, d1=0.692, d2=0.635 g=0.801\n",
      ">2, 229/468, d1=0.705, d2=0.637 g=0.809\n",
      ">2, 230/468, d1=0.705, d2=0.646 g=0.779\n",
      ">2, 231/468, d1=0.684, d2=0.650 g=0.786\n",
      ">2, 232/468, d1=0.668, d2=0.637 g=0.785\n",
      ">2, 233/468, d1=0.688, d2=0.650 g=0.775\n",
      ">2, 234/468, d1=0.693, d2=0.668 g=0.765\n",
      ">2, 235/468, d1=0.680, d2=0.648 g=0.771\n",
      ">2, 236/468, d1=0.670, d2=0.658 g=0.763\n",
      ">2, 237/468, d1=0.689, d2=0.669 g=0.766\n",
      ">2, 238/468, d1=0.657, d2=0.679 g=0.768\n",
      ">2, 239/468, d1=0.679, d2=0.645 g=0.784\n",
      ">2, 240/468, d1=0.681, d2=0.661 g=0.788\n",
      ">2, 241/468, d1=0.671, d2=0.637 g=0.753\n",
      ">2, 242/468, d1=0.692, d2=0.654 g=0.745\n",
      ">2, 243/468, d1=0.675, d2=0.689 g=0.746\n",
      ">2, 244/468, d1=0.678, d2=0.686 g=0.750\n",
      ">2, 245/468, d1=0.662, d2=0.726 g=0.719\n",
      ">2, 246/468, d1=0.688, d2=0.732 g=0.701\n",
      ">2, 247/468, d1=0.703, d2=0.724 g=0.706\n",
      ">2, 248/468, d1=0.689, d2=0.726 g=0.697\n",
      ">2, 249/468, d1=0.690, d2=0.726 g=0.701\n",
      ">2, 250/468, d1=0.688, d2=0.722 g=0.691\n",
      ">2, 251/468, d1=0.696, d2=0.767 g=0.689\n",
      ">2, 252/468, d1=0.693, d2=0.749 g=0.711\n",
      ">2, 253/468, d1=0.697, d2=0.713 g=0.716\n",
      ">2, 254/468, d1=0.706, d2=0.682 g=0.705\n",
      ">2, 255/468, d1=0.716, d2=0.700 g=0.736\n",
      ">2, 256/468, d1=0.685, d2=0.675 g=0.755\n",
      ">2, 257/468, d1=0.690, d2=0.664 g=0.777\n",
      ">2, 258/468, d1=0.727, d2=0.619 g=0.804\n",
      ">2, 259/468, d1=0.708, d2=0.635 g=0.827\n",
      ">2, 260/468, d1=0.696, d2=0.622 g=0.791\n",
      ">2, 261/468, d1=0.686, d2=0.644 g=0.801\n",
      ">2, 262/468, d1=0.681, d2=0.643 g=0.783\n",
      ">2, 263/468, d1=0.673, d2=0.669 g=0.760\n",
      ">2, 264/468, d1=0.666, d2=0.677 g=0.741\n",
      ">2, 265/468, d1=0.666, d2=0.715 g=0.711\n",
      ">2, 266/468, d1=0.662, d2=0.724 g=0.715\n",
      ">2, 267/468, d1=0.652, d2=0.749 g=0.716\n",
      ">2, 268/468, d1=0.647, d2=0.702 g=0.733\n",
      ">2, 269/468, d1=0.656, d2=0.716 g=0.736\n",
      ">2, 270/468, d1=0.659, d2=0.676 g=0.761\n",
      ">2, 271/468, d1=0.663, d2=0.648 g=0.781\n",
      ">2, 272/468, d1=0.633, d2=0.636 g=0.809\n",
      ">2, 273/468, d1=0.628, d2=0.622 g=0.811\n",
      ">2, 274/468, d1=0.640, d2=0.594 g=0.832\n",
      ">2, 275/468, d1=0.629, d2=0.604 g=0.851\n",
      ">2, 276/468, d1=0.656, d2=0.621 g=0.832\n",
      ">2, 277/468, d1=0.643, d2=0.626 g=0.833\n",
      ">2, 278/468, d1=0.637, d2=0.648 g=0.785\n",
      ">2, 279/468, d1=0.651, d2=0.686 g=0.742\n",
      ">2, 280/468, d1=0.664, d2=0.705 g=0.715\n",
      ">2, 281/468, d1=0.618, d2=0.741 g=0.688\n",
      ">2, 282/468, d1=0.610, d2=0.756 g=0.664\n",
      ">2, 283/468, d1=0.651, d2=0.796 g=0.668\n",
      ">2, 284/468, d1=0.665, d2=0.788 g=0.670\n",
      ">2, 285/468, d1=0.663, d2=0.824 g=0.688\n",
      ">2, 286/468, d1=0.653, d2=0.754 g=0.712\n",
      ">2, 287/468, d1=0.670, d2=0.715 g=0.740\n",
      ">2, 288/468, d1=0.681, d2=0.685 g=0.781\n",
      ">2, 289/468, d1=0.702, d2=0.621 g=0.833\n",
      ">2, 290/468, d1=0.709, d2=0.591 g=0.873\n",
      ">2, 291/468, d1=0.679, d2=0.586 g=0.930\n",
      ">2, 292/468, d1=0.702, d2=0.558 g=0.939\n",
      ">2, 293/468, d1=0.688, d2=0.541 g=0.924\n",
      ">2, 294/468, d1=0.668, d2=0.593 g=0.914\n",
      ">2, 295/468, d1=0.694, d2=0.617 g=0.884\n",
      ">2, 296/468, d1=0.714, d2=0.644 g=0.794\n",
      ">2, 297/468, d1=0.685, d2=0.658 g=0.765\n",
      ">2, 298/468, d1=0.710, d2=0.722 g=0.712\n",
      ">2, 299/468, d1=0.660, d2=0.760 g=0.687\n",
      ">2, 300/468, d1=0.705, d2=0.773 g=0.646\n",
      ">2, 301/468, d1=0.716, d2=0.759 g=0.663\n",
      ">2, 302/468, d1=0.730, d2=0.748 g=0.670\n",
      ">2, 303/468, d1=0.699, d2=0.722 g=0.706\n",
      ">2, 304/468, d1=0.665, d2=0.705 g=0.721\n",
      ">2, 305/468, d1=0.669, d2=0.679 g=0.749\n",
      ">2, 306/468, d1=0.688, d2=0.658 g=0.790\n",
      ">2, 307/468, d1=0.678, d2=0.641 g=0.800\n",
      ">2, 308/468, d1=0.650, d2=0.629 g=0.809\n",
      ">2, 309/468, d1=0.665, d2=0.603 g=0.820\n",
      ">2, 310/468, d1=0.658, d2=0.608 g=0.836\n",
      ">2, 311/468, d1=0.630, d2=0.605 g=0.827\n",
      ">2, 312/468, d1=0.642, d2=0.615 g=0.829\n",
      ">2, 313/468, d1=0.675, d2=0.642 g=0.791\n",
      ">2, 314/468, d1=0.629, d2=0.648 g=0.767\n",
      ">2, 315/468, d1=0.662, d2=0.695 g=0.728\n",
      ">2, 316/468, d1=0.639, d2=0.707 g=0.720\n",
      ">2, 317/468, d1=0.659, d2=0.727 g=0.688\n",
      ">2, 318/468, d1=0.646, d2=0.736 g=0.677\n",
      ">2, 319/468, d1=0.629, d2=0.791 g=0.694\n",
      ">2, 320/468, d1=0.656, d2=0.757 g=0.677\n",
      ">2, 321/468, d1=0.693, d2=0.724 g=0.722\n",
      ">2, 322/468, d1=0.667, d2=0.711 g=0.745\n",
      ">2, 323/468, d1=0.684, d2=0.696 g=0.767\n",
      ">2, 324/468, d1=0.678, d2=0.620 g=0.804\n",
      ">2, 325/468, d1=0.654, d2=0.620 g=0.852\n",
      ">2, 326/468, d1=0.681, d2=0.591 g=0.892\n",
      ">2, 327/468, d1=0.693, d2=0.586 g=0.877\n",
      ">2, 328/468, d1=0.717, d2=0.588 g=0.855\n",
      ">2, 329/468, d1=0.696, d2=0.603 g=0.837\n",
      ">2, 330/468, d1=0.707, d2=0.643 g=0.800\n",
      ">2, 331/468, d1=0.719, d2=0.656 g=0.750\n",
      ">2, 332/468, d1=0.685, d2=0.708 g=0.737\n",
      ">2, 333/468, d1=0.674, d2=0.716 g=0.700\n",
      ">2, 334/468, d1=0.677, d2=0.717 g=0.702\n",
      ">2, 335/468, d1=0.638, d2=0.721 g=0.683\n",
      ">2, 336/468, d1=0.677, d2=0.709 g=0.687\n",
      ">2, 337/468, d1=0.662, d2=0.722 g=0.697\n",
      ">2, 338/468, d1=0.699, d2=0.700 g=0.709\n",
      ">2, 339/468, d1=0.654, d2=0.702 g=0.716\n",
      ">2, 340/468, d1=0.662, d2=0.693 g=0.726\n",
      ">2, 341/468, d1=0.665, d2=0.688 g=0.734\n",
      ">2, 342/468, d1=0.642, d2=0.682 g=0.732\n",
      ">2, 343/468, d1=0.616, d2=0.669 g=0.747\n",
      ">2, 344/468, d1=0.664, d2=0.680 g=0.758\n",
      ">2, 345/468, d1=0.628, d2=0.653 g=0.748\n",
      ">2, 346/468, d1=0.599, d2=0.664 g=0.752\n",
      ">2, 347/468, d1=0.630, d2=0.665 g=0.747\n",
      ">2, 348/468, d1=0.653, d2=0.709 g=0.732\n",
      ">2, 349/468, d1=0.639, d2=0.688 g=0.733\n",
      ">2, 350/468, d1=0.663, d2=0.694 g=0.730\n",
      ">2, 351/468, d1=0.654, d2=0.710 g=0.711\n",
      ">2, 352/468, d1=0.647, d2=0.685 g=0.729\n",
      ">2, 353/468, d1=0.674, d2=0.704 g=0.716\n",
      ">2, 354/468, d1=0.671, d2=0.698 g=0.718\n",
      ">2, 355/468, d1=0.664, d2=0.718 g=0.721\n",
      ">2, 356/468, d1=0.680, d2=0.690 g=0.739\n",
      ">2, 357/468, d1=0.667, d2=0.699 g=0.737\n",
      ">2, 358/468, d1=0.651, d2=0.676 g=0.746\n",
      ">2, 359/468, d1=0.677, d2=0.674 g=0.742\n",
      ">2, 360/468, d1=0.645, d2=0.649 g=0.766\n",
      ">2, 361/468, d1=0.668, d2=0.665 g=0.751\n",
      ">2, 362/468, d1=0.680, d2=0.665 g=0.763\n",
      ">2, 363/468, d1=0.673, d2=0.658 g=0.756\n",
      ">2, 364/468, d1=0.660, d2=0.640 g=0.761\n",
      ">2, 365/468, d1=0.663, d2=0.690 g=0.760\n",
      ">2, 366/468, d1=0.666, d2=0.689 g=0.750\n",
      ">2, 367/468, d1=0.667, d2=0.677 g=0.748\n",
      ">2, 368/468, d1=0.674, d2=0.672 g=0.731\n",
      ">2, 369/468, d1=0.672, d2=0.710 g=0.736\n",
      ">2, 370/468, d1=0.656, d2=0.670 g=0.733\n",
      ">2, 371/468, d1=0.663, d2=0.709 g=0.730\n",
      ">2, 372/468, d1=0.664, d2=0.692 g=0.728\n",
      ">2, 373/468, d1=0.660, d2=0.681 g=0.738\n",
      ">2, 374/468, d1=0.665, d2=0.673 g=0.727\n",
      ">2, 375/468, d1=0.648, d2=0.681 g=0.739\n",
      ">2, 376/468, d1=0.652, d2=0.664 g=0.742\n",
      ">2, 377/468, d1=0.660, d2=0.664 g=0.739\n",
      ">2, 378/468, d1=0.637, d2=0.676 g=0.753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">2, 379/468, d1=0.643, d2=0.668 g=0.750\n",
      ">2, 380/468, d1=0.658, d2=0.670 g=0.748\n",
      ">2, 381/468, d1=0.655, d2=0.671 g=0.747\n",
      ">2, 382/468, d1=0.662, d2=0.674 g=0.747\n",
      ">2, 383/468, d1=0.651, d2=0.685 g=0.738\n",
      ">2, 384/468, d1=0.656, d2=0.675 g=0.740\n",
      ">2, 385/468, d1=0.656, d2=0.679 g=0.734\n",
      ">2, 386/468, d1=0.648, d2=0.668 g=0.742\n",
      ">2, 387/468, d1=0.637, d2=0.681 g=0.742\n",
      ">2, 388/468, d1=0.645, d2=0.696 g=0.736\n",
      ">2, 389/468, d1=0.662, d2=0.676 g=0.733\n",
      ">2, 390/468, d1=0.637, d2=0.675 g=0.755\n",
      ">2, 391/468, d1=0.644, d2=0.671 g=0.750\n",
      ">2, 392/468, d1=0.652, d2=0.678 g=0.759\n",
      ">2, 393/468, d1=0.634, d2=0.674 g=0.752\n",
      ">2, 394/468, d1=0.658, d2=0.655 g=0.775\n",
      ">2, 395/468, d1=0.658, d2=0.658 g=0.774\n",
      ">2, 396/468, d1=0.651, d2=0.646 g=0.789\n",
      ">2, 397/468, d1=0.651, d2=0.629 g=0.813\n",
      ">2, 398/468, d1=0.620, d2=0.621 g=0.794\n",
      ">2, 399/468, d1=0.637, d2=0.636 g=0.794\n",
      ">2, 400/468, d1=0.650, d2=0.622 g=0.809\n",
      ">2, 401/468, d1=0.665, d2=0.651 g=0.789\n",
      ">2, 402/468, d1=0.637, d2=0.650 g=0.781\n",
      ">2, 403/468, d1=0.627, d2=0.659 g=0.774\n",
      ">2, 404/468, d1=0.657, d2=0.664 g=0.756\n",
      ">2, 405/468, d1=0.642, d2=0.668 g=0.754\n",
      ">2, 406/468, d1=0.666, d2=0.661 g=0.741\n",
      ">2, 407/468, d1=0.646, d2=0.671 g=0.745\n",
      ">2, 408/468, d1=0.640, d2=0.677 g=0.732\n",
      ">2, 409/468, d1=0.627, d2=0.684 g=0.744\n",
      ">2, 410/468, d1=0.625, d2=0.673 g=0.765\n",
      ">2, 411/468, d1=0.610, d2=0.657 g=0.772\n",
      ">2, 412/468, d1=0.643, d2=0.650 g=0.770\n",
      ">2, 413/468, d1=0.624, d2=0.653 g=0.785\n",
      ">2, 414/468, d1=0.603, d2=0.634 g=0.794\n",
      ">2, 415/468, d1=0.609, d2=0.626 g=0.789\n",
      ">2, 416/468, d1=0.616, d2=0.655 g=0.789\n",
      ">2, 417/468, d1=0.639, d2=0.631 g=0.778\n",
      ">2, 418/468, d1=0.579, d2=0.669 g=0.771\n",
      ">2, 419/468, d1=0.592, d2=0.667 g=0.763\n",
      ">2, 420/468, d1=0.613, d2=0.722 g=0.738\n",
      ">2, 421/468, d1=0.633, d2=0.705 g=0.730\n",
      ">2, 422/468, d1=0.643, d2=0.697 g=0.728\n",
      ">2, 423/468, d1=0.624, d2=0.705 g=0.702\n",
      ">2, 424/468, d1=0.641, d2=0.726 g=0.711\n",
      ">2, 425/468, d1=0.638, d2=0.709 g=0.725\n",
      ">2, 426/468, d1=0.645, d2=0.708 g=0.744\n",
      ">2, 427/468, d1=0.631, d2=0.681 g=0.773\n",
      ">2, 428/468, d1=0.672, d2=0.668 g=0.800\n",
      ">2, 429/468, d1=0.615, d2=0.629 g=0.847\n",
      ">2, 430/468, d1=0.641, d2=0.601 g=0.854\n",
      ">2, 431/468, d1=0.651, d2=0.609 g=0.886\n",
      ">2, 432/468, d1=0.594, d2=0.589 g=0.891\n",
      ">2, 433/468, d1=0.654, d2=0.594 g=0.854\n",
      ">2, 434/468, d1=0.602, d2=0.637 g=0.812\n",
      ">2, 435/468, d1=0.647, d2=0.647 g=0.788\n",
      ">2, 436/468, d1=0.639, d2=0.680 g=0.747\n",
      ">2, 437/468, d1=0.625, d2=0.719 g=0.704\n",
      ">2, 438/468, d1=0.622, d2=0.728 g=0.693\n",
      ">2, 439/468, d1=0.655, d2=0.758 g=0.696\n",
      ">2, 440/468, d1=0.640, d2=0.710 g=0.719\n",
      ">2, 441/468, d1=0.635, d2=0.722 g=0.736\n",
      ">2, 442/468, d1=0.633, d2=0.684 g=0.735\n",
      ">2, 443/468, d1=0.611, d2=0.664 g=0.789\n",
      ">2, 444/468, d1=0.618, d2=0.637 g=0.787\n",
      ">2, 445/468, d1=0.616, d2=0.633 g=0.811\n",
      ">2, 446/468, d1=0.602, d2=0.613 g=0.802\n",
      ">2, 447/468, d1=0.627, d2=0.633 g=0.816\n",
      ">2, 448/468, d1=0.652, d2=0.610 g=0.838\n",
      ">2, 449/468, d1=0.631, d2=0.622 g=0.803\n",
      ">2, 450/468, d1=0.600, d2=0.649 g=0.791\n",
      ">2, 451/468, d1=0.592, d2=0.666 g=0.791\n",
      ">2, 452/468, d1=0.613, d2=0.665 g=0.780\n",
      ">2, 453/468, d1=0.615, d2=0.662 g=0.756\n",
      ">2, 454/468, d1=0.600, d2=0.671 g=0.726\n",
      ">2, 455/468, d1=0.606, d2=0.719 g=0.732\n",
      ">2, 456/468, d1=0.606, d2=0.700 g=0.716\n",
      ">2, 457/468, d1=0.585, d2=0.742 g=0.707\n",
      ">2, 458/468, d1=0.611, d2=0.748 g=0.714\n",
      ">2, 459/468, d1=0.649, d2=0.728 g=0.751\n",
      ">2, 460/468, d1=0.595, d2=0.677 g=0.757\n",
      ">2, 461/468, d1=0.625, d2=0.648 g=0.805\n",
      ">2, 462/468, d1=0.622, d2=0.646 g=0.777\n",
      ">2, 463/468, d1=0.608, d2=0.631 g=0.815\n",
      ">2, 464/468, d1=0.642, d2=0.613 g=0.816\n",
      ">2, 465/468, d1=0.610, d2=0.633 g=0.819\n",
      ">2, 466/468, d1=0.615, d2=0.644 g=0.826\n",
      ">2, 467/468, d1=0.624, d2=0.664 g=0.773\n",
      ">2, 468/468, d1=0.611, d2=0.707 g=0.736\n",
      ">3, 1/468, d1=0.609, d2=0.695 g=0.732\n",
      ">3, 2/468, d1=0.595, d2=0.720 g=0.716\n",
      ">3, 3/468, d1=0.609, d2=0.748 g=0.715\n",
      ">3, 4/468, d1=0.591, d2=0.715 g=0.735\n",
      ">3, 5/468, d1=0.627, d2=0.689 g=0.748\n",
      ">3, 6/468, d1=0.617, d2=0.672 g=0.766\n",
      ">3, 7/468, d1=0.622, d2=0.673 g=0.781\n",
      ">3, 8/468, d1=0.629, d2=0.654 g=0.787\n",
      ">3, 9/468, d1=0.592, d2=0.627 g=0.770\n",
      ">3, 10/468, d1=0.618, d2=0.668 g=0.784\n",
      ">3, 11/468, d1=0.624, d2=0.650 g=0.798\n",
      ">3, 12/468, d1=0.586, d2=0.649 g=0.761\n",
      ">3, 13/468, d1=0.593, d2=0.677 g=0.793\n",
      ">3, 14/468, d1=0.624, d2=0.666 g=0.786\n",
      ">3, 15/468, d1=0.629, d2=0.689 g=0.755\n",
      ">3, 16/468, d1=0.615, d2=0.645 g=0.765\n",
      ">3, 17/468, d1=0.584, d2=0.673 g=0.778\n",
      ">3, 18/468, d1=0.617, d2=0.699 g=0.749\n",
      ">3, 19/468, d1=0.574, d2=0.664 g=0.763\n",
      ">3, 20/468, d1=0.608, d2=0.666 g=0.763\n",
      ">3, 21/468, d1=0.628, d2=0.662 g=0.786\n",
      ">3, 22/468, d1=0.623, d2=0.670 g=0.804\n",
      ">3, 23/468, d1=0.605, d2=0.666 g=0.809\n",
      ">3, 24/468, d1=0.621, d2=0.612 g=0.805\n",
      ">3, 25/468, d1=0.615, d2=0.606 g=0.804\n",
      ">3, 26/468, d1=0.628, d2=0.634 g=0.808\n",
      ">3, 27/468, d1=0.597, d2=0.659 g=0.781\n",
      ">3, 28/468, d1=0.572, d2=0.646 g=0.790\n",
      ">3, 29/468, d1=0.611, d2=0.639 g=0.811\n",
      ">3, 30/468, d1=0.556, d2=0.649 g=0.806\n",
      ">3, 31/468, d1=0.620, d2=0.616 g=0.809\n",
      ">3, 32/468, d1=0.628, d2=0.652 g=0.808\n",
      ">3, 33/468, d1=0.585, d2=0.660 g=0.804\n",
      ">3, 34/468, d1=0.556, d2=0.642 g=0.817\n",
      ">3, 35/468, d1=0.612, d2=0.616 g=0.819\n",
      ">3, 36/468, d1=0.615, d2=0.653 g=0.817\n",
      ">3, 37/468, d1=0.603, d2=0.640 g=0.813\n",
      ">3, 38/468, d1=0.648, d2=0.644 g=0.807\n",
      ">3, 39/468, d1=0.589, d2=0.630 g=0.799\n",
      ">3, 40/468, d1=0.583, d2=0.620 g=0.826\n",
      ">3, 41/468, d1=0.580, d2=0.622 g=0.836\n",
      ">3, 42/468, d1=0.593, d2=0.673 g=0.830\n",
      ">3, 43/468, d1=0.577, d2=0.632 g=0.817\n",
      ">3, 44/468, d1=0.600, d2=0.649 g=0.851\n",
      ">3, 45/468, d1=0.619, d2=0.662 g=0.812\n",
      ">3, 46/468, d1=0.593, d2=0.620 g=0.813\n",
      ">3, 47/468, d1=0.574, d2=0.650 g=0.821\n",
      ">3, 48/468, d1=0.585, d2=0.640 g=0.823\n",
      ">3, 49/468, d1=0.547, d2=0.641 g=0.830\n",
      ">3, 50/468, d1=0.620, d2=0.614 g=0.840\n",
      ">3, 51/468, d1=0.592, d2=0.605 g=0.848\n",
      ">3, 52/468, d1=0.602, d2=0.598 g=0.853\n",
      ">3, 53/468, d1=0.572, d2=0.600 g=0.858\n",
      ">3, 54/468, d1=0.622, d2=0.605 g=0.870\n",
      ">3, 55/468, d1=0.569, d2=0.621 g=0.866\n",
      ">3, 56/468, d1=0.616, d2=0.605 g=0.835\n",
      ">3, 57/468, d1=0.543, d2=0.632 g=0.838\n",
      ">3, 58/468, d1=0.562, d2=0.642 g=0.849\n",
      ">3, 59/468, d1=0.589, d2=0.641 g=0.835\n",
      ">3, 60/468, d1=0.559, d2=0.592 g=0.827\n",
      ">3, 61/468, d1=0.554, d2=0.613 g=0.820\n",
      ">3, 62/468, d1=0.551, d2=0.652 g=0.860\n",
      ">3, 63/468, d1=0.571, d2=0.622 g=0.824\n",
      ">3, 64/468, d1=0.576, d2=0.626 g=0.837\n",
      ">3, 65/468, d1=0.630, d2=0.615 g=0.870\n",
      ">3, 66/468, d1=0.589, d2=0.641 g=0.872\n",
      ">3, 67/468, d1=0.558, d2=0.606 g=0.860\n",
      ">3, 68/468, d1=0.546, d2=0.579 g=0.855\n",
      ">3, 69/468, d1=0.549, d2=0.600 g=0.854\n",
      ">3, 70/468, d1=0.535, d2=0.610 g=0.828\n",
      ">3, 71/468, d1=0.563, d2=0.611 g=0.852\n",
      ">3, 72/468, d1=0.523, d2=0.632 g=0.815\n",
      ">3, 73/468, d1=0.557, d2=0.677 g=0.800\n",
      ">3, 74/468, d1=0.524, d2=0.645 g=0.894\n",
      ">3, 75/468, d1=0.524, d2=0.647 g=0.882\n",
      ">3, 76/468, d1=0.577, d2=0.609 g=0.869\n",
      ">3, 77/468, d1=0.558, d2=0.601 g=0.891\n",
      ">3, 78/468, d1=0.520, d2=0.603 g=0.926\n",
      ">3, 79/468, d1=0.554, d2=0.537 g=0.915\n",
      ">3, 80/468, d1=0.550, d2=0.623 g=0.924\n",
      ">3, 81/468, d1=0.506, d2=0.610 g=0.935\n",
      ">3, 82/468, d1=0.525, d2=0.592 g=0.848\n",
      ">3, 83/468, d1=0.605, d2=0.650 g=0.843\n",
      ">3, 84/468, d1=0.557, d2=0.584 g=0.825\n",
      ">3, 85/468, d1=0.543, d2=0.601 g=0.858\n",
      ">3, 86/468, d1=0.549, d2=0.622 g=0.843\n",
      ">3, 87/468, d1=0.509, d2=0.590 g=0.871\n",
      ">3, 88/468, d1=0.523, d2=0.576 g=0.838\n",
      ">3, 89/468, d1=0.538, d2=0.593 g=0.917\n",
      ">3, 90/468, d1=0.519, d2=0.572 g=0.887\n",
      ">3, 91/468, d1=0.535, d2=0.593 g=0.905\n",
      ">3, 92/468, d1=0.540, d2=0.584 g=0.882\n",
      ">3, 93/468, d1=0.523, d2=0.652 g=0.862\n",
      ">3, 94/468, d1=0.546, d2=0.647 g=0.853\n",
      ">3, 95/468, d1=0.498, d2=0.638 g=0.858\n",
      ">3, 96/468, d1=0.545, d2=0.727 g=0.840\n",
      ">3, 97/468, d1=0.595, d2=0.680 g=0.848\n",
      ">3, 98/468, d1=0.526, d2=0.667 g=0.914\n",
      ">3, 99/468, d1=0.553, d2=0.596 g=0.916\n",
      ">3, 100/468, d1=0.478, d2=0.539 g=0.936\n",
      ">3, 101/468, d1=0.517, d2=0.603 g=1.001\n",
      ">3, 102/468, d1=0.572, d2=0.606 g=0.919\n",
      ">3, 103/468, d1=0.507, d2=0.653 g=0.931\n",
      ">3, 104/468, d1=0.544, d2=0.577 g=0.911\n",
      ">3, 105/468, d1=0.568, d2=0.623 g=0.914\n",
      ">3, 106/468, d1=0.614, d2=0.650 g=0.886\n",
      ">3, 107/468, d1=0.547, d2=0.648 g=0.902\n",
      ">3, 108/468, d1=0.561, d2=0.601 g=0.901\n",
      ">3, 109/468, d1=0.547, d2=0.552 g=0.942\n",
      ">3, 110/468, d1=0.510, d2=0.543 g=0.934\n",
      ">3, 111/468, d1=0.541, d2=0.556 g=0.953\n",
      ">3, 112/468, d1=0.490, d2=0.555 g=0.934\n",
      ">3, 113/468, d1=0.518, d2=0.597 g=0.967\n",
      ">3, 114/468, d1=0.545, d2=0.546 g=0.879\n",
      ">3, 115/468, d1=0.528, d2=0.643 g=0.876\n",
      ">3, 116/468, d1=0.465, d2=0.664 g=0.913\n",
      ">3, 117/468, d1=0.488, d2=0.677 g=0.899\n",
      ">3, 118/468, d1=0.557, d2=0.562 g=0.837\n",
      ">3, 119/468, d1=0.585, d2=0.660 g=0.945\n",
      ">3, 120/468, d1=0.567, d2=0.614 g=0.980\n",
      ">3, 121/468, d1=0.541, d2=0.583 g=0.963\n",
      ">3, 122/468, d1=0.593, d2=0.582 g=0.968\n",
      ">3, 123/468, d1=0.540, d2=0.614 g=1.021\n",
      ">3, 124/468, d1=0.492, d2=0.549 g=1.000\n",
      ">3, 125/468, d1=0.552, d2=0.630 g=1.004\n",
      ">3, 126/468, d1=0.524, d2=0.599 g=0.951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">3, 127/468, d1=0.548, d2=0.619 g=0.882\n",
      ">3, 128/468, d1=0.549, d2=0.621 g=0.876\n",
      ">3, 129/468, d1=0.502, d2=0.665 g=0.885\n",
      ">3, 130/468, d1=0.478, d2=0.605 g=0.947\n",
      ">3, 131/468, d1=0.538, d2=0.546 g=0.914\n",
      ">3, 132/468, d1=0.546, d2=0.588 g=0.995\n",
      ">3, 133/468, d1=0.536, d2=0.546 g=0.928\n",
      ">3, 134/468, d1=0.537, d2=0.594 g=0.995\n",
      ">3, 135/468, d1=0.501, d2=0.575 g=0.942\n",
      ">3, 136/468, d1=0.511, d2=0.597 g=0.926\n",
      ">3, 137/468, d1=0.530, d2=0.626 g=0.901\n",
      ">3, 138/468, d1=0.535, d2=0.599 g=0.840\n",
      ">3, 139/468, d1=0.536, d2=0.730 g=0.873\n",
      ">3, 140/468, d1=0.600, d2=0.646 g=0.881\n",
      ">3, 141/468, d1=0.547, d2=0.663 g=0.833\n",
      ">3, 142/468, d1=0.448, d2=0.639 g=0.912\n",
      ">3, 143/468, d1=0.531, d2=0.638 g=0.967\n",
      ">3, 144/468, d1=0.565, d2=0.592 g=0.925\n",
      ">3, 145/468, d1=0.555, d2=0.596 g=0.842\n",
      ">3, 146/468, d1=0.539, d2=0.662 g=0.812\n",
      ">3, 147/468, d1=0.554, d2=0.701 g=0.859\n",
      ">3, 148/468, d1=0.506, d2=0.688 g=0.838\n",
      ">3, 149/468, d1=0.621, d2=0.655 g=0.885\n",
      ">3, 150/468, d1=0.594, d2=0.697 g=0.879\n",
      ">3, 151/468, d1=0.576, d2=0.614 g=0.883\n",
      ">3, 152/468, d1=0.605, d2=0.676 g=0.873\n",
      ">3, 153/468, d1=0.625, d2=0.668 g=0.827\n",
      ">3, 154/468, d1=0.657, d2=0.694 g=0.778\n",
      ">3, 155/468, d1=0.641, d2=0.721 g=0.764\n",
      ">3, 156/468, d1=0.601, d2=0.716 g=0.801\n",
      ">3, 157/468, d1=0.620, d2=0.695 g=0.796\n",
      ">3, 158/468, d1=0.625, d2=0.722 g=0.812\n",
      ">3, 159/468, d1=0.672, d2=0.703 g=0.811\n",
      ">3, 160/468, d1=0.657, d2=0.701 g=0.817\n",
      ">3, 161/468, d1=0.622, d2=0.727 g=0.805\n",
      ">3, 162/468, d1=0.690, d2=0.683 g=0.818\n",
      ">3, 163/468, d1=0.685, d2=0.775 g=0.796\n",
      ">3, 164/468, d1=0.656, d2=0.725 g=0.769\n",
      ">3, 165/468, d1=0.697, d2=0.724 g=0.748\n",
      ">3, 166/468, d1=0.706, d2=0.736 g=0.776\n",
      ">3, 167/468, d1=0.714, d2=0.717 g=0.798\n",
      ">3, 168/468, d1=0.699, d2=0.675 g=0.766\n",
      ">3, 169/468, d1=0.688, d2=0.749 g=0.791\n",
      ">3, 170/468, d1=0.673, d2=0.658 g=0.822\n",
      ">3, 171/468, d1=0.730, d2=0.685 g=0.816\n",
      ">3, 172/468, d1=0.727, d2=0.686 g=0.809\n",
      ">3, 173/468, d1=0.716, d2=0.680 g=0.806\n",
      ">3, 174/468, d1=0.698, d2=0.683 g=0.828\n",
      ">3, 175/468, d1=0.707, d2=0.670 g=0.804\n",
      ">3, 176/468, d1=0.690, d2=0.678 g=0.804\n",
      ">3, 177/468, d1=0.677, d2=0.666 g=0.797\n",
      ">3, 178/468, d1=0.712, d2=0.694 g=0.777\n",
      ">3, 179/468, d1=0.680, d2=0.623 g=0.804\n",
      ">3, 180/468, d1=0.656, d2=0.710 g=0.801\n",
      ">3, 181/468, d1=0.646, d2=0.688 g=0.786\n",
      ">3, 182/468, d1=0.655, d2=0.700 g=0.805\n",
      ">3, 183/468, d1=0.668, d2=0.695 g=0.782\n",
      ">3, 184/468, d1=0.667, d2=0.691 g=0.774\n",
      ">3, 185/468, d1=0.675, d2=0.674 g=0.799\n",
      ">3, 186/468, d1=0.692, d2=0.703 g=0.774\n",
      ">3, 187/468, d1=0.659, d2=0.683 g=0.764\n",
      ">3, 188/468, d1=0.670, d2=0.697 g=0.770\n",
      ">3, 189/468, d1=0.675, d2=0.725 g=0.719\n",
      ">3, 190/468, d1=0.681, d2=0.749 g=0.744\n",
      ">3, 191/468, d1=0.661, d2=0.741 g=0.751\n",
      ">3, 192/468, d1=0.691, d2=0.690 g=0.781\n",
      ">3, 193/468, d1=0.664, d2=0.714 g=0.817\n",
      ">3, 194/468, d1=0.669, d2=0.679 g=0.839\n",
      ">3, 195/468, d1=0.671, d2=0.698 g=0.780\n",
      ">3, 196/468, d1=0.628, d2=0.690 g=0.773\n",
      ">3, 197/468, d1=0.641, d2=0.728 g=0.725\n",
      ">3, 198/468, d1=0.676, d2=0.738 g=0.717\n",
      ">3, 199/468, d1=0.671, d2=0.721 g=0.754\n",
      ">3, 200/468, d1=0.673, d2=0.723 g=0.761\n",
      ">3, 201/468, d1=0.699, d2=0.679 g=0.759\n",
      ">3, 202/468, d1=0.715, d2=0.682 g=0.788\n",
      ">3, 203/468, d1=0.699, d2=0.712 g=0.804\n",
      ">3, 204/468, d1=0.695, d2=0.705 g=0.740\n",
      ">3, 205/468, d1=0.695, d2=0.754 g=0.727\n",
      ">3, 206/468, d1=0.684, d2=0.754 g=0.732\n",
      ">3, 207/468, d1=0.670, d2=0.737 g=0.762\n",
      ">3, 208/468, d1=0.730, d2=0.731 g=0.788\n",
      ">3, 209/468, d1=0.741, d2=0.702 g=0.804\n",
      ">3, 210/468, d1=0.725, d2=0.691 g=0.795\n",
      ">3, 211/468, d1=0.664, d2=0.657 g=0.759\n",
      ">3, 212/468, d1=0.692, d2=0.714 g=0.735\n",
      ">3, 213/468, d1=0.719, d2=0.749 g=0.714\n",
      ">3, 214/468, d1=0.693, d2=0.748 g=0.749\n",
      ">3, 215/468, d1=0.718, d2=0.715 g=0.765\n",
      ">3, 216/468, d1=0.682, d2=0.683 g=0.800\n",
      ">3, 217/468, d1=0.680, d2=0.668 g=0.794\n",
      ">3, 218/468, d1=0.718, d2=0.662 g=0.795\n",
      ">3, 219/468, d1=0.708, d2=0.710 g=0.759\n",
      ">3, 220/468, d1=0.687, d2=0.733 g=0.747\n",
      ">3, 221/468, d1=0.712, d2=0.735 g=0.757\n",
      ">3, 222/468, d1=0.690, d2=0.708 g=0.746\n",
      ">3, 223/468, d1=0.651, d2=0.660 g=0.793\n",
      ">3, 224/468, d1=0.684, d2=0.700 g=0.781\n",
      ">3, 225/468, d1=0.680, d2=0.701 g=0.793\n",
      ">3, 226/468, d1=0.689, d2=0.677 g=0.763\n",
      ">3, 227/468, d1=0.692, d2=0.689 g=0.739\n",
      ">3, 228/468, d1=0.701, d2=0.705 g=0.754\n",
      ">3, 229/468, d1=0.695, d2=0.702 g=0.760\n",
      ">3, 230/468, d1=0.688, d2=0.688 g=0.786\n",
      ">3, 231/468, d1=0.675, d2=0.654 g=0.792\n",
      ">3, 232/468, d1=0.688, d2=0.709 g=0.789\n",
      ">3, 233/468, d1=0.688, d2=0.701 g=0.760\n",
      ">3, 234/468, d1=0.680, d2=0.684 g=0.759\n",
      ">3, 235/468, d1=0.670, d2=0.663 g=0.748\n",
      ">3, 236/468, d1=0.696, d2=0.678 g=0.778\n",
      ">3, 237/468, d1=0.678, d2=0.702 g=0.779\n",
      ">3, 238/468, d1=0.666, d2=0.680 g=0.798\n",
      ">3, 239/468, d1=0.685, d2=0.670 g=0.813\n",
      ">3, 240/468, d1=0.677, d2=0.672 g=0.811\n",
      ">3, 241/468, d1=0.652, d2=0.666 g=0.789\n",
      ">3, 242/468, d1=0.693, d2=0.681 g=0.779\n",
      ">3, 243/468, d1=0.704, d2=0.714 g=0.747\n",
      ">3, 244/468, d1=0.683, d2=0.696 g=0.781\n",
      ">3, 245/468, d1=0.697, d2=0.700 g=0.801\n",
      ">3, 246/468, d1=0.715, d2=0.662 g=0.803\n",
      ">3, 247/468, d1=0.680, d2=0.615 g=0.828\n",
      ">3, 248/468, d1=0.668, d2=0.625 g=0.857\n",
      ">3, 249/468, d1=0.670, d2=0.631 g=0.834\n",
      ">3, 250/468, d1=0.674, d2=0.642 g=0.812\n",
      ">3, 251/468, d1=0.698, d2=0.648 g=0.804\n",
      ">3, 252/468, d1=0.659, d2=0.702 g=0.758\n",
      ">3, 253/468, d1=0.633, d2=0.707 g=0.736\n",
      ">3, 254/468, d1=0.645, d2=0.753 g=0.741\n",
      ">3, 255/468, d1=0.666, d2=0.742 g=0.788\n",
      ">3, 256/468, d1=0.661, d2=0.677 g=0.828\n",
      ">3, 257/468, d1=0.710, d2=0.606 g=0.872\n",
      ">3, 258/468, d1=0.676, d2=0.610 g=0.902\n",
      ">3, 259/468, d1=0.670, d2=0.630 g=0.867\n",
      ">3, 260/468, d1=0.703, d2=0.649 g=0.801\n",
      ">3, 261/468, d1=0.653, d2=0.733 g=0.764\n",
      ">3, 262/468, d1=0.669, d2=0.740 g=0.746\n",
      ">3, 263/468, d1=0.692, d2=0.733 g=0.754\n",
      ">3, 264/468, d1=0.655, d2=0.693 g=0.810\n",
      ">3, 265/468, d1=0.681, d2=0.652 g=0.837\n",
      ">3, 266/468, d1=0.639, d2=0.595 g=0.894\n",
      ">3, 267/468, d1=0.720, d2=0.620 g=0.839\n",
      ">3, 268/468, d1=0.632, d2=0.647 g=0.844\n",
      ">3, 269/468, d1=0.664, d2=0.687 g=0.780\n",
      ">3, 270/468, d1=0.689, d2=0.721 g=0.760\n",
      ">3, 271/468, d1=0.638, d2=0.764 g=0.743\n",
      ">3, 272/468, d1=0.690, d2=0.729 g=0.760\n",
      ">3, 273/468, d1=0.674, d2=0.711 g=0.799\n",
      ">3, 274/468, d1=0.715, d2=0.645 g=0.845\n",
      ">3, 275/468, d1=0.726, d2=0.602 g=0.936\n",
      ">3, 276/468, d1=0.621, d2=0.607 g=0.953\n",
      ">3, 277/468, d1=0.706, d2=0.588 g=0.865\n",
      ">3, 278/468, d1=0.714, d2=0.648 g=0.857\n",
      ">3, 279/468, d1=0.680, d2=0.649 g=0.785\n",
      ">3, 280/468, d1=0.670, d2=0.732 g=0.707\n",
      ">3, 281/468, d1=0.685, d2=0.752 g=0.755\n",
      ">3, 282/468, d1=0.680, d2=0.690 g=0.782\n",
      ">3, 283/468, d1=0.696, d2=0.639 g=0.835\n",
      ">3, 284/468, d1=0.711, d2=0.630 g=0.851\n",
      ">3, 285/468, d1=0.641, d2=0.623 g=0.847\n",
      ">3, 286/468, d1=0.639, d2=0.634 g=0.827\n",
      ">3, 287/468, d1=0.649, d2=0.675 g=0.767\n",
      ">3, 288/468, d1=0.630, d2=0.754 g=0.748\n",
      ">3, 289/468, d1=0.670, d2=0.748 g=0.716\n",
      ">3, 290/468, d1=0.669, d2=0.733 g=0.736\n",
      ">3, 291/468, d1=0.668, d2=0.700 g=0.739\n",
      ">3, 292/468, d1=0.702, d2=0.684 g=0.809\n",
      ">3, 293/468, d1=0.658, d2=0.644 g=0.839\n",
      ">3, 294/468, d1=0.696, d2=0.608 g=0.883\n",
      ">3, 295/468, d1=0.716, d2=0.589 g=0.887\n",
      ">3, 296/468, d1=0.698, d2=0.594 g=0.840\n",
      ">3, 297/468, d1=0.664, d2=0.663 g=0.820\n",
      ">3, 298/468, d1=0.698, d2=0.679 g=0.763\n",
      ">3, 299/468, d1=0.689, d2=0.696 g=0.719\n",
      ">3, 300/468, d1=0.696, d2=0.705 g=0.737\n",
      ">3, 301/468, d1=0.690, d2=0.703 g=0.736\n",
      ">3, 302/468, d1=0.674, d2=0.696 g=0.772\n",
      ">3, 303/468, d1=0.664, d2=0.675 g=0.817\n",
      ">3, 304/468, d1=0.638, d2=0.653 g=0.791\n",
      ">3, 305/468, d1=0.634, d2=0.655 g=0.803\n",
      ">3, 306/468, d1=0.622, d2=0.664 g=0.787\n",
      ">3, 307/468, d1=0.649, d2=0.659 g=0.762\n",
      ">3, 308/468, d1=0.664, d2=0.696 g=0.765\n",
      ">3, 309/468, d1=0.647, d2=0.701 g=0.756\n",
      ">3, 310/468, d1=0.630, d2=0.701 g=0.756\n",
      ">3, 311/468, d1=0.672, d2=0.678 g=0.758\n",
      ">3, 312/468, d1=0.648, d2=0.711 g=0.760\n",
      ">3, 313/468, d1=0.648, d2=0.675 g=0.773\n",
      ">3, 314/468, d1=0.655, d2=0.664 g=0.800\n",
      ">3, 315/468, d1=0.691, d2=0.673 g=0.775\n",
      ">3, 316/468, d1=0.677, d2=0.655 g=0.771\n",
      ">3, 317/468, d1=0.653, d2=0.661 g=0.744\n",
      ">3, 318/468, d1=0.686, d2=0.678 g=0.769\n",
      ">3, 319/468, d1=0.694, d2=0.691 g=0.735\n",
      ">3, 320/468, d1=0.687, d2=0.698 g=0.742\n",
      ">3, 321/468, d1=0.698, d2=0.709 g=0.732\n",
      ">3, 322/468, d1=0.683, d2=0.711 g=0.741\n",
      ">3, 323/468, d1=0.679, d2=0.701 g=0.761\n",
      ">3, 324/468, d1=0.657, d2=0.681 g=0.753\n",
      ">3, 325/468, d1=0.651, d2=0.692 g=0.757\n",
      ">3, 326/468, d1=0.672, d2=0.669 g=0.783\n",
      ">3, 327/468, d1=0.696, d2=0.663 g=0.797\n",
      ">3, 328/468, d1=0.663, d2=0.647 g=0.800\n",
      ">3, 329/468, d1=0.702, d2=0.640 g=0.789\n",
      ">3, 330/468, d1=0.622, d2=0.666 g=0.791\n",
      ">3, 331/468, d1=0.683, d2=0.661 g=0.780\n",
      ">3, 332/468, d1=0.664, d2=0.651 g=0.784\n",
      ">3, 333/468, d1=0.677, d2=0.670 g=0.784\n",
      ">3, 334/468, d1=0.671, d2=0.674 g=0.783\n",
      ">3, 335/468, d1=0.679, d2=0.658 g=0.808\n",
      ">3, 336/468, d1=0.693, d2=0.661 g=0.845\n",
      ">3, 337/468, d1=0.670, d2=0.633 g=0.831\n",
      ">3, 338/468, d1=0.665, d2=0.598 g=0.862\n",
      ">3, 339/468, d1=0.694, d2=0.613 g=0.842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">3, 340/468, d1=0.661, d2=0.643 g=0.804\n",
      ">3, 341/468, d1=0.653, d2=0.654 g=0.786\n",
      ">3, 342/468, d1=0.652, d2=0.672 g=0.782\n",
      ">3, 343/468, d1=0.703, d2=0.668 g=0.753\n",
      ">3, 344/468, d1=0.692, d2=0.729 g=0.749\n",
      ">3, 345/468, d1=0.738, d2=0.720 g=0.759\n",
      ">3, 346/468, d1=0.698, d2=0.709 g=0.745\n",
      ">3, 347/468, d1=0.707, d2=0.687 g=0.749\n",
      ">3, 348/468, d1=0.693, d2=0.680 g=0.764\n",
      ">3, 349/468, d1=0.702, d2=0.673 g=0.783\n",
      ">3, 350/468, d1=0.680, d2=0.658 g=0.793\n",
      ">3, 351/468, d1=0.703, d2=0.659 g=0.808\n",
      ">3, 352/468, d1=0.713, d2=0.653 g=0.787\n",
      ">3, 353/468, d1=0.687, d2=0.654 g=0.789\n",
      ">3, 354/468, d1=0.714, d2=0.677 g=0.777\n",
      ">3, 355/468, d1=0.690, d2=0.668 g=0.778\n",
      ">3, 356/468, d1=0.703, d2=0.673 g=0.781\n",
      ">3, 357/468, d1=0.678, d2=0.662 g=0.773\n",
      ">3, 358/468, d1=0.702, d2=0.673 g=0.824\n",
      ">3, 359/468, d1=0.691, d2=0.631 g=0.826\n",
      ">3, 360/468, d1=0.701, d2=0.647 g=0.824\n",
      ">3, 361/468, d1=0.701, d2=0.640 g=0.821\n",
      ">3, 362/468, d1=0.693, d2=0.652 g=0.780\n",
      ">3, 363/468, d1=0.685, d2=0.662 g=0.800\n",
      ">3, 364/468, d1=0.670, d2=0.671 g=0.775\n",
      ">3, 365/468, d1=0.686, d2=0.678 g=0.782\n",
      ">3, 366/468, d1=0.689, d2=0.644 g=0.758\n",
      ">3, 367/468, d1=0.674, d2=0.659 g=0.770\n",
      ">3, 368/468, d1=0.652, d2=0.650 g=0.771\n",
      ">3, 369/468, d1=0.647, d2=0.649 g=0.761\n",
      ">3, 370/468, d1=0.630, d2=0.666 g=0.766\n",
      ">3, 371/468, d1=0.639, d2=0.705 g=0.770\n",
      ">3, 372/468, d1=0.660, d2=0.687 g=0.751\n",
      ">3, 373/468, d1=0.677, d2=0.701 g=0.770\n",
      ">3, 374/468, d1=0.664, d2=0.682 g=0.765\n",
      ">3, 375/468, d1=0.673, d2=0.671 g=0.756\n",
      ">3, 376/468, d1=0.639, d2=0.676 g=0.776\n",
      ">3, 377/468, d1=0.679, d2=0.660 g=0.779\n",
      ">3, 378/468, d1=0.671, d2=0.654 g=0.770\n",
      ">3, 379/468, d1=0.648, d2=0.665 g=0.779\n",
      ">3, 380/468, d1=0.684, d2=0.664 g=0.787\n",
      ">3, 381/468, d1=0.701, d2=0.643 g=0.769\n",
      ">3, 382/468, d1=0.665, d2=0.672 g=0.754\n",
      ">3, 383/468, d1=0.663, d2=0.673 g=0.772\n",
      ">3, 384/468, d1=0.663, d2=0.680 g=0.766\n",
      ">3, 385/468, d1=0.673, d2=0.667 g=0.750\n",
      ">3, 386/468, d1=0.675, d2=0.680 g=0.757\n",
      ">3, 387/468, d1=0.660, d2=0.688 g=0.759\n",
      ">3, 388/468, d1=0.686, d2=0.670 g=0.764\n",
      ">3, 389/468, d1=0.667, d2=0.650 g=0.779\n",
      ">3, 390/468, d1=0.643, d2=0.675 g=0.776\n",
      ">3, 391/468, d1=0.656, d2=0.655 g=0.775\n",
      ">3, 392/468, d1=0.661, d2=0.665 g=0.769\n",
      ">3, 393/468, d1=0.668, d2=0.664 g=0.769\n",
      ">3, 394/468, d1=0.637, d2=0.654 g=0.761\n",
      ">3, 395/468, d1=0.700, d2=0.688 g=0.777\n",
      ">3, 396/468, d1=0.658, d2=0.661 g=0.765\n",
      ">3, 397/468, d1=0.669, d2=0.693 g=0.765\n",
      ">3, 398/468, d1=0.672, d2=0.666 g=0.784\n",
      ">3, 399/468, d1=0.653, d2=0.626 g=0.797\n",
      ">3, 400/468, d1=0.699, d2=0.649 g=0.786\n",
      ">3, 401/468, d1=0.700, d2=0.647 g=0.790\n",
      ">3, 402/468, d1=0.665, d2=0.665 g=0.801\n",
      ">3, 403/468, d1=0.663, d2=0.633 g=0.805\n",
      ">3, 404/468, d1=0.697, d2=0.625 g=0.779\n",
      ">3, 405/468, d1=0.657, d2=0.657 g=0.800\n",
      ">3, 406/468, d1=0.652, d2=0.639 g=0.778\n",
      ">3, 407/468, d1=0.649, d2=0.647 g=0.773\n",
      ">3, 408/468, d1=0.674, d2=0.670 g=0.780\n",
      ">3, 409/468, d1=0.665, d2=0.678 g=0.775\n",
      ">3, 410/468, d1=0.697, d2=0.670 g=0.775\n",
      ">3, 411/468, d1=0.665, d2=0.689 g=0.791\n",
      ">3, 412/468, d1=0.692, d2=0.669 g=0.774\n",
      ">3, 413/468, d1=0.656, d2=0.670 g=0.777\n",
      ">3, 414/468, d1=0.660, d2=0.660 g=0.767\n",
      ">3, 415/468, d1=0.680, d2=0.678 g=0.764\n",
      ">3, 416/468, d1=0.684, d2=0.682 g=0.759\n",
      ">3, 417/468, d1=0.676, d2=0.676 g=0.771\n",
      ">3, 418/468, d1=0.693, d2=0.652 g=0.767\n",
      ">3, 419/468, d1=0.669, d2=0.677 g=0.773\n",
      ">3, 420/468, d1=0.671, d2=0.668 g=0.789\n",
      ">3, 421/468, d1=0.686, d2=0.666 g=0.782\n",
      ">3, 422/468, d1=0.677, d2=0.665 g=0.776\n",
      ">3, 423/468, d1=0.655, d2=0.676 g=0.768\n",
      ">3, 424/468, d1=0.664, d2=0.687 g=0.758\n",
      ">3, 425/468, d1=0.656, d2=0.686 g=0.780\n",
      ">3, 426/468, d1=0.631, d2=0.680 g=0.757\n",
      ">3, 427/468, d1=0.640, d2=0.672 g=0.767\n",
      ">3, 428/468, d1=0.688, d2=0.664 g=0.761\n",
      ">3, 429/468, d1=0.648, d2=0.670 g=0.758\n",
      ">3, 430/468, d1=0.651, d2=0.677 g=0.755\n",
      ">3, 431/468, d1=0.682, d2=0.666 g=0.763\n",
      ">3, 432/468, d1=0.630, d2=0.675 g=0.744\n",
      ">3, 433/468, d1=0.657, d2=0.684 g=0.767\n",
      ">3, 434/468, d1=0.655, d2=0.689 g=0.773\n",
      ">3, 435/468, d1=0.659, d2=0.686 g=0.761\n",
      ">3, 436/468, d1=0.639, d2=0.658 g=0.770\n",
      ">3, 437/468, d1=0.657, d2=0.673 g=0.780\n",
      ">3, 438/468, d1=0.669, d2=0.681 g=0.771\n",
      ">3, 439/468, d1=0.646, d2=0.664 g=0.762\n",
      ">3, 440/468, d1=0.664, d2=0.670 g=0.784\n",
      ">3, 441/468, d1=0.645, d2=0.652 g=0.756\n",
      ">3, 442/468, d1=0.661, d2=0.676 g=0.779\n",
      ">3, 443/468, d1=0.666, d2=0.662 g=0.761\n",
      ">3, 444/468, d1=0.655, d2=0.670 g=0.754\n",
      ">3, 445/468, d1=0.664, d2=0.665 g=0.756\n",
      ">3, 446/468, d1=0.655, d2=0.673 g=0.760\n",
      ">3, 447/468, d1=0.632, d2=0.680 g=0.759\n",
      ">3, 448/468, d1=0.666, d2=0.670 g=0.755\n",
      ">3, 449/468, d1=0.674, d2=0.700 g=0.753\n",
      ">3, 450/468, d1=0.666, d2=0.666 g=0.760\n",
      ">3, 451/468, d1=0.677, d2=0.684 g=0.762\n",
      ">3, 452/468, d1=0.642, d2=0.686 g=0.766\n",
      ">3, 453/468, d1=0.675, d2=0.680 g=0.764\n",
      ">3, 454/468, d1=0.684, d2=0.662 g=0.769\n",
      ">3, 455/468, d1=0.663, d2=0.657 g=0.763\n",
      ">3, 456/468, d1=0.661, d2=0.666 g=0.782\n",
      ">3, 457/468, d1=0.655, d2=0.659 g=0.780\n",
      ">3, 458/468, d1=0.664, d2=0.669 g=0.784\n",
      ">3, 459/468, d1=0.670, d2=0.668 g=0.800\n",
      ">3, 460/468, d1=0.697, d2=0.640 g=0.783\n",
      ">3, 461/468, d1=0.692, d2=0.646 g=0.790\n",
      ">3, 462/468, d1=0.682, d2=0.640 g=0.785\n",
      ">3, 463/468, d1=0.679, d2=0.648 g=0.781\n",
      ">3, 464/468, d1=0.667, d2=0.633 g=0.779\n",
      ">3, 465/468, d1=0.650, d2=0.653 g=0.781\n",
      ">3, 466/468, d1=0.662, d2=0.652 g=0.780\n",
      ">3, 467/468, d1=0.652, d2=0.638 g=0.772\n",
      ">3, 468/468, d1=0.650, d2=0.640 g=0.784\n",
      ">4, 1/468, d1=0.653, d2=0.686 g=0.777\n",
      ">4, 2/468, d1=0.671, d2=0.680 g=0.769\n",
      ">4, 3/468, d1=0.651, d2=0.683 g=0.778\n",
      ">4, 4/468, d1=0.645, d2=0.678 g=0.793\n",
      ">4, 5/468, d1=0.667, d2=0.643 g=0.773\n",
      ">4, 6/468, d1=0.647, d2=0.671 g=0.759\n",
      ">4, 7/468, d1=0.659, d2=0.687 g=0.765\n",
      ">4, 8/468, d1=0.664, d2=0.664 g=0.764\n",
      ">4, 9/468, d1=0.675, d2=0.670 g=0.759\n",
      ">4, 10/468, d1=0.644, d2=0.661 g=0.785\n",
      ">4, 11/468, d1=0.658, d2=0.654 g=0.779\n",
      ">4, 12/468, d1=0.647, d2=0.637 g=0.773\n",
      ">4, 13/468, d1=0.655, d2=0.648 g=0.778\n",
      ">4, 14/468, d1=0.656, d2=0.643 g=0.765\n",
      ">4, 15/468, d1=0.687, d2=0.677 g=0.774\n",
      ">4, 16/468, d1=0.675, d2=0.660 g=0.771\n",
      ">4, 17/468, d1=0.659, d2=0.666 g=0.773\n",
      ">4, 18/468, d1=0.664, d2=0.649 g=0.773\n",
      ">4, 19/468, d1=0.667, d2=0.665 g=0.786\n",
      ">4, 20/468, d1=0.693, d2=0.653 g=0.773\n",
      ">4, 21/468, d1=0.670, d2=0.651 g=0.765\n",
      ">4, 22/468, d1=0.658, d2=0.639 g=0.782\n",
      ">4, 23/468, d1=0.643, d2=0.666 g=0.774\n",
      ">4, 24/468, d1=0.646, d2=0.665 g=0.775\n",
      ">4, 25/468, d1=0.666, d2=0.647 g=0.762\n",
      ">4, 26/468, d1=0.661, d2=0.662 g=0.764\n",
      ">4, 27/468, d1=0.673, d2=0.641 g=0.756\n",
      ">4, 28/468, d1=0.637, d2=0.662 g=0.758\n",
      ">4, 29/468, d1=0.659, d2=0.660 g=0.776\n",
      ">4, 30/468, d1=0.643, d2=0.668 g=0.770\n",
      ">4, 31/468, d1=0.680, d2=0.705 g=0.753\n",
      ">4, 32/468, d1=0.629, d2=0.690 g=0.779\n",
      ">4, 33/468, d1=0.662, d2=0.661 g=0.780\n",
      ">4, 34/468, d1=0.673, d2=0.655 g=0.803\n",
      ">4, 35/468, d1=0.663, d2=0.626 g=0.797\n",
      ">4, 36/468, d1=0.671, d2=0.615 g=0.818\n",
      ">4, 37/468, d1=0.654, d2=0.625 g=0.810\n",
      ">4, 38/468, d1=0.670, d2=0.622 g=0.817\n",
      ">4, 39/468, d1=0.669, d2=0.636 g=0.801\n",
      ">4, 40/468, d1=0.680, d2=0.636 g=0.800\n",
      ">4, 41/468, d1=0.661, d2=0.653 g=0.781\n",
      ">4, 42/468, d1=0.650, d2=0.671 g=0.763\n",
      ">4, 43/468, d1=0.689, d2=0.684 g=0.759\n",
      ">4, 44/468, d1=0.626, d2=0.706 g=0.758\n",
      ">4, 45/468, d1=0.655, d2=0.669 g=0.747\n",
      ">4, 46/468, d1=0.653, d2=0.669 g=0.770\n",
      ">4, 47/468, d1=0.685, d2=0.652 g=0.795\n",
      ">4, 48/468, d1=0.658, d2=0.645 g=0.835\n",
      ">4, 49/468, d1=0.643, d2=0.590 g=0.838\n",
      ">4, 50/468, d1=0.624, d2=0.610 g=0.856\n",
      ">4, 51/468, d1=0.621, d2=0.625 g=0.848\n",
      ">4, 52/468, d1=0.625, d2=0.661 g=0.782\n",
      ">4, 53/468, d1=0.625, d2=0.698 g=0.738\n",
      ">4, 54/468, d1=0.653, d2=0.786 g=0.699\n",
      ">4, 55/468, d1=0.656, d2=0.778 g=0.682\n",
      ">4, 56/468, d1=0.664, d2=0.742 g=0.760\n",
      ">4, 57/468, d1=0.663, d2=0.667 g=0.803\n",
      ">4, 58/468, d1=0.696, d2=0.631 g=0.887\n",
      ">4, 59/468, d1=0.683, d2=0.546 g=0.989\n",
      ">4, 60/468, d1=0.682, d2=0.526 g=1.003\n",
      ">4, 61/468, d1=0.685, d2=0.554 g=0.997\n",
      ">4, 62/468, d1=0.705, d2=0.599 g=0.941\n",
      ">4, 63/468, d1=0.709, d2=0.642 g=0.816\n",
      ">4, 64/468, d1=0.666, d2=0.654 g=0.753\n",
      ">4, 65/468, d1=0.674, d2=0.718 g=0.712\n",
      ">4, 66/468, d1=0.670, d2=0.777 g=0.695\n",
      ">4, 67/468, d1=0.668, d2=0.730 g=0.697\n",
      ">4, 68/468, d1=0.622, d2=0.716 g=0.713\n",
      ">4, 69/468, d1=0.676, d2=0.716 g=0.743\n",
      ">4, 70/468, d1=0.639, d2=0.659 g=0.775\n",
      ">4, 71/468, d1=0.630, d2=0.617 g=0.814\n",
      ">4, 72/468, d1=0.650, d2=0.657 g=0.823\n",
      ">4, 73/468, d1=0.621, d2=0.601 g=0.872\n",
      ">4, 74/468, d1=0.644, d2=0.616 g=0.859\n",
      ">4, 75/468, d1=0.624, d2=0.613 g=0.837\n",
      ">4, 76/468, d1=0.690, d2=0.686 g=0.780\n",
      ">4, 77/468, d1=0.642, d2=0.674 g=0.730\n",
      ">4, 78/468, d1=0.597, d2=0.775 g=0.677\n",
      ">4, 79/468, d1=0.654, d2=0.791 g=0.690\n",
      ">4, 80/468, d1=0.654, d2=0.788 g=0.714\n",
      ">4, 81/468, d1=0.671, d2=0.753 g=0.745\n",
      ">4, 82/468, d1=0.656, d2=0.652 g=0.834\n",
      ">4, 83/468, d1=0.704, d2=0.609 g=0.914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4, 84/468, d1=0.691, d2=0.567 g=0.967\n",
      ">4, 85/468, d1=0.685, d2=0.509 g=0.963\n",
      ">4, 86/468, d1=0.659, d2=0.542 g=0.950\n",
      ">4, 87/468, d1=0.666, d2=0.583 g=0.928\n",
      ">4, 88/468, d1=0.708, d2=0.680 g=0.781\n",
      ">4, 89/468, d1=0.691, d2=0.757 g=0.728\n",
      ">4, 90/468, d1=0.679, d2=0.726 g=0.706\n",
      ">4, 91/468, d1=0.629, d2=0.733 g=0.719\n",
      ">4, 92/468, d1=0.646, d2=0.697 g=0.734\n",
      ">4, 93/468, d1=0.659, d2=0.677 g=0.759\n",
      ">4, 94/468, d1=0.645, d2=0.653 g=0.791\n",
      ">4, 95/468, d1=0.617, d2=0.624 g=0.818\n",
      ">4, 96/468, d1=0.614, d2=0.655 g=0.868\n",
      ">4, 97/468, d1=0.610, d2=0.628 g=0.836\n",
      ">4, 98/468, d1=0.647, d2=0.635 g=0.835\n",
      ">4, 99/468, d1=0.598, d2=0.677 g=0.781\n",
      ">4, 100/468, d1=0.593, d2=0.691 g=0.737\n",
      ">4, 101/468, d1=0.635, d2=0.760 g=0.725\n",
      ">4, 102/468, d1=0.624, d2=0.761 g=0.721\n",
      ">4, 103/468, d1=0.652, d2=0.736 g=0.715\n",
      ">4, 104/468, d1=0.662, d2=0.728 g=0.749\n",
      ">4, 105/468, d1=0.679, d2=0.679 g=0.782\n",
      ">4, 106/468, d1=0.651, d2=0.630 g=0.842\n",
      ">4, 107/468, d1=0.648, d2=0.608 g=0.868\n",
      ">4, 108/468, d1=0.650, d2=0.573 g=0.916\n",
      ">4, 109/468, d1=0.691, d2=0.573 g=0.911\n",
      ">4, 110/468, d1=0.713, d2=0.597 g=0.882\n",
      ">4, 111/468, d1=0.652, d2=0.621 g=0.837\n",
      ">4, 112/468, d1=0.690, d2=0.665 g=0.784\n",
      ">4, 113/468, d1=0.680, d2=0.694 g=0.746\n",
      ">4, 114/468, d1=0.685, d2=0.700 g=0.724\n",
      ">4, 115/468, d1=0.652, d2=0.718 g=0.717\n",
      ">4, 116/468, d1=0.645, d2=0.721 g=0.713\n",
      ">4, 117/468, d1=0.671, d2=0.714 g=0.718\n",
      ">4, 118/468, d1=0.635, d2=0.683 g=0.737\n",
      ">4, 119/468, d1=0.653, d2=0.670 g=0.750\n",
      ">4, 120/468, d1=0.644, d2=0.662 g=0.786\n",
      ">4, 121/468, d1=0.583, d2=0.658 g=0.781\n",
      ">4, 122/468, d1=0.605, d2=0.634 g=0.794\n",
      ">4, 123/468, d1=0.648, d2=0.658 g=0.791\n",
      ">4, 124/468, d1=0.614, d2=0.659 g=0.750\n",
      ">4, 125/468, d1=0.615, d2=0.706 g=0.751\n",
      ">4, 126/468, d1=0.639, d2=0.677 g=0.742\n",
      ">4, 127/468, d1=0.607, d2=0.717 g=0.720\n",
      ">4, 128/468, d1=0.626, d2=0.717 g=0.735\n",
      ">4, 129/468, d1=0.638, d2=0.738 g=0.735\n",
      ">4, 130/468, d1=0.645, d2=0.686 g=0.771\n",
      ">4, 131/468, d1=0.655, d2=0.677 g=0.791\n",
      ">4, 132/468, d1=0.654, d2=0.660 g=0.811\n",
      ">4, 133/468, d1=0.677, d2=0.606 g=0.822\n",
      ">4, 134/468, d1=0.718, d2=0.608 g=0.838\n",
      ">4, 135/468, d1=0.695, d2=0.594 g=0.835\n",
      ">4, 136/468, d1=0.671, d2=0.628 g=0.845\n",
      ">4, 137/468, d1=0.707, d2=0.648 g=0.812\n",
      ">4, 138/468, d1=0.672, d2=0.635 g=0.824\n",
      ">4, 139/468, d1=0.672, d2=0.679 g=0.791\n",
      ">4, 140/468, d1=0.708, d2=0.687 g=0.733\n",
      ">4, 141/468, d1=0.693, d2=0.680 g=0.747\n",
      ">4, 142/468, d1=0.665, d2=0.691 g=0.755\n",
      ">4, 143/468, d1=0.667, d2=0.684 g=0.754\n",
      ">4, 144/468, d1=0.652, d2=0.663 g=0.752\n",
      ">4, 145/468, d1=0.652, d2=0.651 g=0.770\n",
      ">4, 146/468, d1=0.655, d2=0.644 g=0.795\n",
      ">4, 147/468, d1=0.680, d2=0.645 g=0.779\n",
      ">4, 148/468, d1=0.643, d2=0.653 g=0.788\n",
      ">4, 149/468, d1=0.679, d2=0.667 g=0.794\n",
      ">4, 150/468, d1=0.648, d2=0.683 g=0.756\n",
      ">4, 151/468, d1=0.677, d2=0.669 g=0.755\n",
      ">4, 152/468, d1=0.684, d2=0.673 g=0.756\n",
      ">4, 153/468, d1=0.667, d2=0.701 g=0.776\n",
      ">4, 154/468, d1=0.674, d2=0.660 g=0.801\n",
      ">4, 155/468, d1=0.666, d2=0.655 g=0.782\n",
      ">4, 156/468, d1=0.687, d2=0.634 g=0.806\n",
      ">4, 157/468, d1=0.678, d2=0.614 g=0.822\n",
      ">4, 158/468, d1=0.660, d2=0.621 g=0.852\n",
      ">4, 159/468, d1=0.668, d2=0.632 g=0.846\n",
      ">4, 160/468, d1=0.665, d2=0.627 g=0.815\n",
      ">4, 161/468, d1=0.680, d2=0.618 g=0.796\n",
      ">4, 162/468, d1=0.714, d2=0.650 g=0.776\n",
      ">4, 163/468, d1=0.672, d2=0.664 g=0.758\n",
      ">4, 164/468, d1=0.658, d2=0.690 g=0.768\n",
      ">4, 165/468, d1=0.663, d2=0.689 g=0.743\n",
      ">4, 166/468, d1=0.658, d2=0.679 g=0.727\n",
      ">4, 167/468, d1=0.630, d2=0.662 g=0.754\n",
      ">4, 168/468, d1=0.655, d2=0.691 g=0.742\n",
      ">4, 169/468, d1=0.644, d2=0.662 g=0.771\n",
      ">4, 170/468, d1=0.641, d2=0.674 g=0.772\n",
      ">4, 171/468, d1=0.630, d2=0.657 g=0.783\n",
      ">4, 172/468, d1=0.665, d2=0.683 g=0.771\n",
      ">4, 173/468, d1=0.649, d2=0.669 g=0.803\n",
      ">4, 174/468, d1=0.641, d2=0.679 g=0.769\n",
      ">4, 175/468, d1=0.663, d2=0.689 g=0.759\n",
      ">4, 176/468, d1=0.675, d2=0.687 g=0.762\n",
      ">4, 177/468, d1=0.651, d2=0.666 g=0.766\n",
      ">4, 178/468, d1=0.628, d2=0.635 g=0.789\n",
      ">4, 179/468, d1=0.642, d2=0.618 g=0.801\n",
      ">4, 180/468, d1=0.657, d2=0.655 g=0.824\n",
      ">4, 181/468, d1=0.660, d2=0.613 g=0.844\n",
      ">4, 182/468, d1=0.700, d2=0.604 g=0.831\n",
      ">4, 183/468, d1=0.684, d2=0.588 g=0.830\n",
      ">4, 184/468, d1=0.685, d2=0.595 g=0.849\n",
      ">4, 185/468, d1=0.698, d2=0.605 g=0.831\n",
      ">4, 186/468, d1=0.656, d2=0.631 g=0.812\n",
      ">4, 187/468, d1=0.697, d2=0.643 g=0.795\n",
      ">4, 188/468, d1=0.691, d2=0.677 g=0.761\n",
      ">4, 189/468, d1=0.677, d2=0.683 g=0.749\n",
      ">4, 190/468, d1=0.677, d2=0.690 g=0.749\n",
      ">4, 191/468, d1=0.628, d2=0.699 g=0.751\n",
      ">4, 192/468, d1=0.657, d2=0.673 g=0.754\n",
      ">4, 193/468, d1=0.622, d2=0.646 g=0.775\n",
      ">4, 194/468, d1=0.650, d2=0.647 g=0.795\n",
      ">4, 195/468, d1=0.637, d2=0.649 g=0.796\n",
      ">4, 196/468, d1=0.633, d2=0.645 g=0.780\n",
      ">4, 197/468, d1=0.650, d2=0.660 g=0.766\n",
      ">4, 198/468, d1=0.603, d2=0.665 g=0.755\n",
      ">4, 199/468, d1=0.598, d2=0.693 g=0.766\n",
      ">4, 200/468, d1=0.674, d2=0.701 g=0.724\n",
      ">4, 201/468, d1=0.658, d2=0.712 g=0.722\n",
      ">4, 202/468, d1=0.643, d2=0.674 g=0.763\n",
      ">4, 203/468, d1=0.653, d2=0.660 g=0.778\n",
      ">4, 204/468, d1=0.690, d2=0.660 g=0.798\n",
      ">4, 205/468, d1=0.642, d2=0.635 g=0.831\n",
      ">4, 206/468, d1=0.682, d2=0.615 g=0.844\n",
      ">4, 207/468, d1=0.726, d2=0.599 g=0.877\n",
      ">4, 208/468, d1=0.707, d2=0.593 g=0.880\n",
      ">4, 209/468, d1=0.748, d2=0.615 g=0.822\n",
      ">4, 210/468, d1=0.692, d2=0.648 g=0.829\n",
      ">4, 211/468, d1=0.682, d2=0.646 g=0.803\n",
      ">4, 212/468, d1=0.667, d2=0.658 g=0.781\n",
      ">4, 213/468, d1=0.655, d2=0.675 g=0.755\n",
      ">4, 214/468, d1=0.667, d2=0.679 g=0.735\n",
      ">4, 215/468, d1=0.679, d2=0.697 g=0.742\n",
      ">4, 216/468, d1=0.663, d2=0.714 g=0.748\n",
      ">4, 217/468, d1=0.659, d2=0.692 g=0.751\n",
      ">4, 218/468, d1=0.630, d2=0.678 g=0.783\n",
      ">4, 219/468, d1=0.628, d2=0.656 g=0.802\n",
      ">4, 220/468, d1=0.625, d2=0.613 g=0.807\n",
      ">4, 221/468, d1=0.628, d2=0.617 g=0.805\n",
      ">4, 222/468, d1=0.627, d2=0.642 g=0.795\n",
      ">4, 223/468, d1=0.644, d2=0.655 g=0.780\n",
      ">4, 224/468, d1=0.615, d2=0.665 g=0.770\n",
      ">4, 225/468, d1=0.654, d2=0.718 g=0.749\n",
      ">4, 226/468, d1=0.650, d2=0.734 g=0.757\n",
      ">4, 227/468, d1=0.662, d2=0.731 g=0.797\n",
      ">4, 228/468, d1=0.683, d2=0.644 g=0.806\n",
      ">4, 229/468, d1=0.702, d2=0.618 g=0.829\n",
      ">4, 230/468, d1=0.688, d2=0.629 g=0.862\n",
      ">4, 231/468, d1=0.684, d2=0.593 g=0.889\n",
      ">4, 232/468, d1=0.722, d2=0.596 g=0.876\n",
      ">4, 233/468, d1=0.701, d2=0.567 g=0.880\n",
      ">4, 234/468, d1=0.703, d2=0.559 g=0.874\n",
      ">4, 235/468, d1=0.699, d2=0.613 g=0.846\n",
      ">4, 236/468, d1=0.705, d2=0.621 g=0.802\n",
      ">4, 237/468, d1=0.689, d2=0.640 g=0.788\n",
      ">4, 238/468, d1=0.692, d2=0.673 g=0.764\n",
      ">4, 239/468, d1=0.677, d2=0.681 g=0.743\n",
      ">4, 240/468, d1=0.636, d2=0.678 g=0.732\n",
      ">4, 241/468, d1=0.636, d2=0.704 g=0.742\n",
      ">4, 242/468, d1=0.620, d2=0.672 g=0.759\n",
      ">4, 243/468, d1=0.655, d2=0.666 g=0.765\n",
      ">4, 244/468, d1=0.631, d2=0.656 g=0.773\n",
      ">4, 245/468, d1=0.609, d2=0.629 g=0.786\n",
      ">4, 246/468, d1=0.600, d2=0.652 g=0.780\n",
      ">4, 247/468, d1=0.602, d2=0.690 g=0.791\n",
      ">4, 248/468, d1=0.625, d2=0.679 g=0.757\n",
      ">4, 249/468, d1=0.590, d2=0.678 g=0.751\n",
      ">4, 250/468, d1=0.600, d2=0.670 g=0.748\n",
      ">4, 251/468, d1=0.631, d2=0.673 g=0.765\n",
      ">4, 252/468, d1=0.648, d2=0.689 g=0.766\n",
      ">4, 253/468, d1=0.649, d2=0.644 g=0.779\n",
      ">4, 254/468, d1=0.694, d2=0.634 g=0.803\n",
      ">4, 255/468, d1=0.691, d2=0.623 g=0.836\n",
      ">4, 256/468, d1=0.665, d2=0.605 g=0.870\n",
      ">4, 257/468, d1=0.726, d2=0.588 g=0.891\n",
      ">4, 258/468, d1=0.713, d2=0.584 g=0.880\n",
      ">4, 259/468, d1=0.681, d2=0.575 g=0.879\n",
      ">4, 260/468, d1=0.681, d2=0.612 g=0.844\n",
      ">4, 261/468, d1=0.701, d2=0.636 g=0.832\n",
      ">4, 262/468, d1=0.662, d2=0.633 g=0.784\n",
      ">4, 263/468, d1=0.663, d2=0.697 g=0.739\n",
      ">4, 264/468, d1=0.667, d2=0.688 g=0.750\n",
      ">4, 265/468, d1=0.710, d2=0.681 g=0.748\n",
      ">4, 266/468, d1=0.663, d2=0.670 g=0.748\n",
      ">4, 267/468, d1=0.657, d2=0.659 g=0.764\n",
      ">4, 268/468, d1=0.628, d2=0.632 g=0.782\n",
      ">4, 269/468, d1=0.638, d2=0.649 g=0.798\n",
      ">4, 270/468, d1=0.617, d2=0.623 g=0.807\n",
      ">4, 271/468, d1=0.616, d2=0.616 g=0.820\n",
      ">4, 272/468, d1=0.613, d2=0.652 g=0.799\n",
      ">4, 273/468, d1=0.589, d2=0.685 g=0.787\n",
      ">4, 274/468, d1=0.597, d2=0.716 g=0.754\n",
      ">4, 275/468, d1=0.648, d2=0.711 g=0.764\n",
      ">4, 276/468, d1=0.602, d2=0.737 g=0.742\n",
      ">4, 277/468, d1=0.662, d2=0.707 g=0.752\n",
      ">4, 278/468, d1=0.659, d2=0.671 g=0.801\n",
      ">4, 279/468, d1=0.708, d2=0.631 g=0.871\n",
      ">4, 280/468, d1=0.702, d2=0.583 g=0.895\n",
      ">4, 281/468, d1=0.727, d2=0.578 g=0.895\n",
      ">4, 282/468, d1=0.707, d2=0.563 g=0.917\n",
      ">4, 283/468, d1=0.700, d2=0.530 g=0.961\n",
      ">4, 284/468, d1=0.708, d2=0.546 g=0.937\n",
      ">4, 285/468, d1=0.671, d2=0.588 g=0.865\n",
      ">4, 286/468, d1=0.693, d2=0.638 g=0.784\n",
      ">4, 287/468, d1=0.675, d2=0.692 g=0.782\n",
      ">4, 288/468, d1=0.669, d2=0.730 g=0.767\n",
      ">4, 289/468, d1=0.666, d2=0.695 g=0.738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4, 290/468, d1=0.675, d2=0.687 g=0.745\n",
      ">4, 291/468, d1=0.671, d2=0.673 g=0.767\n",
      ">4, 292/468, d1=0.657, d2=0.660 g=0.789\n",
      ">4, 293/468, d1=0.645, d2=0.649 g=0.805\n",
      ">4, 294/468, d1=0.644, d2=0.633 g=0.818\n",
      ">4, 295/468, d1=0.623, d2=0.650 g=0.820\n",
      ">4, 296/468, d1=0.633, d2=0.626 g=0.803\n",
      ">4, 297/468, d1=0.670, d2=0.625 g=0.765\n",
      ">4, 298/468, d1=0.630, d2=0.644 g=0.788\n",
      ">4, 299/468, d1=0.616, d2=0.715 g=0.729\n",
      ">4, 300/468, d1=0.608, d2=0.671 g=0.743\n",
      ">4, 301/468, d1=0.622, d2=0.695 g=0.753\n",
      ">4, 302/468, d1=0.633, d2=0.697 g=0.754\n",
      ">4, 303/468, d1=0.673, d2=0.677 g=0.784\n",
      ">4, 304/468, d1=0.670, d2=0.649 g=0.815\n",
      ">4, 305/468, d1=0.665, d2=0.626 g=0.804\n",
      ">4, 306/468, d1=0.686, d2=0.626 g=0.855\n",
      ">4, 307/468, d1=0.688, d2=0.594 g=0.850\n",
      ">4, 308/468, d1=0.689, d2=0.595 g=0.852\n",
      ">4, 309/468, d1=0.675, d2=0.603 g=0.848\n",
      ">4, 310/468, d1=0.710, d2=0.621 g=0.828\n",
      ">4, 311/468, d1=0.684, d2=0.606 g=0.823\n",
      ">4, 312/468, d1=0.653, d2=0.627 g=0.793\n",
      ">4, 313/468, d1=0.684, d2=0.686 g=0.749\n",
      ">4, 314/468, d1=0.676, d2=0.665 g=0.746\n",
      ">4, 315/468, d1=0.678, d2=0.685 g=0.735\n",
      ">4, 316/468, d1=0.645, d2=0.681 g=0.728\n",
      ">4, 317/468, d1=0.664, d2=0.689 g=0.729\n",
      ">4, 318/468, d1=0.637, d2=0.695 g=0.764\n",
      ">4, 319/468, d1=0.632, d2=0.652 g=0.760\n",
      ">4, 320/468, d1=0.606, d2=0.656 g=0.769\n",
      ">4, 321/468, d1=0.611, d2=0.664 g=0.767\n",
      ">4, 322/468, d1=0.618, d2=0.688 g=0.780\n",
      ">4, 323/468, d1=0.589, d2=0.657 g=0.767\n",
      ">4, 324/468, d1=0.650, d2=0.672 g=0.763\n",
      ">4, 325/468, d1=0.624, d2=0.699 g=0.748\n",
      ">4, 326/468, d1=0.640, d2=0.667 g=0.759\n",
      ">4, 327/468, d1=0.602, d2=0.719 g=0.761\n",
      ">4, 328/468, d1=0.629, d2=0.693 g=0.779\n",
      ">4, 329/468, d1=0.638, d2=0.665 g=0.781\n",
      ">4, 330/468, d1=0.643, d2=0.639 g=0.785\n",
      ">4, 331/468, d1=0.642, d2=0.652 g=0.781\n",
      ">4, 332/468, d1=0.652, d2=0.637 g=0.787\n",
      ">4, 333/468, d1=0.663, d2=0.637 g=0.785\n",
      ">4, 334/468, d1=0.633, d2=0.643 g=0.798\n",
      ">4, 335/468, d1=0.674, d2=0.637 g=0.787\n",
      ">4, 336/468, d1=0.646, d2=0.667 g=0.805\n",
      ">4, 337/468, d1=0.698, d2=0.648 g=0.790\n",
      ">4, 338/468, d1=0.646, d2=0.652 g=0.751\n",
      ">4, 339/468, d1=0.653, d2=0.666 g=0.781\n",
      ">4, 340/468, d1=0.642, d2=0.648 g=0.759\n",
      ">4, 341/468, d1=0.639, d2=0.679 g=0.771\n",
      ">4, 342/468, d1=0.659, d2=0.665 g=0.759\n",
      ">4, 343/468, d1=0.633, d2=0.666 g=0.767\n",
      ">4, 344/468, d1=0.617, d2=0.646 g=0.771\n",
      ">4, 345/468, d1=0.656, d2=0.658 g=0.782\n",
      ">4, 346/468, d1=0.660, d2=0.656 g=0.768\n",
      ">4, 347/468, d1=0.643, d2=0.656 g=0.760\n",
      ">4, 348/468, d1=0.653, d2=0.668 g=0.772\n",
      ">4, 349/468, d1=0.645, d2=0.679 g=0.777\n",
      ">4, 350/468, d1=0.655, d2=0.640 g=0.765\n",
      ">4, 351/468, d1=0.642, d2=0.638 g=0.783\n",
      ">4, 352/468, d1=0.665, d2=0.653 g=0.761\n",
      ">4, 353/468, d1=0.653, d2=0.679 g=0.755\n",
      ">4, 354/468, d1=0.666, d2=0.684 g=0.769\n",
      ">4, 355/468, d1=0.656, d2=0.688 g=0.767\n",
      ">4, 356/468, d1=0.653, d2=0.666 g=0.767\n",
      ">4, 357/468, d1=0.638, d2=0.676 g=0.759\n",
      ">4, 358/468, d1=0.666, d2=0.673 g=0.755\n",
      ">4, 359/468, d1=0.646, d2=0.665 g=0.767\n",
      ">4, 360/468, d1=0.642, d2=0.700 g=0.750\n",
      ">4, 361/468, d1=0.674, d2=0.675 g=0.763\n",
      ">4, 362/468, d1=0.667, d2=0.680 g=0.749\n",
      ">4, 363/468, d1=0.651, d2=0.662 g=0.759\n",
      ">4, 364/468, d1=0.645, d2=0.658 g=0.746\n",
      ">4, 365/468, d1=0.656, d2=0.672 g=0.755\n",
      ">4, 366/468, d1=0.646, d2=0.652 g=0.765\n",
      ">4, 367/468, d1=0.663, d2=0.664 g=0.770\n",
      ">4, 368/468, d1=0.645, d2=0.655 g=0.784\n",
      ">4, 369/468, d1=0.672, d2=0.649 g=0.785\n",
      ">4, 370/468, d1=0.669, d2=0.636 g=0.798\n",
      ">4, 371/468, d1=0.654, d2=0.661 g=0.777\n",
      ">4, 372/468, d1=0.681, d2=0.656 g=0.805\n",
      ">4, 373/468, d1=0.664, d2=0.652 g=0.786\n",
      ">4, 374/468, d1=0.668, d2=0.639 g=0.776\n",
      ">4, 375/468, d1=0.653, d2=0.652 g=0.764\n",
      ">4, 376/468, d1=0.660, d2=0.669 g=0.769\n",
      ">4, 377/468, d1=0.652, d2=0.655 g=0.787\n",
      ">4, 378/468, d1=0.675, d2=0.669 g=0.767\n",
      ">4, 379/468, d1=0.651, d2=0.674 g=0.757\n",
      ">4, 380/468, d1=0.668, d2=0.642 g=0.761\n",
      ">4, 381/468, d1=0.663, d2=0.655 g=0.781\n",
      ">4, 382/468, d1=0.646, d2=0.650 g=0.788\n",
      ">4, 383/468, d1=0.624, d2=0.663 g=0.763\n",
      ">4, 384/468, d1=0.697, d2=0.650 g=0.755\n",
      ">4, 385/468, d1=0.657, d2=0.665 g=0.758\n",
      ">4, 386/468, d1=0.682, d2=0.662 g=0.786\n",
      ">4, 387/468, d1=0.696, d2=0.682 g=0.757\n",
      ">4, 388/468, d1=0.667, d2=0.679 g=0.791\n",
      ">4, 389/468, d1=0.687, d2=0.667 g=0.797\n",
      ">4, 390/468, d1=0.662, d2=0.651 g=0.808\n",
      ">4, 391/468, d1=0.673, d2=0.644 g=0.833\n",
      ">4, 392/468, d1=0.678, d2=0.626 g=0.834\n",
      ">4, 393/468, d1=0.690, d2=0.614 g=0.817\n",
      ">4, 394/468, d1=0.665, d2=0.624 g=0.809\n",
      ">4, 395/468, d1=0.665, d2=0.628 g=0.793\n",
      ">4, 396/468, d1=0.688, d2=0.642 g=0.790\n",
      ">4, 397/468, d1=0.670, d2=0.660 g=0.794\n",
      ">4, 398/468, d1=0.672, d2=0.647 g=0.781\n",
      ">4, 399/468, d1=0.662, d2=0.641 g=0.799\n",
      ">4, 400/468, d1=0.644, d2=0.660 g=0.790\n",
      ">4, 401/468, d1=0.624, d2=0.632 g=0.819\n",
      ">4, 402/468, d1=0.656, d2=0.637 g=0.790\n",
      ">4, 403/468, d1=0.636, d2=0.678 g=0.780\n",
      ">4, 404/468, d1=0.679, d2=0.690 g=0.757\n",
      ">4, 405/468, d1=0.653, d2=0.703 g=0.757\n",
      ">4, 406/468, d1=0.663, d2=0.674 g=0.776\n",
      ">4, 407/468, d1=0.692, d2=0.653 g=0.825\n",
      ">4, 408/468, d1=0.690, d2=0.595 g=0.841\n",
      ">4, 409/468, d1=0.715, d2=0.618 g=0.855\n",
      ">4, 410/468, d1=0.701, d2=0.632 g=0.846\n",
      ">4, 411/468, d1=0.733, d2=0.616 g=0.829\n",
      ">4, 412/468, d1=0.703, d2=0.618 g=0.819\n",
      ">4, 413/468, d1=0.693, d2=0.634 g=0.797\n",
      ">4, 414/468, d1=0.695, d2=0.691 g=0.755\n",
      ">4, 415/468, d1=0.649, d2=0.674 g=0.750\n",
      ">4, 416/468, d1=0.677, d2=0.655 g=0.766\n",
      ">4, 417/468, d1=0.649, d2=0.645 g=0.793\n",
      ">4, 418/468, d1=0.646, d2=0.637 g=0.813\n",
      ">4, 419/468, d1=0.624, d2=0.604 g=0.827\n",
      ">4, 420/468, d1=0.647, d2=0.663 g=0.801\n",
      ">4, 421/468, d1=0.612, d2=0.677 g=0.783\n",
      ">4, 422/468, d1=0.633, d2=0.727 g=0.735\n",
      ">4, 423/468, d1=0.615, d2=0.723 g=0.742\n",
      ">4, 424/468, d1=0.644, d2=0.742 g=0.739\n",
      ">4, 425/468, d1=0.641, d2=0.707 g=0.802\n",
      ">4, 426/468, d1=0.653, d2=0.672 g=0.869\n",
      ">4, 427/468, d1=0.655, d2=0.594 g=0.894\n",
      ">4, 428/468, d1=0.705, d2=0.601 g=0.938\n",
      ">4, 429/468, d1=0.703, d2=0.544 g=0.931\n",
      ">4, 430/468, d1=0.733, d2=0.551 g=0.898\n",
      ">4, 431/468, d1=0.761, d2=0.624 g=0.863\n",
      ">4, 432/468, d1=0.702, d2=0.665 g=0.795\n",
      ">4, 433/468, d1=0.679, d2=0.689 g=0.765\n",
      ">4, 434/468, d1=0.706, d2=0.677 g=0.740\n",
      ">4, 435/468, d1=0.691, d2=0.692 g=0.764\n",
      ">4, 436/468, d1=0.681, d2=0.665 g=0.792\n",
      ">4, 437/468, d1=0.636, d2=0.648 g=0.810\n",
      ">4, 438/468, d1=0.638, d2=0.598 g=0.844\n",
      ">4, 439/468, d1=0.610, d2=0.591 g=0.846\n",
      ">4, 440/468, d1=0.650, d2=0.606 g=0.835\n",
      ">4, 441/468, d1=0.678, d2=0.646 g=0.793\n",
      ">4, 442/468, d1=0.636, d2=0.644 g=0.769\n",
      ">4, 443/468, d1=0.663, d2=0.740 g=0.762\n",
      ">4, 444/468, d1=0.652, d2=0.720 g=0.748\n",
      ">4, 445/468, d1=0.619, d2=0.693 g=0.747\n",
      ">4, 446/468, d1=0.648, d2=0.715 g=0.762\n",
      ">4, 447/468, d1=0.670, d2=0.621 g=0.830\n",
      ">4, 448/468, d1=0.692, d2=0.619 g=0.907\n",
      ">4, 449/468, d1=0.698, d2=0.569 g=0.939\n",
      ">4, 450/468, d1=0.651, d2=0.528 g=0.970\n",
      ">4, 451/468, d1=0.735, d2=0.585 g=0.894\n",
      ">4, 452/468, d1=0.669, d2=0.619 g=0.860\n",
      ">4, 453/468, d1=0.712, d2=0.639 g=0.802\n",
      ">4, 454/468, d1=0.693, d2=0.658 g=0.765\n",
      ">4, 455/468, d1=0.710, d2=0.692 g=0.778\n",
      ">4, 456/468, d1=0.657, d2=0.643 g=0.772\n",
      ">4, 457/468, d1=0.664, d2=0.662 g=0.776\n",
      ">4, 458/468, d1=0.645, d2=0.652 g=0.815\n",
      ">4, 459/468, d1=0.638, d2=0.626 g=0.833\n",
      ">4, 460/468, d1=0.607, d2=0.623 g=0.827\n",
      ">4, 461/468, d1=0.615, d2=0.638 g=0.850\n",
      ">4, 462/468, d1=0.588, d2=0.648 g=0.829\n",
      ">4, 463/468, d1=0.628, d2=0.636 g=0.799\n",
      ">4, 464/468, d1=0.692, d2=0.701 g=0.749\n",
      ">4, 465/468, d1=0.622, d2=0.741 g=0.720\n",
      ">4, 466/468, d1=0.649, d2=0.708 g=0.743\n",
      ">4, 467/468, d1=0.655, d2=0.685 g=0.770\n",
      ">4, 468/468, d1=0.633, d2=0.671 g=0.819\n",
      ">5, 1/468, d1=0.657, d2=0.631 g=0.828\n",
      ">5, 2/468, d1=0.674, d2=0.604 g=0.871\n",
      ">5, 3/468, d1=0.667, d2=0.610 g=0.888\n",
      ">5, 4/468, d1=0.701, d2=0.622 g=0.885\n",
      ">5, 5/468, d1=0.703, d2=0.613 g=0.837\n",
      ">5, 6/468, d1=0.713, d2=0.643 g=0.795\n",
      ">5, 7/468, d1=0.615, d2=0.650 g=0.785\n",
      ">5, 8/468, d1=0.690, d2=0.670 g=0.788\n",
      ">5, 9/468, d1=0.710, d2=0.666 g=0.754\n",
      ">5, 10/468, d1=0.645, d2=0.651 g=0.784\n",
      ">5, 11/468, d1=0.640, d2=0.658 g=0.780\n",
      ">5, 12/468, d1=0.643, d2=0.653 g=0.780\n",
      ">5, 13/468, d1=0.640, d2=0.636 g=0.774\n",
      ">5, 14/468, d1=0.616, d2=0.659 g=0.767\n",
      ">5, 15/468, d1=0.640, d2=0.672 g=0.778\n",
      ">5, 16/468, d1=0.652, d2=0.656 g=0.775\n",
      ">5, 17/468, d1=0.600, d2=0.653 g=0.737\n",
      ">5, 18/468, d1=0.658, d2=0.705 g=0.746\n",
      ">5, 19/468, d1=0.648, d2=0.688 g=0.758\n",
      ">5, 20/468, d1=0.659, d2=0.689 g=0.763\n",
      ">5, 21/468, d1=0.648, d2=0.679 g=0.778\n",
      ">5, 22/468, d1=0.648, d2=0.623 g=0.796\n",
      ">5, 23/468, d1=0.634, d2=0.649 g=0.824\n",
      ">5, 24/468, d1=0.677, d2=0.603 g=0.806\n",
      ">5, 25/468, d1=0.685, d2=0.632 g=0.799\n",
      ">5, 26/468, d1=0.656, d2=0.651 g=0.771\n",
      ">5, 27/468, d1=0.662, d2=0.642 g=0.789\n",
      ">5, 28/468, d1=0.679, d2=0.657 g=0.774\n",
      ">5, 29/468, d1=0.664, d2=0.676 g=0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">5, 30/468, d1=0.666, d2=0.683 g=0.743\n",
      ">5, 31/468, d1=0.649, d2=0.694 g=0.768\n",
      ">5, 32/468, d1=0.649, d2=0.645 g=0.804\n",
      ">5, 33/468, d1=0.636, d2=0.661 g=0.799\n",
      ">5, 34/468, d1=0.656, d2=0.649 g=0.792\n",
      ">5, 35/468, d1=0.612, d2=0.635 g=0.793\n",
      ">5, 36/468, d1=0.653, d2=0.651 g=0.762\n",
      ">5, 37/468, d1=0.650, d2=0.707 g=0.752\n",
      ">5, 38/468, d1=0.590, d2=0.686 g=0.732\n",
      ">5, 39/468, d1=0.629, d2=0.706 g=0.734\n",
      ">5, 40/468, d1=0.644, d2=0.724 g=0.764\n",
      ">5, 41/468, d1=0.635, d2=0.710 g=0.766\n",
      ">5, 42/468, d1=0.654, d2=0.662 g=0.840\n",
      ">5, 43/468, d1=0.683, d2=0.634 g=0.853\n",
      ">5, 44/468, d1=0.689, d2=0.589 g=0.876\n",
      ">5, 45/468, d1=0.679, d2=0.570 g=0.894\n",
      ">5, 46/468, d1=0.704, d2=0.610 g=0.874\n",
      ">5, 47/468, d1=0.712, d2=0.625 g=0.844\n",
      ">5, 48/468, d1=0.703, d2=0.638 g=0.791\n",
      ">5, 49/468, d1=0.650, d2=0.654 g=0.783\n",
      ">5, 50/468, d1=0.679, d2=0.664 g=0.760\n",
      ">5, 51/468, d1=0.694, d2=0.678 g=0.771\n",
      ">5, 52/468, d1=0.629, d2=0.659 g=0.778\n",
      ">5, 53/468, d1=0.689, d2=0.671 g=0.771\n",
      ">5, 54/468, d1=0.643, d2=0.669 g=0.775\n",
      ">5, 55/468, d1=0.598, d2=0.662 g=0.793\n",
      ">5, 56/468, d1=0.622, d2=0.643 g=0.764\n",
      ">5, 57/468, d1=0.684, d2=0.694 g=0.771\n",
      ">5, 58/468, d1=0.645, d2=0.719 g=0.790\n",
      ">5, 59/468, d1=0.655, d2=0.630 g=0.745\n",
      ">5, 60/468, d1=0.667, d2=0.685 g=0.752\n",
      ">5, 61/468, d1=0.654, d2=0.674 g=0.759\n",
      ">5, 62/468, d1=0.647, d2=0.672 g=0.778\n",
      ">5, 63/468, d1=0.695, d2=0.636 g=0.781\n",
      ">5, 64/468, d1=0.670, d2=0.619 g=0.815\n",
      ">5, 65/468, d1=0.667, d2=0.636 g=0.807\n",
      ">5, 66/468, d1=0.678, d2=0.599 g=0.833\n",
      ">5, 67/468, d1=0.685, d2=0.636 g=0.787\n",
      ">5, 68/468, d1=0.683, d2=0.676 g=0.772\n",
      ">5, 69/468, d1=0.656, d2=0.669 g=0.759\n",
      ">5, 70/468, d1=0.724, d2=0.693 g=0.755\n",
      ">5, 71/468, d1=0.647, d2=0.673 g=0.750\n",
      ">5, 72/468, d1=0.632, d2=0.659 g=0.775\n",
      ">5, 73/468, d1=0.650, d2=0.652 g=0.774\n",
      ">5, 74/468, d1=0.696, d2=0.668 g=0.772\n",
      ">5, 75/468, d1=0.619, d2=0.648 g=0.761\n",
      ">5, 76/468, d1=0.645, d2=0.670 g=0.747\n",
      ">5, 77/468, d1=0.657, d2=0.676 g=0.748\n",
      ">5, 78/468, d1=0.630, d2=0.702 g=0.731\n",
      ">5, 79/468, d1=0.666, d2=0.707 g=0.766\n",
      ">5, 80/468, d1=0.642, d2=0.689 g=0.774\n",
      ">5, 81/468, d1=0.653, d2=0.693 g=0.745\n",
      ">5, 82/468, d1=0.655, d2=0.664 g=0.787\n",
      ">5, 83/468, d1=0.660, d2=0.649 g=0.819\n",
      ">5, 84/468, d1=0.687, d2=0.635 g=0.830\n",
      ">5, 85/468, d1=0.668, d2=0.624 g=0.864\n",
      ">5, 86/468, d1=0.679, d2=0.577 g=0.851\n",
      ">5, 87/468, d1=0.691, d2=0.597 g=0.837\n",
      ">5, 88/468, d1=0.711, d2=0.670 g=0.799\n",
      ">5, 89/468, d1=0.694, d2=0.653 g=0.759\n",
      ">5, 90/468, d1=0.693, d2=0.673 g=0.745\n",
      ">5, 91/468, d1=0.674, d2=0.670 g=0.746\n",
      ">5, 92/468, d1=0.627, d2=0.684 g=0.758\n",
      ">5, 93/468, d1=0.649, d2=0.676 g=0.787\n",
      ">5, 94/468, d1=0.646, d2=0.672 g=0.796\n",
      ">5, 95/468, d1=0.649, d2=0.650 g=0.770\n",
      ">5, 96/468, d1=0.662, d2=0.668 g=0.791\n",
      ">5, 97/468, d1=0.626, d2=0.688 g=0.782\n",
      ">5, 98/468, d1=0.659, d2=0.732 g=0.746\n",
      ">5, 99/468, d1=0.621, d2=0.702 g=0.742\n",
      ">5, 100/468, d1=0.654, d2=0.690 g=0.765\n",
      ">5, 101/468, d1=0.644, d2=0.656 g=0.786\n",
      ">5, 102/468, d1=0.645, d2=0.631 g=0.815\n",
      ">5, 103/468, d1=0.675, d2=0.627 g=0.814\n",
      ">5, 104/468, d1=0.700, d2=0.625 g=0.828\n",
      ">5, 105/468, d1=0.685, d2=0.617 g=0.835\n",
      ">5, 106/468, d1=0.704, d2=0.634 g=0.834\n",
      ">5, 107/468, d1=0.722, d2=0.633 g=0.806\n",
      ">5, 108/468, d1=0.687, d2=0.641 g=0.789\n",
      ">5, 109/468, d1=0.690, d2=0.637 g=0.769\n",
      ">5, 110/468, d1=0.650, d2=0.648 g=0.770\n",
      ">5, 111/468, d1=0.653, d2=0.669 g=0.786\n",
      ">5, 112/468, d1=0.666, d2=0.668 g=0.781\n",
      ">5, 113/468, d1=0.639, d2=0.663 g=0.778\n",
      ">5, 114/468, d1=0.659, d2=0.665 g=0.778\n",
      ">5, 115/468, d1=0.653, d2=0.673 g=0.772\n",
      ">5, 116/468, d1=0.618, d2=0.680 g=0.765\n",
      ">5, 117/468, d1=0.677, d2=0.673 g=0.794\n",
      ">5, 118/468, d1=0.705, d2=0.651 g=0.758\n",
      ">5, 119/468, d1=0.660, d2=0.669 g=0.772\n",
      ">5, 120/468, d1=0.664, d2=0.670 g=0.758\n",
      ">5, 121/468, d1=0.665, d2=0.676 g=0.811\n",
      ">5, 122/468, d1=0.683, d2=0.651 g=0.804\n",
      ">5, 123/468, d1=0.672, d2=0.649 g=0.800\n",
      ">5, 124/468, d1=0.688, d2=0.655 g=0.775\n",
      ">5, 125/468, d1=0.654, d2=0.639 g=0.752\n",
      ">5, 126/468, d1=0.672, d2=0.652 g=0.769\n",
      ">5, 127/468, d1=0.652, d2=0.658 g=0.782\n",
      ">5, 128/468, d1=0.667, d2=0.675 g=0.776\n",
      ">5, 129/468, d1=0.655, d2=0.646 g=0.776\n",
      ">5, 130/468, d1=0.636, d2=0.675 g=0.767\n",
      ">5, 131/468, d1=0.687, d2=0.632 g=0.758\n",
      ">5, 132/468, d1=0.632, d2=0.680 g=0.801\n",
      ">5, 133/468, d1=0.672, d2=0.665 g=0.769\n",
      ">5, 134/468, d1=0.676, d2=0.681 g=0.751\n",
      ">5, 135/468, d1=0.671, d2=0.690 g=0.763\n",
      ">5, 136/468, d1=0.624, d2=0.670 g=0.779\n",
      ">5, 137/468, d1=0.682, d2=0.668 g=0.795\n",
      ">5, 138/468, d1=0.665, d2=0.628 g=0.835\n",
      ">5, 139/468, d1=0.667, d2=0.609 g=0.832\n",
      ">5, 140/468, d1=0.706, d2=0.617 g=0.846\n",
      ">5, 141/468, d1=0.688, d2=0.626 g=0.821\n",
      ">5, 142/468, d1=0.678, d2=0.631 g=0.815\n",
      ">5, 143/468, d1=0.698, d2=0.702 g=0.772\n",
      ">5, 144/468, d1=0.675, d2=0.658 g=0.758\n",
      ">5, 145/468, d1=0.681, d2=0.673 g=0.767\n",
      ">5, 146/468, d1=0.659, d2=0.673 g=0.773\n",
      ">5, 147/468, d1=0.639, d2=0.651 g=0.788\n",
      ">5, 148/468, d1=0.662, d2=0.633 g=0.799\n",
      ">5, 149/468, d1=0.640, d2=0.646 g=0.794\n",
      ">5, 150/468, d1=0.651, d2=0.676 g=0.763\n",
      ">5, 151/468, d1=0.656, d2=0.702 g=0.780\n",
      ">5, 152/468, d1=0.638, d2=0.701 g=0.776\n",
      ">5, 153/468, d1=0.703, d2=0.662 g=0.762\n",
      ">5, 154/468, d1=0.670, d2=0.679 g=0.774\n",
      ">5, 155/468, d1=0.666, d2=0.638 g=0.810\n",
      ">5, 156/468, d1=0.684, d2=0.616 g=0.832\n",
      ">5, 157/468, d1=0.697, d2=0.591 g=0.853\n",
      ">5, 158/468, d1=0.719, d2=0.610 g=0.855\n",
      ">5, 159/468, d1=0.720, d2=0.611 g=0.850\n",
      ">5, 160/468, d1=0.701, d2=0.649 g=0.823\n",
      ">5, 161/468, d1=0.705, d2=0.674 g=0.783\n",
      ">5, 162/468, d1=0.681, d2=0.687 g=0.772\n",
      ">5, 163/468, d1=0.688, d2=0.665 g=0.777\n",
      ">5, 164/468, d1=0.643, d2=0.657 g=0.808\n",
      ">5, 165/468, d1=0.662, d2=0.622 g=0.816\n",
      ">5, 166/468, d1=0.659, d2=0.629 g=0.844\n",
      ">5, 167/468, d1=0.662, d2=0.646 g=0.802\n",
      ">5, 168/468, d1=0.664, d2=0.696 g=0.766\n",
      ">5, 169/468, d1=0.652, d2=0.711 g=0.753\n",
      ">5, 170/468, d1=0.619, d2=0.712 g=0.744\n",
      ">5, 171/468, d1=0.663, d2=0.677 g=0.765\n",
      ">5, 172/468, d1=0.716, d2=0.659 g=0.816\n",
      ">5, 173/468, d1=0.672, d2=0.620 g=0.858\n",
      ">5, 174/468, d1=0.687, d2=0.614 g=0.874\n",
      ">5, 175/468, d1=0.709, d2=0.617 g=0.839\n",
      ">5, 176/468, d1=0.720, d2=0.621 g=0.814\n",
      ">5, 177/468, d1=0.682, d2=0.623 g=0.789\n",
      ">5, 178/468, d1=0.700, d2=0.663 g=0.786\n",
      ">5, 179/468, d1=0.685, d2=0.669 g=0.784\n",
      ">5, 180/468, d1=0.688, d2=0.662 g=0.775\n",
      ">5, 181/468, d1=0.683, d2=0.660 g=0.775\n",
      ">5, 182/468, d1=0.656, d2=0.679 g=0.793\n",
      ">5, 183/468, d1=0.624, d2=0.642 g=0.795\n",
      ">5, 184/468, d1=0.679, d2=0.647 g=0.780\n",
      ">5, 185/468, d1=0.616, d2=0.649 g=0.791\n",
      ">5, 186/468, d1=0.651, d2=0.682 g=0.768\n",
      ">5, 187/468, d1=0.635, d2=0.682 g=0.769\n",
      ">5, 188/468, d1=0.616, d2=0.674 g=0.762\n",
      ">5, 189/468, d1=0.649, d2=0.694 g=0.750\n",
      ">5, 190/468, d1=0.637, d2=0.660 g=0.795\n",
      ">5, 191/468, d1=0.649, d2=0.637 g=0.823\n",
      ">5, 192/468, d1=0.693, d2=0.631 g=0.829\n",
      ">5, 193/468, d1=0.687, d2=0.619 g=0.830\n",
      ">5, 194/468, d1=0.713, d2=0.614 g=0.842\n",
      ">5, 195/468, d1=0.746, d2=0.631 g=0.804\n",
      ">5, 196/468, d1=0.658, d2=0.648 g=0.798\n",
      ">5, 197/468, d1=0.703, d2=0.637 g=0.788\n",
      ">5, 198/468, d1=0.660, d2=0.676 g=0.759\n",
      ">5, 199/468, d1=0.678, d2=0.677 g=0.764\n",
      ">5, 200/468, d1=0.679, d2=0.663 g=0.788\n",
      ">5, 201/468, d1=0.651, d2=0.626 g=0.766\n",
      ">5, 202/468, d1=0.639, d2=0.658 g=0.804\n",
      ">5, 203/468, d1=0.671, d2=0.615 g=0.787\n",
      ">5, 204/468, d1=0.668, d2=0.681 g=0.750\n",
      ">5, 205/468, d1=0.638, d2=0.768 g=0.741\n",
      ">5, 206/468, d1=0.660, d2=0.714 g=0.735\n",
      ">5, 207/468, d1=0.632, d2=0.718 g=0.783\n",
      ">5, 208/468, d1=0.673, d2=0.661 g=0.783\n",
      ">5, 209/468, d1=0.646, d2=0.645 g=0.817\n",
      ">5, 210/468, d1=0.714, d2=0.644 g=0.820\n",
      ">5, 211/468, d1=0.683, d2=0.626 g=0.826\n",
      ">5, 212/468, d1=0.693, d2=0.620 g=0.827\n",
      ">5, 213/468, d1=0.717, d2=0.626 g=0.812\n",
      ">5, 214/468, d1=0.664, d2=0.644 g=0.797\n",
      ">5, 215/468, d1=0.684, d2=0.657 g=0.777\n",
      ">5, 216/468, d1=0.686, d2=0.659 g=0.779\n",
      ">5, 217/468, d1=0.688, d2=0.664 g=0.769\n",
      ">5, 218/468, d1=0.657, d2=0.655 g=0.763\n",
      ">5, 219/468, d1=0.688, d2=0.666 g=0.758\n",
      ">5, 220/468, d1=0.653, d2=0.668 g=0.775\n",
      ">5, 221/468, d1=0.655, d2=0.648 g=0.781\n",
      ">5, 222/468, d1=0.632, d2=0.655 g=0.751\n",
      ">5, 223/468, d1=0.657, d2=0.657 g=0.790\n",
      ">5, 224/468, d1=0.653, d2=0.671 g=0.758\n",
      ">5, 225/468, d1=0.661, d2=0.691 g=0.777\n",
      ">5, 226/468, d1=0.642, d2=0.680 g=0.748\n",
      ">5, 227/468, d1=0.668, d2=0.696 g=0.771\n",
      ">5, 228/468, d1=0.664, d2=0.631 g=0.789\n",
      ">5, 229/468, d1=0.667, d2=0.636 g=0.802\n",
      ">5, 230/468, d1=0.685, d2=0.646 g=0.812\n",
      ">5, 231/468, d1=0.648, d2=0.652 g=0.808\n",
      ">5, 232/468, d1=0.704, d2=0.632 g=0.811\n",
      ">5, 233/468, d1=0.663, d2=0.631 g=0.793\n",
      ">5, 234/468, d1=0.668, d2=0.629 g=0.793\n",
      ">5, 235/468, d1=0.646, d2=0.628 g=0.783\n",
      ">5, 236/468, d1=0.659, d2=0.663 g=0.763\n",
      ">5, 237/468, d1=0.655, d2=0.660 g=0.766\n",
      ">5, 238/468, d1=0.639, d2=0.670 g=0.782\n",
      ">5, 239/468, d1=0.651, d2=0.661 g=0.785\n",
      ">5, 240/468, d1=0.646, d2=0.653 g=0.787\n",
      ">5, 241/468, d1=0.671, d2=0.641 g=0.794\n",
      ">5, 242/468, d1=0.645, d2=0.671 g=0.762\n",
      ">5, 243/468, d1=0.639, d2=0.684 g=0.753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">5, 244/468, d1=0.673, d2=0.677 g=0.768\n",
      ">5, 245/468, d1=0.650, d2=0.672 g=0.749\n",
      ">5, 246/468, d1=0.689, d2=0.640 g=0.792\n",
      ">5, 247/468, d1=0.634, d2=0.639 g=0.821\n",
      ">5, 248/468, d1=0.693, d2=0.638 g=0.798\n",
      ">5, 249/468, d1=0.700, d2=0.666 g=0.795\n",
      ">5, 250/468, d1=0.700, d2=0.668 g=0.767\n",
      ">5, 251/468, d1=0.650, d2=0.661 g=0.757\n",
      ">5, 252/468, d1=0.657, d2=0.682 g=0.781\n",
      ">5, 253/468, d1=0.687, d2=0.671 g=0.775\n",
      ">5, 254/468, d1=0.661, d2=0.657 g=0.767\n",
      ">5, 255/468, d1=0.653, d2=0.673 g=0.757\n",
      ">5, 256/468, d1=0.637, d2=0.675 g=0.754\n",
      ">5, 257/468, d1=0.651, d2=0.666 g=0.736\n",
      ">5, 258/468, d1=0.640, d2=0.702 g=0.741\n",
      ">5, 259/468, d1=0.601, d2=0.716 g=0.722\n",
      ">5, 260/468, d1=0.649, d2=0.720 g=0.740\n",
      ">5, 261/468, d1=0.660, d2=0.701 g=0.756\n",
      ">5, 262/468, d1=0.660, d2=0.650 g=0.807\n",
      ">5, 263/468, d1=0.680, d2=0.648 g=0.829\n",
      ">5, 264/468, d1=0.659, d2=0.616 g=0.851\n",
      ">5, 265/468, d1=0.690, d2=0.648 g=0.805\n",
      ">5, 266/468, d1=0.718, d2=0.655 g=0.771\n",
      ">5, 267/468, d1=0.658, d2=0.694 g=0.754\n",
      ">5, 268/468, d1=0.677, d2=0.702 g=0.724\n",
      ">5, 269/468, d1=0.676, d2=0.692 g=0.772\n",
      ">5, 270/468, d1=0.649, d2=0.642 g=0.823\n",
      ">5, 271/468, d1=0.633, d2=0.609 g=0.827\n",
      ">5, 272/468, d1=0.646, d2=0.629 g=0.827\n",
      ">5, 273/468, d1=0.611, d2=0.735 g=0.785\n",
      ">5, 274/468, d1=0.650, d2=0.790 g=0.708\n",
      ">5, 275/468, d1=0.633, d2=0.811 g=0.704\n",
      ">5, 276/468, d1=0.671, d2=0.742 g=0.747\n",
      ">5, 277/468, d1=0.655, d2=0.679 g=0.851\n",
      ">5, 278/468, d1=0.696, d2=0.595 g=0.902\n",
      ">5, 279/468, d1=0.705, d2=0.577 g=0.935\n",
      ">5, 280/468, d1=0.705, d2=0.560 g=0.962\n",
      ">5, 281/468, d1=0.703, d2=0.625 g=0.900\n",
      ">5, 282/468, d1=0.716, d2=0.619 g=0.852\n",
      ">5, 283/468, d1=0.750, d2=0.649 g=0.761\n",
      ">5, 284/468, d1=0.707, d2=0.721 g=0.718\n",
      ">5, 285/468, d1=0.665, d2=0.733 g=0.740\n",
      ">5, 286/468, d1=0.641, d2=0.681 g=0.774\n",
      ">5, 287/468, d1=0.655, d2=0.643 g=0.847\n",
      ">5, 288/468, d1=0.671, d2=0.590 g=0.875\n",
      ">5, 289/468, d1=0.656, d2=0.587 g=0.870\n",
      ">5, 290/468, d1=0.632, d2=0.637 g=0.813\n",
      ">5, 291/468, d1=0.646, d2=0.696 g=0.787\n",
      ">5, 292/468, d1=0.623, d2=0.704 g=0.696\n",
      ">5, 293/468, d1=0.587, d2=0.762 g=0.671\n",
      ">5, 294/468, d1=0.616, d2=0.762 g=0.695\n",
      ">5, 295/468, d1=0.609, d2=0.734 g=0.725\n",
      ">5, 296/468, d1=0.667, d2=0.721 g=0.785\n",
      ">5, 297/468, d1=0.670, d2=0.649 g=0.873\n",
      ">5, 298/468, d1=0.705, d2=0.572 g=0.931\n",
      ">5, 299/468, d1=0.703, d2=0.563 g=0.948\n",
      ">5, 300/468, d1=0.715, d2=0.535 g=0.943\n",
      ">5, 301/468, d1=0.675, d2=0.562 g=0.952\n",
      ">5, 302/468, d1=0.667, d2=0.611 g=0.857\n",
      ">5, 303/468, d1=0.684, d2=0.682 g=0.786\n",
      ">5, 304/468, d1=0.719, d2=0.714 g=0.744\n",
      ">5, 305/468, d1=0.708, d2=0.732 g=0.711\n",
      ">5, 306/468, d1=0.668, d2=0.720 g=0.739\n",
      ">5, 307/468, d1=0.635, d2=0.665 g=0.802\n",
      ">5, 308/468, d1=0.675, d2=0.644 g=0.791\n",
      ">5, 309/468, d1=0.601, d2=0.608 g=0.818\n",
      ">5, 310/468, d1=0.644, d2=0.651 g=0.798\n",
      ">5, 311/468, d1=0.622, d2=0.705 g=0.751\n",
      ">5, 312/468, d1=0.633, d2=0.704 g=0.726\n",
      ">5, 313/468, d1=0.628, d2=0.742 g=0.698\n",
      ">5, 314/468, d1=0.636, d2=0.770 g=0.708\n",
      ">5, 315/468, d1=0.653, d2=0.739 g=0.748\n",
      ">5, 316/468, d1=0.689, d2=0.653 g=0.809\n",
      ">5, 317/468, d1=0.662, d2=0.623 g=0.835\n",
      ">5, 318/468, d1=0.651, d2=0.601 g=0.908\n",
      ">5, 319/468, d1=0.643, d2=0.579 g=0.936\n",
      ">5, 320/468, d1=0.742, d2=0.639 g=0.861\n",
      ">5, 321/468, d1=0.731, d2=0.651 g=0.816\n",
      ">5, 322/468, d1=0.719, d2=0.654 g=0.753\n",
      ">5, 323/468, d1=0.655, d2=0.674 g=0.743\n",
      ">5, 324/468, d1=0.669, d2=0.674 g=0.751\n",
      ">5, 325/468, d1=0.664, d2=0.670 g=0.767\n",
      ">5, 326/468, d1=0.661, d2=0.648 g=0.769\n",
      ">5, 327/468, d1=0.673, d2=0.661 g=0.786\n",
      ">5, 328/468, d1=0.651, d2=0.669 g=0.804\n",
      ">5, 329/468, d1=0.652, d2=0.651 g=0.754\n",
      ">5, 330/468, d1=0.631, d2=0.686 g=0.755\n",
      ">5, 331/468, d1=0.649, d2=0.690 g=0.760\n",
      ">5, 332/468, d1=0.662, d2=0.677 g=0.756\n",
      ">5, 333/468, d1=0.644, d2=0.695 g=0.758\n",
      ">5, 334/468, d1=0.645, d2=0.660 g=0.782\n",
      ">5, 335/468, d1=0.657, d2=0.680 g=0.785\n",
      ">5, 336/468, d1=0.674, d2=0.629 g=0.790\n",
      ">5, 337/468, d1=0.679, d2=0.645 g=0.785\n",
      ">5, 338/468, d1=0.663, d2=0.647 g=0.807\n",
      ">5, 339/468, d1=0.662, d2=0.636 g=0.801\n",
      ">5, 340/468, d1=0.699, d2=0.622 g=0.800\n",
      ">5, 341/468, d1=0.664, d2=0.652 g=0.785\n",
      ">5, 342/468, d1=0.693, d2=0.658 g=0.798\n",
      ">5, 343/468, d1=0.676, d2=0.649 g=0.757\n",
      ">5, 344/468, d1=0.673, d2=0.635 g=0.764\n",
      ">5, 345/468, d1=0.665, d2=0.650 g=0.757\n",
      ">5, 346/468, d1=0.667, d2=0.665 g=0.770\n",
      ">5, 347/468, d1=0.694, d2=0.692 g=0.759\n",
      ">5, 348/468, d1=0.661, d2=0.664 g=0.742\n",
      ">5, 349/468, d1=0.650, d2=0.655 g=0.766\n",
      ">5, 350/468, d1=0.667, d2=0.681 g=0.773\n",
      ">5, 351/468, d1=0.624, d2=0.654 g=0.766\n",
      ">5, 352/468, d1=0.607, d2=0.688 g=0.741\n",
      ">5, 353/468, d1=0.672, d2=0.683 g=0.761\n",
      ">5, 354/468, d1=0.650, d2=0.681 g=0.755\n",
      ">5, 355/468, d1=0.656, d2=0.664 g=0.770\n",
      ">5, 356/468, d1=0.661, d2=0.655 g=0.790\n",
      ">5, 357/468, d1=0.653, d2=0.652 g=0.803\n",
      ">5, 358/468, d1=0.685, d2=0.611 g=0.829\n",
      ">5, 359/468, d1=0.669, d2=0.646 g=0.841\n",
      ">5, 360/468, d1=0.681, d2=0.617 g=0.822\n",
      ">5, 361/468, d1=0.676, d2=0.642 g=0.813\n",
      ">5, 362/468, d1=0.659, d2=0.652 g=0.793\n",
      ">5, 363/468, d1=0.650, d2=0.665 g=0.781\n",
      ">5, 364/468, d1=0.671, d2=0.659 g=0.770\n",
      ">5, 365/468, d1=0.662, d2=0.663 g=0.749\n",
      ">5, 366/468, d1=0.677, d2=0.655 g=0.776\n",
      ">5, 367/468, d1=0.665, d2=0.672 g=0.767\n",
      ">5, 368/468, d1=0.657, d2=0.662 g=0.789\n",
      ">5, 369/468, d1=0.680, d2=0.656 g=0.816\n",
      ">5, 370/468, d1=0.655, d2=0.638 g=0.816\n",
      ">5, 371/468, d1=0.667, d2=0.654 g=0.790\n",
      ">5, 372/468, d1=0.648, d2=0.681 g=0.761\n",
      ">5, 373/468, d1=0.640, d2=0.714 g=0.741\n",
      ">5, 374/468, d1=0.604, d2=0.716 g=0.727\n",
      ">5, 375/468, d1=0.642, d2=0.707 g=0.771\n",
      ">5, 376/468, d1=0.651, d2=0.691 g=0.782\n",
      ">5, 377/468, d1=0.675, d2=0.639 g=0.796\n",
      ">5, 378/468, d1=0.691, d2=0.650 g=0.856\n",
      ">5, 379/468, d1=0.685, d2=0.621 g=0.871\n",
      ">5, 380/468, d1=0.684, d2=0.607 g=0.865\n",
      ">5, 381/468, d1=0.684, d2=0.597 g=0.840\n",
      ">5, 382/468, d1=0.690, d2=0.611 g=0.832\n",
      ">5, 383/468, d1=0.699, d2=0.646 g=0.790\n",
      ">5, 384/468, d1=0.677, d2=0.645 g=0.781\n",
      ">5, 385/468, d1=0.647, d2=0.678 g=0.780\n",
      ">5, 386/468, d1=0.639, d2=0.650 g=0.782\n",
      ">5, 387/468, d1=0.672, d2=0.669 g=0.803\n",
      ">5, 388/468, d1=0.628, d2=0.627 g=0.796\n",
      ">5, 389/468, d1=0.653, d2=0.598 g=0.844\n",
      ">5, 390/468, d1=0.638, d2=0.647 g=0.824\n",
      ">5, 391/468, d1=0.644, d2=0.693 g=0.764\n",
      ">5, 392/468, d1=0.628, d2=0.703 g=0.771\n",
      ">5, 393/468, d1=0.683, d2=0.689 g=0.757\n",
      ">5, 394/468, d1=0.658, d2=0.692 g=0.796\n",
      ">5, 395/468, d1=0.670, d2=0.664 g=0.805\n",
      ">5, 396/468, d1=0.707, d2=0.628 g=0.802\n",
      ">5, 397/468, d1=0.719, d2=0.642 g=0.825\n",
      ">5, 398/468, d1=0.678, d2=0.595 g=0.861\n",
      ">5, 399/468, d1=0.669, d2=0.605 g=0.858\n",
      ">5, 400/468, d1=0.671, d2=0.582 g=0.890\n",
      ">5, 401/468, d1=0.676, d2=0.646 g=0.829\n",
      ">5, 402/468, d1=0.690, d2=0.641 g=0.795\n",
      ">5, 403/468, d1=0.699, d2=0.675 g=0.744\n",
      ">5, 404/468, d1=0.674, d2=0.690 g=0.770\n",
      ">5, 405/468, d1=0.662, d2=0.675 g=0.793\n",
      ">5, 406/468, d1=0.636, d2=0.626 g=0.825\n",
      ">5, 407/468, d1=0.645, d2=0.633 g=0.853\n",
      ">5, 408/468, d1=0.658, d2=0.634 g=0.788\n",
      ">5, 409/468, d1=0.663, d2=0.668 g=0.786\n",
      ">5, 410/468, d1=0.639, d2=0.696 g=0.744\n",
      ">5, 411/468, d1=0.651, d2=0.680 g=0.718\n",
      ">5, 412/468, d1=0.666, d2=0.728 g=0.725\n",
      ">5, 413/468, d1=0.636, d2=0.705 g=0.811\n",
      ">5, 414/468, d1=0.667, d2=0.637 g=0.826\n",
      ">5, 415/468, d1=0.665, d2=0.574 g=0.894\n",
      ">5, 416/468, d1=0.664, d2=0.589 g=0.912\n",
      ">5, 417/468, d1=0.661, d2=0.613 g=0.898\n",
      ">5, 418/468, d1=0.678, d2=0.622 g=0.876\n",
      ">5, 419/468, d1=0.699, d2=0.659 g=0.815\n",
      ">5, 420/468, d1=0.687, d2=0.677 g=0.783\n",
      ">5, 421/468, d1=0.684, d2=0.670 g=0.782\n",
      ">5, 422/468, d1=0.680, d2=0.673 g=0.787\n",
      ">5, 423/468, d1=0.690, d2=0.635 g=0.809\n",
      ">5, 424/468, d1=0.626, d2=0.621 g=0.826\n",
      ">5, 425/468, d1=0.661, d2=0.600 g=0.833\n",
      ">5, 426/468, d1=0.655, d2=0.612 g=0.790\n",
      ">5, 427/468, d1=0.671, d2=0.662 g=0.761\n",
      ">5, 428/468, d1=0.663, d2=0.718 g=0.737\n",
      ">5, 429/468, d1=0.641, d2=0.704 g=0.758\n",
      ">5, 430/468, d1=0.624, d2=0.680 g=0.774\n",
      ">5, 431/468, d1=0.636, d2=0.641 g=0.778\n",
      ">5, 432/468, d1=0.665, d2=0.668 g=0.811\n",
      ">5, 433/468, d1=0.658, d2=0.628 g=0.823\n",
      ">5, 434/468, d1=0.702, d2=0.625 g=0.819\n",
      ">5, 435/468, d1=0.648, d2=0.628 g=0.828\n",
      ">5, 436/468, d1=0.662, d2=0.624 g=0.830\n",
      ">5, 437/468, d1=0.641, d2=0.652 g=0.798\n",
      ">5, 438/468, d1=0.696, d2=0.650 g=0.806\n",
      ">5, 439/468, d1=0.707, d2=0.656 g=0.779\n",
      ">5, 440/468, d1=0.668, d2=0.630 g=0.796\n",
      ">5, 441/468, d1=0.678, d2=0.634 g=0.785\n",
      ">5, 442/468, d1=0.662, d2=0.645 g=0.820\n",
      ">5, 443/468, d1=0.656, d2=0.658 g=0.806\n",
      ">5, 444/468, d1=0.660, d2=0.658 g=0.792\n",
      ">5, 445/468, d1=0.629, d2=0.671 g=0.773\n",
      ">5, 446/468, d1=0.615, d2=0.661 g=0.761\n",
      ">5, 447/468, d1=0.645, d2=0.686 g=0.744\n",
      ">5, 448/468, d1=0.657, d2=0.687 g=0.761\n",
      ">5, 449/468, d1=0.644, d2=0.650 g=0.779\n",
      ">5, 450/468, d1=0.669, d2=0.655 g=0.785\n",
      ">5, 451/468, d1=0.668, d2=0.605 g=0.810\n",
      ">5, 452/468, d1=0.673, d2=0.632 g=0.820\n",
      ">5, 453/468, d1=0.686, d2=0.623 g=0.826\n",
      ">5, 454/468, d1=0.711, d2=0.655 g=0.771\n",
      ">5, 455/468, d1=0.653, d2=0.686 g=0.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">5, 456/468, d1=0.647, d2=0.654 g=0.775\n",
      ">5, 457/468, d1=0.658, d2=0.662 g=0.742\n",
      ">5, 458/468, d1=0.682, d2=0.657 g=0.773\n",
      ">5, 459/468, d1=0.638, d2=0.656 g=0.792\n",
      ">5, 460/468, d1=0.652, d2=0.628 g=0.813\n",
      ">5, 461/468, d1=0.660, d2=0.649 g=0.803\n",
      ">5, 462/468, d1=0.650, d2=0.698 g=0.776\n",
      ">5, 463/468, d1=0.674, d2=0.661 g=0.768\n",
      ">5, 464/468, d1=0.636, d2=0.692 g=0.750\n",
      ">5, 465/468, d1=0.665, d2=0.676 g=0.770\n",
      ">5, 466/468, d1=0.633, d2=0.666 g=0.796\n",
      ">5, 467/468, d1=0.656, d2=0.653 g=0.778\n",
      ">5, 468/468, d1=0.641, d2=0.649 g=0.807\n",
      ">6, 1/468, d1=0.637, d2=0.639 g=0.818\n",
      ">6, 2/468, d1=0.685, d2=0.638 g=0.821\n",
      ">6, 3/468, d1=0.679, d2=0.601 g=0.797\n",
      ">6, 4/468, d1=0.666, d2=0.644 g=0.797\n",
      ">6, 5/468, d1=0.683, d2=0.650 g=0.792\n",
      ">6, 6/468, d1=0.654, d2=0.665 g=0.790\n",
      ">6, 7/468, d1=0.649, d2=0.659 g=0.787\n",
      ">6, 8/468, d1=0.636, d2=0.637 g=0.793\n",
      ">6, 9/468, d1=0.654, d2=0.670 g=0.802\n",
      ">6, 10/468, d1=0.671, d2=0.673 g=0.766\n",
      ">6, 11/468, d1=0.658, d2=0.639 g=0.794\n",
      ">6, 12/468, d1=0.682, d2=0.660 g=0.797\n",
      ">6, 13/468, d1=0.660, d2=0.665 g=0.790\n",
      ">6, 14/468, d1=0.621, d2=0.658 g=0.769\n",
      ">6, 15/468, d1=0.648, d2=0.658 g=0.812\n",
      ">6, 16/468, d1=0.667, d2=0.648 g=0.801\n",
      ">6, 17/468, d1=0.685, d2=0.631 g=0.822\n",
      ">6, 18/468, d1=0.700, d2=0.638 g=0.819\n",
      ">6, 19/468, d1=0.666, d2=0.646 g=0.842\n",
      ">6, 20/468, d1=0.673, d2=0.600 g=0.848\n",
      ">6, 21/468, d1=0.680, d2=0.625 g=0.797\n",
      ">6, 22/468, d1=0.652, d2=0.638 g=0.797\n",
      ">6, 23/468, d1=0.673, d2=0.640 g=0.784\n",
      ">6, 24/468, d1=0.649, d2=0.647 g=0.773\n",
      ">6, 25/468, d1=0.660, d2=0.632 g=0.780\n",
      ">6, 26/468, d1=0.678, d2=0.654 g=0.784\n",
      ">6, 27/468, d1=0.640, d2=0.639 g=0.769\n",
      ">6, 28/468, d1=0.648, d2=0.680 g=0.761\n",
      ">6, 29/468, d1=0.630, d2=0.680 g=0.748\n",
      ">6, 30/468, d1=0.619, d2=0.676 g=0.771\n",
      ">6, 31/468, d1=0.625, d2=0.678 g=0.781\n",
      ">6, 32/468, d1=0.680, d2=0.657 g=0.805\n",
      ">6, 33/468, d1=0.669, d2=0.641 g=0.837\n",
      ">6, 34/468, d1=0.679, d2=0.614 g=0.840\n",
      ">6, 35/468, d1=0.674, d2=0.594 g=0.836\n",
      ">6, 36/468, d1=0.697, d2=0.627 g=0.833\n",
      ">6, 37/468, d1=0.709, d2=0.622 g=0.783\n",
      ">6, 38/468, d1=0.655, d2=0.658 g=0.789\n",
      ">6, 39/468, d1=0.669, d2=0.656 g=0.799\n",
      ">6, 40/468, d1=0.688, d2=0.647 g=0.781\n",
      ">6, 41/468, d1=0.636, d2=0.655 g=0.785\n",
      ">6, 42/468, d1=0.645, d2=0.645 g=0.789\n",
      ">6, 43/468, d1=0.642, d2=0.642 g=0.826\n",
      ">6, 44/468, d1=0.642, d2=0.639 g=0.785\n",
      ">6, 45/468, d1=0.672, d2=0.675 g=0.767\n",
      ">6, 46/468, d1=0.632, d2=0.671 g=0.769\n",
      ">6, 47/468, d1=0.656, d2=0.691 g=0.759\n",
      ">6, 48/468, d1=0.638, d2=0.683 g=0.761\n",
      ">6, 49/468, d1=0.648, d2=0.633 g=0.773\n",
      ">6, 50/468, d1=0.645, d2=0.625 g=0.809\n",
      ">6, 51/468, d1=0.684, d2=0.614 g=0.811\n",
      ">6, 52/468, d1=0.638, d2=0.661 g=0.834\n",
      ">6, 53/468, d1=0.666, d2=0.662 g=0.803\n",
      ">6, 54/468, d1=0.682, d2=0.649 g=0.782\n",
      ">6, 55/468, d1=0.624, d2=0.664 g=0.791\n",
      ">6, 56/468, d1=0.640, d2=0.653 g=0.802\n",
      ">6, 57/468, d1=0.669, d2=0.645 g=0.798\n",
      ">6, 58/468, d1=0.626, d2=0.637 g=0.806\n",
      ">6, 59/468, d1=0.645, d2=0.645 g=0.795\n",
      ">6, 60/468, d1=0.653, d2=0.631 g=0.770\n",
      ">6, 61/468, d1=0.646, d2=0.656 g=0.791\n",
      ">6, 62/468, d1=0.682, d2=0.676 g=0.786\n",
      ">6, 63/468, d1=0.629, d2=0.646 g=0.791\n",
      ">6, 64/468, d1=0.643, d2=0.636 g=0.808\n",
      ">6, 65/468, d1=0.653, d2=0.653 g=0.799\n",
      ">6, 66/468, d1=0.646, d2=0.640 g=0.848\n",
      ">6, 67/468, d1=0.678, d2=0.615 g=0.847\n",
      ">6, 68/468, d1=0.683, d2=0.713 g=0.798\n",
      ">6, 69/468, d1=0.667, d2=0.641 g=0.797\n",
      ">6, 70/468, d1=0.708, d2=0.645 g=0.788\n",
      ">6, 71/468, d1=0.695, d2=0.657 g=0.795\n",
      ">6, 72/468, d1=0.669, d2=0.667 g=0.786\n",
      ">6, 73/468, d1=0.650, d2=0.623 g=0.823\n",
      ">6, 74/468, d1=0.680, d2=0.641 g=0.824\n",
      ">6, 75/468, d1=0.671, d2=0.640 g=0.797\n",
      ">6, 76/468, d1=0.653, d2=0.658 g=0.797\n",
      ">6, 77/468, d1=0.631, d2=0.691 g=0.801\n",
      ">6, 78/468, d1=0.650, d2=0.637 g=0.805\n",
      ">6, 79/468, d1=0.672, d2=0.639 g=0.806\n",
      ">6, 80/468, d1=0.671, d2=0.647 g=0.828\n",
      ">6, 81/468, d1=0.644, d2=0.627 g=0.856\n",
      ">6, 82/468, d1=0.687, d2=0.598 g=0.841\n",
      ">6, 83/468, d1=0.660, d2=0.626 g=0.821\n",
      ">6, 84/468, d1=0.659, d2=0.656 g=0.785\n",
      ">6, 85/468, d1=0.655, d2=0.630 g=0.792\n",
      ">6, 86/468, d1=0.649, d2=0.666 g=0.785\n",
      ">6, 87/468, d1=0.674, d2=0.666 g=0.771\n",
      ">6, 88/468, d1=0.676, d2=0.635 g=0.810\n",
      ">6, 89/468, d1=0.602, d2=0.639 g=0.807\n",
      ">6, 90/468, d1=0.671, d2=0.664 g=0.781\n",
      ">6, 91/468, d1=0.659, d2=0.660 g=0.787\n",
      ">6, 92/468, d1=0.671, d2=0.640 g=0.774\n",
      ">6, 93/468, d1=0.615, d2=0.663 g=0.801\n",
      ">6, 94/468, d1=0.640, d2=0.654 g=0.795\n",
      ">6, 95/468, d1=0.684, d2=0.634 g=0.826\n",
      ">6, 96/468, d1=0.690, d2=0.628 g=0.877\n",
      ">6, 97/468, d1=0.696, d2=0.649 g=0.825\n",
      ">6, 98/468, d1=0.685, d2=0.613 g=0.806\n",
      ">6, 99/468, d1=0.697, d2=0.633 g=0.796\n",
      ">6, 100/468, d1=0.663, d2=0.654 g=0.796\n",
      ">6, 101/468, d1=0.641, d2=0.635 g=0.799\n",
      ">6, 102/468, d1=0.664, d2=0.647 g=0.801\n",
      ">6, 103/468, d1=0.648, d2=0.642 g=0.839\n",
      ">6, 104/468, d1=0.664, d2=0.629 g=0.809\n",
      ">6, 105/468, d1=0.621, d2=0.650 g=0.793\n",
      ">6, 106/468, d1=0.649, d2=0.672 g=0.772\n",
      ">6, 107/468, d1=0.640, d2=0.671 g=0.778\n",
      ">6, 108/468, d1=0.620, d2=0.670 g=0.785\n",
      ">6, 109/468, d1=0.663, d2=0.675 g=0.799\n",
      ">6, 110/468, d1=0.647, d2=0.653 g=0.817\n",
      ">6, 111/468, d1=0.677, d2=0.650 g=0.817\n",
      ">6, 112/468, d1=0.675, d2=0.647 g=0.852\n",
      ">6, 113/468, d1=0.668, d2=0.642 g=0.822\n",
      ">6, 114/468, d1=0.688, d2=0.624 g=0.799\n",
      ">6, 115/468, d1=0.694, d2=0.644 g=0.816\n",
      ">6, 116/468, d1=0.669, d2=0.629 g=0.808\n",
      ">6, 117/468, d1=0.699, d2=0.628 g=0.814\n",
      ">6, 118/468, d1=0.672, d2=0.621 g=0.796\n",
      ">6, 119/468, d1=0.680, d2=0.663 g=0.817\n",
      ">6, 120/468, d1=0.667, d2=0.652 g=0.788\n",
      ">6, 121/468, d1=0.642, d2=0.660 g=0.801\n",
      ">6, 122/468, d1=0.677, d2=0.610 g=0.794\n",
      ">6, 123/468, d1=0.649, d2=0.644 g=0.786\n",
      ">6, 124/468, d1=0.650, d2=0.656 g=0.810\n",
      ">6, 125/468, d1=0.642, d2=0.629 g=0.818\n",
      ">6, 126/468, d1=0.670, d2=0.618 g=0.806\n",
      ">6, 127/468, d1=0.652, d2=0.632 g=0.795\n",
      ">6, 128/468, d1=0.667, d2=0.646 g=0.791\n",
      ">6, 129/468, d1=0.664, d2=0.609 g=0.805\n",
      ">6, 130/468, d1=0.684, d2=0.630 g=0.840\n",
      ">6, 131/468, d1=0.708, d2=0.647 g=0.834\n",
      ">6, 132/468, d1=0.707, d2=0.619 g=0.814\n",
      ">6, 133/468, d1=0.672, d2=0.648 g=0.797\n",
      ">6, 134/468, d1=0.654, d2=0.629 g=0.795\n",
      ">6, 135/468, d1=0.680, d2=0.670 g=0.783\n",
      ">6, 136/468, d1=0.634, d2=0.652 g=0.791\n",
      ">6, 137/468, d1=0.604, d2=0.649 g=0.789\n",
      ">6, 138/468, d1=0.637, d2=0.657 g=0.782\n",
      ">6, 139/468, d1=0.670, d2=0.657 g=0.798\n",
      ">6, 140/468, d1=0.654, d2=0.665 g=0.787\n",
      ">6, 141/468, d1=0.658, d2=0.658 g=0.785\n",
      ">6, 142/468, d1=0.620, d2=0.678 g=0.825\n",
      ">6, 143/468, d1=0.664, d2=0.659 g=0.801\n",
      ">6, 144/468, d1=0.686, d2=0.631 g=0.797\n",
      ">6, 145/468, d1=0.686, d2=0.647 g=0.790\n",
      ">6, 146/468, d1=0.683, d2=0.667 g=0.775\n",
      ">6, 147/468, d1=0.639, d2=0.669 g=0.752\n",
      ">6, 148/468, d1=0.660, d2=0.681 g=0.777\n",
      ">6, 149/468, d1=0.660, d2=0.635 g=0.788\n",
      ">6, 150/468, d1=0.605, d2=0.633 g=0.803\n",
      ">6, 151/468, d1=0.669, d2=0.654 g=0.813\n",
      ">6, 152/468, d1=0.634, d2=0.636 g=0.790\n",
      ">6, 153/468, d1=0.676, d2=0.697 g=0.780\n",
      ">6, 154/468, d1=0.631, d2=0.705 g=0.783\n",
      ">6, 155/468, d1=0.661, d2=0.664 g=0.791\n",
      ">6, 156/468, d1=0.651, d2=0.671 g=0.804\n",
      ">6, 157/468, d1=0.681, d2=0.651 g=0.798\n",
      ">6, 158/468, d1=0.648, d2=0.652 g=0.826\n",
      ">6, 159/468, d1=0.654, d2=0.651 g=0.814\n",
      ">6, 160/468, d1=0.711, d2=0.686 g=0.790\n",
      ">6, 161/468, d1=0.657, d2=0.653 g=0.760\n",
      ">6, 162/468, d1=0.639, d2=0.654 g=0.798\n",
      ">6, 163/468, d1=0.662, d2=0.635 g=0.791\n",
      ">6, 164/468, d1=0.665, d2=0.637 g=0.803\n",
      ">6, 165/468, d1=0.632, d2=0.614 g=0.828\n",
      ">6, 166/468, d1=0.698, d2=0.662 g=0.789\n",
      ">6, 167/468, d1=0.629, d2=0.673 g=0.756\n",
      ">6, 168/468, d1=0.607, d2=0.715 g=0.767\n",
      ">6, 169/468, d1=0.639, d2=0.640 g=0.817\n",
      ">6, 170/468, d1=0.669, d2=0.614 g=0.830\n",
      ">6, 171/468, d1=0.647, d2=0.605 g=0.842\n",
      ">6, 172/468, d1=0.709, d2=0.622 g=0.847\n",
      ">6, 173/468, d1=0.672, d2=0.625 g=0.807\n",
      ">6, 174/468, d1=0.650, d2=0.663 g=0.792\n",
      ">6, 175/468, d1=0.636, d2=0.672 g=0.777\n",
      ">6, 176/468, d1=0.662, d2=0.652 g=0.811\n",
      ">6, 177/468, d1=0.665, d2=0.628 g=0.809\n",
      ">6, 178/468, d1=0.670, d2=0.634 g=0.819\n",
      ">6, 179/468, d1=0.684, d2=0.596 g=0.816\n",
      ">6, 180/468, d1=0.666, d2=0.664 g=0.815\n",
      ">6, 181/468, d1=0.654, d2=0.662 g=0.767\n",
      ">6, 182/468, d1=0.662, d2=0.692 g=0.776\n",
      ">6, 183/468, d1=0.678, d2=0.687 g=0.779\n",
      ">6, 184/468, d1=0.631, d2=0.655 g=0.793\n",
      ">6, 185/468, d1=0.646, d2=0.617 g=0.814\n",
      ">6, 186/468, d1=0.641, d2=0.635 g=0.838\n",
      ">6, 187/468, d1=0.665, d2=0.641 g=0.805\n",
      ">6, 188/468, d1=0.684, d2=0.634 g=0.776\n",
      ">6, 189/468, d1=0.665, d2=0.646 g=0.786\n",
      ">6, 190/468, d1=0.649, d2=0.660 g=0.786\n",
      ">6, 191/468, d1=0.653, d2=0.670 g=0.795\n",
      ">6, 192/468, d1=0.644, d2=0.661 g=0.793\n",
      ">6, 193/468, d1=0.639, d2=0.650 g=0.768\n",
      ">6, 194/468, d1=0.647, d2=0.642 g=0.777\n",
      ">6, 195/468, d1=0.642, d2=0.659 g=0.755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">6, 196/468, d1=0.656, d2=0.677 g=0.760\n",
      ">6, 197/468, d1=0.616, d2=0.681 g=0.768\n",
      ">6, 198/468, d1=0.654, d2=0.679 g=0.766\n",
      ">6, 199/468, d1=0.634, d2=0.652 g=0.831\n",
      ">6, 200/468, d1=0.660, d2=0.626 g=0.844\n",
      ">6, 201/468, d1=0.638, d2=0.650 g=0.814\n",
      ">6, 202/468, d1=0.624, d2=0.600 g=0.800\n",
      ">6, 203/468, d1=0.681, d2=0.666 g=0.802\n",
      ">6, 204/468, d1=0.683, d2=0.649 g=0.782\n",
      ">6, 205/468, d1=0.679, d2=0.671 g=0.782\n",
      ">6, 206/468, d1=0.676, d2=0.656 g=0.815\n",
      ">6, 207/468, d1=0.671, d2=0.624 g=0.832\n",
      ">6, 208/468, d1=0.614, d2=0.619 g=0.818\n",
      ">6, 209/468, d1=0.635, d2=0.624 g=0.780\n",
      ">6, 210/468, d1=0.669, d2=0.644 g=0.791\n",
      ">6, 211/468, d1=0.619, d2=0.745 g=0.742\n",
      ">6, 212/468, d1=0.614, d2=0.670 g=0.775\n",
      ">6, 213/468, d1=0.658, d2=0.660 g=0.822\n",
      ">6, 214/468, d1=0.670, d2=0.601 g=0.888\n",
      ">6, 215/468, d1=0.651, d2=0.567 g=0.915\n",
      ">6, 216/468, d1=0.689, d2=0.608 g=0.844\n",
      ">6, 217/468, d1=0.684, d2=0.657 g=0.808\n",
      ">6, 218/468, d1=0.633, d2=0.653 g=0.786\n",
      ">6, 219/468, d1=0.654, d2=0.690 g=0.744\n",
      ">6, 220/468, d1=0.628, d2=0.660 g=0.776\n",
      ">6, 221/468, d1=0.652, d2=0.654 g=0.828\n",
      ">6, 222/468, d1=0.633, d2=0.582 g=0.888\n",
      ">6, 223/468, d1=0.623, d2=0.584 g=0.864\n",
      ">6, 224/468, d1=0.672, d2=0.666 g=0.800\n",
      ">6, 225/468, d1=0.683, d2=0.732 g=0.780\n",
      ">6, 226/468, d1=0.634, d2=0.709 g=0.780\n",
      ">6, 227/468, d1=0.643, d2=0.629 g=0.841\n",
      ">6, 228/468, d1=0.664, d2=0.609 g=0.919\n",
      ">6, 229/468, d1=0.709, d2=0.551 g=0.914\n",
      ">6, 230/468, d1=0.706, d2=0.573 g=0.953\n",
      ">6, 231/468, d1=0.724, d2=0.601 g=0.844\n",
      ">6, 232/468, d1=0.669, d2=0.655 g=0.779\n",
      ">6, 233/468, d1=0.668, d2=0.678 g=0.798\n",
      ">6, 234/468, d1=0.650, d2=0.671 g=0.798\n",
      ">6, 235/468, d1=0.732, d2=0.632 g=0.848\n",
      ">6, 236/468, d1=0.682, d2=0.597 g=0.894\n",
      ">6, 237/468, d1=0.672, d2=0.630 g=0.840\n",
      ">6, 238/468, d1=0.613, d2=0.639 g=0.812\n",
      ">6, 239/468, d1=0.634, d2=0.663 g=0.761\n",
      ">6, 240/468, d1=0.604, d2=0.725 g=0.762\n",
      ">6, 241/468, d1=0.607, d2=0.704 g=0.795\n",
      ">6, 242/468, d1=0.630, d2=0.639 g=0.829\n",
      ">6, 243/468, d1=0.677, d2=0.654 g=0.868\n",
      ">6, 244/468, d1=0.666, d2=0.590 g=0.908\n",
      ">6, 245/468, d1=0.679, d2=0.619 g=0.863\n",
      ">6, 246/468, d1=0.653, d2=0.606 g=0.842\n",
      ">6, 247/468, d1=0.688, d2=0.648 g=0.780\n",
      ">6, 248/468, d1=0.677, d2=0.691 g=0.738\n",
      ">6, 249/468, d1=0.664, d2=0.656 g=0.774\n",
      ">6, 250/468, d1=0.631, d2=0.644 g=0.801\n",
      ">6, 251/468, d1=0.659, d2=0.635 g=0.844\n",
      ">6, 252/468, d1=0.619, d2=0.611 g=0.842\n",
      ">6, 253/468, d1=0.633, d2=0.633 g=0.812\n",
      ">6, 254/468, d1=0.669, d2=0.677 g=0.815\n",
      ">6, 255/468, d1=0.619, d2=0.701 g=0.809\n",
      ">6, 256/468, d1=0.677, d2=0.702 g=0.764\n",
      ">6, 257/468, d1=0.658, d2=0.663 g=0.796\n",
      ">6, 258/468, d1=0.647, d2=0.654 g=0.805\n",
      ">6, 259/468, d1=0.625, d2=0.633 g=0.812\n",
      ">6, 260/468, d1=0.667, d2=0.643 g=0.849\n",
      ">6, 261/468, d1=0.682, d2=0.637 g=0.812\n",
      ">6, 262/468, d1=0.632, d2=0.644 g=0.795\n",
      ">6, 263/468, d1=0.615, d2=0.652 g=0.784\n",
      ">6, 264/468, d1=0.634, d2=0.651 g=0.802\n",
      ">6, 265/468, d1=0.648, d2=0.615 g=0.803\n",
      ">6, 266/468, d1=0.652, d2=0.642 g=0.815\n",
      ">6, 267/468, d1=0.657, d2=0.657 g=0.800\n",
      ">6, 268/468, d1=0.659, d2=0.630 g=0.823\n",
      ">6, 269/468, d1=0.645, d2=0.634 g=0.803\n",
      ">6, 270/468, d1=0.695, d2=0.667 g=0.793\n",
      ">6, 271/468, d1=0.628, d2=0.645 g=0.792\n",
      ">6, 272/468, d1=0.664, d2=0.630 g=0.794\n",
      ">6, 273/468, d1=0.629, d2=0.637 g=0.782\n",
      ">6, 274/468, d1=0.682, d2=0.657 g=0.814\n",
      ">6, 275/468, d1=0.657, d2=0.633 g=0.825\n",
      ">6, 276/468, d1=0.646, d2=0.632 g=0.825\n",
      ">6, 277/468, d1=0.672, d2=0.646 g=0.786\n",
      ">6, 278/468, d1=0.684, d2=0.669 g=0.775\n",
      ">6, 279/468, d1=0.675, d2=0.666 g=0.795\n",
      ">6, 280/468, d1=0.657, d2=0.636 g=0.810\n",
      ">6, 281/468, d1=0.650, d2=0.659 g=0.797\n",
      ">6, 282/468, d1=0.638, d2=0.648 g=0.796\n",
      ">6, 283/468, d1=0.591, d2=0.690 g=0.793\n",
      ">6, 284/468, d1=0.643, d2=0.640 g=0.763\n",
      ">6, 285/468, d1=0.659, d2=0.668 g=0.762\n",
      ">6, 286/468, d1=0.672, d2=0.666 g=0.766\n",
      ">6, 287/468, d1=0.653, d2=0.624 g=0.783\n",
      ">6, 288/468, d1=0.631, d2=0.642 g=0.855\n",
      ">6, 289/468, d1=0.665, d2=0.602 g=0.815\n",
      ">6, 290/468, d1=0.644, d2=0.609 g=0.802\n",
      ">6, 291/468, d1=0.660, d2=0.618 g=0.824\n",
      ">6, 292/468, d1=0.648, d2=0.662 g=0.774\n",
      ">6, 293/468, d1=0.676, d2=0.664 g=0.772\n",
      ">6, 294/468, d1=0.625, d2=0.720 g=0.750\n",
      ">6, 295/468, d1=0.659, d2=0.637 g=0.810\n",
      ">6, 296/468, d1=0.669, d2=0.623 g=0.854\n",
      ">6, 297/468, d1=0.610, d2=0.640 g=0.805\n",
      ">6, 298/468, d1=0.574, d2=0.660 g=0.764\n",
      ">6, 299/468, d1=0.651, d2=0.718 g=0.765\n",
      ">6, 300/468, d1=0.656, d2=0.754 g=0.743\n",
      ">6, 301/468, d1=0.634, d2=0.656 g=0.778\n",
      ">6, 302/468, d1=0.657, d2=0.637 g=0.840\n",
      ">6, 303/468, d1=0.650, d2=0.614 g=0.883\n",
      ">6, 304/468, d1=0.713, d2=0.612 g=0.896\n",
      ">6, 305/468, d1=0.687, d2=0.599 g=0.852\n",
      ">6, 306/468, d1=0.692, d2=0.612 g=0.823\n",
      ">6, 307/468, d1=0.653, d2=0.651 g=0.813\n",
      ">6, 308/468, d1=0.637, d2=0.708 g=0.745\n",
      ">6, 309/468, d1=0.654, d2=0.707 g=0.772\n",
      ">6, 310/468, d1=0.685, d2=0.650 g=0.825\n",
      ">6, 311/468, d1=0.620, d2=0.627 g=0.839\n",
      ">6, 312/468, d1=0.680, d2=0.612 g=0.864\n",
      ">6, 313/468, d1=0.641, d2=0.601 g=0.858\n",
      ">6, 314/468, d1=0.659, d2=0.692 g=0.787\n",
      ">6, 315/468, d1=0.636, d2=0.680 g=0.760\n",
      ">6, 316/468, d1=0.660, d2=0.696 g=0.732\n",
      ">6, 317/468, d1=0.610, d2=0.721 g=0.791\n",
      ">6, 318/468, d1=0.642, d2=0.655 g=0.856\n",
      ">6, 319/468, d1=0.661, d2=0.581 g=0.855\n",
      ">6, 320/468, d1=0.670, d2=0.626 g=0.851\n",
      ">6, 321/468, d1=0.679, d2=0.577 g=0.840\n",
      ">6, 322/468, d1=0.695, d2=0.668 g=0.803\n",
      ">6, 323/468, d1=0.677, d2=0.640 g=0.782\n",
      ">6, 324/468, d1=0.640, d2=0.667 g=0.782\n",
      ">6, 325/468, d1=0.699, d2=0.609 g=0.776\n",
      ">6, 326/468, d1=0.684, d2=0.645 g=0.792\n",
      ">6, 327/468, d1=0.669, d2=0.644 g=0.795\n",
      ">6, 328/468, d1=0.637, d2=0.627 g=0.810\n",
      ">6, 329/468, d1=0.651, d2=0.638 g=0.814\n",
      ">6, 330/468, d1=0.655, d2=0.641 g=0.787\n",
      ">6, 331/468, d1=0.647, d2=0.653 g=0.796\n",
      ">6, 332/468, d1=0.646, d2=0.669 g=0.765\n",
      ">6, 333/468, d1=0.631, d2=0.703 g=0.752\n",
      ">6, 334/468, d1=0.681, d2=0.684 g=0.799\n",
      ">6, 335/468, d1=0.687, d2=0.654 g=0.799\n",
      ">6, 336/468, d1=0.638, d2=0.625 g=0.844\n",
      ">6, 337/468, d1=0.695, d2=0.653 g=0.855\n",
      ">6, 338/468, d1=0.677, d2=0.610 g=0.835\n",
      ">6, 339/468, d1=0.698, d2=0.650 g=0.801\n",
      ">6, 340/468, d1=0.682, d2=0.627 g=0.791\n",
      ">6, 341/468, d1=0.670, d2=0.649 g=0.796\n",
      ">6, 342/468, d1=0.652, d2=0.658 g=0.811\n",
      ">6, 343/468, d1=0.683, d2=0.655 g=0.785\n",
      ">6, 344/468, d1=0.693, d2=0.647 g=0.789\n",
      ">6, 345/468, d1=0.715, d2=0.669 g=0.799\n",
      ">6, 346/468, d1=0.662, d2=0.637 g=0.792\n",
      ">6, 347/468, d1=0.618, d2=0.652 g=0.775\n",
      ">6, 348/468, d1=0.635, d2=0.676 g=0.766\n",
      ">6, 349/468, d1=0.634, d2=0.657 g=0.763\n",
      ">6, 350/468, d1=0.661, d2=0.683 g=0.780\n",
      ">6, 351/468, d1=0.629, d2=0.684 g=0.778\n",
      ">6, 352/468, d1=0.681, d2=0.655 g=0.788\n",
      ">6, 353/468, d1=0.654, d2=0.643 g=0.835\n",
      ">6, 354/468, d1=0.689, d2=0.625 g=0.819\n",
      ">6, 355/468, d1=0.649, d2=0.634 g=0.801\n",
      ">6, 356/468, d1=0.662, d2=0.670 g=0.768\n",
      ">6, 357/468, d1=0.724, d2=0.666 g=0.758\n",
      ">6, 358/468, d1=0.656, d2=0.668 g=0.771\n",
      ">6, 359/468, d1=0.667, d2=0.683 g=0.797\n",
      ">6, 360/468, d1=0.622, d2=0.636 g=0.799\n",
      ">6, 361/468, d1=0.675, d2=0.645 g=0.806\n",
      ">6, 362/468, d1=0.696, d2=0.677 g=0.805\n",
      ">6, 363/468, d1=0.617, d2=0.683 g=0.797\n",
      ">6, 364/468, d1=0.662, d2=0.686 g=0.766\n",
      ">6, 365/468, d1=0.641, d2=0.696 g=0.764\n",
      ">6, 366/468, d1=0.689, d2=0.670 g=0.782\n",
      ">6, 367/468, d1=0.676, d2=0.666 g=0.801\n",
      ">6, 368/468, d1=0.618, d2=0.646 g=0.811\n",
      ">6, 369/468, d1=0.661, d2=0.624 g=0.846\n",
      ">6, 370/468, d1=0.728, d2=0.619 g=0.835\n",
      ">6, 371/468, d1=0.656, d2=0.656 g=0.799\n",
      ">6, 372/468, d1=0.698, d2=0.705 g=0.741\n",
      ">6, 373/468, d1=0.639, d2=0.702 g=0.754\n",
      ">6, 374/468, d1=0.651, d2=0.673 g=0.803\n",
      ">6, 375/468, d1=0.653, d2=0.645 g=0.835\n",
      ">6, 376/468, d1=0.662, d2=0.618 g=0.829\n",
      ">6, 377/468, d1=0.657, d2=0.610 g=0.795\n",
      ">6, 378/468, d1=0.687, d2=0.679 g=0.790\n",
      ">6, 379/468, d1=0.591, d2=0.724 g=0.784\n",
      ">6, 380/468, d1=0.639, d2=0.677 g=0.783\n",
      ">6, 381/468, d1=0.664, d2=0.681 g=0.780\n",
      ">6, 382/468, d1=0.645, d2=0.662 g=0.818\n",
      ">6, 383/468, d1=0.658, d2=0.603 g=0.862\n",
      ">6, 384/468, d1=0.664, d2=0.612 g=0.905\n",
      ">6, 385/468, d1=0.701, d2=0.580 g=0.865\n",
      ">6, 386/468, d1=0.717, d2=0.636 g=0.792\n",
      ">6, 387/468, d1=0.655, d2=0.713 g=0.787\n",
      ">6, 388/468, d1=0.660, d2=0.651 g=0.770\n",
      ">6, 389/468, d1=0.633, d2=0.666 g=0.788\n",
      ">6, 390/468, d1=0.651, d2=0.628 g=0.822\n",
      ">6, 391/468, d1=0.616, d2=0.625 g=0.824\n",
      ">6, 392/468, d1=0.628, d2=0.635 g=0.808\n",
      ">6, 393/468, d1=0.618, d2=0.653 g=0.756\n",
      ">6, 394/468, d1=0.634, d2=0.700 g=0.756\n",
      ">6, 395/468, d1=0.698, d2=0.709 g=0.764\n",
      ">6, 396/468, d1=0.668, d2=0.663 g=0.787\n",
      ">6, 397/468, d1=0.649, d2=0.643 g=0.851\n",
      ">6, 398/468, d1=0.707, d2=0.587 g=0.894\n",
      ">6, 399/468, d1=0.669, d2=0.552 g=0.914\n",
      ">6, 400/468, d1=0.640, d2=0.601 g=0.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">6, 401/468, d1=0.732, d2=0.687 g=0.796\n",
      ">6, 402/468, d1=0.643, d2=0.713 g=0.749\n",
      ">6, 403/468, d1=0.710, d2=0.691 g=0.788\n",
      ">6, 404/468, d1=0.656, d2=0.638 g=0.828\n",
      ">6, 405/468, d1=0.629, d2=0.607 g=0.864\n",
      ">6, 406/468, d1=0.655, d2=0.594 g=0.857\n",
      ">6, 407/468, d1=0.675, d2=0.635 g=0.814\n",
      ">6, 408/468, d1=0.615, d2=0.690 g=0.756\n",
      ">6, 409/468, d1=0.642, d2=0.733 g=0.746\n",
      ">6, 410/468, d1=0.637, d2=0.686 g=0.735\n",
      ">6, 411/468, d1=0.632, d2=0.721 g=0.764\n",
      ">6, 412/468, d1=0.645, d2=0.661 g=0.837\n",
      ">6, 413/468, d1=0.688, d2=0.579 g=0.921\n",
      ">6, 414/468, d1=0.677, d2=0.560 g=0.920\n",
      ">6, 415/468, d1=0.721, d2=0.604 g=0.890\n",
      ">6, 416/468, d1=0.694, d2=0.638 g=0.830\n",
      ">6, 417/468, d1=0.681, d2=0.651 g=0.788\n",
      ">6, 418/468, d1=0.670, d2=0.714 g=0.730\n",
      ">6, 419/468, d1=0.644, d2=0.726 g=0.720\n",
      ">6, 420/468, d1=0.658, d2=0.684 g=0.784\n",
      ">6, 421/468, d1=0.637, d2=0.631 g=0.811\n",
      ">6, 422/468, d1=0.625, d2=0.628 g=0.865\n",
      ">6, 423/468, d1=0.663, d2=0.646 g=0.860\n",
      ">6, 424/468, d1=0.615, d2=0.677 g=0.825\n",
      ">6, 425/468, d1=0.660, d2=0.685 g=0.764\n",
      ">6, 426/468, d1=0.662, d2=0.692 g=0.773\n",
      ">6, 427/468, d1=0.667, d2=0.683 g=0.736\n",
      ">6, 428/468, d1=0.623, d2=0.676 g=0.759\n",
      ">6, 429/468, d1=0.671, d2=0.681 g=0.792\n",
      ">6, 430/468, d1=0.676, d2=0.639 g=0.823\n",
      ">6, 431/468, d1=0.684, d2=0.605 g=0.869\n",
      ">6, 432/468, d1=0.658, d2=0.613 g=0.831\n",
      ">6, 433/468, d1=0.644, d2=0.648 g=0.839\n",
      ">6, 434/468, d1=0.663, d2=0.641 g=0.804\n",
      ">6, 435/468, d1=0.664, d2=0.671 g=0.806\n",
      ">6, 436/468, d1=0.668, d2=0.675 g=0.765\n",
      ">6, 437/468, d1=0.634, d2=0.664 g=0.784\n",
      ">6, 438/468, d1=0.658, d2=0.675 g=0.778\n",
      ">6, 439/468, d1=0.666, d2=0.657 g=0.777\n",
      ">6, 440/468, d1=0.647, d2=0.640 g=0.804\n",
      ">6, 441/468, d1=0.683, d2=0.633 g=0.785\n",
      ">6, 442/468, d1=0.651, d2=0.649 g=0.771\n",
      ">6, 443/468, d1=0.657, d2=0.678 g=0.759\n",
      ">6, 444/468, d1=0.633, d2=0.698 g=0.765\n",
      ">6, 445/468, d1=0.632, d2=0.696 g=0.766\n",
      ">6, 446/468, d1=0.655, d2=0.674 g=0.746\n",
      ">6, 447/468, d1=0.610, d2=0.693 g=0.790\n",
      ">6, 448/468, d1=0.649, d2=0.675 g=0.807\n",
      ">6, 449/468, d1=0.681, d2=0.658 g=0.809\n",
      ">6, 450/468, d1=0.652, d2=0.654 g=0.829\n",
      ">6, 451/468, d1=0.661, d2=0.639 g=0.788\n",
      ">6, 452/468, d1=0.658, d2=0.660 g=0.799\n",
      ">6, 453/468, d1=0.680, d2=0.661 g=0.798\n",
      ">6, 454/468, d1=0.705, d2=0.674 g=0.766\n",
      ">6, 455/468, d1=0.696, d2=0.656 g=0.778\n",
      ">6, 456/468, d1=0.665, d2=0.660 g=0.788\n",
      ">6, 457/468, d1=0.640, d2=0.637 g=0.798\n",
      ">6, 458/468, d1=0.704, d2=0.668 g=0.801\n",
      ">6, 459/468, d1=0.633, d2=0.737 g=0.772\n",
      ">6, 460/468, d1=0.652, d2=0.662 g=0.780\n",
      ">6, 461/468, d1=0.636, d2=0.691 g=0.765\n",
      ">6, 462/468, d1=0.638, d2=0.680 g=0.780\n",
      ">6, 463/468, d1=0.629, d2=0.647 g=0.763\n",
      ">6, 464/468, d1=0.684, d2=0.648 g=0.785\n",
      ">6, 465/468, d1=0.662, d2=0.664 g=0.783\n",
      ">6, 466/468, d1=0.676, d2=0.651 g=0.788\n",
      ">6, 467/468, d1=0.689, d2=0.645 g=0.809\n",
      ">6, 468/468, d1=0.680, d2=0.674 g=0.779\n",
      ">7, 1/468, d1=0.649, d2=0.667 g=0.782\n",
      ">7, 2/468, d1=0.663, d2=0.651 g=0.790\n",
      ">7, 3/468, d1=0.687, d2=0.671 g=0.799\n",
      ">7, 4/468, d1=0.643, d2=0.698 g=0.770\n",
      ">7, 5/468, d1=0.672, d2=0.651 g=0.767\n",
      ">7, 6/468, d1=0.632, d2=0.661 g=0.769\n",
      ">7, 7/468, d1=0.663, d2=0.670 g=0.783\n",
      ">7, 8/468, d1=0.631, d2=0.683 g=0.778\n",
      ">7, 9/468, d1=0.671, d2=0.681 g=0.759\n",
      ">7, 10/468, d1=0.681, d2=0.674 g=0.760\n",
      ">7, 11/468, d1=0.681, d2=0.667 g=0.748\n",
      ">7, 12/468, d1=0.656, d2=0.673 g=0.760\n",
      ">7, 13/468, d1=0.680, d2=0.656 g=0.774\n",
      ">7, 14/468, d1=0.673, d2=0.660 g=0.765\n",
      ">7, 15/468, d1=0.687, d2=0.672 g=0.798\n",
      ">7, 16/468, d1=0.665, d2=0.655 g=0.787\n",
      ">7, 17/468, d1=0.667, d2=0.670 g=0.757\n",
      ">7, 18/468, d1=0.674, d2=0.684 g=0.764\n",
      ">7, 19/468, d1=0.683, d2=0.657 g=0.750\n",
      ">7, 20/468, d1=0.670, d2=0.679 g=0.764\n",
      ">7, 21/468, d1=0.659, d2=0.683 g=0.779\n",
      ">7, 22/468, d1=0.684, d2=0.662 g=0.778\n",
      ">7, 23/468, d1=0.658, d2=0.657 g=0.775\n",
      ">7, 24/468, d1=0.666, d2=0.672 g=0.773\n",
      ">7, 25/468, d1=0.706, d2=0.651 g=0.764\n",
      ">7, 26/468, d1=0.657, d2=0.684 g=0.772\n",
      ">7, 27/468, d1=0.663, d2=0.656 g=0.777\n",
      ">7, 28/468, d1=0.682, d2=0.652 g=0.777\n",
      ">7, 29/468, d1=0.698, d2=0.669 g=0.772\n",
      ">7, 30/468, d1=0.653, d2=0.673 g=0.760\n",
      ">7, 31/468, d1=0.670, d2=0.629 g=0.767\n",
      ">7, 32/468, d1=0.670, d2=0.667 g=0.794\n",
      ">7, 33/468, d1=0.692, d2=0.688 g=0.771\n",
      ">7, 34/468, d1=0.693, d2=0.657 g=0.788\n",
      ">7, 35/468, d1=0.660, d2=0.674 g=0.780\n",
      ">7, 36/468, d1=0.667, d2=0.673 g=0.781\n",
      ">7, 37/468, d1=0.690, d2=0.671 g=0.799\n",
      ">7, 38/468, d1=0.684, d2=0.652 g=0.784\n",
      ">7, 39/468, d1=0.658, d2=0.669 g=0.774\n",
      ">7, 40/468, d1=0.653, d2=0.670 g=0.776\n",
      ">7, 41/468, d1=0.695, d2=0.662 g=0.777\n",
      ">7, 42/468, d1=0.673, d2=0.665 g=0.769\n",
      ">7, 43/468, d1=0.697, d2=0.659 g=0.760\n",
      ">7, 44/468, d1=0.664, d2=0.675 g=0.771\n",
      ">7, 45/468, d1=0.657, d2=0.675 g=0.772\n",
      ">7, 46/468, d1=0.679, d2=0.674 g=0.763\n",
      ">7, 47/468, d1=0.665, d2=0.667 g=0.760\n",
      ">7, 48/468, d1=0.648, d2=0.650 g=0.783\n",
      ">7, 49/468, d1=0.638, d2=0.651 g=0.814\n",
      ">7, 50/468, d1=0.721, d2=0.684 g=0.771\n",
      ">7, 51/468, d1=0.676, d2=0.645 g=0.798\n",
      ">7, 52/468, d1=0.689, d2=0.627 g=0.791\n",
      ">7, 53/468, d1=0.690, d2=0.664 g=0.795\n",
      ">7, 54/468, d1=0.677, d2=0.654 g=0.813\n",
      ">7, 55/468, d1=0.687, d2=0.651 g=0.811\n",
      ">7, 56/468, d1=0.705, d2=0.650 g=0.788\n",
      ">7, 57/468, d1=0.695, d2=0.663 g=0.780\n",
      ">7, 58/468, d1=0.649, d2=0.658 g=0.784\n",
      ">7, 59/468, d1=0.702, d2=0.668 g=0.786\n",
      ">7, 60/468, d1=0.637, d2=0.668 g=0.768\n",
      ">7, 61/468, d1=0.726, d2=0.656 g=0.778\n",
      ">7, 62/468, d1=0.636, d2=0.653 g=0.775\n",
      ">7, 63/468, d1=0.695, d2=0.621 g=0.793\n",
      ">7, 64/468, d1=0.678, d2=0.663 g=0.788\n",
      ">7, 65/468, d1=0.677, d2=0.639 g=0.804\n",
      ">7, 66/468, d1=0.706, d2=0.647 g=0.786\n",
      ">7, 67/468, d1=0.689, d2=0.650 g=0.803\n",
      ">7, 68/468, d1=0.655, d2=0.647 g=0.761\n",
      ">7, 69/468, d1=0.689, d2=0.645 g=0.780\n",
      ">7, 70/468, d1=0.665, d2=0.647 g=0.778\n",
      ">7, 71/468, d1=0.640, d2=0.670 g=0.790\n",
      ">7, 72/468, d1=0.687, d2=0.683 g=0.778\n",
      ">7, 73/468, d1=0.706, d2=0.686 g=0.791\n",
      ">7, 74/468, d1=0.660, d2=0.653 g=0.759\n",
      ">7, 75/468, d1=0.688, d2=0.631 g=0.804\n",
      ">7, 76/468, d1=0.665, d2=0.641 g=0.783\n",
      ">7, 77/468, d1=0.671, d2=0.676 g=0.785\n",
      ">7, 78/468, d1=0.680, d2=0.643 g=0.783\n",
      ">7, 79/468, d1=0.657, d2=0.664 g=0.776\n",
      ">7, 80/468, d1=0.671, d2=0.652 g=0.776\n",
      ">7, 81/468, d1=0.676, d2=0.654 g=0.786\n",
      ">7, 82/468, d1=0.651, d2=0.669 g=0.816\n",
      ">7, 83/468, d1=0.660, d2=0.642 g=0.772\n",
      ">7, 84/468, d1=0.664, d2=0.689 g=0.789\n",
      ">7, 85/468, d1=0.648, d2=0.657 g=0.776\n",
      ">7, 86/468, d1=0.686, d2=0.673 g=0.753\n",
      ">7, 87/468, d1=0.676, d2=0.659 g=0.792\n",
      ">7, 88/468, d1=0.650, d2=0.650 g=0.818\n",
      ">7, 89/468, d1=0.711, d2=0.619 g=0.835\n",
      ">7, 90/468, d1=0.728, d2=0.631 g=0.851\n",
      ">7, 91/468, d1=0.624, d2=0.622 g=0.864\n",
      ">7, 92/468, d1=0.720, d2=0.670 g=0.804\n",
      ">7, 93/468, d1=0.698, d2=0.676 g=0.790\n",
      ">7, 94/468, d1=0.696, d2=0.707 g=0.767\n",
      ">7, 95/468, d1=0.686, d2=0.652 g=0.817\n",
      ">7, 96/468, d1=0.679, d2=0.633 g=0.821\n",
      ">7, 97/468, d1=0.684, d2=0.630 g=0.821\n",
      ">7, 98/468, d1=0.665, d2=0.648 g=0.814\n",
      ">7, 99/468, d1=0.670, d2=0.641 g=0.776\n",
      ">7, 100/468, d1=0.649, d2=0.688 g=0.751\n",
      ">7, 101/468, d1=0.643, d2=0.699 g=0.778\n",
      ">7, 102/468, d1=0.677, d2=0.698 g=0.783\n",
      ">7, 103/468, d1=0.696, d2=0.656 g=0.817\n",
      ">7, 104/468, d1=0.699, d2=0.619 g=0.817\n",
      ">7, 105/468, d1=0.703, d2=0.619 g=0.849\n",
      ">7, 106/468, d1=0.710, d2=0.641 g=0.805\n",
      ">7, 107/468, d1=0.673, d2=0.639 g=0.811\n",
      ">7, 108/468, d1=0.681, d2=0.660 g=0.770\n",
      ">7, 109/468, d1=0.727, d2=0.667 g=0.774\n",
      ">7, 110/468, d1=0.656, d2=0.680 g=0.800\n",
      ">7, 111/468, d1=0.710, d2=0.676 g=0.788\n",
      ">7, 112/468, d1=0.644, d2=0.646 g=0.796\n",
      ">7, 113/468, d1=0.685, d2=0.661 g=0.783\n",
      ">7, 114/468, d1=0.632, d2=0.647 g=0.820\n",
      ">7, 115/468, d1=0.635, d2=0.666 g=0.787\n",
      ">7, 116/468, d1=0.681, d2=0.677 g=0.782\n",
      ">7, 117/468, d1=0.636, d2=0.657 g=0.781\n",
      ">7, 118/468, d1=0.634, d2=0.651 g=0.781\n",
      ">7, 119/468, d1=0.672, d2=0.630 g=0.766\n",
      ">7, 120/468, d1=0.680, d2=0.684 g=0.786\n",
      ">7, 121/468, d1=0.675, d2=0.656 g=0.795\n",
      ">7, 122/468, d1=0.663, d2=0.652 g=0.784\n",
      ">7, 123/468, d1=0.700, d2=0.658 g=0.786\n",
      ">7, 124/468, d1=0.672, d2=0.655 g=0.801\n",
      ">7, 125/468, d1=0.635, d2=0.679 g=0.786\n",
      ">7, 126/468, d1=0.664, d2=0.673 g=0.768\n",
      ">7, 127/468, d1=0.666, d2=0.680 g=0.767\n",
      ">7, 128/468, d1=0.694, d2=0.665 g=0.791\n",
      ">7, 129/468, d1=0.694, d2=0.650 g=0.790\n",
      ">7, 130/468, d1=0.686, d2=0.634 g=0.774\n",
      ">7, 131/468, d1=0.685, d2=0.660 g=0.779\n",
      ">7, 132/468, d1=0.677, d2=0.671 g=0.783\n",
      ">7, 133/468, d1=0.677, d2=0.644 g=0.785\n",
      ">7, 134/468, d1=0.676, d2=0.668 g=0.765\n",
      ">7, 135/468, d1=0.673, d2=0.680 g=0.778\n",
      ">7, 136/468, d1=0.667, d2=0.683 g=0.776\n",
      ">7, 137/468, d1=0.648, d2=0.645 g=0.784\n",
      ">7, 138/468, d1=0.654, d2=0.646 g=0.772\n",
      ">7, 139/468, d1=0.697, d2=0.640 g=0.774\n",
      ">7, 140/468, d1=0.684, d2=0.661 g=0.775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">7, 141/468, d1=0.684, d2=0.667 g=0.774\n",
      ">7, 142/468, d1=0.672, d2=0.668 g=0.788\n",
      ">7, 143/468, d1=0.637, d2=0.672 g=0.776\n",
      ">7, 144/468, d1=0.673, d2=0.643 g=0.766\n",
      ">7, 145/468, d1=0.686, d2=0.658 g=0.772\n",
      ">7, 146/468, d1=0.661, d2=0.667 g=0.755\n",
      ">7, 147/468, d1=0.670, d2=0.642 g=0.782\n",
      ">7, 148/468, d1=0.649, d2=0.668 g=0.767\n",
      ">7, 149/468, d1=0.678, d2=0.667 g=0.738\n",
      ">7, 150/468, d1=0.645, d2=0.646 g=0.789\n",
      ">7, 151/468, d1=0.637, d2=0.656 g=0.798\n",
      ">7, 152/468, d1=0.642, d2=0.652 g=0.796\n",
      ">7, 153/468, d1=0.678, d2=0.657 g=0.771\n",
      ">7, 154/468, d1=0.675, d2=0.738 g=0.741\n",
      ">7, 155/468, d1=0.651, d2=0.662 g=0.748\n",
      ">7, 156/468, d1=0.662, d2=0.653 g=0.794\n",
      ">7, 157/468, d1=0.674, d2=0.691 g=0.784\n",
      ">7, 158/468, d1=0.653, d2=0.645 g=0.799\n",
      ">7, 159/468, d1=0.674, d2=0.629 g=0.792\n",
      ">7, 160/468, d1=0.669, d2=0.664 g=0.769\n",
      ">7, 161/468, d1=0.656, d2=0.661 g=0.786\n",
      ">7, 162/468, d1=0.639, d2=0.647 g=0.774\n",
      ">7, 163/468, d1=0.699, d2=0.663 g=0.766\n",
      ">7, 164/468, d1=0.651, d2=0.676 g=0.787\n",
      ">7, 165/468, d1=0.670, d2=0.674 g=0.798\n",
      ">7, 166/468, d1=0.647, d2=0.642 g=0.769\n",
      ">7, 167/468, d1=0.657, d2=0.650 g=0.807\n",
      ">7, 168/468, d1=0.656, d2=0.676 g=0.790\n",
      ">7, 169/468, d1=0.672, d2=0.665 g=0.786\n",
      ">7, 170/468, d1=0.691, d2=0.679 g=0.768\n",
      ">7, 171/468, d1=0.647, d2=0.678 g=0.750\n",
      ">7, 172/468, d1=0.672, d2=0.668 g=0.782\n",
      ">7, 173/468, d1=0.686, d2=0.643 g=0.792\n",
      ">7, 174/468, d1=0.636, d2=0.651 g=0.800\n",
      ">7, 175/468, d1=0.648, d2=0.651 g=0.837\n",
      ">7, 176/468, d1=0.647, d2=0.649 g=0.798\n",
      ">7, 177/468, d1=0.676, d2=0.655 g=0.806\n",
      ">7, 178/468, d1=0.647, d2=0.627 g=0.762\n",
      ">7, 179/468, d1=0.658, d2=0.667 g=0.776\n",
      ">7, 180/468, d1=0.634, d2=0.650 g=0.823\n",
      ">7, 181/468, d1=0.639, d2=0.662 g=0.802\n",
      ">7, 182/468, d1=0.616, d2=0.664 g=0.794\n",
      ">7, 183/468, d1=0.614, d2=0.666 g=0.778\n",
      ">7, 184/468, d1=0.685, d2=0.666 g=0.803\n",
      ">7, 185/468, d1=0.601, d2=0.642 g=0.745\n",
      ">7, 186/468, d1=0.674, d2=0.667 g=0.783\n",
      ">7, 187/468, d1=0.596, d2=0.672 g=0.786\n",
      ">7, 188/468, d1=0.657, d2=0.655 g=0.815\n",
      ">7, 189/468, d1=0.656, d2=0.650 g=0.842\n",
      ">7, 190/468, d1=0.669, d2=0.679 g=0.820\n",
      ">7, 191/468, d1=0.671, d2=0.669 g=0.783\n",
      ">7, 192/468, d1=0.667, d2=0.629 g=0.805\n",
      ">7, 193/468, d1=0.678, d2=0.651 g=0.778\n",
      ">7, 194/468, d1=0.663, d2=0.680 g=0.788\n",
      ">7, 195/468, d1=0.678, d2=0.641 g=0.813\n",
      ">7, 196/468, d1=0.659, d2=0.647 g=0.794\n",
      ">7, 197/468, d1=0.641, d2=0.657 g=0.796\n",
      ">7, 198/468, d1=0.648, d2=0.636 g=0.823\n",
      ">7, 199/468, d1=0.692, d2=0.641 g=0.794\n",
      ">7, 200/468, d1=0.676, d2=0.641 g=0.809\n",
      ">7, 201/468, d1=0.669, d2=0.634 g=0.809\n",
      ">7, 202/468, d1=0.679, d2=0.668 g=0.789\n",
      ">7, 203/468, d1=0.654, d2=0.639 g=0.764\n",
      ">7, 204/468, d1=0.687, d2=0.682 g=0.784\n",
      ">7, 205/468, d1=0.644, d2=0.662 g=0.791\n",
      ">7, 206/468, d1=0.650, d2=0.635 g=0.797\n",
      ">7, 207/468, d1=0.648, d2=0.676 g=0.792\n",
      ">7, 208/468, d1=0.666, d2=0.641 g=0.812\n",
      ">7, 209/468, d1=0.665, d2=0.669 g=0.774\n",
      ">7, 210/468, d1=0.713, d2=0.651 g=0.763\n",
      ">7, 211/468, d1=0.635, d2=0.664 g=0.765\n",
      ">7, 212/468, d1=0.669, d2=0.660 g=0.755\n",
      ">7, 213/468, d1=0.642, d2=0.671 g=0.760\n",
      ">7, 214/468, d1=0.653, d2=0.701 g=0.768\n",
      ">7, 215/468, d1=0.657, d2=0.691 g=0.778\n",
      ">7, 216/468, d1=0.663, d2=0.695 g=0.769\n",
      ">7, 217/468, d1=0.662, d2=0.661 g=0.790\n",
      ">7, 218/468, d1=0.658, d2=0.659 g=0.796\n",
      ">7, 219/468, d1=0.664, d2=0.637 g=0.803\n",
      ">7, 220/468, d1=0.651, d2=0.642 g=0.794\n",
      ">7, 221/468, d1=0.642, d2=0.616 g=0.799\n",
      ">7, 222/468, d1=0.656, d2=0.665 g=0.815\n",
      ">7, 223/468, d1=0.631, d2=0.646 g=0.812\n",
      ">7, 224/468, d1=0.672, d2=0.628 g=0.790\n",
      ">7, 225/468, d1=0.625, d2=0.637 g=0.827\n",
      ">7, 226/468, d1=0.675, d2=0.671 g=0.773\n",
      ">7, 227/468, d1=0.679, d2=0.718 g=0.760\n",
      ">7, 228/468, d1=0.652, d2=0.694 g=0.777\n",
      ">7, 229/468, d1=0.654, d2=0.653 g=0.823\n",
      ">7, 230/468, d1=0.677, d2=0.597 g=0.876\n",
      ">7, 231/468, d1=0.668, d2=0.587 g=0.850\n",
      ">7, 232/468, d1=0.688, d2=0.628 g=0.835\n",
      ">7, 233/468, d1=0.710, d2=0.640 g=0.787\n",
      ">7, 234/468, d1=0.700, d2=0.680 g=0.764\n",
      ">7, 235/468, d1=0.649, d2=0.680 g=0.754\n",
      ">7, 236/468, d1=0.670, d2=0.687 g=0.796\n",
      ">7, 237/468, d1=0.650, d2=0.635 g=0.826\n",
      ">7, 238/468, d1=0.655, d2=0.627 g=0.843\n",
      ">7, 239/468, d1=0.663, d2=0.636 g=0.783\n",
      ">7, 240/468, d1=0.618, d2=0.701 g=0.773\n",
      ">7, 241/468, d1=0.660, d2=0.716 g=0.752\n",
      ">7, 242/468, d1=0.643, d2=0.710 g=0.781\n",
      ">7, 243/468, d1=0.668, d2=0.656 g=0.812\n",
      ">7, 244/468, d1=0.678, d2=0.600 g=0.858\n",
      ">7, 245/468, d1=0.704, d2=0.605 g=0.899\n",
      ">7, 246/468, d1=0.703, d2=0.583 g=0.858\n",
      ">7, 247/468, d1=0.682, d2=0.610 g=0.848\n",
      ">7, 248/468, d1=0.708, d2=0.624 g=0.868\n",
      ">7, 249/468, d1=0.688, d2=0.634 g=0.790\n",
      ">7, 250/468, d1=0.675, d2=0.660 g=0.819\n",
      ">7, 251/468, d1=0.662, d2=0.632 g=0.814\n",
      ">7, 252/468, d1=0.654, d2=0.627 g=0.850\n",
      ">7, 253/468, d1=0.644, d2=0.638 g=0.825\n",
      ">7, 254/468, d1=0.670, d2=0.610 g=0.846\n",
      ">7, 255/468, d1=0.665, d2=0.642 g=0.828\n",
      ">7, 256/468, d1=0.712, d2=0.628 g=0.816\n",
      ">7, 257/468, d1=0.655, d2=0.649 g=0.802\n",
      ">7, 258/468, d1=0.657, d2=0.657 g=0.799\n",
      ">7, 259/468, d1=0.657, d2=0.633 g=0.802\n",
      ">7, 260/468, d1=0.684, d2=0.648 g=0.800\n",
      ">7, 261/468, d1=0.677, d2=0.634 g=0.805\n",
      ">7, 262/468, d1=0.658, d2=0.632 g=0.832\n",
      ">7, 263/468, d1=0.683, d2=0.635 g=0.824\n",
      ">7, 264/468, d1=0.659, d2=0.662 g=0.807\n",
      ">7, 265/468, d1=0.718, d2=0.658 g=0.791\n",
      ">7, 266/468, d1=0.663, d2=0.642 g=0.806\n",
      ">7, 267/468, d1=0.685, d2=0.658 g=0.790\n",
      ">7, 268/468, d1=0.671, d2=0.673 g=0.799\n",
      ">7, 269/468, d1=0.671, d2=0.630 g=0.785\n",
      ">7, 270/468, d1=0.674, d2=0.653 g=0.791\n",
      ">7, 271/468, d1=0.674, d2=0.649 g=0.762\n",
      ">7, 272/468, d1=0.677, d2=0.672 g=0.763\n",
      ">7, 273/468, d1=0.642, d2=0.670 g=0.797\n",
      ">7, 274/468, d1=0.666, d2=0.656 g=0.799\n",
      ">7, 275/468, d1=0.671, d2=0.653 g=0.797\n",
      ">7, 276/468, d1=0.644, d2=0.652 g=0.798\n",
      ">7, 277/468, d1=0.632, d2=0.664 g=0.797\n",
      ">7, 278/468, d1=0.687, d2=0.651 g=0.815\n",
      ">7, 279/468, d1=0.684, d2=0.616 g=0.807\n",
      ">7, 280/468, d1=0.682, d2=0.649 g=0.782\n",
      ">7, 281/468, d1=0.642, d2=0.640 g=0.801\n",
      ">7, 282/468, d1=0.628, d2=0.655 g=0.787\n",
      ">7, 283/468, d1=0.658, d2=0.656 g=0.782\n",
      ">7, 284/468, d1=0.616, d2=0.661 g=0.786\n",
      ">7, 285/468, d1=0.644, d2=0.666 g=0.774\n",
      ">7, 286/468, d1=0.638, d2=0.666 g=0.752\n",
      ">7, 287/468, d1=0.632, d2=0.660 g=0.764\n",
      ">7, 288/468, d1=0.669, d2=0.678 g=0.783\n",
      ">7, 289/468, d1=0.644, d2=0.648 g=0.758\n",
      ">7, 290/468, d1=0.638, d2=0.691 g=0.775\n",
      ">7, 291/468, d1=0.630, d2=0.671 g=0.779\n",
      ">7, 292/468, d1=0.654, d2=0.680 g=0.770\n",
      ">7, 293/468, d1=0.659, d2=0.657 g=0.771\n",
      ">7, 294/468, d1=0.651, d2=0.629 g=0.792\n",
      ">7, 295/468, d1=0.671, d2=0.685 g=0.769\n",
      ">7, 296/468, d1=0.647, d2=0.671 g=0.788\n",
      ">7, 297/468, d1=0.690, d2=0.649 g=0.795\n",
      ">7, 298/468, d1=0.662, d2=0.645 g=0.790\n",
      ">7, 299/468, d1=0.718, d2=0.661 g=0.811\n",
      ">7, 300/468, d1=0.684, d2=0.645 g=0.807\n",
      ">7, 301/468, d1=0.677, d2=0.637 g=0.811\n",
      ">7, 302/468, d1=0.643, d2=0.658 g=0.774\n",
      ">7, 303/468, d1=0.657, d2=0.627 g=0.782\n",
      ">7, 304/468, d1=0.646, d2=0.653 g=0.774\n",
      ">7, 305/468, d1=0.636, d2=0.659 g=0.771\n",
      ">7, 306/468, d1=0.644, d2=0.673 g=0.780\n",
      ">7, 307/468, d1=0.656, d2=0.672 g=0.757\n",
      ">7, 308/468, d1=0.660, d2=0.675 g=0.768\n",
      ">7, 309/468, d1=0.600, d2=0.648 g=0.772\n",
      ">7, 310/468, d1=0.647, d2=0.653 g=0.783\n",
      ">7, 311/468, d1=0.661, d2=0.649 g=0.800\n",
      ">7, 312/468, d1=0.634, d2=0.669 g=0.753\n",
      ">7, 313/468, d1=0.635, d2=0.681 g=0.773\n",
      ">7, 314/468, d1=0.672, d2=0.694 g=0.765\n",
      ">7, 315/468, d1=0.635, d2=0.658 g=0.772\n"
     ]
    }
   ],
   "source": [
    "# example of training an conditional gan on the fashion mnist dataset\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(28,28,1), n_classes=10):\n",
    "\t# label input\n",
    "\tin_label = Input(shape=(1,))\n",
    "\t# embedding for categorical input\n",
    "\tli = Embedding(n_classes, 50)(in_label)\n",
    "\t# scale up to image dimensions with linear activation\n",
    "\tn_nodes = in_shape[0] * in_shape[1]\n",
    "\tli = Dense(n_nodes)(li)\n",
    "\t# reshape to additional channel\n",
    "\tli = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "\t# image input\n",
    "\tin_image = Input(shape=in_shape)\n",
    "\t# concat label as a channel\n",
    "\tmerge = Concatenate()([in_image, li])\n",
    "\t# downsample\n",
    "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
    "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
    "\t# downsample\n",
    "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
    "\t# flatten feature maps\n",
    "\tfe = Flatten()(fe)\n",
    "\t# dropout\n",
    "\tfe = Dropout(0.4)(fe)\n",
    "\t# output\n",
    "\tout_layer = Dense(1, activation='sigmoid')(fe)\n",
    "\t# define model\n",
    "\tmodel = Model([in_image, in_label], out_layer)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_classes=10):\n",
    "\t# label input\n",
    "\tin_label = Input(shape=(1,))\n",
    "\t# embedding for categorical input\n",
    "\tli = Embedding(n_classes, 50)(in_label)\n",
    "\t# linear multiplication\n",
    "\tn_nodes = 7 * 7\n",
    "\tli = Dense(n_nodes)(li)\n",
    "\t# reshape to additional channel\n",
    "\tli = Reshape((7, 7, 1))(li)\n",
    "\t# image generator input\n",
    "\tin_lat = Input(shape=(latent_dim,))\n",
    "\t# foundation for 7x7 image\n",
    "\tn_nodes = 128 * 7 * 7\n",
    "\tgen = Dense(n_nodes)(in_lat)\n",
    "\tgen = LeakyReLU(alpha=0.2)(gen)\n",
    "\tgen = Reshape((7, 7, 128))(gen)\n",
    "\t# merge image gen and label input\n",
    "\tmerge = Concatenate()([gen, li])\n",
    "\t# upsample to 14x14\n",
    "\tgen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
    "\tgen = LeakyReLU(alpha=0.2)(gen)\n",
    "\t# upsample to 28x28\n",
    "\tgen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "\tgen = LeakyReLU(alpha=0.2)(gen)\n",
    "\t# output\n",
    "\tout_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n",
    "\t# define model\n",
    "\tmodel = Model([in_lat, in_label], out_layer)\n",
    "\treturn model\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\td_model.trainable = False\n",
    "\t# get noise and label inputs from generator model\n",
    "\tgen_noise, gen_label = g_model.input\n",
    "\t# get image output from the generator model\n",
    "\tgen_output = g_model.output\n",
    "\t# connect image output and label input from generator as inputs to discriminator\n",
    "\tgan_output = d_model([gen_output, gen_label])\n",
    "\t# define gan model as taking noise and label and outputting a classification\n",
    "\tmodel = Model([gen_noise, gen_label], gan_output)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\treturn model\n",
    "\n",
    "# load fashion mnist images\n",
    "def load_real_samples():\n",
    "\t# load dataset\n",
    "\t(trainX, trainy), (_, _) = load_data()\n",
    "\t# expand to 3d, e.g. add channels\n",
    "\tX = expand_dims(trainX, axis=-1)\n",
    "\t# convert from ints to floats\n",
    "\tX = X.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX = (X - 127.5) / 127.5\n",
    "\treturn [X, trainy]\n",
    "\n",
    "# # select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# split into images and labels\n",
    "\timages, labels = dataset\n",
    "\t# choose random instances\n",
    "\tix = randint(0, images.shape[0], n_samples)\n",
    "\t# select images and labels\n",
    "\tX, labels = images[ix], labels[ix]\n",
    "\t# generate class labels\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn [X, labels], y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
    "\t# generate labels\n",
    "\tlabels = randint(0, n_classes, n_samples)\n",
    "\treturn [z_input, labels]\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tz_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "\t# predict outputs\n",
    "\timages = generator.predict([z_input, labels_input])\n",
    "\t# create class labels\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn [images, labels_input], y\n",
    "\n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n",
    "\tbat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# enumerate batches over the training set\n",
    "\t\tfor j in range(bat_per_epo):\n",
    "\t\t\t# get randomly selected 'real' samples\n",
    "\t\t\t[X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t\t# update discriminator model weights\n",
    "\t\t\td_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "\t\t\t# generate 'fake' examples\n",
    "\t\t\t[X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t\t# update discriminator model weights\n",
    "\t\t\td_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "\t\t\t# prepare points in latent space as input for the generator\n",
    "\t\t\t[z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t\t# create inverted labels for the fake samples\n",
    "\t\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t\t# update the generator via the discriminator's error\n",
    "\t\t\tg_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "\t\t\t# summarize loss on this batch\n",
    "\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
    "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "\t# save the generator model\n",
    "\tg_model.save('cgan_generator.h5')\n",
    "\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "d_model = define_discriminator()\n",
    "# create the generator\n",
    "g_model = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Batch 1/700: Discriminator loss = 1.2148332595825195, GAN loss = [3.7418015, 0.6616232, 2.1143382]\n",
      "Batch 2/700: Discriminator loss = 1.3512165546417236, GAN loss = [3.9408474, 0.53972405, 2.4353607]\n",
      "Batch 3/700: Discriminator loss = 1.508239984512329, GAN loss = [4.052915, 0.44131073, 2.6459115]\n",
      "Batch 4/700: Discriminator loss = 1.6210124492645264, GAN loss = [3.9980297, 0.39462417, 2.637777]\n",
      "Batch 5/700: Discriminator loss = 1.7666152715682983, GAN loss = [3.9609337, 0.337075, 2.658297]\n",
      "Batch 6/700: Discriminator loss = 1.8829948902130127, GAN loss = [3.7752619, 0.34087598, 2.4688911]\n",
      "Batch 7/700: Discriminator loss = 1.9254709482192993, GAN loss = [3.6310256, 0.32476532, 2.3408394]\n",
      "Batch 8/700: Discriminator loss = 1.9242677688598633, GAN loss = [3.524834, 0.3486791, 2.2108064]\n",
      "Batch 9/700: Discriminator loss = 1.8817198276519775, GAN loss = [3.483163, 0.35155046, 2.166337]\n",
      "Batch 10/700: Discriminator loss = 1.8492584228515625, GAN loss = [3.427281, 0.41143924, 2.050636]\n",
      "Batch 11/700: Discriminator loss = 1.7614552974700928, GAN loss = [3.435706, 0.45783702, 2.0127335]\n",
      "Batch 12/700: Discriminator loss = 1.674521565437317, GAN loss = [3.3862152, 0.51246834, 1.9086827]\n",
      "Batch 13/700: Discriminator loss = 1.6436240673065186, GAN loss = [3.3267217, 0.539427, 1.8223042]\n",
      "Batch 14/700: Discriminator loss = 1.6187158823013306, GAN loss = [3.394925, 0.53907347, 1.8909328]\n",
      "Batch 15/700: Discriminator loss = 1.6870481967926025, GAN loss = [3.31664, 0.5256777, 1.8261129]\n",
      "Batch 16/700: Discriminator loss = 1.6477779150009155, GAN loss = [3.257868, 0.5173052, 1.7757807]\n",
      "Batch 17/700: Discriminator loss = 1.6370207071304321, GAN loss = [3.2027693, 0.51850265, 1.7195528]\n",
      "Batch 18/700: Discriminator loss = 1.6717299222946167, GAN loss = [3.2087667, 0.5034941, 1.740628]\n",
      "Batch 19/700: Discriminator loss = 1.6424140930175781, GAN loss = [3.259502, 0.53181016, 1.7631173]\n",
      "Batch 20/700: Discriminator loss = 1.5947190523147583, GAN loss = [3.277533, 0.5616271, 1.7514054]\n",
      "Batch 21/700: Discriminator loss = 1.5402026176452637, GAN loss = [3.3256633, 0.5919221, 1.7693169]\n",
      "Batch 22/700: Discriminator loss = 1.530880331993103, GAN loss = [3.2754908, 0.6140903, 1.6970544]\n",
      "Batch 23/700: Discriminator loss = 1.5036653280258179, GAN loss = [3.3171782, 0.63527566, 1.7176356]\n",
      "Batch 24/700: Discriminator loss = 1.4647432565689087, GAN loss = [3.3681033, 0.65652114, 1.747395]\n",
      "Batch 25/700: Discriminator loss = 1.4764121770858765, GAN loss = [3.3475876, 0.66586906, 1.7176117]\n",
      "Batch 26/700: Discriminator loss = 1.4790425300598145, GAN loss = [3.3730915, 0.68165374, 1.7274126]\n",
      "Batch 27/700: Discriminator loss = 1.4352234601974487, GAN loss = [3.350105, 0.70934844, 1.6768144]\n",
      "Batch 28/700: Discriminator loss = 1.3938798904418945, GAN loss = [3.3900342, 0.74016935, 1.686009]\n",
      "Batch 29/700: Discriminator loss = 1.4254746437072754, GAN loss = [3.381012, 0.74723244, 1.670012]\n",
      "Batch 30/700: Discriminator loss = 1.427740454673767, GAN loss = [3.3444335, 0.77407, 1.6066824]\n",
      "Batch 31/700: Discriminator loss = 1.3954901695251465, GAN loss = [3.3123515, 0.8103133, 1.5384451]\n",
      "Batch 32/700: Discriminator loss = 1.3838794231414795, GAN loss = [3.379601, 0.83145994, 1.5846404]\n",
      "Batch 33/700: Discriminator loss = 1.353223204612732, GAN loss = [3.3667014, 0.85446393, 1.5488327]\n",
      "Batch 34/700: Discriminator loss = 1.3639696836471558, GAN loss = [3.2967975, 0.86627805, 1.4672127]\n",
      "Batch 35/700: Discriminator loss = 1.3613582849502563, GAN loss = [3.312465, 0.8846161, 1.4646404]\n",
      "Batch 36/700: Discriminator loss = 1.394782304763794, GAN loss = [3.3561766, 0.8788636, 1.5142027]\n",
      "Batch 37/700: Discriminator loss = 1.3974742889404297, GAN loss = [3.2776353, 0.85547864, 1.4591426]\n",
      "Batch 38/700: Discriminator loss = 1.409490942955017, GAN loss = [3.298312, 0.83214927, 1.5032413]\n",
      "Batch 39/700: Discriminator loss = 1.388129472732544, GAN loss = [3.3078802, 0.8467486, 1.4982985]\n",
      "Batch 40/700: Discriminator loss = 1.3519744873046875, GAN loss = [3.36839, 0.8972914, 1.508356]\n",
      "Batch 41/700: Discriminator loss = 1.3127566576004028, GAN loss = [3.4649208, 0.9279469, 1.5743271]\n",
      "Batch 42/700: Discriminator loss = 1.2923210859298706, GAN loss = [3.5579073, 0.9864854, 1.6088753]\n",
      "Batch 43/700: Discriminator loss = 1.227103352546692, GAN loss = [3.5863717, 1.0070356, 1.6168953]\n",
      "Batch 44/700: Discriminator loss = 1.2388495206832886, GAN loss = [3.5317402, 1.0161448, 1.553264]\n",
      "Batch 45/700: Discriminator loss = 1.2532854080200195, GAN loss = [3.5526845, 0.9904101, 1.6000539]\n",
      "Batch 46/700: Discriminator loss = 1.2721502780914307, GAN loss = [3.5552983, 0.96110636, 1.6320813]\n",
      "Batch 47/700: Discriminator loss = 1.2767363786697388, GAN loss = [3.5858762, 0.95211357, 1.6717601]\n",
      "Batch 48/700: Discriminator loss = 1.2932074069976807, GAN loss = [3.5553992, 0.94862014, 1.644884]\n",
      "Batch 49/700: Discriminator loss = 1.2989766597747803, GAN loss = [3.6636977, 0.9514865, 1.7504222]\n",
      "Batch 50/700: Discriminator loss = 1.2489120960235596, GAN loss = [3.688474, 0.9552047, 1.771584]\n",
      "Batch 51/700: Discriminator loss = 1.2127503156661987, GAN loss = [3.6848044, 0.9836745, 1.7395489]\n",
      "Batch 52/700: Discriminator loss = 1.220033049583435, GAN loss = [3.7442005, 1.0099132, 1.7728107]\n",
      "Batch 53/700: Discriminator loss = 1.2001864910125732, GAN loss = [3.754754, 1.0153025, 1.7780817]\n",
      "Batch 54/700: Discriminator loss = 1.2333232164382935, GAN loss = [3.7109163, 1.0097868, 1.7398643]\n",
      "Batch 55/700: Discriminator loss = 1.3204177618026733, GAN loss = [3.6956189, 0.9867551, 1.7477014]\n",
      "Batch 56/700: Discriminator loss = 1.4093542098999023, GAN loss = [3.4814396, 0.95379907, 1.566572]\n",
      "Batch 57/700: Discriminator loss = 1.4126176834106445, GAN loss = [3.4509263, 0.94782555, 1.5421164]\n",
      "Batch 58/700: Discriminator loss = 1.419950246810913, GAN loss = [3.3043394, 0.95419043, 1.3892491]\n",
      "Batch 59/700: Discriminator loss = 1.4533660411834717, GAN loss = [3.2935388, 0.9464056, 1.3863215]\n",
      "Batch 60/700: Discriminator loss = 1.5118643045425415, GAN loss = [3.3342535, 0.9022322, 1.4712992]\n",
      "Batch 61/700: Discriminator loss = 1.496633768081665, GAN loss = [3.1571915, 0.9036832, 1.2928735]\n",
      "Batch 62/700: Discriminator loss = 1.4930269718170166, GAN loss = [3.0829515, 0.8955478, 1.2268553]\n",
      "Batch 63/700: Discriminator loss = 1.4760581254959106, GAN loss = [3.2008078, 0.9091739, 1.3311723]\n",
      "Batch 64/700: Discriminator loss = 1.4433691501617432, GAN loss = [3.2132144, 0.90193677, 1.3509022]\n",
      "Batch 65/700: Discriminator loss = 1.4414284229278564, GAN loss = [3.268389, 0.91968447, 1.3884114]\n",
      "Batch 66/700: Discriminator loss = 1.4532989263534546, GAN loss = [3.1885397, 0.918709, 1.3096168]\n",
      "Batch 67/700: Discriminator loss = 1.4401729106903076, GAN loss = [3.1610863, 0.9401574, 1.2607884]\n",
      "Batch 68/700: Discriminator loss = 1.512287974357605, GAN loss = [3.1687987, 0.93202674, 1.2767016]\n",
      "Batch 69/700: Discriminator loss = 1.4988532066345215, GAN loss = [3.0892165, 0.9305513, 1.1986613]\n",
      "Batch 70/700: Discriminator loss = 1.5668551921844482, GAN loss = [3.0443323, 0.9149871, 1.1694053]\n",
      "Batch 71/700: Discriminator loss = 1.5290184020996094, GAN loss = [3.0755813, 0.9346376, 1.181066]\n",
      "Batch 72/700: Discriminator loss = 1.5447442531585693, GAN loss = [3.0504525, 0.96297777, 1.1276573]\n",
      "Batch 73/700: Discriminator loss = 1.5573675632476807, GAN loss = [2.9877627, 0.9490807, 1.0789247]\n",
      "Batch 74/700: Discriminator loss = 1.5850818157196045, GAN loss = [2.914047, 0.93399394, 1.0203551]\n",
      "Batch 75/700: Discriminator loss = 1.6579841375350952, GAN loss = [2.8657062, 0.90388656, 1.0021806]\n",
      "Batch 76/700: Discriminator loss = 1.7336552143096924, GAN loss = [2.7708225, 0.8679921, 0.9432515]\n",
      "Batch 77/700: Discriminator loss = 1.7943671941757202, GAN loss = [2.678634, 0.8015197, 0.91759485]\n",
      "Batch 78/700: Discriminator loss = 1.7753626108169556, GAN loss = [2.64917, 0.7587019, 0.9310073]\n",
      "Batch 79/700: Discriminator loss = 1.7596049308776855, GAN loss = [2.5886266, 0.74454355, 0.8846804]\n",
      "Batch 80/700: Discriminator loss = 1.741065263748169, GAN loss = [2.6074884, 0.76899254, 0.8791512]\n",
      "Batch 81/700: Discriminator loss = 1.7021180391311646, GAN loss = [2.5831692, 0.7852382, 0.8386479]\n",
      "Batch 82/700: Discriminator loss = 1.6493268013000488, GAN loss = [2.5913243, 0.8093875, 0.82271713]\n",
      "Batch 83/700: Discriminator loss = 1.6071909666061401, GAN loss = [2.569006, 0.8420288, 0.7678217]\n",
      "Batch 84/700: Discriminator loss = 1.5957801342010498, GAN loss = [2.53581, 0.83749527, 0.73922694]\n",
      "Batch 85/700: Discriminator loss = 1.6018534898757935, GAN loss = [2.552049, 0.85617465, 0.7368556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 86/700: Discriminator loss = 1.6338741779327393, GAN loss = [2.5123472, 0.8232923, 0.7301072]\n",
      "Batch 87/700: Discriminator loss = 1.611010193824768, GAN loss = [2.4967158, 0.79617393, 0.74166465]\n",
      "Batch 88/700: Discriminator loss = 1.5930440425872803, GAN loss = [2.4756355, 0.7781681, 0.73866075]\n",
      "Batch 89/700: Discriminator loss = 1.543891429901123, GAN loss = [2.519611, 0.7786584, 0.7822164]\n",
      "Batch 90/700: Discriminator loss = 1.5415540933609009, GAN loss = [2.5089064, 0.7955412, 0.7546991]\n",
      "Batch 91/700: Discriminator loss = 1.499546766281128, GAN loss = [2.516527, 0.7883119, 0.7696199]\n",
      "Batch 92/700: Discriminator loss = 1.5000752210617065, GAN loss = [2.4835505, 0.77092606, 0.7540987]\n",
      "Batch 93/700: Discriminator loss = 1.4857004880905151, GAN loss = [2.494513, 0.77341753, 0.76263636]\n",
      "Batch 94/700: Discriminator loss = 1.4723342657089233, GAN loss = [2.4967787, 0.78491104, 0.75347215]\n",
      "Batch 95/700: Discriminator loss = 1.4576003551483154, GAN loss = [2.4798207, 0.78499115, 0.7364971]\n",
      "Batch 96/700: Discriminator loss = 1.4616252183914185, GAN loss = [2.489265, 0.7851862, 0.74581015]\n",
      "Batch 97/700: Discriminator loss = 1.4696882963180542, GAN loss = [2.4773886, 0.7775103, 0.7416752]\n",
      "Batch 98/700: Discriminator loss = 1.4425058364868164, GAN loss = [2.483739, 0.7632204, 0.76238173]\n",
      "Batch 99/700: Discriminator loss = 1.458500862121582, GAN loss = [2.452704, 0.75799567, 0.7366391]\n",
      "Batch 100/700: Discriminator loss = 1.4650180339813232, GAN loss = [2.445759, 0.7288379, 0.7589196]\n",
      "Batch 101/700: Discriminator loss = 1.4376882314682007, GAN loss = [2.4239132, 0.72942156, 0.736557]\n",
      "Batch 102/700: Discriminator loss = 1.4469150304794312, GAN loss = [2.4499056, 0.7362123, 0.7558278]\n",
      "Batch 103/700: Discriminator loss = 1.434711217880249, GAN loss = [2.4562626, 0.7396629, 0.7588048]\n",
      "Batch 104/700: Discriminator loss = 1.421242594718933, GAN loss = [2.4638026, 0.73010206, 0.7759784]\n",
      "Batch 105/700: Discriminator loss = 1.4065488576889038, GAN loss = [2.4679654, 0.739022, 0.77129525]\n",
      "Batch 106/700: Discriminator loss = 1.4069463014602661, GAN loss = [2.4601507, 0.7380978, 0.76448035]\n",
      "Batch 107/700: Discriminator loss = 1.3893837928771973, GAN loss = [2.4890733, 0.7482705, 0.78330714]\n",
      "Batch 108/700: Discriminator loss = 1.3717482089996338, GAN loss = [2.4955945, 0.75238836, 0.785789]\n",
      "Batch 109/700: Discriminator loss = 1.3486026525497437, GAN loss = [2.5113306, 0.77156496, 0.78242904]\n",
      "Batch 110/700: Discriminator loss = 1.3372777700424194, GAN loss = [2.516858, 0.7682944, 0.791311]\n",
      "Batch 111/700: Discriminator loss = 1.3501756191253662, GAN loss = [2.5263355, 0.75968957, 0.8094788]\n",
      "Batch 112/700: Discriminator loss = 1.3440853357315063, GAN loss = [2.517875, 0.74597144, 0.8148239]\n",
      "Batch 113/700: Discriminator loss = 1.3504831790924072, GAN loss = [2.497818, 0.74237597, 0.79844916]\n",
      "Batch 114/700: Discriminator loss = 1.360230803489685, GAN loss = [2.4894674, 0.73080045, 0.80176044]\n",
      "Batch 115/700: Discriminator loss = 1.3596841096878052, GAN loss = [2.4832678, 0.7283938, 0.7980527]\n",
      "Batch 116/700: Discriminator loss = 1.3607040643692017, GAN loss = [2.4913743, 0.72099245, 0.8136463]\n",
      "Batch 117/700: Discriminator loss = 1.363889217376709, GAN loss = [2.4685926, 0.7153285, 0.79661375]\n",
      "Batch 118/700: Discriminator loss = 1.3646304607391357, GAN loss = [2.4685583, 0.7120096, 0.7999836]\n",
      "Batch 119/700: Discriminator loss = 1.362382173538208, GAN loss = [2.4601696, 0.704152, 0.7995354]\n",
      "Batch 120/700: Discriminator loss = 1.359690546989441, GAN loss = [2.46506, 0.7031614, 0.8054978]\n",
      "Batch 121/700: Discriminator loss = 1.3495491743087769, GAN loss = [2.477513, 0.7069981, 0.814193]\n",
      "Batch 122/700: Discriminator loss = 1.3234846591949463, GAN loss = [2.5002594, 0.7203558, 0.82365876]\n",
      "Batch 123/700: Discriminator loss = 1.306624412536621, GAN loss = [2.532499, 0.7416975, 0.834636]\n",
      "Batch 124/700: Discriminator loss = 1.2903884649276733, GAN loss = [2.562354, 0.75726527, 0.8490051]\n",
      "Batch 125/700: Discriminator loss = 1.2849498987197876, GAN loss = [2.5687416, 0.76287043, 0.8498709]\n",
      "Batch 126/700: Discriminator loss = 1.281409502029419, GAN loss = [2.5658386, 0.7528592, 0.8570631]\n",
      "Batch 127/700: Discriminator loss = 1.2908756732940674, GAN loss = [2.5757165, 0.7588458, 0.8610388]\n",
      "Batch 128/700: Discriminator loss = 1.2930810451507568, GAN loss = [2.5859385, 0.7600465, 0.87014544]\n",
      "Batch 129/700: Discriminator loss = 1.2844219207763672, GAN loss = [2.58304, 0.7573267, 0.87005174]\n",
      "Batch 130/700: Discriminator loss = 1.2906633615493774, GAN loss = [2.589589, 0.7602008, 0.87381065]\n",
      "Batch 131/700: Discriminator loss = 1.2892409563064575, GAN loss = [2.5848935, 0.76439184, 0.86500883]\n",
      "Batch 132/700: Discriminator loss = 1.2833369970321655, GAN loss = [2.6036716, 0.76661146, 0.8816537]\n",
      "Batch 133/700: Discriminator loss = 1.273909091949463, GAN loss = [2.6282873, 0.7817581, 0.89120996]\n",
      "Batch 134/700: Discriminator loss = 1.261128544807434, GAN loss = [2.6473842, 0.80250776, 0.88964725]\n",
      "Batch 135/700: Discriminator loss = 1.2442553043365479, GAN loss = [2.652244, 0.8175592, 0.87954676]\n",
      "Batch 136/700: Discriminator loss = 1.237987995147705, GAN loss = [2.6705432, 0.8328438, 0.8826525]\n",
      "Batch 137/700: Discriminator loss = 1.2242543697357178, GAN loss = [2.6763277, 0.83648604, 0.88488877]\n",
      "Batch 138/700: Discriminator loss = 1.2371703386306763, GAN loss = [2.7117286, 0.8509356, 0.9059353]\n",
      "Batch 139/700: Discriminator loss = 1.2290607690811157, GAN loss = [2.6979592, 0.84599024, 0.8972062]\n",
      "Batch 140/700: Discriminator loss = 1.2512102127075195, GAN loss = [2.6821156, 0.8417022, 0.885745]\n",
      "Batch 141/700: Discriminator loss = 1.2474517822265625, GAN loss = [2.70494, 0.8351817, 0.915183]\n",
      "Batch 142/700: Discriminator loss = 1.2359329462051392, GAN loss = [2.7061803, 0.8285337, 0.9231641]\n",
      "Batch 143/700: Discriminator loss = 1.2472425699234009, GAN loss = [2.7151885, 0.82515436, 0.9356449]\n",
      "Batch 144/700: Discriminator loss = 1.2310717105865479, GAN loss = [2.7461183, 0.8142288, 0.9775933]\n",
      "Batch 145/700: Discriminator loss = 1.239614486694336, GAN loss = [2.7506592, 0.82082963, 0.9756287]\n",
      "Batch 146/700: Discriminator loss = 1.2273821830749512, GAN loss = [2.788223, 0.833658, 1.0004604]\n",
      "Batch 147/700: Discriminator loss = 1.208614468574524, GAN loss = [2.7951446, 0.839723, 1.0014135]\n",
      "Batch 148/700: Discriminator loss = 1.1955739259719849, GAN loss = [2.871493, 0.8619241, 1.0556579]\n",
      "Batch 149/700: Discriminator loss = 1.188547968864441, GAN loss = [2.8828673, 0.8801931, 1.0488609]\n",
      "Batch 150/700: Discriminator loss = 1.1705011129379272, GAN loss = [2.94583, 0.8973171, 1.0947978]\n",
      "Batch 151/700: Discriminator loss = 1.1928709745407104, GAN loss = [2.9305234, 0.91358846, 1.0633199]\n",
      "Batch 152/700: Discriminator loss = 1.1710543632507324, GAN loss = [2.9881392, 0.92084754, 1.1137768]\n",
      "Batch 153/700: Discriminator loss = 1.169929027557373, GAN loss = [2.998824, 0.932248, 1.1131612]\n",
      "Batch 154/700: Discriminator loss = 1.1848962306976318, GAN loss = [3.0137374, 0.95107263, 1.1093503]\n",
      "Batch 155/700: Discriminator loss = 1.1814980506896973, GAN loss = [2.9688938, 0.94322556, 1.072454]\n",
      "Batch 156/700: Discriminator loss = 1.181983470916748, GAN loss = [2.9843044, 0.9611734, 1.070018]\n",
      "Batch 157/700: Discriminator loss = 1.198920488357544, GAN loss = [2.9975023, 0.9650471, 1.0794439]\n",
      "Batch 158/700: Discriminator loss = 1.1931803226470947, GAN loss = [2.977131, 0.9522103, 1.0720128]\n",
      "Batch 159/700: Discriminator loss = 1.2156732082366943, GAN loss = [2.9661832, 0.9577191, 1.0556604]\n",
      "Batch 160/700: Discriminator loss = 1.2189284563064575, GAN loss = [2.9522088, 0.9538095, 1.0456991]\n",
      "Batch 161/700: Discriminator loss = 1.1977816820144653, GAN loss = [2.9613645, 0.9598683, 1.0488986]\n",
      "Batch 162/700: Discriminator loss = 1.1957765817642212, GAN loss = [2.9808922, 0.971375, 1.0570207]\n",
      "Batch 163/700: Discriminator loss = 1.1700273752212524, GAN loss = [3.0173848, 0.97646856, 1.0885202]\n",
      "Batch 164/700: Discriminator loss = 1.1731094121932983, GAN loss = [3.022527, 0.9949934, 1.0752385]\n",
      "Batch 165/700: Discriminator loss = 1.1685484647750854, GAN loss = [3.0710857, 1.0090549, 1.1098391]\n",
      "Batch 166/700: Discriminator loss = 1.1621601581573486, GAN loss = [3.0555873, 0.99723345, 1.1062684]\n",
      "Batch 167/700: Discriminator loss = 1.194000244140625, GAN loss = [3.0395403, 1.0220939, 1.0654705]\n",
      "Batch 168/700: Discriminator loss = 1.1867377758026123, GAN loss = [3.0461383, 1.0090804, 1.0851958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 169/700: Discriminator loss = 1.228506326675415, GAN loss = [2.9589615, 0.9983594, 1.0088559]\n",
      "Batch 170/700: Discriminator loss = 1.2304705381393433, GAN loss = [2.9495656, 0.9767485, 1.0211856]\n",
      "Batch 171/700: Discriminator loss = 1.2675700187683105, GAN loss = [2.852952, 0.96174395, 0.93968713]\n",
      "Batch 172/700: Discriminator loss = 1.2603381872177124, GAN loss = [2.8410714, 0.93826175, 0.95139694]\n",
      "Batch 173/700: Discriminator loss = 1.3416470289230347, GAN loss = [2.81355, 0.953985, 0.90825796]\n",
      "Batch 174/700: Discriminator loss = 1.3296704292297363, GAN loss = [2.7762253, 0.91837955, 0.9066435]\n",
      "Batch 175/700: Discriminator loss = 1.3750784397125244, GAN loss = [2.6961098, 0.89106154, 0.85394496]\n",
      "Batch 176/700: Discriminator loss = 1.3909739255905151, GAN loss = [2.6184933, 0.83946854, 0.8280144]\n",
      "Batch 177/700: Discriminator loss = 1.4678670167922974, GAN loss = [2.5662107, 0.83513826, 0.7801484]\n",
      "Batch 178/700: Discriminator loss = 1.4528828859329224, GAN loss = [2.5295627, 0.80024946, 0.7784729]\n",
      "Batch 179/700: Discriminator loss = 1.4914506673812866, GAN loss = [2.4958854, 0.8157234, 0.7294012]\n",
      "Batch 180/700: Discriminator loss = 1.4027408361434937, GAN loss = [2.492738, 0.7946609, 0.74739486]\n",
      "Batch 181/700: Discriminator loss = 1.4219331741333008, GAN loss = [2.504332, 0.82170904, 0.7320206]\n",
      "Batch 182/700: Discriminator loss = 1.3798534870147705, GAN loss = [2.5259686, 0.83252215, 0.7429286]\n",
      "Batch 183/700: Discriminator loss = 1.357107400894165, GAN loss = [2.5425124, 0.8380425, 0.7540401]\n",
      "Batch 184/700: Discriminator loss = 1.3869467973709106, GAN loss = [2.5512168, 0.83417845, 0.7666986]\n",
      "Batch 185/700: Discriminator loss = 1.3522366285324097, GAN loss = [2.530137, 0.8148317, 0.7650535]\n",
      "Batch 186/700: Discriminator loss = 1.3647348880767822, GAN loss = [2.5339687, 0.8166033, 0.7671996]\n",
      "Batch 187/700: Discriminator loss = 1.3503704071044922, GAN loss = [2.5246549, 0.7958884, 0.77868456]\n",
      "Batch 188/700: Discriminator loss = 1.3760689496994019, GAN loss = [2.5200887, 0.7908592, 0.7792296]\n",
      "Batch 189/700: Discriminator loss = 1.3508943319320679, GAN loss = [2.5467527, 0.78510004, 0.8117327]\n",
      "Batch 190/700: Discriminator loss = 1.3530384302139282, GAN loss = [2.5728776, 0.79149497, 0.83154225]\n",
      "Batch 191/700: Discriminator loss = 1.3260737657546997, GAN loss = [2.6034963, 0.7964194, 0.85731673]\n",
      "Batch 192/700: Discriminator loss = 1.3145803213119507, GAN loss = [2.6375, 0.8167223, 0.87109864]\n",
      "Batch 193/700: Discriminator loss = 1.2976266145706177, GAN loss = [2.6744318, 0.82042265, 0.904414]\n",
      "Batch 194/700: Discriminator loss = 1.2891384363174438, GAN loss = [2.7107532, 0.8321626, 0.9290789]\n",
      "Batch 195/700: Discriminator loss = 1.259778380393982, GAN loss = [2.7350569, 0.82300925, 0.96261877]\n",
      "Batch 196/700: Discriminator loss = 1.2521088123321533, GAN loss = [2.7953947, 0.85431933, 0.99172896]\n",
      "Batch 197/700: Discriminator loss = 1.2327723503112793, GAN loss = [2.8476832, 0.89064926, 1.0077716]\n",
      "Batch 198/700: Discriminator loss = 1.2053574323654175, GAN loss = [2.924752, 0.9083571, 1.0672189]\n",
      "Batch 199/700: Discriminator loss = 1.2005231380462646, GAN loss = [2.9427123, 0.9366943, 1.0569288]\n",
      "Batch 200/700: Discriminator loss = 1.2007006406784058, GAN loss = [2.9777784, 0.9350825, 1.0936961]\n",
      "Batch 201/700: Discriminator loss = 1.2130204439163208, GAN loss = [2.947003, 0.9059977, 1.0920936]\n",
      "Batch 202/700: Discriminator loss = 1.2257750034332275, GAN loss = [2.9541144, 0.9215755, 1.0837151]\n",
      "Batch 203/700: Discriminator loss = 1.2196964025497437, GAN loss = [2.9662423, 0.9233827, 1.0941232]\n",
      "Batch 204/700: Discriminator loss = 1.2349618673324585, GAN loss = [2.9656575, 0.9185395, 1.0984699]\n",
      "Batch 205/700: Discriminator loss = 1.2334473133087158, GAN loss = [2.9771914, 0.92031527, 1.1083134]\n",
      "Batch 206/700: Discriminator loss = 1.2170019149780273, GAN loss = [2.9858634, 0.9360652, 1.1013207]\n",
      "Batch 207/700: Discriminator loss = 1.1949222087860107, GAN loss = [2.985741, 0.93205893, 1.1052904]\n",
      "Batch 208/700: Discriminator loss = 1.2303749322891235, GAN loss = [2.9890413, 0.95648766, 1.084246]\n",
      "Batch 209/700: Discriminator loss = 1.2019773721694946, GAN loss = [2.9588091, 0.9501236, 1.0604607]\n",
      "Batch 210/700: Discriminator loss = 1.2228413820266724, GAN loss = [2.9928677, 0.9729667, 1.0717593]\n",
      "Batch 211/700: Discriminator loss = 1.2104921340942383, GAN loss = [3.0190737, 0.96759117, 1.1034267]\n",
      "Batch 212/700: Discriminator loss = 1.2210087776184082, GAN loss = [3.033696, 0.9771168, 1.1086154]\n",
      "Batch 213/700: Discriminator loss = 1.2269669771194458, GAN loss = [3.0378785, 0.9894518, 1.1005633]\n",
      "Batch 214/700: Discriminator loss = 1.2200651168823242, GAN loss = [2.99614, 0.9747506, 1.0736309]\n",
      "Batch 215/700: Discriminator loss = 1.2454173564910889, GAN loss = [2.989851, 0.9992691, 1.042928]\n",
      "Batch 216/700: Discriminator loss = 1.2873010635375977, GAN loss = [2.970576, 0.98650503, 1.0365225]\n",
      "Batch 217/700: Discriminator loss = 1.3369755744934082, GAN loss = [2.9072273, 0.9699955, 0.9897853]\n",
      "Batch 218/700: Discriminator loss = 1.3959810733795166, GAN loss = [2.8539782, 0.95157135, 0.95505685]\n",
      "Batch 219/700: Discriminator loss = 1.4271215200424194, GAN loss = [2.768995, 0.8855513, 0.9361836]\n",
      "Batch 220/700: Discriminator loss = 1.4688379764556885, GAN loss = [2.717265, 0.84760565, 0.92248106]\n",
      "Batch 221/700: Discriminator loss = 1.4539494514465332, GAN loss = [2.7003312, 0.8374453, 0.9157819]\n",
      "Batch 222/700: Discriminator loss = 1.443328619003296, GAN loss = [2.677214, 0.8375541, 0.8926255]\n",
      "Batch 223/700: Discriminator loss = 1.4300645589828491, GAN loss = [2.7091634, 0.8539637, 0.90823394]\n",
      "Batch 224/700: Discriminator loss = 1.4243378639221191, GAN loss = [2.7396073, 0.8793898, 0.9133236]\n",
      "Batch 225/700: Discriminator loss = 1.3962544202804565, GAN loss = [2.7544522, 0.86515486, 0.94247836]\n",
      "Batch 226/700: Discriminator loss = 1.3785340785980225, GAN loss = [2.7453077, 0.8685587, 0.93000484]\n",
      "Batch 227/700: Discriminator loss = 1.3757617473602295, GAN loss = [2.7862651, 0.9093619, 0.9302337]\n",
      "Batch 228/700: Discriminator loss = 1.3578561544418335, GAN loss = [2.7948494, 0.9188085, 0.9294485]\n",
      "Batch 229/700: Discriminator loss = 1.3634732961654663, GAN loss = [2.7892327, 0.8872675, 0.9554518]\n",
      "Batch 230/700: Discriminator loss = 1.387395977973938, GAN loss = [2.7607746, 0.8476727, 0.9666678]\n",
      "Batch 231/700: Discriminator loss = 1.390678882598877, GAN loss = [2.6801631, 0.8122747, 0.92153084]\n",
      "Batch 232/700: Discriminator loss = 1.4012352228164673, GAN loss = [2.649826, 0.79712945, 0.90641266]\n",
      "Batch 233/700: Discriminator loss = 1.3985031843185425, GAN loss = [2.6199508, 0.78735185, 0.8863867]\n",
      "Batch 234/700: Discriminator loss = 1.393401026725769, GAN loss = [2.6210623, 0.7843879, 0.89052963]\n",
      "Batch 235/700: Discriminator loss = 1.3898899555206299, GAN loss = [2.63181, 0.8029363, 0.8827943]\n",
      "Batch 236/700: Discriminator loss = 1.3649812936782837, GAN loss = [2.6281264, 0.8076647, 0.8744482]\n",
      "Batch 237/700: Discriminator loss = 1.367256760597229, GAN loss = [2.597792, 0.81535095, 0.83649284]\n",
      "Batch 238/700: Discriminator loss = 1.3576315641403198, GAN loss = [2.5955505, 0.8209961, 0.8286726]\n",
      "Batch 239/700: Discriminator loss = 1.3626962900161743, GAN loss = [2.5748832, 0.81264687, 0.816421]\n",
      "Batch 240/700: Discriminator loss = 1.3665934801101685, GAN loss = [2.5557888, 0.7993528, 0.81069016]\n",
      "Batch 241/700: Discriminator loss = 1.388634443283081, GAN loss = [2.551589, 0.8110424, 0.79487145]\n",
      "Batch 242/700: Discriminator loss = 1.38605535030365, GAN loss = [2.53797, 0.79695874, 0.7954068]\n",
      "Batch 243/700: Discriminator loss = 1.4052653312683105, GAN loss = [2.5239394, 0.7991071, 0.7792963]\n",
      "Batch 244/700: Discriminator loss = 1.3612200021743774, GAN loss = [2.5382714, 0.81650347, 0.7763023]\n",
      "Batch 245/700: Discriminator loss = 1.3351895809173584, GAN loss = [2.5631688, 0.8338035, 0.7839735]\n",
      "Batch 246/700: Discriminator loss = 1.3219919204711914, GAN loss = [2.5490725, 0.83393675, 0.7698214]\n",
      "Batch 247/700: Discriminator loss = 1.3093771934509277, GAN loss = [2.5603685, 0.82815343, 0.78697985]\n",
      "Batch 248/700: Discriminator loss = 1.327400803565979, GAN loss = [2.5578842, 0.8273354, 0.7853922]\n",
      "Batch 249/700: Discriminator loss = 1.3371386528015137, GAN loss = [2.5357203, 0.8228245, 0.7678177]\n",
      "Batch 250/700: Discriminator loss = 1.3363592624664307, GAN loss = [2.5343008, 0.82035846, 0.7689411]\n",
      "Batch 251/700: Discriminator loss = 1.3473575115203857, GAN loss = [2.5162904, 0.79523623, 0.776129]\n",
      "Batch 252/700: Discriminator loss = 1.3418995141983032, GAN loss = [2.4880068, 0.7804901, 0.76266515]\n",
      "Batch 253/700: Discriminator loss = 1.3348854780197144, GAN loss = [2.4845827, 0.78428835, 0.75551707]\n",
      "Batch 254/700: Discriminator loss = 1.3079962730407715, GAN loss = [2.5131276, 0.796848, 0.7715797]\n",
      "Batch 255/700: Discriminator loss = 1.2946040630340576, GAN loss = [2.540176, 0.81659997, 0.7789563]\n",
      "Batch 256/700: Discriminator loss = 1.2614480257034302, GAN loss = [2.5848987, 0.8313644, 0.80899996]\n",
      "Batch 257/700: Discriminator loss = 1.2607505321502686, GAN loss = [2.5746932, 0.83550674, 0.79474235]\n",
      "Batch 258/700: Discriminator loss = 1.2576079368591309, GAN loss = [2.5900009, 0.82643133, 0.81921524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 259/700: Discriminator loss = 1.287503957748413, GAN loss = [2.5844562, 0.8209103, 0.8192804]\n",
      "Batch 260/700: Discriminator loss = 1.2705897092819214, GAN loss = [2.5781758, 0.8098037, 0.8241936]\n",
      "Batch 261/700: Discriminator loss = 1.2745068073272705, GAN loss = [2.5638428, 0.80732286, 0.8124261]\n",
      "Batch 262/700: Discriminator loss = 1.260688304901123, GAN loss = [2.5900123, 0.81239396, 0.833609]\n",
      "Batch 263/700: Discriminator loss = 1.2604023218154907, GAN loss = [2.6020308, 0.81357706, 0.8445288]\n",
      "Batch 264/700: Discriminator loss = 1.2647732496261597, GAN loss = [2.6019423, 0.82313365, 0.8349697]\n",
      "Batch 265/700: Discriminator loss = 1.261710524559021, GAN loss = [2.6058621, 0.8259706, 0.83613986]\n",
      "Batch 266/700: Discriminator loss = 1.2548887729644775, GAN loss = [2.5934165, 0.8248056, 0.8249481]\n",
      "Batch 267/700: Discriminator loss = 1.2427923679351807, GAN loss = [2.6170099, 0.83148646, 0.84194964]\n",
      "Batch 268/700: Discriminator loss = 1.2431411743164062, GAN loss = [2.6227334, 0.837491, 0.8417574]\n",
      "Batch 269/700: Discriminator loss = 1.2438809871673584, GAN loss = [2.647383, 0.836084, 0.8679009]\n",
      "Batch 270/700: Discriminator loss = 1.2450870275497437, GAN loss = [2.630417, 0.83583105, 0.8512762]\n",
      "Batch 271/700: Discriminator loss = 1.2410334348678589, GAN loss = [2.666197, 0.8462048, 0.87677383]\n",
      "Batch 272/700: Discriminator loss = 1.2432628870010376, GAN loss = [2.6667237, 0.86177343, 0.86182517]\n",
      "Batch 273/700: Discriminator loss = 1.2342145442962646, GAN loss = [2.6827092, 0.87216794, 0.86751103]\n",
      "Batch 274/700: Discriminator loss = 1.2226321697235107, GAN loss = [2.690937, 0.878778, 0.86922485]\n",
      "Batch 275/700: Discriminator loss = 1.2116230726242065, GAN loss = [2.6830626, 0.86943686, 0.87078863]\n",
      "Batch 276/700: Discriminator loss = 1.2260303497314453, GAN loss = [2.6940866, 0.8902593, 0.86108774]\n",
      "Batch 277/700: Discriminator loss = 1.192907452583313, GAN loss = [2.7183454, 0.88597924, 0.8897287]\n",
      "Batch 278/700: Discriminator loss = 1.2184699773788452, GAN loss = [2.7585661, 0.90659994, 0.909433]\n",
      "Batch 279/700: Discriminator loss = 1.204106330871582, GAN loss = [2.7637835, 0.9015546, 0.91980153]\n",
      "Batch 280/700: Discriminator loss = 1.219264268875122, GAN loss = [2.7550766, 0.89999956, 0.9127538]\n",
      "Batch 281/700: Discriminator loss = 1.2192282676696777, GAN loss = [2.7616847, 0.8979691, 0.92149436]\n",
      "Batch 282/700: Discriminator loss = 1.2249610424041748, GAN loss = [2.7744336, 0.9086635, 0.92364913]\n",
      "Batch 283/700: Discriminator loss = 1.2041889429092407, GAN loss = [2.7849207, 0.9028723, 0.9400269]\n",
      "Batch 284/700: Discriminator loss = 1.2124532461166382, GAN loss = [2.8064046, 0.9267508, 0.9377306]\n",
      "Batch 285/700: Discriminator loss = 1.1842389106750488, GAN loss = [2.8343747, 0.9246395, 0.9679108]\n",
      "Batch 286/700: Discriminator loss = 1.2107282876968384, GAN loss = [2.824865, 0.94627535, 0.9368652]\n",
      "Batch 287/700: Discriminator loss = 1.188655138015747, GAN loss = [2.831184, 0.93117094, 0.95838684]\n",
      "Batch 288/700: Discriminator loss = 1.2316349744796753, GAN loss = [2.7653456, 0.9257848, 0.89802873]\n",
      "Batch 289/700: Discriminator loss = 1.2081212997436523, GAN loss = [2.8101208, 0.90846914, 0.9602091]\n",
      "Batch 290/700: Discriminator loss = 1.2455121278762817, GAN loss = [2.75424, 0.9076072, 0.90527594]\n",
      "Batch 291/700: Discriminator loss = 1.2138186693191528, GAN loss = [2.7699826, 0.88249516, 0.94621444]\n",
      "Batch 292/700: Discriminator loss = 1.2630082368850708, GAN loss = [2.7659175, 0.8987926, 0.9259338]\n",
      "Batch 293/700: Discriminator loss = 1.1962510347366333, GAN loss = [2.818437, 0.8977187, 0.97960883]\n",
      "Batch 294/700: Discriminator loss = 1.1982076168060303, GAN loss = [2.8371959, 0.92593145, 0.97023946]\n",
      "Batch 295/700: Discriminator loss = 1.1701914072036743, GAN loss = [2.906576, 0.9410465, 1.0245914]\n",
      "Batch 296/700: Discriminator loss = 1.1726535558700562, GAN loss = [2.9332922, 0.9643371, 1.0281079]\n",
      "Batch 297/700: Discriminator loss = 1.1644827127456665, GAN loss = [2.9624286, 0.9604797, 1.0611964]\n",
      "Batch 298/700: Discriminator loss = 1.1702158451080322, GAN loss = [3.0076232, 0.9671844, 1.0997832]\n",
      "Batch 299/700: Discriminator loss = 1.1596782207489014, GAN loss = [3.0001066, 0.9625303, 1.0970179]\n",
      "Batch 300/700: Discriminator loss = 1.1954855918884277, GAN loss = [2.967157, 0.9838659, 1.042828]\n",
      "Batch 301/700: Discriminator loss = 1.1959571838378906, GAN loss = [2.9493833, 0.9661852, 1.0428293]\n",
      "Batch 302/700: Discriminator loss = 1.198380470275879, GAN loss = [2.93832, 0.9544433, 1.0436013]\n",
      "Batch 303/700: Discriminator loss = 1.2025738954544067, GAN loss = [2.8811421, 0.9431946, 0.9977653]\n",
      "Batch 304/700: Discriminator loss = 1.2017226219177246, GAN loss = [2.8887968, 0.9371653, 1.0115417]\n",
      "Batch 305/700: Discriminator loss = 1.2205471992492676, GAN loss = [2.9623177, 0.956564, 1.0657557]\n",
      "Batch 306/700: Discriminator loss = 1.2049939632415771, GAN loss = [2.9391263, 0.94552314, 1.0536977]\n",
      "Batch 307/700: Discriminator loss = 1.1997791528701782, GAN loss = [2.9794996, 0.935418, 1.1042674]\n",
      "Batch 308/700: Discriminator loss = 1.2264224290847778, GAN loss = [2.9723127, 0.9306404, 1.1019449]\n",
      "Batch 309/700: Discriminator loss = 1.2317731380462646, GAN loss = [2.9861736, 0.9071125, 1.1394162]\n",
      "Batch 310/700: Discriminator loss = 1.22653067111969, GAN loss = [2.9949272, 0.88196075, 1.1733992]\n",
      "Batch 311/700: Discriminator loss = 1.2529405355453491, GAN loss = [3.0279982, 0.9035705, 1.1849347]\n",
      "Batch 312/700: Discriminator loss = 1.2395832538604736, GAN loss = [3.086155, 0.92480826, 1.2219294]\n",
      "Batch 313/700: Discriminator loss = 1.208728313446045, GAN loss = [3.1321661, 0.93855715, 1.2542722]\n",
      "Batch 314/700: Discriminator loss = 1.221595287322998, GAN loss = [3.1221519, 0.9669867, 1.2159132]\n",
      "Batch 315/700: Discriminator loss = 1.189440369606018, GAN loss = [3.147943, 0.9731562, 1.2356225]\n",
      "Batch 316/700: Discriminator loss = 1.1888604164123535, GAN loss = [3.2123759, 0.99987704, 1.2734233]\n",
      "Batch 317/700: Discriminator loss = 1.1947606801986694, GAN loss = [3.1987479, 1.015531, 1.2442312]\n",
      "Batch 318/700: Discriminator loss = 1.1944599151611328, GAN loss = [3.1077418, 1.0031655, 1.1656777]\n",
      "Batch 319/700: Discriminator loss = 1.2559689283370972, GAN loss = [3.1026616, 1.0251737, 1.1386708]\n",
      "Batch 320/700: Discriminator loss = 1.2711330652236938, GAN loss = [3.041371, 1.0070748, 1.0955572]\n",
      "Batch 321/700: Discriminator loss = 1.3167475461959839, GAN loss = [3.0217488, 1.009037, 1.0740467]\n",
      "Batch 322/700: Discriminator loss = 1.3620004653930664, GAN loss = [2.9880984, 1.0371695, 1.0123341]\n",
      "Batch 323/700: Discriminator loss = 1.3466511964797974, GAN loss = [2.9587405, 1.013676, 1.0065407]\n",
      "Batch 324/700: Discriminator loss = 1.3985400199890137, GAN loss = [2.8965547, 0.98923224, 0.96886843]\n",
      "Batch 325/700: Discriminator loss = 1.3766975402832031, GAN loss = [2.904066, 0.9573511, 1.0083303]\n",
      "Batch 326/700: Discriminator loss = 1.3651381731033325, GAN loss = [2.9335666, 0.9654113, 1.0298423]\n",
      "Batch 327/700: Discriminator loss = 1.339836835861206, GAN loss = [2.9413602, 0.94214267, 1.0609791]\n",
      "Batch 328/700: Discriminator loss = 1.3757638931274414, GAN loss = [2.8409636, 0.8994066, 1.0033929]\n",
      "Batch 329/700: Discriminator loss = 1.3940672874450684, GAN loss = [2.8064563, 0.8896591, 0.97870123]\n",
      "Batch 330/700: Discriminator loss = 1.4058382511138916, GAN loss = [2.7368867, 0.87062806, 0.9282263]\n",
      "Batch 331/700: Discriminator loss = 1.4171535968780518, GAN loss = [2.7170203, 0.8418066, 0.93724215]\n",
      "Batch 332/700: Discriminator loss = 1.4582233428955078, GAN loss = [2.6813385, 0.8386252, 0.9047961]\n",
      "Batch 333/700: Discriminator loss = 1.4078747034072876, GAN loss = [2.6697688, 0.8329036, 0.89900184]\n",
      "Batch 334/700: Discriminator loss = 1.4377586841583252, GAN loss = [2.6633642, 0.82506806, 0.9004816]\n",
      "Batch 335/700: Discriminator loss = 1.4543098211288452, GAN loss = [2.6633315, 0.83617294, 0.8893853]\n",
      "Batch 336/700: Discriminator loss = 1.4095855951309204, GAN loss = [2.6949463, 0.86743516, 0.8897766]\n",
      "Batch 337/700: Discriminator loss = 1.3782075643539429, GAN loss = [2.7134163, 0.8948992, 0.8808233]\n",
      "Batch 338/700: Discriminator loss = 1.3976134061813354, GAN loss = [2.6985974, 0.9039234, 0.8570235]\n",
      "Batch 339/700: Discriminator loss = 1.4354695081710815, GAN loss = [2.670147, 0.91554505, 0.8169975]\n",
      "Batch 340/700: Discriminator loss = 1.418121576309204, GAN loss = [2.649813, 0.9198067, 0.7924515]\n",
      "Batch 341/700: Discriminator loss = 1.392720341682434, GAN loss = [2.6347182, 0.9179988, 0.7792206]\n",
      "Batch 342/700: Discriminator loss = 1.3713583946228027, GAN loss = [2.6188765, 0.89869493, 0.7827465]\n",
      "Batch 343/700: Discriminator loss = 1.3596737384796143, GAN loss = [2.573731, 0.87546486, 0.76089865]\n",
      "Batch 344/700: Discriminator loss = 1.3780544996261597, GAN loss = [2.5461967, 0.8575181, 0.7513779]\n",
      "Batch 345/700: Discriminator loss = 1.384506106376648, GAN loss = [2.5419676, 0.83130866, 0.7734222]\n",
      "Batch 346/700: Discriminator loss = 1.3450067043304443, GAN loss = [2.537535, 0.82648414, 0.7738759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 347/700: Discriminator loss = 1.307246446609497, GAN loss = [2.5740247, 0.85392606, 0.7829883]\n",
      "Batch 348/700: Discriminator loss = 1.2792067527770996, GAN loss = [2.6339614, 0.8781987, 0.81872094]\n",
      "Batch 349/700: Discriminator loss = 1.2408788204193115, GAN loss = [2.675007, 0.8871868, 0.85085297]\n",
      "Batch 350/700: Discriminator loss = 1.265769600868225, GAN loss = [2.6806479, 0.90422964, 0.8395314]\n",
      "Batch 351/700: Discriminator loss = 1.2345998287200928, GAN loss = [2.710416, 0.9012528, 0.8723623]\n",
      "Batch 352/700: Discriminator loss = 1.2489092350006104, GAN loss = [2.6815093, 0.8944298, 0.8503672]\n",
      "Batch 353/700: Discriminator loss = 1.2640372514724731, GAN loss = [2.690258, 0.88645285, 0.8671813]\n",
      "Batch 354/700: Discriminator loss = 1.265895128250122, GAN loss = [2.6798484, 0.8750561, 0.8682548]\n",
      "Batch 355/700: Discriminator loss = 1.276692271232605, GAN loss = [2.6244867, 0.8652661, 0.82276624]\n",
      "Batch 356/700: Discriminator loss = 1.2646607160568237, GAN loss = [2.646463, 0.850817, 0.8592699]\n",
      "Batch 357/700: Discriminator loss = 1.2583141326904297, GAN loss = [2.6432092, 0.8620821, 0.8448309]\n",
      "Batch 358/700: Discriminator loss = 1.2693986892700195, GAN loss = [2.6476269, 0.8856613, 0.8257521]\n",
      "Batch 359/700: Discriminator loss = 1.254546880722046, GAN loss = [2.653862, 0.8940836, 0.823652]\n",
      "Batch 360/700: Discriminator loss = 1.2383348941802979, GAN loss = [2.6783013, 0.90686256, 0.8354026]\n",
      "Batch 361/700: Discriminator loss = 1.2382155656814575, GAN loss = [2.6544895, 0.9077698, 0.81077474]\n",
      "Batch 362/700: Discriminator loss = 1.2322914600372314, GAN loss = [2.673425, 0.91968757, 0.8178829]\n",
      "Batch 363/700: Discriminator loss = 1.2262341976165771, GAN loss = [2.6475043, 0.9210914, 0.79064745]\n",
      "Batch 364/700: Discriminator loss = 1.2343838214874268, GAN loss = [2.6327085, 0.9163723, 0.7806572]\n",
      "Batch 365/700: Discriminator loss = 1.2327978610992432, GAN loss = [2.627197, 0.9198371, 0.77176636]\n",
      "Batch 366/700: Discriminator loss = 1.220270037651062, GAN loss = [2.6390314, 0.91079855, 0.79272383]\n",
      "Batch 367/700: Discriminator loss = 1.2155076265335083, GAN loss = [2.6446002, 0.90888155, 0.80029505]\n",
      "Batch 368/700: Discriminator loss = 1.2028255462646484, GAN loss = [2.6394563, 0.9010294, 0.80308884]\n",
      "Batch 369/700: Discriminator loss = 1.225663185119629, GAN loss = [2.6853573, 0.9201072, 0.8299984]\n",
      "Batch 370/700: Discriminator loss = 1.2076765298843384, GAN loss = [2.6508377, 0.9106312, 0.80504197]\n",
      "Batch 371/700: Discriminator loss = 1.2272027730941772, GAN loss = [2.6542003, 0.9164217, 0.80270135]\n",
      "Batch 372/700: Discriminator loss = 1.1980079412460327, GAN loss = [2.6465738, 0.9114045, 0.8001812]\n",
      "Batch 373/700: Discriminator loss = 1.2105950117111206, GAN loss = [2.6670206, 0.9220162, 0.8101073]\n",
      "Batch 374/700: Discriminator loss = 1.2268975973129272, GAN loss = [2.6607232, 0.9198641, 0.8060554]\n",
      "Batch 375/700: Discriminator loss = 1.226528286933899, GAN loss = [2.6252809, 0.90581346, 0.7847562]\n",
      "Batch 376/700: Discriminator loss = 1.2413400411605835, GAN loss = [2.6000814, 0.87657684, 0.7888842]\n",
      "Batch 377/700: Discriminator loss = 1.2613228559494019, GAN loss = [2.5737731, 0.8440492, 0.7951908]\n",
      "Batch 378/700: Discriminator loss = 1.2947542667388916, GAN loss = [2.542467, 0.81862986, 0.7893866]\n",
      "Batch 379/700: Discriminator loss = 1.268746256828308, GAN loss = [2.5490763, 0.79437184, 0.8203297]\n",
      "Batch 380/700: Discriminator loss = 1.2835100889205933, GAN loss = [2.5595868, 0.8020208, 0.82326436]\n",
      "Batch 381/700: Discriminator loss = 1.2565919160842896, GAN loss = [2.5732315, 0.80125725, 0.8377462]\n",
      "Batch 382/700: Discriminator loss = 1.2564506530761719, GAN loss = [2.6080513, 0.81423706, 0.85965943]\n",
      "Batch 383/700: Discriminator loss = 1.2299752235412598, GAN loss = [2.6280036, 0.8196776, 0.87424666]\n",
      "Batch 384/700: Discriminator loss = 1.2386353015899658, GAN loss = [2.657669, 0.8455551, 0.8781112]\n",
      "Batch 385/700: Discriminator loss = 1.2076749801635742, GAN loss = [2.7024374, 0.85947156, 0.90904045]\n",
      "Batch 386/700: Discriminator loss = 1.1945427656173706, GAN loss = [2.7320373, 0.8820116, 0.9161826]\n",
      "Batch 387/700: Discriminator loss = 1.170815110206604, GAN loss = [2.771603, 0.90829283, 0.9295533]\n",
      "Batch 388/700: Discriminator loss = 1.1666187047958374, GAN loss = [2.8248243, 0.9497906, 0.94136816]\n",
      "Batch 389/700: Discriminator loss = 1.1389926671981812, GAN loss = [2.870434, 0.9577451, 0.9791197]\n",
      "Batch 390/700: Discriminator loss = 1.1398454904556274, GAN loss = [2.8857663, 0.97330093, 0.97899556]\n",
      "Batch 391/700: Discriminator loss = 1.1180976629257202, GAN loss = [2.9509888, 0.98477095, 1.0328491]\n",
      "Batch 392/700: Discriminator loss = 1.1321660280227661, GAN loss = [2.93049, 1.0142518, 0.98297346]\n",
      "Batch 393/700: Discriminator loss = 1.1191774606704712, GAN loss = [2.9903274, 1.0132756, 1.0438926]\n",
      "Batch 394/700: Discriminator loss = 1.1329622268676758, GAN loss = [2.9350972, 1.0122072, 0.9898374]\n",
      "Batch 395/700: Discriminator loss = 1.128088116645813, GAN loss = [2.9516132, 1.0072143, 1.0114495]\n",
      "Batch 396/700: Discriminator loss = 1.1594350337982178, GAN loss = [2.9390953, 1.0360211, 0.9702252]\n",
      "Batch 397/700: Discriminator loss = 1.1411902904510498, GAN loss = [2.9699073, 1.0148399, 1.0223155]\n",
      "Batch 398/700: Discriminator loss = 1.1684083938598633, GAN loss = [2.9750721, 1.0206789, 1.0217352]\n",
      "Batch 399/700: Discriminator loss = 1.1357502937316895, GAN loss = [3.0013497, 0.9867308, 1.0820522]\n",
      "Batch 400/700: Discriminator loss = 1.1501048803329468, GAN loss = [3.0229914, 1.0006045, 1.0899085]\n",
      "Batch 401/700: Discriminator loss = 1.145372986793518, GAN loss = [3.003051, 0.995927, 1.0747318]\n",
      "Batch 402/700: Discriminator loss = 1.1541824340820312, GAN loss = [3.0540392, 1.010159, 1.1115711]\n",
      "Batch 403/700: Discriminator loss = 1.1278417110443115, GAN loss = [3.0755124, 0.9911997, 1.1520848]\n",
      "Batch 404/700: Discriminator loss = 1.156495213508606, GAN loss = [3.0625987, 1.031436, 1.0990176]\n",
      "Batch 405/700: Discriminator loss = 1.1110496520996094, GAN loss = [3.1241658, 1.0199186, 1.1721886]\n",
      "Batch 406/700: Discriminator loss = 1.129721760749817, GAN loss = [3.1230965, 1.0247306, 1.1663991]\n",
      "Batch 407/700: Discriminator loss = 1.126640796661377, GAN loss = [3.1048722, 1.0381291, 1.1348704]\n",
      "Batch 408/700: Discriminator loss = 1.1408851146697998, GAN loss = [3.1357193, 1.039272, 1.1646701]\n",
      "Batch 409/700: Discriminator loss = 1.1404603719711304, GAN loss = [3.1733925, 1.0377711, 1.2039373]\n",
      "Batch 410/700: Discriminator loss = 1.1546454429626465, GAN loss = [3.1165473, 1.0524676, 1.1324857]\n",
      "Batch 411/700: Discriminator loss = 1.1299774646759033, GAN loss = [3.1742125, 1.0275733, 1.2151327]\n",
      "Batch 412/700: Discriminator loss = 1.1722826957702637, GAN loss = [3.1054227, 1.0172482, 1.156754]\n",
      "Batch 413/700: Discriminator loss = 1.1563969850540161, GAN loss = [3.15588, 0.992651, 1.2318882]\n",
      "Batch 414/700: Discriminator loss = 1.1970856189727783, GAN loss = [3.12961, 0.9822309, 1.2161125]\n",
      "Batch 415/700: Discriminator loss = 1.1675937175750732, GAN loss = [3.2357457, 0.9442833, 1.3602594]\n",
      "Batch 416/700: Discriminator loss = 1.19090735912323, GAN loss = [3.226465, 0.965974, 1.32935]\n",
      "Batch 417/700: Discriminator loss = 1.1661361455917358, GAN loss = [3.2976398, 0.94599444, 1.420567]\n",
      "Batch 418/700: Discriminator loss = 1.172016978263855, GAN loss = [3.2915297, 0.9502582, 1.41026]\n",
      "Batch 419/700: Discriminator loss = 1.1592170000076294, GAN loss = [3.41326, 0.9899385, 1.4923824]\n",
      "Batch 420/700: Discriminator loss = 1.1483248472213745, GAN loss = [3.521265, 1.0231037, 1.5672967]\n",
      "Batch 421/700: Discriminator loss = 1.1191291809082031, GAN loss = [3.5697107, 1.0585737, 1.5803486]\n",
      "Batch 422/700: Discriminator loss = 1.1185517311096191, GAN loss = [3.5287235, 1.07105, 1.5269637]\n",
      "Batch 423/700: Discriminator loss = 1.1175904273986816, GAN loss = [3.5944636, 1.0969516, 1.5668842]\n",
      "Batch 424/700: Discriminator loss = 1.1658767461776733, GAN loss = [3.4774585, 1.1111208, 1.4357889]\n",
      "Batch 425/700: Discriminator loss = 1.1389968395233154, GAN loss = [3.5022614, 1.0952173, 1.4765744]\n",
      "Batch 426/700: Discriminator loss = 1.1845037937164307, GAN loss = [3.4689195, 1.0969527, 1.441574]\n",
      "Batch 427/700: Discriminator loss = 1.2115230560302734, GAN loss = [3.3717892, 1.0983325, 1.3431389]\n",
      "Batch 428/700: Discriminator loss = 1.2408839464187622, GAN loss = [3.2591488, 1.0449365, 1.2839738]\n",
      "Batch 429/700: Discriminator loss = 1.294145107269287, GAN loss = [3.2022986, 0.9832496, 1.2888823]\n",
      "Batch 430/700: Discriminator loss = 1.3681846857070923, GAN loss = [3.09812, 0.93549067, 1.2325206]\n",
      "Batch 431/700: Discriminator loss = 1.4176362752914429, GAN loss = [2.9568288, 0.90157473, 1.1251884]\n",
      "Batch 432/700: Discriminator loss = 1.4006887674331665, GAN loss = [2.974686, 0.91272235, 1.1319282]\n",
      "Batch 433/700: Discriminator loss = 1.3706376552581787, GAN loss = [2.9897883, 0.9395601, 1.1202228]\n",
      "Batch 434/700: Discriminator loss = 1.3075048923492432, GAN loss = [2.980647, 0.9628643, 1.0878147]\n",
      "Batch 435/700: Discriminator loss = 1.2894991636276245, GAN loss = [3.0497227, 1.005924, 1.1138823]\n",
      "Batch 436/700: Discriminator loss = 1.2542916536331177, GAN loss = [3.054189, 1.012603, 1.1117313]\n",
      "Batch 437/700: Discriminator loss = 1.256854772567749, GAN loss = [3.0177872, 1.0254757, 1.0625179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 438/700: Discriminator loss = 1.2658106088638306, GAN loss = [2.9594479, 1.0201993, 1.009513]\n",
      "Batch 439/700: Discriminator loss = 1.2897084951400757, GAN loss = [2.9285555, 1.0260272, 0.97285056]\n",
      "Batch 440/700: Discriminator loss = 1.30370032787323, GAN loss = [2.9102554, 1.0224175, 0.9582195]\n",
      "Batch 441/700: Discriminator loss = 1.3287432193756104, GAN loss = [2.846936, 1.0313547, 0.8860263]\n",
      "Batch 442/700: Discriminator loss = 1.3116557598114014, GAN loss = [2.873123, 1.0557824, 0.8878569]\n",
      "Batch 443/700: Discriminator loss = 1.3211058378219604, GAN loss = [2.7821436, 1.046327, 0.8064079]\n",
      "Batch 444/700: Discriminator loss = 1.333493709564209, GAN loss = [2.7474115, 1.0748619, 0.7432134]\n",
      "Batch 445/700: Discriminator loss = 1.3069708347320557, GAN loss = [2.6974182, 1.0446699, 0.7234807]\n",
      "Batch 446/700: Discriminator loss = 1.320109248161316, GAN loss = [2.6352177, 0.97556734, 0.73044705]\n",
      "Batch 447/700: Discriminator loss = 1.3979158401489258, GAN loss = [2.593434, 0.9434743, 0.7208164]\n",
      "Batch 448/700: Discriminator loss = 1.349810004234314, GAN loss = [2.5607016, 0.88529295, 0.74631953]\n",
      "Batch 449/700: Discriminator loss = 1.3985047340393066, GAN loss = [2.497251, 0.8639422, 0.7042743]\n",
      "Batch 450/700: Discriminator loss = 1.365681767463684, GAN loss = [2.4944491, 0.85847175, 0.7069992]\n",
      "Batch 451/700: Discriminator loss = 1.3477829694747925, GAN loss = [2.5413144, 0.8742248, 0.73817015]\n",
      "Batch 452/700: Discriminator loss = 1.3126935958862305, GAN loss = [2.5310433, 0.88206947, 0.7201172]\n",
      "Batch 453/700: Discriminator loss = 1.28900146484375, GAN loss = [2.5710971, 0.91336447, 0.7289418]\n",
      "Batch 454/700: Discriminator loss = 1.2559722661972046, GAN loss = [2.573095, 0.92387944, 0.72049224]\n",
      "Batch 455/700: Discriminator loss = 1.2495073080062866, GAN loss = [2.6143997, 0.95471853, 0.7310266]\n",
      "Batch 456/700: Discriminator loss = 1.2435303926467896, GAN loss = [2.6460063, 0.9609023, 0.7565212]\n",
      "Batch 457/700: Discriminator loss = 1.229019045829773, GAN loss = [2.6395037, 0.95757943, 0.75341517]\n",
      "Batch 458/700: Discriminator loss = 1.230547547340393, GAN loss = [2.6657736, 0.96771896, 0.7696217]\n",
      "Batch 459/700: Discriminator loss = 1.2271754741668701, GAN loss = [2.68716, 0.9852446, 0.7735607]\n",
      "Batch 460/700: Discriminator loss = 1.2185280323028564, GAN loss = [2.6478004, 0.9635634, 0.75596213]\n",
      "Batch 461/700: Discriminator loss = 1.2175108194351196, GAN loss = [2.6828177, 0.95949036, 0.7951316]\n",
      "Batch 462/700: Discriminator loss = 1.2153359651565552, GAN loss = [2.680097, 0.9594351, 0.7925428]\n",
      "Batch 463/700: Discriminator loss = 1.2028261423110962, GAN loss = [2.7593937, 0.9982957, 0.83305556]\n",
      "Batch 464/700: Discriminator loss = 1.1735237836837769, GAN loss = [2.7514658, 0.9968366, 0.8266657]\n",
      "Batch 465/700: Discriminator loss = 1.1972547769546509, GAN loss = [2.7814906, 1.0287737, 0.8248318]\n",
      "Batch 466/700: Discriminator loss = 1.1743614673614502, GAN loss = [2.8081295, 1.0032876, 0.87703514]\n",
      "Batch 467/700: Discriminator loss = 1.211001992225647, GAN loss = [2.7583385, 1.0000428, 0.8305643]\n",
      "Batch 468/700: Discriminator loss = 1.1828484535217285, GAN loss = [2.7779257, 0.98274755, 0.8675227]\n",
      "Batch 469/700: Discriminator loss = 1.221101999282837, GAN loss = [2.736291, 0.9754883, 0.8332207]\n",
      "Batch 470/700: Discriminator loss = 1.214991569519043, GAN loss = [2.6922584, 0.9485328, 0.81621504]\n",
      "Batch 471/700: Discriminator loss = 1.2152068614959717, GAN loss = [2.704869, 0.920845, 0.8565807]\n",
      "Batch 472/700: Discriminator loss = 1.217125654220581, GAN loss = [2.6937962, 0.91573167, 0.85068893]\n",
      "Batch 473/700: Discriminator loss = 1.1911487579345703, GAN loss = [2.732815, 0.89922404, 0.90628314]\n",
      "Batch 474/700: Discriminator loss = 1.2198902368545532, GAN loss = [2.7753696, 0.95080644, 0.8973244]\n",
      "Batch 475/700: Discriminator loss = 1.1483290195465088, GAN loss = [2.837725, 0.93707675, 0.9734837]\n",
      "Batch 476/700: Discriminator loss = 1.167773962020874, GAN loss = [2.8664749, 0.9770518, 0.9623355]\n",
      "Batch 477/700: Discriminator loss = 1.1182303428649902, GAN loss = [2.9528964, 0.9811687, 1.0447234]\n",
      "Batch 478/700: Discriminator loss = 1.1389516592025757, GAN loss = [2.9831734, 1.0437703, 1.0124894]\n",
      "Batch 479/700: Discriminator loss = 1.0828794240951538, GAN loss = [3.0997474, 1.0473901, 1.1255418]\n",
      "Batch 480/700: Discriminator loss = 1.1022870540618896, GAN loss = [3.1253057, 1.1130787, 1.0855136]\n",
      "Batch 481/700: Discriminator loss = 1.0746066570281982, GAN loss = [3.1914148, 1.130406, 1.1344005]\n",
      "Batch 482/700: Discriminator loss = 1.1063121557235718, GAN loss = [3.1795733, 1.1624745, 1.0905975]\n",
      "Batch 483/700: Discriminator loss = 1.0685575008392334, GAN loss = [3.1612659, 1.110589, 1.1242815]\n",
      "Batch 484/700: Discriminator loss = 1.1189427375793457, GAN loss = [3.2194192, 1.1614275, 1.1316999]\n",
      "Batch 485/700: Discriminator loss = 1.1084667444229126, GAN loss = [3.1654038, 1.1011658, 1.1380472]\n",
      "Batch 486/700: Discriminator loss = 1.1513142585754395, GAN loss = [3.1260328, 1.0853156, 1.1146218]\n",
      "Batch 487/700: Discriminator loss = 1.1556627750396729, GAN loss = [3.0758138, 1.0271202, 1.1226875]\n",
      "Batch 488/700: Discriminator loss = 1.219987154006958, GAN loss = [2.9922853, 1.0074848, 1.0588719]\n",
      "Batch 489/700: Discriminator loss = 1.1913232803344727, GAN loss = [2.9317875, 0.93727684, 1.0686527]\n",
      "Batch 490/700: Discriminator loss = 1.2198760509490967, GAN loss = [3.033922, 0.9491778, 1.1589514]\n",
      "Batch 491/700: Discriminator loss = 1.1639665365219116, GAN loss = [3.1385007, 0.931808, 1.2809628]\n",
      "Batch 492/700: Discriminator loss = 1.1674623489379883, GAN loss = [3.1930006, 0.98095095, 1.2863863]\n",
      "Batch 493/700: Discriminator loss = 1.1080856323242188, GAN loss = [3.2313762, 0.99196374, 1.3138206]\n",
      "Batch 494/700: Discriminator loss = 1.1102004051208496, GAN loss = [3.321063, 1.0218077, 1.373739]\n",
      "Batch 495/700: Discriminator loss = 1.090930461883545, GAN loss = [3.3903909, 1.0516295, 1.4133251]\n",
      "Batch 496/700: Discriminator loss = 1.0789343118667603, GAN loss = [3.478996, 1.0654495, 1.4881979]\n",
      "Batch 497/700: Discriminator loss = 1.107692837715149, GAN loss = [3.4893675, 1.103577, 1.4605331]\n",
      "Batch 498/700: Discriminator loss = 1.0950710773468018, GAN loss = [3.5476696, 1.0967425, 1.5257648]\n",
      "Batch 499/700: Discriminator loss = 1.123531460762024, GAN loss = [3.445285, 1.1047688, 1.4154527]\n",
      "Batch 500/700: Discriminator loss = 1.1265642642974854, GAN loss = [3.41933, 1.0882115, 1.4061522]\n",
      "Batch 501/700: Discriminator loss = 1.1383949518203735, GAN loss = [3.3520644, 1.0744108, 1.352778]\n",
      "Batch 502/700: Discriminator loss = 1.1308647394180298, GAN loss = [3.3347535, 1.0493065, 1.3606508]\n",
      "Batch 503/700: Discriminator loss = 1.1604382991790771, GAN loss = [3.2819543, 1.0415766, 1.3156524]\n",
      "Batch 504/700: Discriminator loss = 1.1646430492401123, GAN loss = [3.2673695, 1.039004, 1.3037105]\n",
      "Batch 505/700: Discriminator loss = 1.1594281196594238, GAN loss = [3.369025, 1.0324308, 1.4120102]\n",
      "Batch 506/700: Discriminator loss = 1.2159372568130493, GAN loss = [3.1949449, 1.0252677, 1.2451619]\n",
      "Batch 507/700: Discriminator loss = 1.2244408130645752, GAN loss = [3.1446905, 1.0093684, 1.2108723]\n",
      "Batch 508/700: Discriminator loss = 1.2308510541915894, GAN loss = [3.0411158, 1.0120713, 1.1046565]\n",
      "Batch 509/700: Discriminator loss = 1.238802194595337, GAN loss = [3.1324081, 1.0503882, 1.1576921]\n",
      "Batch 510/700: Discriminator loss = 1.2383753061294556, GAN loss = [2.9680262, 1.0158597, 1.0278988]\n",
      "Batch 511/700: Discriminator loss = 1.3199156522750854, GAN loss = [2.8984735, 1.0142843, 0.9599775]\n",
      "Batch 512/700: Discriminator loss = 1.2802331447601318, GAN loss = [2.8708255, 0.96481985, 0.9818434]\n",
      "Batch 513/700: Discriminator loss = 1.29905366897583, GAN loss = [2.8378048, 0.9728729, 0.940813]\n",
      "Batch 514/700: Discriminator loss = 1.269039511680603, GAN loss = [2.7636974, 0.9253358, 0.9142827]\n",
      "Batch 515/700: Discriminator loss = 1.3636966943740845, GAN loss = [2.7542636, 0.97690374, 0.85331815]\n",
      "Batch 516/700: Discriminator loss = 1.266809105873108, GAN loss = [2.7571476, 0.9243471, 0.9087956]\n",
      "Batch 517/700: Discriminator loss = 1.3236873149871826, GAN loss = [2.7451892, 0.9479267, 0.8732952]\n",
      "Batch 518/700: Discriminator loss = 1.2484050989151, GAN loss = [2.7779944, 0.94073194, 0.9133387]\n",
      "Batch 519/700: Discriminator loss = 1.2676141262054443, GAN loss = [2.801836, 0.9870433, 0.8909177]\n",
      "Batch 520/700: Discriminator loss = 1.2129364013671875, GAN loss = [2.8201718, 0.9838728, 0.912481]\n",
      "Batch 521/700: Discriminator loss = 1.222776174545288, GAN loss = [2.868846, 1.0282327, 0.9168601]\n",
      "Batch 522/700: Discriminator loss = 1.2051080465316772, GAN loss = [2.914221, 1.0339704, 0.9565666]\n",
      "Batch 523/700: Discriminator loss = 1.2070398330688477, GAN loss = [2.9309866, 1.067569, 0.93980527]\n",
      "Batch 524/700: Discriminator loss = 1.1585861444473267, GAN loss = [3.0149603, 1.0644851, 1.0269395]\n",
      "Batch 525/700: Discriminator loss = 1.2109127044677734, GAN loss = [2.9283524, 1.0809906, 0.9239031]\n",
      "Batch 526/700: Discriminator loss = 1.2066420316696167, GAN loss = [2.9461408, 1.0582123, 0.96454436]\n",
      "Batch 527/700: Discriminator loss = 1.2263052463531494, GAN loss = [2.936737, 1.0306461, 0.98277617]\n",
      "Batch 528/700: Discriminator loss = 1.2331726551055908, GAN loss = [2.9053113, 1.0192608, 0.96280324]\n",
      "Batch 529/700: Discriminator loss = 1.245598316192627, GAN loss = [2.9456372, 1.0549282, 0.9675271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 530/700: Discriminator loss = 1.2191262245178223, GAN loss = [2.9516404, 1.0614104, 0.9671138]\n",
      "Batch 531/700: Discriminator loss = 1.2077131271362305, GAN loss = [2.935962, 1.0956208, 0.9172918]\n",
      "Batch 532/700: Discriminator loss = 1.1878925561904907, GAN loss = [2.998217, 1.0951474, 0.98009056]\n",
      "Batch 533/700: Discriminator loss = 1.2063989639282227, GAN loss = [2.9513352, 1.1002594, 0.9281655]\n",
      "Batch 534/700: Discriminator loss = 1.204972743988037, GAN loss = [2.9680915, 1.0928984, 0.9523463]\n",
      "Batch 535/700: Discriminator loss = 1.1921772956848145, GAN loss = [2.9893062, 1.0724684, 0.9940488]\n",
      "Batch 536/700: Discriminator loss = 1.18450927734375, GAN loss = [2.9797375, 1.0498232, 1.0071837]\n",
      "Batch 537/700: Discriminator loss = 1.1846450567245483, GAN loss = [3.0010915, 1.0395474, 1.0388725]\n",
      "Batch 538/700: Discriminator loss = 1.1729555130004883, GAN loss = [3.0121903, 1.0279158, 1.0616621]\n",
      "Batch 539/700: Discriminator loss = 1.171004056930542, GAN loss = [3.0312464, 1.0332378, 1.075454]\n",
      "Batch 540/700: Discriminator loss = 1.1607762575149536, GAN loss = [3.0677168, 1.0406308, 1.1045893]\n",
      "Batch 541/700: Discriminator loss = 1.158871054649353, GAN loss = [3.1590657, 1.042491, 1.1941386]\n",
      "Batch 542/700: Discriminator loss = 1.1517876386642456, GAN loss = [3.142111, 1.0377059, 1.1820312]\n",
      "Batch 543/700: Discriminator loss = 1.1203068494796753, GAN loss = [3.2387807, 1.0293, 1.2871737]\n",
      "Batch 544/700: Discriminator loss = 1.1254242658615112, GAN loss = [3.2684398, 1.0612824, 1.2849228]\n",
      "Batch 545/700: Discriminator loss = 1.1113178730010986, GAN loss = [3.3670075, 1.094403, 1.3504441]\n",
      "Batch 546/700: Discriminator loss = 1.095160961151123, GAN loss = [3.3490756, 1.108676, 1.3183141]\n",
      "Batch 547/700: Discriminator loss = 1.1095033884048462, GAN loss = [3.2791197, 1.1264812, 1.2306267]\n",
      "Batch 548/700: Discriminator loss = 1.0957186222076416, GAN loss = [3.2622557, 1.1331302, 1.2071863]\n",
      "Batch 549/700: Discriminator loss = 1.1130577325820923, GAN loss = [3.3002264, 1.1638534, 1.2145029]\n",
      "Batch 550/700: Discriminator loss = 1.1006436347961426, GAN loss = [3.2469857, 1.1565822, 1.1685997]\n",
      "Batch 551/700: Discriminator loss = 1.1240248680114746, GAN loss = [3.215401, 1.1744958, 1.1191651]\n",
      "Batch 552/700: Discriminator loss = 1.095062255859375, GAN loss = [3.2232754, 1.13139, 1.1702044]\n",
      "Batch 553/700: Discriminator loss = 1.165144920349121, GAN loss = [3.243873, 1.2173071, 1.1049418]\n",
      "Batch 554/700: Discriminator loss = 1.0776883363723755, GAN loss = [3.3137507, 1.1604222, 1.2317644]\n",
      "Batch 555/700: Discriminator loss = 1.145632266998291, GAN loss = [3.2688897, 1.2017021, 1.1456842]\n",
      "Batch 556/700: Discriminator loss = 1.079092264175415, GAN loss = [3.3845837, 1.1864548, 1.2766907]\n",
      "Batch 557/700: Discriminator loss = 1.0873419046401978, GAN loss = [3.3432472, 1.1848886, 1.2369912]\n",
      "Batch 558/700: Discriminator loss = 1.0920112133026123, GAN loss = [3.411475, 1.1869212, 1.3032608]\n",
      "Batch 559/700: Discriminator loss = 1.1128798723220825, GAN loss = [3.392469, 1.1648222, 1.3064287]\n",
      "Batch 560/700: Discriminator loss = 1.1156766414642334, GAN loss = [3.3965254, 1.146189, 1.3291924]\n",
      "Batch 561/700: Discriminator loss = 1.1322540044784546, GAN loss = [3.3585048, 1.1440979, 1.2933359]\n",
      "Batch 562/700: Discriminator loss = 1.173572301864624, GAN loss = [3.2744806, 1.1591741, 1.1943127]\n",
      "Batch 563/700: Discriminator loss = 1.1460540294647217, GAN loss = [3.3206735, 1.1163535, 1.2834071]\n",
      "Batch 564/700: Discriminator loss = 1.1850301027297974, GAN loss = [3.2826583, 1.1122383, 1.2495788]\n",
      "Batch 565/700: Discriminator loss = 1.1567456722259521, GAN loss = [3.363219, 1.0754775, 1.3669592]\n",
      "Batch 566/700: Discriminator loss = 1.170566439628601, GAN loss = [3.437233, 1.1058574, 1.4106424]\n",
      "Batch 567/700: Discriminator loss = 1.13826322555542, GAN loss = [3.4808989, 1.1190072, 1.4412057]\n",
      "Batch 568/700: Discriminator loss = 1.1497341394424438, GAN loss = [3.471496, 1.1192224, 1.4316399]\n",
      "Batch 569/700: Discriminator loss = 1.1538548469543457, GAN loss = [3.5896614, 1.1059893, 1.5630902]\n",
      "Batch 570/700: Discriminator loss = 1.1451332569122314, GAN loss = [3.7365665, 1.0760761, 1.7399594]\n",
      "Batch 571/700: Discriminator loss = 1.187069296836853, GAN loss = [3.5947707, 1.0878116, 1.5864748]\n",
      "Batch 572/700: Discriminator loss = 1.1471437215805054, GAN loss = [3.771024, 1.1045377, 1.7460452]\n",
      "Batch 573/700: Discriminator loss = 1.142806053161621, GAN loss = [3.7819164, 1.1040082, 1.7575135]\n",
      "Batch 574/700: Discriminator loss = 1.1430002450942993, GAN loss = [4.0707507, 1.1090299, 2.0413673]\n",
      "Batch 575/700: Discriminator loss = 1.1372710466384888, GAN loss = [3.9173148, 1.0832226, 1.913778]\n",
      "Batch 576/700: Discriminator loss = 1.1031731367111206, GAN loss = [4.2272396, 1.1146626, 2.1923063]\n",
      "Batch 577/700: Discriminator loss = 1.1449376344680786, GAN loss = [4.0525527, 1.1072521, 2.0250769]\n",
      "Batch 578/700: Discriminator loss = 1.1154972314834595, GAN loss = [4.182669, 1.0974703, 2.165018]\n",
      "Batch 579/700: Discriminator loss = 1.1990017890930176, GAN loss = [3.9389558, 1.0937244, 1.9250896]\n",
      "Batch 580/700: Discriminator loss = 1.2367547750473022, GAN loss = [3.8505173, 1.1072427, 1.8231624]\n",
      "Batch 581/700: Discriminator loss = 1.2614067792892456, GAN loss = [3.5762143, 1.1115196, 1.5446128]\n",
      "Batch 582/700: Discriminator loss = 1.3785278797149658, GAN loss = [3.4205866, 1.1424698, 1.3580709]\n",
      "Batch 583/700: Discriminator loss = 1.457090973854065, GAN loss = [3.0919292, 1.1978807, 0.974036]\n",
      "Batch 584/700: Discriminator loss = 1.4549812078475952, GAN loss = [2.9195156, 1.2124071, 0.78712624]\n",
      "Batch 585/700: Discriminator loss = 1.524221658706665, GAN loss = [2.7242548, 1.2013758, 0.6029219]\n",
      "Batch 586/700: Discriminator loss = 1.4530839920043945, GAN loss = [2.6379247, 1.1444716, 0.57351285]\n",
      "Batch 587/700: Discriminator loss = 1.4751428365707397, GAN loss = [2.605969, 1.1560458, 0.5299928]\n",
      "Batch 588/700: Discriminator loss = 1.3440301418304443, GAN loss = [2.597144, 1.1307088, 0.5465145]\n",
      "Batch 589/700: Discriminator loss = 1.275952696800232, GAN loss = [2.6251488, 1.1379464, 0.5672996]\n",
      "Batch 590/700: Discriminator loss = 1.1944957971572876, GAN loss = [2.6712997, 1.1243659, 0.62706155]\n",
      "Batch 591/700: Discriminator loss = 1.194846510887146, GAN loss = [2.7311919, 1.1260968, 0.68526095]\n",
      "Batch 592/700: Discriminator loss = 1.1790974140167236, GAN loss = [2.7905314, 1.1328804, 0.73785555]\n",
      "Batch 593/700: Discriminator loss = 1.143208384513855, GAN loss = [2.8491745, 1.0957801, 0.83363885]\n",
      "Batch 594/700: Discriminator loss = 1.1397833824157715, GAN loss = [3.0020123, 1.1057245, 0.9765701]\n",
      "Batch 595/700: Discriminator loss = 1.1100586652755737, GAN loss = [3.144326, 1.1185073, 1.1061438]\n",
      "Batch 596/700: Discriminator loss = 1.086754560470581, GAN loss = [3.2035177, 1.1243135, 1.1595829]\n",
      "Batch 597/700: Discriminator loss = 1.1228190660476685, GAN loss = [3.2103994, 1.1076711, 1.1831745]\n",
      "Batch 598/700: Discriminator loss = 1.1581319570541382, GAN loss = [3.2399309, 1.0621068, 1.2583475]\n",
      "Batch 599/700: Discriminator loss = 1.2234809398651123, GAN loss = [3.0902085, 1.0149941, 1.1558205]\n",
      "Batch 600/700: Discriminator loss = 1.2926061153411865, GAN loss = [2.9926665, 0.9903843, 1.0829686]\n",
      "Batch 601/700: Discriminator loss = 1.3246830701828003, GAN loss = [2.8856153, 0.96150696, 1.0048718]\n",
      "Batch 602/700: Discriminator loss = 1.326233148574829, GAN loss = [2.9027896, 0.9741877, 1.0094396]\n",
      "Batch 603/700: Discriminator loss = 1.3155230283737183, GAN loss = [2.8265212, 0.9787857, 0.92864686]\n",
      "Batch 604/700: Discriminator loss = 1.2996824979782104, GAN loss = [2.7675362, 0.9468692, 0.9016549]\n",
      "Batch 605/700: Discriminator loss = 1.2933192253112793, GAN loss = [2.7213066, 0.9323079, 0.87006384]\n",
      "Batch 606/700: Discriminator loss = 1.2910157442092896, GAN loss = [2.7719483, 0.9420676, 0.91102237]\n",
      "Batch 607/700: Discriminator loss = 1.3109982013702393, GAN loss = [2.6849544, 0.9356338, 0.83053803]\n",
      "Batch 608/700: Discriminator loss = 1.257524013519287, GAN loss = [2.7536101, 0.95212936, 0.8827713]\n",
      "Batch 609/700: Discriminator loss = 1.2364227771759033, GAN loss = [2.8057764, 0.981218, 0.9059212]\n",
      "Batch 610/700: Discriminator loss = 1.2380986213684082, GAN loss = [2.7799866, 1.0153229, 0.84610254]\n",
      "Batch 611/700: Discriminator loss = 1.2110271453857422, GAN loss = [2.8825982, 1.0453674, 0.91874754]\n",
      "Batch 612/700: Discriminator loss = 1.19182550907135, GAN loss = [2.8938048, 1.0790111, 0.8963928]\n",
      "Batch 613/700: Discriminator loss = 1.1668089628219604, GAN loss = [2.952066, 1.1107451, 0.92301106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 614/700: Discriminator loss = 1.184000849723816, GAN loss = [2.8873582, 1.1126542, 0.85649496]\n",
      "Batch 615/700: Discriminator loss = 1.1850835084915161, GAN loss = [2.9884264, 1.1199641, 0.95035505]\n",
      "Batch 616/700: Discriminator loss = 1.218543291091919, GAN loss = [2.8878324, 1.082541, 0.88728744]\n",
      "Batch 617/700: Discriminator loss = 1.2460205554962158, GAN loss = [2.8506465, 1.0523603, 0.88037413]\n",
      "Batch 618/700: Discriminator loss = 1.2714875936508179, GAN loss = [2.8081226, 1.0208008, 0.8694927]\n",
      "Batch 619/700: Discriminator loss = 1.2812411785125732, GAN loss = [2.7537155, 0.9769252, 0.8590338]\n",
      "Batch 620/700: Discriminator loss = 1.2636044025421143, GAN loss = [2.7382398, 0.93957937, 0.8809669]\n",
      "Batch 621/700: Discriminator loss = 1.2455699443817139, GAN loss = [2.766352, 0.95733035, 0.8913876]\n",
      "Batch 622/700: Discriminator loss = 1.206552505493164, GAN loss = [2.803984, 0.98511285, 0.9012976]\n",
      "Batch 623/700: Discriminator loss = 1.2157033681869507, GAN loss = [2.851767, 1.0242417, 0.9100111]\n",
      "Batch 624/700: Discriminator loss = 1.1749628782272339, GAN loss = [2.9014993, 1.0436429, 0.9404024]\n",
      "Batch 625/700: Discriminator loss = 1.1750811338424683, GAN loss = [2.9090405, 1.0730937, 0.9185536]\n",
      "Batch 626/700: Discriminator loss = 1.163069486618042, GAN loss = [2.9232976, 1.0886836, 0.9172833]\n",
      "Batch 627/700: Discriminator loss = 1.1736921072006226, GAN loss = [2.9354975, 1.1085778, 0.9096511]\n",
      "Batch 628/700: Discriminator loss = 1.152530312538147, GAN loss = [2.9486375, 1.1013116, 0.9301189]\n",
      "Batch 629/700: Discriminator loss = 1.1892586946487427, GAN loss = [2.9310913, 1.120347, 0.89359576]\n",
      "Batch 630/700: Discriminator loss = 1.1831318140029907, GAN loss = [2.9025629, 1.0984101, 0.88705415]\n",
      "Batch 631/700: Discriminator loss = 1.2246073484420776, GAN loss = [2.888512, 1.0959855, 0.8754682]\n",
      "Batch 632/700: Discriminator loss = 1.248779296875, GAN loss = [2.8338206, 1.0752906, 0.8415043]\n",
      "Batch 633/700: Discriminator loss = 1.2154570817947388, GAN loss = [2.8058345, 1.0356491, 0.8531854]\n",
      "Batch 634/700: Discriminator loss = 1.2369681596755981, GAN loss = [2.745254, 1.0391785, 0.7890998]\n",
      "Batch 635/700: Discriminator loss = 1.2169138193130493, GAN loss = [2.793154, 1.0503764, 0.82583094]\n",
      "Batch 636/700: Discriminator loss = 1.2270772457122803, GAN loss = [2.7682977, 1.0351591, 0.8162267]\n",
      "Batch 637/700: Discriminator loss = 1.2060052156448364, GAN loss = [2.7742631, 1.0303705, 0.8270255]\n",
      "Batch 638/700: Discriminator loss = 1.1882238388061523, GAN loss = [2.7813506, 1.0142467, 0.85029036]\n",
      "Batch 639/700: Discriminator loss = 1.2187094688415527, GAN loss = [2.8230186, 1.0349998, 0.87126124]\n",
      "Batch 640/700: Discriminator loss = 1.2011375427246094, GAN loss = [2.8431952, 1.0280676, 0.8984263]\n",
      "Batch 641/700: Discriminator loss = 1.187826156616211, GAN loss = [2.840454, 1.0134166, 0.91039395]\n",
      "Batch 642/700: Discriminator loss = 1.1950322389602661, GAN loss = [2.852456, 1.0188401, 0.91702867]\n",
      "Batch 643/700: Discriminator loss = 1.1737631559371948, GAN loss = [2.850962, 1.0108051, 0.92362404]\n",
      "Batch 644/700: Discriminator loss = 1.1647005081176758, GAN loss = [2.8533022, 1.0048378, 0.93198615]\n",
      "Batch 645/700: Discriminator loss = 1.1691125631332397, GAN loss = [2.9279737, 1.0154791, 0.99606925]\n",
      "Batch 646/700: Discriminator loss = 1.1732817888259888, GAN loss = [2.8921068, 1.0108616, 0.96487164]\n",
      "Batch 647/700: Discriminator loss = 1.16420316696167, GAN loss = [2.9854026, 1.0124431, 1.0566391]\n",
      "Batch 648/700: Discriminator loss = 1.1672899723052979, GAN loss = [2.9588046, 0.9994733, 1.0430655]\n",
      "Batch 649/700: Discriminator loss = 1.1550332307815552, GAN loss = [2.9846187, 0.9821532, 1.0862556]\n",
      "Batch 650/700: Discriminator loss = 1.1808245182037354, GAN loss = [2.930496, 0.985532, 1.0288138]\n",
      "Batch 651/700: Discriminator loss = 1.1757925748825073, GAN loss = [2.9099634, 0.98514557, 1.0087322]\n",
      "Batch 652/700: Discriminator loss = 1.185977578163147, GAN loss = [2.946302, 0.9837466, 1.0465378]\n",
      "Batch 653/700: Discriminator loss = 1.2006107568740845, GAN loss = [2.977269, 0.98561937, 1.075701]\n",
      "Batch 654/700: Discriminator loss = 1.2208170890808105, GAN loss = [2.9687374, 0.973848, 1.0790095]\n",
      "Batch 655/700: Discriminator loss = 1.2345446348190308, GAN loss = [2.9115136, 0.9782233, 1.0174732]\n",
      "Batch 656/700: Discriminator loss = 1.1961642503738403, GAN loss = [2.9327688, 0.97938347, 1.0376287]\n",
      "Batch 657/700: Discriminator loss = 1.2400394678115845, GAN loss = [2.88689, 0.96809125, 1.0030984]\n",
      "Batch 658/700: Discriminator loss = 1.2322558164596558, GAN loss = [2.9070463, 0.9963606, 0.99503523]\n",
      "Batch 659/700: Discriminator loss = 1.2694147825241089, GAN loss = [2.8371058, 0.9844505, 0.93705213]\n",
      "Batch 660/700: Discriminator loss = 1.2582281827926636, GAN loss = [2.79229, 0.9894082, 0.88732046]\n",
      "Batch 661/700: Discriminator loss = 1.2514309883117676, GAN loss = [2.8001099, 0.9984229, 0.8861653]\n",
      "Batch 662/700: Discriminator loss = 1.247653603553772, GAN loss = [2.8096676, 1.0262848, 0.8678982]\n",
      "Batch 663/700: Discriminator loss = 1.25215482711792, GAN loss = [2.7867646, 1.0062462, 0.8650685]\n",
      "Batch 664/700: Discriminator loss = 1.2429002523422241, GAN loss = [2.7898295, 0.9821203, 0.8922898]\n",
      "Batch 665/700: Discriminator loss = 1.2641288042068481, GAN loss = [2.802588, 0.987491, 0.8997047]\n",
      "Batch 666/700: Discriminator loss = 1.2537177801132202, GAN loss = [2.7275784, 0.9810711, 0.83113694]\n",
      "Batch 667/700: Discriminator loss = 1.248927116394043, GAN loss = [2.8333797, 1.0343218, 0.88370514]\n",
      "Batch 668/700: Discriminator loss = 1.2747374773025513, GAN loss = [2.7312233, 0.9682321, 0.8476595]\n",
      "Batch 669/700: Discriminator loss = 1.273713231086731, GAN loss = [2.7638233, 0.96135527, 0.8871545]\n",
      "Batch 670/700: Discriminator loss = 1.3085664510726929, GAN loss = [2.7506125, 0.91130555, 0.9240112]\n",
      "Batch 671/700: Discriminator loss = 1.3562853336334229, GAN loss = [2.6819885, 0.8814414, 0.88526446]\n",
      "Batch 672/700: Discriminator loss = 1.3631137609481812, GAN loss = [2.6338918, 0.8542105, 0.8644057]\n",
      "Batch 673/700: Discriminator loss = 1.4200692176818848, GAN loss = [2.603869, 0.8127366, 0.8758591]\n",
      "Batch 674/700: Discriminator loss = 1.4286614656448364, GAN loss = [2.5241392, 0.7597296, 0.84914]\n",
      "Batch 675/700: Discriminator loss = 1.412832260131836, GAN loss = [2.5176446, 0.76367843, 0.8387005]\n",
      "Batch 676/700: Discriminator loss = 1.4102299213409424, GAN loss = [2.5161855, 0.7573427, 0.84358764]\n",
      "Batch 677/700: Discriminator loss = 1.4001373052597046, GAN loss = [2.4939513, 0.75241005, 0.8262975]\n",
      "Batch 678/700: Discriminator loss = 1.4013888835906982, GAN loss = [2.5199475, 0.76900834, 0.83571345]\n",
      "Batch 679/700: Discriminator loss = 1.3537229299545288, GAN loss = [2.5085747, 0.77902037, 0.8143543]\n",
      "Batch 680/700: Discriminator loss = 1.3521387577056885, GAN loss = [2.5222387, 0.79084116, 0.81622565]\n",
      "Batch 681/700: Discriminator loss = 1.3088390827178955, GAN loss = [2.5498044, 0.8013276, 0.833337]\n",
      "Batch 682/700: Discriminator loss = 1.3017117977142334, GAN loss = [2.5530972, 0.8072588, 0.8307357]\n",
      "Batch 683/700: Discriminator loss = 1.2880065441131592, GAN loss = [2.5412977, 0.7996888, 0.8265431]\n",
      "Batch 684/700: Discriminator loss = 1.2914377450942993, GAN loss = [2.5758, 0.80133814, 0.85943377]\n",
      "Batch 685/700: Discriminator loss = 1.2891764640808105, GAN loss = [2.5683966, 0.7951216, 0.85828453]\n",
      "Batch 686/700: Discriminator loss = 1.2787460088729858, GAN loss = [2.5612025, 0.8082455, 0.83800566]\n",
      "Batch 687/700: Discriminator loss = 1.2955063581466675, GAN loss = [2.5409873, 0.79696465, 0.8291104]\n",
      "Batch 688/700: Discriminator loss = 1.2976124286651611, GAN loss = [2.5346355, 0.80602384, 0.81374186]\n",
      "Batch 689/700: Discriminator loss = 1.300646424293518, GAN loss = [2.5391638, 0.80393773, 0.82039857]\n",
      "Batch 690/700: Discriminator loss = 1.29924738407135, GAN loss = [2.5222464, 0.8100663, 0.79739606]\n",
      "Batch 691/700: Discriminator loss = 1.292411208152771, GAN loss = [2.5450714, 0.81138873, 0.81894356]\n",
      "Batch 692/700: Discriminator loss = 1.2915396690368652, GAN loss = [2.474706, 0.8075798, 0.7524302]\n",
      "Batch 693/700: Discriminator loss = 1.2948155403137207, GAN loss = [2.511337, 0.8169806, 0.7797042]\n",
      "Batch 694/700: Discriminator loss = 1.2779483795166016, GAN loss = [2.5370584, 0.8360865, 0.7863641]\n",
      "Batch 695/700: Discriminator loss = 1.258439064025879, GAN loss = [2.5476668, 0.8548933, 0.7782141]\n",
      "Batch 696/700: Discriminator loss = 1.2458018064498901, GAN loss = [2.5643778, 0.8594399, 0.79043055]\n",
      "Batch 697/700: Discriminator loss = 1.2363208532333374, GAN loss = [2.5938416, 0.8781869, 0.80120295]\n",
      "Batch 698/700: Discriminator loss = 1.2013403177261353, GAN loss = [2.619111, 0.9055096, 0.79920876]\n",
      "Batch 699/700: Discriminator loss = 1.231062412261963, GAN loss = [2.6135974, 0.8863739, 0.8128937]\n",
      "Batch 700/700: Discriminator loss = 1.221259593963623, GAN loss = [2.6288152, 0.8993808, 0.8151686]\n",
      "Epoch 2/30\n",
      "Batch 1/700: Discriminator loss = 1.2301867008209229, GAN loss = [2.5872478, 0.8846541, 0.7883916]\n",
      "Batch 2/700: Discriminator loss = 1.207528829574585, GAN loss = [2.630251, 0.8765128, 0.83959687]\n",
      "Batch 3/700: Discriminator loss = 1.2540438175201416, GAN loss = [2.5856466, 0.84928954, 0.8222752]\n",
      "Batch 4/700: Discriminator loss = 1.2168365716934204, GAN loss = [2.6168177, 0.8799601, 0.8228348]\n",
      "Batch 5/700: Discriminator loss = 1.2617641687393188, GAN loss = [2.565752, 0.85304207, 0.7987485]\n",
      "Batch 6/700: Discriminator loss = 1.281846284866333, GAN loss = [2.5733352, 0.863265, 0.79616874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7/700: Discriminator loss = 1.252238154411316, GAN loss = [2.5493655, 0.84123236, 0.794292]\n",
      "Batch 8/700: Discriminator loss = 1.2629709243774414, GAN loss = [2.5566835, 0.83027697, 0.8126259]\n",
      "Batch 9/700: Discriminator loss = 1.2653961181640625, GAN loss = [2.50289, 0.81366503, 0.7755058]\n",
      "Batch 10/700: Discriminator loss = 1.2786449193954468, GAN loss = [2.512969, 0.80456495, 0.7947474]\n",
      "Batch 11/700: Discriminator loss = 1.279970645904541, GAN loss = [2.5230277, 0.79842925, 0.8110046]\n",
      "Batch 12/700: Discriminator loss = 1.2861038446426392, GAN loss = [2.5185416, 0.81071883, 0.7942936]\n",
      "Batch 13/700: Discriminator loss = 1.2650959491729736, GAN loss = [2.538761, 0.8287869, 0.79650843]\n",
      "Batch 14/700: Discriminator loss = 1.2570770978927612, GAN loss = [2.551352, 0.83931196, 0.7986405]\n",
      "Batch 15/700: Discriminator loss = 1.240925908088684, GAN loss = [2.5579107, 0.85160285, 0.7929758]\n",
      "Batch 16/700: Discriminator loss = 1.2278815507888794, GAN loss = [2.593347, 0.87102044, 0.80906415]\n",
      "Batch 17/700: Discriminator loss = 1.2333033084869385, GAN loss = [2.6036537, 0.87162375, 0.81883925]\n",
      "Batch 18/700: Discriminator loss = 1.2148196697235107, GAN loss = [2.6064274, 0.8798214, 0.81348723]\n",
      "Batch 19/700: Discriminator loss = 1.2188977003097534, GAN loss = [2.585218, 0.8717174, 0.8004521]\n",
      "Batch 20/700: Discriminator loss = 1.2290879487991333, GAN loss = [2.5943332, 0.87518775, 0.80616295]\n",
      "Batch 21/700: Discriminator loss = 1.2135347127914429, GAN loss = [2.5992181, 0.87086165, 0.81543577]\n",
      "Batch 22/700: Discriminator loss = 1.2244269847869873, GAN loss = [2.5931726, 0.86923456, 0.81107926]\n",
      "Batch 23/700: Discriminator loss = 1.2187001705169678, GAN loss = [2.5831378, 0.86147547, 0.8088651]\n",
      "Batch 24/700: Discriminator loss = 1.2124098539352417, GAN loss = [2.615716, 0.8596854, 0.84329724]\n",
      "Batch 25/700: Discriminator loss = 1.2152882814407349, GAN loss = [2.6414297, 0.8680758, 0.86068594]\n",
      "Batch 26/700: Discriminator loss = 1.208659291267395, GAN loss = [2.6125102, 0.854805, 0.8451069]\n",
      "Batch 27/700: Discriminator loss = 1.1947084665298462, GAN loss = [2.6402884, 0.8668678, 0.86089593]\n",
      "Batch 28/700: Discriminator loss = 1.2003824710845947, GAN loss = [2.694852, 0.8889561, 0.8934484]\n",
      "Batch 29/700: Discriminator loss = 1.1867650747299194, GAN loss = [2.645935, 0.87434274, 0.8592248]\n",
      "Batch 30/700: Discriminator loss = 1.1962718963623047, GAN loss = [2.6780422, 0.8821791, 0.8835749]\n",
      "Batch 31/700: Discriminator loss = 1.1994298696517944, GAN loss = [2.6760314, 0.8866259, 0.87719506]\n",
      "Batch 32/700: Discriminator loss = 1.188840627670288, GAN loss = [2.6884568, 0.8861393, 0.89018327]\n",
      "Batch 33/700: Discriminator loss = 1.1891944408416748, GAN loss = [2.6560326, 0.86741996, 0.87655234]\n",
      "Batch 34/700: Discriminator loss = 1.1921825408935547, GAN loss = [2.6868927, 0.8762604, 0.8986448]\n",
      "Batch 35/700: Discriminator loss = 1.187893271446228, GAN loss = [2.679207, 0.88515735, 0.88213396]\n",
      "Batch 36/700: Discriminator loss = 1.1927614212036133, GAN loss = [2.6915443, 0.88920367, 0.8904969]\n",
      "Batch 37/700: Discriminator loss = 1.1868152618408203, GAN loss = [2.6914105, 0.88869417, 0.8909424]\n",
      "Batch 38/700: Discriminator loss = 1.1797951459884644, GAN loss = [2.6977534, 0.8949078, 0.8911402]\n",
      "Batch 39/700: Discriminator loss = 1.1711069345474243, GAN loss = [2.7312865, 0.90286356, 0.9167857]\n",
      "Batch 40/700: Discriminator loss = 1.1663572788238525, GAN loss = [2.7372646, 0.9204535, 0.9052414]\n",
      "Batch 41/700: Discriminator loss = 1.171478271484375, GAN loss = [2.721821, 0.93284667, 0.87747455]\n",
      "Batch 42/700: Discriminator loss = 1.1595042943954468, GAN loss = [2.7348921, 0.9365642, 0.8868988]\n",
      "Batch 43/700: Discriminator loss = 1.1616297960281372, GAN loss = [2.8019235, 0.94965523, 0.9409112]\n",
      "Batch 44/700: Discriminator loss = 1.1621917486190796, GAN loss = [2.7875025, 0.9537571, 0.9224613]\n",
      "Batch 45/700: Discriminator loss = 1.157366394996643, GAN loss = [2.7638342, 0.9420909, 0.91052985]\n",
      "Batch 46/700: Discriminator loss = 1.1597732305526733, GAN loss = [2.779078, 0.96069664, 0.9072378]\n",
      "Batch 47/700: Discriminator loss = 1.1768964529037476, GAN loss = [2.8075173, 0.9602387, 0.93620265]\n",
      "Batch 48/700: Discriminator loss = 1.1674232482910156, GAN loss = [2.7724247, 0.9448487, 0.91656405]\n",
      "Batch 49/700: Discriminator loss = 1.176064372062683, GAN loss = [2.7842472, 0.95618826, 0.9171118]\n",
      "Batch 50/700: Discriminator loss = 1.171491265296936, GAN loss = [2.7854779, 0.9632887, 0.9113066]\n",
      "Batch 51/700: Discriminator loss = 1.1604949235916138, GAN loss = [2.7622714, 0.95215106, 0.89930224]\n",
      "Batch 52/700: Discriminator loss = 1.162792444229126, GAN loss = [2.7857208, 0.9511934, 0.9237749]\n",
      "Batch 53/700: Discriminator loss = 1.1579877138137817, GAN loss = [2.7491772, 0.94191915, 0.8965729]\n",
      "Batch 54/700: Discriminator loss = 1.1459614038467407, GAN loss = [2.8119967, 0.95560485, 0.9457779]\n",
      "Batch 55/700: Discriminator loss = 1.1499627828598022, GAN loss = [2.8390129, 0.96426684, 0.96420515]\n",
      "Batch 56/700: Discriminator loss = 1.1501013040542603, GAN loss = [2.8070703, 0.95460474, 0.94199806]\n",
      "Batch 57/700: Discriminator loss = 1.1564159393310547, GAN loss = [2.8661115, 0.95108, 1.0046366]\n",
      "Batch 58/700: Discriminator loss = 1.161192774772644, GAN loss = [2.9217675, 0.9595059, 1.0519366]\n",
      "Batch 59/700: Discriminator loss = 1.1657915115356445, GAN loss = [2.9463522, 0.96608657, 1.0700088]\n",
      "Batch 60/700: Discriminator loss = 1.1727763414382935, GAN loss = [2.8940485, 0.9612181, 1.0226403]\n",
      "Batch 61/700: Discriminator loss = 1.145715594291687, GAN loss = [2.9294064, 0.96684194, 1.0524426]\n",
      "Batch 62/700: Discriminator loss = 1.141385555267334, GAN loss = [2.9443257, 0.9818063, 1.0524676]\n",
      "Batch 63/700: Discriminator loss = 1.1508862972259521, GAN loss = [2.9933405, 0.9859812, 1.0973798]\n",
      "Batch 64/700: Discriminator loss = 1.1512529850006104, GAN loss = [2.9427538, 0.9744785, 1.0583694]\n",
      "Batch 65/700: Discriminator loss = 1.1386098861694336, GAN loss = [3.0854971, 1.0149078, 1.1607537]\n",
      "Batch 66/700: Discriminator loss = 1.1390817165374756, GAN loss = [3.0040026, 1.019454, 1.0747821]\n",
      "Batch 67/700: Discriminator loss = 1.151037573814392, GAN loss = [3.029409, 1.0427033, 1.0770047]\n",
      "Batch 68/700: Discriminator loss = 1.1127407550811768, GAN loss = [3.082681, 1.0678108, 1.1052326]\n",
      "Batch 69/700: Discriminator loss = 1.115477442741394, GAN loss = [3.0039766, 1.0714146, 1.0229897]\n",
      "Batch 70/700: Discriminator loss = 1.123542308807373, GAN loss = [3.0688977, 1.0939592, 1.0654349]\n",
      "Batch 71/700: Discriminator loss = 1.1176135540008545, GAN loss = [3.0348108, 1.0996, 1.0257784]\n",
      "Batch 72/700: Discriminator loss = 1.117371678352356, GAN loss = [3.0169349, 1.100903, 1.0066725]\n",
      "Batch 73/700: Discriminator loss = 1.1149952411651611, GAN loss = [3.0877419, 1.1054091, 1.0730454]\n",
      "Batch 74/700: Discriminator loss = 1.1177449226379395, GAN loss = [3.0196333, 1.0982466, 1.0121707]\n",
      "Batch 75/700: Discriminator loss = 1.1209664344787598, GAN loss = [3.0698671, 1.0958223, 1.0649017]\n",
      "Batch 76/700: Discriminator loss = 1.1158448457717896, GAN loss = [3.0932822, 1.1200298, 1.0641836]\n",
      "Batch 77/700: Discriminator loss = 1.1196781396865845, GAN loss = [3.0659516, 1.1174237, 1.0395331]\n",
      "Batch 78/700: Discriminator loss = 1.1108747720718384, GAN loss = [3.0320122, 1.0973276, 1.0257671]\n",
      "Batch 79/700: Discriminator loss = 1.0998708009719849, GAN loss = [3.1083658, 1.1121373, 1.0873871]\n",
      "Batch 80/700: Discriminator loss = 1.10459303855896, GAN loss = [3.1051152, 1.1238532, 1.0724965]\n",
      "Batch 81/700: Discriminator loss = 1.1378304958343506, GAN loss = [3.0495784, 1.1260219, 1.0148668]\n",
      "Batch 82/700: Discriminator loss = 1.1517601013183594, GAN loss = [3.0591538, 1.137356, 1.0131817]\n",
      "Batch 83/700: Discriminator loss = 1.1321769952774048, GAN loss = [3.059871, 1.1155851, 1.035742]\n",
      "Batch 84/700: Discriminator loss = 1.1464502811431885, GAN loss = [3.077769, 1.1387388, 1.0305581]\n",
      "Batch 85/700: Discriminator loss = 1.137550950050354, GAN loss = [3.0877178, 1.1218716, 1.057445]\n",
      "Batch 86/700: Discriminator loss = 1.1647363901138306, GAN loss = [3.0310996, 1.0977352, 1.0250335]\n",
      "Batch 87/700: Discriminator loss = 1.1530095338821411, GAN loss = [2.9586232, 1.0821396, 0.9682176]\n",
      "Batch 88/700: Discriminator loss = 1.14788019657135, GAN loss = [3.0025408, 1.0842788, 1.0100622]\n",
      "Batch 89/700: Discriminator loss = 1.1356254816055298, GAN loss = [2.9885547, 1.0783814, 1.0020418]\n",
      "Batch 90/700: Discriminator loss = 1.1573492288589478, GAN loss = [3.0005565, 1.1204435, 0.9720528]\n",
      "Batch 91/700: Discriminator loss = 1.1097427606582642, GAN loss = [3.0808797, 1.1257809, 1.0471133]\n",
      "Batch 92/700: Discriminator loss = 1.1036226749420166, GAN loss = [3.059987, 1.111865, 1.040214]\n",
      "Batch 93/700: Discriminator loss = 1.1201682090759277, GAN loss = [3.0543141, 1.1403044, 1.0061804]\n",
      "Batch 94/700: Discriminator loss = 1.1258103847503662, GAN loss = [3.0115795, 1.1094904, 0.994339]\n",
      "Batch 95/700: Discriminator loss = 1.132101058959961, GAN loss = [3.0386693, 1.1370456, 0.99395126]\n",
      "Batch 96/700: Discriminator loss = 1.1124796867370605, GAN loss = [3.0513322, 1.1072849, 1.0364476]\n",
      "Batch 97/700: Discriminator loss = 1.1366186141967773, GAN loss = [3.0670881, 1.1505895, 1.0089682]\n",
      "Batch 98/700: Discriminator loss = 1.1436676979064941, GAN loss = [2.9769285, 1.0956994, 0.97376466]\n",
      "Batch 99/700: Discriminator loss = 1.1469634771347046, GAN loss = [3.002873, 1.0963936, 0.99907637]\n",
      "Batch 100/700: Discriminator loss = 1.1389329433441162, GAN loss = [2.9955537, 1.0893958, 0.99881697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 101/700: Discriminator loss = 1.1494485139846802, GAN loss = [2.984834, 1.0794094, 0.9981457]\n",
      "Batch 102/700: Discriminator loss = 1.1406091451644897, GAN loss = [3.0271475, 1.0744528, 1.0454779]\n",
      "Batch 103/700: Discriminator loss = 1.1582505702972412, GAN loss = [3.0485659, 1.1000687, 1.0413414]\n",
      "Batch 104/700: Discriminator loss = 1.1318751573562622, GAN loss = [3.0613666, 1.1024109, 1.0518585]\n",
      "Batch 105/700: Discriminator loss = 1.1406422853469849, GAN loss = [3.1419337, 1.1312127, 1.103683]\n",
      "Batch 106/700: Discriminator loss = 1.1116360425949097, GAN loss = [3.115203, 1.0998939, 1.1083272]\n",
      "Batch 107/700: Discriminator loss = 1.1030575037002563, GAN loss = [3.1830745, 1.1130898, 1.1630569]\n",
      "Batch 108/700: Discriminator loss = 1.1044741868972778, GAN loss = [3.2222643, 1.1284317, 1.186959]\n",
      "Batch 109/700: Discriminator loss = 1.1016205549240112, GAN loss = [3.331351, 1.1526798, 1.2718531]\n",
      "Batch 110/700: Discriminator loss = 1.1090461015701294, GAN loss = [3.2453737, 1.1939015, 1.144712]\n",
      "Batch 111/700: Discriminator loss = 1.1018635034561157, GAN loss = [3.2040577, 1.1267505, 1.1706097]\n",
      "Batch 112/700: Discriminator loss = 1.0814080238342285, GAN loss = [3.3533356, 1.1689658, 1.2777328]\n",
      "Batch 113/700: Discriminator loss = 1.0853190422058105, GAN loss = [3.296623, 1.1549243, 1.235125]\n",
      "Batch 114/700: Discriminator loss = 1.0990972518920898, GAN loss = [3.3896458, 1.2196008, 1.2635351]\n",
      "Batch 115/700: Discriminator loss = 1.128894329071045, GAN loss = [3.3065965, 1.2074351, 1.1927209]\n",
      "Batch 116/700: Discriminator loss = 1.1016348600387573, GAN loss = [3.3762457, 1.2189243, 1.2509526]\n",
      "Batch 117/700: Discriminator loss = 1.0843724012374878, GAN loss = [3.3369446, 1.2369825, 1.1936666]\n",
      "Batch 118/700: Discriminator loss = 1.0985758304595947, GAN loss = [3.415482, 1.2353396, 1.2739259]\n",
      "Batch 119/700: Discriminator loss = 1.1110585927963257, GAN loss = [3.3595748, 1.2251526, 1.228284]\n",
      "Batch 120/700: Discriminator loss = 1.1319881677627563, GAN loss = [3.325673, 1.2562677, 1.1633438]\n",
      "Batch 121/700: Discriminator loss = 1.126085638999939, GAN loss = [3.386952, 1.3199713, 1.1609892]\n",
      "Batch 122/700: Discriminator loss = 1.0580638647079468, GAN loss = [3.4402642, 1.2692478, 1.2650899]\n",
      "Batch 123/700: Discriminator loss = 1.07430899143219, GAN loss = [3.406434, 1.3005906, 1.1999826]\n",
      "Batch 124/700: Discriminator loss = 1.0501372814178467, GAN loss = [3.4626215, 1.3096799, 1.247149]\n",
      "Batch 125/700: Discriminator loss = 1.0614150762557983, GAN loss = [3.5189354, 1.3299643, 1.2832547]\n",
      "Batch 126/700: Discriminator loss = 1.0618114471435547, GAN loss = [3.5859306, 1.3406879, 1.3396082]\n",
      "Batch 127/700: Discriminator loss = 1.0708210468292236, GAN loss = [3.5863535, 1.3266954, 1.3541019]\n",
      "Batch 128/700: Discriminator loss = 1.0713657140731812, GAN loss = [3.592726, 1.3524077, 1.3348365]\n",
      "Batch 129/700: Discriminator loss = 1.083833932876587, GAN loss = [3.5713644, 1.3574648, 1.3084908]\n",
      "Batch 130/700: Discriminator loss = 1.08346426486969, GAN loss = [3.5719433, 1.350425, 1.3161775]\n",
      "Batch 131/700: Discriminator loss = 1.0702999830245972, GAN loss = [3.7618828, 1.3543788, 1.5022333]\n",
      "Batch 132/700: Discriminator loss = 1.0755503177642822, GAN loss = [3.7505548, 1.3749647, 1.4703851]\n",
      "Batch 133/700: Discriminator loss = 1.0656007528305054, GAN loss = [3.816946, 1.3449111, 1.5668874]\n",
      "Batch 134/700: Discriminator loss = 1.1056636571884155, GAN loss = [3.8353004, 1.3764783, 1.5537256]\n",
      "Batch 135/700: Discriminator loss = 1.136542558670044, GAN loss = [3.6987784, 1.3621527, 1.4315727]\n",
      "Batch 136/700: Discriminator loss = 1.1366081237792969, GAN loss = [3.8542676, 1.3642421, 1.5850049]\n",
      "Batch 137/700: Discriminator loss = 1.1355904340744019, GAN loss = [3.812052, 1.3570219, 1.550031]\n",
      "Batch 138/700: Discriminator loss = 1.0936373472213745, GAN loss = [3.9062781, 1.3358858, 1.6654124]\n",
      "Batch 139/700: Discriminator loss = 1.1399108171463013, GAN loss = [3.8146224, 1.344048, 1.5656184]\n",
      "Batch 140/700: Discriminator loss = 1.205478310585022, GAN loss = [3.8563638, 1.3611963, 1.5902365]\n",
      "Batch 141/700: Discriminator loss = 1.2030001878738403, GAN loss = [3.7672102, 1.3260349, 1.5362619]\n",
      "Batch 142/700: Discriminator loss = 1.2275766134262085, GAN loss = [3.7560854, 1.3304633, 1.5207229]\n",
      "Batch 143/700: Discriminator loss = 1.239369511604309, GAN loss = [3.7273302, 1.3028991, 1.5195466]\n",
      "Batch 144/700: Discriminator loss = 1.2158842086791992, GAN loss = [3.8199272, 1.3168607, 1.5981891]\n",
      "Batch 145/700: Discriminator loss = 1.232325792312622, GAN loss = [3.6386635, 1.264621, 1.4691741]\n",
      "Batch 146/700: Discriminator loss = 1.2574528455734253, GAN loss = [3.7446, 1.3214935, 1.5182507]\n",
      "Batch 147/700: Discriminator loss = 1.278296709060669, GAN loss = [3.6397576, 1.3243508, 1.4105688]\n",
      "Batch 148/700: Discriminator loss = 1.263554573059082, GAN loss = [3.5670192, 1.336588, 1.3256173]\n",
      "Batch 149/700: Discriminator loss = 1.2362148761749268, GAN loss = [3.6210968, 1.3557537, 1.3605554]\n",
      "Batch 150/700: Discriminator loss = 1.2096285820007324, GAN loss = [3.653085, 1.4311624, 1.3171585]\n",
      "Batch 151/700: Discriminator loss = 1.1434895992279053, GAN loss = [3.6132975, 1.4203594, 1.2882047]\n",
      "Batch 152/700: Discriminator loss = 1.1808059215545654, GAN loss = [3.5737743, 1.4954655, 1.1736221]\n",
      "Batch 153/700: Discriminator loss = 1.1884636878967285, GAN loss = [3.5397432, 1.457927, 1.1771933]\n",
      "Batch 154/700: Discriminator loss = 1.2702997922897339, GAN loss = [3.3726368, 1.4376569, 1.0304275]\n",
      "Batch 155/700: Discriminator loss = 1.350603461265564, GAN loss = [3.2114406, 1.3898562, 0.9171033]\n",
      "Batch 156/700: Discriminator loss = 1.3271079063415527, GAN loss = [3.0998309, 1.2997916, 0.8956151]\n",
      "Batch 157/700: Discriminator loss = 1.3618557453155518, GAN loss = [2.9882994, 1.2848779, 0.7990381]\n",
      "Batch 158/700: Discriminator loss = 1.3440877199172974, GAN loss = [3.001824, 1.298118, 0.79936105]\n",
      "Batch 159/700: Discriminator loss = 1.3074986934661865, GAN loss = [2.9560597, 1.2328473, 0.8189174]\n",
      "Batch 160/700: Discriminator loss = 1.3237295150756836, GAN loss = [2.8803837, 1.1867056, 0.78943473]\n",
      "Batch 161/700: Discriminator loss = 1.285780429840088, GAN loss = [2.9187775, 1.119472, 0.89511055]\n",
      "Batch 162/700: Discriminator loss = 1.3038926124572754, GAN loss = [2.8563402, 1.112858, 0.8393312]\n",
      "Batch 163/700: Discriminator loss = 1.2604975700378418, GAN loss = [2.84681, 1.0708828, 0.8718153]\n",
      "Batch 164/700: Discriminator loss = 1.272599458694458, GAN loss = [2.8045013, 1.053177, 0.8472472]\n",
      "Batch 165/700: Discriminator loss = 1.2799919843673706, GAN loss = [2.7591226, 1.0368155, 0.81826127]\n",
      "Batch 166/700: Discriminator loss = 1.2505406141281128, GAN loss = [2.8034225, 1.027197, 0.8722069]\n",
      "Batch 167/700: Discriminator loss = 1.2478225231170654, GAN loss = [2.746953, 1.0208683, 0.82209533]\n",
      "Batch 168/700: Discriminator loss = 1.2422972917556763, GAN loss = [2.7633364, 1.0366459, 0.8227343]\n",
      "Batch 169/700: Discriminator loss = 1.243807315826416, GAN loss = [2.6833978, 0.9999224, 0.7795555]\n",
      "Batch 170/700: Discriminator loss = 1.236437201499939, GAN loss = [2.7441347, 1.0156207, 0.82463324]\n",
      "Batch 171/700: Discriminator loss = 1.2317991256713867, GAN loss = [2.7165945, 0.99486643, 0.8178905]\n",
      "Batch 172/700: Discriminator loss = 1.2423986196517944, GAN loss = [2.7246928, 0.9795075, 0.8413916]\n",
      "Batch 173/700: Discriminator loss = 1.2352648973464966, GAN loss = [2.7306194, 0.98313475, 0.8437323]\n",
      "Batch 174/700: Discriminator loss = 1.219674825668335, GAN loss = [2.7665038, 0.96675515, 0.8960361]\n",
      "Batch 175/700: Discriminator loss = 1.2170814275741577, GAN loss = [2.726756, 0.9476358, 0.8754468]\n",
      "Batch 176/700: Discriminator loss = 1.2275922298431396, GAN loss = [2.736619, 0.93596435, 0.897019]\n",
      "Batch 177/700: Discriminator loss = 1.2498762607574463, GAN loss = [2.721149, 0.91294813, 0.9046036]\n",
      "Batch 178/700: Discriminator loss = 1.2641260623931885, GAN loss = [2.6917021, 0.89760745, 0.89053816]\n",
      "Batch 179/700: Discriminator loss = 1.2783008813858032, GAN loss = [2.7374158, 0.9033827, 0.93051666]\n",
      "Batch 180/700: Discriminator loss = 1.3167370557785034, GAN loss = [2.6012692, 0.8654117, 0.83238167]\n",
      "Batch 181/700: Discriminator loss = 1.2929476499557495, GAN loss = [2.6036484, 0.87558204, 0.8246299]\n",
      "Batch 182/700: Discriminator loss = 1.2849448919296265, GAN loss = [2.659174, 0.87715536, 0.8786219]\n",
      "Batch 183/700: Discriminator loss = 1.2676841020584106, GAN loss = [2.6201007, 0.880004, 0.8367413]\n",
      "Batch 184/700: Discriminator loss = 1.2737915515899658, GAN loss = [2.6315675, 0.87747437, 0.8507821]\n",
      "Batch 185/700: Discriminator loss = 1.266162395477295, GAN loss = [2.6352007, 0.87442094, 0.85751486]\n",
      "Batch 186/700: Discriminator loss = 1.2751355171203613, GAN loss = [2.6566467, 0.8732818, 0.88014734]\n",
      "Batch 187/700: Discriminator loss = 1.2675310373306274, GAN loss = [2.6296387, 0.8795746, 0.84689486]\n",
      "Batch 188/700: Discriminator loss = 1.2583965063095093, GAN loss = [2.6336007, 0.91408485, 0.81639624]\n",
      "Batch 189/700: Discriminator loss = 1.2374367713928223, GAN loss = [2.6214721, 0.9074838, 0.8109182]\n",
      "Batch 190/700: Discriminator loss = 1.220129132270813, GAN loss = [2.6269155, 0.92103314, 0.80286163]\n",
      "Batch 191/700: Discriminator loss = 1.2106218338012695, GAN loss = [2.6828253, 0.9290677, 0.8507878]\n",
      "Batch 192/700: Discriminator loss = 1.1911866664886475, GAN loss = [2.731046, 0.94594634, 0.8821806]\n",
      "Batch 193/700: Discriminator loss = 1.1738213300704956, GAN loss = [2.8034308, 0.9569749, 0.94358927]\n",
      "Batch 194/700: Discriminator loss = 1.1726921796798706, GAN loss = [2.8697178, 0.97444093, 0.9924614]\n",
      "Batch 195/700: Discriminator loss = 1.1915479898452759, GAN loss = [2.7596197, 0.95569414, 0.90115786]\n",
      "Batch 196/700: Discriminator loss = 1.1505812406539917, GAN loss = [2.9246557, 0.9880468, 1.0338846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 197/700: Discriminator loss = 1.157420039176941, GAN loss = [2.974997, 0.99278986, 1.0795225]\n",
      "Batch 198/700: Discriminator loss = 1.1967254877090454, GAN loss = [2.8667676, 0.97156787, 0.9925531]\n",
      "Batch 199/700: Discriminator loss = 1.1749461889266968, GAN loss = [2.9300451, 0.9855878, 1.0418497]\n",
      "Batch 200/700: Discriminator loss = 1.1610709428787231, GAN loss = [3.03809, 0.99755895, 1.1379647]\n",
      "Batch 201/700: Discriminator loss = 1.1661092042922974, GAN loss = [3.1121082, 1.0244538, 1.1851295]\n",
      "Batch 202/700: Discriminator loss = 1.1449216604232788, GAN loss = [3.0525968, 1.0248747, 1.1252424]\n",
      "Batch 203/700: Discriminator loss = 1.143869400024414, GAN loss = [3.1133344, 1.0359975, 1.1749082]\n",
      "Batch 204/700: Discriminator loss = 1.1367621421813965, GAN loss = [3.1157112, 1.0374625, 1.1758729]\n",
      "Batch 205/700: Discriminator loss = 1.14736807346344, GAN loss = [3.200385, 1.0928494, 1.2052158]\n",
      "Batch 206/700: Discriminator loss = 1.1264837980270386, GAN loss = [3.0646536, 1.0572816, 1.1051096]\n",
      "Batch 207/700: Discriminator loss = 1.1554837226867676, GAN loss = [3.0873144, 1.0932126, 1.0919023]\n",
      "Batch 208/700: Discriminator loss = 1.1263421773910522, GAN loss = [3.2026532, 1.0935677, 1.206952]\n",
      "Batch 209/700: Discriminator loss = 1.1460341215133667, GAN loss = [3.05568, 1.1020149, 1.0516018]\n",
      "Batch 210/700: Discriminator loss = 1.1524038314819336, GAN loss = [3.0223083, 1.1128434, 1.0074707]\n",
      "Batch 211/700: Discriminator loss = 1.1423678398132324, GAN loss = [2.8924096, 1.074095, 0.91638833]\n",
      "Batch 212/700: Discriminator loss = 1.1918655633926392, GAN loss = [2.9017582, 1.0813675, 0.9185282]\n",
      "Batch 213/700: Discriminator loss = 1.1439194679260254, GAN loss = [2.9313548, 1.0723823, 0.9571722]\n",
      "Batch 214/700: Discriminator loss = 1.1687660217285156, GAN loss = [2.9063435, 1.0510207, 0.9535852]\n",
      "Batch 215/700: Discriminator loss = 1.1724348068237305, GAN loss = [2.8245614, 1.0163492, 0.90653616]\n",
      "Batch 216/700: Discriminator loss = 1.1538161039352417, GAN loss = [2.8741453, 1.0037553, 0.9687709]\n",
      "Batch 217/700: Discriminator loss = 1.205948829650879, GAN loss = [2.7980506, 1.0148957, 0.8815915]\n",
      "Batch 218/700: Discriminator loss = 1.2032731771469116, GAN loss = [2.8143454, 0.9739103, 0.9389261]\n",
      "Batch 219/700: Discriminator loss = 1.200365424156189, GAN loss = [2.8164012, 0.9681294, 0.94681334]\n",
      "Batch 220/700: Discriminator loss = 1.2202273607254028, GAN loss = [2.8605998, 0.959949, 0.999239]\n",
      "Batch 221/700: Discriminator loss = 1.2443220615386963, GAN loss = [2.7396939, 0.9376885, 0.90063536]\n",
      "Batch 222/700: Discriminator loss = 1.227185606956482, GAN loss = [2.8638248, 0.9417275, 1.020763]\n",
      "Batch 223/700: Discriminator loss = 1.236444354057312, GAN loss = [2.7877383, 0.95063263, 0.93580264]\n",
      "Batch 224/700: Discriminator loss = 1.2197142839431763, GAN loss = [2.8973596, 0.96590525, 1.0301836]\n",
      "Batch 225/700: Discriminator loss = 1.181524634361267, GAN loss = [2.8875296, 1.005889, 0.98040175]\n",
      "Batch 226/700: Discriminator loss = 1.2264081239700317, GAN loss = [2.8090901, 1.0008656, 0.9070258]\n",
      "Batch 227/700: Discriminator loss = 1.2031956911087036, GAN loss = [2.9046595, 1.0190986, 0.98440737]\n",
      "Batch 228/700: Discriminator loss = 1.1358911991119385, GAN loss = [3.0660386, 1.0671582, 1.0977756]\n",
      "Batch 229/700: Discriminator loss = 1.1617038249969482, GAN loss = [3.0632508, 1.0719426, 1.0902573]\n",
      "Batch 230/700: Discriminator loss = 1.159915566444397, GAN loss = [2.995566, 1.0968491, 0.9977213]\n",
      "Batch 231/700: Discriminator loss = 1.1209979057312012, GAN loss = [3.0533876, 1.0798439, 1.072605]\n",
      "Batch 232/700: Discriminator loss = 1.1531819105148315, GAN loss = [3.048664, 1.1040283, 1.0437533]\n",
      "Batch 233/700: Discriminator loss = 1.1583718061447144, GAN loss = [3.029371, 1.1105472, 1.0180006]\n",
      "Batch 234/700: Discriminator loss = 1.153216004371643, GAN loss = [3.022685, 1.1291814, 0.99274236]\n",
      "Batch 235/700: Discriminator loss = 1.1412627696990967, GAN loss = [3.1536672, 1.1225415, 1.130425]\n",
      "Batch 236/700: Discriminator loss = 1.1609179973602295, GAN loss = [3.044281, 1.1192628, 1.0243751]\n",
      "Batch 237/700: Discriminator loss = 1.170852780342102, GAN loss = [3.1307883, 1.1256554, 1.1045446]\n",
      "Batch 238/700: Discriminator loss = 1.1833539009094238, GAN loss = [2.9949212, 1.105455, 0.9889289]\n",
      "Batch 239/700: Discriminator loss = 1.1755964756011963, GAN loss = [3.0676446, 1.1170483, 1.0501055]\n",
      "Batch 240/700: Discriminator loss = 1.1540628671646118, GAN loss = [3.0059714, 1.0784092, 1.0271177]\n",
      "Batch 241/700: Discriminator loss = 1.1445586681365967, GAN loss = [3.162762, 1.1388001, 1.1235697]\n",
      "Batch 242/700: Discriminator loss = 1.154865026473999, GAN loss = [3.0716653, 1.1439233, 1.0274084]\n",
      "Batch 243/700: Discriminator loss = 1.1508843898773193, GAN loss = [3.0705647, 1.1268549, 1.0434387]\n",
      "Batch 244/700: Discriminator loss = 1.1576485633850098, GAN loss = [3.0468755, 1.112055, 1.0346115]\n",
      "Batch 245/700: Discriminator loss = 1.1445060968399048, GAN loss = [3.0703075, 1.1178776, 1.0522829]\n",
      "Batch 246/700: Discriminator loss = 1.1709084510803223, GAN loss = [2.972484, 1.1110531, 0.96134776]\n",
      "Batch 247/700: Discriminator loss = 1.1311633586883545, GAN loss = [3.1175675, 1.116322, 1.101225]\n",
      "Batch 248/700: Discriminator loss = 1.146119236946106, GAN loss = [3.1277268, 1.1522483, 1.0755218]\n",
      "Batch 249/700: Discriminator loss = 1.1073416471481323, GAN loss = [3.1210952, 1.1569207, 1.0642846]\n",
      "Batch 250/700: Discriminator loss = 1.1121251583099365, GAN loss = [3.1431723, 1.2013993, 1.041952]\n",
      "Batch 251/700: Discriminator loss = 1.0876282453536987, GAN loss = [3.1352746, 1.1953303, 1.0401964]\n",
      "Batch 252/700: Discriminator loss = 1.0811266899108887, GAN loss = [3.1825657, 1.2223815, 1.0605093]\n",
      "Batch 253/700: Discriminator loss = 1.072192668914795, GAN loss = [3.2768388, 1.2389998, 1.1382362]\n",
      "Batch 254/700: Discriminator loss = 1.0658849477767944, GAN loss = [3.2275906, 1.2422456, 1.0858126]\n",
      "Batch 255/700: Discriminator loss = 1.054247498512268, GAN loss = [3.25771, 1.2942485, 1.0640012]\n",
      "Batch 256/700: Discriminator loss = 1.0644859075546265, GAN loss = [3.2642734, 1.2799774, 1.0849123]\n",
      "Batch 257/700: Discriminator loss = 1.0408638715744019, GAN loss = [3.3497505, 1.288983, 1.1614637]\n",
      "Batch 258/700: Discriminator loss = 1.0719484090805054, GAN loss = [3.3393579, 1.3408306, 1.0993035]\n",
      "Batch 259/700: Discriminator loss = 1.0702496767044067, GAN loss = [3.3562434, 1.3439164, 1.1131821]\n",
      "Batch 260/700: Discriminator loss = 1.0735042095184326, GAN loss = [3.3316677, 1.3510764, 1.0815234]\n",
      "Batch 261/700: Discriminator loss = 1.0537655353546143, GAN loss = [3.4089575, 1.3445456, 1.1654221]\n",
      "Batch 262/700: Discriminator loss = 1.0608285665512085, GAN loss = [3.4288282, 1.3712006, 1.1587181]\n",
      "Batch 263/700: Discriminator loss = 1.0561448335647583, GAN loss = [3.4295845, 1.3726, 1.1581588]\n",
      "Batch 264/700: Discriminator loss = 1.071988821029663, GAN loss = [3.4262214, 1.3769382, 1.1505438]\n",
      "Batch 265/700: Discriminator loss = 1.0704983472824097, GAN loss = [3.408078, 1.3571831, 1.1522434]\n",
      "Batch 266/700: Discriminator loss = 1.0777839422225952, GAN loss = [3.4160554, 1.3508954, 1.1665962]\n",
      "Batch 267/700: Discriminator loss = 1.0752660036087036, GAN loss = [3.4400458, 1.3586645, 1.1829045]\n",
      "Batch 268/700: Discriminator loss = 1.0879337787628174, GAN loss = [3.3678515, 1.3197521, 1.149713]\n",
      "Batch 269/700: Discriminator loss = 1.0854041576385498, GAN loss = [3.324149, 1.2896752, 1.1361729]\n",
      "Batch 270/700: Discriminator loss = 1.100479006767273, GAN loss = [3.3018668, 1.2666028, 1.1370437]\n",
      "Batch 271/700: Discriminator loss = 1.0697479248046875, GAN loss = [3.4833484, 1.3017873, 1.2834191]\n",
      "Batch 272/700: Discriminator loss = 1.0983158349990845, GAN loss = [3.403582, 1.3044499, 1.201068]\n",
      "Batch 273/700: Discriminator loss = 1.0538891553878784, GAN loss = [3.5746648, 1.2760931, 1.4005884]\n",
      "Batch 274/700: Discriminator loss = 1.0440874099731445, GAN loss = [3.6124892, 1.303671, 1.4109166]\n",
      "Batch 275/700: Discriminator loss = 1.0667474269866943, GAN loss = [3.571377, 1.3393545, 1.3341997]\n",
      "Batch 276/700: Discriminator loss = 1.044844150543213, GAN loss = [3.656933, 1.3324009, 1.4267868]\n",
      "Batch 277/700: Discriminator loss = 1.0435090065002441, GAN loss = [3.6682954, 1.339914, 1.4307104]\n",
      "Batch 278/700: Discriminator loss = 1.0358604192733765, GAN loss = [3.788281, 1.3732693, 1.5174142]\n",
      "Batch 279/700: Discriminator loss = 1.019914150238037, GAN loss = [3.6799567, 1.3609141, 1.421517]\n",
      "Batch 280/700: Discriminator loss = 1.0199072360992432, GAN loss = [3.8863058, 1.4112313, 1.5776203]\n",
      "Batch 281/700: Discriminator loss = 0.9995492100715637, GAN loss = [3.8850234, 1.3973514, 1.5902878]\n",
      "Batch 282/700: Discriminator loss = 1.0106581449508667, GAN loss = [3.898122, 1.4312114, 1.5695927]\n",
      "Batch 283/700: Discriminator loss = 1.031887173652649, GAN loss = [3.7703433, 1.4340936, 1.438996]\n",
      "Batch 284/700: Discriminator loss = 1.0033940076828003, GAN loss = [3.9439397, 1.4547479, 1.5919986]\n",
      "Batch 285/700: Discriminator loss = 1.0334234237670898, GAN loss = [3.891123, 1.4699097, 1.524084]\n",
      "Batch 286/700: Discriminator loss = 1.0175566673278809, GAN loss = [4.028479, 1.4554276, 1.6759822]\n",
      "Batch 287/700: Discriminator loss = 1.036988377571106, GAN loss = [4.0913534, 1.4718332, 1.7225085]\n",
      "Batch 288/700: Discriminator loss = 1.0529594421386719, GAN loss = [4.0887065, 1.5159781, 1.6757718]\n",
      "Batch 289/700: Discriminator loss = 1.0248862504959106, GAN loss = [3.9924634, 1.4557557, 1.6398004]\n",
      "Batch 290/700: Discriminator loss = 1.0441590547561646, GAN loss = [4.0433626, 1.4350699, 1.7114302]\n",
      "Batch 291/700: Discriminator loss = 1.1143193244934082, GAN loss = [3.8085308, 1.4218608, 1.4898429]\n",
      "Batch 292/700: Discriminator loss = 1.1209677457809448, GAN loss = [3.915603, 1.3892698, 1.6295301]\n",
      "Batch 293/700: Discriminator loss = 1.147066593170166, GAN loss = [3.8486204, 1.3752075, 1.5766246]\n",
      "Batch 294/700: Discriminator loss = 1.1987197399139404, GAN loss = [3.6708605, 1.3335872, 1.4404936]\n",
      "Batch 295/700: Discriminator loss = 1.250840663909912, GAN loss = [3.632188, 1.3224609, 1.4129457]\n",
      "Batch 296/700: Discriminator loss = 1.2476235628128052, GAN loss = [3.5303118, 1.3156323, 1.3178928]\n",
      "Batch 297/700: Discriminator loss = 1.2598270177841187, GAN loss = [3.5284257, 1.2743152, 1.3573174]\n",
      "Batch 298/700: Discriminator loss = 1.2629830837249756, GAN loss = [3.3913548, 1.2897185, 1.2048413]\n",
      "Batch 299/700: Discriminator loss = 1.2915079593658447, GAN loss = [3.342569, 1.3064914, 1.1392906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300/700: Discriminator loss = 1.2415293455123901, GAN loss = [3.3781145, 1.2558212, 1.2255183]\n",
      "Batch 301/700: Discriminator loss = 1.2400023937225342, GAN loss = [3.4548717, 1.2282407, 1.3298631]\n",
      "Batch 302/700: Discriminator loss = 1.274794101715088, GAN loss = [3.3834517, 1.2244978, 1.2621942]\n",
      "Batch 303/700: Discriminator loss = 1.2743829488754272, GAN loss = [3.3144317, 1.2034842, 1.2141953]\n",
      "Batch 304/700: Discriminator loss = 1.264284610748291, GAN loss = [3.421872, 1.2388055, 1.2863201]\n",
      "Batch 305/700: Discriminator loss = 1.3055015802383423, GAN loss = [3.4474187, 1.2589525, 1.29173]\n",
      "Batch 306/700: Discriminator loss = 1.2476552724838257, GAN loss = [3.4845884, 1.2656535, 1.3221993]\n",
      "Batch 307/700: Discriminator loss = 1.209439754486084, GAN loss = [3.4564657, 1.2791839, 1.2805537]\n",
      "Batch 308/700: Discriminator loss = 1.1872761249542236, GAN loss = [3.5860004, 1.3377063, 1.351581]\n",
      "Batch 309/700: Discriminator loss = 1.2328883409500122, GAN loss = [3.599559, 1.3734581, 1.3294067]\n",
      "Batch 310/700: Discriminator loss = 1.2551325559616089, GAN loss = [3.4494243, 1.3333527, 1.2193881]\n",
      "Batch 311/700: Discriminator loss = 1.216890811920166, GAN loss = [3.5252128, 1.2879899, 1.3405474]\n",
      "Batch 312/700: Discriminator loss = 1.2200003862380981, GAN loss = [3.6333425, 1.2926539, 1.444027]\n",
      "Batch 313/700: Discriminator loss = 1.2381441593170166, GAN loss = [3.6024997, 1.3446693, 1.3611919]\n",
      "Batch 314/700: Discriminator loss = 1.2135790586471558, GAN loss = [3.5219274, 1.3411298, 1.2841814]\n",
      "Batch 315/700: Discriminator loss = 1.1566075086593628, GAN loss = [3.6022737, 1.3347306, 1.37095]\n",
      "Batch 316/700: Discriminator loss = 1.1756399869918823, GAN loss = [3.7247398, 1.4413229, 1.3868505]\n",
      "Batch 317/700: Discriminator loss = 1.1606760025024414, GAN loss = [3.663267, 1.4753679, 1.2913711]\n",
      "Batch 318/700: Discriminator loss = 1.1310091018676758, GAN loss = [3.5943909, 1.4231043, 1.2748073]\n",
      "Batch 319/700: Discriminator loss = 1.193487286567688, GAN loss = [3.6610582, 1.5098648, 1.254759]\n",
      "Batch 320/700: Discriminator loss = 1.1788041591644287, GAN loss = [3.6288164, 1.5009345, 1.2314937]\n",
      "Batch 321/700: Discriminator loss = 1.1857205629348755, GAN loss = [3.5858624, 1.47357, 1.2159461]\n",
      "Batch 322/700: Discriminator loss = 1.3063437938690186, GAN loss = [3.5399127, 1.5702683, 1.0733311]\n",
      "Batch 323/700: Discriminator loss = 1.2093323469161987, GAN loss = [3.3986182, 1.4168274, 1.0855106]\n",
      "Batch 324/700: Discriminator loss = 1.2854729890823364, GAN loss = [3.313838, 1.4238793, 0.9937141]\n",
      "Batch 325/700: Discriminator loss = 1.2686985731124878, GAN loss = [3.282988, 1.4333587, 0.9534247]\n",
      "Batch 326/700: Discriminator loss = 1.2599550485610962, GAN loss = [3.1992512, 1.3610115, 0.94207555]\n",
      "Batch 327/700: Discriminator loss = 1.2602503299713135, GAN loss = [3.1718128, 1.2932487, 0.982445]\n",
      "Batch 328/700: Discriminator loss = 1.3102720975875854, GAN loss = [3.1211529, 1.2956934, 0.92938614]\n",
      "Batch 329/700: Discriminator loss = 1.2880747318267822, GAN loss = [3.0037246, 1.2368599, 0.87084395]\n",
      "Batch 330/700: Discriminator loss = 1.3640145063400269, GAN loss = [2.9254248, 1.2350585, 0.7944004]\n",
      "Batch 331/700: Discriminator loss = 1.309162974357605, GAN loss = [2.8870976, 1.1730022, 0.8181837]\n",
      "Batch 332/700: Discriminator loss = 1.3235255479812622, GAN loss = [2.873544, 1.1897886, 0.787892]\n",
      "Batch 333/700: Discriminator loss = 1.3788076639175415, GAN loss = [2.715586, 1.1039305, 0.71584]\n",
      "Batch 334/700: Discriminator loss = 1.3173507452011108, GAN loss = [2.7207599, 1.09833, 0.72665215]\n",
      "Batch 335/700: Discriminator loss = 1.3369303941726685, GAN loss = [2.6958416, 1.0964062, 0.7036928]\n",
      "Batch 336/700: Discriminator loss = 1.2897769212722778, GAN loss = [2.6863565, 1.0969225, 0.6937206]\n",
      "Batch 337/700: Discriminator loss = 1.264281988143921, GAN loss = [2.7485132, 1.1145167, 0.7383132]\n",
      "Batch 338/700: Discriminator loss = 1.2254116535186768, GAN loss = [2.7195125, 1.105051, 0.7188103]\n",
      "Batch 339/700: Discriminator loss = 1.235813856124878, GAN loss = [2.7456803, 1.1062475, 0.74381775]\n",
      "Batch 340/700: Discriminator loss = 1.2364124059677124, GAN loss = [2.732543, 1.0990807, 0.7378823]\n",
      "Batch 341/700: Discriminator loss = 1.221689224243164, GAN loss = [2.8104196, 1.0986662, 0.81620646]\n",
      "Batch 342/700: Discriminator loss = 1.1838042736053467, GAN loss = [2.9153023, 1.1130872, 0.9067009]\n",
      "Batch 343/700: Discriminator loss = 1.1934280395507812, GAN loss = [2.7982464, 1.0805526, 0.82221115]\n",
      "Batch 344/700: Discriminator loss = 1.1816651821136475, GAN loss = [2.8671057, 1.1083515, 0.8633053]\n",
      "Batch 345/700: Discriminator loss = 1.1600208282470703, GAN loss = [3.0152733, 1.0995653, 1.0202962]\n",
      "Batch 346/700: Discriminator loss = 1.171900749206543, GAN loss = [2.9729102, 1.0789745, 0.9985633]\n",
      "Batch 347/700: Discriminator loss = 1.1760135889053345, GAN loss = [3.0183463, 1.0727965, 1.0502161]\n",
      "Batch 348/700: Discriminator loss = 1.1988272666931152, GAN loss = [3.0392737, 1.0311178, 1.1128606]\n",
      "Batch 349/700: Discriminator loss = 1.211844801902771, GAN loss = [2.9736297, 1.0106753, 1.0676947]\n",
      "Batch 350/700: Discriminator loss = 1.1950467824935913, GAN loss = [3.0585957, 1.0101464, 1.1532214]\n",
      "Batch 351/700: Discriminator loss = 1.1880890130996704, GAN loss = [3.0560083, 0.99649805, 1.1643116]\n",
      "Batch 352/700: Discriminator loss = 1.2328304052352905, GAN loss = [2.999695, 1.0190692, 1.08546]\n",
      "Batch 353/700: Discriminator loss = 1.1911473274230957, GAN loss = [3.0334525, 1.0194098, 1.1189102]\n",
      "Batch 354/700: Discriminator loss = 1.2502620220184326, GAN loss = [2.9106455, 1.0129923, 1.0025522]\n",
      "Batch 355/700: Discriminator loss = 1.2034345865249634, GAN loss = [2.932519, 1.0054051, 1.0320392]\n",
      "Batch 356/700: Discriminator loss = 1.2662911415100098, GAN loss = [2.8098505, 0.97939545, 0.9354028]\n",
      "Batch 357/700: Discriminator loss = 1.232179045677185, GAN loss = [2.847632, 0.99679494, 0.95580596]\n",
      "Batch 358/700: Discriminator loss = 1.205819845199585, GAN loss = [2.874094, 0.97895837, 1.0001287]\n",
      "Batch 359/700: Discriminator loss = 1.1952141523361206, GAN loss = [2.9594617, 1.0304008, 1.0340847]\n",
      "Batch 360/700: Discriminator loss = 1.161192774772644, GAN loss = [2.9303875, 1.020037, 1.015412]\n",
      "Batch 361/700: Discriminator loss = 1.1706863641738892, GAN loss = [2.8820665, 1.0408422, 0.94632894]\n",
      "Batch 362/700: Discriminator loss = 1.1725246906280518, GAN loss = [2.9431186, 1.0655034, 0.98276925]\n",
      "Batch 363/700: Discriminator loss = 1.169112205505371, GAN loss = [2.8818662, 1.0389109, 0.94816077]\n",
      "Batch 364/700: Discriminator loss = 1.1709948778152466, GAN loss = [2.869751, 1.0291908, 0.94581634]\n",
      "Batch 365/700: Discriminator loss = 1.1827847957611084, GAN loss = [2.895719, 1.0615529, 0.93947065]\n",
      "Batch 366/700: Discriminator loss = 1.1870261430740356, GAN loss = [2.8686378, 1.042157, 0.9318333]\n",
      "Batch 367/700: Discriminator loss = 1.204791784286499, GAN loss = [2.8302, 1.0448061, 0.89079523]\n",
      "Batch 368/700: Discriminator loss = 1.2035847902297974, GAN loss = [2.8145778, 1.0170101, 0.903019]\n",
      "Batch 369/700: Discriminator loss = 1.2227755784988403, GAN loss = [2.842847, 1.0207087, 0.9276406]\n",
      "Batch 370/700: Discriminator loss = 1.2069281339645386, GAN loss = [2.8022144, 1.0086846, 0.8990814]\n",
      "Batch 371/700: Discriminator loss = 1.198944091796875, GAN loss = [2.807035, 1.0238237, 0.88881487]\n",
      "Batch 372/700: Discriminator loss = 1.1839736700057983, GAN loss = [2.8595932, 1.030661, 0.93458945]\n",
      "Batch 373/700: Discriminator loss = 1.177931785583496, GAN loss = [2.8566413, 1.0190437, 0.9433107]\n",
      "Batch 374/700: Discriminator loss = 1.178351640701294, GAN loss = [2.8219492, 1.0077889, 0.91993093]\n",
      "Batch 375/700: Discriminator loss = 1.1738234758377075, GAN loss = [2.8641875, 1.0118954, 0.9581239]\n",
      "Batch 376/700: Discriminator loss = 1.1592049598693848, GAN loss = [2.9260523, 1.0309066, 1.0010382]\n",
      "Batch 377/700: Discriminator loss = 1.1641747951507568, GAN loss = [2.9087288, 1.0382572, 0.9764222]\n",
      "Batch 378/700: Discriminator loss = 1.149803876876831, GAN loss = [2.9897125, 1.038192, 1.0575273]\n",
      "Batch 379/700: Discriminator loss = 1.1564618349075317, GAN loss = [2.9246068, 1.0328869, 0.99778384]\n",
      "Batch 380/700: Discriminator loss = 1.1603007316589355, GAN loss = [2.9091494, 1.0367174, 0.9785535]\n",
      "Batch 381/700: Discriminator loss = 1.1640762090682983, GAN loss = [2.9769306, 1.0789319, 1.0041794]\n",
      "Batch 382/700: Discriminator loss = 1.1646382808685303, GAN loss = [2.9398136, 1.0722576, 0.97379714]\n",
      "Batch 383/700: Discriminator loss = 1.1514066457748413, GAN loss = [2.8713708, 1.0641046, 0.9135666]\n",
      "Batch 384/700: Discriminator loss = 1.1571438312530518, GAN loss = [2.9848034, 1.1039937, 0.9871689]\n",
      "Batch 385/700: Discriminator loss = 1.1727789640426636, GAN loss = [2.9042616, 1.0904919, 0.9201843]\n",
      "Batch 386/700: Discriminator loss = 1.1557523012161255, GAN loss = [2.9702644, 1.0964316, 0.98029757]\n",
      "Batch 387/700: Discriminator loss = 1.1387604475021362, GAN loss = [2.9490817, 1.0915982, 0.9639981]\n",
      "Batch 388/700: Discriminator loss = 1.1055556535720825, GAN loss = [3.082872, 1.1339816, 1.0554563]\n",
      "Batch 389/700: Discriminator loss = 1.083770990371704, GAN loss = [2.9813437, 1.090139, 0.9978264]\n",
      "Batch 390/700: Discriminator loss = 1.0959750413894653, GAN loss = [3.0512233, 1.1563351, 1.0015693]\n",
      "Batch 391/700: Discriminator loss = 1.068522334098816, GAN loss = [3.073086, 1.1268288, 1.0530026]\n",
      "Batch 392/700: Discriminator loss = 1.0783530473709106, GAN loss = [3.0791855, 1.1252018, 1.0607963]\n",
      "Batch 393/700: Discriminator loss = 1.0753878355026245, GAN loss = [3.1335495, 1.1358237, 1.1046046]\n",
      "Batch 394/700: Discriminator loss = 1.060255765914917, GAN loss = [3.2294521, 1.1337192, 1.2026792]\n",
      "Batch 395/700: Discriminator loss = 1.0779460668563843, GAN loss = [3.1946611, 1.1258012, 1.1758696]\n",
      "Batch 396/700: Discriminator loss = 1.0604820251464844, GAN loss = [3.2390523, 1.1237489, 1.2223755]\n",
      "Batch 397/700: Discriminator loss = 1.0970286130905151, GAN loss = [3.133974, 1.1132767, 1.127829]\n",
      "Batch 398/700: Discriminator loss = 1.0731658935546875, GAN loss = [3.2385764, 1.1126665, 1.2330959]\n",
      "Batch 399/700: Discriminator loss = 1.0882925987243652, GAN loss = [3.2026112, 1.1124797, 1.1973704]\n",
      "Batch 400/700: Discriminator loss = 1.0952562093734741, GAN loss = [3.276515, 1.12834, 1.2554656]\n",
      "Batch 401/700: Discriminator loss = 1.0945335626602173, GAN loss = [3.18344, 1.1318961, 1.1588848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 402/700: Discriminator loss = 1.0702368021011353, GAN loss = [3.3234613, 1.1304662, 1.3003846]\n",
      "Batch 403/700: Discriminator loss = 1.0918734073638916, GAN loss = [3.1852014, 1.1421455, 1.1504952]\n",
      "Batch 404/700: Discriminator loss = 1.1095004081726074, GAN loss = [3.1512022, 1.1377031, 1.120989]\n",
      "Batch 405/700: Discriminator loss = 1.0851987600326538, GAN loss = [3.2635114, 1.1457492, 1.225301]\n",
      "Batch 406/700: Discriminator loss = 1.1134668588638306, GAN loss = [3.1566813, 1.144085, 1.1201862]\n",
      "Batch 407/700: Discriminator loss = 1.126659870147705, GAN loss = [3.122328, 1.1419891, 1.0879807]\n",
      "Batch 408/700: Discriminator loss = 1.1400011777877808, GAN loss = [3.0674536, 1.1283121, 1.0468322]\n",
      "Batch 409/700: Discriminator loss = 1.1819498538970947, GAN loss = [3.0570076, 1.1123213, 1.0524185]\n",
      "Batch 410/700: Discriminator loss = 1.1474074125289917, GAN loss = [3.1646154, 1.1331922, 1.1391853]\n",
      "Batch 411/700: Discriminator loss = 1.148624300956726, GAN loss = [3.075823, 1.1105961, 1.0730165]\n",
      "Batch 412/700: Discriminator loss = 1.1214287281036377, GAN loss = [3.074652, 1.1334314, 1.0490395]\n",
      "Batch 413/700: Discriminator loss = 1.1231130361557007, GAN loss = [3.109193, 1.1409657, 1.0760771]\n",
      "Batch 414/700: Discriminator loss = 1.1234408617019653, GAN loss = [3.2027636, 1.169028, 1.1416187]\n",
      "Batch 415/700: Discriminator loss = 1.0943992137908936, GAN loss = [3.2129467, 1.1654763, 1.1553899]\n",
      "Batch 416/700: Discriminator loss = 1.0892789363861084, GAN loss = [3.3832784, 1.1872028, 1.3040304]\n",
      "Batch 417/700: Discriminator loss = 1.0915775299072266, GAN loss = [3.30281, 1.192189, 1.2186128]\n",
      "Batch 418/700: Discriminator loss = 1.0797735452651978, GAN loss = [3.3245332, 1.2231152, 1.209446]\n",
      "Batch 419/700: Discriminator loss = 1.09259033203125, GAN loss = [3.2945743, 1.2231253, 1.1795148]\n",
      "Batch 420/700: Discriminator loss = 1.0967926979064941, GAN loss = [3.3171892, 1.2213246, 1.2039682]\n",
      "Batch 421/700: Discriminator loss = 1.0612705945968628, GAN loss = [3.4330409, 1.2343959, 1.306785]\n",
      "Batch 422/700: Discriminator loss = 1.0661511421203613, GAN loss = [3.462684, 1.2554828, 1.3153787]\n",
      "Batch 423/700: Discriminator loss = 1.0961635112762451, GAN loss = [3.3827205, 1.247189, 1.2437459]\n",
      "Batch 424/700: Discriminator loss = 1.0720170736312866, GAN loss = [3.5200443, 1.2658288, 1.362466]\n",
      "Batch 425/700: Discriminator loss = 1.0830786228179932, GAN loss = [3.485601, 1.266988, 1.3268946]\n",
      "Batch 426/700: Discriminator loss = 1.0898324251174927, GAN loss = [3.5567973, 1.3052979, 1.3598121]\n",
      "Batch 427/700: Discriminator loss = 1.0791985988616943, GAN loss = [3.4405262, 1.3185158, 1.2303548]\n",
      "Batch 428/700: Discriminator loss = 1.072633147239685, GAN loss = [3.6253488, 1.3224149, 1.411315]\n",
      "Batch 429/700: Discriminator loss = 1.0434520244598389, GAN loss = [3.6485925, 1.3307761, 1.4262347]\n",
      "Batch 430/700: Discriminator loss = 1.0662968158721924, GAN loss = [3.5910852, 1.3392084, 1.3603375]\n",
      "Batch 431/700: Discriminator loss = 1.089257836341858, GAN loss = [3.5302846, 1.3281065, 1.3106784]\n",
      "Batch 432/700: Discriminator loss = 1.0515881776809692, GAN loss = [3.6160886, 1.3155644, 1.4090592]\n",
      "Batch 433/700: Discriminator loss = 1.057759165763855, GAN loss = [3.6508222, 1.329312, 1.430083]\n",
      "Batch 434/700: Discriminator loss = 1.0555083751678467, GAN loss = [3.6722927, 1.3063174, 1.474586]\n",
      "Batch 435/700: Discriminator loss = 1.1026924848556519, GAN loss = [3.5640368, 1.3267099, 1.3459799]\n",
      "Batch 436/700: Discriminator loss = 1.058308482170105, GAN loss = [3.6047616, 1.3135834, 1.3998687]\n",
      "Batch 437/700: Discriminator loss = 1.0587214231491089, GAN loss = [3.740722, 1.343399, 1.5060467]\n",
      "Batch 438/700: Discriminator loss = 1.0360761880874634, GAN loss = [3.8865645, 1.383406, 1.6119189]\n",
      "Batch 439/700: Discriminator loss = 1.0767945051193237, GAN loss = [3.7991226, 1.4147247, 1.4931973]\n",
      "Batch 440/700: Discriminator loss = 1.059414267539978, GAN loss = [3.8125944, 1.4220452, 1.4993907]\n",
      "Batch 441/700: Discriminator loss = 1.040378451347351, GAN loss = [3.8990488, 1.4651641, 1.5427698]\n",
      "Batch 442/700: Discriminator loss = 1.0422872304916382, GAN loss = [3.9350145, 1.4825568, 1.5613898]\n",
      "Batch 443/700: Discriminator loss = 1.036994457244873, GAN loss = [3.8695579, 1.5208064, 1.4577266]\n",
      "Batch 444/700: Discriminator loss = 1.0382366180419922, GAN loss = [3.908623, 1.5357214, 1.4819157]\n",
      "Batch 445/700: Discriminator loss = 1.0653079748153687, GAN loss = [3.9261189, 1.5518432, 1.4833283]\n",
      "Batch 446/700: Discriminator loss = 1.033082127571106, GAN loss = [3.789098, 1.4566952, 1.441496]\n",
      "Batch 447/700: Discriminator loss = 1.0640827417373657, GAN loss = [3.8081806, 1.4746528, 1.4426634]\n",
      "Batch 448/700: Discriminator loss = 1.0431556701660156, GAN loss = [3.8394265, 1.4919504, 1.4566551]\n",
      "Batch 449/700: Discriminator loss = 1.0259881019592285, GAN loss = [3.8605304, 1.4983125, 1.4714437]\n",
      "Batch 450/700: Discriminator loss = 1.0463283061981201, GAN loss = [3.835067, 1.5190068, 1.4253377]\n",
      "Batch 451/700: Discriminator loss = 1.0638959407806396, GAN loss = [3.8173647, 1.5425922, 1.3841058]\n",
      "Batch 452/700: Discriminator loss = 1.0728390216827393, GAN loss = [3.8723354, 1.5479285, 1.433798]\n",
      "Batch 453/700: Discriminator loss = 1.0573103427886963, GAN loss = [3.9660716, 1.5696325, 1.5058873]\n",
      "Batch 454/700: Discriminator loss = 1.0939834117889404, GAN loss = [3.9495187, 1.6336274, 1.4253964]\n",
      "Batch 455/700: Discriminator loss = 1.1061972379684448, GAN loss = [3.8380806, 1.5862542, 1.3613864]\n",
      "Batch 456/700: Discriminator loss = 1.1035816669464111, GAN loss = [3.853545, 1.6017607, 1.3613958]\n",
      "Batch 457/700: Discriminator loss = 1.1054140329360962, GAN loss = [3.8207712, 1.6263249, 1.304108]\n",
      "Batch 458/700: Discriminator loss = 1.0552845001220703, GAN loss = [3.8432083, 1.6011212, 1.3517994]\n",
      "Batch 459/700: Discriminator loss = 1.1167223453521729, GAN loss = [3.7813468, 1.7051463, 1.1859679]\n",
      "Batch 460/700: Discriminator loss = 1.0285643339157104, GAN loss = [3.967966, 1.6270083, 1.4507954]\n",
      "Batch 461/700: Discriminator loss = 1.101619839668274, GAN loss = [3.719037, 1.6024566, 1.2264954]\n",
      "Batch 462/700: Discriminator loss = 1.1255863904953003, GAN loss = [3.811572, 1.6118294, 1.3097247]\n",
      "Batch 463/700: Discriminator loss = 1.1602882146835327, GAN loss = [3.6793795, 1.6436777, 1.145734]\n",
      "Batch 464/700: Discriminator loss = 1.0332932472229004, GAN loss = [3.8671863, 1.5701191, 1.4071447]\n",
      "Batch 465/700: Discriminator loss = 1.1176743507385254, GAN loss = [3.825166, 1.6589929, 1.2763004]\n",
      "Batch 466/700: Discriminator loss = 1.0834320783615112, GAN loss = [3.8453414, 1.6038883, 1.3516297]\n",
      "Batch 467/700: Discriminator loss = 1.1353216171264648, GAN loss = [3.7195983, 1.6677533, 1.1620655]\n",
      "Batch 468/700: Discriminator loss = 1.1577311754226685, GAN loss = [3.6938562, 1.648479, 1.1556414]\n",
      "Batch 469/700: Discriminator loss = 1.1593117713928223, GAN loss = [3.6359696, 1.6434867, 1.1027852]\n",
      "Batch 470/700: Discriminator loss = 1.1576437950134277, GAN loss = [3.618054, 1.6195313, 1.1088569]\n",
      "Batch 471/700: Discriminator loss = 1.1379356384277344, GAN loss = [3.562287, 1.5887281, 1.0839291]\n",
      "Batch 472/700: Discriminator loss = 1.1458301544189453, GAN loss = [3.5973182, 1.5915488, 1.1161808]\n",
      "Batch 473/700: Discriminator loss = 1.1930028200149536, GAN loss = [3.475563, 1.5818264, 1.0041941]\n",
      "Batch 474/700: Discriminator loss = 1.1673521995544434, GAN loss = [3.4762518, 1.5418097, 1.0449445]\n",
      "Batch 475/700: Discriminator loss = 1.1762158870697021, GAN loss = [3.4077265, 1.4985075, 1.0197623]\n",
      "Batch 476/700: Discriminator loss = 1.218299388885498, GAN loss = [3.2984428, 1.4512671, 0.9577507]\n",
      "Batch 477/700: Discriminator loss = 1.177808403968811, GAN loss = [3.2848935, 1.3416241, 1.0538602]\n",
      "Batch 478/700: Discriminator loss = 1.204681396484375, GAN loss = [3.4002676, 1.4509279, 1.0599301]\n",
      "Batch 479/700: Discriminator loss = 1.1615062952041626, GAN loss = [3.305877, 1.3394439, 1.0770135]\n",
      "Batch 480/700: Discriminator loss = 1.1708163022994995, GAN loss = [3.3789732, 1.3713238, 1.1182187]\n",
      "Batch 481/700: Discriminator loss = 1.1315573453903198, GAN loss = [3.5574677, 1.3786637, 1.289367]\n",
      "Batch 482/700: Discriminator loss = 1.1041078567504883, GAN loss = [3.65755, 1.3645804, 1.4035279]\n",
      "Batch 483/700: Discriminator loss = 1.1037174463272095, GAN loss = [3.7072377, 1.331285, 1.4865054]\n",
      "Batch 484/700: Discriminator loss = 1.1016342639923096, GAN loss = [3.7929537, 1.3522851, 1.5512116]\n",
      "Batch 485/700: Discriminator loss = 1.0643492937088013, GAN loss = [3.9955752, 1.3488072, 1.7573062]\n",
      "Batch 486/700: Discriminator loss = 1.080593228340149, GAN loss = [3.90777, 1.3541727, 1.6641359]\n",
      "Batch 487/700: Discriminator loss = 1.0644077062606812, GAN loss = [4.201725, 1.3969712, 1.9152948]\n",
      "Batch 488/700: Discriminator loss = 1.045336127281189, GAN loss = [4.1625338, 1.3504313, 1.9226456]\n",
      "Batch 489/700: Discriminator loss = 1.0922733545303345, GAN loss = [4.103092, 1.3787559, 1.8348858]\n",
      "Batch 490/700: Discriminator loss = 1.0695362091064453, GAN loss = [4.2928667, 1.3899513, 2.0134714]\n",
      "Batch 491/700: Discriminator loss = 1.097579002380371, GAN loss = [4.193039, 1.3931547, 1.9104463]\n",
      "Batch 492/700: Discriminator loss = 1.1326175928115845, GAN loss = [4.290396, 1.4079608, 1.9929994]\n",
      "Batch 493/700: Discriminator loss = 1.2525866031646729, GAN loss = [4.0673704, 1.4398549, 1.7380774]\n",
      "Batch 494/700: Discriminator loss = 1.3364874124526978, GAN loss = [3.5753424, 1.3936839, 1.2922118]\n",
      "Batch 495/700: Discriminator loss = 1.4569114446640015, GAN loss = [3.299711, 1.3432735, 1.06698]\n",
      "Batch 496/700: Discriminator loss = 1.5447252988815308, GAN loss = [3.0511818, 1.2850444, 0.8766665]\n",
      "Batch 497/700: Discriminator loss = 1.4650776386260986, GAN loss = [2.9102237, 1.1485333, 0.87220144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 498/700: Discriminator loss = 1.6055858135223389, GAN loss = [2.753985, 1.0638664, 0.8006122]\n",
      "Batch 499/700: Discriminator loss = 1.5992084741592407, GAN loss = [2.6254792, 1.0319049, 0.704053]\n",
      "Batch 500/700: Discriminator loss = 1.4097707271575928, GAN loss = [2.677638, 0.9789211, 0.80919176]\n",
      "Batch 501/700: Discriminator loss = 1.4464362859725952, GAN loss = [2.6698906, 0.9833364, 0.7970335]\n",
      "Batch 502/700: Discriminator loss = 1.3907946348190308, GAN loss = [2.6977198, 0.9988703, 0.80934405]\n",
      "Batch 503/700: Discriminator loss = 1.354566216468811, GAN loss = [2.6456923, 1.0042148, 0.75199425]\n",
      "Batch 504/700: Discriminator loss = 1.3184586763381958, GAN loss = [2.674471, 0.9828235, 0.80218995]\n",
      "Batch 505/700: Discriminator loss = 1.3437995910644531, GAN loss = [2.7097158, 0.99745744, 0.8228251]\n",
      "Batch 506/700: Discriminator loss = 1.2984673976898193, GAN loss = [2.7277586, 1.017481, 0.82086426]\n",
      "Batch 507/700: Discriminator loss = 1.325419545173645, GAN loss = [2.6840303, 1.0049063, 0.7897344]\n",
      "Batch 508/700: Discriminator loss = 1.3129264116287231, GAN loss = [2.7107003, 1.0102918, 0.81104845]\n",
      "Batch 509/700: Discriminator loss = 1.3183945417404175, GAN loss = [2.6795726, 1.008901, 0.7813454]\n",
      "Batch 510/700: Discriminator loss = 1.3352046012878418, GAN loss = [2.613903, 0.98059106, 0.7440203]\n",
      "Batch 511/700: Discriminator loss = 1.2282518148422241, GAN loss = [2.7229347, 0.9552713, 0.8784036]\n",
      "Batch 512/700: Discriminator loss = 1.3291112184524536, GAN loss = [2.7405882, 1.0517827, 0.79957545]\n",
      "Batch 513/700: Discriminator loss = 1.2121721506118774, GAN loss = [2.810701, 1.0123873, 0.90911615]\n",
      "Batch 514/700: Discriminator loss = 1.231713891029358, GAN loss = [2.858947, 1.0414803, 0.92830247]\n",
      "Batch 515/700: Discriminator loss = 1.224427342414856, GAN loss = [2.7980769, 1.0434057, 0.8655433]\n",
      "Batch 516/700: Discriminator loss = 1.2077974081039429, GAN loss = [2.8531322, 1.0648233, 0.899217]\n",
      "Batch 517/700: Discriminator loss = 1.1867187023162842, GAN loss = [2.8467286, 1.0316921, 0.92598206]\n",
      "Batch 518/700: Discriminator loss = 1.2544982433319092, GAN loss = [2.8313973, 1.0996817, 0.8427025]\n",
      "Batch 519/700: Discriminator loss = 1.1893409490585327, GAN loss = [2.9003255, 1.0592585, 0.95209765]\n",
      "Batch 520/700: Discriminator loss = 1.2076940536499023, GAN loss = [2.841005, 1.0841098, 0.8679703]\n",
      "Batch 521/700: Discriminator loss = 1.19232177734375, GAN loss = [2.940146, 1.0959408, 0.9553263]\n",
      "Batch 522/700: Discriminator loss = 1.2013310194015503, GAN loss = [2.8755317, 1.1221433, 0.864558]\n",
      "Batch 523/700: Discriminator loss = 1.1849364042282104, GAN loss = [2.9080458, 1.1014419, 0.91782486]\n",
      "Batch 524/700: Discriminator loss = 1.1959164142608643, GAN loss = [2.9698496, 1.1378249, 0.94329745]\n",
      "Batch 525/700: Discriminator loss = 1.153483510017395, GAN loss = [2.8979445, 1.0964618, 0.91280717]\n",
      "Batch 526/700: Discriminator loss = 1.2266258001327515, GAN loss = [2.8783066, 1.1589733, 0.8307092]\n",
      "Batch 527/700: Discriminator loss = 1.142236351966858, GAN loss = [2.9851115, 1.1416122, 0.95492965]\n",
      "Batch 528/700: Discriminator loss = 1.1536768674850464, GAN loss = [2.9615622, 1.120874, 0.9521778]\n",
      "Batch 529/700: Discriminator loss = 1.1648563146591187, GAN loss = [2.98021, 1.1664063, 0.9253554]\n",
      "Batch 530/700: Discriminator loss = 1.164764404296875, GAN loss = [2.945422, 1.1391649, 0.91787285]\n",
      "Batch 531/700: Discriminator loss = 1.1512290239334106, GAN loss = [3.0730844, 1.1849438, 0.99982077]\n",
      "Batch 532/700: Discriminator loss = 1.125099778175354, GAN loss = [3.1370282, 1.161511, 1.0872622]\n",
      "Batch 533/700: Discriminator loss = 1.1858669519424438, GAN loss = [3.0203462, 1.1847317, 0.9474251]\n",
      "Batch 534/700: Discriminator loss = 1.149715781211853, GAN loss = [3.0072978, 1.174047, 0.9451216]\n",
      "Batch 535/700: Discriminator loss = 1.1644349098205566, GAN loss = [3.033101, 1.1710751, 0.9739527]\n",
      "Batch 536/700: Discriminator loss = 1.150485634803772, GAN loss = [3.0696132, 1.1725461, 1.0090476]\n",
      "Batch 537/700: Discriminator loss = 1.1152098178863525, GAN loss = [3.1371415, 1.1710175, 1.0781517]\n",
      "Batch 538/700: Discriminator loss = 1.120431900024414, GAN loss = [3.0650046, 1.1581352, 1.0189395]\n",
      "Batch 539/700: Discriminator loss = 1.1010804176330566, GAN loss = [3.1034744, 1.1654491, 1.0501354]\n",
      "Batch 540/700: Discriminator loss = 1.0920131206512451, GAN loss = [3.198327, 1.2111794, 1.0992981]\n",
      "Batch 541/700: Discriminator loss = 1.064440131187439, GAN loss = [3.2682176, 1.2062919, 1.17412]\n",
      "Batch 542/700: Discriminator loss = 1.0725950002670288, GAN loss = [3.3723779, 1.2420805, 1.2425365]\n",
      "Batch 543/700: Discriminator loss = 1.0508859157562256, GAN loss = [3.4023526, 1.2416279, 1.2730097]\n",
      "Batch 544/700: Discriminator loss = 1.0654081106185913, GAN loss = [3.5378945, 1.3062667, 1.3439612]\n",
      "Batch 545/700: Discriminator loss = 1.056625485420227, GAN loss = [3.4557502, 1.2623734, 1.3057628]\n",
      "Batch 546/700: Discriminator loss = 1.0488157272338867, GAN loss = [3.5002925, 1.2888155, 1.3239175]\n",
      "Batch 547/700: Discriminator loss = 1.0968453884124756, GAN loss = [3.5121942, 1.365019, 1.2596738]\n",
      "Batch 548/700: Discriminator loss = 1.0355688333511353, GAN loss = [3.549993, 1.3479842, 1.3145641]\n",
      "Batch 549/700: Discriminator loss = 1.1086918115615845, GAN loss = [3.3618093, 1.4036613, 1.0707601]\n",
      "Batch 550/700: Discriminator loss = 1.0628820657730103, GAN loss = [3.4554849, 1.3744293, 1.1937257]\n",
      "Batch 551/700: Discriminator loss = 1.0963135957717896, GAN loss = [3.3449674, 1.4120843, 1.045609]\n",
      "Batch 552/700: Discriminator loss = 1.0313307046890259, GAN loss = [3.408396, 1.3213843, 1.1997979]\n",
      "Batch 553/700: Discriminator loss = 1.071096658706665, GAN loss = [3.3819191, 1.3543503, 1.140418]\n",
      "Batch 554/700: Discriminator loss = 1.0473663806915283, GAN loss = [3.3817925, 1.3254943, 1.1692163]\n",
      "Batch 555/700: Discriminator loss = 1.0326998233795166, GAN loss = [3.4674346, 1.3073945, 1.2730287]\n",
      "Batch 556/700: Discriminator loss = 1.0681278705596924, GAN loss = [3.4100528, 1.3452054, 1.1779087]\n",
      "Batch 557/700: Discriminator loss = 1.023012638092041, GAN loss = [3.486707, 1.3186219, 1.2812209]\n",
      "Batch 558/700: Discriminator loss = 1.0547438859939575, GAN loss = [3.511027, 1.3204974, 1.3037409]\n",
      "Batch 559/700: Discriminator loss = 1.026336431503296, GAN loss = [3.5357196, 1.3270919, 1.3219119]\n",
      "Batch 560/700: Discriminator loss = 1.0259758234024048, GAN loss = [3.5217795, 1.3206635, 1.3144723]\n",
      "Batch 561/700: Discriminator loss = 1.0235399007797241, GAN loss = [3.6338954, 1.3444967, 1.4028243]\n",
      "Batch 562/700: Discriminator loss = 1.0306224822998047, GAN loss = [3.610542, 1.3416334, 1.3824031]\n",
      "Batch 563/700: Discriminator loss = 1.0225247144699097, GAN loss = [3.691794, 1.3640126, 1.4413435]\n",
      "Batch 564/700: Discriminator loss = 1.042691946029663, GAN loss = [3.5907269, 1.3542795, 1.350073]\n",
      "Batch 565/700: Discriminator loss = 1.061249017715454, GAN loss = [3.4042497, 1.3105705, 1.2073659]\n",
      "Batch 566/700: Discriminator loss = 1.083297610282898, GAN loss = [3.6223075, 1.3621718, 1.3738785]\n",
      "Batch 567/700: Discriminator loss = 1.0478317737579346, GAN loss = [3.4767158, 1.305523, 1.2849879]\n",
      "Batch 568/700: Discriminator loss = 1.1032365560531616, GAN loss = [3.392048, 1.3373162, 1.1685771]\n",
      "Batch 569/700: Discriminator loss = 1.0925313234329224, GAN loss = [3.3348198, 1.306143, 1.1425706]\n",
      "Batch 570/700: Discriminator loss = 1.086954951286316, GAN loss = [3.3693073, 1.2888843, 1.1943672]\n",
      "Batch 571/700: Discriminator loss = 1.0958340167999268, GAN loss = [3.3186374, 1.2796109, 1.1530223]\n",
      "Batch 572/700: Discriminator loss = 1.0906802415847778, GAN loss = [3.3016508, 1.2720355, 1.1436639]\n",
      "Batch 573/700: Discriminator loss = 1.095526933670044, GAN loss = [3.4352362, 1.3291785, 1.2201594]\n",
      "Batch 574/700: Discriminator loss = 1.0910375118255615, GAN loss = [3.332539, 1.2777587, 1.1689347]\n",
      "Batch 575/700: Discriminator loss = 1.0819264650344849, GAN loss = [3.362822, 1.2922885, 1.1847397]\n",
      "Batch 576/700: Discriminator loss = 1.0601009130477905, GAN loss = [3.4683936, 1.3233168, 1.2593298]\n",
      "Batch 577/700: Discriminator loss = 1.0625922679901123, GAN loss = [3.3825305, 1.270533, 1.2262987]\n",
      "Batch 578/700: Discriminator loss = 1.059505581855774, GAN loss = [3.415443, 1.3225249, 1.207264]\n",
      "Batch 579/700: Discriminator loss = 1.050726056098938, GAN loss = [3.4211638, 1.2968776, 1.2386787]\n",
      "Batch 580/700: Discriminator loss = 1.0696232318878174, GAN loss = [3.5179467, 1.4118745, 1.2205145]\n",
      "Batch 581/700: Discriminator loss = 1.0152357816696167, GAN loss = [3.4116185, 1.3068451, 1.2192718]\n",
      "Batch 582/700: Discriminator loss = 1.0271633863449097, GAN loss = [3.5703688, 1.363995, 1.3209281]\n",
      "Batch 583/700: Discriminator loss = 1.0231530666351318, GAN loss = [3.6047995, 1.3848249, 1.3345859]\n",
      "Batch 584/700: Discriminator loss = 1.1000880002975464, GAN loss = [3.438191, 1.420009, 1.1328522]\n",
      "Batch 585/700: Discriminator loss = 1.0632786750793457, GAN loss = [3.4729016, 1.4058048, 1.1818247]\n",
      "Batch 586/700: Discriminator loss = 1.0542887449264526, GAN loss = [3.5575135, 1.3858954, 1.2863966]\n",
      "Batch 587/700: Discriminator loss = 1.0619549751281738, GAN loss = [3.5126638, 1.3542645, 1.2732239]\n",
      "Batch 588/700: Discriminator loss = 1.0593284368515015, GAN loss = [3.5325136, 1.3770797, 1.2703038]\n",
      "Batch 589/700: Discriminator loss = 1.0440747737884521, GAN loss = [3.41216, 1.3236423, 1.203435]\n",
      "Batch 590/700: Discriminator loss = 1.077225685119629, GAN loss = [3.5512064, 1.3942267, 1.2719516]\n",
      "Batch 591/700: Discriminator loss = 1.0602056980133057, GAN loss = [3.598649, 1.3894829, 1.324196]\n",
      "Batch 592/700: Discriminator loss = 1.077014446258545, GAN loss = [3.6266298, 1.4008754, 1.3408406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 593/700: Discriminator loss = 1.0810059309005737, GAN loss = [3.5241659, 1.3943152, 1.2449887]\n",
      "Batch 594/700: Discriminator loss = 1.0657072067260742, GAN loss = [3.4398675, 1.3317239, 1.223324]\n",
      "Batch 595/700: Discriminator loss = 1.0708192586898804, GAN loss = [3.619439, 1.356722, 1.3779308]\n",
      "Batch 596/700: Discriminator loss = 1.0454095602035522, GAN loss = [3.7286735, 1.3736126, 1.4703033]\n",
      "Batch 597/700: Discriminator loss = 1.0169548988342285, GAN loss = [3.7007387, 1.4060805, 1.4099312]\n",
      "Batch 598/700: Discriminator loss = 1.041035771369934, GAN loss = [3.7560177, 1.4893129, 1.3820096]\n",
      "Batch 599/700: Discriminator loss = 1.068790078163147, GAN loss = [3.5742998, 1.4573587, 1.2322798]\n",
      "Batch 600/700: Discriminator loss = 1.0830304622650146, GAN loss = [3.6103592, 1.499198, 1.2265306]\n",
      "Batch 601/700: Discriminator loss = 1.032105565071106, GAN loss = [3.7460647, 1.459999, 1.4014622]\n",
      "Batch 602/700: Discriminator loss = 1.0537556409835815, GAN loss = [3.8145907, 1.5218644, 1.4081528]\n",
      "Batch 603/700: Discriminator loss = 1.0426088571548462, GAN loss = [3.8119593, 1.5567611, 1.3706567]\n",
      "Batch 604/700: Discriminator loss = 1.0599987506866455, GAN loss = [3.735385, 1.5223624, 1.3285147]\n",
      "Batch 605/700: Discriminator loss = 1.0408668518066406, GAN loss = [3.810494, 1.4934375, 1.4325821]\n",
      "Batch 606/700: Discriminator loss = 1.0745731592178345, GAN loss = [3.7805305, 1.540271, 1.3558152]\n",
      "Batch 607/700: Discriminator loss = 1.0653254985809326, GAN loss = [3.791142, 1.5016743, 1.4050516]\n",
      "Batch 608/700: Discriminator loss = 1.0797432661056519, GAN loss = [3.8311245, 1.5071902, 1.4395443]\n",
      "Batch 609/700: Discriminator loss = 1.0828791856765747, GAN loss = [3.6987162, 1.5215373, 1.2928134]\n",
      "Batch 610/700: Discriminator loss = 1.0903112888336182, GAN loss = [3.836241, 1.5182767, 1.4336257]\n",
      "Batch 611/700: Discriminator loss = 1.094711184501648, GAN loss = [3.784228, 1.5085998, 1.3913131]\n",
      "Batch 612/700: Discriminator loss = 1.1151649951934814, GAN loss = [3.6945643, 1.5399781, 1.2702909]\n",
      "Batch 613/700: Discriminator loss = 1.0490138530731201, GAN loss = [3.8268104, 1.5259335, 1.4166069]\n",
      "Batch 614/700: Discriminator loss = 1.0652958154678345, GAN loss = [3.888547, 1.5433217, 1.4609804]\n",
      "Batch 615/700: Discriminator loss = 1.0940265655517578, GAN loss = [3.8466694, 1.5730885, 1.3893619]\n",
      "Batch 616/700: Discriminator loss = 1.0751503705978394, GAN loss = [3.8485014, 1.5696317, 1.3946751]\n",
      "Batch 617/700: Discriminator loss = 1.0790547132492065, GAN loss = [4.0976725, 1.6048301, 1.6086714]\n",
      "Batch 618/700: Discriminator loss = 1.112518072128296, GAN loss = [3.9157321, 1.6374724, 1.3941127]\n",
      "Batch 619/700: Discriminator loss = 1.111016869544983, GAN loss = [3.946248, 1.6308091, 1.4313095]\n",
      "Batch 620/700: Discriminator loss = 1.1210495233535767, GAN loss = [3.8842113, 1.6506613, 1.349428]\n",
      "Batch 621/700: Discriminator loss = 1.1144932508468628, GAN loss = [3.8209047, 1.6322656, 1.304525]\n",
      "Batch 622/700: Discriminator loss = 1.1088311672210693, GAN loss = [3.8469996, 1.6479949, 1.3149074]\n",
      "Batch 623/700: Discriminator loss = 1.1391748189926147, GAN loss = [3.822232, 1.6824074, 1.2557505]\n",
      "Batch 624/700: Discriminator loss = 1.1368464231491089, GAN loss = [3.6346436, 1.5687991, 1.181796]\n",
      "Batch 625/700: Discriminator loss = 1.177443504333496, GAN loss = [3.601162, 1.502987, 1.2141434]\n",
      "Batch 626/700: Discriminator loss = 1.2034274339675903, GAN loss = [3.5528097, 1.505075, 1.1637203]\n",
      "Batch 627/700: Discriminator loss = 1.1723761558532715, GAN loss = [3.6573622, 1.487571, 1.2857883]\n",
      "Batch 628/700: Discriminator loss = 1.161438226699829, GAN loss = [3.727578, 1.5214534, 1.3221288]\n",
      "Batch 629/700: Discriminator loss = 1.1423161029815674, GAN loss = [3.7554567, 1.5105643, 1.3608963]\n",
      "Batch 630/700: Discriminator loss = 1.108813762664795, GAN loss = [3.7691858, 1.5152153, 1.3699766]\n",
      "Batch 631/700: Discriminator loss = 1.0983942747116089, GAN loss = [3.7850614, 1.4654014, 1.435671]\n",
      "Batch 632/700: Discriminator loss = 1.054823637008667, GAN loss = [4.0356135, 1.4800072, 1.6716201]\n",
      "Batch 633/700: Discriminator loss = 1.1039502620697021, GAN loss = [4.020407, 1.4929283, 1.6434959]\n",
      "Batch 634/700: Discriminator loss = 1.0762580633163452, GAN loss = [4.1231976, 1.5079762, 1.731239]\n",
      "Batch 635/700: Discriminator loss = 1.1076769828796387, GAN loss = [4.0576153, 1.4765713, 1.6970595]\n",
      "Batch 636/700: Discriminator loss = 1.167445182800293, GAN loss = [3.7140806, 1.4660428, 1.3640443]\n",
      "Batch 637/700: Discriminator loss = 1.1846626996994019, GAN loss = [3.6470995, 1.4503325, 1.3127604]\n",
      "Batch 638/700: Discriminator loss = 1.1687203645706177, GAN loss = [3.8467722, 1.4521543, 1.5106065]\n",
      "Batch 639/700: Discriminator loss = 1.199364185333252, GAN loss = [3.6220036, 1.4894729, 1.2485217]\n",
      "Batch 640/700: Discriminator loss = 1.199419379234314, GAN loss = [3.6319222, 1.5033473, 1.2445678]\n",
      "Batch 641/700: Discriminator loss = 1.2276884317398071, GAN loss = [3.6491978, 1.5039536, 1.261238]\n",
      "Batch 642/700: Discriminator loss = 1.22664475440979, GAN loss = [3.8037221, 1.6033032, 1.3164139]\n",
      "Batch 643/700: Discriminator loss = 1.2494903802871704, GAN loss = [3.6691535, 1.6848432, 1.1003106]\n",
      "Batch 644/700: Discriminator loss = 1.2362383604049683, GAN loss = [3.6700222, 1.7396692, 1.0463674]\n",
      "Batch 645/700: Discriminator loss = 1.258523941040039, GAN loss = [3.7441838, 1.7974646, 1.0627513]\n",
      "Batch 646/700: Discriminator loss = 1.338491678237915, GAN loss = [3.6694374, 1.825925, 0.9595563]\n",
      "Batch 647/700: Discriminator loss = 1.2321155071258545, GAN loss = [3.6949904, 1.7358997, 1.075142]\n",
      "Batch 648/700: Discriminator loss = 1.2981998920440674, GAN loss = [3.5970223, 1.7116383, 1.0014377]\n",
      "Batch 649/700: Discriminator loss = 1.146104097366333, GAN loss = [3.7723114, 1.6198012, 1.268572]\n",
      "Batch 650/700: Discriminator loss = 1.2029999494552612, GAN loss = [3.6149137, 1.5518259, 1.179173]\n",
      "Batch 651/700: Discriminator loss = 1.1662368774414062, GAN loss = [3.639006, 1.5123593, 1.2427655]\n",
      "Batch 652/700: Discriminator loss = 1.1735807657241821, GAN loss = [3.8131788, 1.5556682, 1.3736683]\n",
      "Batch 653/700: Discriminator loss = 1.1172094345092773, GAN loss = [3.8391993, 1.5758028, 1.3795961]\n",
      "Batch 654/700: Discriminator loss = 1.1932063102722168, GAN loss = [3.6931698, 1.594079, 1.2153373]\n",
      "Batch 655/700: Discriminator loss = 1.1273705959320068, GAN loss = [3.7818224, 1.5854529, 1.3126668]\n",
      "Batch 656/700: Discriminator loss = 1.2244597673416138, GAN loss = [3.618992, 1.6298189, 1.1055353]\n",
      "Batch 657/700: Discriminator loss = 1.1608940362930298, GAN loss = [3.7024722, 1.5721506, 1.2467568]\n",
      "Batch 658/700: Discriminator loss = 1.1920931339263916, GAN loss = [3.4614532, 1.4923896, 1.0855591]\n",
      "Batch 659/700: Discriminator loss = 1.1775400638580322, GAN loss = [3.3661506, 1.4844364, 0.9982591]\n",
      "Batch 660/700: Discriminator loss = 1.2512949705123901, GAN loss = [3.1998715, 1.451653, 0.86480784]\n",
      "Batch 661/700: Discriminator loss = 1.1226518154144287, GAN loss = [3.3485842, 1.4097484, 1.0554689]\n",
      "Batch 662/700: Discriminator loss = 1.1428247690200806, GAN loss = [3.178036, 1.4160008, 0.8787107]\n",
      "Batch 663/700: Discriminator loss = 1.0985653400421143, GAN loss = [3.209242, 1.3878864, 0.9380738]\n",
      "Batch 664/700: Discriminator loss = 1.116540789604187, GAN loss = [3.3024197, 1.396605, 1.0225704]\n",
      "Batch 665/700: Discriminator loss = 1.0795551538467407, GAN loss = [3.2965672, 1.4078774, 1.0054791]\n",
      "Batch 666/700: Discriminator loss = 1.083130121231079, GAN loss = [3.3244863, 1.4122242, 1.029079]\n",
      "Batch 667/700: Discriminator loss = 1.0733108520507812, GAN loss = [3.4939368, 1.4513947, 1.1593828]\n",
      "Batch 668/700: Discriminator loss = 1.0165334939956665, GAN loss = [3.6026077, 1.4133475, 1.3061234]\n",
      "Batch 669/700: Discriminator loss = 1.0079529285430908, GAN loss = [3.820473, 1.4302306, 1.5071293]\n",
      "Batch 670/700: Discriminator loss = 0.9843213558197021, GAN loss = [3.8692636, 1.4425836, 1.5435926]\n",
      "Batch 671/700: Discriminator loss = 1.0346225500106812, GAN loss = [3.7678683, 1.4294575, 1.4553491]\n",
      "Batch 672/700: Discriminator loss = 1.0255088806152344, GAN loss = [3.7646122, 1.3775008, 1.5040759]\n",
      "Batch 673/700: Discriminator loss = 1.083385944366455, GAN loss = [3.6520174, 1.4290925, 1.3399168]\n",
      "Batch 674/700: Discriminator loss = 1.0382124185562134, GAN loss = [3.6467285, 1.370379, 1.3933674]\n",
      "Batch 675/700: Discriminator loss = 1.0468074083328247, GAN loss = [3.8828306, 1.3447703, 1.6551011]\n",
      "Batch 676/700: Discriminator loss = 1.101262092590332, GAN loss = [3.6867127, 1.3742523, 1.4295212]\n",
      "Batch 677/700: Discriminator loss = 1.0680439472198486, GAN loss = [3.8218818, 1.3629808, 1.5759783]\n",
      "Batch 678/700: Discriminator loss = 1.101662278175354, GAN loss = [3.7288406, 1.3726283, 1.4733013]\n",
      "Batch 679/700: Discriminator loss = 1.0695593357086182, GAN loss = [3.602463, 1.3208168, 1.3987465]\n",
      "Batch 680/700: Discriminator loss = 1.1709214448928833, GAN loss = [3.4613051, 1.3586653, 1.2197485]\n",
      "Batch 681/700: Discriminator loss = 1.1532741785049438, GAN loss = [3.48399, 1.4337704, 1.1673371]\n",
      "Batch 682/700: Discriminator loss = 1.103605031967163, GAN loss = [3.3932967, 1.3395592, 1.170863]\n",
      "Batch 683/700: Discriminator loss = 1.1930036544799805, GAN loss = [3.3434622, 1.3973407, 1.063259]\n",
      "Batch 684/700: Discriminator loss = 1.1073466539382935, GAN loss = [3.3032253, 1.3300253, 1.0903538]\n",
      "Batch 685/700: Discriminator loss = 1.1348049640655518, GAN loss = [3.2906506, 1.3284597, 1.0793718]\n",
      "Batch 686/700: Discriminator loss = 1.1264467239379883, GAN loss = [3.346749, 1.3429213, 1.1210409]\n",
      "Batch 687/700: Discriminator loss = 1.191299319267273, GAN loss = [3.1472454, 1.3005446, 0.96394676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 688/700: Discriminator loss = 1.1511695384979248, GAN loss = [3.2291946, 1.2781625, 1.0683032]\n",
      "Batch 689/700: Discriminator loss = 1.2139862775802612, GAN loss = [3.2092597, 1.3466529, 0.97989917]\n",
      "Batch 690/700: Discriminator loss = 1.17116379737854, GAN loss = [3.234749, 1.3330793, 1.0189767]\n",
      "Batch 691/700: Discriminator loss = 1.158934235572815, GAN loss = [3.1906314, 1.3157134, 0.992245]\n",
      "Batch 692/700: Discriminator loss = 1.1544324159622192, GAN loss = [3.2301028, 1.3673831, 0.9800711]\n",
      "Batch 693/700: Discriminator loss = 1.1444605588912964, GAN loss = [3.1839516, 1.3630506, 0.93828017]\n",
      "Batch 694/700: Discriminator loss = 1.174179196357727, GAN loss = [3.2348583, 1.393508, 0.9587628]\n",
      "Batch 695/700: Discriminator loss = 1.1583536863327026, GAN loss = [3.1948922, 1.3863056, 0.9260324]\n",
      "Batch 696/700: Discriminator loss = 1.1266528367996216, GAN loss = [3.3507774, 1.4052907, 1.0629648]\n",
      "Batch 697/700: Discriminator loss = 1.1758168935775757, GAN loss = [3.2893865, 1.417359, 0.9895354]\n",
      "Batch 698/700: Discriminator loss = 1.1441377401351929, GAN loss = [3.3589797, 1.4033685, 1.0731508]\n",
      "Batch 699/700: Discriminator loss = 1.152104139328003, GAN loss = [3.2475712, 1.3613293, 1.0038142]\n",
      "Batch 700/700: Discriminator loss = 1.1168441772460938, GAN loss = [3.2549117, 1.3209914, 1.0515207]\n",
      "Epoch 3/30\n",
      "Batch 1/700: Discriminator loss = 1.1313937902450562, GAN loss = [3.3103237, 1.3599869, 1.0679593]\n",
      "Batch 2/700: Discriminator loss = 1.1375336647033691, GAN loss = [3.3178558, 1.3210938, 1.1144071]\n",
      "Batch 3/700: Discriminator loss = 1.118099570274353, GAN loss = [3.3073316, 1.304495, 1.1205045]\n",
      "Batch 4/700: Discriminator loss = 1.0967918634414673, GAN loss = [3.2347488, 1.2733604, 1.0790838]\n",
      "Batch 5/700: Discriminator loss = 1.075278401374817, GAN loss = [3.4256067, 1.2963432, 1.2469906]\n",
      "Batch 6/700: Discriminator loss = 1.0710029602050781, GAN loss = [3.4585607, 1.3140484, 1.2622753]\n",
      "Batch 7/700: Discriminator loss = 1.0567935705184937, GAN loss = [3.452191, 1.3293829, 1.2406105]\n",
      "Batch 8/700: Discriminator loss = 1.0657497644424438, GAN loss = [3.4908752, 1.3256164, 1.2831028]\n",
      "Batch 9/700: Discriminator loss = 1.0577106475830078, GAN loss = [3.454632, 1.2878762, 1.2846413]\n",
      "Batch 10/700: Discriminator loss = 1.048274040222168, GAN loss = [3.582089, 1.3123399, 1.3876759]\n",
      "Batch 11/700: Discriminator loss = 1.041614055633545, GAN loss = [3.683392, 1.3613528, 1.440009]\n",
      "Batch 12/700: Discriminator loss = 1.0431371927261353, GAN loss = [3.6479888, 1.397136, 1.3688707]\n",
      "Batch 13/700: Discriminator loss = 1.0797224044799805, GAN loss = [3.4225657, 1.3442136, 1.1964151]\n",
      "Batch 14/700: Discriminator loss = 1.0727601051330566, GAN loss = [3.5498035, 1.3440555, 1.3238522]\n",
      "Batch 15/700: Discriminator loss = 1.0740177631378174, GAN loss = [3.578619, 1.3451663, 1.3515964]\n",
      "Batch 16/700: Discriminator loss = 1.0784999132156372, GAN loss = [3.495874, 1.341045, 1.2730087]\n",
      "Batch 17/700: Discriminator loss = 1.0638291835784912, GAN loss = [3.6964948, 1.3662956, 1.4484124]\n",
      "Batch 18/700: Discriminator loss = 1.055894374847412, GAN loss = [3.7374508, 1.3981801, 1.4575171]\n",
      "Batch 19/700: Discriminator loss = 1.0709116458892822, GAN loss = [3.57131, 1.3400421, 1.3495487]\n",
      "Batch 20/700: Discriminator loss = 1.061327338218689, GAN loss = [3.8413627, 1.4135087, 1.5461689]\n",
      "Batch 21/700: Discriminator loss = 1.045861005783081, GAN loss = [3.8697507, 1.4372003, 1.5509006]\n",
      "Batch 22/700: Discriminator loss = 1.067237377166748, GAN loss = [3.7893066, 1.4011723, 1.5065181]\n",
      "Batch 23/700: Discriminator loss = 1.0401891469955444, GAN loss = [3.9455297, 1.4050844, 1.6588576]\n",
      "Batch 24/700: Discriminator loss = 1.0537102222442627, GAN loss = [3.8816469, 1.3702817, 1.6297972]\n",
      "Batch 25/700: Discriminator loss = 1.110730528831482, GAN loss = [3.7354624, 1.3755072, 1.4784001]\n",
      "Batch 26/700: Discriminator loss = 1.0856910943984985, GAN loss = [3.8060956, 1.4162172, 1.5083355]\n",
      "Batch 27/700: Discriminator loss = 1.0459699630737305, GAN loss = [3.8994906, 1.3727007, 1.6452625]\n",
      "Batch 28/700: Discriminator loss = 1.0673481225967407, GAN loss = [4.121717, 1.4730251, 1.7671815]\n",
      "Batch 29/700: Discriminator loss = 1.0588973760604858, GAN loss = [4.0740485, 1.4551702, 1.7373914]\n",
      "Batch 30/700: Discriminator loss = 1.0711010694503784, GAN loss = [3.953056, 1.4240476, 1.6475363]\n",
      "Batch 31/700: Discriminator loss = 1.019447684288025, GAN loss = [4.2307935, 1.419305, 1.9300199]\n",
      "Batch 32/700: Discriminator loss = 0.981414794921875, GAN loss = [4.4370446, 1.4520998, 2.1034842]\n",
      "Batch 33/700: Discriminator loss = 1.0056554079055786, GAN loss = [4.3522387, 1.4882431, 1.9825532]\n",
      "Batch 34/700: Discriminator loss = 0.9989765286445618, GAN loss = [4.362817, 1.489036, 1.9923664]\n",
      "Batch 35/700: Discriminator loss = 0.9768822193145752, GAN loss = [4.5694304, 1.5270096, 2.1610336]\n",
      "Batch 36/700: Discriminator loss = 0.9609639048576355, GAN loss = [4.6252255, 1.533026, 2.2108407]\n",
      "Batch 37/700: Discriminator loss = 0.9594586491584778, GAN loss = [4.572204, 1.5770711, 2.1137943]\n",
      "Batch 38/700: Discriminator loss = 0.9677245020866394, GAN loss = [4.4269667, 1.5942003, 1.9514552]\n",
      "Batch 39/700: Discriminator loss = 0.9469693303108215, GAN loss = [4.560304, 1.5873941, 2.0916364]\n",
      "Batch 40/700: Discriminator loss = 0.9639921188354492, GAN loss = [4.53276, 1.65584, 1.9956903]\n",
      "Batch 41/700: Discriminator loss = 0.9996074438095093, GAN loss = [4.252713, 1.6313647, 1.7401543]\n",
      "Batch 42/700: Discriminator loss = 1.0246142148971558, GAN loss = [4.4205656, 1.8469532, 1.6924478]\n",
      "Batch 43/700: Discriminator loss = 0.9922859072685242, GAN loss = [4.2665095, 1.7047311, 1.680638]\n",
      "Batch 44/700: Discriminator loss = 1.0076197385787964, GAN loss = [4.2453184, 1.6420372, 1.7221602]\n",
      "Batch 45/700: Discriminator loss = 1.045233130455017, GAN loss = [4.306976, 1.7522597, 1.673616]\n",
      "Batch 46/700: Discriminator loss = 1.0232752561569214, GAN loss = [4.2560024, 1.6674926, 1.7074279]\n",
      "Batch 47/700: Discriminator loss = 1.0565178394317627, GAN loss = [4.339704, 1.7582977, 1.70035]\n",
      "Batch 48/700: Discriminator loss = 1.063410997390747, GAN loss = [4.4666424, 1.867807, 1.7178016]\n",
      "Batch 49/700: Discriminator loss = 1.0452089309692383, GAN loss = [4.6304545, 1.9553916, 1.7940658]\n",
      "Batch 50/700: Discriminator loss = 1.006569266319275, GAN loss = [4.7854495, 1.9724884, 1.9320124]\n",
      "Batch 51/700: Discriminator loss = 1.0541586875915527, GAN loss = [4.674836, 2.103242, 1.6906974]\n",
      "Batch 52/700: Discriminator loss = 1.0266540050506592, GAN loss = [4.8502803, 2.0951297, 1.8743184]\n",
      "Batch 53/700: Discriminator loss = 1.0476253032684326, GAN loss = [4.79957, 2.1471057, 1.7717]\n",
      "Batch 54/700: Discriminator loss = 1.1049295663833618, GAN loss = [4.599158, 2.1087072, 1.6097533]\n",
      "Batch 55/700: Discriminator loss = 1.1632708311080933, GAN loss = [4.38723, 2.1076014, 1.3989897]\n",
      "Batch 56/700: Discriminator loss = 1.2860655784606934, GAN loss = [4.16731, 2.0686834, 1.2180294]\n",
      "Batch 57/700: Discriminator loss = 1.2702395915985107, GAN loss = [3.9569333, 1.8561935, 1.2201543]\n",
      "Batch 58/700: Discriminator loss = 1.291571021080017, GAN loss = [3.9007285, 1.8123146, 1.2078212]\n",
      "Batch 59/700: Discriminator loss = 1.193568468093872, GAN loss = [3.8400521, 1.7795362, 1.1799207]\n",
      "Batch 60/700: Discriminator loss = 1.1971657276153564, GAN loss = [4.1450953, 1.9184717, 1.3460406]\n",
      "Batch 61/700: Discriminator loss = 1.1468461751937866, GAN loss = [3.8628848, 1.8264242, 1.155898]\n",
      "Batch 62/700: Discriminator loss = 1.0757240056991577, GAN loss = [3.99671, 1.68752, 1.4286479]\n",
      "Batch 63/700: Discriminator loss = 1.1754913330078125, GAN loss = [3.8504298, 1.808386, 1.1615279]\n",
      "Batch 64/700: Discriminator loss = 1.0468385219573975, GAN loss = [4.1113777, 1.6865004, 1.5444043]\n",
      "Batch 65/700: Discriminator loss = 1.1612942218780518, GAN loss = [3.9734697, 1.8254067, 1.2676423]\n",
      "Batch 66/700: Discriminator loss = 1.0544898509979248, GAN loss = [4.148857, 1.7066925, 1.5618024]\n",
      "Batch 67/700: Discriminator loss = 1.1680078506469727, GAN loss = [4.0792394, 1.715591, 1.4833429]\n",
      "Batch 68/700: Discriminator loss = 1.2074077129364014, GAN loss = [4.0814333, 1.7302583, 1.4709098]\n",
      "Batch 69/700: Discriminator loss = 1.1888941526412964, GAN loss = [3.9493833, 1.7285144, 1.340628]\n",
      "Batch 70/700: Discriminator loss = 1.1390910148620605, GAN loss = [4.0098724, 1.7018825, 1.4277629]\n",
      "Batch 71/700: Discriminator loss = 1.1047337055206299, GAN loss = [4.104987, 1.6728078, 1.5519621]\n",
      "Batch 72/700: Discriminator loss = 1.137572169303894, GAN loss = [4.0801992, 1.6853873, 1.5146006]\n",
      "Batch 73/700: Discriminator loss = 1.183627963066101, GAN loss = [4.081128, 1.7018121, 1.4991119]\n",
      "Batch 74/700: Discriminator loss = 1.1485443115234375, GAN loss = [3.9168756, 1.559545, 1.477137]\n",
      "Batch 75/700: Discriminator loss = 1.190632700920105, GAN loss = [3.8001091, 1.5185347, 1.4013866]\n",
      "Batch 76/700: Discriminator loss = 1.1612703800201416, GAN loss = [3.8692393, 1.4838121, 1.5052407]\n",
      "Batch 77/700: Discriminator loss = 1.167392611503601, GAN loss = [4.0872836, 1.5141069, 1.6929841]\n",
      "Batch 78/700: Discriminator loss = 1.209032416343689, GAN loss = [3.797253, 1.470245, 1.4468071]\n",
      "Batch 79/700: Discriminator loss = 1.1581528186798096, GAN loss = [3.9572966, 1.4848591, 1.592231]\n",
      "Batch 80/700: Discriminator loss = 1.1226511001586914, GAN loss = [3.9933453, 1.5382526, 1.5748857]\n",
      "Batch 81/700: Discriminator loss = 1.226649284362793, GAN loss = [3.6156108, 1.5158126, 1.2195961]\n",
      "Batch 82/700: Discriminator loss = 1.1558138132095337, GAN loss = [3.6914995, 1.5012976, 1.3100013]\n",
      "Batch 83/700: Discriminator loss = 1.2190907001495361, GAN loss = [3.8273747, 1.6442546, 1.3029244]\n",
      "Batch 84/700: Discriminator loss = 1.1934216022491455, GAN loss = [3.6786222, 1.5679414, 1.2305002]\n",
      "Batch 85/700: Discriminator loss = 1.2241219282150269, GAN loss = [3.5937076, 1.5619473, 1.1516002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 86/700: Discriminator loss = 1.2868497371673584, GAN loss = [3.4766061, 1.5414138, 1.0550514]\n",
      "Batch 87/700: Discriminator loss = 1.3460756540298462, GAN loss = [3.408699, 1.5640991, 0.9644678]\n",
      "Batch 88/700: Discriminator loss = 1.2511199712753296, GAN loss = [3.4043663, 1.5483289, 0.97590166]\n",
      "Batch 89/700: Discriminator loss = 1.3063699007034302, GAN loss = [3.3251882, 1.5059552, 0.9390886]\n",
      "Batch 90/700: Discriminator loss = 1.2540949583053589, GAN loss = [3.315471, 1.4706252, 0.964705]\n",
      "Batch 91/700: Discriminator loss = 1.1973729133605957, GAN loss = [3.3501766, 1.4596968, 1.0103545]\n",
      "Batch 92/700: Discriminator loss = 1.186789870262146, GAN loss = [3.3218524, 1.4607437, 0.9810129]\n",
      "Batch 93/700: Discriminator loss = 1.1667661666870117, GAN loss = [3.3836954, 1.4310732, 1.0725667]\n",
      "Batch 94/700: Discriminator loss = 1.1385153532028198, GAN loss = [3.3473845, 1.43928, 1.0280894]\n",
      "Batch 95/700: Discriminator loss = 1.165921688079834, GAN loss = [3.2653165, 1.4088995, 0.9764439]\n",
      "Batch 96/700: Discriminator loss = 1.1602810621261597, GAN loss = [3.300717, 1.3871019, 1.033684]\n",
      "Batch 97/700: Discriminator loss = 1.1502708196640015, GAN loss = [3.321469, 1.3548584, 1.086721]\n",
      "Batch 98/700: Discriminator loss = 1.1527124643325806, GAN loss = [3.2317784, 1.3510784, 1.0008488]\n",
      "Batch 99/700: Discriminator loss = 1.1838747262954712, GAN loss = [3.1066139, 1.3555218, 0.87127656]\n",
      "Batch 100/700: Discriminator loss = 1.1576273441314697, GAN loss = [3.1371129, 1.3431826, 0.9141457]\n",
      "Batch 101/700: Discriminator loss = 1.146865963935852, GAN loss = [3.2461283, 1.3540139, 1.0123612]\n",
      "Batch 102/700: Discriminator loss = 1.1275473833084106, GAN loss = [3.2092435, 1.3302596, 0.9992618]\n",
      "Batch 103/700: Discriminator loss = 1.1577153205871582, GAN loss = [3.1563098, 1.3415842, 0.9350349]\n",
      "Batch 104/700: Discriminator loss = 1.1535463333129883, GAN loss = [3.1567445, 1.3198962, 0.95718795]\n",
      "Batch 105/700: Discriminator loss = 1.1324737071990967, GAN loss = [3.1386602, 1.2931143, 0.96591467]\n",
      "Batch 106/700: Discriminator loss = 1.1016108989715576, GAN loss = [3.2682755, 1.3215653, 1.0671058]\n",
      "Batch 107/700: Discriminator loss = 1.0938608646392822, GAN loss = [3.232697, 1.3099699, 1.043145]\n",
      "Batch 108/700: Discriminator loss = 1.0918186902999878, GAN loss = [3.3368332, 1.375666, 1.0816061]\n",
      "Batch 109/700: Discriminator loss = 1.0987581014633179, GAN loss = [3.2897658, 1.3668418, 1.0433801]\n",
      "Batch 110/700: Discriminator loss = 1.1161361932754517, GAN loss = [3.186952, 1.3274963, 0.97992593]\n",
      "Batch 111/700: Discriminator loss = 1.0782521963119507, GAN loss = [3.3120139, 1.3250258, 1.1074717]\n",
      "Batch 112/700: Discriminator loss = 1.0853493213653564, GAN loss = [3.3753343, 1.3634213, 1.1324075]\n",
      "Batch 113/700: Discriminator loss = 1.0691395998001099, GAN loss = [3.4027362, 1.3491769, 1.1740625]\n",
      "Batch 114/700: Discriminator loss = 1.0367388725280762, GAN loss = [3.5592587, 1.3679918, 1.3117763]\n",
      "Batch 115/700: Discriminator loss = 1.0354735851287842, GAN loss = [3.5296109, 1.3626648, 1.287464]\n",
      "Batch 116/700: Discriminator loss = 1.0259073972702026, GAN loss = [3.7162151, 1.3959662, 1.4407761]\n",
      "Batch 117/700: Discriminator loss = 1.0757339000701904, GAN loss = [3.5692062, 1.4008695, 1.2888757]\n",
      "Batch 118/700: Discriminator loss = 1.0363541841506958, GAN loss = [3.6354854, 1.3718898, 1.3841417]\n",
      "Batch 119/700: Discriminator loss = 1.061668038368225, GAN loss = [3.6907551, 1.396054, 1.4152532]\n",
      "Batch 120/700: Discriminator loss = 1.070386290550232, GAN loss = [3.5683446, 1.3698134, 1.3190898]\n",
      "Batch 121/700: Discriminator loss = 1.0598280429840088, GAN loss = [3.5687816, 1.3574792, 1.3318689]\n",
      "Batch 122/700: Discriminator loss = 1.0792536735534668, GAN loss = [3.5213418, 1.3197254, 1.322193]\n",
      "Batch 123/700: Discriminator loss = 1.0860050916671753, GAN loss = [3.598508, 1.3190546, 1.400043]\n",
      "Batch 124/700: Discriminator loss = 1.0806505680084229, GAN loss = [3.7164927, 1.3491572, 1.4879413]\n",
      "Batch 125/700: Discriminator loss = 1.0634711980819702, GAN loss = [3.8244762, 1.3661776, 1.5789232]\n",
      "Batch 126/700: Discriminator loss = 1.0584282875061035, GAN loss = [3.7318707, 1.3826175, 1.4698982]\n",
      "Batch 127/700: Discriminator loss = 1.081794023513794, GAN loss = [3.5930233, 1.3766348, 1.3370546]\n",
      "Batch 128/700: Discriminator loss = 1.052227258682251, GAN loss = [3.8134074, 1.417776, 1.5163202]\n",
      "Batch 129/700: Discriminator loss = 1.0475941896438599, GAN loss = [3.7653034, 1.397892, 1.4881288]\n",
      "Batch 130/700: Discriminator loss = 1.0198131799697876, GAN loss = [3.8146293, 1.4152117, 1.5201669]\n",
      "Batch 131/700: Discriminator loss = 1.0412750244140625, GAN loss = [3.7937012, 1.3745832, 1.5399019]\n",
      "Batch 132/700: Discriminator loss = 1.0364595651626587, GAN loss = [3.8244019, 1.4057437, 1.539475]\n",
      "Batch 133/700: Discriminator loss = 1.051573634147644, GAN loss = [3.7759786, 1.4028533, 1.4939789]\n",
      "Batch 134/700: Discriminator loss = 1.0668898820877075, GAN loss = [3.818227, 1.4103147, 1.5288]\n",
      "Batch 135/700: Discriminator loss = 1.0894652605056763, GAN loss = [3.5936255, 1.3919028, 1.3226411]\n",
      "Batch 136/700: Discriminator loss = 1.0611878633499146, GAN loss = [3.6439865, 1.3848405, 1.3800921]\n",
      "Batch 137/700: Discriminator loss = 1.0762428045272827, GAN loss = [3.7828555, 1.3974509, 1.5063826]\n",
      "Batch 138/700: Discriminator loss = 1.028730869293213, GAN loss = [3.9664428, 1.3927279, 1.6947268]\n",
      "Batch 139/700: Discriminator loss = 1.0342507362365723, GAN loss = [3.9522552, 1.3679765, 1.705325]\n",
      "Batch 140/700: Discriminator loss = 1.06798255443573, GAN loss = [3.8636408, 1.4321454, 1.5525765]\n",
      "Batch 141/700: Discriminator loss = 1.0248339176177979, GAN loss = [3.8433022, 1.3779396, 1.5864778]\n",
      "Batch 142/700: Discriminator loss = 1.025542974472046, GAN loss = [3.905303, 1.3673439, 1.6591101]\n",
      "Batch 143/700: Discriminator loss = 1.022794246673584, GAN loss = [3.8851407, 1.4190049, 1.5873245]\n",
      "Batch 144/700: Discriminator loss = 1.0024619102478027, GAN loss = [4.0215178, 1.4757215, 1.6670227]\n",
      "Batch 145/700: Discriminator loss = 1.0300697088241577, GAN loss = [4.0262823, 1.4701086, 1.677434]\n",
      "Batch 146/700: Discriminator loss = 1.0257166624069214, GAN loss = [3.8237698, 1.4693877, 1.4756738]\n",
      "Batch 147/700: Discriminator loss = 1.0641112327575684, GAN loss = [3.96608, 1.4647774, 1.6226193]\n",
      "Batch 148/700: Discriminator loss = 1.0668492317199707, GAN loss = [3.9687781, 1.4542958, 1.6358194]\n",
      "Batch 149/700: Discriminator loss = 1.0904364585876465, GAN loss = [3.9807572, 1.4956627, 1.6064453]\n",
      "Batch 150/700: Discriminator loss = 1.0337063074111938, GAN loss = [3.9507074, 1.5246806, 1.5473865]\n",
      "Batch 151/700: Discriminator loss = 1.0512218475341797, GAN loss = [3.9989429, 1.52437, 1.5959463]\n",
      "Batch 152/700: Discriminator loss = 1.0736310482025146, GAN loss = [3.950724, 1.5366623, 1.5354477]\n",
      "Batch 153/700: Discriminator loss = 1.0951389074325562, GAN loss = [3.8633842, 1.5312696, 1.45352]\n",
      "Batch 154/700: Discriminator loss = 1.0985854864120483, GAN loss = [3.765756, 1.4977306, 1.3894429]\n",
      "Batch 155/700: Discriminator loss = 1.1221736669540405, GAN loss = [3.8457577, 1.4884028, 1.4787831]\n",
      "Batch 156/700: Discriminator loss = 1.1180180311203003, GAN loss = [3.7735202, 1.493747, 1.4012069]\n",
      "Batch 157/700: Discriminator loss = 1.1677998304367065, GAN loss = [3.8558052, 1.4970876, 1.4801607]\n",
      "Batch 158/700: Discriminator loss = 1.1765376329421997, GAN loss = [3.7009118, 1.5172517, 1.3051047]\n",
      "Batch 159/700: Discriminator loss = 1.147796392440796, GAN loss = [3.714317, 1.460102, 1.3756604]\n",
      "Batch 160/700: Discriminator loss = 1.2318241596221924, GAN loss = [3.5416868, 1.4651918, 1.1979312]\n",
      "Batch 161/700: Discriminator loss = 1.2016407251358032, GAN loss = [3.4979815, 1.4136195, 1.2057824]\n",
      "Batch 162/700: Discriminator loss = 1.1852505207061768, GAN loss = [3.5701296, 1.4306985, 1.260831]\n",
      "Batch 163/700: Discriminator loss = 1.2080265283584595, GAN loss = [3.541762, 1.3802092, 1.2829378]\n",
      "Batch 164/700: Discriminator loss = 1.1708800792694092, GAN loss = [3.4429898, 1.3677533, 1.1966077]\n",
      "Batch 165/700: Discriminator loss = 1.1886175870895386, GAN loss = [3.4509761, 1.3726915, 1.1996479]\n",
      "Batch 166/700: Discriminator loss = 1.135588526725769, GAN loss = [3.5853527, 1.3754866, 1.3312273]\n",
      "Batch 167/700: Discriminator loss = 1.174038290977478, GAN loss = [3.5185719, 1.3761176, 1.263819]\n",
      "Batch 168/700: Discriminator loss = 1.2038406133651733, GAN loss = [3.3827028, 1.3633553, 1.1407167]\n",
      "Batch 169/700: Discriminator loss = 1.2140915393829346, GAN loss = [3.512671, 1.477149, 1.1568928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 170/700: Discriminator loss = 1.213334560394287, GAN loss = [3.3585827, 1.4295528, 1.0503972]\n",
      "Batch 171/700: Discriminator loss = 1.2137547731399536, GAN loss = [3.4022808, 1.486559, 1.0370784]\n",
      "Batch 172/700: Discriminator loss = 1.24329674243927, GAN loss = [3.3658617, 1.5433311, 0.9438751]\n",
      "Batch 173/700: Discriminator loss = 1.2019973993301392, GAN loss = [3.3561606, 1.4897139, 0.9877783]\n",
      "Batch 174/700: Discriminator loss = 1.2054541110992432, GAN loss = [3.3385637, 1.5081677, 0.9517166]\n",
      "Batch 175/700: Discriminator loss = 1.1103298664093018, GAN loss = [3.478885, 1.4927028, 1.1074979]\n",
      "Batch 176/700: Discriminator loss = 1.1501784324645996, GAN loss = [3.4614804, 1.5147098, 1.068087]\n",
      "Batch 177/700: Discriminator loss = 1.1286245584487915, GAN loss = [3.585676, 1.5325446, 1.1744547]\n",
      "Batch 178/700: Discriminator loss = 1.0500208139419556, GAN loss = [3.706502, 1.4741759, 1.3536572]\n",
      "Batch 179/700: Discriminator loss = 1.1605539321899414, GAN loss = [3.532357, 1.4795523, 1.1741481]\n",
      "Batch 180/700: Discriminator loss = 1.1079018115997314, GAN loss = [3.6138096, 1.4373878, 1.2977805]\n",
      "Batch 181/700: Discriminator loss = 1.0706220865249634, GAN loss = [3.9534366, 1.4546256, 1.6201893]\n",
      "Batch 182/700: Discriminator loss = 1.1134685277938843, GAN loss = [3.680724, 1.4404451, 1.3616743]\n",
      "Batch 183/700: Discriminator loss = 1.059536337852478, GAN loss = [3.825286, 1.3877931, 1.5589054]\n",
      "Batch 184/700: Discriminator loss = 1.0525225400924683, GAN loss = [3.920131, 1.3814843, 1.6600776]\n",
      "Batch 185/700: Discriminator loss = 1.0695573091506958, GAN loss = [3.9739811, 1.3894151, 1.7060161]\n",
      "Batch 186/700: Discriminator loss = 1.1163113117218018, GAN loss = [3.7826848, 1.3548878, 1.5492702]\n",
      "Batch 187/700: Discriminator loss = 1.101075530052185, GAN loss = [3.6867516, 1.3496675, 1.458582]\n",
      "Batch 188/700: Discriminator loss = 1.1119755506515503, GAN loss = [3.8881788, 1.3563521, 1.6533514]\n",
      "Batch 189/700: Discriminator loss = 1.1357499361038208, GAN loss = [3.5945709, 1.3293908, 1.3867334]\n",
      "Batch 190/700: Discriminator loss = 1.1594759225845337, GAN loss = [3.5233996, 1.3107165, 1.3342595]\n",
      "Batch 191/700: Discriminator loss = 1.2190124988555908, GAN loss = [3.5513515, 1.3224504, 1.350494]\n",
      "Batch 192/700: Discriminator loss = 1.2802345752716064, GAN loss = [3.4354818, 1.3324214, 1.2246652]\n",
      "Batch 193/700: Discriminator loss = 1.2386749982833862, GAN loss = [3.3750784, 1.300694, 1.195991]\n",
      "Batch 194/700: Discriminator loss = 1.223786473274231, GAN loss = [3.3934143, 1.2875274, 1.2274946]\n",
      "Batch 195/700: Discriminator loss = 1.1953754425048828, GAN loss = [3.4433062, 1.2908887, 1.2740246]\n",
      "Batch 196/700: Discriminator loss = 1.2010289430618286, GAN loss = [3.3708723, 1.2873163, 1.2051625]\n",
      "Batch 197/700: Discriminator loss = 1.1759017705917358, GAN loss = [3.4431803, 1.2558059, 1.3089769]\n",
      "Batch 198/700: Discriminator loss = 1.1582410335540771, GAN loss = [3.4963412, 1.2742227, 1.3437107]\n",
      "Batch 199/700: Discriminator loss = 1.154890537261963, GAN loss = [3.5699933, 1.2588192, 1.4327567]\n",
      "Batch 200/700: Discriminator loss = 1.1404587030410767, GAN loss = [3.566988, 1.2666016, 1.4219673]\n",
      "Batch 201/700: Discriminator loss = 1.1300491094589233, GAN loss = [3.6116278, 1.3794465, 1.353764]\n",
      "Batch 202/700: Discriminator loss = 1.1481214761734009, GAN loss = [3.6712322, 1.2930908, 1.4997337]\n",
      "Batch 203/700: Discriminator loss = 1.1516119241714478, GAN loss = [3.742384, 1.2801845, 1.5838009]\n",
      "Batch 204/700: Discriminator loss = 1.1784967184066772, GAN loss = [3.8501825, 1.3516836, 1.6201122]\n",
      "Batch 205/700: Discriminator loss = 1.163283109664917, GAN loss = [3.5835867, 1.3044467, 1.400761]\n",
      "Batch 206/700: Discriminator loss = 1.2515051364898682, GAN loss = [3.51135, 1.3397616, 1.2932129]\n",
      "Batch 207/700: Discriminator loss = 1.2340664863586426, GAN loss = [3.4081502, 1.4258903, 1.1038826]\n",
      "Batch 208/700: Discriminator loss = 1.2999011278152466, GAN loss = [3.121568, 1.299917, 0.9432711]\n",
      "Batch 209/700: Discriminator loss = 1.1746766567230225, GAN loss = [3.2386823, 1.2953988, 1.0649016]\n",
      "Batch 210/700: Discriminator loss = 1.2526159286499023, GAN loss = [3.2256575, 1.3578792, 0.989399]\n",
      "Batch 211/700: Discriminator loss = 1.1711872816085815, GAN loss = [3.2013204, 1.2528411, 1.0701038]\n",
      "Batch 212/700: Discriminator loss = 1.2059390544891357, GAN loss = [3.0128655, 1.2406715, 0.8938269]\n",
      "Batch 213/700: Discriminator loss = 1.1945098638534546, GAN loss = [3.05815, 1.2189491, 0.96084833]\n",
      "Batch 214/700: Discriminator loss = 1.1828913688659668, GAN loss = [3.1398423, 1.2748168, 0.9866919]\n",
      "Batch 215/700: Discriminator loss = 1.1773649454116821, GAN loss = [3.0945988, 1.2705055, 0.9457803]\n",
      "Batch 216/700: Discriminator loss = 1.1637502908706665, GAN loss = [3.0872743, 1.2495781, 0.95940363]\n",
      "Batch 217/700: Discriminator loss = 1.1638234853744507, GAN loss = [3.0716598, 1.2472296, 0.94615996]\n",
      "Batch 218/700: Discriminator loss = 1.1263673305511475, GAN loss = [3.107599, 1.2486542, 0.9806951]\n",
      "Batch 219/700: Discriminator loss = 1.1593753099441528, GAN loss = [3.1184015, 1.2653503, 0.9748241]\n",
      "Batch 220/700: Discriminator loss = 1.107269287109375, GAN loss = [3.1610043, 1.2253752, 1.0574275]\n",
      "Batch 221/700: Discriminator loss = 1.1174026727676392, GAN loss = [3.234385, 1.28062, 1.075586]\n",
      "Batch 222/700: Discriminator loss = 1.1451581716537476, GAN loss = [3.0961056, 1.2330191, 0.98492604]\n",
      "Batch 223/700: Discriminator loss = 1.090628743171692, GAN loss = [3.2041802, 1.2207897, 1.1052446]\n",
      "Batch 224/700: Discriminator loss = 1.1302839517593384, GAN loss = [3.205664, 1.233863, 1.0936661]\n",
      "Batch 225/700: Discriminator loss = 1.1625093221664429, GAN loss = [3.1911278, 1.211538, 1.1014628]\n",
      "Batch 226/700: Discriminator loss = 1.1339191198349, GAN loss = [3.2140934, 1.2213943, 1.1145724]\n",
      "Batch 227/700: Discriminator loss = 1.191656470298767, GAN loss = [3.2038543, 1.2197686, 1.1059562]\n",
      "Batch 228/700: Discriminator loss = 1.1735427379608154, GAN loss = [3.0935519, 1.1880975, 1.0273154]\n",
      "Batch 229/700: Discriminator loss = 1.1940727233886719, GAN loss = [3.1720376, 1.2223738, 1.0715146]\n",
      "Batch 230/700: Discriminator loss = 1.1890079975128174, GAN loss = [3.045358, 1.1389428, 1.0282532]\n",
      "Batch 231/700: Discriminator loss = 1.1870768070220947, GAN loss = [3.1209981, 1.2115154, 1.0313054]\n",
      "Batch 232/700: Discriminator loss = 1.1933302879333496, GAN loss = [3.0620718, 1.2007473, 0.98313093]\n",
      "Batch 233/700: Discriminator loss = 1.2082414627075195, GAN loss = [3.062929, 1.2171286, 0.96759725]\n",
      "Batch 234/700: Discriminator loss = 1.1792601346969604, GAN loss = [3.086419, 1.1873304, 1.0208786]\n",
      "Batch 235/700: Discriminator loss = 1.1750526428222656, GAN loss = [3.1405058, 1.2069623, 1.0553304]\n",
      "Batch 236/700: Discriminator loss = 1.1852749586105347, GAN loss = [3.0292237, 1.2015512, 0.9494634]\n",
      "Batch 237/700: Discriminator loss = 1.1998592615127563, GAN loss = [3.0265567, 1.1671718, 0.98118514]\n",
      "Batch 238/700: Discriminator loss = 1.202277660369873, GAN loss = [3.088367, 1.2181202, 0.99205744]\n",
      "Batch 239/700: Discriminator loss = 1.1597875356674194, GAN loss = [3.0633392, 1.1978784, 0.9872783]\n",
      "Batch 240/700: Discriminator loss = 1.2063782215118408, GAN loss = [2.982275, 1.1812872, 0.9228137]\n",
      "Batch 241/700: Discriminator loss = 1.2448896169662476, GAN loss = [2.9299555, 1.1492118, 0.90257674]\n",
      "Batch 242/700: Discriminator loss = 1.2028262615203857, GAN loss = [2.921074, 1.1440706, 0.8988419]\n",
      "Batch 243/700: Discriminator loss = 1.2018238306045532, GAN loss = [2.9940526, 1.1396546, 0.97624624]\n",
      "Batch 244/700: Discriminator loss = 1.2146425247192383, GAN loss = [2.9220815, 1.1163406, 0.92759895]\n",
      "Batch 245/700: Discriminator loss = 1.196398138999939, GAN loss = [3.0771399, 1.1293404, 1.0696685]\n",
      "Batch 246/700: Discriminator loss = 1.1962931156158447, GAN loss = [3.0368917, 1.1253511, 1.0334196]\n",
      "Batch 247/700: Discriminator loss = 1.1775895357131958, GAN loss = [3.0478594, 1.14392, 1.0258288]\n",
      "Batch 248/700: Discriminator loss = 1.1850136518478394, GAN loss = [3.0764248, 1.1668664, 1.0314567]\n",
      "Batch 249/700: Discriminator loss = 1.156679630279541, GAN loss = [3.05908, 1.1415226, 1.0394689]\n",
      "Batch 250/700: Discriminator loss = 1.176889419555664, GAN loss = [3.0756855, 1.1383333, 1.0592786]\n",
      "Batch 251/700: Discriminator loss = 1.1825487613677979, GAN loss = [3.0505526, 1.1568327, 1.0156611]\n",
      "Batch 252/700: Discriminator loss = 1.1617982387542725, GAN loss = [3.173408, 1.1784936, 1.1168668]\n",
      "Batch 253/700: Discriminator loss = 1.1600139141082764, GAN loss = [3.2012296, 1.1768491, 1.1463472]\n",
      "Batch 254/700: Discriminator loss = 1.1793291568756104, GAN loss = [3.2164774, 1.2415522, 1.0969044]\n",
      "Batch 255/700: Discriminator loss = 1.1543656587600708, GAN loss = [3.2340534, 1.2082852, 1.1477576]\n",
      "Batch 256/700: Discriminator loss = 1.1364268064498901, GAN loss = [3.2184, 1.1927663, 1.1476341]\n",
      "Batch 257/700: Discriminator loss = 1.1847307682037354, GAN loss = [3.1605911, 1.1870006, 1.095609]\n",
      "Batch 258/700: Discriminator loss = 1.1676263809204102, GAN loss = [3.2746196, 1.1990718, 1.1975849]\n",
      "Batch 259/700: Discriminator loss = 1.2140048742294312, GAN loss = [3.1742907, 1.1761589, 1.1201882]\n",
      "Batch 260/700: Discriminator loss = 1.191906452178955, GAN loss = [3.1925504, 1.1983397, 1.1162847]\n",
      "Batch 261/700: Discriminator loss = 1.1974955797195435, GAN loss = [3.286846, 1.172171, 1.2367624]\n",
      "Batch 262/700: Discriminator loss = 1.2229808568954468, GAN loss = [3.3329937, 1.219603, 1.2354895]\n",
      "Batch 263/700: Discriminator loss = 1.2224489450454712, GAN loss = [3.2164378, 1.2068076, 1.1317424]\n",
      "Batch 264/700: Discriminator loss = 1.2162429094314575, GAN loss = [3.1771855, 1.1788322, 1.1204787]\n",
      "Batch 265/700: Discriminator loss = 1.2727943658828735, GAN loss = [3.0487826, 1.1955494, 0.9753766]\n",
      "Batch 266/700: Discriminator loss = 1.2437738180160522, GAN loss = [3.0806954, 1.1640207, 1.0388362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 267/700: Discriminator loss = 1.3121538162231445, GAN loss = [2.98867, 1.1823978, 0.9284568]\n",
      "Batch 268/700: Discriminator loss = 1.2186120748519897, GAN loss = [3.1896336, 1.2109494, 1.1008917]\n",
      "Batch 269/700: Discriminator loss = 1.2377649545669556, GAN loss = [2.9875724, 1.1899413, 0.91986114]\n",
      "Batch 270/700: Discriminator loss = 1.2581040859222412, GAN loss = [3.0464358, 1.2239013, 0.9447899]\n",
      "Batch 271/700: Discriminator loss = 1.2508049011230469, GAN loss = [3.1079147, 1.2638389, 0.966359]\n",
      "Batch 272/700: Discriminator loss = 1.225754976272583, GAN loss = [2.9314134, 1.1856178, 0.8681069]\n",
      "Batch 273/700: Discriminator loss = 1.2474210262298584, GAN loss = [2.9303544, 1.1757525, 0.87694055]\n",
      "Batch 274/700: Discriminator loss = 1.2274399995803833, GAN loss = [2.937432, 1.1475135, 0.9122824]\n",
      "Batch 275/700: Discriminator loss = 1.2295184135437012, GAN loss = [2.8839762, 1.1113158, 0.895047]\n",
      "Batch 276/700: Discriminator loss = 1.2174237966537476, GAN loss = [2.903165, 1.1133094, 0.9122627]\n",
      "Batch 277/700: Discriminator loss = 1.1947247982025146, GAN loss = [3.0391326, 1.1199105, 1.0416521]\n",
      "Batch 278/700: Discriminator loss = 1.201647400856018, GAN loss = [2.996316, 1.0943885, 1.0243796]\n",
      "Batch 279/700: Discriminator loss = 1.2012054920196533, GAN loss = [2.916422, 1.0846859, 0.95421255]\n",
      "Batch 280/700: Discriminator loss = 1.1991758346557617, GAN loss = [2.9602354, 1.0775003, 1.0052385]\n",
      "Batch 281/700: Discriminator loss = 1.180225133895874, GAN loss = [2.987089, 1.1082746, 1.001346]\n",
      "Batch 282/700: Discriminator loss = 1.1661579608917236, GAN loss = [3.025696, 1.10244, 1.0458188]\n",
      "Batch 283/700: Discriminator loss = 1.1944299936294556, GAN loss = [2.9379601, 1.091894, 0.96865964]\n",
      "Batch 284/700: Discriminator loss = 1.173121690750122, GAN loss = [2.9394362, 1.0895913, 0.9724682]\n",
      "Batch 285/700: Discriminator loss = 1.173962116241455, GAN loss = [2.9617026, 1.1130561, 0.9712994]\n",
      "Batch 286/700: Discriminator loss = 1.1845837831497192, GAN loss = [2.9638104, 1.1202676, 0.9662244]\n",
      "Batch 287/700: Discriminator loss = 1.1794300079345703, GAN loss = [2.970977, 1.099336, 0.9943506]\n",
      "Batch 288/700: Discriminator loss = 1.2026399374008179, GAN loss = [2.998693, 1.1432942, 0.97813445]\n",
      "Batch 289/700: Discriminator loss = 1.1406985521316528, GAN loss = [3.0883472, 1.1629533, 1.048157]\n",
      "Batch 290/700: Discriminator loss = 1.1339107751846313, GAN loss = [3.1954072, 1.1989442, 1.1192509]\n",
      "Batch 291/700: Discriminator loss = 1.1211789846420288, GAN loss = [3.1250894, 1.1714057, 1.0764941]\n",
      "Batch 292/700: Discriminator loss = 1.1561164855957031, GAN loss = [3.3593805, 1.2509285, 1.231285]\n",
      "Batch 293/700: Discriminator loss = 1.1003185510635376, GAN loss = [3.2341862, 1.243656, 1.1133821]\n",
      "Batch 294/700: Discriminator loss = 1.0922666788101196, GAN loss = [3.338846, 1.2620372, 1.1996771]\n",
      "Batch 295/700: Discriminator loss = 1.0969210863113403, GAN loss = [3.2241356, 1.2264137, 1.1206067]\n",
      "Batch 296/700: Discriminator loss = 1.086869716644287, GAN loss = [3.2710361, 1.2611287, 1.1328106]\n",
      "Batch 297/700: Discriminator loss = 1.0772533416748047, GAN loss = [3.376914, 1.2765161, 1.2233214]\n",
      "Batch 298/700: Discriminator loss = 1.0933574438095093, GAN loss = [3.3635082, 1.2511617, 1.2352942]\n",
      "Batch 299/700: Discriminator loss = 1.1111279726028442, GAN loss = [3.4115531, 1.2612226, 1.2733014]\n",
      "Batch 300/700: Discriminator loss = 1.1054786443710327, GAN loss = [3.3417447, 1.2993982, 1.1653386]\n",
      "Batch 301/700: Discriminator loss = 1.1432298421859741, GAN loss = [3.2098083, 1.2787683, 1.0540527]\n",
      "Batch 302/700: Discriminator loss = 1.0987651348114014, GAN loss = [3.371819, 1.2764542, 1.218393]\n",
      "Batch 303/700: Discriminator loss = 1.1198256015777588, GAN loss = [3.3601556, 1.2664008, 1.2167987]\n",
      "Batch 304/700: Discriminator loss = 1.1687250137329102, GAN loss = [3.2485194, 1.2587614, 1.1128147]\n",
      "Batch 305/700: Discriminator loss = 1.103515625, GAN loss = [3.3032684, 1.2863383, 1.1400023]\n",
      "Batch 306/700: Discriminator loss = 1.1306941509246826, GAN loss = [3.1806931, 1.2590215, 1.0447638]\n",
      "Batch 307/700: Discriminator loss = 1.0894495248794556, GAN loss = [3.396426, 1.2695098, 1.250033]\n",
      "Batch 308/700: Discriminator loss = 1.145274043083191, GAN loss = [3.1852872, 1.2695254, 1.0389081]\n",
      "Batch 309/700: Discriminator loss = 1.1292213201522827, GAN loss = [3.2192779, 1.2431091, 1.0993482]\n",
      "Batch 310/700: Discriminator loss = 1.1062769889831543, GAN loss = [3.3304474, 1.2810845, 1.1725763]\n",
      "Batch 311/700: Discriminator loss = 1.1186339855194092, GAN loss = [3.311372, 1.2674556, 1.1671648]\n",
      "Batch 312/700: Discriminator loss = 1.0978081226348877, GAN loss = [3.4432507, 1.2956177, 1.2709148]\n",
      "Batch 313/700: Discriminator loss = 1.104292631149292, GAN loss = [3.2414641, 1.2659541, 1.0988268]\n",
      "Batch 314/700: Discriminator loss = 1.1157753467559814, GAN loss = [3.285721, 1.2712038, 1.13787]\n",
      "Batch 315/700: Discriminator loss = 1.101536750793457, GAN loss = [3.4625614, 1.3002195, 1.2857324]\n",
      "Batch 316/700: Discriminator loss = 1.1217068433761597, GAN loss = [3.2782855, 1.2962602, 1.1054524]\n",
      "Batch 317/700: Discriminator loss = 1.1091861724853516, GAN loss = [3.3216906, 1.2963295, 1.1488267]\n",
      "Batch 318/700: Discriminator loss = 1.0963687896728516, GAN loss = [3.3540697, 1.3094778, 1.1680951]\n",
      "Batch 319/700: Discriminator loss = 1.127539873123169, GAN loss = [3.1850984, 1.2423874, 1.0662507]\n",
      "Batch 320/700: Discriminator loss = 1.1336965560913086, GAN loss = [3.2989051, 1.266884, 1.155593]\n",
      "Batch 321/700: Discriminator loss = 1.135346531867981, GAN loss = [3.2905917, 1.254965, 1.1592261]\n",
      "Batch 322/700: Discriminator loss = 1.1343967914581299, GAN loss = [3.2760317, 1.2787322, 1.120924]\n",
      "Batch 323/700: Discriminator loss = 1.082249641418457, GAN loss = [3.3692703, 1.3080858, 1.1848309]\n",
      "Batch 324/700: Discriminator loss = 1.097997784614563, GAN loss = [3.2291267, 1.2705368, 1.0822562]\n",
      "Batch 325/700: Discriminator loss = 1.1034818887710571, GAN loss = [3.2679157, 1.283171, 1.1084329]\n",
      "Batch 326/700: Discriminator loss = 1.068461537361145, GAN loss = [3.3680065, 1.3065175, 1.1852026]\n",
      "Batch 327/700: Discriminator loss = 1.0677224397659302, GAN loss = [3.2733567, 1.3269633, 1.0701367]\n",
      "Batch 328/700: Discriminator loss = 1.071351408958435, GAN loss = [3.2881992, 1.3027639, 1.1092095]\n",
      "Batch 329/700: Discriminator loss = 1.0577422380447388, GAN loss = [3.4421995, 1.3370575, 1.2289501]\n",
      "Batch 330/700: Discriminator loss = 1.0508882999420166, GAN loss = [3.398551, 1.3021653, 1.2202284]\n",
      "Batch 331/700: Discriminator loss = 1.0732804536819458, GAN loss = [3.4669125, 1.3588086, 1.2319809]\n",
      "Batch 332/700: Discriminator loss = 1.0663201808929443, GAN loss = [3.4808345, 1.3307971, 1.273946]\n",
      "Batch 333/700: Discriminator loss = 1.0181974172592163, GAN loss = [3.4855373, 1.3518312, 1.2576442]\n",
      "Batch 334/700: Discriminator loss = 1.047942876815796, GAN loss = [3.4877126, 1.3704077, 1.2412754]\n",
      "Batch 335/700: Discriminator loss = 1.0614527463912964, GAN loss = [3.5791323, 1.3704507, 1.332683]\n",
      "Batch 336/700: Discriminator loss = 1.0657495260238647, GAN loss = [3.5609705, 1.357219, 1.3277802]\n",
      "Batch 337/700: Discriminator loss = 1.0640827417373657, GAN loss = [3.665717, 1.3960918, 1.3936794]\n",
      "Batch 338/700: Discriminator loss = 1.0428602695465088, GAN loss = [3.710507, 1.4176172, 1.4169677]\n",
      "Batch 339/700: Discriminator loss = 1.0602657794952393, GAN loss = [3.6373386, 1.3886299, 1.372807]\n",
      "Batch 340/700: Discriminator loss = 1.0637482404708862, GAN loss = [3.7083921, 1.4111272, 1.4213811]\n",
      "Batch 341/700: Discriminator loss = 1.022778868675232, GAN loss = [3.7854037, 1.4134218, 1.4961135]\n",
      "Batch 342/700: Discriminator loss = 1.062235713005066, GAN loss = [3.6443863, 1.4257413, 1.3427929]\n",
      "Batch 343/700: Discriminator loss = 1.0758651494979858, GAN loss = [3.596911, 1.4947689, 1.226303]\n",
      "Batch 344/700: Discriminator loss = 1.0624078512191772, GAN loss = [3.7457156, 1.4389353, 1.4309562]\n",
      "Batch 345/700: Discriminator loss = 1.0818331241607666, GAN loss = [3.6570477, 1.4731221, 1.3081166]\n",
      "Batch 346/700: Discriminator loss = 1.1124769449234009, GAN loss = [3.54166, 1.4364166, 1.2294525]\n",
      "Batch 347/700: Discriminator loss = 1.1179838180541992, GAN loss = [3.748989, 1.513169, 1.3600476]\n",
      "Batch 348/700: Discriminator loss = 1.0586488246917725, GAN loss = [3.6760879, 1.4601984, 1.3401337]\n",
      "Batch 349/700: Discriminator loss = 1.0605660676956177, GAN loss = [3.7819948, 1.463224, 1.4430339]\n",
      "Batch 350/700: Discriminator loss = 1.0741733312606812, GAN loss = [3.5628183, 1.4795005, 1.2076067]\n",
      "Batch 351/700: Discriminator loss = 1.12166428565979, GAN loss = [3.6507967, 1.5188928, 1.2562243]\n",
      "Batch 352/700: Discriminator loss = 1.083389163017273, GAN loss = [3.6309762, 1.4847395, 1.2705916]\n",
      "Batch 353/700: Discriminator loss = 1.1237772703170776, GAN loss = [3.5308912, 1.5158688, 1.139413]\n",
      "Batch 354/700: Discriminator loss = 1.1227710247039795, GAN loss = [3.5093327, 1.5207976, 1.1129594]\n",
      "Batch 355/700: Discriminator loss = 1.0790212154388428, GAN loss = [3.6415904, 1.5071151, 1.2589315]\n",
      "Batch 356/700: Discriminator loss = 1.1336538791656494, GAN loss = [3.5785599, 1.5279166, 1.1751324]\n",
      "Batch 357/700: Discriminator loss = 1.082350730895996, GAN loss = [3.4941442, 1.4700279, 1.1486387]\n",
      "Batch 358/700: Discriminator loss = 1.0688226222991943, GAN loss = [3.6751273, 1.5023887, 1.297294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 359/700: Discriminator loss = 1.0685815811157227, GAN loss = [3.8032024, 1.5635053, 1.3642879]\n",
      "Batch 360/700: Discriminator loss = 1.0344161987304688, GAN loss = [3.7551985, 1.5676094, 1.3122171]\n",
      "Batch 361/700: Discriminator loss = 1.0466841459274292, GAN loss = [3.6634238, 1.5028573, 1.2852297]\n",
      "Batch 362/700: Discriminator loss = 1.0138689279556274, GAN loss = [3.9002824, 1.5583705, 1.4666079]\n",
      "Batch 363/700: Discriminator loss = 1.0524425506591797, GAN loss = [3.6955512, 1.577731, 1.2425462]\n",
      "Batch 364/700: Discriminator loss = 1.0290579795837402, GAN loss = [3.7537582, 1.5650064, 1.3135083]\n",
      "Batch 365/700: Discriminator loss = 1.0313844680786133, GAN loss = [3.6764138, 1.5700581, 1.2311416]\n",
      "Batch 366/700: Discriminator loss = 1.0526903867721558, GAN loss = [3.755553, 1.5887125, 1.2916582]\n",
      "Batch 367/700: Discriminator loss = 1.0139657258987427, GAN loss = [3.9173486, 1.6311331, 1.4110647]\n",
      "Batch 368/700: Discriminator loss = 1.0009068250656128, GAN loss = [4.1234484, 1.6884683, 1.559862]\n",
      "Batch 369/700: Discriminator loss = 0.9968112111091614, GAN loss = [3.9754512, 1.6338652, 1.4665016]\n",
      "Batch 370/700: Discriminator loss = 1.020357370376587, GAN loss = [3.908016, 1.6769776, 1.3559872]\n",
      "Batch 371/700: Discriminator loss = 1.004997968673706, GAN loss = [4.088508, 1.6987933, 1.5146976]\n",
      "Batch 372/700: Discriminator loss = 1.0180286169052124, GAN loss = [4.0180583, 1.6961157, 1.4469588]\n",
      "Batch 373/700: Discriminator loss = 0.9636884331703186, GAN loss = [4.1647887, 1.6914014, 1.5984399]\n",
      "Batch 374/700: Discriminator loss = 1.02720308303833, GAN loss = [3.9440572, 1.6583132, 1.4108304]\n",
      "Batch 375/700: Discriminator loss = 1.0540194511413574, GAN loss = [3.875158, 1.7003436, 1.2999294]\n",
      "Batch 376/700: Discriminator loss = 1.0328197479248047, GAN loss = [3.9209833, 1.6675338, 1.3785882]\n",
      "Batch 377/700: Discriminator loss = 1.0795811414718628, GAN loss = [3.688911, 1.6675172, 1.1465561]\n",
      "Batch 378/700: Discriminator loss = 1.1137759685516357, GAN loss = [3.7767959, 1.6772748, 1.2247075]\n",
      "Batch 379/700: Discriminator loss = 1.1012638807296753, GAN loss = [3.820293, 1.6749387, 1.2705661]\n",
      "Batch 380/700: Discriminator loss = 1.1722264289855957, GAN loss = [3.6423986, 1.6368735, 1.1307586]\n",
      "Batch 381/700: Discriminator loss = 1.0586495399475098, GAN loss = [3.7656648, 1.5683391, 1.3225769]\n",
      "Batch 382/700: Discriminator loss = 1.1219205856323242, GAN loss = [3.5590603, 1.5761726, 1.1081574]\n",
      "Batch 383/700: Discriminator loss = 1.0933531522750854, GAN loss = [3.5765848, 1.5803686, 1.1215065]\n",
      "Batch 384/700: Discriminator loss = 1.0732430219650269, GAN loss = [3.5795763, 1.5325595, 1.1723305]\n",
      "Batch 385/700: Discriminator loss = 1.0645672082901, GAN loss = [3.6852188, 1.5370983, 1.2734592]\n",
      "Batch 386/700: Discriminator loss = 1.0489089488983154, GAN loss = [3.7387636, 1.5355202, 1.3286064]\n",
      "Batch 387/700: Discriminator loss = 1.0418431758880615, GAN loss = [3.6212442, 1.5079936, 1.2386404]\n",
      "Batch 388/700: Discriminator loss = 1.0475342273712158, GAN loss = [3.6515465, 1.5125537, 1.2644101]\n",
      "Batch 389/700: Discriminator loss = 1.0542018413543701, GAN loss = [3.718405, 1.5215583, 1.3222934]\n",
      "Batch 390/700: Discriminator loss = 1.0626393556594849, GAN loss = [3.6891766, 1.5625197, 1.25213]\n",
      "Batch 391/700: Discriminator loss = 1.0667222738265991, GAN loss = [3.6184812, 1.5257744, 1.2182046]\n",
      "Batch 392/700: Discriminator loss = 1.0880790948867798, GAN loss = [3.6178339, 1.4992516, 1.2441005]\n",
      "Batch 393/700: Discriminator loss = 1.0794163942337036, GAN loss = [3.639051, 1.512563, 1.2520194]\n",
      "Batch 394/700: Discriminator loss = 1.0884606838226318, GAN loss = [3.687842, 1.5330336, 1.2803513]\n",
      "Batch 395/700: Discriminator loss = 1.0937204360961914, GAN loss = [3.6291428, 1.5153718, 1.2393279]\n",
      "Batch 396/700: Discriminator loss = 1.0739586353302002, GAN loss = [3.603999, 1.4989339, 1.230633]\n",
      "Batch 397/700: Discriminator loss = 1.083691120147705, GAN loss = [3.574635, 1.509776, 1.1904384]\n",
      "Batch 398/700: Discriminator loss = 1.1027436256408691, GAN loss = [3.5845027, 1.5387964, 1.1712959]\n",
      "Batch 399/700: Discriminator loss = 1.039987564086914, GAN loss = [3.7915196, 1.5416626, 1.3754588]\n",
      "Batch 400/700: Discriminator loss = 1.0550391674041748, GAN loss = [3.7768705, 1.5594854, 1.3430017]\n",
      "Batch 401/700: Discriminator loss = 1.0706861019134521, GAN loss = [3.74639, 1.5697724, 1.3022516]\n",
      "Batch 402/700: Discriminator loss = 1.059428334236145, GAN loss = [3.7842453, 1.5778862, 1.3320096]\n",
      "Batch 403/700: Discriminator loss = 1.025604009628296, GAN loss = [3.9527378, 1.5614829, 1.5169177]\n",
      "Batch 404/700: Discriminator loss = 1.0209776163101196, GAN loss = [3.9193962, 1.5539863, 1.4910834]\n",
      "Batch 405/700: Discriminator loss = 1.0762965679168701, GAN loss = [3.772543, 1.5849501, 1.3132793]\n",
      "Batch 406/700: Discriminator loss = 1.0298811197280884, GAN loss = [4.121411, 1.6272827, 1.6198318]\n",
      "Batch 407/700: Discriminator loss = 1.051021933555603, GAN loss = [3.946632, 1.6199166, 1.4524391]\n",
      "Batch 408/700: Discriminator loss = 1.0308600664138794, GAN loss = [3.912536, 1.6253772, 1.4129004]\n",
      "Batch 409/700: Discriminator loss = 1.0859038829803467, GAN loss = [3.9535685, 1.6827301, 1.3965977]\n",
      "Batch 410/700: Discriminator loss = 1.0551844835281372, GAN loss = [3.951672, 1.6693714, 1.4080806]\n",
      "Batch 411/700: Discriminator loss = 1.0143225193023682, GAN loss = [4.046872, 1.6877316, 1.4849439]\n",
      "Batch 412/700: Discriminator loss = 1.0658135414123535, GAN loss = [4.0483885, 1.7697699, 1.4044483]\n",
      "Batch 413/700: Discriminator loss = 1.0502599477767944, GAN loss = [3.873221, 1.7016635, 1.2974138]\n",
      "Batch 414/700: Discriminator loss = 1.0628999471664429, GAN loss = [3.9595273, 1.7456053, 1.3398014]\n",
      "Batch 415/700: Discriminator loss = 1.0609909296035767, GAN loss = [3.8548675, 1.7076477, 1.2731212]\n",
      "Batch 416/700: Discriminator loss = 1.0733318328857422, GAN loss = [3.9456713, 1.8009381, 1.2706538]\n",
      "Batch 417/700: Discriminator loss = 1.0757296085357666, GAN loss = [3.9114475, 1.7280095, 1.3093816]\n",
      "Batch 418/700: Discriminator loss = 1.0305432081222534, GAN loss = [4.1063337, 1.7779597, 1.4543391]\n",
      "Batch 419/700: Discriminator loss = 1.0792549848556519, GAN loss = [4.056635, 1.7890515, 1.3935732]\n",
      "Batch 420/700: Discriminator loss = 1.0605535507202148, GAN loss = [3.963539, 1.7849493, 1.3046051]\n",
      "Batch 421/700: Discriminator loss = 1.0206639766693115, GAN loss = [4.114061, 1.7691598, 1.4709418]\n",
      "Batch 422/700: Discriminator loss = 1.0635693073272705, GAN loss = [4.129299, 1.7982478, 1.4571137]\n",
      "Batch 423/700: Discriminator loss = 1.0855145454406738, GAN loss = [4.1176543, 1.7633244, 1.4804138]\n",
      "Batch 424/700: Discriminator loss = 1.080695390701294, GAN loss = [4.2422214, 1.8657193, 1.5026126]\n",
      "Batch 425/700: Discriminator loss = 1.0113946199417114, GAN loss = [4.1323414, 1.8050267, 1.4534519]\n",
      "Batch 426/700: Discriminator loss = 0.9928793907165527, GAN loss = [4.4325323, 1.8930589, 1.6656427]\n",
      "Batch 427/700: Discriminator loss = 1.0014125108718872, GAN loss = [4.346238, 1.859964, 1.6124814]\n",
      "Batch 428/700: Discriminator loss = 0.9845154285430908, GAN loss = [4.487079, 1.884174, 1.7291553]\n",
      "Batch 429/700: Discriminator loss = 0.986720860004425, GAN loss = [4.4683843, 1.8562741, 1.7384028]\n",
      "Batch 430/700: Discriminator loss = 1.0340113639831543, GAN loss = [4.447477, 1.9659175, 1.60789]\n",
      "Batch 431/700: Discriminator loss = 0.986138105392456, GAN loss = [4.6631336, 1.8929602, 1.8965372]\n",
      "Batch 432/700: Discriminator loss = 1.0356248617172241, GAN loss = [4.47293, 1.8787439, 1.7205774]\n",
      "Batch 433/700: Discriminator loss = 1.0724161863327026, GAN loss = [4.396487, 1.9678007, 1.5551023]\n",
      "Batch 434/700: Discriminator loss = 1.0347576141357422, GAN loss = [4.443052, 1.8818706, 1.6876184]\n",
      "Batch 435/700: Discriminator loss = 1.0528982877731323, GAN loss = [4.6001596, 1.8961267, 1.8304898]\n",
      "Batch 436/700: Discriminator loss = 1.0480128526687622, GAN loss = [4.2985935, 1.8074948, 1.6175759]\n",
      "Batch 437/700: Discriminator loss = 1.032274842262268, GAN loss = [4.38173, 1.8928285, 1.615407]\n",
      "Batch 438/700: Discriminator loss = 1.1556799411773682, GAN loss = [4.2811594, 1.9626453, 1.445052]\n",
      "Batch 439/700: Discriminator loss = 1.1224068403244019, GAN loss = [4.007905, 1.8477336, 1.286736]\n",
      "Batch 440/700: Discriminator loss = 1.0460309982299805, GAN loss = [4.0664124, 1.7645497, 1.4284596]\n",
      "Batch 441/700: Discriminator loss = 1.0196456909179688, GAN loss = [4.146334, 1.7132334, 1.5597296]\n",
      "Batch 442/700: Discriminator loss = 1.112598180770874, GAN loss = [3.969761, 1.7351323, 1.3612926]\n",
      "Batch 443/700: Discriminator loss = 1.0813941955566406, GAN loss = [4.035968, 1.7467772, 1.4158926]\n",
      "Batch 444/700: Discriminator loss = 1.0779969692230225, GAN loss = [4.044401, 1.7234899, 1.4476498]\n",
      "Batch 445/700: Discriminator loss = 1.0907233953475952, GAN loss = [3.890987, 1.7799793, 1.2377833]\n",
      "Batch 446/700: Discriminator loss = 1.0564950704574585, GAN loss = [4.0001407, 1.7250916, 1.4018663]\n",
      "Batch 447/700: Discriminator loss = 1.0526682138442993, GAN loss = [3.9177392, 1.6989864, 1.3456116]\n",
      "Batch 448/700: Discriminator loss = 1.0602171421051025, GAN loss = [3.9116955, 1.7324578, 1.3061382]\n",
      "Batch 449/700: Discriminator loss = 1.0509363412857056, GAN loss = [3.971135, 1.7353832, 1.3626869]\n",
      "Batch 450/700: Discriminator loss = 1.0479216575622559, GAN loss = [4.032114, 1.7413784, 1.4177065]\n",
      "Batch 451/700: Discriminator loss = 1.0369352102279663, GAN loss = [4.067677, 1.7332563, 1.4614251]\n",
      "Batch 452/700: Discriminator loss = 1.034651279449463, GAN loss = [4.054191, 1.6819434, 1.4992833]\n",
      "Batch 453/700: Discriminator loss = 1.0296434164047241, GAN loss = [4.0401974, 1.7320011, 1.4352626]\n",
      "Batch 454/700: Discriminator loss = 1.0175890922546387, GAN loss = [4.203241, 1.7162349, 1.6140969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 455/700: Discriminator loss = 1.0709916353225708, GAN loss = [4.198389, 1.8414966, 1.4840053]\n",
      "Batch 456/700: Discriminator loss = 1.0598995685577393, GAN loss = [3.8835812, 1.744726, 1.2659838]\n",
      "Batch 457/700: Discriminator loss = 1.0638655424118042, GAN loss = [3.9676185, 1.7772328, 1.3175339]\n",
      "Batch 458/700: Discriminator loss = 1.0776232481002808, GAN loss = [4.078308, 1.8013792, 1.4041009]\n",
      "Batch 459/700: Discriminator loss = 1.03300940990448, GAN loss = [4.054404, 1.7639875, 1.4176141]\n",
      "Batch 460/700: Discriminator loss = 1.0720927715301514, GAN loss = [3.9878836, 1.7846707, 1.3304377]\n",
      "Batch 461/700: Discriminator loss = 1.0224653482437134, GAN loss = [4.3235598, 1.778479, 1.6723293]\n",
      "Batch 462/700: Discriminator loss = 1.1385605335235596, GAN loss = [3.8319318, 1.81341, 1.1457932]\n",
      "Batch 463/700: Discriminator loss = 1.1054271459579468, GAN loss = [4.162305, 1.8743781, 1.4152185]\n",
      "Batch 464/700: Discriminator loss = 1.0670313835144043, GAN loss = [4.178897, 1.8169894, 1.4892153]\n",
      "Batch 465/700: Discriminator loss = 1.0809756517410278, GAN loss = [4.077297, 1.8020009, 1.4026191]\n",
      "Batch 466/700: Discriminator loss = 1.149789810180664, GAN loss = [3.9561133, 1.7771014, 1.3063443]\n",
      "Batch 467/700: Discriminator loss = 1.0941215753555298, GAN loss = [4.015779, 1.7327267, 1.4103858]\n",
      "Batch 468/700: Discriminator loss = 1.1723071336746216, GAN loss = [3.8260062, 1.803283, 1.1500525]\n",
      "Batch 469/700: Discriminator loss = 1.1027237176895142, GAN loss = [3.9237773, 1.7299871, 1.321113]\n",
      "Batch 470/700: Discriminator loss = 1.1999726295471191, GAN loss = [3.88245, 1.8247586, 1.185004]\n",
      "Batch 471/700: Discriminator loss = 1.1089352369308472, GAN loss = [3.8193693, 1.7390345, 1.2076404]\n",
      "Batch 472/700: Discriminator loss = 1.149769902229309, GAN loss = [3.8966348, 1.775491, 1.248444]\n",
      "Batch 473/700: Discriminator loss = 1.1353607177734375, GAN loss = [3.7242262, 1.6993829, 1.1521406]\n",
      "Batch 474/700: Discriminator loss = 1.137770175933838, GAN loss = [3.8355234, 1.7411456, 1.2216773]\n",
      "Batch 475/700: Discriminator loss = 1.1584278345108032, GAN loss = [3.6107912, 1.676698, 1.0613952]\n",
      "Batch 476/700: Discriminator loss = 1.1665229797363281, GAN loss = [3.8281958, 1.7810526, 1.1744453]\n",
      "Batch 477/700: Discriminator loss = 1.209909439086914, GAN loss = [3.6746733, 1.6956581, 1.1063167]\n",
      "Batch 478/700: Discriminator loss = 1.1638940572738647, GAN loss = [3.7234957, 1.7256444, 1.1251496]\n",
      "Batch 479/700: Discriminator loss = 1.1718354225158691, GAN loss = [3.6495948, 1.680889, 1.0960046]\n",
      "Batch 480/700: Discriminator loss = 1.140211582183838, GAN loss = [3.5721326, 1.6289386, 1.0705056]\n",
      "Batch 481/700: Discriminator loss = 1.1001735925674438, GAN loss = [3.7866907, 1.699415, 1.214605]\n",
      "Batch 482/700: Discriminator loss = 1.1557278633117676, GAN loss = [3.7805595, 1.719381, 1.1885238]\n",
      "Batch 483/700: Discriminator loss = 1.1865341663360596, GAN loss = [3.6560712, 1.6994874, 1.0839391]\n",
      "Batch 484/700: Discriminator loss = 1.1622401475906372, GAN loss = [3.72643, 1.7069027, 1.1468881]\n",
      "Batch 485/700: Discriminator loss = 1.1860169172286987, GAN loss = [3.7234044, 1.7680352, 1.0827396]\n",
      "Batch 486/700: Discriminator loss = 1.179957389831543, GAN loss = [3.5888317, 1.6947936, 1.021418]\n",
      "Batch 487/700: Discriminator loss = 1.1800392866134644, GAN loss = [3.7803051, 1.7793813, 1.1283164]\n",
      "Batch 488/700: Discriminator loss = 1.1337472200393677, GAN loss = [3.7847219, 1.7194152, 1.1927112]\n",
      "Batch 489/700: Discriminator loss = 1.1821449995040894, GAN loss = [3.670778, 1.7173136, 1.0808854]\n",
      "Batch 490/700: Discriminator loss = 1.2138310670852661, GAN loss = [3.5421293, 1.6668495, 1.002718]\n",
      "Batch 491/700: Discriminator loss = 1.1668052673339844, GAN loss = [3.6435177, 1.6255116, 1.1454633]\n",
      "Batch 492/700: Discriminator loss = 1.1555557250976562, GAN loss = [3.722031, 1.6288315, 1.220675]\n",
      "Batch 493/700: Discriminator loss = 1.1493587493896484, GAN loss = [3.5378354, 1.5666466, 1.0986819]\n",
      "Batch 494/700: Discriminator loss = 1.1399122476577759, GAN loss = [3.6490817, 1.5374545, 1.2391489]\n",
      "Batch 495/700: Discriminator loss = 1.1330792903900146, GAN loss = [3.6541686, 1.5682387, 1.2134795]\n",
      "Batch 496/700: Discriminator loss = 1.100446105003357, GAN loss = [3.6677482, 1.5600125, 1.2353095]\n",
      "Batch 497/700: Discriminator loss = 1.1492518186569214, GAN loss = [3.7741714, 1.5726389, 1.3291292]\n",
      "Batch 498/700: Discriminator loss = 1.1065318584442139, GAN loss = [3.6164033, 1.5115683, 1.2324497]\n",
      "Batch 499/700: Discriminator loss = 1.1495338678359985, GAN loss = [3.553911, 1.5311016, 1.1504363]\n",
      "Batch 500/700: Discriminator loss = 1.1735587120056152, GAN loss = [3.6726134, 1.5705693, 1.2296782]\n",
      "Batch 501/700: Discriminator loss = 1.1446177959442139, GAN loss = [3.633343, 1.5457208, 1.2152569]\n",
      "Batch 502/700: Discriminator loss = 1.0892970561981201, GAN loss = [3.795389, 1.5481027, 1.37492]\n",
      "Batch 503/700: Discriminator loss = 1.0691908597946167, GAN loss = [3.7276895, 1.5317189, 1.323609]\n",
      "Batch 504/700: Discriminator loss = 1.093267560005188, GAN loss = [3.7127109, 1.5179759, 1.3223898]\n",
      "Batch 505/700: Discriminator loss = 1.0983062982559204, GAN loss = [3.9074047, 1.5421774, 1.4929016]\n",
      "Batch 506/700: Discriminator loss = 1.0856484174728394, GAN loss = [3.8173597, 1.5221599, 1.4229004]\n",
      "Batch 507/700: Discriminator loss = 1.088620662689209, GAN loss = [3.9656386, 1.585356, 1.5080049]\n",
      "Batch 508/700: Discriminator loss = 1.1060492992401123, GAN loss = [3.7317264, 1.5373244, 1.3221413]\n",
      "Batch 509/700: Discriminator loss = 1.1000946760177612, GAN loss = [3.8279092, 1.5699563, 1.3857086]\n",
      "Batch 510/700: Discriminator loss = 1.1089136600494385, GAN loss = [3.6602502, 1.5560653, 1.2319543]\n",
      "Batch 511/700: Discriminator loss = 1.0610976219177246, GAN loss = [3.7550964, 1.5702568, 1.3126258]\n",
      "Batch 512/700: Discriminator loss = 1.1138845682144165, GAN loss = [3.804744, 1.5998013, 1.3327498]\n",
      "Batch 513/700: Discriminator loss = 1.1407023668289185, GAN loss = [3.6590846, 1.6138135, 1.1731015]\n",
      "Batch 514/700: Discriminator loss = 1.079471468925476, GAN loss = [3.8226504, 1.5957447, 1.3547604]\n",
      "Batch 515/700: Discriminator loss = 1.0811243057250977, GAN loss = [3.760333, 1.6002501, 1.2879611]\n",
      "Batch 516/700: Discriminator loss = 1.0926365852355957, GAN loss = [3.7479675, 1.5651021, 1.310771]\n",
      "Batch 517/700: Discriminator loss = 1.0929135084152222, GAN loss = [3.776826, 1.6008804, 1.3038772]\n",
      "Batch 518/700: Discriminator loss = 1.062729001045227, GAN loss = [3.6822011, 1.539616, 1.2705436]\n",
      "Batch 519/700: Discriminator loss = 1.1112439632415771, GAN loss = [3.7029831, 1.5628886, 1.2680823]\n",
      "Batch 520/700: Discriminator loss = 1.1024034023284912, GAN loss = [3.7031448, 1.5548728, 1.2762889]\n",
      "Batch 521/700: Discriminator loss = 1.1157941818237305, GAN loss = [3.7417712, 1.558227, 1.3115865]\n",
      "Batch 522/700: Discriminator loss = 1.1404606103897095, GAN loss = [3.6929052, 1.5700934, 1.2508754]\n",
      "Batch 523/700: Discriminator loss = 1.1041525602340698, GAN loss = [3.669235, 1.5121597, 1.2851562]\n",
      "Batch 524/700: Discriminator loss = 1.1945979595184326, GAN loss = [3.5589924, 1.5841682, 1.1029199]\n",
      "Batch 525/700: Discriminator loss = 1.1755083799362183, GAN loss = [3.4639163, 1.5135132, 1.0785141]\n",
      "Batch 526/700: Discriminator loss = 1.1880264282226562, GAN loss = [3.5019033, 1.5196965, 1.1103269]\n",
      "Batch 527/700: Discriminator loss = 1.1912649869918823, GAN loss = [3.4149318, 1.4469589, 1.0960993]\n",
      "Batch 528/700: Discriminator loss = 1.1402820348739624, GAN loss = [3.5451891, 1.4426978, 1.2306236]\n",
      "Batch 529/700: Discriminator loss = 1.139754056930542, GAN loss = [3.4562776, 1.4471511, 1.1372671]\n",
      "Batch 530/700: Discriminator loss = 1.1185442209243774, GAN loss = [3.6395376, 1.4766018, 1.2910882]\n",
      "Batch 531/700: Discriminator loss = 1.1699386835098267, GAN loss = [3.7581518, 1.5150017, 1.3713189]\n",
      "Batch 532/700: Discriminator loss = 1.05922532081604, GAN loss = [3.7565851, 1.5107245, 1.3740505]\n",
      "Batch 533/700: Discriminator loss = 1.1099693775177002, GAN loss = [3.6914985, 1.5199665, 1.2997468]\n",
      "Batch 534/700: Discriminator loss = 1.0939280986785889, GAN loss = [3.6418576, 1.5186435, 1.2514533]\n",
      "Batch 535/700: Discriminator loss = 1.0807687044143677, GAN loss = [3.6557245, 1.5411354, 1.242856]\n",
      "Batch 536/700: Discriminator loss = 1.1110155582427979, GAN loss = [3.7593567, 1.6061351, 1.2815181]\n",
      "Batch 537/700: Discriminator loss = 1.0871672630310059, GAN loss = [3.7457156, 1.6406753, 1.2333627]\n",
      "Batch 538/700: Discriminator loss = 1.1033833026885986, GAN loss = [3.6986768, 1.6449907, 1.182032]\n",
      "Batch 539/700: Discriminator loss = 1.0930390357971191, GAN loss = [3.90826, 1.7177974, 1.3188314]\n",
      "Batch 540/700: Discriminator loss = 1.0898780822753906, GAN loss = [3.719336, 1.6428006, 1.2049242]\n",
      "Batch 541/700: Discriminator loss = 1.1126978397369385, GAN loss = [3.6054265, 1.6504024, 1.0834328]\n",
      "Batch 542/700: Discriminator loss = 1.0402251482009888, GAN loss = [3.738842, 1.6275656, 1.239707]\n",
      "Batch 543/700: Discriminator loss = 1.0543237924575806, GAN loss = [3.8334975, 1.6945606, 1.2673936]\n",
      "Batch 544/700: Discriminator loss = 1.0681867599487305, GAN loss = [3.8138022, 1.6603379, 1.2819493]\n",
      "Batch 545/700: Discriminator loss = 1.0852782726287842, GAN loss = [3.8616579, 1.6901691, 1.3000009]\n",
      "Batch 546/700: Discriminator loss = 1.0866936445236206, GAN loss = [3.7103155, 1.7183609, 1.1204901]\n",
      "Batch 547/700: Discriminator loss = 1.086637258529663, GAN loss = [3.8661013, 1.7486567, 1.2459987]\n",
      "Batch 548/700: Discriminator loss = 1.120907187461853, GAN loss = [3.7104068, 1.6771376, 1.1618356]\n",
      "Batch 549/700: Discriminator loss = 1.091407060623169, GAN loss = [3.725325, 1.6636803, 1.1902128]\n",
      "Batch 550/700: Discriminator loss = 1.0632245540618896, GAN loss = [3.853323, 1.6776576, 1.3042312]\n",
      "Batch 551/700: Discriminator loss = 1.0683456659317017, GAN loss = [3.8054202, 1.6512531, 1.282736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 552/700: Discriminator loss = 1.0665892362594604, GAN loss = [3.8592303, 1.646008, 1.3418018]\n",
      "Batch 553/700: Discriminator loss = 1.0325769186019897, GAN loss = [3.83051, 1.5942175, 1.364891]\n",
      "Batch 554/700: Discriminator loss = 1.0797377824783325, GAN loss = [3.770917, 1.5990943, 1.3004419]\n",
      "Batch 555/700: Discriminator loss = 1.056260347366333, GAN loss = [3.9651587, 1.6405813, 1.4532162]\n",
      "Batch 556/700: Discriminator loss = 1.0749821662902832, GAN loss = [3.8491137, 1.5930438, 1.3847265]\n",
      "Batch 557/700: Discriminator loss = 1.1082783937454224, GAN loss = [3.9431431, 1.6008061, 1.4710109]\n",
      "Batch 558/700: Discriminator loss = 1.110673427581787, GAN loss = [3.7686772, 1.5987209, 1.2986426]\n",
      "Batch 559/700: Discriminator loss = 1.1628907918930054, GAN loss = [3.8627918, 1.670554, 1.3209343]\n",
      "Batch 560/700: Discriminator loss = 1.113730549812317, GAN loss = [3.7942348, 1.6259122, 1.2970266]\n",
      "Batch 561/700: Discriminator loss = 1.1551605463027954, GAN loss = [3.9020169, 1.6394962, 1.3912317]\n",
      "Batch 562/700: Discriminator loss = 1.1474984884262085, GAN loss = [3.6866083, 1.5836716, 1.2316551]\n",
      "Batch 563/700: Discriminator loss = 1.1704533100128174, GAN loss = [3.7663434, 1.6326901, 1.2623779]\n",
      "Batch 564/700: Discriminator loss = 1.154829502105713, GAN loss = [3.709488, 1.5854346, 1.252786]\n",
      "Batch 565/700: Discriminator loss = 1.20062255859375, GAN loss = [3.7526085, 1.6143413, 1.2670132]\n",
      "Batch 566/700: Discriminator loss = 1.1605596542358398, GAN loss = [3.6490853, 1.614664, 1.1631806]\n",
      "Batch 567/700: Discriminator loss = 1.0945954322814941, GAN loss = [3.6701365, 1.5234802, 1.2754308]\n",
      "Batch 568/700: Discriminator loss = 1.1459742784500122, GAN loss = [3.642642, 1.5177658, 1.2536685]\n",
      "Batch 569/700: Discriminator loss = 1.1146297454833984, GAN loss = [3.5869465, 1.4740225, 1.2417374]\n",
      "Batch 570/700: Discriminator loss = 1.136628270149231, GAN loss = [3.6223066, 1.5037953, 1.2473491]\n",
      "Batch 571/700: Discriminator loss = 1.0918744802474976, GAN loss = [3.7206933, 1.4557831, 1.3937739]\n",
      "Batch 572/700: Discriminator loss = 1.1558409929275513, GAN loss = [3.6070275, 1.4856294, 1.2502872]\n",
      "Batch 573/700: Discriminator loss = 1.1191538572311401, GAN loss = [3.763488, 1.4903446, 1.4020592]\n",
      "Batch 574/700: Discriminator loss = 1.1304161548614502, GAN loss = [3.5585744, 1.4516153, 1.2359004]\n",
      "Batch 575/700: Discriminator loss = 1.1685460805892944, GAN loss = [3.5589511, 1.4981432, 1.1897742]\n",
      "Batch 576/700: Discriminator loss = 1.0808430910110474, GAN loss = [3.7147286, 1.4643027, 1.3794129]\n",
      "Batch 577/700: Discriminator loss = 1.094099998474121, GAN loss = [3.7588577, 1.4597303, 1.4281323]\n",
      "Batch 578/700: Discriminator loss = 1.105623483657837, GAN loss = [3.6442409, 1.4423301, 1.3309314]\n",
      "Batch 579/700: Discriminator loss = 1.0923312902450562, GAN loss = [3.657377, 1.4884295, 1.2979789]\n",
      "Batch 580/700: Discriminator loss = 1.1038365364074707, GAN loss = [3.672472, 1.4659673, 1.3355526]\n",
      "Batch 581/700: Discriminator loss = 1.0829520225524902, GAN loss = [3.7195296, 1.4870776, 1.3615192]\n",
      "Batch 582/700: Discriminator loss = 1.0767220258712769, GAN loss = [3.8659172, 1.4817879, 1.5132223]\n",
      "Batch 583/700: Discriminator loss = 1.0926177501678467, GAN loss = [3.7893133, 1.4727767, 1.4456553]\n",
      "Batch 584/700: Discriminator loss = 1.0779333114624023, GAN loss = [3.945384, 1.5043575, 1.5701748]\n",
      "Batch 585/700: Discriminator loss = 1.0796396732330322, GAN loss = [3.902015, 1.5156931, 1.5154982]\n",
      "Batch 586/700: Discriminator loss = 1.1233162879943848, GAN loss = [3.7964935, 1.5037454, 1.4219524]\n",
      "Batch 587/700: Discriminator loss = 1.0879641771316528, GAN loss = [3.6640332, 1.4499952, 1.3432679]\n",
      "Batch 588/700: Discriminator loss = 1.1353886127471924, GAN loss = [3.7583547, 1.469686, 1.4179244]\n",
      "Batch 589/700: Discriminator loss = 1.1505690813064575, GAN loss = [3.7784746, 1.4595749, 1.4481813]\n",
      "Batch 590/700: Discriminator loss = 1.176577091217041, GAN loss = [3.4867625, 1.423765, 1.1923058]\n",
      "Batch 591/700: Discriminator loss = 1.0741994380950928, GAN loss = [3.8844721, 1.5051762, 1.5086273]\n",
      "Batch 592/700: Discriminator loss = 1.1219406127929688, GAN loss = [3.6117668, 1.4370356, 1.3040838]\n",
      "Batch 593/700: Discriminator loss = 1.160778522491455, GAN loss = [3.6451507, 1.4853302, 1.2891873]\n",
      "Batch 594/700: Discriminator loss = 1.1898090839385986, GAN loss = [3.546128, 1.4647343, 1.2107729]\n",
      "Batch 595/700: Discriminator loss = 1.131394863128662, GAN loss = [3.5395453, 1.4559435, 1.2129809]\n",
      "Batch 596/700: Discriminator loss = 1.1301864385604858, GAN loss = [3.5776305, 1.4884996, 1.2185079]\n",
      "Batch 597/700: Discriminator loss = 1.1765741109848022, GAN loss = [3.6727448, 1.5719414, 1.2301798]\n",
      "Batch 598/700: Discriminator loss = 1.0783231258392334, GAN loss = [3.733273, 1.5880139, 1.2746372]\n",
      "Batch 599/700: Discriminator loss = 1.0695618391036987, GAN loss = [3.9009905, 1.5918192, 1.4385576]\n",
      "Batch 600/700: Discriminator loss = 1.073511004447937, GAN loss = [3.7368786, 1.5116813, 1.3545909]\n",
      "Batch 601/700: Discriminator loss = 1.1022553443908691, GAN loss = [3.7121131, 1.5442141, 1.2972988]\n",
      "Batch 602/700: Discriminator loss = 1.0671051740646362, GAN loss = [3.8547492, 1.5401634, 1.4439914]\n",
      "Batch 603/700: Discriminator loss = 1.0469746589660645, GAN loss = [3.8598828, 1.5191584, 1.4701365]\n",
      "Batch 604/700: Discriminator loss = 1.0394343137741089, GAN loss = [4.1404467, 1.5743325, 1.6955371]\n",
      "Batch 605/700: Discriminator loss = 1.1143125295639038, GAN loss = [3.838614, 1.5891598, 1.3788867]\n",
      "Batch 606/700: Discriminator loss = 1.042999505996704, GAN loss = [4.0083823, 1.5537072, 1.5841194]\n",
      "Batch 607/700: Discriminator loss = 1.0715945959091187, GAN loss = [3.9375143, 1.5571373, 1.5098337]\n",
      "Batch 608/700: Discriminator loss = 1.0634845495224, GAN loss = [4.237888, 1.6307524, 1.7366093]\n",
      "Batch 609/700: Discriminator loss = 1.0249475240707397, GAN loss = [3.9570763, 1.586921, 1.4996458]\n",
      "Batch 610/700: Discriminator loss = 1.039689302444458, GAN loss = [4.1290765, 1.5943092, 1.6642717]\n",
      "Batch 611/700: Discriminator loss = 1.047001838684082, GAN loss = [4.0902047, 1.6594081, 1.560313]\n",
      "Batch 612/700: Discriminator loss = 1.034438133239746, GAN loss = [4.045253, 1.548142, 1.6266437]\n",
      "Batch 613/700: Discriminator loss = 1.027469515800476, GAN loss = [4.210063, 1.5865489, 1.7530655]\n",
      "Batch 614/700: Discriminator loss = 0.9909983277320862, GAN loss = [4.2541943, 1.6058078, 1.7779627]\n",
      "Batch 615/700: Discriminator loss = 1.0017907619476318, GAN loss = [4.2440996, 1.6092638, 1.764444]\n",
      "Batch 616/700: Discriminator loss = 1.0024805068969727, GAN loss = [4.256401, 1.6421957, 1.7438459]\n",
      "Batch 617/700: Discriminator loss = 1.001676321029663, GAN loss = [4.1551795, 1.632939, 1.6519166]\n",
      "Batch 618/700: Discriminator loss = 1.0303905010223389, GAN loss = [4.1066213, 1.6527246, 1.5836045]\n",
      "Batch 619/700: Discriminator loss = 0.9911993741989136, GAN loss = [4.238965, 1.6555334, 1.7131715]\n",
      "Batch 620/700: Discriminator loss = 1.0232759714126587, GAN loss = [4.1370974, 1.6316665, 1.6352044]\n",
      "Batch 621/700: Discriminator loss = 1.0463547706604004, GAN loss = [4.0590215, 1.6862019, 1.5026282]\n",
      "Batch 622/700: Discriminator loss = 0.984957218170166, GAN loss = [4.377092, 1.6903944, 1.8165375]\n",
      "Batch 623/700: Discriminator loss = 1.0071414709091187, GAN loss = [4.2031083, 1.7183723, 1.6146073]\n",
      "Batch 624/700: Discriminator loss = 1.0043423175811768, GAN loss = [4.1305356, 1.6877615, 1.5726776]\n",
      "Batch 625/700: Discriminator loss = 0.9779272079467773, GAN loss = [4.1150937, 1.6634232, 1.5816069]\n",
      "Batch 626/700: Discriminator loss = 1.010323166847229, GAN loss = [4.1435127, 1.6664474, 1.6070367]\n",
      "Batch 627/700: Discriminator loss = 1.0149072408676147, GAN loss = [4.287822, 1.7949638, 1.6228677]\n",
      "Batch 628/700: Discriminator loss = 0.9815956950187683, GAN loss = [4.4008913, 1.7635788, 1.7673589]\n",
      "Batch 629/700: Discriminator loss = 1.0069462060928345, GAN loss = [4.412758, 1.7926937, 1.7501465]\n",
      "Batch 630/700: Discriminator loss = 1.022848129272461, GAN loss = [4.082147, 1.7290765, 1.4831817]\n",
      "Batch 631/700: Discriminator loss = 1.0962436199188232, GAN loss = [4.1120687, 1.7824888, 1.4597167]\n",
      "Batch 632/700: Discriminator loss = 1.0437517166137695, GAN loss = [4.0505495, 1.7417929, 1.4389143]\n",
      "Batch 633/700: Discriminator loss = 1.0480108261108398, GAN loss = [4.1221333, 1.7085289, 1.5437831]\n",
      "Batch 634/700: Discriminator loss = 1.0458852052688599, GAN loss = [4.1603503, 1.7261055, 1.5644459]\n",
      "Batch 635/700: Discriminator loss = 1.0860544443130493, GAN loss = [4.166008, 1.7856749, 1.510556]\n",
      "Batch 636/700: Discriminator loss = 1.0389137268066406, GAN loss = [4.19472, 1.7759466, 1.5490154]\n",
      "Batch 637/700: Discriminator loss = 1.0882282257080078, GAN loss = [4.1943164, 1.8670768, 1.4575047]\n",
      "Batch 638/700: Discriminator loss = 1.062950849533081, GAN loss = [4.160526, 1.8620206, 1.4287871]\n",
      "Batch 639/700: Discriminator loss = 1.081884503364563, GAN loss = [4.074432, 1.822905, 1.3818197]\n",
      "Batch 640/700: Discriminator loss = 1.1100974082946777, GAN loss = [4.145838, 1.8840142, 1.3921204]\n",
      "Batch 641/700: Discriminator loss = 1.0458810329437256, GAN loss = [4.2113028, 1.8702996, 1.4713016]\n",
      "Batch 642/700: Discriminator loss = 1.0964161157608032, GAN loss = [4.18606, 1.9521539, 1.3642071]\n",
      "Batch 643/700: Discriminator loss = 1.0430724620819092, GAN loss = [4.4018216, 2.0216446, 1.5104818]\n",
      "Batch 644/700: Discriminator loss = 1.0342539548873901, GAN loss = [4.377909, 2.0031796, 1.5050446]\n",
      "Batch 645/700: Discriminator loss = 1.0344806909561157, GAN loss = [4.2803764, 1.9142345, 1.496466]\n",
      "Batch 646/700: Discriminator loss = 1.0096455812454224, GAN loss = [4.3182106, 1.8736116, 1.5749353]\n",
      "Batch 647/700: Discriminator loss = 1.0164817571640015, GAN loss = [4.448426, 1.8820935, 1.6966912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 648/700: Discriminator loss = 1.0351245403289795, GAN loss = [4.395235, 1.8856463, 1.6399701]\n",
      "Batch 649/700: Discriminator loss = 1.0604515075683594, GAN loss = [4.3184385, 1.8515183, 1.5973245]\n",
      "Batch 650/700: Discriminator loss = 1.0773053169250488, GAN loss = [4.3376594, 1.8609529, 1.6071336]\n",
      "Batch 651/700: Discriminator loss = 0.9996768832206726, GAN loss = [4.400643, 1.7770875, 1.7540045]\n",
      "Batch 652/700: Discriminator loss = 1.0980439186096191, GAN loss = [4.3058524, 1.9300182, 1.5063089]\n",
      "Batch 653/700: Discriminator loss = 1.0560132265090942, GAN loss = [4.3590164, 1.8414841, 1.6480407]\n",
      "Batch 654/700: Discriminator loss = 1.0490427017211914, GAN loss = [4.463287, 1.7996979, 1.7941414]\n",
      "Batch 655/700: Discriminator loss = 1.1321196556091309, GAN loss = [3.9755418, 1.8356034, 1.2705371]\n",
      "Batch 656/700: Discriminator loss = 1.123457908630371, GAN loss = [4.127762, 1.8216527, 1.436754]\n",
      "Batch 657/700: Discriminator loss = 1.0652087926864624, GAN loss = [4.007637, 1.7150007, 1.4233267]\n",
      "Batch 658/700: Discriminator loss = 1.1391959190368652, GAN loss = [3.9214938, 1.757884, 1.2943459]\n",
      "Batch 659/700: Discriminator loss = 1.1473220586776733, GAN loss = [3.8971317, 1.832317, 1.1956015]\n",
      "Batch 660/700: Discriminator loss = 1.1461552381515503, GAN loss = [3.8350525, 1.7420206, 1.2238677]\n",
      "Batch 661/700: Discriminator loss = 1.0689164400100708, GAN loss = [3.8648794, 1.6230184, 1.3727467]\n",
      "Batch 662/700: Discriminator loss = 1.1186721324920654, GAN loss = [3.9508235, 1.6733876, 1.4083714]\n",
      "Batch 663/700: Discriminator loss = 1.1582560539245605, GAN loss = [3.7943392, 1.7167224, 1.2086072]\n",
      "Batch 664/700: Discriminator loss = 1.07805335521698, GAN loss = [3.9105635, 1.6879443, 1.3536658]\n",
      "Batch 665/700: Discriminator loss = 1.0518901348114014, GAN loss = [4.0000334, 1.7325755, 1.3985682]\n",
      "Batch 666/700: Discriminator loss = 1.0684223175048828, GAN loss = [3.8665514, 1.6925213, 1.3052001]\n",
      "Batch 667/700: Discriminator loss = 1.1037087440490723, GAN loss = [3.8157873, 1.7549183, 1.1920955]\n",
      "Batch 668/700: Discriminator loss = 1.0918841361999512, GAN loss = [3.9687006, 1.7934265, 1.3065513]\n",
      "Batch 669/700: Discriminator loss = 1.0581653118133545, GAN loss = [3.8916771, 1.7437385, 1.2792673]\n",
      "Batch 670/700: Discriminator loss = 1.0453572273254395, GAN loss = [3.9544032, 1.8046037, 1.2811754]\n",
      "Batch 671/700: Discriminator loss = 1.0552866458892822, GAN loss = [3.9211397, 1.8135653, 1.2389944]\n",
      "Batch 672/700: Discriminator loss = 1.0657141208648682, GAN loss = [3.8693657, 1.8059998, 1.1948225]\n",
      "Batch 673/700: Discriminator loss = 1.0488792657852173, GAN loss = [4.128147, 1.9151078, 1.34453]\n",
      "Batch 674/700: Discriminator loss = 1.0420042276382446, GAN loss = [3.9261491, 1.8250515, 1.2326242]\n",
      "Batch 675/700: Discriminator loss = 1.0455381870269775, GAN loss = [4.0731316, 1.8954967, 1.3091992]\n",
      "Batch 676/700: Discriminator loss = 1.0270322561264038, GAN loss = [4.1148205, 1.897723, 1.3487041]\n",
      "Batch 677/700: Discriminator loss = 1.0575906038284302, GAN loss = [4.021082, 1.931243, 1.2214912]\n",
      "Batch 678/700: Discriminator loss = 0.9860870838165283, GAN loss = [4.208789, 1.8935117, 1.4469779]\n",
      "Batch 679/700: Discriminator loss = 1.0385980606079102, GAN loss = [4.1075397, 1.8426546, 1.3966286]\n",
      "Batch 680/700: Discriminator loss = 1.0332627296447754, GAN loss = [4.156453, 1.897013, 1.3912227]\n",
      "Batch 681/700: Discriminator loss = 1.0531269311904907, GAN loss = [3.991072, 1.8357337, 1.2871575]\n",
      "Batch 682/700: Discriminator loss = 1.0778918266296387, GAN loss = [4.0764933, 1.8506697, 1.357676]\n",
      "Batch 683/700: Discriminator loss = 1.037520408630371, GAN loss = [3.9764953, 1.7926375, 1.3157405]\n",
      "Batch 684/700: Discriminator loss = 1.0305284261703491, GAN loss = [3.9352171, 1.7726593, 1.2944694]\n",
      "Batch 685/700: Discriminator loss = 1.0963138341903687, GAN loss = [3.8990428, 1.7911077, 1.2398762]\n",
      "Batch 686/700: Discriminator loss = 1.0490529537200928, GAN loss = [3.9457257, 1.7436247, 1.3340697]\n",
      "Batch 687/700: Discriminator loss = 1.114305853843689, GAN loss = [4.006074, 1.8265395, 1.3115321]\n",
      "Batch 688/700: Discriminator loss = 1.0290592908859253, GAN loss = [3.929476, 1.6764587, 1.3850447]\n",
      "Batch 689/700: Discriminator loss = 1.0825477838516235, GAN loss = [3.9405437, 1.7033896, 1.3692119]\n",
      "Batch 690/700: Discriminator loss = 1.0480175018310547, GAN loss = [3.9575849, 1.6763215, 1.4133457]\n",
      "Batch 691/700: Discriminator loss = 1.1105918884277344, GAN loss = [3.7366521, 1.6633791, 1.2053772]\n",
      "Batch 692/700: Discriminator loss = 1.1036596298217773, GAN loss = [3.906321, 1.6708007, 1.36764]\n",
      "Batch 693/700: Discriminator loss = 1.1047272682189941, GAN loss = [3.7223573, 1.6135843, 1.2409095]\n",
      "Batch 694/700: Discriminator loss = 1.0597013235092163, GAN loss = [4.077809, 1.6262512, 1.5837109]\n",
      "Batch 695/700: Discriminator loss = 1.1187721490859985, GAN loss = [3.8395796, 1.5753855, 1.3963634]\n",
      "Batch 696/700: Discriminator loss = 1.1443697214126587, GAN loss = [3.8896928, 1.6305462, 1.3913308]\n",
      "Batch 697/700: Discriminator loss = 1.131983757019043, GAN loss = [3.7271955, 1.5798059, 1.279589]\n",
      "Batch 698/700: Discriminator loss = 1.130945086479187, GAN loss = [3.7237642, 1.5790253, 1.2769486]\n",
      "Batch 699/700: Discriminator loss = 1.1240044832229614, GAN loss = [3.7343764, 1.5746018, 1.2919946]\n",
      "Batch 700/700: Discriminator loss = 1.1083943843841553, GAN loss = [3.8636537, 1.5698307, 1.4260476]\n",
      "Epoch 4/30\n",
      "Batch 1/700: Discriminator loss = 1.1418358087539673, GAN loss = [3.797017, 1.5932873, 1.3359597]\n",
      "Batch 2/700: Discriminator loss = 1.087044358253479, GAN loss = [3.8639703, 1.5667872, 1.4294187]\n",
      "Batch 3/700: Discriminator loss = 1.1244378089904785, GAN loss = [3.7494571, 1.5843161, 1.297385]\n",
      "Batch 4/700: Discriminator loss = 1.1599712371826172, GAN loss = [3.6987462, 1.6820542, 1.1489491]\n",
      "Batch 5/700: Discriminator loss = 1.0882480144500732, GAN loss = [3.8451858, 1.6532352, 1.3242263]\n",
      "Batch 6/700: Discriminator loss = 1.1641958951950073, GAN loss = [3.8879876, 1.6981317, 1.3221515]\n",
      "Batch 7/700: Discriminator loss = 1.1563879251480103, GAN loss = [3.730784, 1.6248384, 1.2382604]\n",
      "Batch 8/700: Discriminator loss = 1.0871974229812622, GAN loss = [3.8112562, 1.6146642, 1.3289158]\n",
      "Batch 9/700: Discriminator loss = 1.211982011795044, GAN loss = [3.6037514, 1.6029997, 1.1330781]\n",
      "Batch 10/700: Discriminator loss = 1.2307990789413452, GAN loss = [3.75235, 1.5572014, 1.3274665]\n",
      "Batch 11/700: Discriminator loss = 1.1689651012420654, GAN loss = [3.8608751, 1.5481015, 1.4450873]\n",
      "Batch 12/700: Discriminator loss = 1.2334980964660645, GAN loss = [3.675794, 1.5043701, 1.3037274]\n",
      "Batch 13/700: Discriminator loss = 1.167486310005188, GAN loss = [3.8157585, 1.5017579, 1.446293]\n",
      "Batch 14/700: Discriminator loss = 1.1884207725524902, GAN loss = [3.672764, 1.5090295, 1.2960204]\n",
      "Batch 15/700: Discriminator loss = 1.1379708051681519, GAN loss = [3.6933649, 1.5216575, 1.3039889]\n",
      "Batch 16/700: Discriminator loss = 1.1082391738891602, GAN loss = [3.790097, 1.5199698, 1.4024062]\n",
      "Batch 17/700: Discriminator loss = 1.1360492706298828, GAN loss = [3.7733426, 1.5426702, 1.3629553]\n",
      "Batch 18/700: Discriminator loss = 1.1321333646774292, GAN loss = [3.8552954, 1.5828167, 1.4047683]\n",
      "Batch 19/700: Discriminator loss = 1.1462396383285522, GAN loss = [3.8490448, 1.590054, 1.3912897]\n",
      "Batch 20/700: Discriminator loss = 1.1674448251724243, GAN loss = [3.7618906, 1.5995717, 1.2946243]\n",
      "Batch 21/700: Discriminator loss = 1.1441422700881958, GAN loss = [3.8021553, 1.6336446, 1.3008252]\n",
      "Batch 22/700: Discriminator loss = 1.0977507829666138, GAN loss = [3.849656, 1.6020039, 1.3799767]\n",
      "Batch 23/700: Discriminator loss = 1.1512315273284912, GAN loss = [3.8058422, 1.6565077, 1.2816681]\n",
      "Batch 24/700: Discriminator loss = 1.0847371816635132, GAN loss = [3.7765682, 1.5954498, 1.3134593]\n",
      "Batch 25/700: Discriminator loss = 1.1571422815322876, GAN loss = [3.855669, 1.7441489, 1.2438726]\n",
      "Batch 26/700: Discriminator loss = 1.0888577699661255, GAN loss = [3.8073962, 1.6251023, 1.3146569]\n",
      "Batch 27/700: Discriminator loss = 1.1545637845993042, GAN loss = [3.861514, 1.6496769, 1.3442111]\n",
      "Batch 28/700: Discriminator loss = 1.1923571825027466, GAN loss = [3.8093798, 1.7159142, 1.2258474]\n",
      "Batch 29/700: Discriminator loss = 1.1910096406936646, GAN loss = [3.753144, 1.6581218, 1.2274082]\n",
      "Batch 30/700: Discriminator loss = 1.2035386562347412, GAN loss = [3.6669455, 1.6147913, 1.1845464]\n",
      "Batch 31/700: Discriminator loss = 1.218336820602417, GAN loss = [3.7271097, 1.633316, 1.2261885]\n",
      "Batch 32/700: Discriminator loss = 1.2011795043945312, GAN loss = [3.5604432, 1.5973346, 1.0955077]\n",
      "Batch 33/700: Discriminator loss = 1.1810798645019531, GAN loss = [3.6122227, 1.6053145, 1.1393113]\n",
      "Batch 34/700: Discriminator loss = 1.1989505290985107, GAN loss = [3.5964518, 1.6108662, 1.1179945]\n",
      "Batch 35/700: Discriminator loss = 1.2367466688156128, GAN loss = [3.6307743, 1.7065053, 1.0566896]\n",
      "Batch 36/700: Discriminator loss = 1.1335766315460205, GAN loss = [3.7008226, 1.6539961, 1.1792641]\n",
      "Batch 37/700: Discriminator loss = 1.1429535150527954, GAN loss = [3.780325, 1.7086792, 1.2041063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 38/700: Discriminator loss = 1.1254173517227173, GAN loss = [3.7917933, 1.6375221, 1.2867613]\n",
      "Batch 39/700: Discriminator loss = 1.1880419254302979, GAN loss = [3.6378303, 1.629084, 1.1412696]\n",
      "Batch 40/700: Discriminator loss = 1.1802996397018433, GAN loss = [3.6810951, 1.6016862, 1.2119626]\n",
      "Batch 41/700: Discriminator loss = 1.201094388961792, GAN loss = [3.6462934, 1.5556647, 1.2232122]\n",
      "Batch 42/700: Discriminator loss = 1.2186359167099, GAN loss = [3.6980875, 1.5767009, 1.2539995]\n",
      "Batch 43/700: Discriminator loss = 1.2337162494659424, GAN loss = [3.5613904, 1.5711074, 1.1229262]\n",
      "Batch 44/700: Discriminator loss = 1.1691151857376099, GAN loss = [3.669075, 1.5595958, 1.2421579]\n",
      "Batch 45/700: Discriminator loss = 1.1610080003738403, GAN loss = [3.7701352, 1.6136626, 1.2891874]\n",
      "Batch 46/700: Discriminator loss = 1.1901439428329468, GAN loss = [3.6235502, 1.5416043, 1.2147]\n",
      "Batch 47/700: Discriminator loss = 1.127134084701538, GAN loss = [3.640232, 1.4803128, 1.292709]\n",
      "Batch 48/700: Discriminator loss = 1.213240146636963, GAN loss = [3.5466135, 1.5654644, 1.1139759]\n",
      "Batch 49/700: Discriminator loss = 1.155990719795227, GAN loss = [3.6388474, 1.5391262, 1.2325847]\n",
      "Batch 50/700: Discriminator loss = 1.1635303497314453, GAN loss = [3.6594126, 1.5511963, 1.241118]\n",
      "Batch 51/700: Discriminator loss = 1.1277079582214355, GAN loss = [3.5839403, 1.5148538, 1.2020291]\n",
      "Batch 52/700: Discriminator loss = 1.170346975326538, GAN loss = [3.5872276, 1.5394826, 1.1807308]\n",
      "Batch 53/700: Discriminator loss = 1.189358115196228, GAN loss = [3.523176, 1.5074505, 1.1487552]\n",
      "Batch 54/700: Discriminator loss = 1.2121837139129639, GAN loss = [3.458519, 1.4561659, 1.1354227]\n",
      "Batch 55/700: Discriminator loss = 1.1965080499649048, GAN loss = [3.314907, 1.3718203, 1.0761915]\n",
      "Batch 56/700: Discriminator loss = 1.2177073955535889, GAN loss = [3.303952, 1.4197607, 1.017326]\n",
      "Batch 57/700: Discriminator loss = 1.1962839365005493, GAN loss = [3.3587105, 1.4085237, 1.0833504]\n",
      "Batch 58/700: Discriminator loss = 1.2137643098831177, GAN loss = [3.2000725, 1.3685973, 0.9646701]\n",
      "Batch 59/700: Discriminator loss = 1.1963505744934082, GAN loss = [3.3028426, 1.3725461, 1.0635165]\n",
      "Batch 60/700: Discriminator loss = 1.1855355501174927, GAN loss = [3.3777392, 1.3921298, 1.1188514]\n",
      "Batch 61/700: Discriminator loss = 1.154642939567566, GAN loss = [3.423097, 1.3806055, 1.1757512]\n",
      "Batch 62/700: Discriminator loss = 1.1700434684753418, GAN loss = [3.3224103, 1.3944973, 1.0611959]\n",
      "Batch 63/700: Discriminator loss = 1.1216566562652588, GAN loss = [3.4016666, 1.4217738, 1.1131985]\n",
      "Batch 64/700: Discriminator loss = 1.1146663427352905, GAN loss = [3.4645991, 1.4400358, 1.157895]\n",
      "Batch 65/700: Discriminator loss = 1.0977174043655396, GAN loss = [3.4809465, 1.4413654, 1.1729387]\n",
      "Batch 66/700: Discriminator loss = 1.1091643571853638, GAN loss = [3.4436178, 1.4601609, 1.1168423]\n",
      "Batch 67/700: Discriminator loss = 1.1308157444000244, GAN loss = [3.3922594, 1.4352247, 1.0904485]\n",
      "Batch 68/700: Discriminator loss = 1.1428261995315552, GAN loss = [3.3796432, 1.4292046, 1.0838813]\n",
      "Batch 69/700: Discriminator loss = 1.1185661554336548, GAN loss = [3.5427663, 1.4465443, 1.2296883]\n",
      "Batch 70/700: Discriminator loss = 1.130432367324829, GAN loss = [3.4887366, 1.4327089, 1.1895242]\n",
      "Batch 71/700: Discriminator loss = 1.1285065412521362, GAN loss = [3.4577076, 1.4382646, 1.152972]\n",
      "Batch 72/700: Discriminator loss = 1.1216696500778198, GAN loss = [3.4504151, 1.4015744, 1.1824032]\n",
      "Batch 73/700: Discriminator loss = 1.1146198511123657, GAN loss = [3.5470083, 1.4481514, 1.232454]\n",
      "Batch 74/700: Discriminator loss = 1.121294617652893, GAN loss = [3.5028405, 1.4507127, 1.185761]\n",
      "Batch 75/700: Discriminator loss = 1.111280083656311, GAN loss = [3.435686, 1.4370471, 1.1323098]\n",
      "Batch 76/700: Discriminator loss = 1.12342369556427, GAN loss = [3.5491276, 1.4764665, 1.206372]\n",
      "Batch 77/700: Discriminator loss = 1.1133414506912231, GAN loss = [3.4597862, 1.4349158, 1.1586252]\n",
      "Batch 78/700: Discriminator loss = 1.1617165803909302, GAN loss = [3.3961992, 1.4230838, 1.1069125]\n",
      "Batch 79/700: Discriminator loss = 1.1503551006317139, GAN loss = [3.408845, 1.4354786, 1.1072035]\n",
      "Batch 80/700: Discriminator loss = 1.1065874099731445, GAN loss = [3.5027907, 1.4433843, 1.1932808]\n",
      "Batch 81/700: Discriminator loss = 1.1397120952606201, GAN loss = [3.391804, 1.422985, 1.1027308]\n",
      "Batch 82/700: Discriminator loss = 1.0974024534225464, GAN loss = [3.579061, 1.4517963, 1.261213]\n",
      "Batch 83/700: Discriminator loss = 1.0990382432937622, GAN loss = [3.4508092, 1.414701, 1.1700902]\n",
      "Batch 84/700: Discriminator loss = 1.0984888076782227, GAN loss = [3.5608742, 1.4213357, 1.273555]\n",
      "Batch 85/700: Discriminator loss = 1.1000083684921265, GAN loss = [3.7130702, 1.4477626, 1.3993586]\n",
      "Batch 86/700: Discriminator loss = 1.086658239364624, GAN loss = [3.5521166, 1.4230554, 1.2631409]\n",
      "Batch 87/700: Discriminator loss = 1.07990562915802, GAN loss = [3.7306795, 1.4364946, 1.4282923]\n",
      "Batch 88/700: Discriminator loss = 1.094182014465332, GAN loss = [3.6365564, 1.3929973, 1.3776927]\n",
      "Batch 89/700: Discriminator loss = 1.084873914718628, GAN loss = [3.6718667, 1.390247, 1.4157846]\n",
      "Batch 90/700: Discriminator loss = 1.0713742971420288, GAN loss = [3.749875, 1.3879743, 1.496098]\n",
      "Batch 91/700: Discriminator loss = 1.0921399593353271, GAN loss = [3.658912, 1.4255928, 1.367549]\n",
      "Batch 92/700: Discriminator loss = 1.0549798011779785, GAN loss = [3.7610857, 1.4330388, 1.4623096]\n",
      "Batch 93/700: Discriminator loss = 1.0771958827972412, GAN loss = [3.730733, 1.4363288, 1.4287002]\n",
      "Batch 94/700: Discriminator loss = 1.0598357915878296, GAN loss = [3.8622754, 1.474424, 1.5221783]\n",
      "Batch 95/700: Discriminator loss = 1.0397453308105469, GAN loss = [3.8822105, 1.4293839, 1.5871828]\n",
      "Batch 96/700: Discriminator loss = 1.0604586601257324, GAN loss = [3.6392815, 1.450074, 1.323591]\n",
      "Batch 97/700: Discriminator loss = 1.018645167350769, GAN loss = [3.892785, 1.4788097, 1.5483885]\n",
      "Batch 98/700: Discriminator loss = 1.0301337242126465, GAN loss = [3.7172043, 1.5008131, 1.3508363]\n",
      "Batch 99/700: Discriminator loss = 0.973671019077301, GAN loss = [4.2538, 1.5634754, 1.8248023]\n",
      "Batch 100/700: Discriminator loss = 0.9930353164672852, GAN loss = [4.1196904, 1.6164916, 1.6377078]\n",
      "Batch 101/700: Discriminator loss = 0.9791171550750732, GAN loss = [4.1452103, 1.6264932, 1.6532576]\n",
      "Batch 102/700: Discriminator loss = 0.9999829530715942, GAN loss = [4.0465717, 1.6618645, 1.5192752]\n",
      "Batch 103/700: Discriminator loss = 0.9832417964935303, GAN loss = [3.9917257, 1.5988965, 1.5274223]\n",
      "Batch 104/700: Discriminator loss = 0.981069803237915, GAN loss = [4.0688415, 1.6421505, 1.5613056]\n",
      "Batch 105/700: Discriminator loss = 1.0075360536575317, GAN loss = [4.186996, 1.7280972, 1.5935309]\n",
      "Batch 106/700: Discriminator loss = 1.0017389059066772, GAN loss = [4.1533475, 1.692251, 1.5957446]\n",
      "Batch 107/700: Discriminator loss = 1.05784273147583, GAN loss = [4.1222067, 1.7516974, 1.5051786]\n",
      "Batch 108/700: Discriminator loss = 0.9960486888885498, GAN loss = [4.063371, 1.7044578, 1.4936059]\n",
      "Batch 109/700: Discriminator loss = 1.0568116903305054, GAN loss = [3.9723318, 1.7061752, 1.4008716]\n",
      "Batch 110/700: Discriminator loss = 1.0388622283935547, GAN loss = [4.0293703, 1.7346858, 1.4294215]\n",
      "Batch 111/700: Discriminator loss = 1.024858832359314, GAN loss = [3.9066114, 1.756786, 1.2845863]\n",
      "Batch 112/700: Discriminator loss = 1.0541086196899414, GAN loss = [3.9452431, 1.7713258, 1.3087051]\n",
      "Batch 113/700: Discriminator loss = 1.0144709348678589, GAN loss = [3.9294412, 1.6723282, 1.3919287]\n",
      "Batch 114/700: Discriminator loss = 1.0625966787338257, GAN loss = [3.9546425, 1.8034776, 1.2860091]\n",
      "Batch 115/700: Discriminator loss = 0.9793971180915833, GAN loss = [4.0961533, 1.7757396, 1.4552912]\n",
      "Batch 116/700: Discriminator loss = 1.0359712839126587, GAN loss = [3.9563365, 1.8067749, 1.2844723]\n",
      "Batch 117/700: Discriminator loss = 1.02530837059021, GAN loss = [4.059308, 1.7686886, 1.425568]\n",
      "Batch 118/700: Discriminator loss = 1.0660550594329834, GAN loss = [3.9984815, 1.8037512, 1.3297137]\n",
      "Batch 119/700: Discriminator loss = 1.0597583055496216, GAN loss = [4.0080824, 1.7896215, 1.3534731]\n",
      "Batch 120/700: Discriminator loss = 1.0433542728424072, GAN loss = [4.073218, 1.8165034, 1.3917553]\n",
      "Batch 121/700: Discriminator loss = 1.0218756198883057, GAN loss = [4.198256, 1.7654946, 1.5678334]\n",
      "Batch 122/700: Discriminator loss = 1.0969769954681396, GAN loss = [3.8662703, 1.7539897, 1.2473797]\n",
      "Batch 123/700: Discriminator loss = 1.0338757038116455, GAN loss = [4.0550785, 1.6530204, 1.5371792]\n",
      "Batch 124/700: Discriminator loss = 1.056307077407837, GAN loss = [4.144203, 1.6893059, 1.59004]\n",
      "Batch 125/700: Discriminator loss = 1.043147087097168, GAN loss = [4.222415, 1.6856596, 1.6719177]\n",
      "Batch 126/700: Discriminator loss = 1.0974749326705933, GAN loss = [4.274228, 1.7335123, 1.6758941]\n",
      "Batch 127/700: Discriminator loss = 1.0210713148117065, GAN loss = [4.176768, 1.618711, 1.6932493]\n",
      "Batch 128/700: Discriminator loss = 1.07177734375, GAN loss = [4.1559806, 1.6362575, 1.6549301]\n",
      "Batch 129/700: Discriminator loss = 1.0586812496185303, GAN loss = [4.2184877, 1.6084439, 1.7452691]\n",
      "Batch 130/700: Discriminator loss = 1.0456289052963257, GAN loss = [4.2083406, 1.6430713, 1.7005154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 131/700: Discriminator loss = 1.0202335119247437, GAN loss = [4.0852313, 1.5941823, 1.6263192]\n",
      "Batch 132/700: Discriminator loss = 1.0198575258255005, GAN loss = [4.3196692, 1.5622363, 1.892726]\n",
      "Batch 133/700: Discriminator loss = 1.054351568222046, GAN loss = [4.089301, 1.5667691, 1.6578463]\n",
      "Batch 134/700: Discriminator loss = 1.0131332874298096, GAN loss = [4.3740644, 1.5276663, 1.9817319]\n",
      "Batch 135/700: Discriminator loss = 1.026556372642517, GAN loss = [4.595474, 1.5581369, 2.172688]\n",
      "Batch 136/700: Discriminator loss = 1.015168309211731, GAN loss = [4.3523145, 1.5873041, 1.9003798]\n",
      "Batch 137/700: Discriminator loss = 1.0053932666778564, GAN loss = [4.745294, 1.6123029, 2.268378]\n",
      "Batch 138/700: Discriminator loss = 0.9753879308700562, GAN loss = [4.451261, 1.5700083, 2.0166576]\n",
      "Batch 139/700: Discriminator loss = 0.9791120290756226, GAN loss = [4.7251616, 1.6478927, 2.2126935]\n",
      "Batch 140/700: Discriminator loss = 0.9841241240501404, GAN loss = [4.7335143, 1.611061, 2.257896]\n",
      "Batch 141/700: Discriminator loss = 1.0716255903244019, GAN loss = [4.2500997, 1.6539661, 1.731595]\n",
      "Batch 142/700: Discriminator loss = 1.1109009981155396, GAN loss = [3.937412, 1.6478344, 1.4250547]\n",
      "Batch 143/700: Discriminator loss = 1.0420753955841064, GAN loss = [4.392972, 1.6309453, 1.8975139]\n",
      "Batch 144/700: Discriminator loss = 1.0236775875091553, GAN loss = [4.1865973, 1.6073792, 1.7147169]\n",
      "Batch 145/700: Discriminator loss = 1.0249065160751343, GAN loss = [4.4243426, 1.5808198, 1.9790318]\n",
      "Batch 146/700: Discriminator loss = 1.0555344820022583, GAN loss = [4.4358325, 1.6561664, 1.9151857]\n",
      "Batch 147/700: Discriminator loss = 1.0560411214828491, GAN loss = [4.265893, 1.6369792, 1.7644415]\n",
      "Batch 148/700: Discriminator loss = 1.0407029390335083, GAN loss = [4.4360657, 1.6437579, 1.9278449]\n",
      "Batch 149/700: Discriminator loss = 1.0425889492034912, GAN loss = [4.33716, 1.6326813, 1.8400307]\n",
      "Batch 150/700: Discriminator loss = 1.0725102424621582, GAN loss = [4.4675865, 1.6134952, 1.9896557]\n",
      "Batch 151/700: Discriminator loss = 1.1466355323791504, GAN loss = [4.130453, 1.6307682, 1.6352553]\n",
      "Batch 152/700: Discriminator loss = 1.1278973817825317, GAN loss = [4.083682, 1.6590331, 1.5602111]\n",
      "Batch 153/700: Discriminator loss = 1.143274188041687, GAN loss = [3.898395, 1.6025386, 1.4314038]\n",
      "Batch 154/700: Discriminator loss = 1.1210073232650757, GAN loss = [4.0075417, 1.6319999, 1.5110704]\n",
      "Batch 155/700: Discriminator loss = 1.0894991159439087, GAN loss = [4.3329883, 1.6982459, 1.7702472]\n",
      "Batch 156/700: Discriminator loss = 1.0865920782089233, GAN loss = [4.218625, 1.6954961, 1.6586047]\n",
      "Batch 157/700: Discriminator loss = 1.1354992389678955, GAN loss = [4.03049, 1.7811713, 1.3847638]\n",
      "Batch 158/700: Discriminator loss = 1.0698095560073853, GAN loss = [4.423298, 1.8268709, 1.7318501]\n",
      "Batch 159/700: Discriminator loss = 1.0800888538360596, GAN loss = [4.1703534, 1.7701584, 1.5356027]\n",
      "Batch 160/700: Discriminator loss = 1.054701805114746, GAN loss = [4.5361032, 1.7712402, 1.9002544]\n",
      "Batch 161/700: Discriminator loss = 1.111487627029419, GAN loss = [4.4508576, 1.8602121, 1.7260219]\n",
      "Batch 162/700: Discriminator loss = 1.080772042274475, GAN loss = [4.6541624, 1.8358176, 1.9537039]\n",
      "Batch 163/700: Discriminator loss = 1.1079790592193604, GAN loss = [4.3687334, 1.818274, 1.6857945]\n",
      "Batch 164/700: Discriminator loss = 1.0966582298278809, GAN loss = [4.6215944, 1.8050271, 1.9518759]\n",
      "Batch 165/700: Discriminator loss = 1.1035382747650146, GAN loss = [4.4638677, 1.8507794, 1.7483661]\n",
      "Batch 166/700: Discriminator loss = 1.1268259286880493, GAN loss = [4.275609, 1.7930019, 1.6178536]\n",
      "Batch 167/700: Discriminator loss = 1.122198462486267, GAN loss = [4.5046315, 1.8220282, 1.8178232]\n",
      "Batch 168/700: Discriminator loss = 1.0739049911499023, GAN loss = [4.3238063, 1.7834332, 1.67557]\n",
      "Batch 169/700: Discriminator loss = 1.1513733863830566, GAN loss = [4.2160606, 1.7454966, 1.6057547]\n",
      "Batch 170/700: Discriminator loss = 1.1165964603424072, GAN loss = [4.1082754, 1.7105834, 1.5328723]\n",
      "Batch 171/700: Discriminator loss = 1.072425127029419, GAN loss = [4.2100835, 1.7082149, 1.6370406]\n",
      "Batch 172/700: Discriminator loss = 1.0453884601593018, GAN loss = [4.3578744, 1.6439579, 1.8490852]\n",
      "Batch 173/700: Discriminator loss = 1.053301453590393, GAN loss = [4.2525907, 1.676234, 1.7115281]\n",
      "Batch 174/700: Discriminator loss = 1.0688982009887695, GAN loss = [4.296137, 1.6704321, 1.7608802]\n",
      "Batch 175/700: Discriminator loss = 1.0825951099395752, GAN loss = [4.1833224, 1.6986325, 1.6198648]\n",
      "Batch 176/700: Discriminator loss = 1.026432991027832, GAN loss = [4.4038787, 1.70821, 1.8308427]\n",
      "Batch 177/700: Discriminator loss = 1.0311979055404663, GAN loss = [4.5281987, 1.7319169, 1.9314617]\n",
      "Batch 178/700: Discriminator loss = 1.0297821760177612, GAN loss = [4.5686336, 1.8276587, 1.8761678]\n",
      "Batch 179/700: Discriminator loss = 1.0200146436691284, GAN loss = [4.3501554, 1.642549, 1.8428159]\n",
      "Batch 180/700: Discriminator loss = 1.050666332244873, GAN loss = [4.672536, 1.7292697, 2.078494]\n",
      "Batch 181/700: Discriminator loss = 1.100450038909912, GAN loss = [4.134994, 1.6819007, 1.5883408]\n",
      "Batch 182/700: Discriminator loss = 1.0963621139526367, GAN loss = [4.33116, 1.8204747, 1.6459547]\n",
      "Batch 183/700: Discriminator loss = 1.069402813911438, GAN loss = [4.331516, 1.740127, 1.7266867]\n",
      "Batch 184/700: Discriminator loss = 1.1606786251068115, GAN loss = [4.0725713, 1.675477, 1.5324265]\n",
      "Batch 185/700: Discriminator loss = 1.1409931182861328, GAN loss = [4.432889, 1.7075338, 1.860724]\n",
      "Batch 186/700: Discriminator loss = 1.2746256589889526, GAN loss = [4.0167255, 1.7289983, 1.4231255]\n",
      "Batch 187/700: Discriminator loss = 1.1925487518310547, GAN loss = [3.928111, 1.646862, 1.4166751]\n",
      "Batch 188/700: Discriminator loss = 1.2325431108474731, GAN loss = [3.6609027, 1.5640923, 1.2322599]\n",
      "Batch 189/700: Discriminator loss = 1.1185836791992188, GAN loss = [3.8983579, 1.6003653, 1.4334606]\n",
      "Batch 190/700: Discriminator loss = 1.1748430728912354, GAN loss = [3.7277956, 1.5630385, 1.3002466]\n",
      "Batch 191/700: Discriminator loss = 1.2038123607635498, GAN loss = [3.7125096, 1.5705445, 1.2774769]\n",
      "Batch 192/700: Discriminator loss = 1.1410764455795288, GAN loss = [3.7676442, 1.5565813, 1.3465936]\n",
      "Batch 193/700: Discriminator loss = 1.1238429546356201, GAN loss = [3.6237452, 1.4999384, 1.2593553]\n",
      "Batch 194/700: Discriminator loss = 1.165533185005188, GAN loss = [3.7270064, 1.5240196, 1.3385494]\n",
      "Batch 195/700: Discriminator loss = 1.1006343364715576, GAN loss = [3.816606, 1.502219, 1.4499643]\n",
      "Batch 196/700: Discriminator loss = 1.1242748498916626, GAN loss = [3.589938, 1.4881668, 1.2373608]\n",
      "Batch 197/700: Discriminator loss = 1.1420810222625732, GAN loss = [3.6226482, 1.4675415, 1.2907073]\n",
      "Batch 198/700: Discriminator loss = 1.1457618474960327, GAN loss = [3.638608, 1.5056897, 1.2685298]\n",
      "Batch 199/700: Discriminator loss = 1.1477123498916626, GAN loss = [3.752441, 1.5782807, 1.3097833]\n",
      "Batch 200/700: Discriminator loss = 1.1119191646575928, GAN loss = [3.8434968, 1.5693538, 1.4097815]\n",
      "Batch 201/700: Discriminator loss = 1.2001203298568726, GAN loss = [3.5508199, 1.6132911, 1.0731851]\n",
      "Batch 202/700: Discriminator loss = 1.1579275131225586, GAN loss = [3.747098, 1.5817118, 1.3010651]\n",
      "Batch 203/700: Discriminator loss = 1.218233346939087, GAN loss = [3.610099, 1.5816847, 1.1641122]\n",
      "Batch 204/700: Discriminator loss = 1.2000494003295898, GAN loss = [3.533139, 1.5384154, 1.1304344]\n",
      "Batch 205/700: Discriminator loss = 1.216848373413086, GAN loss = [3.6232092, 1.5856918, 1.1732326]\n",
      "Batch 206/700: Discriminator loss = 1.2367877960205078, GAN loss = [3.4137955, 1.4815755, 1.0679291]\n",
      "Batch 207/700: Discriminator loss = 1.243689775466919, GAN loss = [3.5136774, 1.5383188, 1.1110542]\n",
      "Batch 208/700: Discriminator loss = 1.1651619672775269, GAN loss = [3.6225936, 1.5674074, 1.1908729]\n",
      "Batch 209/700: Discriminator loss = 1.2041531801223755, GAN loss = [3.5054514, 1.5271825, 1.1139574]\n",
      "Batch 210/700: Discriminator loss = 1.200891137123108, GAN loss = [3.5192769, 1.60648, 1.0484825]\n",
      "Batch 211/700: Discriminator loss = 1.1222975254058838, GAN loss = [3.6656573, 1.5071762, 1.2941722]\n",
      "Batch 212/700: Discriminator loss = 1.193009376525879, GAN loss = [3.557813, 1.580658, 1.1128502]\n",
      "Batch 213/700: Discriminator loss = 1.127493977546692, GAN loss = [3.5852032, 1.5315174, 1.1893928]\n",
      "Batch 214/700: Discriminator loss = 1.1435341835021973, GAN loss = [3.6535447, 1.6064858, 1.1827822]\n",
      "Batch 215/700: Discriminator loss = 1.0793702602386475, GAN loss = [3.7629225, 1.566542, 1.3321273]\n",
      "Batch 216/700: Discriminator loss = 1.1224923133850098, GAN loss = [3.7311792, 1.5188415, 1.348115]\n",
      "Batch 217/700: Discriminator loss = 1.0955488681793213, GAN loss = [3.5664213, 1.5056425, 1.1965896]\n",
      "Batch 218/700: Discriminator loss = 1.1482783555984497, GAN loss = [3.6784706, 1.5264676, 1.2878444]\n",
      "Batch 219/700: Discriminator loss = 1.1156991720199585, GAN loss = [3.8302968, 1.5778258, 1.3883432]\n",
      "Batch 220/700: Discriminator loss = 1.1739712953567505, GAN loss = [3.5587685, 1.5246403, 1.1700364]\n",
      "Batch 221/700: Discriminator loss = 1.1379715204238892, GAN loss = [3.5532782, 1.5012492, 1.1879724]\n",
      "Batch 222/700: Discriminator loss = 1.1752238273620605, GAN loss = [3.4576647, 1.4688137, 1.1248267]\n",
      "Batch 223/700: Discriminator loss = 1.1344152688980103, GAN loss = [3.6110554, 1.5200799, 1.2269803]\n",
      "Batch 224/700: Discriminator loss = 1.2220524549484253, GAN loss = [3.50571, 1.5548549, 1.0868902]\n",
      "Batch 225/700: Discriminator loss = 1.0892646312713623, GAN loss = [3.5895975, 1.5288477, 1.1968137]\n",
      "Batch 226/700: Discriminator loss = 1.1141301393508911, GAN loss = [3.5391104, 1.490466, 1.1847433]\n",
      "Batch 227/700: Discriminator loss = 1.1050772666931152, GAN loss = [3.503558, 1.479472, 1.1602178]\n",
      "Batch 228/700: Discriminator loss = 1.1124237775802612, GAN loss = [3.5173922, 1.5093951, 1.1441616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 229/700: Discriminator loss = 1.0591343641281128, GAN loss = [3.602854, 1.4833179, 1.2557279]\n",
      "Batch 230/700: Discriminator loss = 1.0984152555465698, GAN loss = [3.5818045, 1.4616209, 1.2564007]\n",
      "Batch 231/700: Discriminator loss = 1.0395244359970093, GAN loss = [3.869483, 1.532272, 1.4734508]\n",
      "Batch 232/700: Discriminator loss = 1.0586434602737427, GAN loss = [3.6463025, 1.4910601, 1.2915059]\n",
      "Batch 233/700: Discriminator loss = 1.049491047859192, GAN loss = [3.7923317, 1.5154821, 1.4131352]\n",
      "Batch 234/700: Discriminator loss = 1.011038064956665, GAN loss = [3.8977633, 1.5191085, 1.5149603]\n",
      "Batch 235/700: Discriminator loss = 1.0024566650390625, GAN loss = [3.9286742, 1.5486568, 1.5163437]\n",
      "Batch 236/700: Discriminator loss = 1.0410780906677246, GAN loss = [3.8438725, 1.5576651, 1.4225523]\n",
      "Batch 237/700: Discriminator loss = 1.0624761581420898, GAN loss = [3.9377146, 1.6058863, 1.468191]\n",
      "Batch 238/700: Discriminator loss = 1.0638067722320557, GAN loss = [3.8890212, 1.5942099, 1.4311906]\n",
      "Batch 239/700: Discriminator loss = 1.0586801767349243, GAN loss = [3.8339705, 1.5926578, 1.3777043]\n",
      "Batch 240/700: Discriminator loss = 1.0942381620407104, GAN loss = [3.7504656, 1.6053675, 1.2814974]\n",
      "Batch 241/700: Discriminator loss = 1.0987147092819214, GAN loss = [3.816855, 1.6718243, 1.2814362]\n",
      "Batch 242/700: Discriminator loss = 1.0733556747436523, GAN loss = [3.7087595, 1.5887085, 1.2564613]\n",
      "Batch 243/700: Discriminator loss = 1.0617351531982422, GAN loss = [3.76726, 1.6680152, 1.2356538]\n",
      "Batch 244/700: Discriminator loss = 1.0939233303070068, GAN loss = [3.6169496, 1.5797027, 1.1736555]\n",
      "Batch 245/700: Discriminator loss = 1.0739821195602417, GAN loss = [3.7744913, 1.6250458, 1.2858548]\n",
      "Batch 246/700: Discriminator loss = 1.070444941520691, GAN loss = [3.7728736, 1.5631926, 1.346089]\n",
      "Batch 247/700: Discriminator loss = 1.0114027261734009, GAN loss = [4.117418, 1.5657653, 1.6880606]\n",
      "Batch 248/700: Discriminator loss = 1.063460111618042, GAN loss = [3.7383704, 1.5246524, 1.3501251]\n",
      "Batch 249/700: Discriminator loss = 1.0523324012756348, GAN loss = [4.0814795, 1.6029975, 1.614891]\n",
      "Batch 250/700: Discriminator loss = 1.031360387802124, GAN loss = [4.010854, 1.5971923, 1.550074]\n",
      "Batch 251/700: Discriminator loss = 1.00344979763031, GAN loss = [4.0460553, 1.5550647, 1.6274118]\n",
      "Batch 252/700: Discriminator loss = 1.0418800115585327, GAN loss = [4.129996, 1.5893406, 1.6770923]\n",
      "Batch 253/700: Discriminator loss = 1.0441197156906128, GAN loss = [4.0652413, 1.5650184, 1.6366752]\n",
      "Batch 254/700: Discriminator loss = 1.0690521001815796, GAN loss = [4.284471, 1.6111697, 1.8097656]\n",
      "Batch 255/700: Discriminator loss = 1.0563666820526123, GAN loss = [4.332272, 1.669232, 1.7995121]\n",
      "Batch 256/700: Discriminator loss = 1.0020403861999512, GAN loss = [4.1946616, 1.5684755, 1.7626638]\n",
      "Batch 257/700: Discriminator loss = 1.0433508157730103, GAN loss = [4.3511996, 1.7129853, 1.7747022]\n",
      "Batch 258/700: Discriminator loss = 0.997805655002594, GAN loss = [4.3498845, 1.6245995, 1.861795]\n",
      "Batch 259/700: Discriminator loss = 0.9760497212409973, GAN loss = [4.727782, 1.6932597, 2.171053]\n",
      "Batch 260/700: Discriminator loss = 1.099536418914795, GAN loss = [4.481229, 1.7686756, 1.8491073]\n",
      "Batch 261/700: Discriminator loss = 1.0299218893051147, GAN loss = [4.265403, 1.7077537, 1.6942143]\n",
      "Batch 262/700: Discriminator loss = 1.0577553510665894, GAN loss = [4.2648335, 1.7324922, 1.668921]\n",
      "Batch 263/700: Discriminator loss = 1.082870364189148, GAN loss = [3.985156, 1.641698, 1.4800506]\n",
      "Batch 264/700: Discriminator loss = 1.0397584438323975, GAN loss = [4.070758, 1.608205, 1.5991561]\n",
      "Batch 265/700: Discriminator loss = 1.0693846940994263, GAN loss = [4.100808, 1.6251391, 1.6122895]\n",
      "Batch 266/700: Discriminator loss = 1.0672338008880615, GAN loss = [4.0789537, 1.7081584, 1.5074344]\n",
      "Batch 267/700: Discriminator loss = 1.056420922279358, GAN loss = [4.0127177, 1.6666297, 1.4827375]\n",
      "Batch 268/700: Discriminator loss = 1.1293905973434448, GAN loss = [3.8922348, 1.6837754, 1.3451184]\n",
      "Batch 269/700: Discriminator loss = 1.1056644916534424, GAN loss = [3.7634585, 1.6916146, 1.2085103]\n",
      "Batch 270/700: Discriminator loss = 1.1329727172851562, GAN loss = [3.9560616, 1.8221936, 1.2705396]\n",
      "Batch 271/700: Discriminator loss = 1.012543797492981, GAN loss = [3.809339, 1.6408381, 1.3051773]\n",
      "Batch 272/700: Discriminator loss = 1.1122066974639893, GAN loss = [3.6124697, 1.6140293, 1.135124]\n",
      "Batch 273/700: Discriminator loss = 1.071077585220337, GAN loss = [3.8199003, 1.6798931, 1.2767043]\n",
      "Batch 274/700: Discriminator loss = 1.0781480073928833, GAN loss = [3.6749663, 1.579881, 1.2317979]\n",
      "Batch 275/700: Discriminator loss = 1.1074481010437012, GAN loss = [3.9248576, 1.7881969, 1.2733971]\n",
      "Batch 276/700: Discriminator loss = 1.0304421186447144, GAN loss = [3.7455208, 1.6691525, 1.2131267]\n",
      "Batch 277/700: Discriminator loss = 1.1012513637542725, GAN loss = [3.6304808, 1.6415815, 1.1256777]\n",
      "Batch 278/700: Discriminator loss = 1.0570757389068604, GAN loss = [3.7832494, 1.6568198, 1.2632339]\n",
      "Batch 279/700: Discriminator loss = 1.0986688137054443, GAN loss = [3.7910259, 1.7548279, 1.1730256]\n",
      "Batch 280/700: Discriminator loss = 1.0777150392532349, GAN loss = [3.7618554, 1.6815833, 1.2171185]\n",
      "Batch 281/700: Discriminator loss = 1.0314606428146362, GAN loss = [3.8511927, 1.6525966, 1.3354614]\n",
      "Batch 282/700: Discriminator loss = 1.0598697662353516, GAN loss = [3.8448536, 1.6563405, 1.325399]\n",
      "Batch 283/700: Discriminator loss = 1.0706536769866943, GAN loss = [3.780878, 1.6446205, 1.2731683]\n",
      "Batch 284/700: Discriminator loss = 1.0985387563705444, GAN loss = [3.7762663, 1.6993016, 1.2138993]\n",
      "Batch 285/700: Discriminator loss = 1.08135986328125, GAN loss = [3.8452127, 1.7325023, 1.2496619]\n",
      "Batch 286/700: Discriminator loss = 1.0451312065124512, GAN loss = [3.9001727, 1.6978548, 1.3392917]\n",
      "Batch 287/700: Discriminator loss = 1.0481115579605103, GAN loss = [3.8428037, 1.6917775, 1.2880129]\n",
      "Batch 288/700: Discriminator loss = 1.1123387813568115, GAN loss = [3.7942917, 1.6590456, 1.2722404]\n",
      "Batch 289/700: Discriminator loss = 1.0643787384033203, GAN loss = [3.878782, 1.6338292, 1.3819497]\n",
      "Batch 290/700: Discriminator loss = 1.1203073263168335, GAN loss = [3.846659, 1.6737404, 1.309918]\n",
      "Batch 291/700: Discriminator loss = 1.0738688707351685, GAN loss = [3.8888032, 1.6186547, 1.4071469]\n",
      "Batch 292/700: Discriminator loss = 1.0778874158859253, GAN loss = [3.8988342, 1.5902884, 1.4455425]\n",
      "Batch 293/700: Discriminator loss = 1.0897084474563599, GAN loss = [3.8479478, 1.6079518, 1.3769919]\n",
      "Batch 294/700: Discriminator loss = 1.0905061960220337, GAN loss = [3.877753, 1.661231, 1.3535179]\n",
      "Batch 295/700: Discriminator loss = 1.092734694480896, GAN loss = [3.8094752, 1.6656785, 1.2807885]\n",
      "Batch 296/700: Discriminator loss = 1.067504644393921, GAN loss = [3.8517141, 1.6435503, 1.3451538]\n",
      "Batch 297/700: Discriminator loss = 1.0985435247421265, GAN loss = [3.7869058, 1.655073, 1.2688235]\n",
      "Batch 298/700: Discriminator loss = 1.0706562995910645, GAN loss = [3.848693, 1.6417052, 1.3439778]\n",
      "Batch 299/700: Discriminator loss = 1.0577971935272217, GAN loss = [3.8524692, 1.6355395, 1.353919]\n",
      "Batch 300/700: Discriminator loss = 1.0719116926193237, GAN loss = [3.935516, 1.648341, 1.4241632]\n",
      "Batch 301/700: Discriminator loss = 1.0671809911727905, GAN loss = [3.9330573, 1.6493496, 1.4206917]\n",
      "Batch 302/700: Discriminator loss = 1.1189206838607788, GAN loss = [3.724639, 1.6741649, 1.1874504]\n",
      "Batch 303/700: Discriminator loss = 1.0670117139816284, GAN loss = [3.9029634, 1.6076055, 1.4323235]\n",
      "Batch 304/700: Discriminator loss = 1.1026067733764648, GAN loss = [3.8663642, 1.6714956, 1.3318219]\n",
      "Batch 305/700: Discriminator loss = 1.115646481513977, GAN loss = [3.8081357, 1.6716748, 1.2734001]\n",
      "Batch 306/700: Discriminator loss = 1.1345158815383911, GAN loss = [3.8494859, 1.6886333, 1.2977754]\n",
      "Batch 307/700: Discriminator loss = 1.1391260623931885, GAN loss = [3.739236, 1.6310496, 1.2451005]\n",
      "Batch 308/700: Discriminator loss = 1.1461211442947388, GAN loss = [3.8646967, 1.6485419, 1.3530595]\n",
      "Batch 309/700: Discriminator loss = 1.1777549982070923, GAN loss = [3.7346666, 1.6642909, 1.2072744]\n",
      "Batch 310/700: Discriminator loss = 1.1846344470977783, GAN loss = [3.6727393, 1.6374907, 1.1721469]\n",
      "Batch 311/700: Discriminator loss = 1.136184811592102, GAN loss = [3.9598646, 1.6798822, 1.4168755]\n",
      "Batch 312/700: Discriminator loss = 1.202392578125, GAN loss = [3.7175379, 1.6678529, 1.186572]\n",
      "Batch 313/700: Discriminator loss = 1.1629889011383057, GAN loss = [3.735464, 1.6704482, 1.2018977]\n",
      "Batch 314/700: Discriminator loss = 1.207322359085083, GAN loss = [3.7915976, 1.6675879, 1.2608882]\n",
      "Batch 315/700: Discriminator loss = 1.156876564025879, GAN loss = [3.8712523, 1.6261909, 1.3819225]\n",
      "Batch 316/700: Discriminator loss = 1.1709198951721191, GAN loss = [3.7619402, 1.6008878, 1.2979045]\n",
      "Batch 317/700: Discriminator loss = 1.1161084175109863, GAN loss = [3.9055583, 1.6355693, 1.4068253]\n",
      "Batch 318/700: Discriminator loss = 1.139345645904541, GAN loss = [3.8964658, 1.6076659, 1.4256291]\n",
      "Batch 319/700: Discriminator loss = 1.1231127977371216, GAN loss = [3.7875988, 1.5575343, 1.3668932]\n",
      "Batch 320/700: Discriminator loss = 1.2013776302337646, GAN loss = [3.7015238, 1.6071609, 1.2311958]\n",
      "Batch 321/700: Discriminator loss = 1.1973674297332764, GAN loss = [3.6554852, 1.5747316, 1.217594]\n",
      "Batch 322/700: Discriminator loss = 1.1737176179885864, GAN loss = [3.634105, 1.6531028, 1.1178452]\n",
      "Batch 323/700: Discriminator loss = 1.1278427839279175, GAN loss = [3.801214, 1.6247737, 1.3132802]\n",
      "Batch 324/700: Discriminator loss = 1.1373748779296875, GAN loss = [3.7840157, 1.5803685, 1.3404981]\n",
      "Batch 325/700: Discriminator loss = 1.2419588565826416, GAN loss = [3.6392572, 1.653288, 1.1228366]\n",
      "Batch 326/700: Discriminator loss = 1.151678442955017, GAN loss = [3.690963, 1.5940328, 1.2338141]\n",
      "Batch 327/700: Discriminator loss = 1.1469935178756714, GAN loss = [3.6248631, 1.5872679, 1.174494]\n",
      "Batch 328/700: Discriminator loss = 1.1454252004623413, GAN loss = [3.7590332, 1.7015077, 1.1944449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 329/700: Discriminator loss = 1.128069519996643, GAN loss = [3.7110856, 1.6330525, 1.2149678]\n",
      "Batch 330/700: Discriminator loss = 1.1209592819213867, GAN loss = [3.630756, 1.5998806, 1.1678233]\n",
      "Batch 331/700: Discriminator loss = 1.141167163848877, GAN loss = [3.562745, 1.5459204, 1.153782]\n",
      "Batch 332/700: Discriminator loss = 1.1501628160476685, GAN loss = [3.6105514, 1.5419537, 1.2055675]\n",
      "Batch 333/700: Discriminator loss = 1.1332236528396606, GAN loss = [3.7735302, 1.6368715, 1.2736365]\n",
      "Batch 334/700: Discriminator loss = 1.1025218963623047, GAN loss = [3.7793486, 1.5696579, 1.3466724]\n",
      "Batch 335/700: Discriminator loss = 1.0938855409622192, GAN loss = [3.7649486, 1.5281155, 1.3738213]\n",
      "Batch 336/700: Discriminator loss = 1.126959204673767, GAN loss = [3.857015, 1.6086891, 1.3853189]\n",
      "Batch 337/700: Discriminator loss = 1.0937180519104004, GAN loss = [3.826833, 1.5751169, 1.3887073]\n",
      "Batch 338/700: Discriminator loss = 1.0771232843399048, GAN loss = [3.7540388, 1.570282, 1.3207439]\n",
      "Batch 339/700: Discriminator loss = 1.0441241264343262, GAN loss = [4.136014, 1.616437, 1.6565654]\n",
      "Batch 340/700: Discriminator loss = 1.065434455871582, GAN loss = [3.9554348, 1.5981746, 1.4942514]\n",
      "Batch 341/700: Discriminator loss = 1.0519781112670898, GAN loss = [4.0989265, 1.6312157, 1.6047097]\n",
      "Batch 342/700: Discriminator loss = 1.0420295000076294, GAN loss = [3.8217266, 1.6119964, 1.3467383]\n",
      "Batch 343/700: Discriminator loss = 1.0511109828948975, GAN loss = [4.0841103, 1.6718272, 1.5493068]\n",
      "Batch 344/700: Discriminator loss = 1.016402006149292, GAN loss = [4.148714, 1.6227982, 1.66296]\n",
      "Batch 345/700: Discriminator loss = 1.0610939264297485, GAN loss = [4.1194944, 1.6582727, 1.5982856]\n",
      "Batch 346/700: Discriminator loss = 1.0823755264282227, GAN loss = [4.1293263, 1.6890097, 1.5773932]\n",
      "Batch 347/700: Discriminator loss = 1.043496012687683, GAN loss = [4.1376038, 1.6299384, 1.6447438]\n",
      "Batch 348/700: Discriminator loss = 1.0962519645690918, GAN loss = [3.8903155, 1.668089, 1.3593063]\n",
      "Batch 349/700: Discriminator loss = 1.0317496061325073, GAN loss = [3.9471462, 1.5918216, 1.4924072]\n",
      "Batch 350/700: Discriminator loss = 1.047762393951416, GAN loss = [4.0309815, 1.6672163, 1.5008559]\n",
      "Batch 351/700: Discriminator loss = 1.0120080709457397, GAN loss = [4.169735, 1.6626625, 1.6441728]\n",
      "Batch 352/700: Discriminator loss = 1.050703525543213, GAN loss = [4.214174, 1.6923059, 1.6589817]\n",
      "Batch 353/700: Discriminator loss = 1.0039036273956299, GAN loss = [4.1606464, 1.6837819, 1.6139903]\n",
      "Batch 354/700: Discriminator loss = 1.0555448532104492, GAN loss = [4.128926, 1.6906488, 1.5754149]\n",
      "Batch 355/700: Discriminator loss = 0.9971004128456116, GAN loss = [4.1664987, 1.714915, 1.588727]\n",
      "Batch 356/700: Discriminator loss = 1.0112172365188599, GAN loss = [4.318705, 1.7200993, 1.7357537]\n",
      "Batch 357/700: Discriminator loss = 1.053153157234192, GAN loss = [4.2459335, 1.7628773, 1.6202095]\n",
      "Batch 358/700: Discriminator loss = 1.0714826583862305, GAN loss = [4.0726285, 1.7808328, 1.4289578]\n",
      "Batch 359/700: Discriminator loss = 0.9745506048202515, GAN loss = [4.2785254, 1.7706028, 1.6450998]\n",
      "Batch 360/700: Discriminator loss = 1.0241631269454956, GAN loss = [4.453381, 1.8642471, 1.726324]\n",
      "Batch 361/700: Discriminator loss = 0.9678975939750671, GAN loss = [4.4820685, 1.794761, 1.824508]\n",
      "Batch 362/700: Discriminator loss = 0.9637259244918823, GAN loss = [4.5261917, 1.7768303, 1.8865721]\n",
      "Batch 363/700: Discriminator loss = 0.9642354249954224, GAN loss = [4.7020097, 1.9089226, 1.9303128]\n",
      "Batch 364/700: Discriminator loss = 0.996112048625946, GAN loss = [4.5641217, 1.9439957, 1.7573717]\n",
      "Batch 365/700: Discriminator loss = 0.9783177375793457, GAN loss = [4.5972323, 1.9004227, 1.8340765]\n",
      "Batch 366/700: Discriminator loss = 1.009174108505249, GAN loss = [4.721546, 1.9534286, 1.9054027]\n",
      "Batch 367/700: Discriminator loss = 0.9467888474464417, GAN loss = [4.8197284, 1.865128, 2.0918992]\n",
      "Batch 368/700: Discriminator loss = 0.9710875153541565, GAN loss = [4.830377, 2.0340726, 1.9336076]\n",
      "Batch 369/700: Discriminator loss = 0.9616642594337463, GAN loss = [4.7830744, 1.9893444, 1.9310299]\n",
      "Batch 370/700: Discriminator loss = 1.0446380376815796, GAN loss = [4.736029, 2.1544213, 1.7188972]\n",
      "Batch 371/700: Discriminator loss = 0.9825658798217773, GAN loss = [4.7425537, 2.042867, 1.8369622]\n",
      "Batch 372/700: Discriminator loss = 0.9521031379699707, GAN loss = [4.9250755, 2.0721178, 1.9902226]\n",
      "Batch 373/700: Discriminator loss = 0.9386793375015259, GAN loss = [4.8544297, 2.096088, 1.8956066]\n",
      "Batch 374/700: Discriminator loss = 1.0504404306411743, GAN loss = [4.5581226, 2.1882203, 1.5071709]\n",
      "Batch 375/700: Discriminator loss = 0.9325982928276062, GAN loss = [4.914327, 2.068157, 1.9834535]\n",
      "Batch 376/700: Discriminator loss = 0.9784281253814697, GAN loss = [4.6749105, 2.0730567, 1.7391607]\n",
      "Batch 377/700: Discriminator loss = 1.0252740383148193, GAN loss = [4.728258, 2.2905593, 1.5750251]\n",
      "Batch 378/700: Discriminator loss = 0.9732160568237305, GAN loss = [4.676869, 2.0891035, 1.7251062]\n",
      "Batch 379/700: Discriminator loss = 1.0218170881271362, GAN loss = [4.808811, 2.2932847, 1.6528838]\n",
      "Batch 380/700: Discriminator loss = 0.9923434853553772, GAN loss = [4.5756874, 2.1884148, 1.5246472]\n",
      "Batch 381/700: Discriminator loss = 1.0383416414260864, GAN loss = [4.6272726, 2.2488418, 1.515824]\n",
      "Batch 382/700: Discriminator loss = 1.0290321111679077, GAN loss = [4.5400023, 2.226258, 1.4511546]\n",
      "Batch 383/700: Discriminator loss = 1.103312611579895, GAN loss = [4.4998813, 2.314664, 1.3226509]\n",
      "Batch 384/700: Discriminator loss = 1.0114405155181885, GAN loss = [4.49324, 2.112504, 1.5181888]\n",
      "Batch 385/700: Discriminator loss = 1.1557313203811646, GAN loss = [4.305862, 2.2429945, 1.2003446]\n",
      "Batch 386/700: Discriminator loss = 1.0463486909866333, GAN loss = [4.427994, 2.1240919, 1.4414026]\n",
      "Batch 387/700: Discriminator loss = 1.0733232498168945, GAN loss = [4.473702, 2.225044, 1.3861854]\n",
      "Batch 388/700: Discriminator loss = 1.0226460695266724, GAN loss = [4.565108, 2.0632012, 1.6394695]\n",
      "Batch 389/700: Discriminator loss = 1.1461037397384644, GAN loss = [4.361592, 2.1821237, 1.3170648]\n",
      "Batch 390/700: Discriminator loss = 1.1815370321273804, GAN loss = [4.4340706, 2.4104247, 1.1612717]\n",
      "Batch 391/700: Discriminator loss = 1.0876015424728394, GAN loss = [4.3668733, 2.1507318, 1.3538082]\n",
      "Batch 392/700: Discriminator loss = 1.0789620876312256, GAN loss = [4.64047, 2.3107862, 1.4673927]\n",
      "Batch 393/700: Discriminator loss = 1.0911508798599243, GAN loss = [4.636831, 2.2110162, 1.5635636]\n",
      "Batch 394/700: Discriminator loss = 1.0396218299865723, GAN loss = [4.458662, 2.1239033, 1.4725586]\n",
      "Batch 395/700: Discriminator loss = 1.0496596097946167, GAN loss = [4.4114385, 2.1364403, 1.4128417]\n",
      "Batch 396/700: Discriminator loss = 0.9955956339836121, GAN loss = [4.656673, 2.0854151, 1.7091414]\n",
      "Batch 397/700: Discriminator loss = 1.1059610843658447, GAN loss = [4.4637294, 2.125782, 1.4758697]\n",
      "Batch 398/700: Discriminator loss = 1.020112156867981, GAN loss = [4.656675, 2.1278732, 1.6667638]\n",
      "Batch 399/700: Discriminator loss = 1.0719001293182373, GAN loss = [4.4215307, 2.100118, 1.45941]\n",
      "Batch 400/700: Discriminator loss = 1.0153268575668335, GAN loss = [4.554153, 2.045814, 1.6463629]\n",
      "Batch 401/700: Discriminator loss = 1.0521706342697144, GAN loss = [4.5968494, 2.0994368, 1.6354619]\n",
      "Batch 402/700: Discriminator loss = 1.0337952375411987, GAN loss = [4.571453, 2.099184, 1.6103415]\n",
      "Batch 403/700: Discriminator loss = 0.9995277523994446, GAN loss = [4.4507656, 1.9398913, 1.6489732]\n",
      "Batch 404/700: Discriminator loss = 1.1010977029800415, GAN loss = [4.283119, 2.0493162, 1.3719285]\n",
      "Batch 405/700: Discriminator loss = 1.0860109329223633, GAN loss = [4.40975, 2.0354462, 1.5124565]\n",
      "Batch 406/700: Discriminator loss = 1.095747947692871, GAN loss = [4.4223776, 2.0399294, 1.5206233]\n",
      "Batch 407/700: Discriminator loss = 1.0821832418441772, GAN loss = [4.414451, 1.9153857, 1.6372639]\n",
      "Batch 408/700: Discriminator loss = 1.1345242261886597, GAN loss = [4.3816357, 2.0400367, 1.4798198]\n",
      "Batch 409/700: Discriminator loss = 1.0599963665008545, GAN loss = [4.1883683, 1.8394998, 1.4871095]\n",
      "Batch 410/700: Discriminator loss = 1.1046912670135498, GAN loss = [4.102277, 1.9345223, 1.3060105]\n",
      "Batch 411/700: Discriminator loss = 1.0613632202148438, GAN loss = [4.2665477, 1.9273518, 1.4774665]\n",
      "Batch 412/700: Discriminator loss = 1.1984943151474, GAN loss = [4.127992, 2.0558648, 1.2104199]\n",
      "Batch 413/700: Discriminator loss = 1.0969643592834473, GAN loss = [3.9433596, 1.8767066, 1.2049699]\n",
      "Batch 414/700: Discriminator loss = 1.181288480758667, GAN loss = [3.8096042, 1.9275916, 1.020353]\n",
      "Batch 415/700: Discriminator loss = 1.1034239530563354, GAN loss = [3.8703647, 1.8680023, 1.1407251]\n",
      "Batch 416/700: Discriminator loss = 1.0993982553482056, GAN loss = [3.7947114, 1.7791214, 1.1539723]\n",
      "Batch 417/700: Discriminator loss = 1.1894515752792358, GAN loss = [3.8409824, 1.9571341, 1.0222487]\n",
      "Batch 418/700: Discriminator loss = 1.1032427549362183, GAN loss = [3.8020158, 1.820464, 1.1199735]\n",
      "Batch 419/700: Discriminator loss = 1.01793372631073, GAN loss = [4.109806, 1.7885548, 1.4596925]\n",
      "Batch 420/700: Discriminator loss = 1.0752077102661133, GAN loss = [3.9297721, 1.8421228, 1.22611]\n",
      "Batch 421/700: Discriminator loss = 1.1354349851608276, GAN loss = [3.869986, 1.9006191, 1.107849]\n",
      "Batch 422/700: Discriminator loss = 1.0407770872116089, GAN loss = [3.981018, 1.7623895, 1.3571285]\n",
      "Batch 423/700: Discriminator loss = 1.064488172531128, GAN loss = [3.9309406, 1.7456124, 1.3238443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 424/700: Discriminator loss = 1.0338927507400513, GAN loss = [4.0083513, 1.7241002, 1.4227775]\n",
      "Batch 425/700: Discriminator loss = 1.0609773397445679, GAN loss = [4.094091, 1.7509663, 1.4816599]\n",
      "Batch 426/700: Discriminator loss = 1.018384575843811, GAN loss = [4.218371, 1.7788167, 1.5780965]\n",
      "Batch 427/700: Discriminator loss = 1.072226643562317, GAN loss = [4.114692, 1.8757762, 1.3774686]\n",
      "Batch 428/700: Discriminator loss = 0.9890447854995728, GAN loss = [4.253046, 1.7645434, 1.6270617]\n",
      "Batch 429/700: Discriminator loss = 1.0886671543121338, GAN loss = [4.072045, 1.8513312, 1.3592808]\n",
      "Batch 430/700: Discriminator loss = 0.9582871794700623, GAN loss = [4.420421, 1.7835519, 1.7754437]\n",
      "Batch 431/700: Discriminator loss = 1.0633950233459473, GAN loss = [4.323802, 1.916098, 1.5462909]\n",
      "Batch 432/700: Discriminator loss = 0.9946691393852234, GAN loss = [4.2682786, 1.7991492, 1.607727]\n",
      "Batch 433/700: Discriminator loss = 0.9758152961730957, GAN loss = [4.3744426, 1.805632, 1.7074236]\n",
      "Batch 434/700: Discriminator loss = 1.0116350650787354, GAN loss = [4.3086176, 1.8545821, 1.5926687]\n",
      "Batch 435/700: Discriminator loss = 1.007825493812561, GAN loss = [4.370658, 1.8684193, 1.6408932]\n",
      "Batch 436/700: Discriminator loss = 1.006332516670227, GAN loss = [4.326552, 1.8303962, 1.6348311]\n",
      "Batch 437/700: Discriminator loss = 1.0119259357452393, GAN loss = [4.39132, 1.8668313, 1.6631837]\n",
      "Batch 438/700: Discriminator loss = 1.0310784578323364, GAN loss = [4.4263444, 1.9027768, 1.6622853]\n",
      "Batch 439/700: Discriminator loss = 0.9872245192527771, GAN loss = [4.4739194, 1.8466823, 1.7659814]\n",
      "Batch 440/700: Discriminator loss = 1.0355380773544312, GAN loss = [4.3591895, 1.9106765, 1.5872867]\n",
      "Batch 441/700: Discriminator loss = 1.0005019903182983, GAN loss = [4.41234, 1.9067532, 1.6443905]\n",
      "Batch 442/700: Discriminator loss = 1.0129270553588867, GAN loss = [4.3998284, 1.8818524, 1.6568118]\n",
      "Batch 443/700: Discriminator loss = 1.0313794612884521, GAN loss = [4.306533, 1.8506768, 1.5947195]\n",
      "Batch 444/700: Discriminator loss = 1.0476897954940796, GAN loss = [4.2585187, 1.8940434, 1.5033706]\n",
      "Batch 445/700: Discriminator loss = 1.003530740737915, GAN loss = [4.3984094, 1.8546427, 1.6826911]\n",
      "Batch 446/700: Discriminator loss = 0.9965004920959473, GAN loss = [4.438107, 1.860521, 1.7165442]\n",
      "Batch 447/700: Discriminator loss = 0.9967978596687317, GAN loss = [4.3358316, 1.8299623, 1.6448609]\n",
      "Batch 448/700: Discriminator loss = 1.029801607131958, GAN loss = [4.3378596, 1.8159214, 1.6609629]\n",
      "Batch 449/700: Discriminator loss = 0.9934919476509094, GAN loss = [4.5099297, 1.8792392, 1.7697443]\n",
      "Batch 450/700: Discriminator loss = 1.1322320699691772, GAN loss = [4.200731, 1.9875833, 1.3522274]\n",
      "Batch 451/700: Discriminator loss = 0.9936416149139404, GAN loss = [4.2246084, 1.7939448, 1.5697654]\n",
      "Batch 452/700: Discriminator loss = 1.0581363439559937, GAN loss = [4.1596966, 1.8148804, 1.4839398]\n",
      "Batch 453/700: Discriminator loss = 1.003354549407959, GAN loss = [4.3885384, 1.7847083, 1.7429717]\n",
      "Batch 454/700: Discriminator loss = 1.0545564889907837, GAN loss = [4.0343814, 1.778899, 1.3946402]\n",
      "Batch 455/700: Discriminator loss = 1.016926884651184, GAN loss = [4.374243, 1.7616704, 1.7517409]\n",
      "Batch 456/700: Discriminator loss = 1.0215567350387573, GAN loss = [4.314348, 1.7141093, 1.7394196]\n",
      "Batch 457/700: Discriminator loss = 1.1377922296524048, GAN loss = [3.9817042, 1.7610083, 1.3598797]\n",
      "Batch 458/700: Discriminator loss = 1.068691611289978, GAN loss = [4.1447754, 1.660971, 1.6229882]\n",
      "Batch 459/700: Discriminator loss = 1.0807461738586426, GAN loss = [4.043784, 1.6870182, 1.4959449]\n",
      "Batch 460/700: Discriminator loss = 1.1214841604232788, GAN loss = [4.0678425, 1.6964759, 1.5105377]\n",
      "Batch 461/700: Discriminator loss = 1.1127285957336426, GAN loss = [3.9422462, 1.6225781, 1.4588275]\n",
      "Batch 462/700: Discriminator loss = 1.0865892171859741, GAN loss = [3.9169326, 1.6188129, 1.4372696]\n",
      "Batch 463/700: Discriminator loss = 1.0943589210510254, GAN loss = [3.9707887, 1.6657677, 1.4441576]\n",
      "Batch 464/700: Discriminator loss = 1.0636069774627686, GAN loss = [4.0500336, 1.6171683, 1.5719835]\n",
      "Batch 465/700: Discriminator loss = 1.0231600999832153, GAN loss = [4.1645193, 1.6490283, 1.6545905]\n",
      "Batch 466/700: Discriminator loss = 1.0830881595611572, GAN loss = [4.1151686, 1.6782393, 1.5760046]\n",
      "Batch 467/700: Discriminator loss = 0.9718820452690125, GAN loss = [4.4364552, 1.697387, 1.8781258]\n",
      "Batch 468/700: Discriminator loss = 1.0165345668792725, GAN loss = [4.519978, 1.729806, 1.9292173]\n",
      "Batch 469/700: Discriminator loss = 0.9932234287261963, GAN loss = [4.5437284, 1.6954811, 1.9872931]\n",
      "Batch 470/700: Discriminator loss = 1.0501264333724976, GAN loss = [4.394801, 1.6644367, 1.869407]\n",
      "Batch 471/700: Discriminator loss = 0.9970060586929321, GAN loss = [4.6317563, 1.7030644, 2.0677347]\n",
      "Batch 472/700: Discriminator loss = 1.0607753992080688, GAN loss = [4.447077, 1.7190769, 1.8670431]\n",
      "Batch 473/700: Discriminator loss = 1.0123627185821533, GAN loss = [4.4530396, 1.6747909, 1.917283]\n",
      "Batch 474/700: Discriminator loss = 1.064592719078064, GAN loss = [4.5729656, 1.7436802, 1.9683125]\n",
      "Batch 475/700: Discriminator loss = 1.0749552249908447, GAN loss = [4.4732766, 1.7436919, 1.8685995]\n",
      "Batch 476/700: Discriminator loss = 1.1541950702667236, GAN loss = [4.2400823, 1.7513591, 1.6277242]\n",
      "Batch 477/700: Discriminator loss = 1.1126976013183594, GAN loss = [4.1595106, 1.6456344, 1.6528525]\n",
      "Batch 478/700: Discriminator loss = 1.1056073904037476, GAN loss = [4.4934587, 1.7253827, 1.9070326]\n",
      "Batch 479/700: Discriminator loss = 1.1009196043014526, GAN loss = [4.2493005, 1.6610283, 1.727209]\n",
      "Batch 480/700: Discriminator loss = 1.0907143354415894, GAN loss = [4.3400435, 1.727792, 1.7511704]\n",
      "Batch 481/700: Discriminator loss = 1.2751680612564087, GAN loss = [3.7534313, 1.6868674, 1.2054597]\n",
      "Batch 482/700: Discriminator loss = 1.2001078128814697, GAN loss = [3.9711273, 1.7028543, 1.4071419]\n",
      "Batch 483/700: Discriminator loss = 1.1900973320007324, GAN loss = [4.060991, 1.7793826, 1.4204531]\n",
      "Batch 484/700: Discriminator loss = 1.2094889879226685, GAN loss = [3.807575, 1.7235016, 1.2228963]\n",
      "Batch 485/700: Discriminator loss = 1.1963601112365723, GAN loss = [3.868091, 1.7022564, 1.3046348]\n",
      "Batch 486/700: Discriminator loss = 1.2043472528457642, GAN loss = [3.617287, 1.5845677, 1.1714965]\n",
      "Batch 487/700: Discriminator loss = 1.1947054862976074, GAN loss = [3.7928534, 1.5612895, 1.3703192]\n",
      "Batch 488/700: Discriminator loss = 1.335985541343689, GAN loss = [3.592991, 1.7172024, 1.0145262]\n",
      "Batch 489/700: Discriminator loss = 1.2108434438705444, GAN loss = [3.6910286, 1.599581, 1.2301639]\n",
      "Batch 490/700: Discriminator loss = 1.3876967430114746, GAN loss = [3.3725286, 1.6084034, 0.9028235]\n",
      "Batch 491/700: Discriminator loss = 1.2680515050888062, GAN loss = [3.4852636, 1.6003505, 1.0235932]\n",
      "Batch 492/700: Discriminator loss = 1.1779032945632935, GAN loss = [3.4872255, 1.5749038, 1.0509821]\n",
      "Batch 493/700: Discriminator loss = 1.216776728630066, GAN loss = [3.4009342, 1.5208853, 1.0186905]\n",
      "Batch 494/700: Discriminator loss = 1.206957221031189, GAN loss = [3.5049257, 1.5620476, 1.0815021]\n",
      "Batch 495/700: Discriminator loss = 1.2432504892349243, GAN loss = [3.5673091, 1.709814, 0.9961049]\n",
      "Batch 496/700: Discriminator loss = 1.1542640924453735, GAN loss = [3.4852889, 1.6119637, 1.011921]\n",
      "Batch 497/700: Discriminator loss = 1.1881380081176758, GAN loss = [3.4449878, 1.6134595, 0.97010946]\n",
      "Batch 498/700: Discriminator loss = 1.1481813192367554, GAN loss = [3.3989584, 1.5376277, 0.9998992]\n",
      "Batch 499/700: Discriminator loss = 1.131724238395691, GAN loss = [3.5480235, 1.5722187, 1.1143688]\n",
      "Batch 500/700: Discriminator loss = 1.1124712228775024, GAN loss = [3.5777445, 1.546384, 1.1699246]\n",
      "Batch 501/700: Discriminator loss = 1.1310396194458008, GAN loss = [3.4463422, 1.45838, 1.126533]\n",
      "Batch 502/700: Discriminator loss = 1.1421948671340942, GAN loss = [3.5435414, 1.4593526, 1.2227639]\n",
      "Batch 503/700: Discriminator loss = 1.1508498191833496, GAN loss = [3.4277325, 1.475049, 1.0912647]\n",
      "Batch 504/700: Discriminator loss = 1.2038562297821045, GAN loss = [3.3885732, 1.4377756, 1.0893819]\n",
      "Batch 505/700: Discriminator loss = 1.1727063655853271, GAN loss = [3.5061164, 1.4562765, 1.1884274]\n",
      "Batch 506/700: Discriminator loss = 1.128671407699585, GAN loss = [3.475575, 1.4518485, 1.1623268]\n",
      "Batch 507/700: Discriminator loss = 1.1191128492355347, GAN loss = [3.6058168, 1.4746444, 1.2697865]\n",
      "Batch 508/700: Discriminator loss = 1.1086740493774414, GAN loss = [3.6158683, 1.454574, 1.299922]\n",
      "Batch 509/700: Discriminator loss = 1.1435432434082031, GAN loss = [3.627391, 1.541143, 1.2248802]\n",
      "Batch 510/700: Discriminator loss = 1.1616677045822144, GAN loss = [3.4351313, 1.4285157, 1.1452583]\n",
      "Batch 511/700: Discriminator loss = 1.2155596017837524, GAN loss = [3.3785858, 1.4406879, 1.0765495]\n",
      "Batch 512/700: Discriminator loss = 1.1216533184051514, GAN loss = [3.5225017, 1.457902, 1.2032616]\n",
      "Batch 513/700: Discriminator loss = 1.1463719606399536, GAN loss = [3.3758528, 1.4236282, 1.0909019]\n",
      "Batch 514/700: Discriminator loss = 1.1552480459213257, GAN loss = [3.548431, 1.4470466, 1.2400764]\n",
      "Batch 515/700: Discriminator loss = 1.1697876453399658, GAN loss = [3.5088804, 1.5069749, 1.1406087]\n",
      "Batch 516/700: Discriminator loss = 1.138736605644226, GAN loss = [3.4584777, 1.3763486, 1.2208441]\n",
      "Batch 517/700: Discriminator loss = 1.1396377086639404, GAN loss = [3.4034252, 1.3395518, 1.2026008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 518/700: Discriminator loss = 1.1934343576431274, GAN loss = [3.3811712, 1.4150463, 1.1048555]\n",
      "Batch 519/700: Discriminator loss = 1.1023046970367432, GAN loss = [3.5732667, 1.4016523, 1.3103489]\n",
      "Batch 520/700: Discriminator loss = 1.1607062816619873, GAN loss = [3.418703, 1.3526776, 1.2047644]\n",
      "Batch 521/700: Discriminator loss = 1.2010711431503296, GAN loss = [3.2799697, 1.3563064, 1.0624058]\n",
      "Batch 522/700: Discriminator loss = 1.1648985147476196, GAN loss = [3.3814743, 1.3633776, 1.1568515]\n",
      "Batch 523/700: Discriminator loss = 1.1487252712249756, GAN loss = [3.3908904, 1.3450627, 1.1845943]\n",
      "Batch 524/700: Discriminator loss = 1.1796923875808716, GAN loss = [3.3108125, 1.3254601, 1.1241292]\n",
      "Batch 525/700: Discriminator loss = 1.1617804765701294, GAN loss = [3.3190763, 1.298573, 1.1592913]\n",
      "Batch 526/700: Discriminator loss = 1.1236854791641235, GAN loss = [3.3791451, 1.3372619, 1.1806778]\n",
      "Batch 527/700: Discriminator loss = 1.1045730113983154, GAN loss = [3.4723778, 1.3454825, 1.2656887]\n",
      "Batch 528/700: Discriminator loss = 1.2301002740859985, GAN loss = [3.2966943, 1.3972981, 1.0381875]\n",
      "Batch 529/700: Discriminator loss = 1.1120078563690186, GAN loss = [3.3412616, 1.3691585, 1.1108825]\n",
      "Batch 530/700: Discriminator loss = 1.154052972793579, GAN loss = [3.2522595, 1.3492497, 1.0417801]\n",
      "Batch 531/700: Discriminator loss = 1.1123101711273193, GAN loss = [3.3192425, 1.3328842, 1.1251167]\n",
      "Batch 532/700: Discriminator loss = 1.177132487297058, GAN loss = [3.1730797, 1.3233584, 0.98847127]\n",
      "Batch 533/700: Discriminator loss = 1.2067511081695557, GAN loss = [3.1456213, 1.3193928, 0.96497285]\n",
      "Batch 534/700: Discriminator loss = 1.1269760131835938, GAN loss = [3.1656637, 1.3188331, 0.9855679]\n",
      "Batch 535/700: Discriminator loss = 1.1703249216079712, GAN loss = [3.1879787, 1.3020705, 1.0246364]\n",
      "Batch 536/700: Discriminator loss = 1.194777011871338, GAN loss = [3.2340486, 1.3077403, 1.0650246]\n",
      "Batch 537/700: Discriminator loss = 1.1534219980239868, GAN loss = [3.1228328, 1.28025, 0.9812837]\n",
      "Batch 538/700: Discriminator loss = 1.1456350088119507, GAN loss = [3.1825037, 1.2881144, 1.0330759]\n",
      "Batch 539/700: Discriminator loss = 1.1217888593673706, GAN loss = [3.2551486, 1.2988094, 1.0950136]\n",
      "Batch 540/700: Discriminator loss = 1.1818536520004272, GAN loss = [3.1164672, 1.2264787, 1.0286446]\n",
      "Batch 541/700: Discriminator loss = 1.2145195007324219, GAN loss = [3.0837357, 1.212117, 1.0102607]\n",
      "Batch 542/700: Discriminator loss = 1.1883418560028076, GAN loss = [3.2195675, 1.2932254, 1.0649742]\n",
      "Batch 543/700: Discriminator loss = 1.200958013534546, GAN loss = [2.9968407, 1.1899159, 0.9455506]\n",
      "Batch 544/700: Discriminator loss = 1.2120856046676636, GAN loss = [3.079133, 1.2202032, 0.9975438]\n",
      "Batch 545/700: Discriminator loss = 1.1909080743789673, GAN loss = [3.06887, 1.2337412, 0.9737313]\n",
      "Batch 546/700: Discriminator loss = 1.1942487955093384, GAN loss = [3.084834, 1.232241, 0.991187]\n",
      "Batch 547/700: Discriminator loss = 1.1446975469589233, GAN loss = [3.1595016, 1.2494682, 1.0486165]\n",
      "Batch 548/700: Discriminator loss = 1.1770408153533936, GAN loss = [3.275297, 1.246305, 1.1675667]\n",
      "Batch 549/700: Discriminator loss = 1.151242733001709, GAN loss = [3.2447462, 1.2369092, 1.1464077]\n",
      "Batch 550/700: Discriminator loss = 1.1695653200149536, GAN loss = [3.2677922, 1.2729152, 1.1334424]\n",
      "Batch 551/700: Discriminator loss = 1.1811187267303467, GAN loss = [3.193284, 1.260735, 1.0711137]\n",
      "Batch 552/700: Discriminator loss = 1.1290860176086426, GAN loss = [3.16242, 1.2581483, 1.0428354]\n",
      "Batch 553/700: Discriminator loss = 1.134291172027588, GAN loss = [3.1913545, 1.2538826, 1.0760412]\n",
      "Batch 554/700: Discriminator loss = 1.11754310131073, GAN loss = [3.25674, 1.2123396, 1.1829803]\n",
      "Batch 555/700: Discriminator loss = 1.0686895847320557, GAN loss = [3.365395, 1.2400836, 1.2639011]\n",
      "Batch 556/700: Discriminator loss = 1.1279590129852295, GAN loss = [3.2205155, 1.266189, 1.0929253]\n",
      "Batch 557/700: Discriminator loss = 1.1195828914642334, GAN loss = [3.4019191, 1.3159927, 1.224534]\n",
      "Batch 558/700: Discriminator loss = 1.131188154220581, GAN loss = [3.1677246, 1.2140949, 1.0922514]\n",
      "Batch 559/700: Discriminator loss = 1.090653657913208, GAN loss = [3.3870687, 1.2279013, 1.2978057]\n",
      "Batch 560/700: Discriminator loss = 1.112470269203186, GAN loss = [3.344304, 1.2498988, 1.2330573]\n",
      "Batch 561/700: Discriminator loss = 1.0918121337890625, GAN loss = [3.3105571, 1.2115043, 1.2377176]\n",
      "Batch 562/700: Discriminator loss = 1.1113604307174683, GAN loss = [3.225261, 1.2258357, 1.1381009]\n",
      "Batch 563/700: Discriminator loss = 1.088639736175537, GAN loss = [3.3919814, 1.2410138, 1.2896533]\n",
      "Batch 564/700: Discriminator loss = 1.0837761163711548, GAN loss = [3.2714293, 1.2074766, 1.202642]\n",
      "Batch 565/700: Discriminator loss = 1.0946931838989258, GAN loss = [3.417754, 1.2596834, 1.2967645]\n",
      "Batch 566/700: Discriminator loss = 1.095947504043579, GAN loss = [3.4252925, 1.2534156, 1.3105725]\n",
      "Batch 567/700: Discriminator loss = 1.0541819334030151, GAN loss = [3.5678632, 1.2777698, 1.4287906]\n",
      "Batch 568/700: Discriminator loss = 1.067426323890686, GAN loss = [3.2873466, 1.2698973, 1.1561456]\n",
      "Batch 569/700: Discriminator loss = 1.0732766389846802, GAN loss = [3.4093876, 1.2549914, 1.2930945]\n",
      "Batch 570/700: Discriminator loss = 1.12226140499115, GAN loss = [3.2044005, 1.256737, 1.0863639]\n",
      "Batch 571/700: Discriminator loss = 1.0922003984451294, GAN loss = [3.391308, 1.2504117, 1.2796001]\n",
      "Batch 572/700: Discriminator loss = 1.062659502029419, GAN loss = [3.4029317, 1.252428, 1.2892096]\n",
      "Batch 573/700: Discriminator loss = 1.0797340869903564, GAN loss = [3.3855443, 1.2913878, 1.232864]\n",
      "Batch 574/700: Discriminator loss = 1.1033159494400024, GAN loss = [3.4023466, 1.316545, 1.2245096]\n",
      "Batch 575/700: Discriminator loss = 1.059992790222168, GAN loss = [3.4743826, 1.3144089, 1.2986854]\n",
      "Batch 576/700: Discriminator loss = 1.0575029850006104, GAN loss = [3.3854618, 1.3428079, 1.1813687]\n",
      "Batch 577/700: Discriminator loss = 1.0890631675720215, GAN loss = [3.3384805, 1.2879294, 1.189274]\n",
      "Batch 578/700: Discriminator loss = 1.1307951211929321, GAN loss = [3.1837234, 1.2190232, 1.1034329]\n",
      "Batch 579/700: Discriminator loss = 1.1166915893554688, GAN loss = [3.3172166, 1.2767327, 1.1792262]\n",
      "Batch 580/700: Discriminator loss = 1.0832709074020386, GAN loss = [3.4102137, 1.2799774, 1.2689865]\n",
      "Batch 581/700: Discriminator loss = 1.0860346555709839, GAN loss = [3.3620253, 1.2687426, 1.2320433]\n",
      "Batch 582/700: Discriminator loss = 1.0919830799102783, GAN loss = [3.4274483, 1.2814755, 1.2847437]\n",
      "Batch 583/700: Discriminator loss = 1.1025556325912476, GAN loss = [3.3757405, 1.2417607, 1.2727628]\n",
      "Batch 584/700: Discriminator loss = 1.1380462646484375, GAN loss = [3.3307157, 1.2501595, 1.2193501]\n",
      "Batch 585/700: Discriminator loss = 1.086977243423462, GAN loss = [3.4337435, 1.2911552, 1.2813942]\n",
      "Batch 586/700: Discriminator loss = 1.0889989137649536, GAN loss = [3.5703316, 1.3151623, 1.3939872]\n",
      "Batch 587/700: Discriminator loss = 1.1051857471466064, GAN loss = [3.3660681, 1.2968265, 1.20807]\n",
      "Batch 588/700: Discriminator loss = 1.119369387626648, GAN loss = [3.4018235, 1.2816172, 1.2590454]\n",
      "Batch 589/700: Discriminator loss = 1.0967106819152832, GAN loss = [3.4851458, 1.2668064, 1.3571926]\n",
      "Batch 590/700: Discriminator loss = 1.0768578052520752, GAN loss = [3.7390294, 1.3362199, 1.541676]\n",
      "Batch 591/700: Discriminator loss = 1.0515851974487305, GAN loss = [3.483827, 1.3082609, 1.3144515]\n",
      "Batch 592/700: Discriminator loss = 1.0929561853408813, GAN loss = [3.6916747, 1.3327397, 1.4978375]\n",
      "Batch 593/700: Discriminator loss = 1.0859180688858032, GAN loss = [3.6029785, 1.315944, 1.4259577]\n",
      "Batch 594/700: Discriminator loss = 1.0920186042785645, GAN loss = [3.604794, 1.3107265, 1.4330094]\n",
      "Batch 595/700: Discriminator loss = 1.0671879053115845, GAN loss = [3.5349224, 1.3369938, 1.3368894]\n",
      "Batch 596/700: Discriminator loss = 1.0819681882858276, GAN loss = [3.4632208, 1.3183202, 1.2838807]\n",
      "Batch 597/700: Discriminator loss = 1.0651229619979858, GAN loss = [3.6796613, 1.3528035, 1.4658638]\n",
      "Batch 598/700: Discriminator loss = 1.1003166437149048, GAN loss = [3.6507642, 1.3697302, 1.4200624]\n",
      "Batch 599/700: Discriminator loss = 1.0843448638916016, GAN loss = [3.6476314, 1.3636833, 1.4229933]\n",
      "Batch 600/700: Discriminator loss = 1.087610125541687, GAN loss = [3.4862666, 1.364145, 1.2611817]\n",
      "Batch 601/700: Discriminator loss = 1.0696895122528076, GAN loss = [3.7044017, 1.3920969, 1.4513866]\n",
      "Batch 602/700: Discriminator loss = 1.09356689453125, GAN loss = [3.5667415, 1.4058453, 1.300001]\n",
      "Batch 603/700: Discriminator loss = 1.0819005966186523, GAN loss = [3.6024485, 1.3866887, 1.3548877]\n",
      "Batch 604/700: Discriminator loss = 1.1190837621688843, GAN loss = [3.6072516, 1.4159094, 1.3304884]\n",
      "Batch 605/700: Discriminator loss = 1.0994129180908203, GAN loss = [3.6529143, 1.4014145, 1.3906666]\n",
      "Batch 606/700: Discriminator loss = 1.1121939420700073, GAN loss = [3.4378967, 1.4349108, 1.1421676]\n",
      "Batch 607/700: Discriminator loss = 1.0896435976028442, GAN loss = [3.6300871, 1.4277639, 1.3415238]\n",
      "Batch 608/700: Discriminator loss = 1.1286780834197998, GAN loss = [3.5806139, 1.4203572, 1.2994742]\n",
      "Batch 609/700: Discriminator loss = 1.0625650882720947, GAN loss = [3.5365195, 1.4074609, 1.2682892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 610/700: Discriminator loss = 1.106755256652832, GAN loss = [3.669671, 1.4454739, 1.363442]\n",
      "Batch 611/700: Discriminator loss = 1.0700546503067017, GAN loss = [3.6202557, 1.4466641, 1.3128455]\n",
      "Batch 612/700: Discriminator loss = 1.0942063331604004, GAN loss = [3.6455564, 1.4658543, 1.3189664]\n",
      "Batch 613/700: Discriminator loss = 1.083903193473816, GAN loss = [3.507989, 1.4370658, 1.2102057]\n",
      "Batch 614/700: Discriminator loss = 1.0849069356918335, GAN loss = [3.6127617, 1.4629875, 1.2890785]\n",
      "Batch 615/700: Discriminator loss = 1.0983655452728271, GAN loss = [3.5945098, 1.4273224, 1.3065152]\n",
      "Batch 616/700: Discriminator loss = 1.0746530294418335, GAN loss = [3.5561917, 1.4167682, 1.2787668]\n",
      "Batch 617/700: Discriminator loss = 1.0985426902770996, GAN loss = [3.6520433, 1.480727, 1.3106755]\n",
      "Batch 618/700: Discriminator loss = 1.1186187267303467, GAN loss = [3.592157, 1.5003633, 1.2311714]\n",
      "Batch 619/700: Discriminator loss = 1.1149989366531372, GAN loss = [3.5614514, 1.4304953, 1.270353]\n",
      "Batch 620/700: Discriminator loss = 1.1020522117614746, GAN loss = [3.6226087, 1.4572172, 1.3048072]\n",
      "Batch 621/700: Discriminator loss = 1.0553019046783447, GAN loss = [3.6607704, 1.4808525, 1.3193521]\n",
      "Batch 622/700: Discriminator loss = 1.1364521980285645, GAN loss = [3.5093062, 1.449868, 1.1988887]\n",
      "Batch 623/700: Discriminator loss = 1.1364258527755737, GAN loss = [3.4261894, 1.4563519, 1.1093059]\n",
      "Batch 624/700: Discriminator loss = 1.0893793106079102, GAN loss = [3.5805056, 1.4412993, 1.2786899]\n",
      "Batch 625/700: Discriminator loss = 1.1085563898086548, GAN loss = [3.6571596, 1.449883, 1.3467727]\n",
      "Batch 626/700: Discriminator loss = 1.1072770357131958, GAN loss = [3.5221667, 1.4511851, 1.2104936]\n",
      "Batch 627/700: Discriminator loss = 1.105857253074646, GAN loss = [3.627885, 1.4789156, 1.2884963]\n",
      "Batch 628/700: Discriminator loss = 1.078721523284912, GAN loss = [3.7539215, 1.4837697, 1.409697]\n",
      "Batch 629/700: Discriminator loss = 1.139333724975586, GAN loss = [3.6121562, 1.5253147, 1.2264012]\n",
      "Batch 630/700: Discriminator loss = 1.0980749130249023, GAN loss = [3.5446606, 1.4076244, 1.2766091]\n",
      "Batch 631/700: Discriminator loss = 1.0721319913864136, GAN loss = [3.7164078, 1.4779266, 1.3780669]\n",
      "Batch 632/700: Discriminator loss = 1.0764508247375488, GAN loss = [3.561248, 1.4774978, 1.2233483]\n",
      "Batch 633/700: Discriminator loss = 1.07277250289917, GAN loss = [3.6219354, 1.436468, 1.3250777]\n",
      "Batch 634/700: Discriminator loss = 1.0928138494491577, GAN loss = [3.6789906, 1.5280441, 1.2905672]\n",
      "Batch 635/700: Discriminator loss = 1.0705773830413818, GAN loss = [3.6359155, 1.4810939, 1.2944438]\n",
      "Batch 636/700: Discriminator loss = 1.0784177780151367, GAN loss = [3.7082288, 1.4843372, 1.363515]\n",
      "Batch 637/700: Discriminator loss = 1.1025949716567993, GAN loss = [3.697301, 1.5088114, 1.3281186]\n",
      "Batch 638/700: Discriminator loss = 1.1052359342575073, GAN loss = [3.5666807, 1.49544, 1.2108742]\n",
      "Batch 639/700: Discriminator loss = 1.060523271560669, GAN loss = [3.673438, 1.4936153, 1.3194629]\n",
      "Batch 640/700: Discriminator loss = 1.059019684791565, GAN loss = [3.9086916, 1.4795434, 1.5687976]\n",
      "Batch 641/700: Discriminator loss = 1.1163028478622437, GAN loss = [3.7276676, 1.4943503, 1.3729781]\n",
      "Batch 642/700: Discriminator loss = 1.1267516613006592, GAN loss = [3.799849, 1.5546231, 1.3848968]\n",
      "Batch 643/700: Discriminator loss = 1.0756957530975342, GAN loss = [3.6909575, 1.5129886, 1.3176475]\n",
      "Batch 644/700: Discriminator loss = 1.170345425605774, GAN loss = [3.6515214, 1.5117073, 1.2794937]\n",
      "Batch 645/700: Discriminator loss = 1.1395161151885986, GAN loss = [3.694134, 1.5513948, 1.2824167]\n",
      "Batch 646/700: Discriminator loss = 1.1051170825958252, GAN loss = [3.6170487, 1.5215373, 1.235183]\n",
      "Batch 647/700: Discriminator loss = 1.1894631385803223, GAN loss = [3.4295352, 1.4970633, 1.0721388]\n",
      "Batch 648/700: Discriminator loss = 1.0806350708007812, GAN loss = [3.6380727, 1.486834, 1.2908962]\n",
      "Batch 649/700: Discriminator loss = 1.1528706550598145, GAN loss = [3.5342479, 1.4840076, 1.1898876]\n",
      "Batch 650/700: Discriminator loss = 1.1585350036621094, GAN loss = [3.6019654, 1.5239563, 1.2176434]\n",
      "Batch 651/700: Discriminator loss = 1.1756365299224854, GAN loss = [3.4504313, 1.5080866, 1.0819713]\n",
      "Batch 652/700: Discriminator loss = 1.134061574935913, GAN loss = [3.5352364, 1.4698008, 1.2050489]\n",
      "Batch 653/700: Discriminator loss = 1.1462056636810303, GAN loss = [3.4345353, 1.4853234, 1.0888139]\n",
      "Batch 654/700: Discriminator loss = 1.1146231889724731, GAN loss = [3.509961, 1.4996666, 1.1498809]\n",
      "Batch 655/700: Discriminator loss = 1.0808234214782715, GAN loss = [3.8306985, 1.5823468, 1.3879308]\n",
      "Batch 656/700: Discriminator loss = 1.1192854642868042, GAN loss = [3.523592, 1.4702125, 1.1929579]\n",
      "Batch 657/700: Discriminator loss = 1.1565256118774414, GAN loss = [3.507437, 1.4198701, 1.2271457]\n",
      "Batch 658/700: Discriminator loss = 1.1233974695205688, GAN loss = [3.538546, 1.4484693, 1.2296541]\n",
      "Batch 659/700: Discriminator loss = 1.1094355583190918, GAN loss = [3.6230752, 1.470155, 1.2925001]\n",
      "Batch 660/700: Discriminator loss = 1.0705710649490356, GAN loss = [3.604569, 1.4730679, 1.2710862]\n",
      "Batch 661/700: Discriminator loss = 1.1052037477493286, GAN loss = [3.5147038, 1.4452317, 1.2090658]\n",
      "Batch 662/700: Discriminator loss = 1.066336989402771, GAN loss = [3.629065, 1.4484384, 1.3202306]\n",
      "Batch 663/700: Discriminator loss = 1.0954208374023438, GAN loss = [3.586945, 1.4454807, 1.2810858]\n",
      "Batch 664/700: Discriminator loss = 1.1175178289413452, GAN loss = [3.5651844, 1.4254706, 1.2793599]\n",
      "Batch 665/700: Discriminator loss = 1.0993216037750244, GAN loss = [3.653892, 1.4647374, 1.3288274]\n",
      "Batch 666/700: Discriminator loss = 1.1387263536453247, GAN loss = [3.6269345, 1.4959053, 1.2707317]\n",
      "Batch 667/700: Discriminator loss = 1.0841753482818604, GAN loss = [3.6165287, 1.4399643, 1.3162957]\n",
      "Batch 668/700: Discriminator loss = 1.105918049812317, GAN loss = [3.5726616, 1.461879, 1.2505404]\n",
      "Batch 669/700: Discriminator loss = 1.0903327465057373, GAN loss = [3.630234, 1.437662, 1.3323588]\n",
      "Batch 670/700: Discriminator loss = 1.0773427486419678, GAN loss = [3.5019572, 1.416079, 1.2256979]\n",
      "Batch 671/700: Discriminator loss = 1.0669670104980469, GAN loss = [3.7597392, 1.4751773, 1.4244128]\n",
      "Batch 672/700: Discriminator loss = 1.0752482414245605, GAN loss = [3.693582, 1.4866018, 1.346866]\n",
      "Batch 673/700: Discriminator loss = 1.133272409439087, GAN loss = [3.5293517, 1.4696127, 1.1996592]\n",
      "Batch 674/700: Discriminator loss = 1.0877103805541992, GAN loss = [3.598181, 1.4364287, 1.3017082]\n",
      "Batch 675/700: Discriminator loss = 1.110025405883789, GAN loss = [3.7062685, 1.4932714, 1.3529891]\n",
      "Batch 676/700: Discriminator loss = 1.0949345827102661, GAN loss = [3.621341, 1.4512614, 1.3101083]\n",
      "Batch 677/700: Discriminator loss = 1.0746954679489136, GAN loss = [3.7572663, 1.518802, 1.3785323]\n",
      "Batch 678/700: Discriminator loss = 1.0706489086151123, GAN loss = [3.8548, 1.4858114, 1.5090938]\n",
      "Batch 679/700: Discriminator loss = 1.0466070175170898, GAN loss = [3.7704487, 1.4623976, 1.4481902]\n",
      "Batch 680/700: Discriminator loss = 1.065618872642517, GAN loss = [3.8490539, 1.4967624, 1.4924601]\n",
      "Batch 681/700: Discriminator loss = 1.0576475858688354, GAN loss = [3.6857264, 1.4704345, 1.3554912]\n",
      "Batch 682/700: Discriminator loss = 1.0656698942184448, GAN loss = [3.608032, 1.4597845, 1.2884752]\n",
      "Batch 683/700: Discriminator loss = 1.0167168378829956, GAN loss = [3.908372, 1.4802955, 1.5683295]\n",
      "Batch 684/700: Discriminator loss = 1.0429688692092896, GAN loss = [3.783478, 1.4963058, 1.427456]\n",
      "Batch 685/700: Discriminator loss = 1.0140184164047241, GAN loss = [3.9974256, 1.5196586, 1.6180816]\n",
      "Batch 686/700: Discriminator loss = 1.01541006565094, GAN loss = [3.8518088, 1.4994546, 1.492698]\n",
      "Batch 687/700: Discriminator loss = 1.0411468744277954, GAN loss = [3.8146756, 1.5334923, 1.421556]\n",
      "Batch 688/700: Discriminator loss = 0.9836048483848572, GAN loss = [4.0551476, 1.5677971, 1.6277549]\n",
      "Batch 689/700: Discriminator loss = 1.0063413381576538, GAN loss = [4.084186, 1.5500838, 1.6745355]\n",
      "Batch 690/700: Discriminator loss = 1.0333951711654663, GAN loss = [3.9552908, 1.5415709, 1.5541809]\n",
      "Batch 691/700: Discriminator loss = 1.0030218362808228, GAN loss = [3.9229422, 1.5476669, 1.515755]\n",
      "Batch 692/700: Discriminator loss = 1.0402700901031494, GAN loss = [3.842834, 1.5318782, 1.4514483]\n",
      "Batch 693/700: Discriminator loss = 1.0536209344863892, GAN loss = [3.9165237, 1.5658075, 1.4912174]\n",
      "Batch 694/700: Discriminator loss = 1.0599534511566162, GAN loss = [3.924636, 1.6092583, 1.4558864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 695/700: Discriminator loss = 1.007440209388733, GAN loss = [4.024399, 1.5852723, 1.5796465]\n",
      "Batch 696/700: Discriminator loss = 1.0147610902786255, GAN loss = [4.122036, 1.6776547, 1.5849159]\n",
      "Batch 697/700: Discriminator loss = 0.9836249351501465, GAN loss = [4.1867137, 1.6350625, 1.6922039]\n",
      "Batch 698/700: Discriminator loss = 1.0371088981628418, GAN loss = [4.0744395, 1.6620575, 1.5529523]\n",
      "Batch 699/700: Discriminator loss = 1.0751395225524902, GAN loss = [4.0915637, 1.7780515, 1.4541019]\n",
      "Batch 700/700: Discriminator loss = 1.0187643766403198, GAN loss = [4.133814, 1.6812668, 1.5931535]\n",
      "Epoch 5/30\n",
      "Batch 1/700: Discriminator loss = 1.086338996887207, GAN loss = [4.1775293, 1.7392082, 1.5789402]\n",
      "Batch 2/700: Discriminator loss = 1.000451922416687, GAN loss = [4.2493644, 1.7331303, 1.6568604]\n",
      "Batch 3/700: Discriminator loss = 1.0314542055130005, GAN loss = [4.1114173, 1.7124966, 1.5395551]\n",
      "Batch 4/700: Discriminator loss = 1.0657727718353271, GAN loss = [4.086061, 1.7542173, 1.4724878]\n",
      "Batch 5/700: Discriminator loss = 1.0273751020431519, GAN loss = [4.239229, 1.7366792, 1.6432042]\n",
      "Batch 6/700: Discriminator loss = 0.9736171364784241, GAN loss = [4.309496, 1.7152904, 1.7348675]\n",
      "Batch 7/700: Discriminator loss = 1.0120890140533447, GAN loss = [4.3204885, 1.7534301, 1.7077259]\n",
      "Batch 8/700: Discriminator loss = 1.0513395071029663, GAN loss = [4.1229477, 1.7167087, 1.5469077]\n",
      "Batch 9/700: Discriminator loss = 1.0309244394302368, GAN loss = [4.144997, 1.6911721, 1.5944949]\n",
      "Batch 10/700: Discriminator loss = 0.9854433536529541, GAN loss = [4.384711, 1.7623074, 1.7630745]\n",
      "Batch 11/700: Discriminator loss = 1.017317771911621, GAN loss = [4.3400307, 1.7880789, 1.6926266]\n",
      "Batch 12/700: Discriminator loss = 1.0257385969161987, GAN loss = [4.3408637, 1.7533303, 1.7282122]\n",
      "Batch 13/700: Discriminator loss = 1.0391464233398438, GAN loss = [4.3175035, 1.770512, 1.6876733]\n",
      "Batch 14/700: Discriminator loss = 1.1048152446746826, GAN loss = [4.0390544, 1.8235124, 1.3562317]\n",
      "Batch 15/700: Discriminator loss = 1.0694772005081177, GAN loss = [4.3218665, 1.9010589, 1.5615059]\n",
      "Batch 16/700: Discriminator loss = 1.0734496116638184, GAN loss = [4.1499887, 1.8143382, 1.476357]\n",
      "Batch 17/700: Discriminator loss = 1.1034278869628906, GAN loss = [3.9876587, 1.8004045, 1.3279674]\n",
      "Batch 18/700: Discriminator loss = 1.0570566654205322, GAN loss = [4.2169414, 1.8030568, 1.5546062]\n",
      "Batch 19/700: Discriminator loss = 1.061705231666565, GAN loss = [4.2195373, 1.8019016, 1.558372]\n",
      "Batch 20/700: Discriminator loss = 1.0482020378112793, GAN loss = [4.533261, 1.8323973, 1.8416171]\n",
      "Batch 21/700: Discriminator loss = 1.0957508087158203, GAN loss = [4.2389607, 1.7756336, 1.6041045]\n",
      "Batch 22/700: Discriminator loss = 1.0879290103912354, GAN loss = [4.29185, 1.8964603, 1.5361879]\n",
      "Batch 23/700: Discriminator loss = 1.0275498628616333, GAN loss = [4.156497, 1.7701545, 1.5271554]\n",
      "Batch 24/700: Discriminator loss = 1.0243867635726929, GAN loss = [4.4559507, 1.7804946, 1.8162886]\n",
      "Batch 25/700: Discriminator loss = 1.0767666101455688, GAN loss = [4.242132, 1.7744231, 1.6085632]\n",
      "Batch 26/700: Discriminator loss = 1.0977970361709595, GAN loss = [4.0544066, 1.7331738, 1.4621049]\n",
      "Batch 27/700: Discriminator loss = 1.1397110223770142, GAN loss = [4.2794733, 1.7748817, 1.6454816]\n",
      "Batch 28/700: Discriminator loss = 1.1354591846466064, GAN loss = [4.332968, 1.8567207, 1.6171552]\n",
      "Batch 29/700: Discriminator loss = 1.0232805013656616, GAN loss = [4.4887543, 1.7569281, 1.8727577]\n",
      "Batch 30/700: Discriminator loss = 1.0890218019485474, GAN loss = [4.196897, 1.7053207, 1.6325362]\n",
      "Batch 31/700: Discriminator loss = 1.1124680042266846, GAN loss = [4.140273, 1.7177663, 1.5634928]\n",
      "Batch 32/700: Discriminator loss = 1.0670377016067505, GAN loss = [4.231498, 1.7808952, 1.5916172]\n",
      "Batch 33/700: Discriminator loss = 1.0470701456069946, GAN loss = [4.2377505, 1.7325003, 1.6462932]\n",
      "Batch 34/700: Discriminator loss = 1.0688140392303467, GAN loss = [4.110293, 1.7051187, 1.5462474]\n",
      "Batch 35/700: Discriminator loss = 0.9984931349754333, GAN loss = [4.476099, 1.7154095, 1.9017905]\n",
      "Batch 36/700: Discriminator loss = 1.0684703588485718, GAN loss = [4.131814, 1.7612185, 1.5117259]\n",
      "Batch 37/700: Discriminator loss = 1.0112453699111938, GAN loss = [4.5036364, 1.7120084, 1.9327846]\n",
      "Batch 38/700: Discriminator loss = 1.0544111728668213, GAN loss = [4.233647, 1.6959796, 1.6788467]\n",
      "Batch 39/700: Discriminator loss = 0.9738451242446899, GAN loss = [4.628231, 1.6878551, 2.0815773]\n",
      "Batch 40/700: Discriminator loss = 1.080673336982727, GAN loss = [4.3300548, 1.710693, 1.7605885]\n",
      "Batch 41/700: Discriminator loss = 1.0042773485183716, GAN loss = [4.407065, 1.6693937, 1.8789171]\n",
      "Batch 42/700: Discriminator loss = 1.044374942779541, GAN loss = [4.3130975, 1.6102103, 1.8441498]\n",
      "Batch 43/700: Discriminator loss = 1.0837867259979248, GAN loss = [4.2325664, 1.6771476, 1.6966949]\n",
      "Batch 44/700: Discriminator loss = 1.0629997253417969, GAN loss = [4.3657603, 1.840401, 1.6666512]\n",
      "Batch 45/700: Discriminator loss = 1.071689248085022, GAN loss = [4.170679, 1.7429116, 1.5690783]\n",
      "Batch 46/700: Discriminator loss = 1.0495107173919678, GAN loss = [4.221443, 1.6832048, 1.6795658]\n",
      "Batch 47/700: Discriminator loss = 1.0896382331848145, GAN loss = [4.2365055, 1.7201535, 1.6576886]\n",
      "Batch 48/700: Discriminator loss = 1.0716526508331299, GAN loss = [4.1828766, 1.6995714, 1.6246506]\n",
      "Batch 49/700: Discriminator loss = 1.0229941606521606, GAN loss = [4.345155, 1.6648668, 1.8216393]\n",
      "Batch 50/700: Discriminator loss = 1.0824916362762451, GAN loss = [4.428973, 1.7229799, 1.8473471]\n",
      "Batch 51/700: Discriminator loss = 1.0313900709152222, GAN loss = [4.302723, 1.6268284, 1.817252]\n",
      "Batch 52/700: Discriminator loss = 1.0596975088119507, GAN loss = [4.233545, 1.6752985, 1.6996057]\n",
      "Batch 53/700: Discriminator loss = 1.0226733684539795, GAN loss = [4.508229, 1.7195665, 1.9300238]\n",
      "Batch 54/700: Discriminator loss = 1.0229920148849487, GAN loss = [4.5782056, 1.7415872, 1.9779825]\n",
      "Batch 55/700: Discriminator loss = 1.051323413848877, GAN loss = [4.1353455, 1.6142584, 1.6624539]\n",
      "Batch 56/700: Discriminator loss = 1.007667064666748, GAN loss = [4.2904687, 1.6471733, 1.7846678]\n",
      "Batch 57/700: Discriminator loss = 1.099661111831665, GAN loss = [4.179476, 1.6935745, 1.6272805]\n",
      "Batch 58/700: Discriminator loss = 1.0769917964935303, GAN loss = [4.4529967, 1.7310697, 1.863316]\n",
      "Batch 59/700: Discriminator loss = 1.0153164863586426, GAN loss = [4.3064823, 1.6274195, 1.8204606]\n",
      "Batch 60/700: Discriminator loss = 1.0240956544876099, GAN loss = [4.270853, 1.6564004, 1.7558593]\n",
      "Batch 61/700: Discriminator loss = 1.0130966901779175, GAN loss = [4.287937, 1.6596903, 1.7696624]\n",
      "Batch 62/700: Discriminator loss = 1.007684588432312, GAN loss = [4.245361, 1.6922601, 1.6945282]\n",
      "Batch 63/700: Discriminator loss = 1.1059306859970093, GAN loss = [4.078718, 1.773039, 1.4471207]\n",
      "Batch 64/700: Discriminator loss = 1.0200351476669312, GAN loss = [4.090477, 1.7248138, 1.5071197]\n",
      "Batch 65/700: Discriminator loss = 1.0938701629638672, GAN loss = [4.0930123, 1.8226976, 1.4117856]\n",
      "Batch 66/700: Discriminator loss = 1.0997720956802368, GAN loss = [3.9366574, 1.7198918, 1.3582448]\n",
      "Batch 67/700: Discriminator loss = 1.1100775003433228, GAN loss = [4.0211654, 1.7924196, 1.3702327]\n",
      "Batch 68/700: Discriminator loss = 1.1086872816085815, GAN loss = [3.881167, 1.6965042, 1.3261583]\n",
      "Batch 69/700: Discriminator loss = 1.064951777458191, GAN loss = [3.9932466, 1.6968592, 1.4378896]\n",
      "Batch 70/700: Discriminator loss = 1.1280367374420166, GAN loss = [4.100033, 1.8473678, 1.394176]\n",
      "Batch 71/700: Discriminator loss = 1.0780882835388184, GAN loss = [3.8790472, 1.6614391, 1.3591272]\n",
      "Batch 72/700: Discriminator loss = 1.1527138948440552, GAN loss = [4.0432954, 1.7488997, 1.4359233]\n",
      "Batch 73/700: Discriminator loss = 1.1186840534210205, GAN loss = [3.8013425, 1.6752369, 1.2676412]\n",
      "Batch 74/700: Discriminator loss = 1.1088719367980957, GAN loss = [3.934407, 1.7056102, 1.3703413]\n",
      "Batch 75/700: Discriminator loss = 1.0906643867492676, GAN loss = [3.8903432, 1.6495492, 1.3823439]\n",
      "Batch 76/700: Discriminator loss = 1.2118507623672485, GAN loss = [3.6233597, 1.6804051, 1.0845101]\n",
      "Batch 77/700: Discriminator loss = 1.1682932376861572, GAN loss = [3.862437, 1.7679063, 1.2360895]\n",
      "Batch 78/700: Discriminator loss = 1.1349718570709229, GAN loss = [3.866652, 1.7103766, 1.297837]\n",
      "Batch 79/700: Discriminator loss = 1.1990489959716797, GAN loss = [3.7782547, 1.7378345, 1.1819911]\n",
      "Batch 80/700: Discriminator loss = 1.1470032930374146, GAN loss = [3.7334151, 1.7825661, 1.0924277]\n",
      "Batch 81/700: Discriminator loss = 1.178795337677002, GAN loss = [3.8147252, 1.7716752, 1.1846393]\n",
      "Batch 82/700: Discriminator loss = 1.1615322828292847, GAN loss = [3.6762056, 1.7035402, 1.1142716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 83/700: Discriminator loss = 1.1386946439743042, GAN loss = [3.6862528, 1.6368859, 1.1909928]\n",
      "Batch 84/700: Discriminator loss = 1.0700129270553589, GAN loss = [3.7260225, 1.6011479, 1.266523]\n",
      "Batch 85/700: Discriminator loss = 1.1366766691207886, GAN loss = [3.777022, 1.6175157, 1.3011775]\n",
      "Batch 86/700: Discriminator loss = 1.0494495630264282, GAN loss = [4.135712, 1.6776712, 1.5997367]\n",
      "Batch 87/700: Discriminator loss = 1.0765804052352905, GAN loss = [3.8288581, 1.5955019, 1.3750745]\n",
      "Batch 88/700: Discriminator loss = 1.1601872444152832, GAN loss = [3.8466918, 1.6621654, 1.3262712]\n",
      "Batch 89/700: Discriminator loss = 1.1794836521148682, GAN loss = [3.7224417, 1.5839705, 1.2802466]\n",
      "Batch 90/700: Discriminator loss = 1.1173417568206787, GAN loss = [3.8092496, 1.6484734, 1.3025823]\n",
      "Batch 91/700: Discriminator loss = 1.0639678239822388, GAN loss = [4.040664, 1.6216453, 1.5608547]\n",
      "Batch 92/700: Discriminator loss = 1.111587405204773, GAN loss = [3.7219577, 1.6070564, 1.2567672]\n",
      "Batch 93/700: Discriminator loss = 1.227192997932434, GAN loss = [3.7481725, 1.6683446, 1.2217354]\n",
      "Batch 94/700: Discriminator loss = 1.1283022165298462, GAN loss = [3.612991, 1.5799377, 1.1749997]\n",
      "Batch 95/700: Discriminator loss = 1.1138761043548584, GAN loss = [3.677806, 1.5730189, 1.2467685]\n",
      "Batch 96/700: Discriminator loss = 1.1076114177703857, GAN loss = [3.7412648, 1.5585964, 1.3246807]\n",
      "Batch 97/700: Discriminator loss = 1.114656686782837, GAN loss = [3.778054, 1.5947171, 1.3253777]\n",
      "Batch 98/700: Discriminator loss = 1.1045938730239868, GAN loss = [3.6298602, 1.5173547, 1.2545733]\n",
      "Batch 99/700: Discriminator loss = 1.2224313020706177, GAN loss = [3.490641, 1.531505, 1.1012269]\n",
      "Batch 100/700: Discriminator loss = 1.0791945457458496, GAN loss = [3.6688945, 1.5235409, 1.2874643]\n",
      "Batch 101/700: Discriminator loss = 1.1446431875228882, GAN loss = [3.754089, 1.5160794, 1.3801391]\n",
      "Batch 102/700: Discriminator loss = 1.1041816473007202, GAN loss = [3.7220485, 1.5571563, 1.3070297]\n",
      "Batch 103/700: Discriminator loss = 1.0865191221237183, GAN loss = [3.5937104, 1.4341632, 1.3016937]\n",
      "Batch 104/700: Discriminator loss = 1.143190860748291, GAN loss = [3.6030622, 1.4453115, 1.2999077]\n",
      "Batch 105/700: Discriminator loss = 1.0729856491088867, GAN loss = [3.9227033, 1.5515143, 1.5133579]\n",
      "Batch 106/700: Discriminator loss = 1.1394214630126953, GAN loss = [3.8454268, 1.5664121, 1.4211963]\n",
      "Batch 107/700: Discriminator loss = 1.0671170949935913, GAN loss = [3.7817116, 1.5048884, 1.4190185]\n",
      "Batch 108/700: Discriminator loss = 1.1070531606674194, GAN loss = [3.762521, 1.5625279, 1.3422066]\n",
      "Batch 109/700: Discriminator loss = 1.0801599025726318, GAN loss = [3.8957765, 1.6167232, 1.4212881]\n",
      "Batch 110/700: Discriminator loss = 1.0503404140472412, GAN loss = [4.0422773, 1.5814115, 1.6031182]\n",
      "Batch 111/700: Discriminator loss = 1.0468952655792236, GAN loss = [3.9201295, 1.5937057, 1.4686989]\n",
      "Batch 112/700: Discriminator loss = 1.0315724611282349, GAN loss = [4.002379, 1.5999744, 1.5447106]\n",
      "Batch 113/700: Discriminator loss = 1.107092261314392, GAN loss = [3.7028496, 1.5600345, 1.2851541]\n",
      "Batch 114/700: Discriminator loss = 1.0701252222061157, GAN loss = [3.9587133, 1.5712953, 1.529787]\n",
      "Batch 115/700: Discriminator loss = 1.1834622621536255, GAN loss = [3.6264353, 1.5456394, 1.2231975]\n",
      "Batch 116/700: Discriminator loss = 1.1453219652175903, GAN loss = [3.7214298, 1.6033478, 1.2605107]\n",
      "Batch 117/700: Discriminator loss = 1.0951765775680542, GAN loss = [3.7638388, 1.5738761, 1.3324113]\n",
      "Batch 118/700: Discriminator loss = 1.1018636226654053, GAN loss = [3.6101766, 1.5621402, 1.1905075]\n",
      "Batch 119/700: Discriminator loss = 1.0729068517684937, GAN loss = [3.8009467, 1.5424738, 1.4009743]\n",
      "Batch 120/700: Discriminator loss = 1.1822582483291626, GAN loss = [3.7345407, 1.6965388, 1.1805348]\n",
      "Batch 121/700: Discriminator loss = 1.071398138999939, GAN loss = [3.8284705, 1.6161532, 1.3548803]\n",
      "Batch 122/700: Discriminator loss = 1.0634448528289795, GAN loss = [3.8630173, 1.6357313, 1.3698776]\n",
      "Batch 123/700: Discriminator loss = 1.0929197072982788, GAN loss = [3.89292, 1.6634923, 1.3720508]\n",
      "Batch 124/700: Discriminator loss = 1.0983855724334717, GAN loss = [3.7495053, 1.5917113, 1.3004471]\n",
      "Batch 125/700: Discriminator loss = 1.0946428775787354, GAN loss = [3.8439622, 1.6619704, 1.3246742]\n",
      "Batch 126/700: Discriminator loss = 1.0876802206039429, GAN loss = [3.741613, 1.5692794, 1.3150383]\n",
      "Batch 127/700: Discriminator loss = 1.183574914932251, GAN loss = [3.7036397, 1.6839616, 1.1623994]\n",
      "Batch 128/700: Discriminator loss = 1.1160200834274292, GAN loss = [3.6940663, 1.5820323, 1.2547712]\n",
      "Batch 129/700: Discriminator loss = 1.0480737686157227, GAN loss = [3.8229446, 1.5899886, 1.3757077]\n",
      "Batch 130/700: Discriminator loss = 1.093664526939392, GAN loss = [3.6345341, 1.5555911, 1.2217087]\n",
      "Batch 131/700: Discriminator loss = 1.0896583795547485, GAN loss = [3.924741, 1.6467606, 1.4207588]\n",
      "Batch 132/700: Discriminator loss = 1.0922023057937622, GAN loss = [3.7470126, 1.5970862, 1.2927188]\n",
      "Batch 133/700: Discriminator loss = 1.1453098058700562, GAN loss = [3.7012327, 1.5918365, 1.2522007]\n",
      "Batch 134/700: Discriminator loss = 1.0902827978134155, GAN loss = [3.8282886, 1.5822681, 1.3888359]\n",
      "Batch 135/700: Discriminator loss = 1.1469215154647827, GAN loss = [3.6867397, 1.6118798, 1.2176899]\n",
      "Batch 136/700: Discriminator loss = 1.0365980863571167, GAN loss = [3.9295073, 1.5927908, 1.4795619]\n",
      "Batch 137/700: Discriminator loss = 1.087342619895935, GAN loss = [3.947095, 1.6198907, 1.4700685]\n",
      "Batch 138/700: Discriminator loss = 1.1682205200195312, GAN loss = [3.5630274, 1.5868508, 1.1190577]\n",
      "Batch 139/700: Discriminator loss = 1.0391819477081299, GAN loss = [3.8389943, 1.5971826, 1.3847111]\n",
      "Batch 140/700: Discriminator loss = 1.1383874416351318, GAN loss = [3.9274657, 1.7745373, 1.2958498]\n",
      "Batch 141/700: Discriminator loss = 1.1230638027191162, GAN loss = [3.6963596, 1.6482613, 1.1910317]\n",
      "Batch 142/700: Discriminator loss = 1.1292682886123657, GAN loss = [3.5879364, 1.5937839, 1.1370957]\n",
      "Batch 143/700: Discriminator loss = 1.0734896659851074, GAN loss = [3.718169, 1.5846962, 1.2764298]\n",
      "Batch 144/700: Discriminator loss = 1.0836085081100464, GAN loss = [3.7352166, 1.6131546, 1.2650352]\n",
      "Batch 145/700: Discriminator loss = 1.089632272720337, GAN loss = [3.5930429, 1.5706254, 1.1654065]\n",
      "Batch 146/700: Discriminator loss = 1.138041377067566, GAN loss = [3.5814803, 1.6047674, 1.1197178]\n",
      "Batch 147/700: Discriminator loss = 1.1483137607574463, GAN loss = [3.6128836, 1.5889696, 1.1669316]\n",
      "Batch 148/700: Discriminator loss = 1.1468150615692139, GAN loss = [3.6376574, 1.5996451, 1.1810372]\n",
      "Batch 149/700: Discriminator loss = 1.160219430923462, GAN loss = [3.5581968, 1.5490959, 1.1521329]\n",
      "Batch 150/700: Discriminator loss = 1.1058382987976074, GAN loss = [3.6113758, 1.5507684, 1.2036477]\n",
      "Batch 151/700: Discriminator loss = 1.1320210695266724, GAN loss = [3.6522908, 1.5072097, 1.2881275]\n",
      "Batch 152/700: Discriminator loss = 1.1256873607635498, GAN loss = [3.6660929, 1.4935194, 1.3156258]\n",
      "Batch 153/700: Discriminator loss = 1.104121446609497, GAN loss = [3.7299094, 1.4624971, 1.4104706]\n",
      "Batch 154/700: Discriminator loss = 1.1320788860321045, GAN loss = [3.5740602, 1.506218, 1.2109065]\n",
      "Batch 155/700: Discriminator loss = 1.1817013025283813, GAN loss = [3.4498768, 1.4777471, 1.1152059]\n",
      "Batch 156/700: Discriminator loss = 1.096160650253296, GAN loss = [3.7417705, 1.5137769, 1.3710803]\n",
      "Batch 157/700: Discriminator loss = 1.1323286294937134, GAN loss = [3.6492155, 1.5083055, 1.2840087]\n",
      "Batch 158/700: Discriminator loss = 1.072932481765747, GAN loss = [3.8900847, 1.5275526, 1.505644]\n",
      "Batch 159/700: Discriminator loss = 1.1023072004318237, GAN loss = [3.6938584, 1.522016, 1.3149643]\n",
      "Batch 160/700: Discriminator loss = 1.1328524351119995, GAN loss = [3.7276306, 1.5500395, 1.3207216]\n",
      "Batch 161/700: Discriminator loss = 1.0711711645126343, GAN loss = [3.683485, 1.5210202, 1.3056021]\n",
      "Batch 162/700: Discriminator loss = 1.0615073442459106, GAN loss = [3.8810976, 1.5056592, 1.5185834]\n",
      "Batch 163/700: Discriminator loss = 1.1012042760849, GAN loss = [3.8161814, 1.5978928, 1.3614419]\n",
      "Batch 164/700: Discriminator loss = 1.0341837406158447, GAN loss = [3.8469143, 1.5920873, 1.3979981]\n",
      "Batch 165/700: Discriminator loss = 1.0830812454223633, GAN loss = [3.982881, 1.5775054, 1.5485612]\n",
      "Batch 166/700: Discriminator loss = 1.0807843208312988, GAN loss = [3.820404, 1.5759759, 1.3876259]\n",
      "Batch 167/700: Discriminator loss = 1.1393117904663086, GAN loss = [3.8887992, 1.5729196, 1.4590902]\n",
      "Batch 168/700: Discriminator loss = 1.0789415836334229, GAN loss = [3.6975489, 1.4761343, 1.3646393]\n",
      "Batch 169/700: Discriminator loss = 1.1208590269088745, GAN loss = [3.8674128, 1.5960419, 1.4146149]\n",
      "Batch 170/700: Discriminator loss = 1.0212801694869995, GAN loss = [4.1748033, 1.5985929, 1.7194848]\n",
      "Batch 171/700: Discriminator loss = 1.0661221742630005, GAN loss = [3.866083, 1.5085075, 1.5008813]\n",
      "Batch 172/700: Discriminator loss = 1.105155110359192, GAN loss = [3.8555613, 1.5435448, 1.455354]\n",
      "Batch 173/700: Discriminator loss = 1.0723906755447388, GAN loss = [3.9674182, 1.5151498, 1.5956303]\n",
      "Batch 174/700: Discriminator loss = 1.0823224782943726, GAN loss = [4.0466137, 1.5393915, 1.6506085]\n",
      "Batch 175/700: Discriminator loss = 1.157827615737915, GAN loss = [4.035235, 1.5977733, 1.5808678]\n",
      "Batch 176/700: Discriminator loss = 1.1343108415603638, GAN loss = [3.7944188, 1.5414853, 1.396359]\n",
      "Batch 177/700: Discriminator loss = 1.1135526895523071, GAN loss = [3.6795077, 1.4765935, 1.346355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 178/700: Discriminator loss = 1.1527574062347412, GAN loss = [3.6502817, 1.5255609, 1.2681798]\n",
      "Batch 179/700: Discriminator loss = 1.0880318880081177, GAN loss = [3.8253574, 1.518893, 1.4499451]\n",
      "Batch 180/700: Discriminator loss = 1.1226444244384766, GAN loss = [3.8768802, 1.5481339, 1.4722509]\n",
      "Batch 181/700: Discriminator loss = 1.115460991859436, GAN loss = [3.6861513, 1.5567868, 1.272893]\n",
      "Batch 182/700: Discriminator loss = 1.135347604751587, GAN loss = [3.5807514, 1.5433087, 1.1810043]\n",
      "Batch 183/700: Discriminator loss = 1.0962169170379639, GAN loss = [3.6928506, 1.5967555, 1.2396892]\n",
      "Batch 184/700: Discriminator loss = 1.0893067121505737, GAN loss = [3.6348927, 1.5544407, 1.2240831]\n",
      "Batch 185/700: Discriminator loss = 1.0675437450408936, GAN loss = [3.8877122, 1.5647748, 1.4666022]\n",
      "Batch 186/700: Discriminator loss = 1.0525057315826416, GAN loss = [3.9459653, 1.5490863, 1.5405786]\n",
      "Batch 187/700: Discriminator loss = 1.158508062362671, GAN loss = [3.6269486, 1.5548158, 1.215864]\n",
      "Batch 188/700: Discriminator loss = 1.0346832275390625, GAN loss = [3.8920841, 1.5472149, 1.4886246]\n",
      "Batch 189/700: Discriminator loss = 1.0571072101593018, GAN loss = [3.7899375, 1.4740319, 1.4596863]\n",
      "Batch 190/700: Discriminator loss = 1.0904223918914795, GAN loss = [3.9695992, 1.5411437, 1.5722617]\n",
      "Batch 191/700: Discriminator loss = 1.0620614290237427, GAN loss = [3.9180646, 1.4943122, 1.5675856]\n",
      "Batch 192/700: Discriminator loss = 1.0739939212799072, GAN loss = [3.758591, 1.4841728, 1.4182723]\n",
      "Batch 193/700: Discriminator loss = 1.0484267473220825, GAN loss = [3.683111, 1.4858035, 1.3411837]\n",
      "Batch 194/700: Discriminator loss = 1.0994092226028442, GAN loss = [3.573598, 1.4937268, 1.2237672]\n",
      "Batch 195/700: Discriminator loss = 1.0890589952468872, GAN loss = [3.7639096, 1.4748263, 1.4329997]\n",
      "Batch 196/700: Discriminator loss = 1.0541489124298096, GAN loss = [3.8918383, 1.514643, 1.5211285]\n",
      "Batch 197/700: Discriminator loss = 1.045289158821106, GAN loss = [3.806741, 1.5601676, 1.3905226]\n",
      "Batch 198/700: Discriminator loss = 1.1016874313354492, GAN loss = [3.6317172, 1.5238932, 1.2517964]\n",
      "Batch 199/700: Discriminator loss = 1.062684416770935, GAN loss = [3.902496, 1.50279, 1.5436962]\n",
      "Batch 200/700: Discriminator loss = 1.0714606046676636, GAN loss = [3.7971365, 1.4916787, 1.4494652]\n",
      "Batch 201/700: Discriminator loss = 1.0722060203552246, GAN loss = [3.802943, 1.4859396, 1.461028]\n",
      "Batch 202/700: Discriminator loss = 1.056413173675537, GAN loss = [3.7408888, 1.4689234, 1.4160038]\n",
      "Batch 203/700: Discriminator loss = 1.0778460502624512, GAN loss = [3.7174547, 1.4947243, 1.366782]\n",
      "Batch 204/700: Discriminator loss = 1.1101665496826172, GAN loss = [3.7273402, 1.5032963, 1.368105]\n",
      "Batch 205/700: Discriminator loss = 1.1068378686904907, GAN loss = [3.8525748, 1.5351698, 1.4614753]\n",
      "Batch 206/700: Discriminator loss = 1.0868127346038818, GAN loss = [3.9171216, 1.6267892, 1.434407]\n",
      "Batch 207/700: Discriminator loss = 1.0741366147994995, GAN loss = [3.7615018, 1.4891832, 1.4163976]\n",
      "Batch 208/700: Discriminator loss = 1.091123104095459, GAN loss = [3.6100376, 1.4596908, 1.2944281]\n",
      "Batch 209/700: Discriminator loss = 1.1615784168243408, GAN loss = [3.5305295, 1.4420336, 1.2325785]\n",
      "Batch 210/700: Discriminator loss = 1.1254173517227173, GAN loss = [3.6218154, 1.4291185, 1.33679]\n",
      "Batch 211/700: Discriminator loss = 1.0743837356567383, GAN loss = [3.7510788, 1.4883392, 1.4068352]\n",
      "Batch 212/700: Discriminator loss = 1.1166883707046509, GAN loss = [3.5350006, 1.465124, 1.2139782]\n",
      "Batch 213/700: Discriminator loss = 1.1320645809173584, GAN loss = [3.5592582, 1.4624648, 1.2408997]\n",
      "Batch 214/700: Discriminator loss = 1.1055535078048706, GAN loss = [3.7152758, 1.4844164, 1.374974]\n",
      "Batch 215/700: Discriminator loss = 1.1380378007888794, GAN loss = [3.5268478, 1.4368277, 1.234143]\n",
      "Batch 216/700: Discriminator loss = 1.1026331186294556, GAN loss = [3.5364616, 1.4192245, 1.2613674]\n",
      "Batch 217/700: Discriminator loss = 1.1845802068710327, GAN loss = [3.5336552, 1.4093585, 1.2684387]\n",
      "Batch 218/700: Discriminator loss = 1.1706833839416504, GAN loss = [3.4724596, 1.3462907, 1.270321]\n",
      "Batch 219/700: Discriminator loss = 1.1752984523773193, GAN loss = [3.468533, 1.3576195, 1.2550732]\n",
      "Batch 220/700: Discriminator loss = 1.1843103170394897, GAN loss = [3.509352, 1.4505647, 1.2029545]\n",
      "Batch 221/700: Discriminator loss = 1.1784483194351196, GAN loss = [3.4357443, 1.3623914, 1.2175317]\n",
      "Batch 222/700: Discriminator loss = 1.1696393489837646, GAN loss = [3.5066752, 1.3824413, 1.2684224]\n",
      "Batch 223/700: Discriminator loss = 1.1396586894989014, GAN loss = [3.5707793, 1.3874484, 1.3275316]\n",
      "Batch 224/700: Discriminator loss = 1.2192035913467407, GAN loss = [3.414577, 1.3403889, 1.2184033]\n",
      "Batch 225/700: Discriminator loss = 1.2789491415023804, GAN loss = [3.309775, 1.3847632, 1.069244]\n",
      "Batch 226/700: Discriminator loss = 1.1891746520996094, GAN loss = [3.3540049, 1.3353827, 1.1628752]\n",
      "Batch 227/700: Discriminator loss = 1.159183144569397, GAN loss = [3.457398, 1.3132428, 1.2884347]\n",
      "Batch 228/700: Discriminator loss = 1.1889365911483765, GAN loss = [3.395679, 1.3705876, 1.169392]\n",
      "Batch 229/700: Discriminator loss = 1.1951904296875, GAN loss = [3.5679946, 1.3583527, 1.3539646]\n",
      "Batch 230/700: Discriminator loss = 1.139864444732666, GAN loss = [3.4652586, 1.3189238, 1.2906771]\n",
      "Batch 231/700: Discriminator loss = 1.1922483444213867, GAN loss = [3.416319, 1.3194325, 1.24125]\n",
      "Batch 232/700: Discriminator loss = 1.2118604183197021, GAN loss = [3.3056974, 1.3085005, 1.141582]\n",
      "Batch 233/700: Discriminator loss = 1.1324671506881714, GAN loss = [3.5215528, 1.3078792, 1.3580817]\n",
      "Batch 234/700: Discriminator loss = 1.1714797019958496, GAN loss = [3.399817, 1.3222861, 1.2219677]\n",
      "Batch 235/700: Discriminator loss = 1.1625452041625977, GAN loss = [3.607261, 1.3626965, 1.3890306]\n",
      "Batch 236/700: Discriminator loss = 1.0952945947647095, GAN loss = [3.857622, 1.3866608, 1.6154596]\n",
      "Batch 237/700: Discriminator loss = 1.1352840662002563, GAN loss = [3.5247781, 1.3461298, 1.3231826]\n",
      "Batch 238/700: Discriminator loss = 1.1311851739883423, GAN loss = [3.4728553, 1.3514388, 1.2659892]\n",
      "Batch 239/700: Discriminator loss = 1.1036468744277954, GAN loss = [3.72526, 1.3784755, 1.4913968]\n",
      "Batch 240/700: Discriminator loss = 1.1567054986953735, GAN loss = [3.5411026, 1.3889396, 1.2968122]\n",
      "Batch 241/700: Discriminator loss = 1.0733708143234253, GAN loss = [3.8577287, 1.3541642, 1.6482538]\n",
      "Batch 242/700: Discriminator loss = 1.098046898841858, GAN loss = [3.6286576, 1.344222, 1.4291639]\n",
      "Batch 243/700: Discriminator loss = 1.1316096782684326, GAN loss = [3.5424817, 1.3632933, 1.3239548]\n",
      "Batch 244/700: Discriminator loss = 1.0735543966293335, GAN loss = [3.6743076, 1.3576108, 1.4615006]\n",
      "Batch 245/700: Discriminator loss = 1.0639444589614868, GAN loss = [3.9671707, 1.4099659, 1.7020432]\n",
      "Batch 246/700: Discriminator loss = 1.0981332063674927, GAN loss = [3.79445, 1.4075339, 1.5317894]\n",
      "Batch 247/700: Discriminator loss = 1.0786329507827759, GAN loss = [3.836275, 1.4364668, 1.5447158]\n",
      "Batch 248/700: Discriminator loss = 1.0811398029327393, GAN loss = [3.9970756, 1.4415219, 1.7004949]\n",
      "Batch 249/700: Discriminator loss = 1.061983346939087, GAN loss = [3.7125602, 1.4436009, 1.4139308]\n",
      "Batch 250/700: Discriminator loss = 1.0414423942565918, GAN loss = [4.097547, 1.4564011, 1.7861459]\n",
      "Batch 251/700: Discriminator loss = 1.0939273834228516, GAN loss = [3.675168, 1.4229693, 1.397229]\n",
      "Batch 252/700: Discriminator loss = 1.075597882270813, GAN loss = [3.9443138, 1.4493872, 1.6399819]\n",
      "Batch 253/700: Discriminator loss = 1.048448085784912, GAN loss = [3.8766353, 1.452096, 1.5696139]\n",
      "Batch 254/700: Discriminator loss = 1.1308395862579346, GAN loss = [3.7901714, 1.4861403, 1.4491217]\n",
      "Batch 255/700: Discriminator loss = 1.0404845476150513, GAN loss = [3.9281402, 1.4189272, 1.6543192]\n",
      "Batch 256/700: Discriminator loss = 1.0682976245880127, GAN loss = [3.7364032, 1.4683716, 1.413156]\n",
      "Batch 257/700: Discriminator loss = 1.0824319124221802, GAN loss = [3.6407824, 1.4735101, 1.3124162]\n",
      "Batch 258/700: Discriminator loss = 1.0405775308609009, GAN loss = [3.9433374, 1.4975619, 1.5909395]\n",
      "Batch 259/700: Discriminator loss = 1.0904182195663452, GAN loss = [3.8536181, 1.5696336, 1.4291681]\n",
      "Batch 260/700: Discriminator loss = 1.054264783859253, GAN loss = [3.8231735, 1.5236495, 1.4447309]\n",
      "Batch 261/700: Discriminator loss = 1.012758493423462, GAN loss = [3.8849876, 1.4905034, 1.5397133]\n",
      "Batch 262/700: Discriminator loss = 1.0453003644943237, GAN loss = [3.8954198, 1.4990578, 1.541616]\n",
      "Batch 263/700: Discriminator loss = 1.0637414455413818, GAN loss = [3.8430343, 1.5123901, 1.475919]\n",
      "Batch 264/700: Discriminator loss = 1.0395541191101074, GAN loss = [3.7925942, 1.5488516, 1.3890387]\n",
      "Batch 265/700: Discriminator loss = 1.0141526460647583, GAN loss = [4.0200086, 1.4901564, 1.6751735]\n",
      "Batch 266/700: Discriminator loss = 1.0554165840148926, GAN loss = [3.9196494, 1.5341202, 1.5308703]\n",
      "Batch 267/700: Discriminator loss = 1.040701150894165, GAN loss = [3.7023134, 1.4996604, 1.3480165]\n",
      "Batch 268/700: Discriminator loss = 1.1144638061523438, GAN loss = [3.7851129, 1.5353084, 1.3951863]\n",
      "Batch 269/700: Discriminator loss = 1.0473464727401733, GAN loss = [4.056183, 1.5806518, 1.6209337]\n",
      "Batch 270/700: Discriminator loss = 1.1222933530807495, GAN loss = [3.727024, 1.52091, 1.3515427]\n",
      "Batch 271/700: Discriminator loss = 1.0480846166610718, GAN loss = [4.1053634, 1.5069673, 1.7438551]\n",
      "Batch 272/700: Discriminator loss = 1.0569276809692383, GAN loss = [3.855932, 1.5677347, 1.4336839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 273/700: Discriminator loss = 1.1112315654754639, GAN loss = [3.600602, 1.4977505, 1.2483661]\n",
      "Batch 274/700: Discriminator loss = 1.0714921951293945, GAN loss = [3.7798975, 1.5088284, 1.4166086]\n",
      "Batch 275/700: Discriminator loss = 1.0717957019805908, GAN loss = [3.8787997, 1.5586519, 1.4657159]\n",
      "Batch 276/700: Discriminator loss = 1.0547622442245483, GAN loss = [3.9221258, 1.5169166, 1.5508043]\n",
      "Batch 277/700: Discriminator loss = 1.105254888534546, GAN loss = [3.8251252, 1.5033526, 1.4673946]\n",
      "Batch 278/700: Discriminator loss = 1.047553539276123, GAN loss = [3.8737607, 1.5036001, 1.5158072]\n",
      "Batch 279/700: Discriminator loss = 1.0633434057235718, GAN loss = [3.940198, 1.5174865, 1.5683821]\n",
      "Batch 280/700: Discriminator loss = 1.0910007953643799, GAN loss = [3.8351328, 1.5039357, 1.4768888]\n",
      "Batch 281/700: Discriminator loss = 1.0325878858566284, GAN loss = [4.19204, 1.5347037, 1.8030461]\n",
      "Batch 282/700: Discriminator loss = 1.0313481092453003, GAN loss = [3.985637, 1.5372455, 1.594119]\n",
      "Batch 283/700: Discriminator loss = 1.0958963632583618, GAN loss = [3.9429095, 1.6117481, 1.4769107]\n",
      "Batch 284/700: Discriminator loss = 1.066939115524292, GAN loss = [3.832282, 1.553685, 1.4243699]\n",
      "Batch 285/700: Discriminator loss = 1.1314756870269775, GAN loss = [3.7806306, 1.5663527, 1.360073]\n",
      "Batch 286/700: Discriminator loss = 1.0645618438720703, GAN loss = [3.8322272, 1.556779, 1.4212629]\n",
      "Batch 287/700: Discriminator loss = 1.042894721031189, GAN loss = [4.0777407, 1.5605321, 1.6630487]\n",
      "Batch 288/700: Discriminator loss = 1.0431749820709229, GAN loss = [3.8443446, 1.5092995, 1.4809096]\n",
      "Batch 289/700: Discriminator loss = 1.1241445541381836, GAN loss = [3.7849293, 1.5946687, 1.3361462]\n",
      "Batch 290/700: Discriminator loss = 1.0439999103546143, GAN loss = [3.8843288, 1.512096, 1.5181379]\n",
      "Batch 291/700: Discriminator loss = 1.0957351922988892, GAN loss = [3.915346, 1.5546837, 1.5065852]\n",
      "Batch 292/700: Discriminator loss = 1.0464801788330078, GAN loss = [3.9859009, 1.5745049, 1.5573364]\n",
      "Batch 293/700: Discriminator loss = 1.0827596187591553, GAN loss = [3.826082, 1.5196767, 1.4523624]\n",
      "Batch 294/700: Discriminator loss = 0.9954346418380737, GAN loss = [4.2037525, 1.5936656, 1.7560639]\n",
      "Batch 295/700: Discriminator loss = 1.0864368677139282, GAN loss = [3.826881, 1.5449088, 1.4279703]\n",
      "Batch 296/700: Discriminator loss = 1.132280707359314, GAN loss = [3.618354, 1.5440819, 1.2202902]\n",
      "Batch 297/700: Discriminator loss = 1.121762990951538, GAN loss = [3.6666987, 1.5394235, 1.2733175]\n",
      "Batch 298/700: Discriminator loss = 1.099212884902954, GAN loss = [3.8922875, 1.5458113, 1.4925379]\n",
      "Batch 299/700: Discriminator loss = 1.1406443119049072, GAN loss = [3.675713, 1.5103863, 1.3114052]\n",
      "Batch 300/700: Discriminator loss = 1.093506097793579, GAN loss = [3.673824, 1.4654946, 1.3544226]\n",
      "Batch 301/700: Discriminator loss = 1.2041717767715454, GAN loss = [3.348993, 1.4929211, 1.0021802]\n",
      "Batch 302/700: Discriminator loss = 1.0811958312988281, GAN loss = [3.5509336, 1.449285, 1.2477658]\n",
      "Batch 303/700: Discriminator loss = 1.1686252355575562, GAN loss = [3.4204793, 1.4322853, 1.1343255]\n",
      "Batch 304/700: Discriminator loss = 1.177832841873169, GAN loss = [3.3214905, 1.3898098, 1.0778235]\n",
      "Batch 305/700: Discriminator loss = 1.1625460386276245, GAN loss = [3.3629684, 1.3625407, 1.1465819]\n",
      "Batch 306/700: Discriminator loss = 1.1957221031188965, GAN loss = [3.380463, 1.3882747, 1.1383502]\n",
      "Batch 307/700: Discriminator loss = 1.2397551536560059, GAN loss = [3.4212596, 1.4458671, 1.12156]\n",
      "Batch 308/700: Discriminator loss = 1.1355441808700562, GAN loss = [3.4151762, 1.4271195, 1.1342369]\n",
      "Batch 309/700: Discriminator loss = 1.1692683696746826, GAN loss = [3.3536935, 1.3855987, 1.1142871]\n",
      "Batch 310/700: Discriminator loss = 1.1731946468353271, GAN loss = [3.3124957, 1.3714828, 1.0872153]\n",
      "Batch 311/700: Discriminator loss = 1.1473298072814941, GAN loss = [3.3566184, 1.3559129, 1.1469188]\n",
      "Batch 312/700: Discriminator loss = 1.149574875831604, GAN loss = [3.2850544, 1.3363696, 1.0949095]\n",
      "Batch 313/700: Discriminator loss = 1.1923772096633911, GAN loss = [3.3232396, 1.3777661, 1.091708]\n",
      "Batch 314/700: Discriminator loss = 1.134098768234253, GAN loss = [3.3761232, 1.3452278, 1.1771435]\n",
      "Batch 315/700: Discriminator loss = 1.0995779037475586, GAN loss = [3.4611015, 1.3744345, 1.2329284]\n",
      "Batch 316/700: Discriminator loss = 1.1205875873565674, GAN loss = [3.543484, 1.3989717, 1.290792]\n",
      "Batch 317/700: Discriminator loss = 1.096605658531189, GAN loss = [3.5110486, 1.3891196, 1.2682296]\n",
      "Batch 318/700: Discriminator loss = 1.1010596752166748, GAN loss = [3.5990539, 1.442311, 1.3030602]\n",
      "Batch 319/700: Discriminator loss = 1.0786218643188477, GAN loss = [3.5831997, 1.4290341, 1.3004967]\n",
      "Batch 320/700: Discriminator loss = 1.1022279262542725, GAN loss = [3.6305563, 1.4120815, 1.3648176]\n",
      "Batch 321/700: Discriminator loss = 1.050773024559021, GAN loss = [4.1333246, 1.4662216, 1.8134593]\n",
      "Batch 322/700: Discriminator loss = 1.04179048538208, GAN loss = [3.762413, 1.4777876, 1.4309916]\n",
      "Batch 323/700: Discriminator loss = 1.067367434501648, GAN loss = [3.776206, 1.4631844, 1.4593967]\n",
      "Batch 324/700: Discriminator loss = 1.0505657196044922, GAN loss = [3.9064155, 1.4564347, 1.5963674]\n",
      "Batch 325/700: Discriminator loss = 1.0493659973144531, GAN loss = [3.8098629, 1.4443707, 1.5118941]\n",
      "Batch 326/700: Discriminator loss = 1.0358742475509644, GAN loss = [3.9822395, 1.461544, 1.6671114]\n",
      "Batch 327/700: Discriminator loss = 1.0484927892684937, GAN loss = [3.8572845, 1.5079154, 1.495792]\n",
      "Batch 328/700: Discriminator loss = 1.0394306182861328, GAN loss = [3.9081507, 1.5092435, 1.5453389]\n",
      "Batch 329/700: Discriminator loss = 1.0331989526748657, GAN loss = [3.8081062, 1.4736838, 1.4808643]\n",
      "Batch 330/700: Discriminator loss = 1.0810538530349731, GAN loss = [3.9109576, 1.4899275, 1.5674824]\n",
      "Batch 331/700: Discriminator loss = 1.1102713346481323, GAN loss = [3.8186138, 1.4931397, 1.4719348]\n",
      "Batch 332/700: Discriminator loss = 1.0584957599639893, GAN loss = [3.9287915, 1.537846, 1.5374115]\n",
      "Batch 333/700: Discriminator loss = 1.0601438283920288, GAN loss = [3.8008876, 1.4769467, 1.470419]\n",
      "Batch 334/700: Discriminator loss = 1.060168981552124, GAN loss = [3.908042, 1.5404382, 1.5140891]\n",
      "Batch 335/700: Discriminator loss = 1.0164004564285278, GAN loss = [3.8142416, 1.534153, 1.4265809]\n",
      "Batch 336/700: Discriminator loss = 1.0964986085891724, GAN loss = [3.7646785, 1.5836189, 1.3275659]\n",
      "Batch 337/700: Discriminator loss = 1.0531020164489746, GAN loss = [3.8147976, 1.5761483, 1.385172]\n",
      "Batch 338/700: Discriminator loss = 1.046004295349121, GAN loss = [3.7766495, 1.599618, 1.3235676]\n",
      "Batch 339/700: Discriminator loss = 1.0791196823120117, GAN loss = [3.76983, 1.6632112, 1.2531725]\n",
      "Batch 340/700: Discriminator loss = 1.0746570825576782, GAN loss = [3.8848515, 1.6859409, 1.3454759]\n",
      "Batch 341/700: Discriminator loss = 1.0922918319702148, GAN loss = [3.75807, 1.6291667, 1.2754788]\n",
      "Batch 342/700: Discriminator loss = 1.082845687866211, GAN loss = [3.9341605, 1.6698472, 1.4108924]\n",
      "Batch 343/700: Discriminator loss = 1.0912702083587646, GAN loss = [3.6633976, 1.6221052, 1.1878762]\n",
      "Batch 344/700: Discriminator loss = 1.1890881061553955, GAN loss = [3.6849954, 1.6668944, 1.1646869]\n",
      "Batch 345/700: Discriminator loss = 1.0802597999572754, GAN loss = [3.895427, 1.6728394, 1.3691757]\n",
      "Batch 346/700: Discriminator loss = 1.136883020401001, GAN loss = [3.681705, 1.6131238, 1.2151722]\n",
      "Batch 347/700: Discriminator loss = 1.0890171527862549, GAN loss = [3.7579646, 1.6424009, 1.2621549]\n",
      "Batch 348/700: Discriminator loss = 1.1181981563568115, GAN loss = [3.863959, 1.66466, 1.3458983]\n",
      "Batch 349/700: Discriminator loss = 1.0944454669952393, GAN loss = [3.9633307, 1.6589196, 1.4510161]\n",
      "Batch 350/700: Discriminator loss = 1.0829576253890991, GAN loss = [3.844891, 1.6089859, 1.3825133]\n",
      "Batch 351/700: Discriminator loss = 1.0577988624572754, GAN loss = [3.8381708, 1.5745887, 1.4101927]\n",
      "Batch 352/700: Discriminator loss = 1.1123368740081787, GAN loss = [3.9619446, 1.5702995, 1.5382642]\n",
      "Batch 353/700: Discriminator loss = 1.1965301036834717, GAN loss = [3.6606011, 1.5577254, 1.2495043]\n",
      "Batch 354/700: Discriminator loss = 1.0482953786849976, GAN loss = [3.8965712, 1.5009629, 1.5422423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 355/700: Discriminator loss = 1.0772900581359863, GAN loss = [3.8810291, 1.5007699, 1.5268989]\n",
      "Batch 356/700: Discriminator loss = 1.0104745626449585, GAN loss = [4.0845237, 1.5915024, 1.6396682]\n",
      "Batch 357/700: Discriminator loss = 1.075095295906067, GAN loss = [3.865978, 1.4931624, 1.5194762]\n",
      "Batch 358/700: Discriminator loss = 1.0521141290664673, GAN loss = [4.1036787, 1.552704, 1.6976525]\n",
      "Batch 359/700: Discriminator loss = 1.0684535503387451, GAN loss = [4.2578707, 1.6210538, 1.783523]\n",
      "Batch 360/700: Discriminator loss = 1.0049066543579102, GAN loss = [4.437876, 1.6156236, 1.9689924]\n",
      "Batch 361/700: Discriminator loss = 1.0805332660675049, GAN loss = [3.9128401, 1.5446244, 1.5149951]\n",
      "Batch 362/700: Discriminator loss = 1.029642105102539, GAN loss = [4.2291894, 1.522752, 1.8532524]\n",
      "Batch 363/700: Discriminator loss = 1.0070079565048218, GAN loss = [4.212211, 1.6218799, 1.7371774]\n",
      "Batch 364/700: Discriminator loss = 1.0660649538040161, GAN loss = [3.8988893, 1.5389519, 1.5068138]\n",
      "Batch 365/700: Discriminator loss = 1.0985115766525269, GAN loss = [3.8800118, 1.6046548, 1.42227]\n",
      "Batch 366/700: Discriminator loss = 1.057266354560852, GAN loss = [3.9045959, 1.5045319, 1.5470111]\n",
      "Batch 367/700: Discriminator loss = 1.0676133632659912, GAN loss = [4.1138005, 1.57596, 1.6848176]\n",
      "Batch 368/700: Discriminator loss = 1.0586144924163818, GAN loss = [3.9037638, 1.5577656, 1.4930136]\n",
      "Batch 369/700: Discriminator loss = 1.1138917207717896, GAN loss = [3.7750578, 1.4924203, 1.4296906]\n",
      "Batch 370/700: Discriminator loss = 1.091932773590088, GAN loss = [3.9532614, 1.5475492, 1.5527954]\n",
      "Batch 371/700: Discriminator loss = 1.0908215045928955, GAN loss = [3.8631124, 1.5447999, 1.4654208]\n",
      "Batch 372/700: Discriminator loss = 1.1274354457855225, GAN loss = [3.7129738, 1.5916686, 1.2684379]\n",
      "Batch 373/700: Discriminator loss = 1.1561076641082764, GAN loss = [3.5668654, 1.5136213, 1.2004055]\n",
      "Batch 374/700: Discriminator loss = 1.1332893371582031, GAN loss = [3.6770542, 1.5358635, 1.2883797]\n",
      "Batch 375/700: Discriminator loss = 1.1779282093048096, GAN loss = [3.6118014, 1.5256591, 1.2333518]\n",
      "Batch 376/700: Discriminator loss = 1.1873738765716553, GAN loss = [3.3681512, 1.4771363, 1.0382421]\n",
      "Batch 377/700: Discriminator loss = 1.1460047960281372, GAN loss = [3.5320902, 1.4365839, 1.2427487]\n",
      "Batch 378/700: Discriminator loss = 1.1185479164123535, GAN loss = [3.560557, 1.416062, 1.2917504]\n",
      "Batch 379/700: Discriminator loss = 1.1701698303222656, GAN loss = [3.5080428, 1.381145, 1.2741643]\n",
      "Batch 380/700: Discriminator loss = 1.1178761720657349, GAN loss = [3.5205066, 1.3710617, 1.2967255]\n",
      "Batch 381/700: Discriminator loss = 1.206143856048584, GAN loss = [3.4223666, 1.389108, 1.1805582]\n",
      "Batch 382/700: Discriminator loss = 1.1425141096115112, GAN loss = [3.4584289, 1.3311387, 1.2746134]\n",
      "Batch 383/700: Discriminator loss = 1.089892864227295, GAN loss = [3.6142225, 1.3777709, 1.3837998]\n",
      "Batch 384/700: Discriminator loss = 1.1250998973846436, GAN loss = [3.5410995, 1.3667364, 1.3217419]\n",
      "Batch 385/700: Discriminator loss = 1.1032497882843018, GAN loss = [3.5424955, 1.3737209, 1.3161861]\n",
      "Batch 386/700: Discriminator loss = 1.0885295867919922, GAN loss = [3.5830808, 1.3990865, 1.3314439]\n",
      "Batch 387/700: Discriminator loss = 1.0846664905548096, GAN loss = [3.571904, 1.4282504, 1.2911412]\n",
      "Batch 388/700: Discriminator loss = 1.078059196472168, GAN loss = [3.68934, 1.3987987, 1.4380679]\n",
      "Batch 389/700: Discriminator loss = 1.0859429836273193, GAN loss = [3.611262, 1.3831646, 1.3756636]\n",
      "Batch 390/700: Discriminator loss = 1.0525225400924683, GAN loss = [3.5930243, 1.434232, 1.3063971]\n",
      "Batch 391/700: Discriminator loss = 1.0899658203125, GAN loss = [3.6019435, 1.4068544, 1.3427305]\n",
      "Batch 392/700: Discriminator loss = 1.0628958940505981, GAN loss = [3.7374132, 1.4233714, 1.4617184]\n",
      "Batch 393/700: Discriminator loss = 1.0873380899429321, GAN loss = [3.5433624, 1.4028789, 1.2881911]\n",
      "Batch 394/700: Discriminator loss = 1.1027195453643799, GAN loss = [3.7656877, 1.4744455, 1.4389791]\n",
      "Batch 395/700: Discriminator loss = 1.1203997135162354, GAN loss = [3.6665401, 1.5348929, 1.2794169]\n",
      "Batch 396/700: Discriminator loss = 1.0375316143035889, GAN loss = [3.8950145, 1.5252603, 1.5175602]\n",
      "Batch 397/700: Discriminator loss = 1.0548653602600098, GAN loss = [3.877601, 1.5429736, 1.4824672]\n",
      "Batch 398/700: Discriminator loss = 1.117757797241211, GAN loss = [3.5660963, 1.5116489, 1.202312]\n",
      "Batch 399/700: Discriminator loss = 1.1165716648101807, GAN loss = [3.6493614, 1.4963728, 1.3008733]\n",
      "Batch 400/700: Discriminator loss = 1.1350903511047363, GAN loss = [3.5693817, 1.4644853, 1.2527994]\n",
      "Batch 401/700: Discriminator loss = 1.1232956647872925, GAN loss = [3.5511477, 1.4905795, 1.2084854]\n",
      "Batch 402/700: Discriminator loss = 1.1068964004516602, GAN loss = [3.753118, 1.5286461, 1.3724033]\n",
      "Batch 403/700: Discriminator loss = 1.1567097902297974, GAN loss = [3.6738398, 1.5910481, 1.2307397]\n",
      "Batch 404/700: Discriminator loss = 1.094448208808899, GAN loss = [3.638967, 1.5542392, 1.2326956]\n",
      "Batch 405/700: Discriminator loss = 1.0878700017929077, GAN loss = [3.74728, 1.5235469, 1.3717182]\n",
      "Batch 406/700: Discriminator loss = 1.083574652671814, GAN loss = [3.686188, 1.5427496, 1.2914349]\n",
      "Batch 407/700: Discriminator loss = 1.1451332569122314, GAN loss = [3.733229, 1.5741148, 1.3071197]\n",
      "Batch 408/700: Discriminator loss = 1.1072218418121338, GAN loss = [3.616486, 1.5097365, 1.2547625]\n",
      "Batch 409/700: Discriminator loss = 1.1343086957931519, GAN loss = [3.6779015, 1.614079, 1.2118487]\n",
      "Batch 410/700: Discriminator loss = 1.1134393215179443, GAN loss = [3.6836843, 1.5436707, 1.2880607]\n",
      "Batch 411/700: Discriminator loss = 1.0743460655212402, GAN loss = [3.7002108, 1.583357, 1.2649208]\n",
      "Batch 412/700: Discriminator loss = 1.1345185041427612, GAN loss = [3.4893966, 1.4925294, 1.144957]\n",
      "Batch 413/700: Discriminator loss = 1.0979124307632446, GAN loss = [3.7604156, 1.5226938, 1.3858328]\n",
      "Batch 414/700: Discriminator loss = 1.1114920377731323, GAN loss = [3.5492504, 1.4991357, 1.1982421]\n",
      "Batch 415/700: Discriminator loss = 1.1331093311309814, GAN loss = [3.535971, 1.5260224, 1.1580945]\n",
      "Batch 416/700: Discriminator loss = 1.0803887844085693, GAN loss = [3.829489, 1.4977353, 1.4799198]\n",
      "Batch 417/700: Discriminator loss = 1.1556437015533447, GAN loss = [3.608028, 1.5424458, 1.2137694]\n",
      "Batch 418/700: Discriminator loss = 1.0516808032989502, GAN loss = [3.7512312, 1.5137173, 1.3857154]\n",
      "Batch 419/700: Discriminator loss = 1.0667097568511963, GAN loss = [3.7573977, 1.5178739, 1.3877378]\n",
      "Batch 420/700: Discriminator loss = 1.1146577596664429, GAN loss = [3.7588537, 1.5356506, 1.3714309]\n",
      "Batch 421/700: Discriminator loss = 1.0930659770965576, GAN loss = [3.698994, 1.4754822, 1.3717561]\n",
      "Batch 422/700: Discriminator loss = 1.1105927228927612, GAN loss = [3.8088574, 1.5212507, 1.4358666]\n",
      "Batch 423/700: Discriminator loss = 1.113908290863037, GAN loss = [3.6017327, 1.4934456, 1.256566]\n",
      "Batch 424/700: Discriminator loss = 1.0806208848953247, GAN loss = [3.6029832, 1.506699, 1.2445791]\n",
      "Batch 425/700: Discriminator loss = 1.116047978401184, GAN loss = [3.6559095, 1.4953939, 1.3088257]\n",
      "Batch 426/700: Discriminator loss = 1.0413352251052856, GAN loss = [3.7718837, 1.4655327, 1.454681]\n",
      "Batch 427/700: Discriminator loss = 1.0917820930480957, GAN loss = [3.7056172, 1.4819136, 1.3720573]\n",
      "Batch 428/700: Discriminator loss = 1.061038851737976, GAN loss = [3.7485402, 1.4707451, 1.4261703]\n",
      "Batch 429/700: Discriminator loss = 1.104080080986023, GAN loss = [3.751532, 1.4838408, 1.4160907]\n",
      "Batch 430/700: Discriminator loss = 1.0588237047195435, GAN loss = [3.8213935, 1.4902277, 1.4795874]\n",
      "Batch 431/700: Discriminator loss = 1.0538665056228638, GAN loss = [3.7020452, 1.4589595, 1.3915248]\n",
      "Batch 432/700: Discriminator loss = 1.081658124923706, GAN loss = [3.7814178, 1.4835854, 1.446289]\n",
      "Batch 433/700: Discriminator loss = 1.1039892435073853, GAN loss = [3.6066363, 1.4704809, 1.2846327]\n",
      "Batch 434/700: Discriminator loss = 1.0633615255355835, GAN loss = [3.8092525, 1.4904141, 1.4673375]\n",
      "Batch 435/700: Discriminator loss = 1.088766098022461, GAN loss = [3.722678, 1.4763618, 1.3948354]\n",
      "Batch 436/700: Discriminator loss = 1.0696475505828857, GAN loss = [3.686744, 1.4480978, 1.3871845]\n",
      "Batch 437/700: Discriminator loss = 1.085397720336914, GAN loss = [3.92931, 1.4275519, 1.6503121]\n",
      "Batch 438/700: Discriminator loss = 1.0591262578964233, GAN loss = [3.8361776, 1.4599272, 1.5248213]\n",
      "Batch 439/700: Discriminator loss = 1.0827752351760864, GAN loss = [4.044903, 1.5020443, 1.6914445]\n",
      "Batch 440/700: Discriminator loss = 1.0906089544296265, GAN loss = [3.733339, 1.4727997, 1.4091417]\n",
      "Batch 441/700: Discriminator loss = 1.0627003908157349, GAN loss = [3.8762689, 1.4979111, 1.5269761]\n",
      "Batch 442/700: Discriminator loss = 1.1556463241577148, GAN loss = [3.6974597, 1.508484, 1.3376112]\n",
      "Batch 443/700: Discriminator loss = 1.061561942100525, GAN loss = [3.8075647, 1.4860235, 1.4701974]\n",
      "Batch 444/700: Discriminator loss = 1.0970243215560913, GAN loss = [3.8447933, 1.524111, 1.4693577]\n",
      "Batch 445/700: Discriminator loss = 1.0348358154296875, GAN loss = [3.9760175, 1.5992932, 1.5254178]\n",
      "Batch 446/700: Discriminator loss = 1.0825504064559937, GAN loss = [3.8526194, 1.5408032, 1.4605336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 447/700: Discriminator loss = 1.0942045450210571, GAN loss = [3.8109639, 1.4733349, 1.4863706]\n",
      "Batch 448/700: Discriminator loss = 1.134780764579773, GAN loss = [3.9588294, 1.5747969, 1.5327868]\n",
      "Batch 449/700: Discriminator loss = 1.1747221946716309, GAN loss = [3.549187, 1.4714513, 1.2265053]\n",
      "Batch 450/700: Discriminator loss = 1.0907331705093384, GAN loss = [3.9260519, 1.5551977, 1.519632]\n",
      "Batch 451/700: Discriminator loss = 1.0768426656723022, GAN loss = [3.8848028, 1.5052453, 1.5283504]\n",
      "Batch 452/700: Discriminator loss = 1.161612868309021, GAN loss = [3.8522782, 1.5971363, 1.4039601]\n",
      "Batch 453/700: Discriminator loss = 1.0257246494293213, GAN loss = [4.1026034, 1.6164235, 1.6350266]\n",
      "Batch 454/700: Discriminator loss = 1.129254698753357, GAN loss = [3.8315077, 1.5596254, 1.4207584]\n",
      "Batch 455/700: Discriminator loss = 1.1106244325637817, GAN loss = [3.6139164, 1.4902753, 1.2725501]\n",
      "Batch 456/700: Discriminator loss = 1.2016535997390747, GAN loss = [3.5438175, 1.5536966, 1.1390584]\n",
      "Batch 457/700: Discriminator loss = 1.1903325319290161, GAN loss = [3.611126, 1.5329257, 1.2271681]\n",
      "Batch 458/700: Discriminator loss = 1.1493713855743408, GAN loss = [3.6048813, 1.5159781, 1.2378944]\n",
      "Batch 459/700: Discriminator loss = 1.2110189199447632, GAN loss = [3.4641294, 1.5076745, 1.1054703]\n",
      "Batch 460/700: Discriminator loss = 1.1220548152923584, GAN loss = [3.5421126, 1.4773792, 1.2137728]\n",
      "Batch 461/700: Discriminator loss = 1.140950322151184, GAN loss = [3.6171744, 1.4725899, 1.2936527]\n",
      "Batch 462/700: Discriminator loss = 1.1762892007827759, GAN loss = [3.622112, 1.555553, 1.2156583]\n",
      "Batch 463/700: Discriminator loss = 1.1437463760375977, GAN loss = [3.6327765, 1.5800941, 1.2018113]\n",
      "Batch 464/700: Discriminator loss = 1.1586836576461792, GAN loss = [3.5620842, 1.6087921, 1.1024507]\n",
      "Batch 465/700: Discriminator loss = 1.2054264545440674, GAN loss = [3.4651115, 1.5652919, 1.0490108]\n",
      "Batch 466/700: Discriminator loss = 1.3039392232894897, GAN loss = [3.5025806, 1.5654814, 1.0863154]\n",
      "Batch 467/700: Discriminator loss = 1.177968978881836, GAN loss = [3.5511224, 1.5662531, 1.1341021]\n",
      "Batch 468/700: Discriminator loss = 1.1696319580078125, GAN loss = [3.506333, 1.564674, 1.0909123]\n",
      "Batch 469/700: Discriminator loss = 1.215364933013916, GAN loss = [3.4741719, 1.5469569, 1.0764927]\n",
      "Batch 470/700: Discriminator loss = 1.1783748865127563, GAN loss = [3.3863885, 1.4877884, 1.0479004]\n",
      "Batch 471/700: Discriminator loss = 1.1174551248550415, GAN loss = [3.4489896, 1.5173172, 1.0809983]\n",
      "Batch 472/700: Discriminator loss = 1.157194972038269, GAN loss = [3.5256891, 1.522378, 1.1526668]\n",
      "Batch 473/700: Discriminator loss = 1.230642557144165, GAN loss = [3.426695, 1.5888561, 0.9872265]\n",
      "Batch 474/700: Discriminator loss = 1.1616766452789307, GAN loss = [3.5230856, 1.565002, 1.1075038]\n",
      "Batch 475/700: Discriminator loss = 1.146870493888855, GAN loss = [3.4932287, 1.5846581, 1.0580274]\n",
      "Batch 476/700: Discriminator loss = 1.1183586120605469, GAN loss = [3.5222774, 1.5135293, 1.1582433]\n",
      "Batch 477/700: Discriminator loss = 1.1764744520187378, GAN loss = [3.393626, 1.5388964, 1.0042592]\n",
      "Batch 478/700: Discriminator loss = 1.2385499477386475, GAN loss = [3.4230206, 1.5284392, 1.0441506]\n",
      "Batch 479/700: Discriminator loss = 1.1072120666503906, GAN loss = [3.6478655, 1.523037, 1.2744343]\n",
      "Batch 480/700: Discriminator loss = 1.105699896812439, GAN loss = [3.5858727, 1.4904351, 1.2450798]\n",
      "Batch 481/700: Discriminator loss = 1.1167702674865723, GAN loss = [3.5714312, 1.4796233, 1.2414908]\n",
      "Batch 482/700: Discriminator loss = 1.0833687782287598, GAN loss = [3.5592167, 1.5319262, 1.1770113]\n",
      "Batch 483/700: Discriminator loss = 1.0853114128112793, GAN loss = [3.6962712, 1.5456762, 1.3003511]\n",
      "Batch 484/700: Discriminator loss = 1.1414151191711426, GAN loss = [3.6512773, 1.5234774, 1.2775924]\n",
      "Batch 485/700: Discriminator loss = 1.1711783409118652, GAN loss = [3.4789457, 1.469446, 1.1593275]\n",
      "Batch 486/700: Discriminator loss = 1.1553027629852295, GAN loss = [3.62526, 1.5012366, 1.2738903]\n",
      "Batch 487/700: Discriminator loss = 1.0805175304412842, GAN loss = [3.766112, 1.5438844, 1.3721286]\n",
      "Batch 488/700: Discriminator loss = 1.2374094724655151, GAN loss = [3.6254392, 1.6286345, 1.1467423]\n",
      "Batch 489/700: Discriminator loss = 1.1204113960266113, GAN loss = [3.527278, 1.5193858, 1.1578594]\n",
      "Batch 490/700: Discriminator loss = 1.1634886264801025, GAN loss = [3.5014195, 1.4967241, 1.1546931]\n",
      "Batch 491/700: Discriminator loss = 1.102512001991272, GAN loss = [3.6627917, 1.5409225, 1.2718923]\n",
      "Batch 492/700: Discriminator loss = 1.1568920612335205, GAN loss = [3.6273537, 1.5463552, 1.2310468]\n",
      "Batch 493/700: Discriminator loss = 1.1530942916870117, GAN loss = [3.5312932, 1.5216964, 1.1596677]\n",
      "Batch 494/700: Discriminator loss = 1.1694159507751465, GAN loss = [3.637725, 1.5228631, 1.2649554]\n",
      "Batch 495/700: Discriminator loss = 1.1461831331253052, GAN loss = [3.4388487, 1.4125699, 1.1763923]\n",
      "Batch 496/700: Discriminator loss = 1.087401032447815, GAN loss = [3.6987367, 1.4266763, 1.4221964]\n",
      "Batch 497/700: Discriminator loss = 1.149617075920105, GAN loss = [3.5848782, 1.441969, 1.293067]\n",
      "Batch 498/700: Discriminator loss = 1.1673965454101562, GAN loss = [3.407004, 1.4683292, 1.0888501]\n",
      "Batch 499/700: Discriminator loss = 1.0838607549667358, GAN loss = [3.7319145, 1.4697627, 1.4123502]\n",
      "Batch 500/700: Discriminator loss = 1.1921212673187256, GAN loss = [3.4717357, 1.5019284, 1.1200309]\n",
      "Batch 501/700: Discriminator loss = 1.051568627357483, GAN loss = [3.8103096, 1.508691, 1.451864]\n",
      "Batch 502/700: Discriminator loss = 1.084256649017334, GAN loss = [3.7606611, 1.4899955, 1.4209381]\n",
      "Batch 503/700: Discriminator loss = 1.0512959957122803, GAN loss = [3.7948005, 1.5796051, 1.3654938]\n",
      "Batch 504/700: Discriminator loss = 1.0842114686965942, GAN loss = [3.7614233, 1.4917145, 1.4200374]\n",
      "Batch 505/700: Discriminator loss = 1.1214898824691772, GAN loss = [3.6814842, 1.5050917, 1.3267475]\n",
      "Batch 506/700: Discriminator loss = 1.0989367961883545, GAN loss = [3.6245782, 1.5281494, 1.2468102]\n",
      "Batch 507/700: Discriminator loss = 1.101904034614563, GAN loss = [3.6883302, 1.5017157, 1.3370224]\n",
      "Batch 508/700: Discriminator loss = 1.08131742477417, GAN loss = [3.6728485, 1.4704995, 1.3527805]\n",
      "Batch 509/700: Discriminator loss = 1.0779461860656738, GAN loss = [3.6552505, 1.4757024, 1.3300034]\n",
      "Batch 510/700: Discriminator loss = 1.021916151046753, GAN loss = [3.8093247, 1.4986612, 1.4611439]\n",
      "Batch 511/700: Discriminator loss = 1.1057019233703613, GAN loss = [3.56753, 1.4883014, 1.2297349]\n",
      "Batch 512/700: Discriminator loss = 1.0473060607910156, GAN loss = [3.7021134, 1.4639716, 1.3886737]\n",
      "Batch 513/700: Discriminator loss = 1.1027276515960693, GAN loss = [3.587019, 1.498926, 1.2386489]\n",
      "Batch 514/700: Discriminator loss = 1.0681114196777344, GAN loss = [3.6321902, 1.4644014, 1.3183652]\n",
      "Batch 515/700: Discriminator loss = 1.0580066442489624, GAN loss = [3.7437212, 1.500781, 1.3935384]\n",
      "Batch 516/700: Discriminator loss = 1.1373012065887451, GAN loss = [3.629955, 1.4999013, 1.2806711]\n",
      "Batch 517/700: Discriminator loss = 1.079984188079834, GAN loss = [3.5383563, 1.4699287, 1.2190613]\n",
      "Batch 518/700: Discriminator loss = 1.0448954105377197, GAN loss = [3.6174347, 1.452277, 1.3158046]\n",
      "Batch 519/700: Discriminator loss = 1.0452600717544556, GAN loss = [3.7494311, 1.4919795, 1.408117]\n",
      "Batch 520/700: Discriminator loss = 1.0808929204940796, GAN loss = [3.6703951, 1.4895849, 1.331499]\n",
      "Batch 521/700: Discriminator loss = 1.0168492794036865, GAN loss = [3.887373, 1.4939936, 1.544095]\n",
      "Batch 522/700: Discriminator loss = 1.0545241832733154, GAN loss = [3.9198074, 1.5179127, 1.5526451]\n",
      "Batch 523/700: Discriminator loss = 1.0516499280929565, GAN loss = [3.791918, 1.4902295, 1.4524654]\n",
      "Batch 524/700: Discriminator loss = 1.0197231769561768, GAN loss = [3.913121, 1.4837955, 1.5801315]\n",
      "Batch 525/700: Discriminator loss = 1.0713484287261963, GAN loss = [3.8300743, 1.502043, 1.4788643]\n",
      "Batch 526/700: Discriminator loss = 1.0753992795944214, GAN loss = [3.8452668, 1.5238512, 1.4722724]\n",
      "Batch 527/700: Discriminator loss = 1.0513378381729126, GAN loss = [3.7324145, 1.4646183, 1.4186716]\n",
      "Batch 528/700: Discriminator loss = 1.0137211084365845, GAN loss = [3.8603868, 1.4824822, 1.5288004]\n",
      "Batch 529/700: Discriminator loss = 1.0796842575073242, GAN loss = [3.8570187, 1.5747861, 1.4331475]\n",
      "Batch 530/700: Discriminator loss = 1.0210387706756592, GAN loss = [3.9296558, 1.5304264, 1.5501698]\n",
      "Batch 531/700: Discriminator loss = 1.0421103239059448, GAN loss = [3.9259748, 1.5874585, 1.4894783]\n",
      "Batch 532/700: Discriminator loss = 1.047967553138733, GAN loss = [3.7929087, 1.5040857, 1.4398106]\n",
      "Batch 533/700: Discriminator loss = 1.0427391529083252, GAN loss = [3.9594631, 1.5306866, 1.5797911]\n",
      "Batch 534/700: Discriminator loss = 0.9830236434936523, GAN loss = [4.091628, 1.5415525, 1.7011195]\n",
      "Batch 535/700: Discriminator loss = 1.0339592695236206, GAN loss = [4.188044, 1.6870121, 1.6521063]\n",
      "Batch 536/700: Discriminator loss = 1.0231828689575195, GAN loss = [4.0048594, 1.5587848, 1.5971783]\n",
      "Batch 537/700: Discriminator loss = 1.0175690650939941, GAN loss = [4.1065264, 1.5446641, 1.7129971]\n",
      "Batch 538/700: Discriminator loss = 1.0559420585632324, GAN loss = [3.9171805, 1.5532961, 1.5150473]\n",
      "Batch 539/700: Discriminator loss = 1.061358094215393, GAN loss = [3.835823, 1.52009, 1.4669267]\n",
      "Batch 540/700: Discriminator loss = 1.0433580875396729, GAN loss = [3.865746, 1.5567287, 1.4602371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 541/700: Discriminator loss = 1.0656763315200806, GAN loss = [3.7158484, 1.4855094, 1.3815814]\n",
      "Batch 542/700: Discriminator loss = 1.0551375150680542, GAN loss = [3.8042352, 1.5101475, 1.4453566]\n",
      "Batch 543/700: Discriminator loss = 1.0778312683105469, GAN loss = [3.8534021, 1.5192875, 1.4854027]\n",
      "Batch 544/700: Discriminator loss = 1.097166657447815, GAN loss = [3.7212808, 1.4484204, 1.4241648]\n",
      "Batch 545/700: Discriminator loss = 1.103061556816101, GAN loss = [3.6424034, 1.4815934, 1.3121282]\n",
      "Batch 546/700: Discriminator loss = 1.0957856178283691, GAN loss = [3.7930248, 1.457295, 1.4870683]\n",
      "Batch 547/700: Discriminator loss = 1.0953917503356934, GAN loss = [3.58945, 1.4764142, 1.2643946]\n",
      "Batch 548/700: Discriminator loss = 1.045901894569397, GAN loss = [3.8242106, 1.4564079, 1.5191842]\n",
      "Batch 549/700: Discriminator loss = 1.101562261581421, GAN loss = [3.7450745, 1.5017749, 1.3947057]\n",
      "Batch 550/700: Discriminator loss = 1.0479580163955688, GAN loss = [3.9030488, 1.4911509, 1.5633283]\n",
      "Batch 551/700: Discriminator loss = 1.0525411367416382, GAN loss = [3.9112058, 1.4945549, 1.5681059]\n",
      "Batch 552/700: Discriminator loss = 1.086750864982605, GAN loss = [3.7511659, 1.4911846, 1.4114608]\n",
      "Batch 553/700: Discriminator loss = 1.0749739408493042, GAN loss = [3.9326308, 1.576984, 1.507154]\n",
      "Batch 554/700: Discriminator loss = 1.0196573734283447, GAN loss = [3.80878, 1.5084387, 1.4518743]\n",
      "Batch 555/700: Discriminator loss = 1.0823465585708618, GAN loss = [3.8189466, 1.5021667, 1.4683434]\n",
      "Batch 556/700: Discriminator loss = 1.0541564226150513, GAN loss = [3.8386078, 1.5232377, 1.4669577]\n",
      "Batch 557/700: Discriminator loss = 1.018762469291687, GAN loss = [3.901344, 1.5585803, 1.494373]\n",
      "Batch 558/700: Discriminator loss = 0.992836594581604, GAN loss = [4.1167254, 1.5170704, 1.7512861]\n",
      "Batch 559/700: Discriminator loss = 1.0270317792892456, GAN loss = [3.9498518, 1.4931716, 1.6083348]\n",
      "Batch 560/700: Discriminator loss = 1.0503486394882202, GAN loss = [3.9190655, 1.5388423, 1.5319072]\n",
      "Batch 561/700: Discriminator loss = 1.033790111541748, GAN loss = [3.8684819, 1.5156064, 1.5045849]\n",
      "Batch 562/700: Discriminator loss = 1.028504729270935, GAN loss = [3.8418782, 1.4887902, 1.5048212]\n",
      "Batch 563/700: Discriminator loss = 1.0776387453079224, GAN loss = [3.92763, 1.5420308, 1.5373626]\n",
      "Batch 564/700: Discriminator loss = 1.029677152633667, GAN loss = [3.7608974, 1.4817016, 1.4309874]\n",
      "Batch 565/700: Discriminator loss = 1.0302437543869019, GAN loss = [3.914909, 1.5495557, 1.5171722]\n",
      "Batch 566/700: Discriminator loss = 1.0654836893081665, GAN loss = [3.7834654, 1.51385, 1.421458]\n",
      "Batch 567/700: Discriminator loss = 0.9910734295845032, GAN loss = [3.833211, 1.5067451, 1.4783281]\n",
      "Batch 568/700: Discriminator loss = 1.0896400213241577, GAN loss = [3.8425996, 1.5910197, 1.4034618]\n",
      "Batch 569/700: Discriminator loss = 0.9991830587387085, GAN loss = [4.029082, 1.541026, 1.6399584]\n",
      "Batch 570/700: Discriminator loss = 1.0470972061157227, GAN loss = [3.843262, 1.5478997, 1.4472846]\n",
      "Batch 571/700: Discriminator loss = 0.9991194605827332, GAN loss = [4.2605925, 1.6856339, 1.7268982]\n",
      "Batch 572/700: Discriminator loss = 1.0586427450180054, GAN loss = [3.9013839, 1.5480745, 1.5052614]\n",
      "Batch 573/700: Discriminator loss = 1.0453853607177734, GAN loss = [3.958109, 1.5694231, 1.5406452]\n",
      "Batch 574/700: Discriminator loss = 1.0034724473953247, GAN loss = [4.069, 1.5898066, 1.6311549]\n",
      "Batch 575/700: Discriminator loss = 1.0021083354949951, GAN loss = [4.11273, 1.6338784, 1.6308191]\n",
      "Batch 576/700: Discriminator loss = 1.0235875844955444, GAN loss = [3.9570081, 1.5915287, 1.517444]\n",
      "Batch 577/700: Discriminator loss = 1.0443215370178223, GAN loss = [3.997814, 1.7048187, 1.4449626]\n",
      "Batch 578/700: Discriminator loss = 1.037255048751831, GAN loss = [4.0798497, 1.621962, 1.6098553]\n",
      "Batch 579/700: Discriminator loss = 1.030481219291687, GAN loss = [3.8822358, 1.5336517, 1.5005507]\n",
      "Batch 580/700: Discriminator loss = 1.0428943634033203, GAN loss = [3.9558098, 1.6136013, 1.4941782]\n",
      "Batch 581/700: Discriminator loss = 0.999304473400116, GAN loss = [4.0048623, 1.590131, 1.5667132]\n",
      "Batch 582/700: Discriminator loss = 1.038907766342163, GAN loss = [3.9502976, 1.6354785, 1.4668117]\n",
      "Batch 583/700: Discriminator loss = 1.0462756156921387, GAN loss = [3.9170585, 1.5796536, 1.4894149]\n",
      "Batch 584/700: Discriminator loss = 1.0471011400222778, GAN loss = [3.9565935, 1.6523529, 1.4562703]\n",
      "Batch 585/700: Discriminator loss = 1.0249272584915161, GAN loss = [4.1063733, 1.5756803, 1.6827404]\n",
      "Batch 586/700: Discriminator loss = 1.0521291494369507, GAN loss = [3.8378816, 1.5616091, 1.4283391]\n",
      "Batch 587/700: Discriminator loss = 1.0844571590423584, GAN loss = [3.845744, 1.6106977, 1.3871298]\n",
      "Batch 588/700: Discriminator loss = 1.038679599761963, GAN loss = [3.836448, 1.5557351, 1.4328152]\n",
      "Batch 589/700: Discriminator loss = 1.0519301891326904, GAN loss = [4.000753, 1.6742947, 1.4785776]\n",
      "Batch 590/700: Discriminator loss = 1.082805871963501, GAN loss = [3.8167355, 1.629074, 1.3398025]\n",
      "Batch 591/700: Discriminator loss = 1.060889720916748, GAN loss = [3.7844448, 1.6027932, 1.3338171]\n",
      "Batch 592/700: Discriminator loss = 1.1132214069366455, GAN loss = [3.7458427, 1.5741129, 1.323916]\n",
      "Batch 593/700: Discriminator loss = 1.0636059045791626, GAN loss = [3.785241, 1.5579443, 1.3794975]\n",
      "Batch 594/700: Discriminator loss = 1.0351684093475342, GAN loss = [3.9727378, 1.5899043, 1.53505]\n",
      "Batch 595/700: Discriminator loss = 1.0976625680923462, GAN loss = [3.787459, 1.5921979, 1.3474988]\n",
      "Batch 596/700: Discriminator loss = 1.0497825145721436, GAN loss = [3.88215, 1.6643803, 1.3700268]\n",
      "Batch 597/700: Discriminator loss = 1.0610857009887695, GAN loss = [3.8065095, 1.5813686, 1.377418]\n",
      "Batch 598/700: Discriminator loss = 1.1168268918991089, GAN loss = [3.5806844, 1.5519754, 1.1810092]\n",
      "Batch 599/700: Discriminator loss = 1.0739116668701172, GAN loss = [3.8422835, 1.5878292, 1.4067807]\n",
      "Batch 600/700: Discriminator loss = 1.0765634775161743, GAN loss = [4.0652018, 1.6933217, 1.524238]\n",
      "Batch 601/700: Discriminator loss = 1.0605411529541016, GAN loss = [3.9499078, 1.6175842, 1.48471]\n",
      "Batch 602/700: Discriminator loss = 1.07511305809021, GAN loss = [3.9317267, 1.6558653, 1.4282694]\n",
      "Batch 603/700: Discriminator loss = 1.16696298122406, GAN loss = [3.7070096, 1.6349121, 1.2245204]\n",
      "Batch 604/700: Discriminator loss = 1.058310627937317, GAN loss = [3.732098, 1.563799, 1.3207332]\n",
      "Batch 605/700: Discriminator loss = 1.0470010042190552, GAN loss = [3.745601, 1.5472381, 1.3508139]\n",
      "Batch 606/700: Discriminator loss = 1.119200587272644, GAN loss = [3.7631097, 1.5305164, 1.3850639]\n",
      "Batch 607/700: Discriminator loss = 1.0898256301879883, GAN loss = [3.6986663, 1.5206338, 1.3305179]\n",
      "Batch 608/700: Discriminator loss = 1.132312536239624, GAN loss = [3.699761, 1.5619487, 1.2903134]\n",
      "Batch 609/700: Discriminator loss = 1.0781440734863281, GAN loss = [3.6911778, 1.507278, 1.3364187]\n",
      "Batch 610/700: Discriminator loss = 1.0922014713287354, GAN loss = [3.7781336, 1.531757, 1.3989149]\n",
      "Batch 611/700: Discriminator loss = 1.1030375957489014, GAN loss = [3.7695832, 1.5455867, 1.3765532]\n",
      "Batch 612/700: Discriminator loss = 1.07859468460083, GAN loss = [3.733258, 1.4917415, 1.3940884]\n",
      "Batch 613/700: Discriminator loss = 1.1079542636871338, GAN loss = [3.6117463, 1.4765172, 1.2878116]\n",
      "Batch 614/700: Discriminator loss = 1.0744167566299438, GAN loss = [3.803371, 1.5104759, 1.4454883]\n",
      "Batch 615/700: Discriminator loss = 1.1023651361465454, GAN loss = [3.6565561, 1.5164582, 1.292704]\n",
      "Batch 616/700: Discriminator loss = 1.1086755990982056, GAN loss = [3.8097873, 1.5458103, 1.4165938]\n",
      "Batch 617/700: Discriminator loss = 1.0678679943084717, GAN loss = [3.927406, 1.5158741, 1.5641626]\n",
      "Batch 618/700: Discriminator loss = 1.0875879526138306, GAN loss = [3.7737348, 1.5069985, 1.4193738]\n",
      "Batch 619/700: Discriminator loss = 1.0546300411224365, GAN loss = [4.0514154, 1.5501466, 1.6539127]\n",
      "Batch 620/700: Discriminator loss = 1.1697845458984375, GAN loss = [3.6858199, 1.4818364, 1.3566328]\n",
      "Batch 621/700: Discriminator loss = 1.1096614599227905, GAN loss = [3.493789, 1.4616907, 1.1847467]\n",
      "Batch 622/700: Discriminator loss = 1.1326271295547485, GAN loss = [3.5470645, 1.4378504, 1.2618653]\n",
      "Batch 623/700: Discriminator loss = 1.0926401615142822, GAN loss = [3.753755, 1.503107, 1.4033018]\n",
      "Batch 624/700: Discriminator loss = 1.0642865896224976, GAN loss = [3.7860272, 1.4913414, 1.4473435]\n",
      "Batch 625/700: Discriminator loss = 1.0946118831634521, GAN loss = [3.7110174, 1.4646802, 1.3990042]\n",
      "Batch 626/700: Discriminator loss = 1.0718681812286377, GAN loss = [3.7306423, 1.5016799, 1.3816407]\n",
      "Batch 627/700: Discriminator loss = 1.082692265510559, GAN loss = [3.845953, 1.5012158, 1.4974251]\n",
      "Batch 628/700: Discriminator loss = 1.0633624792099, GAN loss = [3.748592, 1.4968532, 1.404432]\n",
      "Batch 629/700: Discriminator loss = 1.0690125226974487, GAN loss = [3.76757, 1.5435146, 1.376751]\n",
      "Batch 630/700: Discriminator loss = 1.0470974445343018, GAN loss = [3.9654818, 1.5204835, 1.597693]\n",
      "Batch 631/700: Discriminator loss = 1.1113828420639038, GAN loss = [3.737405, 1.5260537, 1.364035]\n",
      "Batch 632/700: Discriminator loss = 1.0578696727752686, GAN loss = [3.835914, 1.5175414, 1.4710441]\n",
      "Batch 633/700: Discriminator loss = 1.0448143482208252, GAN loss = [4.1376667, 1.5729165, 1.7174071]\n",
      "Batch 634/700: Discriminator loss = 1.1377168893814087, GAN loss = [3.9042032, 1.5352632, 1.5215842]\n",
      "Batch 635/700: Discriminator loss = 1.1273036003112793, GAN loss = [3.8299086, 1.533771, 1.448774]\n",
      "Batch 636/700: Discriminator loss = 1.0893521308898926, GAN loss = [3.8501856, 1.5481026, 1.4547025]\n",
      "Batch 637/700: Discriminator loss = 1.0979632139205933, GAN loss = [3.9184785, 1.5717005, 1.4993885]\n",
      "Batch 638/700: Discriminator loss = 1.1378984451293945, GAN loss = [3.858532, 1.5767397, 1.4343966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 639/700: Discriminator loss = 1.0938740968704224, GAN loss = [4.036824, 1.5589843, 1.6304561]\n",
      "Batch 640/700: Discriminator loss = 1.0965501070022583, GAN loss = [3.8006246, 1.5982962, 1.3549514]\n",
      "Batch 641/700: Discriminator loss = 1.1251513957977295, GAN loss = [3.8245058, 1.5459789, 1.4311566]\n",
      "Batch 642/700: Discriminator loss = 1.1071065664291382, GAN loss = [3.923959, 1.5691366, 1.5074525]\n",
      "Batch 643/700: Discriminator loss = 1.0717439651489258, GAN loss = [3.8866575, 1.5269583, 1.5123262]\n",
      "Batch 644/700: Discriminator loss = 1.0953309535980225, GAN loss = [3.8319252, 1.5340866, 1.4504617]\n",
      "Batch 645/700: Discriminator loss = 1.113533616065979, GAN loss = [3.8332124, 1.5659276, 1.4199071]\n",
      "Batch 646/700: Discriminator loss = 1.0981624126434326, GAN loss = [3.8054492, 1.534788, 1.4232948]\n",
      "Batch 647/700: Discriminator loss = 1.103602647781372, GAN loss = [3.8954973, 1.543989, 1.5041522]\n",
      "Batch 648/700: Discriminator loss = 1.1264053583145142, GAN loss = [3.6553526, 1.5332499, 1.2747526]\n",
      "Batch 649/700: Discriminator loss = 1.1422570943832397, GAN loss = [3.884006, 1.5116483, 1.5250113]\n",
      "Batch 650/700: Discriminator loss = 1.1041390895843506, GAN loss = [3.9365208, 1.5144137, 1.5747659]\n",
      "Batch 651/700: Discriminator loss = 1.1441049575805664, GAN loss = [3.8849177, 1.537847, 1.499734]\n",
      "Batch 652/700: Discriminator loss = 1.0945427417755127, GAN loss = [3.967387, 1.500762, 1.619296]\n",
      "Batch 653/700: Discriminator loss = 1.1584081649780273, GAN loss = [3.647772, 1.4554114, 1.3450378]\n",
      "Batch 654/700: Discriminator loss = 1.1525483131408691, GAN loss = [3.7424226, 1.4907155, 1.404395]\n",
      "Batch 655/700: Discriminator loss = 1.0727869272232056, GAN loss = [3.8889782, 1.5517682, 1.4899098]\n",
      "Batch 656/700: Discriminator loss = 1.1268436908721924, GAN loss = [3.6001546, 1.5060958, 1.2467827]\n",
      "Batch 657/700: Discriminator loss = 1.122650384902954, GAN loss = [3.6807778, 1.458403, 1.3751286]\n",
      "Batch 658/700: Discriminator loss = 1.1014550924301147, GAN loss = [3.846966, 1.4955535, 1.5042017]\n",
      "Batch 659/700: Discriminator loss = 1.116038203239441, GAN loss = [3.6836054, 1.4669722, 1.369456]\n",
      "Batch 660/700: Discriminator loss = 1.0614534616470337, GAN loss = [3.836044, 1.517335, 1.4715643]\n",
      "Batch 661/700: Discriminator loss = 1.062785267829895, GAN loss = [3.9296274, 1.4980167, 1.5845001]\n",
      "Batch 662/700: Discriminator loss = 1.0456916093826294, GAN loss = [3.860519, 1.4994038, 1.5140287]\n",
      "Batch 663/700: Discriminator loss = 1.0620135068893433, GAN loss = [3.7600684, 1.5398738, 1.3731319]\n",
      "Batch 664/700: Discriminator loss = 1.1068994998931885, GAN loss = [3.97061, 1.5368643, 1.5867058]\n",
      "Batch 665/700: Discriminator loss = 1.055837869644165, GAN loss = [3.934375, 1.4986749, 1.5886734]\n",
      "Batch 666/700: Discriminator loss = 1.0980850458145142, GAN loss = [3.7393715, 1.5494822, 1.3428797]\n",
      "Batch 667/700: Discriminator loss = 1.0667380094528198, GAN loss = [3.7492652, 1.581357, 1.3209276]\n",
      "Batch 668/700: Discriminator loss = 1.0179896354675293, GAN loss = [4.0613103, 1.5791441, 1.6352142]\n",
      "Batch 669/700: Discriminator loss = 1.0998836755752563, GAN loss = [3.9463239, 1.5354103, 1.5639881]\n",
      "Batch 670/700: Discriminator loss = 1.1262874603271484, GAN loss = [3.889113, 1.5617309, 1.4804837]\n",
      "Batch 671/700: Discriminator loss = 1.0829863548278809, GAN loss = [4.0657854, 1.5865904, 1.6323173]\n",
      "Batch 672/700: Discriminator loss = 1.1496646404266357, GAN loss = [3.8099756, 1.5264636, 1.4366487]\n",
      "Batch 673/700: Discriminator loss = 1.1782383918762207, GAN loss = [3.602033, 1.4987663, 1.2564156]\n",
      "Batch 674/700: Discriminator loss = 1.1231448650360107, GAN loss = [4.094137, 1.659991, 1.5873069]\n",
      "Batch 675/700: Discriminator loss = 1.1398680210113525, GAN loss = [3.9265227, 1.5655661, 1.5141302]\n",
      "Batch 676/700: Discriminator loss = 1.1471151113510132, GAN loss = [3.7849722, 1.6303222, 1.3078331]\n",
      "Batch 677/700: Discriminator loss = 1.1314702033996582, GAN loss = [3.8312128, 1.5615674, 1.422838]\n",
      "Batch 678/700: Discriminator loss = 1.1842740774154663, GAN loss = [3.7352827, 1.6013939, 1.2870913]\n",
      "Batch 679/700: Discriminator loss = 1.1364144086837769, GAN loss = [3.7841575, 1.6248186, 1.3125501]\n",
      "Batch 680/700: Discriminator loss = 1.195846676826477, GAN loss = [3.7997131, 1.547152, 1.405786]\n",
      "Batch 681/700: Discriminator loss = 1.2033149003982544, GAN loss = [3.7478192, 1.5701543, 1.3309081]\n",
      "Batch 682/700: Discriminator loss = 1.2207200527191162, GAN loss = [3.5092182, 1.5615511, 1.1009237]\n",
      "Batch 683/700: Discriminator loss = 1.168828010559082, GAN loss = [3.6211667, 1.524355, 1.2500829]\n",
      "Batch 684/700: Discriminator loss = 1.1728122234344482, GAN loss = [3.5095146, 1.5071611, 1.1556349]\n",
      "Batch 685/700: Discriminator loss = 1.1387219429016113, GAN loss = [3.5773695, 1.4882785, 1.2423886]\n",
      "Batch 686/700: Discriminator loss = 1.2591910362243652, GAN loss = [3.2461863, 1.3997575, 0.999752]\n",
      "Batch 687/700: Discriminator loss = 1.1114873886108398, GAN loss = [3.6237235, 1.5227493, 1.2543195]\n",
      "Batch 688/700: Discriminator loss = 1.116370677947998, GAN loss = [3.6290505, 1.4716411, 1.3107802]\n",
      "Batch 689/700: Discriminator loss = 1.1501708030700684, GAN loss = [3.4559858, 1.4543589, 1.1550218]\n",
      "Batch 690/700: Discriminator loss = 1.161139965057373, GAN loss = [3.4684603, 1.4331697, 1.1887113]\n",
      "Batch 691/700: Discriminator loss = 1.1494650840759277, GAN loss = [3.5182161, 1.4235578, 1.2481006]\n",
      "Batch 692/700: Discriminator loss = 1.1524633169174194, GAN loss = [3.5041704, 1.4112288, 1.2464062]\n",
      "Batch 693/700: Discriminator loss = 1.2085694074630737, GAN loss = [3.6027057, 1.3761994, 1.3799931]\n",
      "Batch 694/700: Discriminator loss = 1.213470697402954, GAN loss = [3.4146228, 1.3788356, 1.1892947]\n",
      "Batch 695/700: Discriminator loss = 1.1406627893447876, GAN loss = [3.637785, 1.429443, 1.3618705]\n",
      "Batch 696/700: Discriminator loss = 1.1538597345352173, GAN loss = [3.5536537, 1.3859645, 1.3212432]\n",
      "Batch 697/700: Discriminator loss = 1.1377054452896118, GAN loss = [3.4926014, 1.3435335, 1.302644]\n",
      "Batch 698/700: Discriminator loss = 1.1099427938461304, GAN loss = [3.5220878, 1.3613021, 1.314378]\n",
      "Batch 699/700: Discriminator loss = 1.2017319202423096, GAN loss = [3.4741173, 1.3483667, 1.2793568]\n",
      "Batch 700/700: Discriminator loss = 1.0884931087493896, GAN loss = [3.7610605, 1.4225525, 1.4921337]\n",
      "Epoch 6/30\n",
      "Batch 1/700: Discriminator loss = 1.1302343606948853, GAN loss = [3.5206637, 1.4226369, 1.2516756]\n",
      "Batch 2/700: Discriminator loss = 1.0813456773757935, GAN loss = [3.5652404, 1.3895115, 1.3293998]\n",
      "Batch 3/700: Discriminator loss = 1.129197359085083, GAN loss = [3.3867722, 1.3550713, 1.1853942]\n",
      "Batch 4/700: Discriminator loss = 1.1315962076187134, GAN loss = [3.3625786, 1.341709, 1.1745842]\n",
      "Batch 5/700: Discriminator loss = 1.148437738418579, GAN loss = [3.5202503, 1.4093548, 1.2646341]\n",
      "Batch 6/700: Discriminator loss = 1.1864594221115112, GAN loss = [3.5835335, 1.4573725, 1.2799287]\n",
      "Batch 7/700: Discriminator loss = 1.1504731178283691, GAN loss = [3.5414948, 1.4266145, 1.268675]\n",
      "Batch 8/700: Discriminator loss = 1.1209360361099243, GAN loss = [3.5733685, 1.4741215, 1.2530626]\n",
      "Batch 9/700: Discriminator loss = 1.1552735567092896, GAN loss = [3.4169803, 1.4878732, 1.082945]\n",
      "Batch 10/700: Discriminator loss = 1.1110783815383911, GAN loss = [3.455204, 1.4080634, 1.2010022]\n",
      "Batch 11/700: Discriminator loss = 1.1054761409759521, GAN loss = [3.3831975, 1.3569379, 1.1801479]\n",
      "Batch 12/700: Discriminator loss = 1.1273375749588013, GAN loss = [3.4716427, 1.4342026, 1.1913508]\n",
      "Batch 13/700: Discriminator loss = 1.0596556663513184, GAN loss = [3.6795754, 1.443489, 1.3900194]\n",
      "Batch 14/700: Discriminator loss = 1.1270231008529663, GAN loss = [3.635022, 1.482484, 1.3064903]\n",
      "Batch 15/700: Discriminator loss = 1.079195499420166, GAN loss = [3.7349665, 1.485934, 1.4030014]\n",
      "Batch 16/700: Discriminator loss = 1.0877368450164795, GAN loss = [3.6016498, 1.4515582, 1.3040767]\n",
      "Batch 17/700: Discriminator loss = 1.1112678050994873, GAN loss = [3.749042, 1.502253, 1.4007967]\n",
      "Batch 18/700: Discriminator loss = 1.1049970388412476, GAN loss = [3.4693768, 1.4296983, 1.193705]\n",
      "Batch 19/700: Discriminator loss = 1.0865814685821533, GAN loss = [3.6560574, 1.4725273, 1.3375735]\n",
      "Batch 20/700: Discriminator loss = 1.1835819482803345, GAN loss = [3.4645991, 1.4567358, 1.1619247]\n",
      "Batch 21/700: Discriminator loss = 1.0856882333755493, GAN loss = [3.6238148, 1.4498631, 1.3280265]\n",
      "Batch 22/700: Discriminator loss = 1.1171120405197144, GAN loss = [3.3716347, 1.3688178, 1.1569096]\n",
      "Batch 23/700: Discriminator loss = 1.1286530494689941, GAN loss = [3.577548, 1.4438607, 1.2877922]\n",
      "Batch 24/700: Discriminator loss = 1.1036741733551025, GAN loss = [3.661917, 1.4667166, 1.3493195]\n",
      "Batch 25/700: Discriminator loss = 1.1044484376907349, GAN loss = [3.5994437, 1.40197, 1.3516065]\n",
      "Batch 26/700: Discriminator loss = 1.1127054691314697, GAN loss = [3.6979594, 1.4970536, 1.3550465]\n",
      "Batch 27/700: Discriminator loss = 1.1660432815551758, GAN loss = [3.53601, 1.4873184, 1.2028406]\n",
      "Batch 28/700: Discriminator loss = 1.1316192150115967, GAN loss = [3.4088838, 1.454971, 1.1080737]\n",
      "Batch 29/700: Discriminator loss = 1.0801684856414795, GAN loss = [3.5289872, 1.4544148, 1.2287436]\n",
      "Batch 30/700: Discriminator loss = 1.094450831413269, GAN loss = [3.4849532, 1.4355747, 1.2035589]\n",
      "Batch 31/700: Discriminator loss = 1.0815666913986206, GAN loss = [3.7705405, 1.5111954, 1.4135389]\n",
      "Batch 32/700: Discriminator loss = 1.0101161003112793, GAN loss = [3.881994, 1.5062824, 1.5299164]\n",
      "Batch 33/700: Discriminator loss = 1.0793741941452026, GAN loss = [3.5736423, 1.4547877, 1.2730715]\n",
      "Batch 34/700: Discriminator loss = 1.0842140913009644, GAN loss = [3.5859497, 1.4457353, 1.2944412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 35/700: Discriminator loss = 1.0368225574493408, GAN loss = [3.7782304, 1.5102803, 1.4221932]\n",
      "Batch 36/700: Discriminator loss = 1.0821985006332397, GAN loss = [3.7509043, 1.520178, 1.3849895]\n",
      "Batch 37/700: Discriminator loss = 1.0584834814071655, GAN loss = [3.8047535, 1.517135, 1.4419049]\n",
      "Batch 38/700: Discriminator loss = 1.0632665157318115, GAN loss = [3.9057953, 1.53824, 1.5218611]\n",
      "Batch 39/700: Discriminator loss = 1.0777888298034668, GAN loss = [3.7640185, 1.5089236, 1.4094256]\n",
      "Batch 40/700: Discriminator loss = 1.0861440896987915, GAN loss = [3.8373978, 1.5207709, 1.4709787]\n",
      "Batch 41/700: Discriminator loss = 1.056947946548462, GAN loss = [3.7663548, 1.5128534, 1.4078723]\n",
      "Batch 42/700: Discriminator loss = 1.0743358135223389, GAN loss = [3.7671487, 1.5400921, 1.3814445]\n",
      "Batch 43/700: Discriminator loss = 1.0837159156799316, GAN loss = [3.811802, 1.5611157, 1.4050843]\n",
      "Batch 44/700: Discriminator loss = 1.1021182537078857, GAN loss = [3.737413, 1.5092049, 1.3826185]\n",
      "Batch 45/700: Discriminator loss = 1.1549779176712036, GAN loss = [3.834651, 1.5462757, 1.442799]\n",
      "Batch 46/700: Discriminator loss = 1.1051380634307861, GAN loss = [3.8325408, 1.5358351, 1.451143]\n",
      "Batch 47/700: Discriminator loss = 1.10080885887146, GAN loss = [3.6781082, 1.5091377, 1.3234239]\n",
      "Batch 48/700: Discriminator loss = 1.1031235456466675, GAN loss = [3.5915697, 1.4289209, 1.3171213]\n",
      "Batch 49/700: Discriminator loss = 1.074118733406067, GAN loss = [3.7856386, 1.4712303, 1.4689084]\n",
      "Batch 50/700: Discriminator loss = 1.0896100997924805, GAN loss = [3.6347833, 1.5072503, 1.2820609]\n",
      "Batch 51/700: Discriminator loss = 1.1254156827926636, GAN loss = [3.700176, 1.4508455, 1.4038894]\n",
      "Batch 52/700: Discriminator loss = 1.0910648107528687, GAN loss = [3.745487, 1.4789102, 1.4211626]\n",
      "Batch 53/700: Discriminator loss = 1.1015548706054688, GAN loss = [3.7131357, 1.4765707, 1.3911792]\n",
      "Batch 54/700: Discriminator loss = 1.087083101272583, GAN loss = [3.7256677, 1.5171242, 1.3631865]\n",
      "Batch 55/700: Discriminator loss = 1.0683026313781738, GAN loss = [3.7416317, 1.5384809, 1.3578262]\n",
      "Batch 56/700: Discriminator loss = 1.0597509145736694, GAN loss = [3.9645023, 1.5015645, 1.6176487]\n",
      "Batch 57/700: Discriminator loss = 1.087038516998291, GAN loss = [3.7723978, 1.4873118, 1.439828]\n",
      "Batch 58/700: Discriminator loss = 1.0795962810516357, GAN loss = [3.7627718, 1.5041357, 1.4134076]\n",
      "Batch 59/700: Discriminator loss = 1.0926406383514404, GAN loss = [3.545575, 1.5120562, 1.1883149]\n",
      "Batch 60/700: Discriminator loss = 1.1428145170211792, GAN loss = [3.83205, 1.6144725, 1.372399]\n",
      "Batch 61/700: Discriminator loss = 1.0488543510437012, GAN loss = [3.8333392, 1.5369003, 1.4512887]\n",
      "Batch 62/700: Discriminator loss = 1.1073359251022339, GAN loss = [3.7406735, 1.5169001, 1.3786557]\n",
      "Batch 63/700: Discriminator loss = 1.0659369230270386, GAN loss = [3.6502628, 1.5245534, 1.2806237]\n",
      "Batch 64/700: Discriminator loss = 1.1177992820739746, GAN loss = [3.6085556, 1.4905896, 1.2729135]\n",
      "Batch 65/700: Discriminator loss = 1.0899287462234497, GAN loss = [3.605174, 1.4560868, 1.304071]\n",
      "Batch 66/700: Discriminator loss = 1.09473717212677, GAN loss = [3.7834673, 1.4819875, 1.4564941]\n",
      "Batch 67/700: Discriminator loss = 1.1076645851135254, GAN loss = [3.726643, 1.4707863, 1.4109027]\n",
      "Batch 68/700: Discriminator loss = 1.130866527557373, GAN loss = [3.5399177, 1.4922981, 1.2026949]\n",
      "Batch 69/700: Discriminator loss = 1.0847270488739014, GAN loss = [3.694513, 1.4928503, 1.356764]\n",
      "Batch 70/700: Discriminator loss = 1.1123206615447998, GAN loss = [3.6167545, 1.4868059, 1.2850717]\n",
      "Batch 71/700: Discriminator loss = 1.1445173025131226, GAN loss = [3.5296671, 1.474157, 1.2106566]\n",
      "Batch 72/700: Discriminator loss = 1.0990444421768188, GAN loss = [3.6853297, 1.5296723, 1.3108249]\n",
      "Batch 73/700: Discriminator loss = 1.107344388961792, GAN loss = [3.5268252, 1.4867626, 1.1952547]\n",
      "Batch 74/700: Discriminator loss = 1.0692743062973022, GAN loss = [3.6274538, 1.4819797, 1.3006883]\n",
      "Batch 75/700: Discriminator loss = 1.1551110744476318, GAN loss = [3.4964366, 1.4828529, 1.1688212]\n",
      "Batch 76/700: Discriminator loss = 1.1194612979888916, GAN loss = [3.6021085, 1.4441459, 1.3132269]\n",
      "Batch 77/700: Discriminator loss = 1.0876637697219849, GAN loss = [3.4295144, 1.4038363, 1.1809709]\n",
      "Batch 78/700: Discriminator loss = 1.0858346223831177, GAN loss = [3.5042608, 1.425035, 1.2345463]\n",
      "Batch 79/700: Discriminator loss = 1.0607028007507324, GAN loss = [3.4995446, 1.4119035, 1.2429829]\n",
      "Batch 80/700: Discriminator loss = 1.0752780437469482, GAN loss = [3.4955633, 1.4286015, 1.2223202]\n",
      "Batch 81/700: Discriminator loss = 1.076319694519043, GAN loss = [3.6397798, 1.4286058, 1.3665489]\n",
      "Batch 82/700: Discriminator loss = 1.108091950416565, GAN loss = [3.431619, 1.3761107, 1.2109059]\n",
      "Batch 83/700: Discriminator loss = 1.1001513004302979, GAN loss = [3.600926, 1.3711704, 1.3851749]\n",
      "Batch 84/700: Discriminator loss = 1.0864243507385254, GAN loss = [3.6101816, 1.4184928, 1.3471277]\n",
      "Batch 85/700: Discriminator loss = 1.056970238685608, GAN loss = [3.6722484, 1.3948113, 1.4328963]\n",
      "Batch 86/700: Discriminator loss = 1.1096937656402588, GAN loss = [3.5882213, 1.3994275, 1.3442699]\n",
      "Batch 87/700: Discriminator loss = 1.1037343740463257, GAN loss = [3.582604, 1.4022298, 1.3358704]\n",
      "Batch 88/700: Discriminator loss = 1.068995475769043, GAN loss = [3.5581033, 1.4038795, 1.3097432]\n",
      "Batch 89/700: Discriminator loss = 1.0388399362564087, GAN loss = [3.7089324, 1.3764168, 1.4880567]\n",
      "Batch 90/700: Discriminator loss = 1.035351276397705, GAN loss = [3.7394028, 1.4113591, 1.4836026]\n",
      "Batch 91/700: Discriminator loss = 1.0682612657546997, GAN loss = [3.6137989, 1.38374, 1.3856397]\n",
      "Batch 92/700: Discriminator loss = 1.0675735473632812, GAN loss = [3.5906093, 1.3902359, 1.3559722]\n",
      "Batch 93/700: Discriminator loss = 1.0157709121704102, GAN loss = [4.0173516, 1.4368324, 1.7361374]\n",
      "Batch 94/700: Discriminator loss = 1.0837841033935547, GAN loss = [3.6352644, 1.3689114, 1.4219917]\n",
      "Batch 95/700: Discriminator loss = 1.036634922027588, GAN loss = [3.8318574, 1.4356716, 1.5518537]\n",
      "Batch 96/700: Discriminator loss = 1.0255955457687378, GAN loss = [3.7775126, 1.4440813, 1.4891343]\n",
      "Batch 97/700: Discriminator loss = 1.0605082511901855, GAN loss = [3.710987, 1.3974462, 1.4692867]\n",
      "Batch 98/700: Discriminator loss = 1.0648659467697144, GAN loss = [3.7627134, 1.3918059, 1.5266925]\n",
      "Batch 99/700: Discriminator loss = 1.026442289352417, GAN loss = [3.7517226, 1.4217424, 1.4857973]\n",
      "Batch 100/700: Discriminator loss = 1.0641796588897705, GAN loss = [3.7572882, 1.4319317, 1.4812082]\n",
      "Batch 101/700: Discriminator loss = 1.0579938888549805, GAN loss = [3.6148915, 1.4494473, 1.3213263]\n",
      "Batch 102/700: Discriminator loss = 1.0704140663146973, GAN loss = [3.6686335, 1.4478488, 1.3766977]\n",
      "Batch 103/700: Discriminator loss = 1.0438390970230103, GAN loss = [3.8588736, 1.476207, 1.5386158]\n",
      "Batch 104/700: Discriminator loss = 1.0157407522201538, GAN loss = [3.768219, 1.4672272, 1.4569788]\n",
      "Batch 105/700: Discriminator loss = 0.9938858151435852, GAN loss = [3.7735007, 1.4539728, 1.4755523]\n",
      "Batch 106/700: Discriminator loss = 0.9882014989852905, GAN loss = [3.8180723, 1.5045407, 1.4695897]\n",
      "Batch 107/700: Discriminator loss = 1.0257580280303955, GAN loss = [3.86787, 1.476749, 1.5472133]\n",
      "Batch 108/700: Discriminator loss = 1.0020838975906372, GAN loss = [3.8785946, 1.5454918, 1.4892287]\n",
      "Batch 109/700: Discriminator loss = 1.0414780378341675, GAN loss = [3.5764613, 1.4403031, 1.2923188]\n",
      "Batch 110/700: Discriminator loss = 1.0635370016098022, GAN loss = [3.5638328, 1.4089918, 1.3110372]\n",
      "Batch 111/700: Discriminator loss = 1.0325191020965576, GAN loss = [3.8045313, 1.4758145, 1.4849455]\n",
      "Batch 112/700: Discriminator loss = 1.044731855392456, GAN loss = [3.6732433, 1.4197311, 1.4097768]\n",
      "Batch 113/700: Discriminator loss = 1.067258358001709, GAN loss = [3.7731776, 1.4249836, 1.5044911]\n",
      "Batch 114/700: Discriminator loss = 1.064825415611267, GAN loss = [3.6670988, 1.4263587, 1.3970692]\n",
      "Batch 115/700: Discriminator loss = 1.0514706373214722, GAN loss = [3.6692493, 1.4272804, 1.3983252]\n",
      "Batch 116/700: Discriminator loss = 1.031967043876648, GAN loss = [3.6769893, 1.4416989, 1.3916719]\n",
      "Batch 117/700: Discriminator loss = 1.1361993551254272, GAN loss = [3.50086, 1.3961273, 1.2611384]\n",
      "Batch 118/700: Discriminator loss = 1.0803488492965698, GAN loss = [3.5770633, 1.3718543, 1.36164]\n",
      "Batch 119/700: Discriminator loss = 1.1444997787475586, GAN loss = [3.5157504, 1.3689694, 1.3032346]\n",
      "Batch 120/700: Discriminator loss = 1.0760482549667358, GAN loss = [3.730264, 1.4238378, 1.4628989]\n",
      "Batch 121/700: Discriminator loss = 1.0809615850448608, GAN loss = [3.5455434, 1.4068155, 1.2952139]\n",
      "Batch 122/700: Discriminator loss = 1.129164695739746, GAN loss = [3.346068, 1.371884, 1.1306854]\n",
      "Batch 123/700: Discriminator loss = 1.1367392539978027, GAN loss = [3.4128428, 1.320373, 1.2489859]\n",
      "Batch 124/700: Discriminator loss = 1.1612848043441772, GAN loss = [3.4800937, 1.3577638, 1.2788616]\n",
      "Batch 125/700: Discriminator loss = 1.0711649656295776, GAN loss = [3.805663, 1.4587244, 1.5034794]\n",
      "Batch 126/700: Discriminator loss = 1.1342847347259521, GAN loss = [3.5510361, 1.4312346, 1.2763488]\n",
      "Batch 127/700: Discriminator loss = 1.1701469421386719, GAN loss = [3.6073637, 1.494577, 1.2693429]\n",
      "Batch 128/700: Discriminator loss = 1.1043115854263306, GAN loss = [3.567652, 1.3902559, 1.3339653]\n",
      "Batch 129/700: Discriminator loss = 1.1361712217330933, GAN loss = [3.7763362, 1.5463694, 1.386546]\n",
      "Batch 130/700: Discriminator loss = 1.1051087379455566, GAN loss = [3.4940958, 1.4447587, 1.2059256]\n",
      "Batch 131/700: Discriminator loss = 1.1091972589492798, GAN loss = [3.5426598, 1.3573387, 1.3419235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 132/700: Discriminator loss = 1.1240205764770508, GAN loss = [3.7533538, 1.4254973, 1.4844707]\n",
      "Batch 133/700: Discriminator loss = 1.099581241607666, GAN loss = [3.7218559, 1.432925, 1.4455554]\n",
      "Batch 134/700: Discriminator loss = 1.1205472946166992, GAN loss = [3.5218527, 1.3521608, 1.3263248]\n",
      "Batch 135/700: Discriminator loss = 1.1788688898086548, GAN loss = [3.5905905, 1.4263448, 1.3208874]\n",
      "Batch 136/700: Discriminator loss = 1.0940351486206055, GAN loss = [3.7303622, 1.3930005, 1.4940125]\n",
      "Batch 137/700: Discriminator loss = 1.1346664428710938, GAN loss = [3.624841, 1.3507681, 1.4307332]\n",
      "Batch 138/700: Discriminator loss = 1.1002436876296997, GAN loss = [3.5526767, 1.3585229, 1.3508159]\n",
      "Batch 139/700: Discriminator loss = 1.1051479578018188, GAN loss = [3.6025538, 1.4144275, 1.344792]\n",
      "Batch 140/700: Discriminator loss = 1.0952951908111572, GAN loss = [3.7016206, 1.4534063, 1.4048874]\n",
      "Batch 141/700: Discriminator loss = 1.1413084268569946, GAN loss = [3.6644602, 1.44192, 1.3792225]\n",
      "Batch 142/700: Discriminator loss = 1.0723319053649902, GAN loss = [3.863016, 1.4947249, 1.5249847]\n",
      "Batch 143/700: Discriminator loss = 1.0532655715942383, GAN loss = [3.7257743, 1.4959285, 1.3865477]\n",
      "Batch 144/700: Discriminator loss = 1.147000789642334, GAN loss = [3.6094112, 1.4463298, 1.3197902]\n",
      "Batch 145/700: Discriminator loss = 1.1089239120483398, GAN loss = [3.7112246, 1.5220027, 1.3459342]\n",
      "Batch 146/700: Discriminator loss = 1.0696762800216675, GAN loss = [3.6488507, 1.4794061, 1.3261589]\n",
      "Batch 147/700: Discriminator loss = 1.0822343826293945, GAN loss = [3.82662, 1.4547287, 1.5286074]\n",
      "Batch 148/700: Discriminator loss = 1.1116117238998413, GAN loss = [3.6993592, 1.5011297, 1.3549454]\n",
      "Batch 149/700: Discriminator loss = 1.107208013534546, GAN loss = [3.5470426, 1.4136939, 1.2900695]\n",
      "Batch 150/700: Discriminator loss = 1.1066908836364746, GAN loss = [3.652588, 1.4760989, 1.3332186]\n",
      "Batch 151/700: Discriminator loss = 1.0842727422714233, GAN loss = [3.702892, 1.4446346, 1.4149965]\n",
      "Batch 152/700: Discriminator loss = 1.169083595275879, GAN loss = [3.5415776, 1.426763, 1.271561]\n",
      "Batch 153/700: Discriminator loss = 1.1613547801971436, GAN loss = [3.4264607, 1.4197814, 1.1634377]\n",
      "Batch 154/700: Discriminator loss = 1.128706455230713, GAN loss = [3.6215427, 1.4244761, 1.3538332]\n",
      "Batch 155/700: Discriminator loss = 1.1768860816955566, GAN loss = [3.5243149, 1.4515257, 1.2295626]\n",
      "Batch 156/700: Discriminator loss = 1.121226191520691, GAN loss = [3.5385566, 1.4400351, 1.2553141]\n",
      "Batch 157/700: Discriminator loss = 1.0905870199203491, GAN loss = [3.539119, 1.4194226, 1.27651]\n",
      "Batch 158/700: Discriminator loss = 1.140796184539795, GAN loss = [3.735291, 1.5219477, 1.3701879]\n",
      "Batch 159/700: Discriminator loss = 1.111586570739746, GAN loss = [3.5154202, 1.4093416, 1.262957]\n",
      "Batch 160/700: Discriminator loss = 1.1766362190246582, GAN loss = [3.4587042, 1.3667707, 1.248853]\n",
      "Batch 161/700: Discriminator loss = 1.1174302101135254, GAN loss = [3.4065547, 1.4059994, 1.1575118]\n",
      "Batch 162/700: Discriminator loss = 1.1019190549850464, GAN loss = [3.4999316, 1.4181027, 1.2388264]\n",
      "Batch 163/700: Discriminator loss = 1.1087325811386108, GAN loss = [3.6715171, 1.4137577, 1.4147953]\n",
      "Batch 164/700: Discriminator loss = 1.1405714750289917, GAN loss = [3.509517, 1.4554995, 1.2110902]\n",
      "Batch 165/700: Discriminator loss = 1.123368740081787, GAN loss = [3.600106, 1.4686774, 1.2885317]\n",
      "Batch 166/700: Discriminator loss = 1.1054940223693848, GAN loss = [3.587893, 1.4061961, 1.3388344]\n",
      "Batch 167/700: Discriminator loss = 1.130788803100586, GAN loss = [3.552738, 1.4366462, 1.2732579]\n",
      "Batch 168/700: Discriminator loss = 1.1708812713623047, GAN loss = [3.3660924, 1.4293356, 1.0939491]\n",
      "Batch 169/700: Discriminator loss = 1.1536191701889038, GAN loss = [3.6215587, 1.4494612, 1.3293159]\n",
      "Batch 170/700: Discriminator loss = 1.0816131830215454, GAN loss = [3.6684563, 1.5077726, 1.3179326]\n",
      "Batch 171/700: Discriminator loss = 1.1396520137786865, GAN loss = [3.619698, 1.4537582, 1.32322]\n",
      "Batch 172/700: Discriminator loss = 1.1287562847137451, GAN loss = [3.540205, 1.493753, 1.2037615]\n",
      "Batch 173/700: Discriminator loss = 1.129409909248352, GAN loss = [3.4965827, 1.4805884, 1.1733334]\n",
      "Batch 174/700: Discriminator loss = 1.126718521118164, GAN loss = [3.560839, 1.4323651, 1.2858407]\n",
      "Batch 175/700: Discriminator loss = 1.1035503149032593, GAN loss = [3.5784266, 1.4564916, 1.2793347]\n",
      "Batch 176/700: Discriminator loss = 1.1291401386260986, GAN loss = [3.7455292, 1.5074043, 1.39556]\n",
      "Batch 177/700: Discriminator loss = 1.1220858097076416, GAN loss = [3.499346, 1.4710517, 1.1857638]\n",
      "Batch 178/700: Discriminator loss = 1.1142702102661133, GAN loss = [3.5511577, 1.4392815, 1.2693851]\n",
      "Batch 179/700: Discriminator loss = 1.180586338043213, GAN loss = [3.4814327, 1.4234195, 1.2155613]\n",
      "Batch 180/700: Discriminator loss = 1.1167528629302979, GAN loss = [3.5833888, 1.4197776, 1.3211904]\n",
      "Batch 181/700: Discriminator loss = 1.1315780878067017, GAN loss = [3.4487817, 1.4248258, 1.1815755]\n",
      "Batch 182/700: Discriminator loss = 1.1873677968978882, GAN loss = [3.4428937, 1.3964682, 1.2040763]\n",
      "Batch 183/700: Discriminator loss = 1.1441810131072998, GAN loss = [3.6557891, 1.4551059, 1.3583672]\n",
      "Batch 184/700: Discriminator loss = 1.066464900970459, GAN loss = [3.5451035, 1.3895999, 1.3132184]\n",
      "Batch 185/700: Discriminator loss = 1.1106950044631958, GAN loss = [3.5400507, 1.374708, 1.323084]\n",
      "Batch 186/700: Discriminator loss = 1.1185417175292969, GAN loss = [3.5951986, 1.4090409, 1.3439224]\n",
      "Batch 187/700: Discriminator loss = 1.0663056373596191, GAN loss = [3.6758902, 1.4078842, 1.425793]\n",
      "Batch 188/700: Discriminator loss = 1.0663422346115112, GAN loss = [3.4551697, 1.3592792, 1.2536983]\n",
      "Batch 189/700: Discriminator loss = 1.0909662246704102, GAN loss = [3.4281504, 1.3387642, 1.2472157]\n",
      "Batch 190/700: Discriminator loss = 1.1207149028778076, GAN loss = [3.51512, 1.3058249, 1.3671408]\n",
      "Batch 191/700: Discriminator loss = 1.1253750324249268, GAN loss = [3.3537912, 1.2824821, 1.229171]\n",
      "Batch 192/700: Discriminator loss = 1.1172906160354614, GAN loss = [3.4050324, 1.2919229, 1.2709913]\n",
      "Batch 193/700: Discriminator loss = 1.0959407091140747, GAN loss = [3.4622717, 1.3205216, 1.2996602]\n",
      "Batch 194/700: Discriminator loss = 1.0684049129486084, GAN loss = [3.5454051, 1.3641216, 1.3392187]\n",
      "Batch 195/700: Discriminator loss = 1.1504261493682861, GAN loss = [3.4644587, 1.314573, 1.3078554]\n",
      "Batch 196/700: Discriminator loss = 1.1350743770599365, GAN loss = [3.4160757, 1.3235397, 1.2505382]\n",
      "Batch 197/700: Discriminator loss = 1.1109118461608887, GAN loss = [3.5126488, 1.3422427, 1.3284364]\n",
      "Batch 198/700: Discriminator loss = 1.0892150402069092, GAN loss = [3.4668126, 1.3011724, 1.3236989]\n",
      "Batch 199/700: Discriminator loss = 1.1062560081481934, GAN loss = [3.6018815, 1.399666, 1.3603079]\n",
      "Batch 200/700: Discriminator loss = 1.1243454217910767, GAN loss = [3.4421413, 1.3592293, 1.241039]\n",
      "Batch 201/700: Discriminator loss = 1.0894355773925781, GAN loss = [3.4737225, 1.3223631, 1.3095192]\n",
      "Batch 202/700: Discriminator loss = 1.144282579421997, GAN loss = [3.422437, 1.3000114, 1.2806153]\n",
      "Batch 203/700: Discriminator loss = 1.0625203847885132, GAN loss = [3.4397662, 1.3385738, 1.2594157]\n",
      "Batch 204/700: Discriminator loss = 1.0985229015350342, GAN loss = [3.5159202, 1.3466263, 1.3275512]\n",
      "Batch 205/700: Discriminator loss = 1.0920734405517578, GAN loss = [3.605215, 1.3455725, 1.417937]\n",
      "Batch 206/700: Discriminator loss = 1.1430100202560425, GAN loss = [3.4865732, 1.3315873, 1.31332]\n",
      "Batch 207/700: Discriminator loss = 1.1445941925048828, GAN loss = [3.5445, 1.3962666, 1.3066083]\n",
      "Batch 208/700: Discriminator loss = 1.0761638879776, GAN loss = [3.6182024, 1.340661, 1.4359581]\n",
      "Batch 209/700: Discriminator loss = 1.09727144241333, GAN loss = [3.5410347, 1.3695633, 1.3299218]\n",
      "Batch 210/700: Discriminator loss = 1.0652109384536743, GAN loss = [3.7351613, 1.357518, 1.5361346]\n",
      "Batch 211/700: Discriminator loss = 1.0598223209381104, GAN loss = [3.7354767, 1.4154291, 1.4785801]\n",
      "Batch 212/700: Discriminator loss = 1.08133864402771, GAN loss = [3.5561142, 1.3504639, 1.3642256]\n",
      "Batch 213/700: Discriminator loss = 1.075644612312317, GAN loss = [3.5096788, 1.3359821, 1.3323197]\n",
      "Batch 214/700: Discriminator loss = 1.1022250652313232, GAN loss = [3.5911472, 1.377732, 1.372087]\n",
      "Batch 215/700: Discriminator loss = 1.0780805349349976, GAN loss = [3.4604535, 1.3257939, 1.2933781]\n",
      "Batch 216/700: Discriminator loss = 1.086076021194458, GAN loss = [3.5773234, 1.3436474, 1.392444]\n",
      "Batch 217/700: Discriminator loss = 1.1122304201126099, GAN loss = [3.5905945, 1.3873574, 1.3620497]\n",
      "Batch 218/700: Discriminator loss = 1.090004324913025, GAN loss = [3.6397846, 1.3692273, 1.4294133]\n",
      "Batch 219/700: Discriminator loss = 1.0657374858856201, GAN loss = [3.5182025, 1.3722354, 1.3048682]\n",
      "Batch 220/700: Discriminator loss = 1.1320339441299438, GAN loss = [3.422294, 1.3667853, 1.2144542]\n",
      "Batch 221/700: Discriminator loss = 1.1140022277832031, GAN loss = [3.5740674, 1.3610463, 1.3720108]\n",
      "Batch 222/700: Discriminator loss = 1.1024806499481201, GAN loss = [3.4858785, 1.3292818, 1.3156264]\n",
      "Batch 223/700: Discriminator loss = 1.0550495386123657, GAN loss = [3.6356976, 1.3728551, 1.4219114]\n",
      "Batch 224/700: Discriminator loss = 1.1144295930862427, GAN loss = [3.356347, 1.3216071, 1.1938452]\n",
      "Batch 225/700: Discriminator loss = 1.0753990411758423, GAN loss = [3.680785, 1.3379638, 1.501959]\n",
      "Batch 226/700: Discriminator loss = 1.0688081979751587, GAN loss = [3.6573167, 1.367159, 1.4493272]\n",
      "Batch 227/700: Discriminator loss = 1.0827138423919678, GAN loss = [3.4385216, 1.3693982, 1.2283254]\n",
      "Batch 228/700: Discriminator loss = 1.0493853092193604, GAN loss = [3.668061, 1.3518524, 1.4754441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 229/700: Discriminator loss = 1.097777009010315, GAN loss = [3.6744127, 1.3974199, 1.4362606]\n",
      "Batch 230/700: Discriminator loss = 1.0837374925613403, GAN loss = [3.4055445, 1.3534619, 1.2113812]\n",
      "Batch 231/700: Discriminator loss = 1.0511683225631714, GAN loss = [3.7414641, 1.4034107, 1.4973813]\n",
      "Batch 232/700: Discriminator loss = 1.074522614479065, GAN loss = [3.6325917, 1.3718573, 1.4200934]\n",
      "Batch 233/700: Discriminator loss = 1.1575040817260742, GAN loss = [3.4180686, 1.303255, 1.2741944]\n",
      "Batch 234/700: Discriminator loss = 1.1104933023452759, GAN loss = [3.444291, 1.3548223, 1.248866]\n",
      "Batch 235/700: Discriminator loss = 1.0938326120376587, GAN loss = [3.4731574, 1.3050674, 1.3274977]\n",
      "Batch 236/700: Discriminator loss = 1.1408146619796753, GAN loss = [3.431076, 1.2951065, 1.2953933]\n",
      "Batch 237/700: Discriminator loss = 1.0768674612045288, GAN loss = [3.6239383, 1.3561369, 1.4272432]\n",
      "Batch 238/700: Discriminator loss = 1.088627576828003, GAN loss = [3.703611, 1.3307587, 1.5323119]\n",
      "Batch 239/700: Discriminator loss = 1.1278094053268433, GAN loss = [3.550752, 1.3650693, 1.3451558]\n",
      "Batch 240/700: Discriminator loss = 1.1016429662704468, GAN loss = [3.5796843, 1.3251548, 1.4140198]\n",
      "Batch 241/700: Discriminator loss = 1.1192973852157593, GAN loss = [3.6441283, 1.3403804, 1.4632487]\n",
      "Batch 242/700: Discriminator loss = 1.099733829498291, GAN loss = [3.574494, 1.3423283, 1.3916762]\n",
      "Batch 243/700: Discriminator loss = 1.143458366394043, GAN loss = [3.515779, 1.3729291, 1.3023742]\n",
      "Batch 244/700: Discriminator loss = 1.093374490737915, GAN loss = [3.4753675, 1.3141754, 1.3207364]\n",
      "Batch 245/700: Discriminator loss = 1.1417232751846313, GAN loss = [3.4622872, 1.287957, 1.3338984]\n",
      "Batch 246/700: Discriminator loss = 1.1039460897445679, GAN loss = [3.551371, 1.3355153, 1.3754487]\n",
      "Batch 247/700: Discriminator loss = 1.1267486810684204, GAN loss = [3.3627558, 1.3017381, 1.2206402]\n",
      "Batch 248/700: Discriminator loss = 1.1173863410949707, GAN loss = [3.5495505, 1.3604733, 1.348726]\n",
      "Batch 249/700: Discriminator loss = 1.095889925956726, GAN loss = [3.604764, 1.3195815, 1.4448576]\n",
      "Batch 250/700: Discriminator loss = 1.1071727275848389, GAN loss = [3.5738134, 1.3110865, 1.4224267]\n",
      "Batch 251/700: Discriminator loss = 1.1310381889343262, GAN loss = [3.4795535, 1.2934548, 1.3458234]\n",
      "Batch 252/700: Discriminator loss = 1.1390595436096191, GAN loss = [3.3551922, 1.2718333, 1.2431029]\n",
      "Batch 253/700: Discriminator loss = 1.0749965906143188, GAN loss = [3.535581, 1.2942973, 1.4010513]\n",
      "Batch 254/700: Discriminator loss = 1.148128628730774, GAN loss = [3.3432968, 1.2575849, 1.2455021]\n",
      "Batch 255/700: Discriminator loss = 1.1499820947647095, GAN loss = [3.3276138, 1.2429117, 1.2445155]\n",
      "Batch 256/700: Discriminator loss = 1.1598020792007446, GAN loss = [3.4616525, 1.29664, 1.324844]\n",
      "Batch 257/700: Discriminator loss = 1.1548843383789062, GAN loss = [3.4547675, 1.2710834, 1.3435391]\n",
      "Batch 258/700: Discriminator loss = 1.125226616859436, GAN loss = [3.4973361, 1.256089, 1.4011295]\n",
      "Batch 259/700: Discriminator loss = 1.1915123462677002, GAN loss = [3.4206467, 1.2837191, 1.2968323]\n",
      "Batch 260/700: Discriminator loss = 1.1306313276290894, GAN loss = [3.4889479, 1.2471265, 1.4017503]\n",
      "Batch 261/700: Discriminator loss = 1.1149758100509644, GAN loss = [3.5492756, 1.2719004, 1.4373314]\n",
      "Batch 262/700: Discriminator loss = 1.0823640823364258, GAN loss = [3.753588, 1.3102808, 1.6032954]\n",
      "Batch 263/700: Discriminator loss = 1.1270513534545898, GAN loss = [3.4238925, 1.2762877, 1.307629]\n",
      "Batch 264/700: Discriminator loss = 1.1032105684280396, GAN loss = [3.557329, 1.3383228, 1.379062]\n",
      "Batch 265/700: Discriminator loss = 1.1028692722320557, GAN loss = [3.54848, 1.2747439, 1.4338242]\n",
      "Batch 266/700: Discriminator loss = 1.1219310760498047, GAN loss = [3.4899068, 1.27459, 1.375438]\n",
      "Batch 267/700: Discriminator loss = 1.0934436321258545, GAN loss = [3.4458516, 1.2583017, 1.3477005]\n",
      "Batch 268/700: Discriminator loss = 1.0965266227722168, GAN loss = [3.5273073, 1.2472298, 1.4402558]\n",
      "Batch 269/700: Discriminator loss = 1.1086357831954956, GAN loss = [3.5031166, 1.249477, 1.4138436]\n",
      "Batch 270/700: Discriminator loss = 1.0965614318847656, GAN loss = [3.5367215, 1.2487477, 1.4482036]\n",
      "Batch 271/700: Discriminator loss = 1.1181275844573975, GAN loss = [3.5463812, 1.2658715, 1.4407688]\n",
      "Batch 272/700: Discriminator loss = 1.0929419994354248, GAN loss = [3.5800748, 1.2890037, 1.4513574]\n",
      "Batch 273/700: Discriminator loss = 1.0810407400131226, GAN loss = [3.75525, 1.3137642, 1.6018006]\n",
      "Batch 274/700: Discriminator loss = 1.0700316429138184, GAN loss = [3.9172862, 1.3175162, 1.7601058]\n",
      "Batch 275/700: Discriminator loss = 1.0492713451385498, GAN loss = [3.6393151, 1.2620164, 1.5376525]\n",
      "Batch 276/700: Discriminator loss = 1.0594384670257568, GAN loss = [3.8067715, 1.3268777, 1.6402681]\n",
      "Batch 277/700: Discriminator loss = 1.0536497831344604, GAN loss = [3.639655, 1.3184181, 1.4816253]\n",
      "Batch 278/700: Discriminator loss = 1.0944814682006836, GAN loss = [3.841446, 1.3538451, 1.6480058]\n",
      "Batch 279/700: Discriminator loss = 1.0629891157150269, GAN loss = [3.6368856, 1.3033884, 1.4939189]\n",
      "Batch 280/700: Discriminator loss = 1.0996837615966797, GAN loss = [3.5207498, 1.323168, 1.3580198]\n",
      "Batch 281/700: Discriminator loss = 1.032107949256897, GAN loss = [3.5665195, 1.3268505, 1.4001205]\n",
      "Batch 282/700: Discriminator loss = 1.063395380973816, GAN loss = [3.5519915, 1.3229916, 1.3894674]\n",
      "Batch 283/700: Discriminator loss = 1.108123779296875, GAN loss = [3.611948, 1.3328812, 1.4395543]\n",
      "Batch 284/700: Discriminator loss = 1.0820144414901733, GAN loss = [3.5478437, 1.3209481, 1.387404]\n",
      "Batch 285/700: Discriminator loss = 1.057664394378662, GAN loss = [3.70353, 1.3973014, 1.4667511]\n",
      "Batch 286/700: Discriminator loss = 1.0611987113952637, GAN loss = [3.655547, 1.3843688, 1.4317169]\n",
      "Batch 287/700: Discriminator loss = 1.0464073419570923, GAN loss = [3.8316445, 1.3879529, 1.6042416]\n",
      "Batch 288/700: Discriminator loss = 1.099481225013733, GAN loss = [3.5397635, 1.3190031, 1.381323]\n",
      "Batch 289/700: Discriminator loss = 1.084782600402832, GAN loss = [3.587059, 1.330582, 1.4170474]\n",
      "Batch 290/700: Discriminator loss = 1.0993494987487793, GAN loss = [3.4850254, 1.3073725, 1.3382334]\n",
      "Batch 291/700: Discriminator loss = 1.089743971824646, GAN loss = [3.6204438, 1.3624458, 1.4185902]\n",
      "Batch 292/700: Discriminator loss = 1.0627291202545166, GAN loss = [3.648509, 1.3458695, 1.4632368]\n",
      "Batch 293/700: Discriminator loss = 1.1076072454452515, GAN loss = [3.5855038, 1.3082722, 1.4378277]\n",
      "Batch 294/700: Discriminator loss = 1.1152726411819458, GAN loss = [3.4618642, 1.3159813, 1.3064787]\n",
      "Batch 295/700: Discriminator loss = 1.1039917469024658, GAN loss = [3.607925, 1.3084968, 1.4600209]\n",
      "Batch 296/700: Discriminator loss = 1.1435647010803223, GAN loss = [3.4685082, 1.3239312, 1.3051709]\n",
      "Batch 297/700: Discriminator loss = 1.1230167150497437, GAN loss = [3.5475318, 1.3343943, 1.3737326]\n",
      "Batch 298/700: Discriminator loss = 1.1038808822631836, GAN loss = [3.4788353, 1.3566933, 1.28274]\n",
      "Batch 299/700: Discriminator loss = 1.0902206897735596, GAN loss = [3.6474085, 1.3536944, 1.4543152]\n",
      "Batch 300/700: Discriminator loss = 1.181740641593933, GAN loss = [3.311604, 1.3489484, 1.1232606]\n",
      "Batch 301/700: Discriminator loss = 1.1092865467071533, GAN loss = [3.4350214, 1.3310366, 1.2645917]\n",
      "Batch 302/700: Discriminator loss = 1.1420254707336426, GAN loss = [3.183673, 1.3324753, 1.0118091]\n",
      "Batch 303/700: Discriminator loss = 1.1389210224151611, GAN loss = [3.2939289, 1.3045828, 1.1499622]\n",
      "Batch 304/700: Discriminator loss = 1.1090662479400635, GAN loss = [3.4262183, 1.3481418, 1.2386982]\n",
      "Batch 305/700: Discriminator loss = 1.1278514862060547, GAN loss = [3.3512292, 1.34834, 1.1635242]\n",
      "Batch 306/700: Discriminator loss = 1.1315028667449951, GAN loss = [3.4546723, 1.3278011, 1.2875224]\n",
      "Batch 307/700: Discriminator loss = 1.1381852626800537, GAN loss = [3.4217148, 1.3352482, 1.2471335]\n",
      "Batch 308/700: Discriminator loss = 1.1357440948486328, GAN loss = [3.4965746, 1.366483, 1.2907662]\n",
      "Batch 309/700: Discriminator loss = 1.1218163967132568, GAN loss = [3.6237462, 1.364465, 1.4199624]\n",
      "Batch 310/700: Discriminator loss = 1.0763068199157715, GAN loss = [3.5627315, 1.3655947, 1.3578221]\n",
      "Batch 311/700: Discriminator loss = 1.0902161598205566, GAN loss = [3.4963543, 1.3491434, 1.3078985]\n",
      "Batch 312/700: Discriminator loss = 1.1366196870803833, GAN loss = [3.6135817, 1.3245573, 1.4497192]\n",
      "Batch 313/700: Discriminator loss = 1.1207001209259033, GAN loss = [3.4461381, 1.313456, 1.2933781]\n",
      "Batch 314/700: Discriminator loss = 1.1380696296691895, GAN loss = [3.4415696, 1.3283123, 1.2739542]\n",
      "Batch 315/700: Discriminator loss = 1.1272269487380981, GAN loss = [3.6257212, 1.3437018, 1.4427203]\n",
      "Batch 316/700: Discriminator loss = 1.128158688545227, GAN loss = [3.3916762, 1.3001612, 1.2522273]\n",
      "Batch 317/700: Discriminator loss = 1.12653648853302, GAN loss = [3.4323356, 1.3046999, 1.2883638]\n",
      "Batch 318/700: Discriminator loss = 1.061445713043213, GAN loss = [3.8594744, 1.3251511, 1.6950684]\n",
      "Batch 319/700: Discriminator loss = 1.0426812171936035, GAN loss = [3.8604047, 1.3696165, 1.6515529]\n",
      "Batch 320/700: Discriminator loss = 1.0693825483322144, GAN loss = [3.7305572, 1.3408362, 1.5505072]\n",
      "Batch 321/700: Discriminator loss = 1.0938760042190552, GAN loss = [3.522871, 1.3445172, 1.3391593]\n",
      "Batch 322/700: Discriminator loss = 1.0534647703170776, GAN loss = [3.8436403, 1.3767034, 1.6277626]\n",
      "Batch 323/700: Discriminator loss = 1.0469624996185303, GAN loss = [3.9533713, 1.4015317, 1.7126857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 324/700: Discriminator loss = 1.0329777002334595, GAN loss = [3.8473186, 1.3938537, 1.6143323]\n",
      "Batch 325/700: Discriminator loss = 1.047711968421936, GAN loss = [3.9460776, 1.4605339, 1.646423]\n",
      "Batch 326/700: Discriminator loss = 1.096169352531433, GAN loss = [3.744434, 1.4128734, 1.4924493]\n",
      "Batch 327/700: Discriminator loss = 1.0430777072906494, GAN loss = [3.8361506, 1.399655, 1.5973886]\n",
      "Batch 328/700: Discriminator loss = 1.0715734958648682, GAN loss = [3.9760652, 1.4414369, 1.6955328]\n",
      "Batch 329/700: Discriminator loss = 1.1113396883010864, GAN loss = [3.7626445, 1.417499, 1.5060666]\n",
      "Batch 330/700: Discriminator loss = 1.1116218566894531, GAN loss = [3.7973547, 1.4578805, 1.5004132]\n",
      "Batch 331/700: Discriminator loss = 1.091592788696289, GAN loss = [3.764441, 1.4182341, 1.5071563]\n",
      "Batch 332/700: Discriminator loss = 1.0932793617248535, GAN loss = [3.7549617, 1.4412113, 1.4747026]\n",
      "Batch 333/700: Discriminator loss = 1.1025652885437012, GAN loss = [3.611485, 1.4064232, 1.3660235]\n",
      "Batch 334/700: Discriminator loss = 1.1156319379806519, GAN loss = [3.6403272, 1.4282032, 1.3730981]\n",
      "Batch 335/700: Discriminator loss = 1.2073947191238403, GAN loss = [3.5969698, 1.4203392, 1.3376175]\n",
      "Batch 336/700: Discriminator loss = 1.1788673400878906, GAN loss = [3.5862045, 1.517738, 1.229459]\n",
      "Batch 337/700: Discriminator loss = 1.1952694654464722, GAN loss = [3.3103902, 1.4051414, 1.0662472]\n",
      "Batch 338/700: Discriminator loss = 1.1726692914962769, GAN loss = [3.48392, 1.4397105, 1.2052113]\n",
      "Batch 339/700: Discriminator loss = 1.1494799852371216, GAN loss = [3.5242422, 1.5064279, 1.1788157]\n",
      "Batch 340/700: Discriminator loss = 1.1128383874893188, GAN loss = [3.3400042, 1.3856698, 1.1153377]\n",
      "Batch 341/700: Discriminator loss = 1.1280328035354614, GAN loss = [3.5207555, 1.4752219, 1.2065431]\n",
      "Batch 342/700: Discriminator loss = 1.1370234489440918, GAN loss = [3.4756608, 1.4700633, 1.1666154]\n",
      "Batch 343/700: Discriminator loss = 1.0835490226745605, GAN loss = [3.512813, 1.5002985, 1.1735436]\n",
      "Batch 344/700: Discriminator loss = 1.1550450325012207, GAN loss = [3.4474924, 1.5469815, 1.0615584]\n",
      "Batch 345/700: Discriminator loss = 1.0619765520095825, GAN loss = [3.5896158, 1.5335741, 1.2171162]\n",
      "Batch 346/700: Discriminator loss = 1.1463080644607544, GAN loss = [3.4713213, 1.5188504, 1.1135753]\n",
      "Batch 347/700: Discriminator loss = 1.1292314529418945, GAN loss = [3.6036918, 1.5226505, 1.2421746]\n",
      "Batch 348/700: Discriminator loss = 1.103041648864746, GAN loss = [3.5073478, 1.4835619, 1.184944]\n",
      "Batch 349/700: Discriminator loss = 1.177926778793335, GAN loss = [3.4481108, 1.4283113, 1.1809765]\n",
      "Batch 350/700: Discriminator loss = 1.1175835132598877, GAN loss = [3.4954672, 1.453891, 1.2027642]\n",
      "Batch 351/700: Discriminator loss = 1.0836125612258911, GAN loss = [3.5789635, 1.4844964, 1.2556717]\n",
      "Batch 352/700: Discriminator loss = 1.1011866331100464, GAN loss = [3.6069632, 1.5575424, 1.210654]\n",
      "Batch 353/700: Discriminator loss = 1.052203893661499, GAN loss = [3.6318748, 1.4962944, 1.2968405]\n",
      "Batch 354/700: Discriminator loss = 1.1153168678283691, GAN loss = [3.531292, 1.4593755, 1.233207]\n",
      "Batch 355/700: Discriminator loss = 1.0728422403335571, GAN loss = [3.5633001, 1.4267966, 1.2978264]\n",
      "Batch 356/700: Discriminator loss = 1.0834285020828247, GAN loss = [3.4981532, 1.4139769, 1.2455361]\n",
      "Batch 357/700: Discriminator loss = 1.0828781127929688, GAN loss = [3.5801458, 1.4176259, 1.3239186]\n",
      "Batch 358/700: Discriminator loss = 1.0873472690582275, GAN loss = [3.5087411, 1.374553, 1.2956265]\n",
      "Batch 359/700: Discriminator loss = 1.1368637084960938, GAN loss = [3.5131474, 1.3820844, 1.2925442]\n",
      "Batch 360/700: Discriminator loss = 1.0886274576187134, GAN loss = [3.5234835, 1.3557342, 1.32927]\n",
      "Batch 361/700: Discriminator loss = 1.0642822980880737, GAN loss = [3.7248049, 1.3727072, 1.5136518]\n",
      "Batch 362/700: Discriminator loss = 1.1262116432189941, GAN loss = [3.5739913, 1.3254818, 1.4100926]\n",
      "Batch 363/700: Discriminator loss = 1.1751952171325684, GAN loss = [3.4678667, 1.3146979, 1.3147794]\n",
      "Batch 364/700: Discriminator loss = 1.0789175033569336, GAN loss = [3.6689866, 1.349581, 1.4810398]\n",
      "Batch 365/700: Discriminator loss = 1.1246225833892822, GAN loss = [3.552196, 1.3352025, 1.3786551]\n",
      "Batch 366/700: Discriminator loss = 1.1163724660873413, GAN loss = [3.6714988, 1.3413109, 1.49188]\n",
      "Batch 367/700: Discriminator loss = 1.112186312675476, GAN loss = [3.653913, 1.3705618, 1.4450737]\n",
      "Batch 368/700: Discriminator loss = 1.10587739944458, GAN loss = [3.4896903, 1.3401825, 1.3112645]\n",
      "Batch 369/700: Discriminator loss = 1.0671226978302002, GAN loss = [3.6983843, 1.3654466, 1.4947243]\n",
      "Batch 370/700: Discriminator loss = 1.145151972770691, GAN loss = [3.7985253, 1.3813248, 1.5790166]\n",
      "Batch 371/700: Discriminator loss = 1.079695224761963, GAN loss = [3.6471813, 1.3858316, 1.423199]\n",
      "Batch 372/700: Discriminator loss = 1.0703667402267456, GAN loss = [3.755718, 1.4062271, 1.5113739]\n",
      "Batch 373/700: Discriminator loss = 1.089152216911316, GAN loss = [3.665489, 1.398484, 1.4289215]\n",
      "Batch 374/700: Discriminator loss = 1.0565789937973022, GAN loss = [3.7271996, 1.4039754, 1.4851713]\n",
      "Batch 375/700: Discriminator loss = 1.0882203578948975, GAN loss = [3.777284, 1.3778899, 1.5613741]\n",
      "Batch 376/700: Discriminator loss = 1.0215932130813599, GAN loss = [3.8253202, 1.3973839, 1.5899568]\n",
      "Batch 377/700: Discriminator loss = 1.0805859565734863, GAN loss = [3.8060021, 1.3595978, 1.6084621]\n",
      "Batch 378/700: Discriminator loss = 1.1033961772918701, GAN loss = [3.5405345, 1.3772682, 1.3253614]\n",
      "Batch 379/700: Discriminator loss = 1.077571153640747, GAN loss = [3.5175142, 1.3297431, 1.349906]\n",
      "Batch 380/700: Discriminator loss = 1.117384433746338, GAN loss = [3.6132846, 1.367981, 1.4074746]\n",
      "Batch 381/700: Discriminator loss = 1.116139531135559, GAN loss = [3.5852149, 1.3490357, 1.3983932]\n",
      "Batch 382/700: Discriminator loss = 1.137366771697998, GAN loss = [3.4888213, 1.3259726, 1.3251048]\n",
      "Batch 383/700: Discriminator loss = 1.173829197883606, GAN loss = [3.415671, 1.3128896, 1.2650752]\n",
      "Batch 384/700: Discriminator loss = 1.1471567153930664, GAN loss = [3.56006, 1.3677614, 1.3546275]\n",
      "Batch 385/700: Discriminator loss = 1.1275478601455688, GAN loss = [3.568741, 1.3901867, 1.3409185]\n",
      "Batch 386/700: Discriminator loss = 1.0823498964309692, GAN loss = [3.541634, 1.3386368, 1.3653942]\n",
      "Batch 387/700: Discriminator loss = 1.1199227571487427, GAN loss = [3.4955878, 1.3192221, 1.3387918]\n",
      "Batch 388/700: Discriminator loss = 1.1270408630371094, GAN loss = [3.3398638, 1.296674, 1.2056382]\n",
      "Batch 389/700: Discriminator loss = 1.102072834968567, GAN loss = [3.4665935, 1.2707388, 1.3583261]\n",
      "Batch 390/700: Discriminator loss = 1.0984840393066406, GAN loss = [3.6022372, 1.3359833, 1.4287513]\n",
      "Batch 391/700: Discriminator loss = 1.074925184249878, GAN loss = [3.539962, 1.3176279, 1.3848625]\n",
      "Batch 392/700: Discriminator loss = 1.0856623649597168, GAN loss = [3.490337, 1.3493239, 1.3035715]\n",
      "Batch 393/700: Discriminator loss = 1.0660215616226196, GAN loss = [3.6504714, 1.353787, 1.4592665]\n",
      "Batch 394/700: Discriminator loss = 1.0476551055908203, GAN loss = [3.6573691, 1.3125879, 1.5073922]\n",
      "Batch 395/700: Discriminator loss = 1.070053219795227, GAN loss = [3.6011994, 1.3247272, 1.439113]\n",
      "Batch 396/700: Discriminator loss = 1.1168538331985474, GAN loss = [3.526917, 1.2791178, 1.4104712]\n",
      "Batch 397/700: Discriminator loss = 1.0718032121658325, GAN loss = [3.7641513, 1.3178775, 1.6089803]\n",
      "Batch 398/700: Discriminator loss = 1.0544809103012085, GAN loss = [3.7164886, 1.324167, 1.555065]\n",
      "Batch 399/700: Discriminator loss = 1.1077195405960083, GAN loss = [3.5417764, 1.2946593, 1.4098964]\n",
      "Batch 400/700: Discriminator loss = 1.1021509170532227, GAN loss = [3.566781, 1.3056645, 1.4239285]\n",
      "Batch 401/700: Discriminator loss = 1.1064401865005493, GAN loss = [3.6466994, 1.3375311, 1.4720062]\n",
      "Batch 402/700: Discriminator loss = 1.1165134906768799, GAN loss = [3.5208058, 1.2689968, 1.414669]\n",
      "Batch 403/700: Discriminator loss = 1.1298187971115112, GAN loss = [3.4687433, 1.3468939, 1.284727]\n",
      "Batch 404/700: Discriminator loss = 1.0590956211090088, GAN loss = [3.7526243, 1.3366412, 1.5788846]\n",
      "Batch 405/700: Discriminator loss = 1.0566688776016235, GAN loss = [3.7026901, 1.2944685, 1.571147]\n",
      "Batch 406/700: Discriminator loss = 1.0848138332366943, GAN loss = [3.7048826, 1.3324673, 1.5353633]\n",
      "Batch 407/700: Discriminator loss = 1.1110308170318604, GAN loss = [3.7250252, 1.3150773, 1.5729206]\n",
      "Batch 408/700: Discriminator loss = 1.0682717561721802, GAN loss = [3.777953, 1.288044, 1.6529014]\n",
      "Batch 409/700: Discriminator loss = 1.0685384273529053, GAN loss = [3.6577036, 1.2967734, 1.523945]\n",
      "Batch 410/700: Discriminator loss = 1.1217414140701294, GAN loss = [3.4429884, 1.2941664, 1.3118596]\n",
      "Batch 411/700: Discriminator loss = 1.0773063898086548, GAN loss = [3.6999104, 1.295268, 1.5677022]\n",
      "Batch 412/700: Discriminator loss = 1.1217451095581055, GAN loss = [3.6978576, 1.2677459, 1.5931948]\n",
      "Batch 413/700: Discriminator loss = 1.0848978757858276, GAN loss = [3.584296, 1.2929398, 1.4544592]\n",
      "Batch 414/700: Discriminator loss = 1.086225986480713, GAN loss = [3.692275, 1.2749473, 1.5804524]\n",
      "Batch 415/700: Discriminator loss = 1.1002092361450195, GAN loss = [3.5774546, 1.3353139, 1.4052827]\n",
      "Batch 416/700: Discriminator loss = 1.1253612041473389, GAN loss = [3.4014742, 1.2768123, 1.2878262]\n",
      "Batch 417/700: Discriminator loss = 1.1379438638687134, GAN loss = [3.4304512, 1.2912053, 1.302431]\n",
      "Batch 418/700: Discriminator loss = 1.1744378805160522, GAN loss = [3.427436, 1.2801697, 1.310471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 419/700: Discriminator loss = 1.1343599557876587, GAN loss = [3.517331, 1.3208842, 1.3596692]\n",
      "Batch 420/700: Discriminator loss = 1.1009585857391357, GAN loss = [3.4209619, 1.3240224, 1.260169]\n",
      "Batch 421/700: Discriminator loss = 1.1556419134140015, GAN loss = [3.4329154, 1.3529427, 1.2432096]\n",
      "Batch 422/700: Discriminator loss = 1.1420040130615234, GAN loss = [3.3160977, 1.3469095, 1.1324341]\n",
      "Batch 423/700: Discriminator loss = 1.1098606586456299, GAN loss = [3.35865, 1.3722012, 1.1497037]\n",
      "Batch 424/700: Discriminator loss = 1.1580289602279663, GAN loss = [3.372364, 1.3395889, 1.1960475]\n",
      "Batch 425/700: Discriminator loss = 1.1657131910324097, GAN loss = [3.3010066, 1.3599617, 1.1043369]\n",
      "Batch 426/700: Discriminator loss = 1.1415607929229736, GAN loss = [3.3792932, 1.3691138, 1.173495]\n",
      "Batch 427/700: Discriminator loss = 1.1549885272979736, GAN loss = [3.2681746, 1.3483596, 1.0831449]\n",
      "Batch 428/700: Discriminator loss = 1.1433950662612915, GAN loss = [3.3556354, 1.3581387, 1.1608386]\n",
      "Batch 429/700: Discriminator loss = 1.1037269830703735, GAN loss = [3.4916787, 1.3903657, 1.2646643]\n",
      "Batch 430/700: Discriminator loss = 1.1602576971054077, GAN loss = [3.3626842, 1.4736038, 1.0524473]\n",
      "Batch 431/700: Discriminator loss = 1.0685522556304932, GAN loss = [3.5453317, 1.4158309, 1.2928863]\n",
      "Batch 432/700: Discriminator loss = 1.1218769550323486, GAN loss = [3.4153273, 1.3587183, 1.2200128]\n",
      "Batch 433/700: Discriminator loss = 1.118117094039917, GAN loss = [3.3356972, 1.3581412, 1.1409737]\n",
      "Batch 434/700: Discriminator loss = 1.1380257606506348, GAN loss = [3.4190977, 1.3763324, 1.2062052]\n",
      "Batch 435/700: Discriminator loss = 1.103186845779419, GAN loss = [3.3823276, 1.2989492, 1.2468467]\n",
      "Batch 436/700: Discriminator loss = 1.1749095916748047, GAN loss = [3.4565852, 1.3817372, 1.2383451]\n",
      "Batch 437/700: Discriminator loss = 1.111055612564087, GAN loss = [3.3735833, 1.3505439, 1.1865629]\n",
      "Batch 438/700: Discriminator loss = 1.091145396232605, GAN loss = [3.5045645, 1.352247, 1.3158723]\n",
      "Batch 439/700: Discriminator loss = 1.1323895454406738, GAN loss = [3.3036897, 1.3311357, 1.1361375]\n",
      "Batch 440/700: Discriminator loss = 1.1428829431533813, GAN loss = [3.2303722, 1.2628512, 1.1311347]\n",
      "Batch 441/700: Discriminator loss = 1.0902360677719116, GAN loss = [3.441636, 1.3030087, 1.3022763]\n",
      "Batch 442/700: Discriminator loss = 1.1237123012542725, GAN loss = [3.3721056, 1.2843487, 1.2514393]\n",
      "Batch 443/700: Discriminator loss = 1.1034033298492432, GAN loss = [3.323033, 1.3392645, 1.1474805]\n",
      "Batch 444/700: Discriminator loss = 1.1035300493240356, GAN loss = [3.4606764, 1.3189563, 1.3054636]\n",
      "Batch 445/700: Discriminator loss = 1.118508219718933, GAN loss = [3.3959856, 1.3207862, 1.2389702]\n",
      "Batch 446/700: Discriminator loss = 1.171554446220398, GAN loss = [3.1289551, 1.27399, 1.0187612]\n",
      "Batch 447/700: Discriminator loss = 1.126962661743164, GAN loss = [3.379089, 1.3252388, 1.2176735]\n",
      "Batch 448/700: Discriminator loss = 1.1208001375198364, GAN loss = [3.2271612, 1.2991116, 1.0919011]\n",
      "Batch 449/700: Discriminator loss = 1.1101762056350708, GAN loss = [3.3608217, 1.3291782, 1.1955283]\n",
      "Batch 450/700: Discriminator loss = 1.1587868928909302, GAN loss = [3.2393568, 1.2864707, 1.1168027]\n",
      "Batch 451/700: Discriminator loss = 1.1422353982925415, GAN loss = [3.2507715, 1.2790087, 1.1357133]\n",
      "Batch 452/700: Discriminator loss = 1.1141554117202759, GAN loss = [3.2687204, 1.2920231, 1.1406802]\n",
      "Batch 453/700: Discriminator loss = 1.1360646486282349, GAN loss = [3.3417084, 1.30739, 1.198332]\n",
      "Batch 454/700: Discriminator loss = 1.148268461227417, GAN loss = [3.219228, 1.2910547, 1.0922179]\n",
      "Batch 455/700: Discriminator loss = 1.1297967433929443, GAN loss = [3.2078032, 1.2960395, 1.0758393]\n",
      "Batch 456/700: Discriminator loss = 1.1971700191497803, GAN loss = [3.2128274, 1.3062468, 1.0706936]\n",
      "Batch 457/700: Discriminator loss = 1.1145095825195312, GAN loss = [3.2062075, 1.308558, 1.0618037]\n",
      "Batch 458/700: Discriminator loss = 1.1503645181655884, GAN loss = [3.2412279, 1.3204675, 1.0849549]\n",
      "Batch 459/700: Discriminator loss = 1.1109957695007324, GAN loss = [3.278411, 1.3048304, 1.1378158]\n",
      "Batch 460/700: Discriminator loss = 1.1265920400619507, GAN loss = [3.3349793, 1.3247895, 1.1744653]\n",
      "Batch 461/700: Discriminator loss = 1.1275845766067505, GAN loss = [3.4362, 1.327829, 1.2726849]\n",
      "Batch 462/700: Discriminator loss = 1.0965023040771484, GAN loss = [3.2611554, 1.3162951, 1.1092103]\n",
      "Batch 463/700: Discriminator loss = 1.1244497299194336, GAN loss = [3.2740772, 1.3231761, 1.1152886]\n",
      "Batch 464/700: Discriminator loss = 1.1471372842788696, GAN loss = [3.3068297, 1.3789222, 1.0923316]\n",
      "Batch 465/700: Discriminator loss = 1.0772249698638916, GAN loss = [3.4758384, 1.3996066, 1.2406951]\n",
      "Batch 466/700: Discriminator loss = 1.1557906866073608, GAN loss = [3.2463193, 1.3535782, 1.0572441]\n",
      "Batch 467/700: Discriminator loss = 1.0987318754196167, GAN loss = [3.3977587, 1.3929765, 1.1693252]\n",
      "Batch 468/700: Discriminator loss = 1.132355809211731, GAN loss = [3.2953978, 1.3674923, 1.0924888]\n",
      "Batch 469/700: Discriminator loss = 1.075344443321228, GAN loss = [3.4397063, 1.3823756, 1.2219507]\n",
      "Batch 470/700: Discriminator loss = 1.0887218713760376, GAN loss = [3.4187102, 1.381681, 1.2016872]\n",
      "Batch 471/700: Discriminator loss = 1.120825171470642, GAN loss = [3.2033005, 1.330428, 1.0375683]\n",
      "Batch 472/700: Discriminator loss = 1.1050711870193481, GAN loss = [3.3412576, 1.3977286, 1.1082597]\n",
      "Batch 473/700: Discriminator loss = 1.0614789724349976, GAN loss = [3.2426307, 1.3432624, 1.0641327]\n",
      "Batch 474/700: Discriminator loss = 1.1168400049209595, GAN loss = [3.3755333, 1.3622891, 1.1780429]\n",
      "Batch 475/700: Discriminator loss = 1.070251703262329, GAN loss = [3.4605505, 1.385552, 1.2398254]\n",
      "Batch 476/700: Discriminator loss = 1.13235342502594, GAN loss = [3.3292227, 1.358747, 1.1353267]\n",
      "Batch 477/700: Discriminator loss = 1.0847700834274292, GAN loss = [3.4665105, 1.407936, 1.2234479]\n",
      "Batch 478/700: Discriminator loss = 1.0660988092422485, GAN loss = [3.4859927, 1.4075377, 1.2433585]\n",
      "Batch 479/700: Discriminator loss = 1.1148560047149658, GAN loss = [3.3879054, 1.4003246, 1.1525146]\n",
      "Batch 480/700: Discriminator loss = 1.090896725654602, GAN loss = [3.515007, 1.3609972, 1.318979]\n",
      "Batch 481/700: Discriminator loss = 1.0827720165252686, GAN loss = [3.432625, 1.3811952, 1.2164326]\n",
      "Batch 482/700: Discriminator loss = 1.0803414583206177, GAN loss = [3.456995, 1.3723406, 1.2496924]\n",
      "Batch 483/700: Discriminator loss = 1.0585843324661255, GAN loss = [3.6020126, 1.3258721, 1.4412131]\n",
      "Batch 484/700: Discriminator loss = 1.1055604219436646, GAN loss = [3.4331284, 1.3503186, 1.2479162]\n",
      "Batch 485/700: Discriminator loss = 1.0840030908584595, GAN loss = [3.4137454, 1.2898316, 1.2890573]\n",
      "Batch 486/700: Discriminator loss = 1.1239869594573975, GAN loss = [3.500012, 1.3184552, 1.3467342]\n",
      "Batch 487/700: Discriminator loss = 1.1179379224777222, GAN loss = [3.3352678, 1.2997139, 1.2007631]\n",
      "Batch 488/700: Discriminator loss = 1.167133092880249, GAN loss = [3.3239267, 1.3055571, 1.1836072]\n",
      "Batch 489/700: Discriminator loss = 1.1321152448654175, GAN loss = [3.3526137, 1.3039752, 1.2139091]\n",
      "Batch 490/700: Discriminator loss = 1.1079511642456055, GAN loss = [3.389276, 1.3216727, 1.2329049]\n",
      "Batch 491/700: Discriminator loss = 1.1951849460601807, GAN loss = [3.3168354, 1.3389581, 1.1432083]\n",
      "Batch 492/700: Discriminator loss = 1.1353988647460938, GAN loss = [3.389184, 1.2889273, 1.2656114]\n",
      "Batch 493/700: Discriminator loss = 1.1287932395935059, GAN loss = [3.2813256, 1.3055841, 1.1411163]\n",
      "Batch 494/700: Discriminator loss = 1.1569921970367432, GAN loss = [3.3143332, 1.3111664, 1.1685618]\n",
      "Batch 495/700: Discriminator loss = 1.1053820848464966, GAN loss = [3.4990287, 1.3842261, 1.2802141]\n",
      "Batch 496/700: Discriminator loss = 1.1113879680633545, GAN loss = [3.409313, 1.345485, 1.2292572]\n",
      "Batch 497/700: Discriminator loss = 1.1261413097381592, GAN loss = [3.3659694, 1.3684301, 1.1629862]\n",
      "Batch 498/700: Discriminator loss = 1.1089450120925903, GAN loss = [3.3833616, 1.3039403, 1.2448821]\n",
      "Batch 499/700: Discriminator loss = 1.1207919120788574, GAN loss = [3.382631, 1.3369246, 1.2111796]\n",
      "Batch 500/700: Discriminator loss = 1.0723832845687866, GAN loss = [3.523336, 1.3420154, 1.3468109]\n",
      "Batch 501/700: Discriminator loss = 1.1287187337875366, GAN loss = [3.4747207, 1.3119004, 1.3283254]\n",
      "Batch 502/700: Discriminator loss = 1.1265056133270264, GAN loss = [3.4025352, 1.3106141, 1.2574394]\n",
      "Batch 503/700: Discriminator loss = 1.1181862354278564, GAN loss = [3.2664304, 1.3180486, 1.1139122]\n",
      "Batch 504/700: Discriminator loss = 1.1564465761184692, GAN loss = [3.352501, 1.3405572, 1.1774887]\n",
      "Batch 505/700: Discriminator loss = 1.149610996246338, GAN loss = [3.2843666, 1.2766515, 1.1732751]\n",
      "Batch 506/700: Discriminator loss = 1.154555320739746, GAN loss = [3.432663, 1.3620373, 1.2362019]\n",
      "Batch 507/700: Discriminator loss = 1.1201549768447876, GAN loss = [3.4273908, 1.3050184, 1.2879591]\n",
      "Batch 508/700: Discriminator loss = 1.1436256170272827, GAN loss = [3.3677192, 1.361303, 1.1720114]\n",
      "Batch 509/700: Discriminator loss = 1.127367377281189, GAN loss = [3.3508656, 1.3410839, 1.1753839]\n",
      "Batch 510/700: Discriminator loss = 1.1471527814865112, GAN loss = [3.3091443, 1.3287021, 1.146057]\n",
      "Batch 511/700: Discriminator loss = 1.129281759262085, GAN loss = [3.4467251, 1.3616891, 1.2506613]\n",
      "Batch 512/700: Discriminator loss = 1.1282427310943604, GAN loss = [3.3576355, 1.3483386, 1.1749359]\n",
      "Batch 513/700: Discriminator loss = 1.124333381652832, GAN loss = [3.306331, 1.3624449, 1.10954]\n",
      "Batch 514/700: Discriminator loss = 1.1379808187484741, GAN loss = [3.2057483, 1.3100184, 1.0614003]\n",
      "Batch 515/700: Discriminator loss = 1.1464475393295288, GAN loss = [3.5745962, 1.4094682, 1.3308175]\n",
      "Batch 516/700: Discriminator loss = 1.0776493549346924, GAN loss = [3.5995016, 1.3799669, 1.3852423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 517/700: Discriminator loss = 1.0989205837249756, GAN loss = [3.4575372, 1.3438863, 1.2793791]\n",
      "Batch 518/700: Discriminator loss = 1.07895827293396, GAN loss = [3.651272, 1.3804085, 1.4366088]\n",
      "Batch 519/700: Discriminator loss = 1.0904247760772705, GAN loss = [3.6443229, 1.3933251, 1.4167619]\n",
      "Batch 520/700: Discriminator loss = 1.105074167251587, GAN loss = [3.5405242, 1.3669157, 1.3393865]\n",
      "Batch 521/700: Discriminator loss = 1.0865217447280884, GAN loss = [3.4999256, 1.3415434, 1.3241723]\n",
      "Batch 522/700: Discriminator loss = 1.1153370141983032, GAN loss = [3.5600686, 1.4002403, 1.3256346]\n",
      "Batch 523/700: Discriminator loss = 1.061037302017212, GAN loss = [3.5879061, 1.4259441, 1.3277872]\n",
      "Batch 524/700: Discriminator loss = 1.051330327987671, GAN loss = [3.668526, 1.3875685, 1.446791]\n",
      "Batch 525/700: Discriminator loss = 1.1000055074691772, GAN loss = [3.6004767, 1.4323792, 1.3339419]\n",
      "Batch 526/700: Discriminator loss = 1.1043294668197632, GAN loss = [3.6938212, 1.4702698, 1.3894082]\n",
      "Batch 527/700: Discriminator loss = 1.0962822437286377, GAN loss = [3.5212965, 1.3415213, 1.3456445]\n",
      "Batch 528/700: Discriminator loss = 1.1268430948257446, GAN loss = [3.5489147, 1.4236794, 1.2911136]\n",
      "Batch 529/700: Discriminator loss = 1.1790542602539062, GAN loss = [3.415714, 1.3947796, 1.1868222]\n",
      "Batch 530/700: Discriminator loss = 1.1368101835250854, GAN loss = [3.297449, 1.36561, 1.0977334]\n",
      "Batch 531/700: Discriminator loss = 1.164698600769043, GAN loss = [3.367905, 1.3910625, 1.1427503]\n",
      "Batch 532/700: Discriminator loss = 1.0870715379714966, GAN loss = [3.4007905, 1.3366824, 1.2300304]\n",
      "Batch 533/700: Discriminator loss = 1.1190733909606934, GAN loss = [3.423447, 1.3788105, 1.2105743]\n",
      "Batch 534/700: Discriminator loss = 1.1346007585525513, GAN loss = [3.4265876, 1.3843158, 1.2082204]\n",
      "Batch 535/700: Discriminator loss = 1.1337270736694336, GAN loss = [3.336316, 1.3644893, 1.137779]\n",
      "Batch 536/700: Discriminator loss = 1.1004406213760376, GAN loss = [3.3832183, 1.3583723, 1.1908026]\n",
      "Batch 537/700: Discriminator loss = 1.120888590812683, GAN loss = [3.3713205, 1.3561362, 1.1811486]\n",
      "Batch 538/700: Discriminator loss = 1.1278496980667114, GAN loss = [3.2784154, 1.3177835, 1.1266046]\n",
      "Batch 539/700: Discriminator loss = 1.0768804550170898, GAN loss = [3.479606, 1.3536928, 1.2918901]\n",
      "Batch 540/700: Discriminator loss = 1.1336698532104492, GAN loss = [3.2393558, 1.3563476, 1.0489916]\n",
      "Batch 541/700: Discriminator loss = 1.0997867584228516, GAN loss = [3.4915278, 1.3737144, 1.283807]\n",
      "Batch 542/700: Discriminator loss = 1.126135230064392, GAN loss = [3.3045168, 1.3102733, 1.1602473]\n",
      "Batch 543/700: Discriminator loss = 1.1051582098007202, GAN loss = [3.3668284, 1.3399342, 1.1929059]\n",
      "Batch 544/700: Discriminator loss = 1.1233593225479126, GAN loss = [3.338952, 1.3421053, 1.1628678]\n",
      "Batch 545/700: Discriminator loss = 1.1144921779632568, GAN loss = [3.3134468, 1.3100977, 1.1693805]\n",
      "Batch 546/700: Discriminator loss = 1.1236801147460938, GAN loss = [3.3265157, 1.3069888, 1.1855712]\n",
      "Batch 547/700: Discriminator loss = 1.1164734363555908, GAN loss = [3.3245177, 1.2971845, 1.1933883]\n",
      "Batch 548/700: Discriminator loss = 1.1309771537780762, GAN loss = [3.3497338, 1.323398, 1.1923968]\n",
      "Batch 549/700: Discriminator loss = 1.0852611064910889, GAN loss = [3.5171375, 1.3310342, 1.3521718]\n",
      "Batch 550/700: Discriminator loss = 1.0890991687774658, GAN loss = [3.329555, 1.2862351, 1.2094024]\n",
      "Batch 551/700: Discriminator loss = 1.0886268615722656, GAN loss = [3.4348347, 1.2900343, 1.3108969]\n",
      "Batch 552/700: Discriminator loss = 1.064719796180725, GAN loss = [3.5218983, 1.3142042, 1.3738061]\n",
      "Batch 553/700: Discriminator loss = 1.1038240194320679, GAN loss = [3.3198304, 1.2888225, 1.1971295]\n",
      "Batch 554/700: Discriminator loss = 1.0936806201934814, GAN loss = [3.362117, 1.3131312, 1.2151217]\n",
      "Batch 555/700: Discriminator loss = 1.0749831199645996, GAN loss = [3.5075312, 1.3220298, 1.3516618]\n",
      "Batch 556/700: Discriminator loss = 1.1255155801773071, GAN loss = [3.5031643, 1.3758342, 1.2935088]\n",
      "Batch 557/700: Discriminator loss = 1.102905035018921, GAN loss = [3.4375954, 1.3339332, 1.2698637]\n",
      "Batch 558/700: Discriminator loss = 1.1003212928771973, GAN loss = [3.5227768, 1.3329028, 1.3561021]\n",
      "Batch 559/700: Discriminator loss = 1.0585896968841553, GAN loss = [3.5869966, 1.3456682, 1.4075817]\n",
      "Batch 560/700: Discriminator loss = 1.0910242795944214, GAN loss = [3.4919357, 1.3843164, 1.2738973]\n",
      "Batch 561/700: Discriminator loss = 1.0737574100494385, GAN loss = [3.5714533, 1.3315539, 1.406203]\n",
      "Batch 562/700: Discriminator loss = 1.0493777990341187, GAN loss = [3.7246947, 1.3582326, 1.5327927]\n",
      "Batch 563/700: Discriminator loss = 1.0707590579986572, GAN loss = [3.7131732, 1.3590552, 1.5204755]\n",
      "Batch 564/700: Discriminator loss = 1.0772075653076172, GAN loss = [3.5618055, 1.3713171, 1.3568686]\n",
      "Batch 565/700: Discriminator loss = 1.0829745531082153, GAN loss = [3.461311, 1.3335401, 1.2941786]\n",
      "Batch 566/700: Discriminator loss = 1.0752168893814087, GAN loss = [3.5026774, 1.3145338, 1.3545766]\n",
      "Batch 567/700: Discriminator loss = 1.0869758129119873, GAN loss = [3.5758593, 1.345314, 1.3969992]\n",
      "Batch 568/700: Discriminator loss = 1.0603145360946655, GAN loss = [3.5659335, 1.3404994, 1.391906]\n",
      "Batch 569/700: Discriminator loss = 1.0797115564346313, GAN loss = [3.6816888, 1.377016, 1.471163]\n",
      "Batch 570/700: Discriminator loss = 1.036817193031311, GAN loss = [3.5210896, 1.3767465, 1.3108547]\n",
      "Batch 571/700: Discriminator loss = 1.0800929069519043, GAN loss = [3.5018904, 1.3472635, 1.3211601]\n",
      "Batch 572/700: Discriminator loss = 1.0329625606536865, GAN loss = [3.7034414, 1.389079, 1.480909]\n",
      "Batch 573/700: Discriminator loss = 1.0822381973266602, GAN loss = [3.5483487, 1.3287272, 1.3861787]\n",
      "Batch 574/700: Discriminator loss = 1.0943235158920288, GAN loss = [3.6546316, 1.3449553, 1.4762529]\n",
      "Batch 575/700: Discriminator loss = 1.0810660123825073, GAN loss = [3.5573435, 1.3713361, 1.3525907]\n",
      "Batch 576/700: Discriminator loss = 1.057847023010254, GAN loss = [3.6737523, 1.3875573, 1.4527917]\n",
      "Batch 577/700: Discriminator loss = 1.038630485534668, GAN loss = [3.6418843, 1.3848364, 1.423662]\n",
      "Batch 578/700: Discriminator loss = 1.0531928539276123, GAN loss = [3.6772368, 1.381268, 1.4626074]\n",
      "Batch 579/700: Discriminator loss = 1.0715091228485107, GAN loss = [3.658379, 1.3774971, 1.4475437]\n",
      "Batch 580/700: Discriminator loss = 1.0792990922927856, GAN loss = [3.7243876, 1.418889, 1.4721762]\n",
      "Batch 581/700: Discriminator loss = 1.0821952819824219, GAN loss = [3.6198695, 1.4407419, 1.3458127]\n",
      "Batch 582/700: Discriminator loss = 1.0598288774490356, GAN loss = [3.671646, 1.3977556, 1.4405841]\n",
      "Batch 583/700: Discriminator loss = 1.0808746814727783, GAN loss = [3.6930656, 1.4593478, 1.4004195]\n",
      "Batch 584/700: Discriminator loss = 1.0964983701705933, GAN loss = [3.6293511, 1.4648759, 1.3311859]\n",
      "Batch 585/700: Discriminator loss = 1.0710653066635132, GAN loss = [3.5921524, 1.4400303, 1.3188471]\n",
      "Batch 586/700: Discriminator loss = 1.0546295642852783, GAN loss = [3.7264183, 1.4884312, 1.4047265]\n",
      "Batch 587/700: Discriminator loss = 1.049446702003479, GAN loss = [3.6496544, 1.4658755, 1.3505245]\n",
      "Batch 588/700: Discriminator loss = 1.0284126996994019, GAN loss = [3.7272599, 1.42734, 1.4666692]\n",
      "Batch 589/700: Discriminator loss = 1.0757454633712769, GAN loss = [3.6180415, 1.3896866, 1.395115]\n",
      "Batch 590/700: Discriminator loss = 1.0766239166259766, GAN loss = [3.555589, 1.4214473, 1.3009195]\n",
      "Batch 591/700: Discriminator loss = 1.0533596277236938, GAN loss = [3.6683006, 1.3816233, 1.4534754]\n",
      "Batch 592/700: Discriminator loss = 1.1215869188308716, GAN loss = [3.6583748, 1.4048995, 1.4202933]\n",
      "Batch 593/700: Discriminator loss = 1.1640325784683228, GAN loss = [3.4358735, 1.4483603, 1.1543527]\n",
      "Batch 594/700: Discriminator loss = 1.092798113822937, GAN loss = [3.593534, 1.422148, 1.3382457]\n",
      "Batch 595/700: Discriminator loss = 1.1256171464920044, GAN loss = [3.4316516, 1.366394, 1.232133]\n",
      "Batch 596/700: Discriminator loss = 1.1603732109069824, GAN loss = [3.4603713, 1.4138718, 1.2133849]\n",
      "Batch 597/700: Discriminator loss = 1.12900972366333, GAN loss = [3.4890976, 1.4063818, 1.2496156]\n",
      "Batch 598/700: Discriminator loss = 1.126904010772705, GAN loss = [3.4156444, 1.4107127, 1.1718478]\n",
      "Batch 599/700: Discriminator loss = 1.107311487197876, GAN loss = [3.3760633, 1.3382686, 1.2047286]\n",
      "Batch 600/700: Discriminator loss = 1.1350644826889038, GAN loss = [3.3959627, 1.3876827, 1.1752338]\n",
      "Batch 601/700: Discriminator loss = 1.1261948347091675, GAN loss = [3.3210337, 1.3590049, 1.1290067]\n",
      "Batch 602/700: Discriminator loss = 1.1366980075836182, GAN loss = [3.376339, 1.34901, 1.1943344]\n",
      "Batch 603/700: Discriminator loss = 1.0724643468856812, GAN loss = [3.5607533, 1.3937564, 1.3340333]\n",
      "Batch 604/700: Discriminator loss = 1.0699299573898315, GAN loss = [3.5523136, 1.3953316, 1.3240579]\n",
      "Batch 605/700: Discriminator loss = 1.1077725887298584, GAN loss = [3.3359704, 1.3310652, 1.1720258]\n",
      "Batch 606/700: Discriminator loss = 1.1135092973709106, GAN loss = [3.4508111, 1.3603854, 1.2575873]\n",
      "Batch 607/700: Discriminator loss = 1.0688375234603882, GAN loss = [3.7290285, 1.3810341, 1.5152009]\n",
      "Batch 608/700: Discriminator loss = 1.0557390451431274, GAN loss = [3.4944413, 1.3618681, 1.299819]\n",
      "Batch 609/700: Discriminator loss = 1.1300594806671143, GAN loss = [3.427094, 1.3314116, 1.2629688]\n",
      "Batch 610/700: Discriminator loss = 1.076418161392212, GAN loss = [3.4217632, 1.3676975, 1.2213933]\n",
      "Batch 611/700: Discriminator loss = 1.093752384185791, GAN loss = [3.5161557, 1.3874404, 1.296089]\n",
      "Batch 612/700: Discriminator loss = 1.096745491027832, GAN loss = [3.6836991, 1.3809987, 1.4701257]\n",
      "Batch 613/700: Discriminator loss = 1.0833934545516968, GAN loss = [3.5337212, 1.3803982, 1.3208007]\n",
      "Batch 614/700: Discriminator loss = 1.0997660160064697, GAN loss = [3.5337386, 1.3900845, 1.3111874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 615/700: Discriminator loss = 1.0551886558532715, GAN loss = [3.5028806, 1.3298622, 1.3406012]\n",
      "Batch 616/700: Discriminator loss = 1.0659419298171997, GAN loss = [3.4788587, 1.3415246, 1.3049587]\n",
      "Batch 617/700: Discriminator loss = 1.0982272624969482, GAN loss = [3.6221578, 1.3715334, 1.4182849]\n",
      "Batch 618/700: Discriminator loss = 1.0955443382263184, GAN loss = [3.5398061, 1.3504835, 1.3570251]\n",
      "Batch 619/700: Discriminator loss = 1.0984774827957153, GAN loss = [3.5132759, 1.3334311, 1.3475893]\n",
      "Batch 620/700: Discriminator loss = 1.0668139457702637, GAN loss = [3.5616283, 1.3512964, 1.3781157]\n",
      "Batch 621/700: Discriminator loss = 1.0961332321166992, GAN loss = [3.4318154, 1.3051972, 1.2944367]\n",
      "Batch 622/700: Discriminator loss = 1.0816038846969604, GAN loss = [3.5563545, 1.3452749, 1.3789353]\n",
      "Batch 623/700: Discriminator loss = 1.0777078866958618, GAN loss = [3.5436337, 1.4071951, 1.304331]\n",
      "Batch 624/700: Discriminator loss = 1.0800564289093018, GAN loss = [3.5365741, 1.3728354, 1.3316679]\n",
      "Batch 625/700: Discriminator loss = 1.102186918258667, GAN loss = [3.4009826, 1.3426362, 1.2263107]\n",
      "Batch 626/700: Discriminator loss = 1.0693954229354858, GAN loss = [3.4743874, 1.3835684, 1.2588154]\n",
      "Batch 627/700: Discriminator loss = 1.0479665994644165, GAN loss = [3.7922456, 1.4405667, 1.5197055]\n",
      "Batch 628/700: Discriminator loss = 1.097952127456665, GAN loss = [3.4871132, 1.365428, 1.2897438]\n",
      "Batch 629/700: Discriminator loss = 1.1150490045547485, GAN loss = [3.4514549, 1.3871193, 1.2324319]\n",
      "Batch 630/700: Discriminator loss = 1.1156980991363525, GAN loss = [3.5083761, 1.3560349, 1.3204755]\n",
      "Batch 631/700: Discriminator loss = 1.0753743648529053, GAN loss = [3.551013, 1.3820304, 1.3371568]\n",
      "Batch 632/700: Discriminator loss = 1.0685317516326904, GAN loss = [3.5800135, 1.3919339, 1.3562906]\n",
      "Batch 633/700: Discriminator loss = 1.1132959127426147, GAN loss = [3.5371153, 1.4282216, 1.2771473]\n",
      "Batch 634/700: Discriminator loss = 1.0816017389297485, GAN loss = [3.534379, 1.4010311, 1.3016496]\n",
      "Batch 635/700: Discriminator loss = 1.0818899869918823, GAN loss = [3.5850868, 1.4015222, 1.3519102]\n",
      "Batch 636/700: Discriminator loss = 1.1258502006530762, GAN loss = [3.5652843, 1.3667614, 1.3669119]\n",
      "Batch 637/700: Discriminator loss = 1.1345504522323608, GAN loss = [3.4437513, 1.3882747, 1.2239054]\n",
      "Batch 638/700: Discriminator loss = 1.1217988729476929, GAN loss = [3.4433367, 1.376575, 1.2352269]\n",
      "Batch 639/700: Discriminator loss = 1.1260042190551758, GAN loss = [3.5254087, 1.3920052, 1.3018999]\n",
      "Batch 640/700: Discriminator loss = 1.1172484159469604, GAN loss = [3.450882, 1.4382473, 1.1811588]\n",
      "Batch 641/700: Discriminator loss = 1.1476199626922607, GAN loss = [3.500871, 1.4574856, 1.2119385]\n",
      "Batch 642/700: Discriminator loss = 1.0642246007919312, GAN loss = [3.5777526, 1.388484, 1.357854]\n",
      "Batch 643/700: Discriminator loss = 1.117052674293518, GAN loss = [3.6796834, 1.450703, 1.3975968]\n",
      "Batch 644/700: Discriminator loss = 1.1048665046691895, GAN loss = [3.5032518, 1.4094572, 1.2624403]\n",
      "Batch 645/700: Discriminator loss = 1.1078929901123047, GAN loss = [3.4874177, 1.3838466, 1.2722453]\n",
      "Batch 646/700: Discriminator loss = 1.140568733215332, GAN loss = [3.377621, 1.3637149, 1.1826005]\n",
      "Batch 647/700: Discriminator loss = 1.0753121376037598, GAN loss = [3.655389, 1.4133921, 1.4107106]\n",
      "Batch 648/700: Discriminator loss = 1.0915443897247314, GAN loss = [3.5512264, 1.3496703, 1.3702936]\n",
      "Batch 649/700: Discriminator loss = 1.1155591011047363, GAN loss = [3.4873166, 1.3629395, 1.2931428]\n",
      "Batch 650/700: Discriminator loss = 1.0637603998184204, GAN loss = [3.6413054, 1.33984, 1.4702635]\n",
      "Batch 651/700: Discriminator loss = 1.1004765033721924, GAN loss = [3.5994964, 1.4005374, 1.3677906]\n",
      "Batch 652/700: Discriminator loss = 1.0771013498306274, GAN loss = [3.7870817, 1.4146893, 1.5412576]\n",
      "Batch 653/700: Discriminator loss = 1.0754294395446777, GAN loss = [3.4957125, 1.3815815, 1.2830309]\n",
      "Batch 654/700: Discriminator loss = 1.0975264310836792, GAN loss = [3.396632, 1.3359084, 1.2296585]\n",
      "Batch 655/700: Discriminator loss = 1.1138955354690552, GAN loss = [3.55807, 1.3746321, 1.3524112]\n",
      "Batch 656/700: Discriminator loss = 1.021594524383545, GAN loss = [3.7449021, 1.3986217, 1.5152922]\n",
      "Batch 657/700: Discriminator loss = 1.0643045902252197, GAN loss = [3.8214505, 1.4394113, 1.5510904]\n",
      "Batch 658/700: Discriminator loss = 1.117880940437317, GAN loss = [3.4561353, 1.3604722, 1.2647519]\n",
      "Batch 659/700: Discriminator loss = 1.0384113788604736, GAN loss = [3.5637152, 1.3919456, 1.3408978]\n",
      "Batch 660/700: Discriminator loss = 1.0766701698303223, GAN loss = [3.7227762, 1.3836218, 1.5083194]\n",
      "Batch 661/700: Discriminator loss = 1.0314226150512695, GAN loss = [3.5932815, 1.3901627, 1.3723193]\n",
      "Batch 662/700: Discriminator loss = 1.0945103168487549, GAN loss = [3.5252557, 1.4292346, 1.2652549]\n",
      "Batch 663/700: Discriminator loss = 1.0401853322982788, GAN loss = [3.8021793, 1.4471939, 1.52425]\n",
      "Batch 664/700: Discriminator loss = 1.009645938873291, GAN loss = [3.7522917, 1.4028702, 1.5187148]\n",
      "Batch 665/700: Discriminator loss = 1.0579489469528198, GAN loss = [3.7397408, 1.4171869, 1.4918759]\n",
      "Batch 666/700: Discriminator loss = 1.0487955808639526, GAN loss = [3.675517, 1.4561212, 1.3887535]\n",
      "Batch 667/700: Discriminator loss = 1.0499629974365234, GAN loss = [3.6529248, 1.3975047, 1.4248092]\n",
      "Batch 668/700: Discriminator loss = 1.064387321472168, GAN loss = [3.7123952, 1.4441317, 1.4376857]\n",
      "Batch 669/700: Discriminator loss = 1.020599365234375, GAN loss = [3.574648, 1.3643378, 1.379764]\n",
      "Batch 670/700: Discriminator loss = 1.0465736389160156, GAN loss = [3.6821918, 1.4197448, 1.4319309]\n",
      "Batch 671/700: Discriminator loss = 1.0507296323776245, GAN loss = [3.788838, 1.4708322, 1.4875139]\n",
      "Batch 672/700: Discriminator loss = 1.076281189918518, GAN loss = [3.6829557, 1.4831067, 1.3693892]\n",
      "Batch 673/700: Discriminator loss = 1.0201321840286255, GAN loss = [3.769757, 1.4386821, 1.5006499]\n",
      "Batch 674/700: Discriminator loss = 1.0853508710861206, GAN loss = [3.7374275, 1.4755782, 1.4314641]\n",
      "Batch 675/700: Discriminator loss = 1.0498143434524536, GAN loss = [3.655879, 1.4055454, 1.4199847]\n",
      "Batch 676/700: Discriminator loss = 1.0349210500717163, GAN loss = [3.8265126, 1.3958446, 1.6003499]\n",
      "Batch 677/700: Discriminator loss = 1.0641475915908813, GAN loss = [3.6982799, 1.4297132, 1.4382799]\n",
      "Batch 678/700: Discriminator loss = 1.0630431175231934, GAN loss = [3.4648287, 1.4007083, 1.2338628]\n",
      "Batch 679/700: Discriminator loss = 1.0707679986953735, GAN loss = [3.610604, 1.4064635, 1.3739111]\n",
      "Batch 680/700: Discriminator loss = 1.0419964790344238, GAN loss = [3.6658044, 1.4247226, 1.4108769]\n",
      "Batch 681/700: Discriminator loss = 1.0547068119049072, GAN loss = [3.7907808, 1.4462966, 1.5143028]\n",
      "Batch 682/700: Discriminator loss = 1.0983633995056152, GAN loss = [3.843342, 1.4405273, 1.5726553]\n",
      "Batch 683/700: Discriminator loss = 1.0274394750595093, GAN loss = [3.943034, 1.5119382, 1.600958]\n",
      "Batch 684/700: Discriminator loss = 1.056726098060608, GAN loss = [3.6987627, 1.4049612, 1.4636862]\n",
      "Batch 685/700: Discriminator loss = 1.0257371664047241, GAN loss = [4.0061517, 1.4775041, 1.6985515]\n",
      "Batch 686/700: Discriminator loss = 1.0443414449691772, GAN loss = [3.836036, 1.4547995, 1.5511639]\n",
      "Batch 687/700: Discriminator loss = 1.0266233682632446, GAN loss = [3.8584764, 1.4982121, 1.5302234]\n",
      "Batch 688/700: Discriminator loss = 1.0602025985717773, GAN loss = [3.7510633, 1.4405905, 1.4804628]\n",
      "Batch 689/700: Discriminator loss = 1.0805692672729492, GAN loss = [3.8373063, 1.4772998, 1.5300213]\n",
      "Batch 690/700: Discriminator loss = 1.1085450649261475, GAN loss = [3.5816758, 1.4152043, 1.3365091]\n",
      "Batch 691/700: Discriminator loss = 1.1231563091278076, GAN loss = [3.53243, 1.435435, 1.2670567]\n",
      "Batch 692/700: Discriminator loss = 1.0651260614395142, GAN loss = [3.7521331, 1.4907079, 1.4315131]\n",
      "Batch 693/700: Discriminator loss = 1.1251684427261353, GAN loss = [3.3870995, 1.4112842, 1.1459358]\n",
      "Batch 694/700: Discriminator loss = 1.0308465957641602, GAN loss = [3.765069, 1.4458793, 1.4893434]\n",
      "Batch 695/700: Discriminator loss = 1.0540536642074585, GAN loss = [3.5475771, 1.3961093, 1.321659]\n",
      "Batch 696/700: Discriminator loss = 1.0822689533233643, GAN loss = [3.5802429, 1.4062538, 1.3442172]\n",
      "Batch 697/700: Discriminator loss = 1.0710687637329102, GAN loss = [3.6445115, 1.4456341, 1.3691449]\n",
      "Batch 698/700: Discriminator loss = 1.0657508373260498, GAN loss = [3.6644728, 1.4568455, 1.3779292]\n",
      "Batch 699/700: Discriminator loss = 1.0475164651870728, GAN loss = [3.4644523, 1.3516475, 1.2831386]\n",
      "Batch 700/700: Discriminator loss = 1.0566787719726562, GAN loss = [3.6744328, 1.4312266, 1.4135678]\n",
      "Epoch 7/30\n",
      "Batch 1/700: Discriminator loss = 1.0895212888717651, GAN loss = [3.579269, 1.3968891, 1.3527712]\n",
      "Batch 2/700: Discriminator loss = 1.0849217176437378, GAN loss = [3.6675708, 1.4651113, 1.3728821]\n",
      "Batch 3/700: Discriminator loss = 1.0015493631362915, GAN loss = [3.6355062, 1.42892, 1.3770415]\n",
      "Batch 4/700: Discriminator loss = 1.0782419443130493, GAN loss = [3.4536448, 1.359883, 1.2642514]\n",
      "Batch 5/700: Discriminator loss = 1.092665672302246, GAN loss = [3.610939, 1.4000118, 1.3814528]\n",
      "Batch 6/700: Discriminator loss = 1.084649920463562, GAN loss = [3.5847633, 1.4191611, 1.3361597]\n",
      "Batch 7/700: Discriminator loss = 1.1068263053894043, GAN loss = [3.5311358, 1.4187387, 1.2829769]\n",
      "Batch 8/700: Discriminator loss = 1.0654224157333374, GAN loss = [3.6436462, 1.4798602, 1.3343929]\n",
      "Batch 9/700: Discriminator loss = 1.0849305391311646, GAN loss = [3.495446, 1.443914, 1.2221653]\n",
      "Batch 10/700: Discriminator loss = 1.1091272830963135, GAN loss = [3.7065449, 1.4093112, 1.467895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11/700: Discriminator loss = 1.1065256595611572, GAN loss = [3.4967334, 1.5195999, 1.1478133]\n",
      "Batch 12/700: Discriminator loss = 1.131574034690857, GAN loss = [3.4494581, 1.4653182, 1.1548371]\n",
      "Batch 13/700: Discriminator loss = 1.0785413980484009, GAN loss = [3.7778804, 1.4735179, 1.4750775]\n",
      "Batch 14/700: Discriminator loss = 1.0868403911590576, GAN loss = [3.543027, 1.4342119, 1.2795544]\n",
      "Batch 15/700: Discriminator loss = 1.0333834886550903, GAN loss = [3.7753763, 1.4615891, 1.4845512]\n",
      "Batch 16/700: Discriminator loss = 1.0432517528533936, GAN loss = [3.8308973, 1.4683589, 1.5333314]\n",
      "Batch 17/700: Discriminator loss = 1.0839276313781738, GAN loss = [3.6580026, 1.4095525, 1.4192663]\n",
      "Batch 18/700: Discriminator loss = 1.0848110914230347, GAN loss = [3.8107095, 1.4449803, 1.5365633]\n",
      "Batch 19/700: Discriminator loss = 1.0559014081954956, GAN loss = [3.9641552, 1.4633807, 1.6716189]\n",
      "Batch 20/700: Discriminator loss = 1.0561285018920898, GAN loss = [3.7719383, 1.446186, 1.4966059]\n",
      "Batch 21/700: Discriminator loss = 1.1202949285507202, GAN loss = [3.5881438, 1.4038322, 1.3551755]\n",
      "Batch 22/700: Discriminator loss = 1.0573128461837769, GAN loss = [3.8382385, 1.4143741, 1.5947369]\n",
      "Batch 23/700: Discriminator loss = 1.106653094291687, GAN loss = [3.512355, 1.3983505, 1.2848866]\n",
      "Batch 24/700: Discriminator loss = 1.124257206916809, GAN loss = [3.7382596, 1.4631084, 1.4460406]\n",
      "Batch 25/700: Discriminator loss = 1.0891293287277222, GAN loss = [3.6470382, 1.4242438, 1.3936926]\n",
      "Batch 26/700: Discriminator loss = 1.1305313110351562, GAN loss = [3.6512914, 1.4517674, 1.370425]\n",
      "Batch 27/700: Discriminator loss = 1.062245488166809, GAN loss = [3.7238746, 1.4628747, 1.4319077]\n",
      "Batch 28/700: Discriminator loss = 1.0771936178207397, GAN loss = [3.5714915, 1.4387288, 1.3036804]\n",
      "Batch 29/700: Discriminator loss = 1.0836281776428223, GAN loss = [3.7225945, 1.4396157, 1.4539102]\n",
      "Batch 30/700: Discriminator loss = 1.0851110219955444, GAN loss = [3.5973167, 1.4248359, 1.3434243]\n",
      "Batch 31/700: Discriminator loss = 1.0794806480407715, GAN loss = [3.6938677, 1.3991928, 1.4656317]\n",
      "Batch 32/700: Discriminator loss = 1.0819844007492065, GAN loss = [3.6282513, 1.4140375, 1.3851782]\n",
      "Batch 33/700: Discriminator loss = 1.0481443405151367, GAN loss = [3.6231892, 1.4572891, 1.336872]\n",
      "Batch 34/700: Discriminator loss = 1.0725955963134766, GAN loss = [3.7210379, 1.415289, 1.4767296]\n",
      "Batch 35/700: Discriminator loss = 1.0490328073501587, GAN loss = [3.6261964, 1.4309602, 1.3662323]\n",
      "Batch 36/700: Discriminator loss = 1.028759241104126, GAN loss = [3.8076382, 1.4459363, 1.532718]\n",
      "Batch 37/700: Discriminator loss = 1.0263813734054565, GAN loss = [3.615876, 1.4612316, 1.3256723]\n",
      "Batch 38/700: Discriminator loss = 1.0765738487243652, GAN loss = [3.5990458, 1.3973665, 1.3727268]\n",
      "Batch 39/700: Discriminator loss = 1.0628290176391602, GAN loss = [3.7312315, 1.4646068, 1.4376979]\n",
      "Batch 40/700: Discriminator loss = 1.0197217464447021, GAN loss = [3.7081683, 1.4387741, 1.4404972]\n",
      "Batch 41/700: Discriminator loss = 1.0806477069854736, GAN loss = [3.6744232, 1.4391448, 1.4064076]\n",
      "Batch 42/700: Discriminator loss = 1.0774284601211548, GAN loss = [3.6452196, 1.4234432, 1.3929394]\n",
      "Batch 43/700: Discriminator loss = 1.0815987586975098, GAN loss = [3.6490142, 1.4380264, 1.3821634]\n",
      "Batch 44/700: Discriminator loss = 1.1005922555923462, GAN loss = [3.7391193, 1.4216696, 1.4886441]\n",
      "Batch 45/700: Discriminator loss = 1.0938526391983032, GAN loss = [3.5102253, 1.4313059, 1.2501228]\n",
      "Batch 46/700: Discriminator loss = 1.0735924243927002, GAN loss = [3.660262, 1.4235996, 1.4078778]\n",
      "Batch 47/700: Discriminator loss = 1.0763399600982666, GAN loss = [3.578838, 1.4143915, 1.3356731]\n",
      "Batch 48/700: Discriminator loss = 1.0674611330032349, GAN loss = [3.569666, 1.4032909, 1.337606]\n",
      "Batch 49/700: Discriminator loss = 1.0844945907592773, GAN loss = [3.5490985, 1.4238683, 1.296463]\n",
      "Batch 50/700: Discriminator loss = 1.09588623046875, GAN loss = [3.5343373, 1.433394, 1.2721959]\n",
      "Batch 51/700: Discriminator loss = 1.1107416152954102, GAN loss = [3.4370167, 1.4009082, 1.2073725]\n",
      "Batch 52/700: Discriminator loss = 1.0901991128921509, GAN loss = [3.6396239, 1.4486182, 1.3622802]\n",
      "Batch 53/700: Discriminator loss = 1.041032075881958, GAN loss = [3.437519, 1.4048275, 1.2039822]\n",
      "Batch 54/700: Discriminator loss = 1.0957164764404297, GAN loss = [3.4703174, 1.414857, 1.22677]\n",
      "Batch 55/700: Discriminator loss = 1.0614428520202637, GAN loss = [3.6349132, 1.4310164, 1.3752358]\n",
      "Batch 56/700: Discriminator loss = 1.0567383766174316, GAN loss = [3.5876443, 1.4017906, 1.3572246]\n",
      "Batch 57/700: Discriminator loss = 1.0588059425354004, GAN loss = [3.7219915, 1.454251, 1.4391358]\n",
      "Batch 58/700: Discriminator loss = 1.039750576019287, GAN loss = [3.6164446, 1.4104676, 1.3773988]\n",
      "Batch 59/700: Discriminator loss = 1.0396461486816406, GAN loss = [3.7463884, 1.4037341, 1.514098]\n",
      "Batch 60/700: Discriminator loss = 1.0824567079544067, GAN loss = [3.7267473, 1.3902254, 1.5079836]\n",
      "Batch 61/700: Discriminator loss = 1.0936493873596191, GAN loss = [3.4794748, 1.381406, 1.269541]\n",
      "Batch 62/700: Discriminator loss = 1.0332807302474976, GAN loss = [3.7073119, 1.3754872, 1.5033096]\n",
      "Batch 63/700: Discriminator loss = 1.0671440362930298, GAN loss = [3.7384875, 1.3850812, 1.5248996]\n",
      "Batch 64/700: Discriminator loss = 1.043897032737732, GAN loss = [3.6063337, 1.4071455, 1.3706889]\n",
      "Batch 65/700: Discriminator loss = 1.0588440895080566, GAN loss = [3.6701958, 1.3928456, 1.4488574]\n",
      "Batch 66/700: Discriminator loss = 1.092629075050354, GAN loss = [3.609554, 1.3352518, 1.4458122]\n",
      "Batch 67/700: Discriminator loss = 1.0662143230438232, GAN loss = [3.5918844, 1.3504024, 1.41299]\n",
      "Batch 68/700: Discriminator loss = 1.089698314666748, GAN loss = [3.678175, 1.4231378, 1.4265448]\n",
      "Batch 69/700: Discriminator loss = 1.0421062707901, GAN loss = [3.6475463, 1.4085187, 1.4105353]\n",
      "Batch 70/700: Discriminator loss = 1.0776219367980957, GAN loss = [3.7369328, 1.3994222, 1.5090157]\n",
      "Batch 71/700: Discriminator loss = 1.0732439756393433, GAN loss = [3.627165, 1.3883448, 1.4103252]\n",
      "Batch 72/700: Discriminator loss = 1.0848088264465332, GAN loss = [3.5780065, 1.3990418, 1.3504694]\n",
      "Batch 73/700: Discriminator loss = 1.0459245443344116, GAN loss = [3.7734897, 1.4345189, 1.5104755]\n",
      "Batch 74/700: Discriminator loss = 1.023362636566162, GAN loss = [3.838438, 1.4303753, 1.5795747]\n",
      "Batch 75/700: Discriminator loss = 1.0890743732452393, GAN loss = [3.6821034, 1.420523, 1.4330993]\n",
      "Batch 76/700: Discriminator loss = 1.0612398386001587, GAN loss = [3.7355726, 1.4596345, 1.4474591]\n",
      "Batch 77/700: Discriminator loss = 1.0980722904205322, GAN loss = [3.6974568, 1.4193933, 1.4495816]\n",
      "Batch 78/700: Discriminator loss = 1.0874167680740356, GAN loss = [3.660119, 1.4174467, 1.4141912]\n",
      "Batch 79/700: Discriminator loss = 1.0754860639572144, GAN loss = [3.839577, 1.4597949, 1.5513086]\n",
      "Batch 80/700: Discriminator loss = 1.0598641633987427, GAN loss = [3.7605433, 1.4709022, 1.4611764]\n",
      "Batch 81/700: Discriminator loss = 1.0830020904541016, GAN loss = [3.591874, 1.4476304, 1.3157803]\n",
      "Batch 82/700: Discriminator loss = 1.0813952684402466, GAN loss = [3.7642813, 1.4847199, 1.451096]\n",
      "Batch 83/700: Discriminator loss = 1.0991151332855225, GAN loss = [3.5713968, 1.4224727, 1.320452]\n",
      "Batch 84/700: Discriminator loss = 1.0914828777313232, GAN loss = [3.6930525, 1.4680536, 1.3965167]\n",
      "Batch 85/700: Discriminator loss = 1.1035758256912231, GAN loss = [3.59238, 1.4538872, 1.3100017]\n",
      "Batch 86/700: Discriminator loss = 1.087300419807434, GAN loss = [3.6745582, 1.4211732, 1.4248897]\n",
      "Batch 87/700: Discriminator loss = 1.1273353099822998, GAN loss = [3.6848185, 1.5802908, 1.2760257]\n",
      "Batch 88/700: Discriminator loss = 1.1341850757598877, GAN loss = [3.5102062, 1.4040495, 1.2776467]\n",
      "Batch 89/700: Discriminator loss = 1.1782701015472412, GAN loss = [3.4598973, 1.4606148, 1.1707616]\n",
      "Batch 90/700: Discriminator loss = 1.1403650045394897, GAN loss = [3.5000098, 1.4624766, 1.2090104]\n",
      "Batch 91/700: Discriminator loss = 1.0775728225708008, GAN loss = [3.5391996, 1.4239552, 1.2867125]\n",
      "Batch 92/700: Discriminator loss = 1.0635637044906616, GAN loss = [3.6435595, 1.4405951, 1.3744266]\n",
      "Batch 93/700: Discriminator loss = 1.1428359746932983, GAN loss = [3.557148, 1.452263, 1.2763504]\n",
      "Batch 94/700: Discriminator loss = 1.1094086170196533, GAN loss = [3.723264, 1.4575711, 1.4371629]\n",
      "Batch 95/700: Discriminator loss = 1.1194607019424438, GAN loss = [3.7093608, 1.4333558, 1.4474738]\n",
      "Batch 96/700: Discriminator loss = 1.11570405960083, GAN loss = [3.7170548, 1.5130101, 1.3755149]\n",
      "Batch 97/700: Discriminator loss = 1.0971275568008423, GAN loss = [3.714078, 1.4840782, 1.4014794]\n",
      "Batch 98/700: Discriminator loss = 1.1469838619232178, GAN loss = [3.6303318, 1.4199457, 1.3818799]\n",
      "Batch 99/700: Discriminator loss = 1.1607725620269775, GAN loss = [3.665531, 1.4696028, 1.3674381]\n",
      "Batch 100/700: Discriminator loss = 1.086248517036438, GAN loss = [3.8864887, 1.4956, 1.5624236]\n",
      "Batch 101/700: Discriminator loss = 1.148034691810608, GAN loss = [3.7303076, 1.4244294, 1.4774405]\n",
      "Batch 102/700: Discriminator loss = 1.1934391260147095, GAN loss = [3.4347236, 1.397439, 1.20887]\n",
      "Batch 103/700: Discriminator loss = 1.1390622854232788, GAN loss = [3.6221726, 1.4909297, 1.3028555]\n",
      "Batch 104/700: Discriminator loss = 1.1211897134780884, GAN loss = [3.6457512, 1.4582161, 1.3591855]\n",
      "Batch 105/700: Discriminator loss = 1.1483055353164673, GAN loss = [3.5803938, 1.4509622, 1.3011266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 106/700: Discriminator loss = 1.1515320539474487, GAN loss = [3.520813, 1.4274043, 1.2651461]\n",
      "Batch 107/700: Discriminator loss = 1.141900897026062, GAN loss = [3.6722462, 1.5172504, 1.3267747]\n",
      "Batch 108/700: Discriminator loss = 1.0927854776382446, GAN loss = [3.622473, 1.4454266, 1.3488681]\n",
      "Batch 109/700: Discriminator loss = 1.1493852138519287, GAN loss = [3.4822958, 1.4013214, 1.2528391]\n",
      "Batch 110/700: Discriminator loss = 1.1409128904342651, GAN loss = [3.3951986, 1.3446939, 1.2224063]\n",
      "Batch 111/700: Discriminator loss = 1.1251641511917114, GAN loss = [3.6093967, 1.4112228, 1.3701051]\n",
      "Batch 112/700: Discriminator loss = 1.1219841241836548, GAN loss = [3.633297, 1.3900665, 1.4151944]\n",
      "Batch 113/700: Discriminator loss = 1.1155635118484497, GAN loss = [3.628944, 1.361491, 1.4394443]\n",
      "Batch 114/700: Discriminator loss = 1.0791542530059814, GAN loss = [3.6910512, 1.4067234, 1.4563468]\n",
      "Batch 115/700: Discriminator loss = 1.0405455827713013, GAN loss = [3.73544, 1.3823037, 1.525184]\n",
      "Batch 116/700: Discriminator loss = 1.0252115726470947, GAN loss = [4.1207595, 1.4586434, 1.8341953]\n",
      "Batch 117/700: Discriminator loss = 1.0254929065704346, GAN loss = [4.030485, 1.4392295, 1.763366]\n",
      "Batch 118/700: Discriminator loss = 1.0399943590164185, GAN loss = [3.8822038, 1.421437, 1.63291]\n",
      "Batch 119/700: Discriminator loss = 1.07083261013031, GAN loss = [3.809824, 1.3759722, 1.606026]\n",
      "Batch 120/700: Discriminator loss = 1.0377250909805298, GAN loss = [3.950053, 1.3883522, 1.7339015]\n",
      "Batch 121/700: Discriminator loss = 1.0263615846633911, GAN loss = [4.0289764, 1.4379331, 1.7632625]\n",
      "Batch 122/700: Discriminator loss = 1.050786018371582, GAN loss = [3.7639642, 1.422583, 1.5136203]\n",
      "Batch 123/700: Discriminator loss = 1.0440099239349365, GAN loss = [3.796422, 1.4003193, 1.5683597]\n",
      "Batch 124/700: Discriminator loss = 1.0473910570144653, GAN loss = [3.7432792, 1.3804102, 1.5351434]\n",
      "Batch 125/700: Discriminator loss = 1.0520461797714233, GAN loss = [3.65155, 1.4081095, 1.4157321]\n",
      "Batch 126/700: Discriminator loss = 1.032070517539978, GAN loss = [3.762179, 1.42451, 1.5099809]\n",
      "Batch 127/700: Discriminator loss = 1.078583836555481, GAN loss = [3.621943, 1.3948364, 1.3994423]\n",
      "Batch 128/700: Discriminator loss = 1.068533182144165, GAN loss = [3.8974369, 1.4324182, 1.6373742]\n",
      "Batch 129/700: Discriminator loss = 1.0330395698547363, GAN loss = [3.931112, 1.4163357, 1.6871634]\n",
      "Batch 130/700: Discriminator loss = 1.0431333780288696, GAN loss = [3.7319155, 1.3953186, 1.5090121]\n",
      "Batch 131/700: Discriminator loss = 1.0733054876327515, GAN loss = [3.6423562, 1.361824, 1.4529651]\n",
      "Batch 132/700: Discriminator loss = 1.0476491451263428, GAN loss = [3.847057, 1.3885618, 1.6309459]\n",
      "Batch 133/700: Discriminator loss = 1.0181645154953003, GAN loss = [3.8416321, 1.4288754, 1.5852257]\n",
      "Batch 134/700: Discriminator loss = 1.0732345581054688, GAN loss = [3.7285414, 1.3568999, 1.544128]\n",
      "Batch 135/700: Discriminator loss = 1.089695692062378, GAN loss = [3.7321339, 1.3442007, 1.5604385]\n",
      "Batch 136/700: Discriminator loss = 1.0746155977249146, GAN loss = [3.772153, 1.3463572, 1.5983231]\n",
      "Batch 137/700: Discriminator loss = 1.0367799997329712, GAN loss = [3.8894641, 1.4025214, 1.6594921]\n",
      "Batch 138/700: Discriminator loss = 1.0434755086898804, GAN loss = [3.7869716, 1.3781112, 1.5814357]\n",
      "Batch 139/700: Discriminator loss = 1.0551395416259766, GAN loss = [3.8619366, 1.3409283, 1.693602]\n",
      "Batch 140/700: Discriminator loss = 1.0172663927078247, GAN loss = [3.885558, 1.3960559, 1.6621118]\n",
      "Batch 141/700: Discriminator loss = 1.0140818357467651, GAN loss = [3.8495908, 1.3687395, 1.6534777]\n",
      "Batch 142/700: Discriminator loss = 1.0626164674758911, GAN loss = [3.7911196, 1.3557969, 1.607966]\n",
      "Batch 143/700: Discriminator loss = 1.0885870456695557, GAN loss = [3.8488002, 1.3705094, 1.6509535]\n",
      "Batch 144/700: Discriminator loss = 1.061444878578186, GAN loss = [3.7434647, 1.3690969, 1.5470519]\n",
      "Batch 145/700: Discriminator loss = 1.1807565689086914, GAN loss = [3.442269, 1.3321922, 1.2827902]\n",
      "Batch 146/700: Discriminator loss = 1.0893621444702148, GAN loss = [3.6278517, 1.3150978, 1.4854981]\n",
      "Batch 147/700: Discriminator loss = 1.0955055952072144, GAN loss = [3.687515, 1.3584123, 1.5018768]\n",
      "Batch 148/700: Discriminator loss = 1.1092252731323242, GAN loss = [3.4747462, 1.3568269, 1.2907108]\n",
      "Batch 149/700: Discriminator loss = 1.119894027709961, GAN loss = [3.5798204, 1.3285327, 1.4240983]\n",
      "Batch 150/700: Discriminator loss = 1.1167480945587158, GAN loss = [3.5301344, 1.3282646, 1.3746983]\n",
      "Batch 151/700: Discriminator loss = 1.1289674043655396, GAN loss = [3.4964504, 1.3255893, 1.3437028]\n",
      "Batch 152/700: Discriminator loss = 1.130216121673584, GAN loss = [3.5392113, 1.3662801, 1.3457856]\n",
      "Batch 153/700: Discriminator loss = 1.1459261178970337, GAN loss = [3.6052868, 1.3547003, 1.4234557]\n",
      "Batch 154/700: Discriminator loss = 1.0714131593704224, GAN loss = [3.5770712, 1.3612629, 1.3886917]\n",
      "Batch 155/700: Discriminator loss = 1.0429983139038086, GAN loss = [3.6004484, 1.4197844, 1.3535683]\n",
      "Batch 156/700: Discriminator loss = 1.1037577390670776, GAN loss = [3.4779332, 1.3390683, 1.3117936]\n",
      "Batch 157/700: Discriminator loss = 1.1037540435791016, GAN loss = [3.514871, 1.303881, 1.3839413]\n",
      "Batch 158/700: Discriminator loss = 1.1047834157943726, GAN loss = [3.5174859, 1.3132591, 1.377192]\n",
      "Batch 159/700: Discriminator loss = 1.0572118759155273, GAN loss = [3.6148028, 1.3652928, 1.4224916]\n",
      "Batch 160/700: Discriminator loss = 1.0642088651657104, GAN loss = [3.6575134, 1.3369665, 1.4935434]\n",
      "Batch 161/700: Discriminator loss = 1.069817304611206, GAN loss = [3.5595546, 1.3748637, 1.3577015]\n",
      "Batch 162/700: Discriminator loss = 1.1083322763442993, GAN loss = [3.2965624, 1.2916011, 1.1779922]\n",
      "Batch 163/700: Discriminator loss = 1.1227918863296509, GAN loss = [3.3884177, 1.3613735, 1.2001061]\n",
      "Batch 164/700: Discriminator loss = 1.052520751953125, GAN loss = [3.6022332, 1.3537925, 1.4215407]\n",
      "Batch 165/700: Discriminator loss = 1.0959006547927856, GAN loss = [3.4654677, 1.3047442, 1.3338531]\n",
      "Batch 166/700: Discriminator loss = 1.1525664329528809, GAN loss = [3.4485126, 1.3350775, 1.286591]\n",
      "Batch 167/700: Discriminator loss = 1.0599361658096313, GAN loss = [3.7845025, 1.3668337, 1.5908529]\n",
      "Batch 168/700: Discriminator loss = 1.0784049034118652, GAN loss = [3.6618867, 1.3244984, 1.5105928]\n",
      "Batch 169/700: Discriminator loss = 1.0758056640625, GAN loss = [3.6794183, 1.3501308, 1.5025146]\n",
      "Batch 170/700: Discriminator loss = 1.1483358144760132, GAN loss = [3.383737, 1.3279033, 1.229089]\n",
      "Batch 171/700: Discriminator loss = 1.084970474243164, GAN loss = [3.5477672, 1.3585935, 1.3624527]\n",
      "Batch 172/700: Discriminator loss = 1.0630555152893066, GAN loss = [3.6011183, 1.335821, 1.4385985]\n",
      "Batch 173/700: Discriminator loss = 1.1240955591201782, GAN loss = [3.5937846, 1.3493751, 1.4177263]\n",
      "Batch 174/700: Discriminator loss = 1.1339386701583862, GAN loss = [3.5461357, 1.3475512, 1.3719107]\n",
      "Batch 175/700: Discriminator loss = 1.1128044128417969, GAN loss = [3.3702974, 1.347999, 1.1956314]\n",
      "Batch 176/700: Discriminator loss = 1.1091278791427612, GAN loss = [3.580975, 1.362751, 1.3915673]\n",
      "Batch 177/700: Discriminator loss = 1.0834343433380127, GAN loss = [3.5453055, 1.3550018, 1.3636568]\n",
      "Batch 178/700: Discriminator loss = 1.1334515810012817, GAN loss = [3.385718, 1.3260492, 1.2330271]\n",
      "Batch 179/700: Discriminator loss = 1.1425265073776245, GAN loss = [3.6123216, 1.3705766, 1.4151076]\n",
      "Batch 180/700: Discriminator loss = 1.1406716108322144, GAN loss = [3.4054723, 1.3477556, 1.2310771]\n",
      "Batch 181/700: Discriminator loss = 1.1994279623031616, GAN loss = [3.4090743, 1.30893, 1.2735188]\n",
      "Batch 182/700: Discriminator loss = 1.1149158477783203, GAN loss = [3.318086, 1.288863, 1.202609]\n",
      "Batch 183/700: Discriminator loss = 1.1108641624450684, GAN loss = [3.39067, 1.3374109, 1.2266444]\n",
      "Batch 184/700: Discriminator loss = 1.2063719034194946, GAN loss = [3.376102, 1.3222278, 1.2272629]\n",
      "Batch 185/700: Discriminator loss = 1.130387783050537, GAN loss = [3.3812017, 1.2971742, 1.2574261]\n",
      "Batch 186/700: Discriminator loss = 1.1593985557556152, GAN loss = [3.283896, 1.2863312, 1.1709713]\n",
      "Batch 187/700: Discriminator loss = 1.149070143699646, GAN loss = [3.439321, 1.3769383, 1.2357898]\n",
      "Batch 188/700: Discriminator loss = 1.1796207427978516, GAN loss = [3.4471402, 1.341264, 1.279289]\n",
      "Batch 189/700: Discriminator loss = 1.1849080324172974, GAN loss = [3.2324321, 1.3032806, 1.102579]\n",
      "Batch 190/700: Discriminator loss = 1.1835354566574097, GAN loss = [3.2448444, 1.2791414, 1.1391497]\n",
      "Batch 191/700: Discriminator loss = 1.1725696325302124, GAN loss = [3.2166374, 1.3080684, 1.0820427]\n",
      "Batch 192/700: Discriminator loss = 1.155832052230835, GAN loss = [3.3991966, 1.361252, 1.211449]\n",
      "Batch 193/700: Discriminator loss = 1.107272744178772, GAN loss = [3.3226743, 1.3452828, 1.1509287]\n",
      "Batch 194/700: Discriminator loss = 1.1294877529144287, GAN loss = [3.473699, 1.3813641, 1.265903]\n",
      "Batch 195/700: Discriminator loss = 1.163525938987732, GAN loss = [3.334281, 1.3423506, 1.1655215]\n",
      "Batch 196/700: Discriminator loss = 1.1160426139831543, GAN loss = [3.3283587, 1.3476994, 1.1542696]\n",
      "Batch 197/700: Discriminator loss = 1.1631475687026978, GAN loss = [3.3592992, 1.3184638, 1.214456]\n",
      "Batch 198/700: Discriminator loss = 1.1242049932479858, GAN loss = [3.365249, 1.3606894, 1.1781912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 199/700: Discriminator loss = 1.1160131692886353, GAN loss = [3.306928, 1.3272439, 1.1533338]\n",
      "Batch 200/700: Discriminator loss = 1.1390609741210938, GAN loss = [3.202193, 1.3078208, 1.0680523]\n",
      "Batch 201/700: Discriminator loss = 1.1806546449661255, GAN loss = [3.3035285, 1.314723, 1.1625166]\n",
      "Batch 202/700: Discriminator loss = 1.1152034997940063, GAN loss = [3.4320033, 1.34352, 1.262233]\n",
      "Batch 203/700: Discriminator loss = 1.089768409729004, GAN loss = [3.2966537, 1.3250945, 1.1453505]\n",
      "Batch 204/700: Discriminator loss = 1.0978225469589233, GAN loss = [3.2958193, 1.3552787, 1.1143762]\n",
      "Batch 205/700: Discriminator loss = 1.1606985330581665, GAN loss = [3.1870358, 1.2794185, 1.0814987]\n",
      "Batch 206/700: Discriminator loss = 1.1198605298995972, GAN loss = [3.3145883, 1.2932181, 1.1953001]\n",
      "Batch 207/700: Discriminator loss = 1.1017825603485107, GAN loss = [3.3335032, 1.3197925, 1.187683]\n",
      "Batch 208/700: Discriminator loss = 1.1534591913223267, GAN loss = [3.2256563, 1.2667023, 1.1329675]\n",
      "Batch 209/700: Discriminator loss = 1.1578706502914429, GAN loss = [3.353362, 1.3413756, 1.1860362]\n",
      "Batch 210/700: Discriminator loss = 1.1050288677215576, GAN loss = [3.5115056, 1.3436984, 1.3418976]\n",
      "Batch 211/700: Discriminator loss = 1.0923186540603638, GAN loss = [3.3623238, 1.3487912, 1.1876565]\n",
      "Batch 212/700: Discriminator loss = 1.1412311792373657, GAN loss = [3.2770746, 1.3111223, 1.1401116]\n",
      "Batch 213/700: Discriminator loss = 1.0981296300888062, GAN loss = [3.3994155, 1.312023, 1.2615929]\n",
      "Batch 214/700: Discriminator loss = 1.1288049221038818, GAN loss = [3.491946, 1.3281552, 1.338031]\n",
      "Batch 215/700: Discriminator loss = 1.0833022594451904, GAN loss = [3.5031207, 1.2968124, 1.3805833]\n",
      "Batch 216/700: Discriminator loss = 1.1378625631332397, GAN loss = [3.2781422, 1.3505235, 1.1019288]\n",
      "Batch 217/700: Discriminator loss = 1.0995630025863647, GAN loss = [3.36987, 1.2946064, 1.2496109]\n",
      "Batch 218/700: Discriminator loss = 1.099923849105835, GAN loss = [3.3737855, 1.2876222, 1.2605469]\n",
      "Batch 219/700: Discriminator loss = 1.105567455291748, GAN loss = [3.351671, 1.290754, 1.2353368]\n",
      "Batch 220/700: Discriminator loss = 1.0979247093200684, GAN loss = [3.2768867, 1.2968316, 1.1545095]\n",
      "Batch 221/700: Discriminator loss = 1.1509456634521484, GAN loss = [3.260862, 1.279778, 1.1555715]\n",
      "Batch 222/700: Discriminator loss = 1.1249911785125732, GAN loss = [3.376491, 1.304794, 1.2462093]\n",
      "Batch 223/700: Discriminator loss = 1.1441081762313843, GAN loss = [3.476906, 1.3744756, 1.276964]\n",
      "Batch 224/700: Discriminator loss = 1.08902907371521, GAN loss = [3.3578053, 1.3345128, 1.1978424]\n",
      "Batch 225/700: Discriminator loss = 1.1505107879638672, GAN loss = [3.351854, 1.3451209, 1.1812974]\n",
      "Batch 226/700: Discriminator loss = 1.0987987518310547, GAN loss = [3.3971796, 1.353064, 1.2186958]\n",
      "Batch 227/700: Discriminator loss = 1.1144781112670898, GAN loss = [3.5477662, 1.3919045, 1.3304551]\n",
      "Batch 228/700: Discriminator loss = 1.127671718597412, GAN loss = [3.3856757, 1.3244846, 1.2357923]\n",
      "Batch 229/700: Discriminator loss = 1.090718150138855, GAN loss = [3.4761066, 1.3403958, 1.3103224]\n",
      "Batch 230/700: Discriminator loss = 1.1531044244766235, GAN loss = [3.3755836, 1.2837082, 1.2664962]\n",
      "Batch 231/700: Discriminator loss = 1.137478232383728, GAN loss = [3.4581985, 1.2994316, 1.3333975]\n",
      "Batch 232/700: Discriminator loss = 1.1415073871612549, GAN loss = [3.3783717, 1.3241924, 1.2288176]\n",
      "Batch 233/700: Discriminator loss = 1.1312127113342285, GAN loss = [3.3543873, 1.3079753, 1.221061]\n",
      "Batch 234/700: Discriminator loss = 1.0942671298980713, GAN loss = [3.3918436, 1.3439163, 1.2225858]\n",
      "Batch 235/700: Discriminator loss = 1.1023436784744263, GAN loss = [3.3751872, 1.3575106, 1.1923594]\n",
      "Batch 236/700: Discriminator loss = 1.1360080242156982, GAN loss = [3.405364, 1.3214569, 1.2586129]\n",
      "Batch 237/700: Discriminator loss = 1.0981310606002808, GAN loss = [3.5569859, 1.3463031, 1.3854098]\n",
      "Batch 238/700: Discriminator loss = 1.076669454574585, GAN loss = [3.6817453, 1.3536065, 1.5028832]\n",
      "Batch 239/700: Discriminator loss = 1.1426526308059692, GAN loss = [3.218521, 1.2972091, 1.0960784]\n",
      "Batch 240/700: Discriminator loss = 1.0863604545593262, GAN loss = [3.453385, 1.2801224, 1.3480529]\n",
      "Batch 241/700: Discriminator loss = 1.1304084062576294, GAN loss = [3.3632343, 1.2809504, 1.2570938]\n",
      "Batch 242/700: Discriminator loss = 1.1335418224334717, GAN loss = [3.444757, 1.2994937, 1.3200885]\n",
      "Batch 243/700: Discriminator loss = 1.113602876663208, GAN loss = [3.395992, 1.2833844, 1.287461]\n",
      "Batch 244/700: Discriminator loss = 1.079615592956543, GAN loss = [3.5223444, 1.2974901, 1.399733]\n",
      "Batch 245/700: Discriminator loss = 1.0648456811904907, GAN loss = [3.4048045, 1.3402126, 1.2394934]\n",
      "Batch 246/700: Discriminator loss = 1.1088902950286865, GAN loss = [3.3388805, 1.2865205, 1.2272825]\n",
      "Batch 247/700: Discriminator loss = 1.1080834865570068, GAN loss = [3.5267575, 1.3323381, 1.3693595]\n",
      "Batch 248/700: Discriminator loss = 1.066901683807373, GAN loss = [3.6586022, 1.3550503, 1.4785166]\n",
      "Batch 249/700: Discriminator loss = 1.1084175109863281, GAN loss = [3.7254303, 1.3332962, 1.5671248]\n",
      "Batch 250/700: Discriminator loss = 1.0922904014587402, GAN loss = [3.5368965, 1.2997246, 1.4121875]\n",
      "Batch 251/700: Discriminator loss = 1.1408143043518066, GAN loss = [3.5322204, 1.3411251, 1.3661293]\n",
      "Batch 252/700: Discriminator loss = 1.0693992376327515, GAN loss = [3.7416599, 1.3441162, 1.5725931]\n",
      "Batch 253/700: Discriminator loss = 1.1237211227416992, GAN loss = [3.439597, 1.3101331, 1.30452]\n",
      "Batch 254/700: Discriminator loss = 1.1637979745864868, GAN loss = [3.3976803, 1.3322628, 1.2404857]\n",
      "Batch 255/700: Discriminator loss = 1.064212441444397, GAN loss = [3.5609226, 1.3498143, 1.386189]\n",
      "Batch 256/700: Discriminator loss = 1.1405481100082397, GAN loss = [3.3252146, 1.2775594, 1.2227494]\n",
      "Batch 257/700: Discriminator loss = 1.128210425376892, GAN loss = [3.3504722, 1.3433744, 1.1822042]\n",
      "Batch 258/700: Discriminator loss = 1.1182639598846436, GAN loss = [3.3299227, 1.2629813, 1.2420655]\n",
      "Batch 259/700: Discriminator loss = 1.100060224533081, GAN loss = [3.5458195, 1.3554868, 1.365472]\n",
      "Batch 260/700: Discriminator loss = 1.0871975421905518, GAN loss = [3.4903786, 1.3357822, 1.3297489]\n",
      "Batch 261/700: Discriminator loss = 1.0831584930419922, GAN loss = [3.6678405, 1.3544692, 1.4885454]\n",
      "Batch 262/700: Discriminator loss = 1.0886152982711792, GAN loss = [3.3266504, 1.3179615, 1.1838889]\n",
      "Batch 263/700: Discriminator loss = 1.0635608434677124, GAN loss = [3.532655, 1.3194647, 1.3884091]\n",
      "Batch 264/700: Discriminator loss = 1.106790542602539, GAN loss = [3.4182823, 1.3077251, 1.2857944]\n",
      "Batch 265/700: Discriminator loss = 1.1054675579071045, GAN loss = [3.514207, 1.3244622, 1.3649945]\n",
      "Batch 266/700: Discriminator loss = 1.0524699687957764, GAN loss = [3.4888325, 1.3313103, 1.3327823]\n",
      "Batch 267/700: Discriminator loss = 1.1072373390197754, GAN loss = [3.4471447, 1.2864575, 1.3359554]\n",
      "Batch 268/700: Discriminator loss = 1.082222819328308, GAN loss = [3.5566614, 1.2758849, 1.4560556]\n",
      "Batch 269/700: Discriminator loss = 1.1282380819320679, GAN loss = [3.269932, 1.2428042, 1.2024175]\n",
      "Batch 270/700: Discriminator loss = 1.1038841009140015, GAN loss = [3.3769062, 1.249575, 1.3026335]\n",
      "Batch 271/700: Discriminator loss = 1.1287227869033813, GAN loss = [3.3816519, 1.2606308, 1.296333]\n",
      "Batch 272/700: Discriminator loss = 1.1389721632003784, GAN loss = [3.4101436, 1.2394203, 1.3460512]\n",
      "Batch 273/700: Discriminator loss = 1.1301970481872559, GAN loss = [3.339915, 1.2530792, 1.2621762]\n",
      "Batch 274/700: Discriminator loss = 1.1559056043624878, GAN loss = [3.2622302, 1.2729332, 1.1646463]\n",
      "Batch 275/700: Discriminator loss = 1.122841715812683, GAN loss = [3.3270433, 1.2270176, 1.2753878]\n",
      "Batch 276/700: Discriminator loss = 1.1516838073730469, GAN loss = [3.0802815, 1.1917615, 1.0638916]\n",
      "Batch 277/700: Discriminator loss = 1.1312052011489868, GAN loss = [3.2350106, 1.2503345, 1.1600604]\n",
      "Batch 278/700: Discriminator loss = 1.0964285135269165, GAN loss = [3.5206, 1.2981629, 1.3978368]\n",
      "Batch 279/700: Discriminator loss = 1.1397813558578491, GAN loss = [3.2491176, 1.1993008, 1.2252343]\n",
      "Batch 280/700: Discriminator loss = 1.1032090187072754, GAN loss = [3.271209, 1.2278848, 1.2187537]\n",
      "Batch 281/700: Discriminator loss = 1.1428569555282593, GAN loss = [3.3471315, 1.2227144, 1.2998554]\n",
      "Batch 282/700: Discriminator loss = 1.0904892683029175, GAN loss = [3.3142645, 1.2789661, 1.210743]\n",
      "Batch 283/700: Discriminator loss = 1.130699634552002, GAN loss = [3.423888, 1.2532871, 1.3460578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 284/700: Discriminator loss = 1.1357334852218628, GAN loss = [3.411025, 1.3109473, 1.275549]\n",
      "Batch 285/700: Discriminator loss = 1.0966771841049194, GAN loss = [3.3037562, 1.2480146, 1.2312297]\n",
      "Batch 286/700: Discriminator loss = 1.1293927431106567, GAN loss = [3.4691026, 1.3510447, 1.2935574]\n",
      "Batch 287/700: Discriminator loss = 1.099818468093872, GAN loss = [3.3504112, 1.2980059, 1.2279141]\n",
      "Batch 288/700: Discriminator loss = 1.1201399564743042, GAN loss = [3.4040303, 1.2994506, 1.2800992]\n",
      "Batch 289/700: Discriminator loss = 1.0580002069473267, GAN loss = [3.4546828, 1.308924, 1.3212907]\n",
      "Batch 290/700: Discriminator loss = 1.139149785041809, GAN loss = [3.4366436, 1.2771442, 1.3350409]\n",
      "Batch 291/700: Discriminator loss = 1.1433231830596924, GAN loss = [3.390177, 1.3311783, 1.2345418]\n",
      "Batch 292/700: Discriminator loss = 1.1012111902236938, GAN loss = [3.378778, 1.3159468, 1.2383714]\n",
      "Batch 293/700: Discriminator loss = 1.0763390064239502, GAN loss = [3.4553022, 1.3296759, 1.3011606]\n",
      "Batch 294/700: Discriminator loss = 1.1102876663208008, GAN loss = [3.423619, 1.3120399, 1.287108]\n",
      "Batch 295/700: Discriminator loss = 1.1685795783996582, GAN loss = [3.3414693, 1.2877563, 1.2292424]\n",
      "Batch 296/700: Discriminator loss = 1.0985612869262695, GAN loss = [3.3150089, 1.275229, 1.2153057]\n",
      "Batch 297/700: Discriminator loss = 1.1584047079086304, GAN loss = [3.2566633, 1.2561812, 1.1760144]\n",
      "Batch 298/700: Discriminator loss = 1.0789355039596558, GAN loss = [3.4593227, 1.2862096, 1.3486644]\n",
      "Batch 299/700: Discriminator loss = 1.091946005821228, GAN loss = [3.4418485, 1.3116778, 1.3057362]\n",
      "Batch 300/700: Discriminator loss = 1.1365320682525635, GAN loss = [3.3057892, 1.2719483, 1.2094165]\n",
      "Batch 301/700: Discriminator loss = 1.1281818151474, GAN loss = [3.3461251, 1.2846698, 1.237042]\n",
      "Batch 302/700: Discriminator loss = 1.0855982303619385, GAN loss = [3.401644, 1.3054582, 1.2717944]\n",
      "Batch 303/700: Discriminator loss = 1.106561541557312, GAN loss = [3.4337537, 1.2810997, 1.328283]\n",
      "Batch 304/700: Discriminator loss = 1.1069735288619995, GAN loss = [3.5494633, 1.3477092, 1.3773985]\n",
      "Batch 305/700: Discriminator loss = 1.1289042234420776, GAN loss = [3.421813, 1.3281167, 1.2693584]\n",
      "Batch 306/700: Discriminator loss = 1.1778758764266968, GAN loss = [3.315884, 1.3081441, 1.1834174]\n",
      "Batch 307/700: Discriminator loss = 1.117235779762268, GAN loss = [3.4358058, 1.2957358, 1.3157701]\n",
      "Batch 308/700: Discriminator loss = 1.1163737773895264, GAN loss = [3.2945406, 1.2950436, 1.1752168]\n",
      "Batch 309/700: Discriminator loss = 1.1174196004867554, GAN loss = [3.2484927, 1.2538894, 1.1703358]\n",
      "Batch 310/700: Discriminator loss = 1.1206669807434082, GAN loss = [3.2354038, 1.2504039, 1.1607392]\n",
      "Batch 311/700: Discriminator loss = 1.161321997642517, GAN loss = [3.327995, 1.2625738, 1.2411644]\n",
      "Batch 312/700: Discriminator loss = 1.1186307668685913, GAN loss = [3.2434454, 1.2265506, 1.192637]\n",
      "Batch 313/700: Discriminator loss = 1.1397173404693604, GAN loss = [3.2615883, 1.2149638, 1.222367]\n",
      "Batch 314/700: Discriminator loss = 1.151275873184204, GAN loss = [3.316053, 1.2265103, 1.26529]\n",
      "Batch 315/700: Discriminator loss = 1.114790439605713, GAN loss = [3.2617958, 1.2361594, 1.2013801]\n",
      "Batch 316/700: Discriminator loss = 1.157851219177246, GAN loss = [3.4073117, 1.2133489, 1.36971]\n",
      "Batch 317/700: Discriminator loss = 1.1350243091583252, GAN loss = [3.291289, 1.2626253, 1.2044083]\n",
      "Batch 318/700: Discriminator loss = 1.1017135381698608, GAN loss = [3.4429913, 1.2564887, 1.362246]\n",
      "Batch 319/700: Discriminator loss = 1.1094661951065063, GAN loss = [3.348194, 1.24445, 1.2794851]\n",
      "Batch 320/700: Discriminator loss = 1.1522884368896484, GAN loss = [3.293705, 1.2413038, 1.2281384]\n",
      "Batch 321/700: Discriminator loss = 1.1313039064407349, GAN loss = [3.2311172, 1.2282184, 1.1786336]\n",
      "Batch 322/700: Discriminator loss = 1.1419850587844849, GAN loss = [3.2787695, 1.2087848, 1.2457232]\n",
      "Batch 323/700: Discriminator loss = 1.1572037935256958, GAN loss = [3.161753, 1.2086406, 1.128851]\n",
      "Batch 324/700: Discriminator loss = 1.1138936281204224, GAN loss = [3.328029, 1.2462114, 1.25756]\n",
      "Batch 325/700: Discriminator loss = 1.1258949041366577, GAN loss = [3.3442926, 1.2325419, 1.287491]\n",
      "Batch 326/700: Discriminator loss = 1.1337617635726929, GAN loss = [3.3848832, 1.2510368, 1.3095794]\n",
      "Batch 327/700: Discriminator loss = 1.1212443113327026, GAN loss = [3.279493, 1.1982199, 1.2569969]\n",
      "Batch 328/700: Discriminator loss = 1.1200875043869019, GAN loss = [3.4376395, 1.2278008, 1.3855532]\n",
      "Batch 329/700: Discriminator loss = 1.1546282768249512, GAN loss = [2.9994066, 1.1617237, 1.0133884]\n",
      "Batch 330/700: Discriminator loss = 1.1221905946731567, GAN loss = [3.4268112, 1.2456473, 1.3568661]\n",
      "Batch 331/700: Discriminator loss = 1.1482189893722534, GAN loss = [3.2224643, 1.2446209, 1.1535443]\n",
      "Batch 332/700: Discriminator loss = 1.0822385549545288, GAN loss = [3.340808, 1.2353863, 1.2811241]\n",
      "Batch 333/700: Discriminator loss = 1.1212077140808105, GAN loss = [3.3198397, 1.2564756, 1.2390635]\n",
      "Batch 334/700: Discriminator loss = 1.0916253328323364, GAN loss = [3.4728675, 1.2577051, 1.3908715]\n",
      "Batch 335/700: Discriminator loss = 1.0708818435668945, GAN loss = [3.4302459, 1.2546932, 1.3512733]\n",
      "Batch 336/700: Discriminator loss = 1.0595937967300415, GAN loss = [3.4295704, 1.2942771, 1.3110269]\n",
      "Batch 337/700: Discriminator loss = 1.1258772611618042, GAN loss = [3.5612223, 1.2679863, 1.4689834]\n",
      "Batch 338/700: Discriminator loss = 1.1048763990402222, GAN loss = [3.3028927, 1.2570524, 1.2215947]\n",
      "Batch 339/700: Discriminator loss = 1.0949536561965942, GAN loss = [3.5135639, 1.2169697, 1.4723573]\n",
      "Batch 340/700: Discriminator loss = 1.1690973043441772, GAN loss = [3.2533224, 1.2012088, 1.2278894]\n",
      "Batch 341/700: Discriminator loss = 1.1263985633850098, GAN loss = [3.3682175, 1.2069137, 1.3370938]\n",
      "Batch 342/700: Discriminator loss = 1.151482343673706, GAN loss = [3.3687198, 1.2272844, 1.3172389]\n",
      "Batch 343/700: Discriminator loss = 1.1578978300094604, GAN loss = [3.3120193, 1.1811659, 1.306668]\n",
      "Batch 344/700: Discriminator loss = 1.1420797109603882, GAN loss = [3.3836486, 1.2006508, 1.3588207]\n",
      "Batch 345/700: Discriminator loss = 1.1354645490646362, GAN loss = [3.4862466, 1.253105, 1.4089683]\n",
      "Batch 346/700: Discriminator loss = 1.1101245880126953, GAN loss = [3.3604498, 1.2507362, 1.2855523]\n",
      "Batch 347/700: Discriminator loss = 1.1301053762435913, GAN loss = [3.3203604, 1.2534077, 1.2428064]\n",
      "Batch 348/700: Discriminator loss = 1.06890070438385, GAN loss = [3.4708276, 1.3097169, 1.3369813]\n",
      "Batch 349/700: Discriminator loss = 1.1026980876922607, GAN loss = [3.346966, 1.2658921, 1.2569628]\n",
      "Batch 350/700: Discriminator loss = 1.147134780883789, GAN loss = [3.2381399, 1.2493601, 1.1646937]\n",
      "Batch 351/700: Discriminator loss = 1.085274577140808, GAN loss = [3.4457562, 1.2917923, 1.3298935]\n",
      "Batch 352/700: Discriminator loss = 1.1255223751068115, GAN loss = [3.3000052, 1.2632782, 1.2126725]\n",
      "Batch 353/700: Discriminator loss = 1.1227129697799683, GAN loss = [3.3765314, 1.2301066, 1.3223825]\n",
      "Batch 354/700: Discriminator loss = 1.0881394147872925, GAN loss = [3.4499445, 1.2678956, 1.3580133]\n",
      "Batch 355/700: Discriminator loss = 1.127953290939331, GAN loss = [3.254773, 1.2574433, 1.1733007]\n",
      "Batch 356/700: Discriminator loss = 1.1229084730148315, GAN loss = [3.3773637, 1.2495639, 1.3037872]\n",
      "Batch 357/700: Discriminator loss = 1.1543108224868774, GAN loss = [3.3785794, 1.2555757, 1.2990094]\n",
      "Batch 358/700: Discriminator loss = 1.10405695438385, GAN loss = [3.2567308, 1.2448192, 1.1879462]\n",
      "Batch 359/700: Discriminator loss = 1.1205917596817017, GAN loss = [3.3448112, 1.2332318, 1.2876462]\n",
      "Batch 360/700: Discriminator loss = 1.1593804359436035, GAN loss = [3.0969548, 1.172015, 1.1010364]\n",
      "Batch 361/700: Discriminator loss = 1.189994215965271, GAN loss = [3.182494, 1.1970884, 1.1615299]\n",
      "Batch 362/700: Discriminator loss = 1.1460055112838745, GAN loss = [3.3086774, 1.2398168, 1.2450124]\n",
      "Batch 363/700: Discriminator loss = 1.0962976217269897, GAN loss = [3.302082, 1.2108791, 1.2673796]\n",
      "Batch 364/700: Discriminator loss = 1.1038638353347778, GAN loss = [3.3101923, 1.2479973, 1.2383931]\n",
      "Batch 365/700: Discriminator loss = 1.1027463674545288, GAN loss = [3.3378913, 1.2371362, 1.2769705]\n",
      "Batch 366/700: Discriminator loss = 1.1278767585754395, GAN loss = [3.3193371, 1.225098, 1.270467]\n",
      "Batch 367/700: Discriminator loss = 1.1176183223724365, GAN loss = [3.352751, 1.2355303, 1.2934642]\n",
      "Batch 368/700: Discriminator loss = 1.1364011764526367, GAN loss = [3.4323199, 1.2504963, 1.3580798]\n",
      "Batch 369/700: Discriminator loss = 1.0813542604446411, GAN loss = [3.3794272, 1.2366879, 1.3190143]\n",
      "Batch 370/700: Discriminator loss = 1.1225824356079102, GAN loss = [3.3492737, 1.2112303, 1.3143361]\n",
      "Batch 371/700: Discriminator loss = 1.1416507959365845, GAN loss = [3.426848, 1.1930684, 1.4100858]\n",
      "Batch 372/700: Discriminator loss = 1.1180530786514282, GAN loss = [3.4449704, 1.2061741, 1.4151206]\n",
      "Batch 373/700: Discriminator loss = 1.1014982461929321, GAN loss = [3.07427, 1.1742015, 1.0764078]\n",
      "Batch 374/700: Discriminator loss = 1.1587704420089722, GAN loss = [3.240371, 1.1814784, 1.2352538]\n",
      "Batch 375/700: Discriminator loss = 1.0856989622116089, GAN loss = [3.6121318, 1.2715538, 1.5169556]\n",
      "Batch 376/700: Discriminator loss = 1.098174810409546, GAN loss = [3.5423033, 1.2393866, 1.4793134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 377/700: Discriminator loss = 1.1180330514907837, GAN loss = [3.3550692, 1.2182918, 1.3131887]\n",
      "Batch 378/700: Discriminator loss = 1.0801236629486084, GAN loss = [3.3877254, 1.2517303, 1.3124281]\n",
      "Batch 379/700: Discriminator loss = 1.1278430223464966, GAN loss = [3.3661423, 1.2016934, 1.3409097]\n",
      "Batch 380/700: Discriminator loss = 1.1192278861999512, GAN loss = [3.2485528, 1.1861211, 1.238912]\n",
      "Batch 381/700: Discriminator loss = 1.1405082941055298, GAN loss = [3.2726703, 1.1983461, 1.2508167]\n",
      "Batch 382/700: Discriminator loss = 1.1119356155395508, GAN loss = [3.3696742, 1.2222724, 1.3239108]\n",
      "Batch 383/700: Discriminator loss = 1.13640296459198, GAN loss = [3.3451009, 1.232173, 1.2894521]\n",
      "Batch 384/700: Discriminator loss = 1.187447190284729, GAN loss = [3.1647644, 1.2166967, 1.1246003]\n",
      "Batch 385/700: Discriminator loss = 1.1298913955688477, GAN loss = [3.3222973, 1.2081391, 1.2907028]\n",
      "Batch 386/700: Discriminator loss = 1.147247314453125, GAN loss = [3.3042815, 1.2265466, 1.2542844]\n",
      "Batch 387/700: Discriminator loss = 1.1092888116836548, GAN loss = [3.4163642, 1.2548416, 1.3380809]\n",
      "Batch 388/700: Discriminator loss = 1.1383867263793945, GAN loss = [3.304724, 1.2143351, 1.2669638]\n",
      "Batch 389/700: Discriminator loss = 1.0750573873519897, GAN loss = [3.401346, 1.2564669, 1.3214706]\n",
      "Batch 390/700: Discriminator loss = 1.1280277967453003, GAN loss = [3.271699, 1.2501034, 1.1982044]\n",
      "Batch 391/700: Discriminator loss = 1.0845524072647095, GAN loss = [3.4124923, 1.2309756, 1.3581358]\n",
      "Batch 392/700: Discriminator loss = 1.1104705333709717, GAN loss = [3.2177956, 1.2443721, 1.1500561]\n",
      "Batch 393/700: Discriminator loss = 1.1412785053253174, GAN loss = [3.1826146, 1.1883117, 1.1709511]\n",
      "Batch 394/700: Discriminator loss = 1.0550804138183594, GAN loss = [3.4260175, 1.2699639, 1.3327159]\n",
      "Batch 395/700: Discriminator loss = 1.1624348163604736, GAN loss = [3.2799253, 1.267023, 1.1895772]\n",
      "Batch 396/700: Discriminator loss = 1.1662957668304443, GAN loss = [3.2121813, 1.2098061, 1.1790568]\n",
      "Batch 397/700: Discriminator loss = 1.1059995889663696, GAN loss = [3.338102, 1.253519, 1.2612659]\n",
      "Batch 398/700: Discriminator loss = 1.1041107177734375, GAN loss = [3.4168031, 1.2668041, 1.3266917]\n",
      "Batch 399/700: Discriminator loss = 1.0886610746383667, GAN loss = [3.3310373, 1.2591957, 1.2485497]\n",
      "Batch 400/700: Discriminator loss = 1.1049597263336182, GAN loss = [3.2442768, 1.2220808, 1.1989145]\n",
      "Batch 401/700: Discriminator loss = 1.142113208770752, GAN loss = [3.2494566, 1.2827787, 1.143406]\n",
      "Batch 402/700: Discriminator loss = 1.1162075996398926, GAN loss = [3.3845944, 1.2594472, 1.3018887]\n",
      "Batch 403/700: Discriminator loss = 1.1084626913070679, GAN loss = [3.3473892, 1.2459476, 1.2781924]\n",
      "Batch 404/700: Discriminator loss = 1.16118586063385, GAN loss = [3.321747, 1.2561393, 1.2423661]\n",
      "Batch 405/700: Discriminator loss = 1.1277756690979004, GAN loss = [3.3150191, 1.2008349, 1.290955]\n",
      "Batch 406/700: Discriminator loss = 1.2269878387451172, GAN loss = [3.1357415, 1.2010354, 1.1114854]\n",
      "Batch 407/700: Discriminator loss = 1.1512658596038818, GAN loss = [3.3216114, 1.2308068, 1.2675878]\n",
      "Batch 408/700: Discriminator loss = 1.17805016040802, GAN loss = [3.1945934, 1.229074, 1.1423151]\n",
      "Batch 409/700: Discriminator loss = 1.1737126111984253, GAN loss = [3.1825497, 1.2315146, 1.1278415]\n",
      "Batch 410/700: Discriminator loss = 1.142441749572754, GAN loss = [3.4291458, 1.27, 1.3359666]\n",
      "Batch 411/700: Discriminator loss = 1.1015806198120117, GAN loss = [3.3939552, 1.3161033, 1.2546936]\n",
      "Batch 412/700: Discriminator loss = 1.1781487464904785, GAN loss = [3.2256787, 1.2527043, 1.1498432]\n",
      "Batch 413/700: Discriminator loss = 1.15426504611969, GAN loss = [3.201744, 1.2515438, 1.1270921]\n",
      "Batch 414/700: Discriminator loss = 1.145229697227478, GAN loss = [3.264257, 1.3103021, 1.1308722]\n",
      "Batch 415/700: Discriminator loss = 1.1780160665512085, GAN loss = [3.1711097, 1.2578325, 1.0902299]\n",
      "Batch 416/700: Discriminator loss = 1.1218260526657104, GAN loss = [3.2916012, 1.2658576, 1.2027335]\n",
      "Batch 417/700: Discriminator loss = 1.12859308719635, GAN loss = [3.2918525, 1.262763, 1.2061095]\n",
      "Batch 418/700: Discriminator loss = 1.099898099899292, GAN loss = [3.4067492, 1.3104498, 1.2733531]\n",
      "Batch 419/700: Discriminator loss = 1.146531581878662, GAN loss = [3.23735, 1.2420743, 1.1723655]\n",
      "Batch 420/700: Discriminator loss = 1.1180535554885864, GAN loss = [3.337697, 1.3046832, 1.210138]\n",
      "Batch 421/700: Discriminator loss = 1.0939472913742065, GAN loss = [3.2804556, 1.246634, 1.2109795]\n",
      "Batch 422/700: Discriminator loss = 1.090289831161499, GAN loss = [3.4030268, 1.2750665, 1.3051573]\n",
      "Batch 423/700: Discriminator loss = 1.1169679164886475, GAN loss = [3.271576, 1.244144, 1.2046726]\n",
      "Batch 424/700: Discriminator loss = 1.0809345245361328, GAN loss = [3.377595, 1.2383602, 1.3165131]\n",
      "Batch 425/700: Discriminator loss = 1.1258795261383057, GAN loss = [3.4688306, 1.2516867, 1.3944546]\n",
      "Batch 426/700: Discriminator loss = 1.1008455753326416, GAN loss = [3.3892066, 1.2306014, 1.3359478]\n",
      "Batch 427/700: Discriminator loss = 1.1010568141937256, GAN loss = [3.414332, 1.2612582, 1.3304505]\n",
      "Batch 428/700: Discriminator loss = 1.0682331323623657, GAN loss = [3.4447916, 1.2766362, 1.3455697]\n",
      "Batch 429/700: Discriminator loss = 1.1013418436050415, GAN loss = [3.4706573, 1.2468314, 1.4012773]\n",
      "Batch 430/700: Discriminator loss = 1.0326541662216187, GAN loss = [3.6426318, 1.324798, 1.4953189]\n",
      "Batch 431/700: Discriminator loss = 1.071651577949524, GAN loss = [3.3834116, 1.2694842, 1.2914401]\n",
      "Batch 432/700: Discriminator loss = 1.0888164043426514, GAN loss = [3.435068, 1.2639908, 1.3486181]\n",
      "Batch 433/700: Discriminator loss = 1.1062017679214478, GAN loss = [3.4356883, 1.2600666, 1.3531926]\n",
      "Batch 434/700: Discriminator loss = 1.0896961688995361, GAN loss = [3.4539814, 1.3023541, 1.3292233]\n",
      "Batch 435/700: Discriminator loss = 1.059922695159912, GAN loss = [3.559588, 1.3107965, 1.4264092]\n",
      "Batch 436/700: Discriminator loss = 1.1109167337417603, GAN loss = [3.358369, 1.3031787, 1.2328309]\n",
      "Batch 437/700: Discriminator loss = 1.0949724912643433, GAN loss = [3.4752948, 1.3100842, 1.3428721]\n",
      "Batch 438/700: Discriminator loss = 1.1030747890472412, GAN loss = [3.3852177, 1.2707924, 1.2921002]\n",
      "Batch 439/700: Discriminator loss = 1.0906106233596802, GAN loss = [3.4154577, 1.3195908, 1.2735646]\n",
      "Batch 440/700: Discriminator loss = 1.0766263008117676, GAN loss = [3.2937253, 1.2853279, 1.1861129]\n",
      "Batch 441/700: Discriminator loss = 1.0824031829833984, GAN loss = [3.365292, 1.3305691, 1.2124559]\n",
      "Batch 442/700: Discriminator loss = 1.0861505270004272, GAN loss = [3.3675354, 1.3124063, 1.2328823]\n",
      "Batch 443/700: Discriminator loss = 1.092411994934082, GAN loss = [3.371027, 1.3140799, 1.2347255]\n",
      "Batch 444/700: Discriminator loss = 1.1073123216629028, GAN loss = [3.1687987, 1.2362988, 1.1103035]\n",
      "Batch 445/700: Discriminator loss = 1.136234998703003, GAN loss = [3.3334846, 1.3385887, 1.172722]\n",
      "Batch 446/700: Discriminator loss = 1.0809400081634521, GAN loss = [3.3122869, 1.3271265, 1.163023]\n",
      "Batch 447/700: Discriminator loss = 1.0900722742080688, GAN loss = [3.2624, 1.3020854, 1.1382109]\n",
      "Batch 448/700: Discriminator loss = 1.0963349342346191, GAN loss = [3.264953, 1.2693924, 1.1734893]\n",
      "Batch 449/700: Discriminator loss = 1.1083306074142456, GAN loss = [3.3807094, 1.2947905, 1.263875]\n",
      "Batch 450/700: Discriminator loss = 1.120136022567749, GAN loss = [3.2921631, 1.2608898, 1.2092685]\n",
      "Batch 451/700: Discriminator loss = 1.1109436750411987, GAN loss = [3.381937, 1.2613541, 1.298609]\n",
      "Batch 452/700: Discriminator loss = 1.095359206199646, GAN loss = [3.3357422, 1.2425691, 1.2712275]\n",
      "Batch 453/700: Discriminator loss = 1.082623839378357, GAN loss = [3.411889, 1.2510144, 1.3389633]\n",
      "Batch 454/700: Discriminator loss = 1.0978643894195557, GAN loss = [3.2427442, 1.2139709, 1.2068948]\n",
      "Batch 455/700: Discriminator loss = 1.0743759870529175, GAN loss = [3.3974636, 1.2411687, 1.334439]\n",
      "Batch 456/700: Discriminator loss = 1.1465215682983398, GAN loss = [3.2902727, 1.1833113, 1.2851274]\n",
      "Batch 457/700: Discriminator loss = 1.0867373943328857, GAN loss = [3.3836243, 1.2167095, 1.345106]\n",
      "Batch 458/700: Discriminator loss = 1.116537094116211, GAN loss = [3.3958077, 1.2332847, 1.3407385]\n",
      "Batch 459/700: Discriminator loss = 1.1105886697769165, GAN loss = [3.2251673, 1.1928933, 1.2105218]\n",
      "Batch 460/700: Discriminator loss = 1.1071664094924927, GAN loss = [3.3388746, 1.2499633, 1.2671902]\n",
      "Batch 461/700: Discriminator loss = 1.1288836002349854, GAN loss = [3.2056792, 1.1806827, 1.2033007]\n",
      "Batch 462/700: Discriminator loss = 1.146114468574524, GAN loss = [3.195923, 1.175466, 1.1987863]\n",
      "Batch 463/700: Discriminator loss = 1.1494332551956177, GAN loss = [3.242598, 1.1685253, 1.2524227]\n",
      "Batch 464/700: Discriminator loss = 1.1061091423034668, GAN loss = [3.2825375, 1.1937326, 1.2671828]\n",
      "Batch 465/700: Discriminator loss = 1.1111639738082886, GAN loss = [3.2213602, 1.1531396, 1.246624]\n",
      "Batch 466/700: Discriminator loss = 1.1226325035095215, GAN loss = [3.1096768, 1.1813053, 1.1067965]\n",
      "Batch 467/700: Discriminator loss = 1.147732138633728, GAN loss = [3.3264878, 1.1866715, 1.3182683]\n",
      "Batch 468/700: Discriminator loss = 1.1211762428283691, GAN loss = [3.2600052, 1.1843897, 1.2540967]\n",
      "Batch 469/700: Discriminator loss = 1.0858700275421143, GAN loss = [3.3144457, 1.1998289, 1.293129]\n",
      "Batch 470/700: Discriminator loss = 1.0983599424362183, GAN loss = [3.2385342, 1.1896245, 1.2274523]\n",
      "Batch 471/700: Discriminator loss = 1.0654069185256958, GAN loss = [3.4845374, 1.2502483, 1.4128556]\n",
      "Batch 472/700: Discriminator loss = 1.097390055656433, GAN loss = [3.451916, 1.2054876, 1.425022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 473/700: Discriminator loss = 1.06889009475708, GAN loss = [3.5008366, 1.2454283, 1.4340279]\n",
      "Batch 474/700: Discriminator loss = 1.117424726486206, GAN loss = [3.4165003, 1.2212712, 1.37388]\n",
      "Batch 475/700: Discriminator loss = 1.0851008892059326, GAN loss = [3.3456855, 1.2420331, 1.2823377]\n",
      "Batch 476/700: Discriminator loss = 1.0804086923599243, GAN loss = [3.5457554, 1.2985501, 1.4259094]\n",
      "Batch 477/700: Discriminator loss = 1.0906403064727783, GAN loss = [3.5436275, 1.2506938, 1.4716599]\n",
      "Batch 478/700: Discriminator loss = 1.124155879020691, GAN loss = [3.504719, 1.2101004, 1.473367]\n",
      "Batch 479/700: Discriminator loss = 1.078704595565796, GAN loss = [3.444108, 1.2463536, 1.376522]\n",
      "Batch 480/700: Discriminator loss = 1.0732946395874023, GAN loss = [3.447558, 1.2463317, 1.3800101]\n",
      "Batch 481/700: Discriminator loss = 1.1741334199905396, GAN loss = [3.3312886, 1.2151603, 1.294928]\n",
      "Batch 482/700: Discriminator loss = 1.1105446815490723, GAN loss = [3.468924, 1.2813392, 1.3663977]\n",
      "Batch 483/700: Discriminator loss = 1.1854887008666992, GAN loss = [3.2419865, 1.2374073, 1.1834059]\n",
      "Batch 484/700: Discriminator loss = 1.156908631324768, GAN loss = [3.2568448, 1.2596878, 1.1759932]\n",
      "Batch 485/700: Discriminator loss = 1.0758030414581299, GAN loss = [3.49314, 1.3112645, 1.3607249]\n",
      "Batch 486/700: Discriminator loss = 1.100610613822937, GAN loss = [3.4273343, 1.3012959, 1.3048956]\n",
      "Batch 487/700: Discriminator loss = 1.0867913961410522, GAN loss = [3.2720222, 1.262394, 1.188504]\n",
      "Batch 488/700: Discriminator loss = 1.1177622079849243, GAN loss = [3.3392863, 1.2420024, 1.276181]\n",
      "Batch 489/700: Discriminator loss = 1.1070246696472168, GAN loss = [3.4681973, 1.2874032, 1.359704]\n",
      "Batch 490/700: Discriminator loss = 1.0903396606445312, GAN loss = [3.4202, 1.2521392, 1.3469772]\n",
      "Batch 491/700: Discriminator loss = 1.1013025045394897, GAN loss = [3.306124, 1.268922, 1.2161232]\n",
      "Batch 492/700: Discriminator loss = 1.1283478736877441, GAN loss = [3.3294277, 1.2881018, 1.2202574]\n",
      "Batch 493/700: Discriminator loss = 1.0928598642349243, GAN loss = [3.4252253, 1.2881008, 1.3160601]\n",
      "Batch 494/700: Discriminator loss = 1.09467351436615, GAN loss = [3.456444, 1.2527268, 1.3826658]\n",
      "Batch 495/700: Discriminator loss = 1.0943446159362793, GAN loss = [3.533827, 1.3172951, 1.395496]\n",
      "Batch 496/700: Discriminator loss = 1.100227952003479, GAN loss = [3.366732, 1.2925491, 1.2531585]\n",
      "Batch 497/700: Discriminator loss = 1.0646522045135498, GAN loss = [3.427566, 1.2728992, 1.3336539]\n",
      "Batch 498/700: Discriminator loss = 1.0756820440292358, GAN loss = [3.5205016, 1.3096585, 1.3898445]\n",
      "Batch 499/700: Discriminator loss = 1.1412168741226196, GAN loss = [3.239448, 1.2608241, 1.1576395]\n",
      "Batch 500/700: Discriminator loss = 1.1021684408187866, GAN loss = [3.4487398, 1.2553164, 1.37245]\n",
      "Batch 501/700: Discriminator loss = 1.1121188402175903, GAN loss = [3.5334218, 1.2867302, 1.4257373]\n",
      "Batch 502/700: Discriminator loss = 1.120968222618103, GAN loss = [3.4187274, 1.2307335, 1.3670584]\n",
      "Batch 503/700: Discriminator loss = 1.117396354675293, GAN loss = [3.4008982, 1.2781948, 1.3017845]\n",
      "Batch 504/700: Discriminator loss = 1.0880900621414185, GAN loss = [3.6778035, 1.3465732, 1.5103253]\n",
      "Batch 505/700: Discriminator loss = 1.0912749767303467, GAN loss = [3.546187, 1.3628492, 1.362452]\n",
      "Batch 506/700: Discriminator loss = 1.108356237411499, GAN loss = [3.3381097, 1.2621528, 1.2550855]\n",
      "Batch 507/700: Discriminator loss = 1.1077674627304077, GAN loss = [3.515271, 1.342592, 1.3518136]\n",
      "Batch 508/700: Discriminator loss = 1.1187480688095093, GAN loss = [3.5381193, 1.3314434, 1.385814]\n",
      "Batch 509/700: Discriminator loss = 1.1909990310668945, GAN loss = [3.1430893, 1.2356372, 1.0865957]\n",
      "Batch 510/700: Discriminator loss = 1.122554898262024, GAN loss = [3.371317, 1.2816505, 1.2688092]\n",
      "Batch 511/700: Discriminator loss = 1.1177690029144287, GAN loss = [3.4401991, 1.3488258, 1.2705203]\n",
      "Batch 512/700: Discriminator loss = 1.0754094123840332, GAN loss = [3.4515758, 1.314573, 1.3161486]\n",
      "Batch 513/700: Discriminator loss = 1.1592419147491455, GAN loss = [3.2812684, 1.2676256, 1.1927965]\n",
      "Batch 514/700: Discriminator loss = 1.1776930093765259, GAN loss = [3.1956139, 1.257223, 1.117547]\n",
      "Batch 515/700: Discriminator loss = 1.1538163423538208, GAN loss = [3.3505588, 1.2863688, 1.2433566]\n",
      "Batch 516/700: Discriminator loss = 1.1081570386886597, GAN loss = [3.3018162, 1.2498534, 1.2311358]\n",
      "Batch 517/700: Discriminator loss = 1.1382030248641968, GAN loss = [3.154558, 1.1993625, 1.1343739]\n",
      "Batch 518/700: Discriminator loss = 1.1613532304763794, GAN loss = [3.2210104, 1.241189, 1.1590029]\n",
      "Batch 519/700: Discriminator loss = 1.0990043878555298, GAN loss = [3.5113592, 1.2754354, 1.4151049]\n",
      "Batch 520/700: Discriminator loss = 1.1341850757598877, GAN loss = [3.2785242, 1.2829634, 1.1747308]\n",
      "Batch 521/700: Discriminator loss = 1.1717439889907837, GAN loss = [3.1608005, 1.2253985, 1.1145667]\n",
      "Batch 522/700: Discriminator loss = 1.1327096223831177, GAN loss = [3.233292, 1.2455848, 1.1668738]\n",
      "Batch 523/700: Discriminator loss = 1.1375173330307007, GAN loss = [3.230807, 1.2499106, 1.1600628]\n",
      "Batch 524/700: Discriminator loss = 1.1597118377685547, GAN loss = [3.2107787, 1.2375926, 1.1523585]\n",
      "Batch 525/700: Discriminator loss = 1.1868988275527954, GAN loss = [3.2261755, 1.284988, 1.1203669]\n",
      "Batch 526/700: Discriminator loss = 1.1151221990585327, GAN loss = [3.3025458, 1.258871, 1.2228744]\n",
      "Batch 527/700: Discriminator loss = 1.1360284090042114, GAN loss = [3.2425003, 1.2152562, 1.2064604]\n",
      "Batch 528/700: Discriminator loss = 1.1320620775222778, GAN loss = [3.3472786, 1.232296, 1.2942122]\n",
      "Batch 529/700: Discriminator loss = 1.2045003175735474, GAN loss = [3.1200285, 1.1900493, 1.1092227]\n",
      "Batch 530/700: Discriminator loss = 1.1917086839675903, GAN loss = [3.1053388, 1.192558, 1.0920398]\n",
      "Batch 531/700: Discriminator loss = 1.16976797580719, GAN loss = [3.1332324, 1.199184, 1.1133299]\n",
      "Batch 532/700: Discriminator loss = 1.1721450090408325, GAN loss = [3.329208, 1.2342771, 1.2742314]\n",
      "Batch 533/700: Discriminator loss = 1.1335759162902832, GAN loss = [3.1994905, 1.2418263, 1.1369796]\n",
      "Batch 534/700: Discriminator loss = 1.0937916040420532, GAN loss = [3.2414541, 1.2684927, 1.1522987]\n",
      "Batch 535/700: Discriminator loss = 1.1292780637741089, GAN loss = [3.2192981, 1.2505543, 1.1481041]\n",
      "Batch 536/700: Discriminator loss = 1.1650267839431763, GAN loss = [3.1032875, 1.2070715, 1.0756061]\n",
      "Batch 537/700: Discriminator loss = 1.083450198173523, GAN loss = [3.331528, 1.2767247, 1.2342236]\n",
      "Batch 538/700: Discriminator loss = 1.1557117700576782, GAN loss = [3.2649646, 1.21772, 1.226696]\n",
      "Batch 539/700: Discriminator loss = 1.10639226436615, GAN loss = [3.2327814, 1.2326787, 1.1795831]\n",
      "Batch 540/700: Discriminator loss = 1.1032824516296387, GAN loss = [3.2766554, 1.2314008, 1.2247598]\n",
      "Batch 541/700: Discriminator loss = 1.138106107711792, GAN loss = [3.295026, 1.2175518, 1.2570103]\n",
      "Batch 542/700: Discriminator loss = 1.175917387008667, GAN loss = [3.295823, 1.1529588, 1.3224384]\n",
      "Batch 543/700: Discriminator loss = 1.1567953824996948, GAN loss = [3.2829213, 1.1969019, 1.2656262]\n",
      "Batch 544/700: Discriminator loss = 1.1286091804504395, GAN loss = [3.3311813, 1.2063268, 1.3044962]\n",
      "Batch 545/700: Discriminator loss = 1.220078468322754, GAN loss = [3.220633, 1.1940148, 1.2062837]\n",
      "Batch 546/700: Discriminator loss = 1.1390936374664307, GAN loss = [3.24862, 1.2029688, 1.2253419]\n",
      "Batch 547/700: Discriminator loss = 1.1719807386398315, GAN loss = [3.2404807, 1.1850582, 1.2351329]\n",
      "Batch 548/700: Discriminator loss = 1.1687220335006714, GAN loss = [3.2615116, 1.2553837, 1.1858616]\n",
      "Batch 549/700: Discriminator loss = 1.1558912992477417, GAN loss = [3.2608812, 1.2042233, 1.236419]\n",
      "Batch 550/700: Discriminator loss = 1.1379344463348389, GAN loss = [3.3748899, 1.2184278, 1.3362385]\n",
      "Batch 551/700: Discriminator loss = 1.1897079944610596, GAN loss = [3.2333112, 1.2057897, 1.207311]\n",
      "Batch 552/700: Discriminator loss = 1.158368468284607, GAN loss = [3.297413, 1.292536, 1.1846806]\n",
      "Batch 553/700: Discriminator loss = 1.1116713285446167, GAN loss = [3.447221, 1.2822902, 1.3447474]\n",
      "Batch 554/700: Discriminator loss = 1.1416434049606323, GAN loss = [3.3546991, 1.2234588, 1.3110689]\n",
      "Batch 555/700: Discriminator loss = 1.2061750888824463, GAN loss = [3.247155, 1.1947838, 1.2322171]\n",
      "Batch 556/700: Discriminator loss = 1.191373348236084, GAN loss = [3.2221315, 1.2088845, 1.1931118]\n",
      "Batch 557/700: Discriminator loss = 1.1484490633010864, GAN loss = [3.2564752, 1.2658505, 1.1705092]\n",
      "Batch 558/700: Discriminator loss = 1.1194720268249512, GAN loss = [3.3355715, 1.2222315, 1.2932496]\n",
      "Batch 559/700: Discriminator loss = 1.1254243850708008, GAN loss = [3.275304, 1.1996946, 1.2555369]\n",
      "Batch 560/700: Discriminator loss = 1.0986329317092896, GAN loss = [3.3234184, 1.2500733, 1.2532895]\n",
      "Batch 561/700: Discriminator loss = 1.085389494895935, GAN loss = [3.471999, 1.2463554, 1.4056106]\n",
      "Batch 562/700: Discriminator loss = 1.1652523279190063, GAN loss = [3.2808118, 1.2393438, 1.2214533]\n",
      "Batch 563/700: Discriminator loss = 1.100001573562622, GAN loss = [3.377401, 1.2398747, 1.3175244]\n",
      "Batch 564/700: Discriminator loss = 1.1060608625411987, GAN loss = [3.2434273, 1.2482381, 1.1752005]\n",
      "Batch 565/700: Discriminator loss = 1.12287437915802, GAN loss = [3.356318, 1.222611, 1.3137391]\n",
      "Batch 566/700: Discriminator loss = 1.1164486408233643, GAN loss = [3.2699404, 1.223309, 1.226686]\n",
      "Batch 567/700: Discriminator loss = 1.161547303199768, GAN loss = [3.3974946, 1.2749796, 1.3025955]\n",
      "Batch 568/700: Discriminator loss = 1.0811717510223389, GAN loss = [3.386145, 1.2542819, 1.3119704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 569/700: Discriminator loss = 1.113609790802002, GAN loss = [3.3353908, 1.21712, 1.2984041]\n",
      "Batch 570/700: Discriminator loss = 1.1687977313995361, GAN loss = [3.2038949, 1.205305, 1.1787391]\n",
      "Batch 571/700: Discriminator loss = 1.1963059902191162, GAN loss = [3.0002186, 1.1624436, 1.0179439]\n",
      "Batch 572/700: Discriminator loss = 1.1516073942184448, GAN loss = [3.165476, 1.1915729, 1.1540942]\n",
      "Batch 573/700: Discriminator loss = 1.1266387701034546, GAN loss = [3.3266554, 1.2125201, 1.2943496]\n",
      "Batch 574/700: Discriminator loss = 1.1807525157928467, GAN loss = [3.196038, 1.1916293, 1.1846513]\n",
      "Batch 575/700: Discriminator loss = 1.1528774499893188, GAN loss = [3.3141513, 1.2528039, 1.241611]\n",
      "Batch 576/700: Discriminator loss = 1.1620402336120605, GAN loss = [3.3193095, 1.2557303, 1.243862]\n",
      "Batch 577/700: Discriminator loss = 1.1581767797470093, GAN loss = [3.146233, 1.2006254, 1.1259178]\n",
      "Batch 578/700: Discriminator loss = 1.1541244983673096, GAN loss = [3.1307225, 1.2013528, 1.1097027]\n",
      "Batch 579/700: Discriminator loss = 1.165820837020874, GAN loss = [3.2602553, 1.1806767, 1.2599312]\n",
      "Batch 580/700: Discriminator loss = 1.1724889278411865, GAN loss = [3.1639283, 1.1768831, 1.1674198]\n",
      "Batch 581/700: Discriminator loss = 1.1270475387573242, GAN loss = [3.3002486, 1.1929533, 1.287686]\n",
      "Batch 582/700: Discriminator loss = 1.2137187719345093, GAN loss = [3.188282, 1.1778641, 1.190831]\n",
      "Batch 583/700: Discriminator loss = 1.2028725147247314, GAN loss = [2.9896522, 1.1575515, 1.012539]\n",
      "Batch 584/700: Discriminator loss = 1.168542742729187, GAN loss = [3.1622694, 1.2026284, 1.1400945]\n",
      "Batch 585/700: Discriminator loss = 1.1515778303146362, GAN loss = [3.1798337, 1.2117553, 1.1485488]\n",
      "Batch 586/700: Discriminator loss = 1.147823691368103, GAN loss = [3.2094905, 1.2004536, 1.1895242]\n",
      "Batch 587/700: Discriminator loss = 1.189512014389038, GAN loss = [3.0932193, 1.1662878, 1.1074351]\n",
      "Batch 588/700: Discriminator loss = 1.1409475803375244, GAN loss = [3.2023015, 1.2112266, 1.1715983]\n",
      "Batch 589/700: Discriminator loss = 1.1600288152694702, GAN loss = [3.1127176, 1.207277, 1.085983]\n",
      "Batch 590/700: Discriminator loss = 1.1041905879974365, GAN loss = [3.2557132, 1.2478268, 1.1884519]\n",
      "Batch 591/700: Discriminator loss = 1.1804133653640747, GAN loss = [3.0161798, 1.1573472, 1.0394182]\n",
      "Batch 592/700: Discriminator loss = 1.1875063180923462, GAN loss = [3.160621, 1.1987692, 1.142459]\n",
      "Batch 593/700: Discriminator loss = 1.1667922735214233, GAN loss = [3.1482, 1.1601921, 1.1686403]\n",
      "Batch 594/700: Discriminator loss = 1.141708254814148, GAN loss = [3.2003565, 1.1653763, 1.2156267]\n",
      "Batch 595/700: Discriminator loss = 1.186066746711731, GAN loss = [3.1019638, 1.137251, 1.1453763]\n",
      "Batch 596/700: Discriminator loss = 1.1845879554748535, GAN loss = [3.106693, 1.1160882, 1.1712779]\n",
      "Batch 597/700: Discriminator loss = 1.2025405168533325, GAN loss = [2.867449, 1.0856919, 0.9624331]\n",
      "Batch 598/700: Discriminator loss = 1.1519702672958374, GAN loss = [3.1043715, 1.1371776, 1.1478777]\n",
      "Batch 599/700: Discriminator loss = 1.1754610538482666, GAN loss = [3.1037612, 1.1267914, 1.1576654]\n",
      "Batch 600/700: Discriminator loss = 1.1899031400680542, GAN loss = [3.133065, 1.098634, 1.2151322]\n",
      "Batch 601/700: Discriminator loss = 1.1524344682693481, GAN loss = [3.0713165, 1.1251721, 1.1268536]\n",
      "Batch 602/700: Discriminator loss = 1.1762473583221436, GAN loss = [3.097912, 1.1219165, 1.1567131]\n",
      "Batch 603/700: Discriminator loss = 1.1855523586273193, GAN loss = [2.997177, 1.1088169, 1.0690876]\n",
      "Batch 604/700: Discriminator loss = 1.1712281703948975, GAN loss = [3.0401022, 1.1177075, 1.1031244]\n",
      "Batch 605/700: Discriminator loss = 1.1655820608139038, GAN loss = [3.110854, 1.1240948, 1.1674874]\n",
      "Batch 606/700: Discriminator loss = 1.1946954727172852, GAN loss = [3.0690372, 1.1286707, 1.1210896]\n",
      "Batch 607/700: Discriminator loss = 1.1578667163848877, GAN loss = [3.0354137, 1.1251303, 1.0910039]\n",
      "Batch 608/700: Discriminator loss = 1.197136640548706, GAN loss = [2.9971392, 1.120938, 1.0569328]\n",
      "Batch 609/700: Discriminator loss = 1.1986726522445679, GAN loss = [3.1091473, 1.1353383, 1.1545589]\n",
      "Batch 610/700: Discriminator loss = 1.1766576766967773, GAN loss = [3.1253555, 1.1287069, 1.1774161]\n",
      "Batch 611/700: Discriminator loss = 1.1391775608062744, GAN loss = [3.1283598, 1.1571577, 1.1519848]\n",
      "Batch 612/700: Discriminator loss = 1.1848409175872803, GAN loss = [3.0217128, 1.1336784, 1.0688304]\n",
      "Batch 613/700: Discriminator loss = 1.1695431470870972, GAN loss = [3.041863, 1.1223705, 1.100298]\n",
      "Batch 614/700: Discriminator loss = 1.2156888246536255, GAN loss = [2.9994867, 1.1099455, 1.0703521]\n",
      "Batch 615/700: Discriminator loss = 1.1685311794281006, GAN loss = [2.9777977, 1.1094434, 1.0491704]\n",
      "Batch 616/700: Discriminator loss = 1.1613953113555908, GAN loss = [3.141976, 1.1497426, 1.1730536]\n",
      "Batch 617/700: Discriminator loss = 1.1298694610595703, GAN loss = [3.186333, 1.178945, 1.1882164]\n",
      "Batch 618/700: Discriminator loss = 1.1836856603622437, GAN loss = [2.9852827, 1.1288218, 1.0372919]\n",
      "Batch 619/700: Discriminator loss = 1.1667582988739014, GAN loss = [3.0161576, 1.1509935, 1.046011]\n",
      "Batch 620/700: Discriminator loss = 1.1665806770324707, GAN loss = [3.1205857, 1.1632495, 1.1381935]\n",
      "Batch 621/700: Discriminator loss = 1.162909984588623, GAN loss = [2.9963977, 1.1503117, 1.0269618]\n",
      "Batch 622/700: Discriminator loss = 1.1552735567092896, GAN loss = [3.0638447, 1.1531736, 1.0915627]\n",
      "Batch 623/700: Discriminator loss = 1.1643774509429932, GAN loss = [3.1352801, 1.1995935, 1.1165969]\n",
      "Batch 624/700: Discriminator loss = 1.1389821767807007, GAN loss = [3.0907516, 1.1717733, 1.0999117]\n",
      "Batch 625/700: Discriminator loss = 1.1784684658050537, GAN loss = [3.0264964, 1.1259394, 1.0815055]\n",
      "Batch 626/700: Discriminator loss = 1.1819955110549927, GAN loss = [3.0365493, 1.123143, 1.0943654]\n",
      "Batch 627/700: Discriminator loss = 1.1552984714508057, GAN loss = [2.990458, 1.1129999, 1.0584179]\n",
      "Batch 628/700: Discriminator loss = 1.1448661088943481, GAN loss = [3.1412523, 1.1556275, 1.1665859]\n",
      "Batch 629/700: Discriminator loss = 1.1295409202575684, GAN loss = [3.2957978, 1.1852999, 1.2914727]\n",
      "Batch 630/700: Discriminator loss = 1.171049952507019, GAN loss = [3.223337, 1.1904476, 1.213882]\n",
      "Batch 631/700: Discriminator loss = 1.1060503721237183, GAN loss = [3.154787, 1.1692117, 1.1665864]\n",
      "Batch 632/700: Discriminator loss = 1.0971901416778564, GAN loss = [3.2476034, 1.1787506, 1.2498865]\n",
      "Batch 633/700: Discriminator loss = 1.161653757095337, GAN loss = [3.1189551, 1.1765763, 1.1234291]\n",
      "Batch 634/700: Discriminator loss = 1.1380902528762817, GAN loss = [3.227956, 1.1836824, 1.2253385]\n",
      "Batch 635/700: Discriminator loss = 1.2259362936019897, GAN loss = [3.024191, 1.093092, 1.1121842]\n",
      "Batch 636/700: Discriminator loss = 1.1876018047332764, GAN loss = [3.0614343, 1.1333219, 1.1092157]\n",
      "Batch 637/700: Discriminator loss = 1.177201509475708, GAN loss = [3.0380278, 1.1187364, 1.1004139]\n",
      "Batch 638/700: Discriminator loss = 1.1619316339492798, GAN loss = [3.0488496, 1.1321262, 1.0978616]\n",
      "Batch 639/700: Discriminator loss = 1.1453968286514282, GAN loss = [3.1324804, 1.1736416, 1.1399965]\n",
      "Batch 640/700: Discriminator loss = 1.1978543996810913, GAN loss = [3.1094768, 1.1374115, 1.1532463]\n",
      "Batch 641/700: Discriminator loss = 1.1409600973129272, GAN loss = [3.0512514, 1.1596655, 1.07279]\n",
      "Batch 642/700: Discriminator loss = 1.1665810346603394, GAN loss = [3.0821671, 1.1096671, 1.1537286]\n",
      "Batch 643/700: Discriminator loss = 1.1701953411102295, GAN loss = [3.0245898, 1.1377357, 1.0681039]\n",
      "Batch 644/700: Discriminator loss = 1.1058807373046875, GAN loss = [3.1582417, 1.1777594, 1.1617582]\n",
      "Batch 645/700: Discriminator loss = 1.1357885599136353, GAN loss = [3.1626644, 1.1389775, 1.2049949]\n",
      "Batch 646/700: Discriminator loss = 1.1806230545043945, GAN loss = [3.0700822, 1.1034193, 1.147994]\n",
      "Batch 647/700: Discriminator loss = 1.1168452501296997, GAN loss = [3.2569072, 1.144984, 1.2932782]\n",
      "Batch 648/700: Discriminator loss = 1.1472705602645874, GAN loss = [3.245914, 1.209447, 1.2178521]\n",
      "Batch 649/700: Discriminator loss = 1.1257067918777466, GAN loss = [3.1649845, 1.1744341, 1.1719661]\n",
      "Batch 650/700: Discriminator loss = 1.1513190269470215, GAN loss = [3.1860723, 1.1675816, 1.1999371]\n",
      "Batch 651/700: Discriminator loss = 1.1901366710662842, GAN loss = [3.0150573, 1.1270496, 1.0694838]\n",
      "Batch 652/700: Discriminator loss = 1.1643763780593872, GAN loss = [3.1329033, 1.1324995, 1.1819106]\n",
      "Batch 653/700: Discriminator loss = 1.1390576362609863, GAN loss = [3.1128573, 1.1202401, 1.1741577]\n",
      "Batch 654/700: Discriminator loss = 1.2114598751068115, GAN loss = [3.0629754, 1.1169428, 1.1276019]\n",
      "Batch 655/700: Discriminator loss = 1.1956030130386353, GAN loss = [3.1033397, 1.162228, 1.1226904]\n",
      "Batch 656/700: Discriminator loss = 1.1789138317108154, GAN loss = [3.0600383, 1.1600809, 1.0815516]\n",
      "Batch 657/700: Discriminator loss = 1.187881350517273, GAN loss = [3.0349245, 1.1182718, 1.0982624]\n",
      "Batch 658/700: Discriminator loss = 1.1969168186187744, GAN loss = [3.0413184, 1.1251538, 1.0977933]\n",
      "Batch 659/700: Discriminator loss = 1.2085405588150024, GAN loss = [3.0207887, 1.1070769, 1.0953573]\n",
      "Batch 660/700: Discriminator loss = 1.1819708347320557, GAN loss = [3.1357687, 1.1301173, 1.1873088]\n",
      "Batch 661/700: Discriminator loss = 1.211651086807251, GAN loss = [2.9636512, 1.0959917, 1.0493362]\n",
      "Batch 662/700: Discriminator loss = 1.2389519214630127, GAN loss = [2.9527247, 1.0977305, 1.0366945]\n",
      "Batch 663/700: Discriminator loss = 1.1934016942977905, GAN loss = [3.0705938, 1.1590482, 1.0932701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 664/700: Discriminator loss = 1.2388200759887695, GAN loss = [3.1017923, 1.1705054, 1.11303]\n",
      "Batch 665/700: Discriminator loss = 1.2037112712860107, GAN loss = [2.9777482, 1.1105069, 1.0490162]\n",
      "Batch 666/700: Discriminator loss = 1.1674073934555054, GAN loss = [3.0495017, 1.1362458, 1.0950541]\n",
      "Batch 667/700: Discriminator loss = 1.2133671045303345, GAN loss = [2.9851048, 1.1007389, 1.0661925]\n",
      "Batch 668/700: Discriminator loss = 1.1981050968170166, GAN loss = [2.9552555, 1.099088, 1.0380195]\n",
      "Batch 669/700: Discriminator loss = 1.2246978282928467, GAN loss = [2.9146185, 1.109021, 0.98747605]\n",
      "Batch 670/700: Discriminator loss = 1.2149944305419922, GAN loss = [2.8625026, 1.0652404, 0.97917014]\n",
      "Batch 671/700: Discriminator loss = 1.1621947288513184, GAN loss = [2.951532, 1.0773121, 1.0561535]\n",
      "Batch 672/700: Discriminator loss = 1.2731000185012817, GAN loss = [2.7857256, 1.0384742, 0.92921656]\n",
      "Batch 673/700: Discriminator loss = 1.2209669351577759, GAN loss = [3.0065362, 1.0666497, 1.1218879]\n",
      "Batch 674/700: Discriminator loss = 1.2009351253509521, GAN loss = [3.0174122, 1.1220691, 1.0773821]\n",
      "Batch 675/700: Discriminator loss = 1.1397556066513062, GAN loss = [3.1207554, 1.1066045, 1.1962247]\n",
      "Batch 676/700: Discriminator loss = 1.2064012289047241, GAN loss = [2.8912044, 1.0418928, 1.0314144]\n",
      "Batch 677/700: Discriminator loss = 1.2133456468582153, GAN loss = [3.0003178, 1.0830587, 1.0993831]\n",
      "Batch 678/700: Discriminator loss = 1.1927456855773926, GAN loss = [2.9748626, 1.0596373, 1.0973699]\n",
      "Batch 679/700: Discriminator loss = 1.1376593112945557, GAN loss = [2.9726624, 1.0923293, 1.0624955]\n",
      "Batch 680/700: Discriminator loss = 1.1848949193954468, GAN loss = [2.9310923, 1.0241706, 1.0891095]\n",
      "Batch 681/700: Discriminator loss = 1.1840014457702637, GAN loss = [2.9547527, 1.0388256, 1.0981362]\n",
      "Batch 682/700: Discriminator loss = 1.1054824590682983, GAN loss = [3.1145902, 1.1167808, 1.1800388]\n",
      "Batch 683/700: Discriminator loss = 1.2085018157958984, GAN loss = [2.8738067, 1.0548729, 1.0011879]\n",
      "Batch 684/700: Discriminator loss = 1.200605034828186, GAN loss = [2.8433466, 1.0651932, 0.9604408]\n",
      "Batch 685/700: Discriminator loss = 1.1586133241653442, GAN loss = [2.9636106, 1.0758439, 1.0700903]\n",
      "Batch 686/700: Discriminator loss = 1.167486548423767, GAN loss = [2.9417498, 1.0666043, 1.0575058]\n",
      "Batch 687/700: Discriminator loss = 1.177010416984558, GAN loss = [3.0177338, 1.0497862, 1.1503388]\n",
      "Batch 688/700: Discriminator loss = 1.1556737422943115, GAN loss = [3.0478551, 1.0951036, 1.1351727]\n",
      "Batch 689/700: Discriminator loss = 1.1633315086364746, GAN loss = [2.8585396, 1.0456073, 0.99538785]\n",
      "Batch 690/700: Discriminator loss = 1.1513617038726807, GAN loss = [3.1124594, 1.0899899, 1.2049487]\n",
      "Batch 691/700: Discriminator loss = 1.1666995286941528, GAN loss = [3.0664482, 1.1094571, 1.1394941]\n",
      "Batch 692/700: Discriminator loss = 1.1345568895339966, GAN loss = [3.048794, 1.1439347, 1.0873915]\n",
      "Batch 693/700: Discriminator loss = 1.19716477394104, GAN loss = [2.9785542, 1.0691975, 1.0919194]\n",
      "Batch 694/700: Discriminator loss = 1.1494425535202026, GAN loss = [3.0915644, 1.104, 1.1701638]\n",
      "Batch 695/700: Discriminator loss = 1.1406751871109009, GAN loss = [2.9983604, 1.0916524, 1.0893378]\n",
      "Batch 696/700: Discriminator loss = 1.222497820854187, GAN loss = [2.9005532, 1.0400482, 1.0431637]\n",
      "Batch 697/700: Discriminator loss = 1.141831398010254, GAN loss = [3.0356078, 1.0750257, 1.1432701]\n",
      "Batch 698/700: Discriminator loss = 1.1752821207046509, GAN loss = [2.802649, 1.0593051, 0.9260561]\n",
      "Batch 699/700: Discriminator loss = 1.1851308345794678, GAN loss = [2.9555793, 1.0623094, 1.0760099]\n",
      "Batch 700/700: Discriminator loss = 1.1662209033966064, GAN loss = [3.0651903, 1.0602694, 1.1876838]\n",
      "Epoch 8/30\n",
      "Batch 1/700: Discriminator loss = 1.1258519887924194, GAN loss = [3.0283952, 1.0804516, 1.1307319]\n",
      "Batch 2/700: Discriminator loss = 1.2152342796325684, GAN loss = [2.9976842, 1.0908101, 1.089684]\n",
      "Batch 3/700: Discriminator loss = 1.1928551197052002, GAN loss = [2.9257705, 1.0613719, 1.0472356]\n",
      "Batch 4/700: Discriminator loss = 1.1645268201828003, GAN loss = [3.024282, 1.091426, 1.1157241]\n",
      "Batch 5/700: Discriminator loss = 1.1147111654281616, GAN loss = [3.2062345, 1.1390296, 1.2501048]\n",
      "Batch 6/700: Discriminator loss = 1.154822826385498, GAN loss = [3.06822, 1.0864553, 1.1646955]\n",
      "Batch 7/700: Discriminator loss = 1.1315569877624512, GAN loss = [3.0224779, 1.0647146, 1.1407202]\n",
      "Batch 8/700: Discriminator loss = 1.1511460542678833, GAN loss = [2.8989382, 1.0456221, 1.0362995]\n",
      "Batch 9/700: Discriminator loss = 1.1692538261413574, GAN loss = [3.022229, 1.0580277, 1.1472088]\n",
      "Batch 10/700: Discriminator loss = 1.1670780181884766, GAN loss = [2.9614916, 1.0607654, 1.083754]\n",
      "Batch 11/700: Discriminator loss = 1.1683515310287476, GAN loss = [2.957464, 1.0248834, 1.1156389]\n",
      "Batch 12/700: Discriminator loss = 1.1706868410110474, GAN loss = [2.9368255, 1.0352567, 1.0846546]\n",
      "Batch 13/700: Discriminator loss = 1.1558418273925781, GAN loss = [3.0295143, 1.0619057, 1.1507204]\n",
      "Batch 14/700: Discriminator loss = 1.2067421674728394, GAN loss = [3.1111248, 1.0467067, 1.2475612]\n",
      "Batch 15/700: Discriminator loss = 1.1283879280090332, GAN loss = [3.2069032, 1.0833278, 1.3067443]\n",
      "Batch 16/700: Discriminator loss = 1.146358847618103, GAN loss = [2.909115, 1.0354495, 1.0568724]\n",
      "Batch 17/700: Discriminator loss = 1.1445945501327515, GAN loss = [2.9143653, 1.0437795, 1.0538268]\n",
      "Batch 18/700: Discriminator loss = 1.1727734804153442, GAN loss = [2.9863033, 1.0216739, 1.1478993]\n",
      "Batch 19/700: Discriminator loss = 1.1500879526138306, GAN loss = [3.0519001, 1.0429457, 1.192242]\n",
      "Batch 20/700: Discriminator loss = 1.1793615818023682, GAN loss = [2.9907298, 1.0163652, 1.1576757]\n",
      "Batch 21/700: Discriminator loss = 1.12516188621521, GAN loss = [3.0417907, 1.0565329, 1.1685907]\n",
      "Batch 22/700: Discriminator loss = 1.1635743379592896, GAN loss = [2.9760134, 1.0445436, 1.1148223]\n",
      "Batch 23/700: Discriminator loss = 1.1473504304885864, GAN loss = [3.0026288, 1.0545522, 1.1314573]\n",
      "Batch 24/700: Discriminator loss = 1.1578487157821655, GAN loss = [2.8271654, 1.0462468, 0.96432555]\n",
      "Batch 25/700: Discriminator loss = 1.1499359607696533, GAN loss = [2.971027, 1.0474201, 1.1070454]\n",
      "Batch 26/700: Discriminator loss = 1.1515367031097412, GAN loss = [3.060667, 1.0783888, 1.16575]\n",
      "Batch 27/700: Discriminator loss = 1.1540981531143188, GAN loss = [3.0080621, 1.0402882, 1.1512773]\n",
      "Batch 28/700: Discriminator loss = 1.140071153640747, GAN loss = [2.9534607, 1.0316839, 1.1053097]\n",
      "Batch 29/700: Discriminator loss = 1.152733564376831, GAN loss = [2.985434, 1.0489584, 1.1200336]\n",
      "Batch 30/700: Discriminator loss = 1.1329635381698608, GAN loss = [3.0230517, 1.0624346, 1.1441985]\n",
      "Batch 31/700: Discriminator loss = 1.1680576801300049, GAN loss = [2.9283164, 1.0292646, 1.0826603]\n",
      "Batch 32/700: Discriminator loss = 1.1665195226669312, GAN loss = [2.9527771, 1.018481, 1.1179312]\n",
      "Batch 33/700: Discriminator loss = 1.1492432355880737, GAN loss = [3.0028155, 1.0306414, 1.1558294]\n",
      "Batch 34/700: Discriminator loss = 1.1685994863510132, GAN loss = [2.9775455, 1.0265849, 1.1346341]\n",
      "Batch 35/700: Discriminator loss = 1.153001070022583, GAN loss = [2.986565, 1.0496799, 1.1205719]\n",
      "Batch 36/700: Discriminator loss = 1.1697463989257812, GAN loss = [2.9618657, 1.0444773, 1.1010891]\n",
      "Batch 37/700: Discriminator loss = 1.1576406955718994, GAN loss = [3.0142756, 1.0495572, 1.1484357]\n",
      "Batch 38/700: Discriminator loss = 1.1626096963882446, GAN loss = [2.9923637, 1.030091, 1.1460114]\n",
      "Batch 39/700: Discriminator loss = 1.172342300415039, GAN loss = [2.91121, 1.0121195, 1.0828531]\n",
      "Batch 40/700: Discriminator loss = 1.1778218746185303, GAN loss = [2.925287, 1.0214049, 1.0876616]\n",
      "Batch 41/700: Discriminator loss = 1.1985416412353516, GAN loss = [2.8777153, 1.0122377, 1.0492727]\n",
      "Batch 42/700: Discriminator loss = 1.1917673349380493, GAN loss = [2.8876839, 1.0187244, 1.0527686]\n",
      "Batch 43/700: Discriminator loss = 1.1647920608520508, GAN loss = [2.969336, 1.0180019, 1.1351546]\n",
      "Batch 44/700: Discriminator loss = 1.1898547410964966, GAN loss = [2.881158, 0.9988991, 1.0660892]\n",
      "Batch 45/700: Discriminator loss = 1.2112876176834106, GAN loss = [2.9581673, 0.9867717, 1.1552382]\n",
      "Batch 46/700: Discriminator loss = 1.1677337884902954, GAN loss = [2.8690546, 1.0061663, 1.0467399]\n",
      "Batch 47/700: Discriminator loss = 1.159826397895813, GAN loss = [2.8802924, 1.0054772, 1.0586743]\n",
      "Batch 48/700: Discriminator loss = 1.232082724571228, GAN loss = [2.7763765, 0.95967376, 1.000572]\n",
      "Batch 49/700: Discriminator loss = 1.2196824550628662, GAN loss = [2.8649228, 0.9711728, 1.0776289]\n",
      "Batch 50/700: Discriminator loss = 1.2017430067062378, GAN loss = [2.8438923, 0.9781557, 1.0496213]\n",
      "Batch 51/700: Discriminator loss = 1.2389190196990967, GAN loss = [2.9117303, 0.9618138, 1.1338078]\n",
      "Batch 52/700: Discriminator loss = 1.176920771598816, GAN loss = [2.807265, 0.99132025, 0.99984527]\n",
      "Batch 53/700: Discriminator loss = 1.1960654258728027, GAN loss = [2.9096038, 1.0041375, 1.0893815]\n",
      "Batch 54/700: Discriminator loss = 1.204606056213379, GAN loss = [2.9497237, 1.0067335, 1.1269199]\n",
      "Batch 55/700: Discriminator loss = 1.2155426740646362, GAN loss = [2.8307111, 0.96834666, 1.0463048]\n",
      "Batch 56/700: Discriminator loss = 1.1908081769943237, GAN loss = [2.9922884, 1.0433478, 1.1328915]\n",
      "Batch 57/700: Discriminator loss = 1.196358323097229, GAN loss = [2.8860424, 1.050587, 1.0194265]\n",
      "Batch 58/700: Discriminator loss = 1.211966633796692, GAN loss = [2.8173177, 1.0314407, 0.96987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 59/700: Discriminator loss = 1.180130124092102, GAN loss = [2.9470437, 1.0296623, 1.1014003]\n",
      "Batch 60/700: Discriminator loss = 1.1647543907165527, GAN loss = [2.871548, 1.0108442, 1.0447456]\n",
      "Batch 61/700: Discriminator loss = 1.1725800037384033, GAN loss = [2.836163, 1.066118, 0.9541056]\n",
      "Batch 62/700: Discriminator loss = 1.17819082736969, GAN loss = [2.843505, 1.0254455, 1.0021479]\n",
      "Batch 63/700: Discriminator loss = 1.137519359588623, GAN loss = [3.02449, 1.1013542, 1.1072531]\n",
      "Batch 64/700: Discriminator loss = 1.1526700258255005, GAN loss = [3.043256, 1.0227968, 1.2045994]\n",
      "Batch 65/700: Discriminator loss = 1.196285605430603, GAN loss = [2.930111, 1.0480654, 1.0662029]\n",
      "Batch 66/700: Discriminator loss = 1.1279133558273315, GAN loss = [2.9889052, 1.0950246, 1.0780517]\n",
      "Batch 67/700: Discriminator loss = 1.144879698753357, GAN loss = [3.0189683, 1.0856613, 1.1174934]\n",
      "Batch 68/700: Discriminator loss = 1.1532789468765259, GAN loss = [2.9703395, 1.1279023, 1.0266445]\n",
      "Batch 69/700: Discriminator loss = 1.120680332183838, GAN loss = [3.0122116, 1.0917472, 1.1046916]\n",
      "Batch 70/700: Discriminator loss = 1.1131305694580078, GAN loss = [3.10326, 1.1267523, 1.1607534]\n",
      "Batch 71/700: Discriminator loss = 1.1265110969543457, GAN loss = [3.097814, 1.1098238, 1.1722641]\n",
      "Batch 72/700: Discriminator loss = 1.1455626487731934, GAN loss = [3.0304377, 1.138158, 1.076584]\n",
      "Batch 73/700: Discriminator loss = 1.1446956396102905, GAN loss = [2.9894686, 1.0929441, 1.0808693]\n",
      "Batch 74/700: Discriminator loss = 1.1244782209396362, GAN loss = [3.0035963, 1.1425854, 1.0453967]\n",
      "Batch 75/700: Discriminator loss = 1.149578332901001, GAN loss = [3.0289123, 1.0882556, 1.1250788]\n",
      "Batch 76/700: Discriminator loss = 1.1372729539871216, GAN loss = [2.9373572, 1.0579637, 1.063847]\n",
      "Batch 77/700: Discriminator loss = 1.1359845399856567, GAN loss = [3.0292706, 1.077966, 1.1357942]\n",
      "Batch 78/700: Discriminator loss = 1.1319841146469116, GAN loss = [3.1102135, 1.122079, 1.1726683]\n",
      "Batch 79/700: Discriminator loss = 1.1770884990692139, GAN loss = [2.9575815, 1.063934, 1.0782179]\n",
      "Batch 80/700: Discriminator loss = 1.1658319234848022, GAN loss = [2.9601347, 1.0606415, 1.0840993]\n",
      "Batch 81/700: Discriminator loss = 1.1586006879806519, GAN loss = [2.9225187, 1.0940766, 1.0130802]\n",
      "Batch 82/700: Discriminator loss = 1.1800005435943604, GAN loss = [2.9538522, 1.0488797, 1.0896459]\n",
      "Batch 83/700: Discriminator loss = 1.1876846551895142, GAN loss = [2.7960312, 1.0566121, 0.92412573]\n",
      "Batch 84/700: Discriminator loss = 1.1611788272857666, GAN loss = [2.95084, 1.0894679, 1.0461166]\n",
      "Batch 85/700: Discriminator loss = 1.1658536195755005, GAN loss = [2.7769322, 1.04439, 0.91732466]\n",
      "Batch 86/700: Discriminator loss = 1.1655712127685547, GAN loss = [2.9255621, 1.0733149, 1.0370625]\n",
      "Batch 87/700: Discriminator loss = 1.162616491317749, GAN loss = [2.9306037, 1.0541544, 1.0613075]\n",
      "Batch 88/700: Discriminator loss = 1.1208858489990234, GAN loss = [2.9777818, 1.0944822, 1.0681944]\n",
      "Batch 89/700: Discriminator loss = 1.1758733987808228, GAN loss = [2.9474096, 1.0722119, 1.0601181]\n",
      "Batch 90/700: Discriminator loss = 1.2079143524169922, GAN loss = [2.7574952, 1.0264237, 0.9160161]\n",
      "Batch 91/700: Discriminator loss = 1.1687897443771362, GAN loss = [2.9531782, 1.0847638, 1.053389]\n",
      "Batch 92/700: Discriminator loss = 1.1881508827209473, GAN loss = [2.9062498, 1.0435883, 1.0476671]\n",
      "Batch 93/700: Discriminator loss = 1.1638295650482178, GAN loss = [2.8746657, 1.0472442, 1.0124543]\n",
      "Batch 94/700: Discriminator loss = 1.2064690589904785, GAN loss = [2.8097544, 1.015041, 0.97977155]\n",
      "Batch 95/700: Discriminator loss = 1.2119598388671875, GAN loss = [2.8440833, 1.0448117, 0.98435074]\n",
      "Batch 96/700: Discriminator loss = 1.1615482568740845, GAN loss = [2.8166702, 1.0377256, 0.9640539]\n",
      "Batch 97/700: Discriminator loss = 1.2097241878509521, GAN loss = [2.7938006, 1.0033436, 0.97559416]\n",
      "Batch 98/700: Discriminator loss = 1.1612184047698975, GAN loss = [2.8798683, 1.0480468, 1.0169843]\n",
      "Batch 99/700: Discriminator loss = 1.2176976203918457, GAN loss = [2.7903752, 0.9843409, 0.991224]\n",
      "Batch 100/700: Discriminator loss = 1.187196969985962, GAN loss = [2.8169487, 1.0161095, 0.9860586]\n",
      "Batch 101/700: Discriminator loss = 1.1427395343780518, GAN loss = [2.859256, 1.0585513, 0.9859505]\n",
      "Batch 102/700: Discriminator loss = 1.1882843971252441, GAN loss = [2.8084695, 1.0152407, 0.9784984]\n",
      "Batch 103/700: Discriminator loss = 1.1761510372161865, GAN loss = [2.7816172, 1.0017127, 0.96521074]\n",
      "Batch 104/700: Discriminator loss = 1.1782550811767578, GAN loss = [2.8136783, 1.023211, 0.9758082]\n",
      "Batch 105/700: Discriminator loss = 1.168662428855896, GAN loss = [2.8557382, 1.0151397, 1.0259777]\n",
      "Batch 106/700: Discriminator loss = 1.2103240489959717, GAN loss = [2.790705, 1.0115143, 0.9646089]\n",
      "Batch 107/700: Discriminator loss = 1.1835612058639526, GAN loss = [2.822106, 1.0235388, 0.984021]\n",
      "Batch 108/700: Discriminator loss = 1.1891274452209473, GAN loss = [2.8186913, 0.9936611, 1.0105157]\n",
      "Batch 109/700: Discriminator loss = 1.1791855096817017, GAN loss = [2.7884917, 0.9990621, 0.9749503]\n",
      "Batch 110/700: Discriminator loss = 1.1847566366195679, GAN loss = [2.802905, 1.0132775, 0.9751766]\n",
      "Batch 111/700: Discriminator loss = 1.1991820335388184, GAN loss = [2.8275383, 0.99420893, 1.0189109]\n",
      "Batch 112/700: Discriminator loss = 1.1411571502685547, GAN loss = [2.8088226, 1.0382777, 0.9561617]\n",
      "Batch 113/700: Discriminator loss = 1.1539195775985718, GAN loss = [2.9445777, 1.0691508, 1.0610797]\n",
      "Batch 114/700: Discriminator loss = 1.161855936050415, GAN loss = [2.8323994, 1.019594, 0.9984938]\n",
      "Batch 115/700: Discriminator loss = 1.2228935956954956, GAN loss = [2.8445263, 1.0002233, 1.0300298]\n",
      "Batch 116/700: Discriminator loss = 1.1558375358581543, GAN loss = [2.7945573, 1.0163921, 0.9639293]\n",
      "Batch 117/700: Discriminator loss = 1.1736078262329102, GAN loss = [2.8351278, 1.0221123, 0.9988121]\n",
      "Batch 118/700: Discriminator loss = 1.1880707740783691, GAN loss = [2.8385718, 1.0439792, 0.9804195]\n",
      "Batch 119/700: Discriminator loss = 1.1786439418792725, GAN loss = [2.8058858, 0.99634206, 0.9954009]\n",
      "Batch 120/700: Discriminator loss = 1.1582852602005005, GAN loss = [2.8558373, 1.040805, 1.0009214]\n",
      "Batch 121/700: Discriminator loss = 1.1384400129318237, GAN loss = [2.8570023, 1.0404874, 1.0024364]\n",
      "Batch 122/700: Discriminator loss = 1.1630747318267822, GAN loss = [2.8443835, 1.0265422, 1.0037944]\n",
      "Batch 123/700: Discriminator loss = 1.1471989154815674, GAN loss = [2.89164, 1.0326215, 1.0449996]\n",
      "Batch 124/700: Discriminator loss = 1.1336286067962646, GAN loss = [2.8720973, 1.0552261, 1.0028894]\n",
      "Batch 125/700: Discriminator loss = 1.1922223567962646, GAN loss = [2.8364844, 1.0193197, 1.0032187]\n",
      "Batch 126/700: Discriminator loss = 1.1470270156860352, GAN loss = [2.8700223, 1.0570173, 0.999096]\n",
      "Batch 127/700: Discriminator loss = 1.1527775526046753, GAN loss = [2.9489462, 1.0476568, 1.087421]\n",
      "Batch 128/700: Discriminator loss = 1.130975365638733, GAN loss = [3.018972, 1.0611424, 1.1439985]\n",
      "Batch 129/700: Discriminator loss = 1.1278209686279297, GAN loss = [2.9042919, 1.021803, 1.0686892]\n",
      "Batch 130/700: Discriminator loss = 1.1599723100662231, GAN loss = [2.8741558, 1.0008695, 1.0595168]\n",
      "Batch 131/700: Discriminator loss = 1.1782615184783936, GAN loss = [2.8658903, 0.99957883, 1.0525641]\n",
      "Batch 132/700: Discriminator loss = 1.1547996997833252, GAN loss = [2.9028993, 1.0263267, 1.0628518]\n",
      "Batch 133/700: Discriminator loss = 1.1416599750518799, GAN loss = [2.9132416, 1.0148414, 1.0847145]\n",
      "Batch 134/700: Discriminator loss = 1.1308622360229492, GAN loss = [2.8864768, 1.0413046, 1.0315167]\n",
      "Batch 135/700: Discriminator loss = 1.1407415866851807, GAN loss = [2.885058, 1.0082493, 1.0631816]\n",
      "Batch 136/700: Discriminator loss = 1.1244210004806519, GAN loss = [2.9641225, 1.0518789, 1.0986439]\n",
      "Batch 137/700: Discriminator loss = 1.1282140016555786, GAN loss = [2.9520047, 1.0653785, 1.0730488]\n",
      "Batch 138/700: Discriminator loss = 1.1706196069717407, GAN loss = [2.909371, 1.0324025, 1.0634148]\n",
      "Batch 139/700: Discriminator loss = 1.1431328058242798, GAN loss = [2.824341, 1.0405155, 0.97029793]\n",
      "Batch 140/700: Discriminator loss = 1.1731451749801636, GAN loss = [2.8239822, 1.0462674, 0.9642165]\n",
      "Batch 141/700: Discriminator loss = 1.1615697145462036, GAN loss = [2.8898532, 1.0240272, 1.0523623]\n",
      "Batch 142/700: Discriminator loss = 1.1540613174438477, GAN loss = [3.0072906, 1.044386, 1.1494734]\n",
      "Batch 143/700: Discriminator loss = 1.1634212732315063, GAN loss = [2.9240758, 1.0432714, 1.0674119]\n",
      "Batch 144/700: Discriminator loss = 1.1604639291763306, GAN loss = [2.9028633, 1.0381036, 1.0514]\n",
      "Batch 145/700: Discriminator loss = 1.1439706087112427, GAN loss = [2.9099011, 1.0396215, 1.05695]\n",
      "Batch 146/700: Discriminator loss = 1.132996678352356, GAN loss = [2.985536, 1.0640707, 1.1081634]\n",
      "Batch 147/700: Discriminator loss = 1.1663106679916382, GAN loss = [2.9101715, 1.0562024, 1.0406904]\n",
      "Batch 148/700: Discriminator loss = 1.125880479812622, GAN loss = [2.9780014, 1.0907625, 1.0739872]\n",
      "Batch 149/700: Discriminator loss = 1.139968991279602, GAN loss = [2.989816, 1.0647798, 1.1118217]\n",
      "Batch 150/700: Discriminator loss = 1.1235380172729492, GAN loss = [2.9798691, 1.0671972, 1.0994878]\n",
      "Batch 151/700: Discriminator loss = 1.125249981880188, GAN loss = [3.0252914, 1.0894126, 1.1227218]\n",
      "Batch 152/700: Discriminator loss = 1.1885621547698975, GAN loss = [2.7697167, 1.013824, 0.9427643]\n",
      "Batch 153/700: Discriminator loss = 1.145402193069458, GAN loss = [3.0125248, 1.0678748, 1.1315452]\n",
      "Batch 154/700: Discriminator loss = 1.1103346347808838, GAN loss = [3.011767, 1.0983782, 1.1003144]\n",
      "Batch 155/700: Discriminator loss = 1.1327893733978271, GAN loss = [3.0283315, 1.0540454, 1.1612422]\n",
      "Batch 156/700: Discriminator loss = 1.1598689556121826, GAN loss = [2.9773605, 1.040897, 1.1234514]\n",
      "Batch 157/700: Discriminator loss = 1.116384744644165, GAN loss = [3.0509927, 1.0854294, 1.152578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 158/700: Discriminator loss = 1.1397490501403809, GAN loss = [3.020098, 1.0732356, 1.133903]\n",
      "Batch 159/700: Discriminator loss = 1.138723373413086, GAN loss = [2.9598632, 1.0541472, 1.0927858]\n",
      "Batch 160/700: Discriminator loss = 1.138465166091919, GAN loss = [3.0707407, 1.0642624, 1.1935731]\n",
      "Batch 161/700: Discriminator loss = 1.129866361618042, GAN loss = [3.0825524, 1.0742136, 1.1954577]\n",
      "Batch 162/700: Discriminator loss = 1.1594167947769165, GAN loss = [2.9552965, 1.0486939, 1.0937495]\n",
      "Batch 163/700: Discriminator loss = 1.1543291807174683, GAN loss = [3.0189679, 1.0753553, 1.13079]\n",
      "Batch 164/700: Discriminator loss = 1.1891419887542725, GAN loss = [2.9883494, 1.030526, 1.1450281]\n",
      "Batch 165/700: Discriminator loss = 1.1415132284164429, GAN loss = [2.9330115, 1.0715604, 1.0486926]\n",
      "Batch 166/700: Discriminator loss = 1.1682485342025757, GAN loss = [3.0008063, 1.0433887, 1.1446954]\n",
      "Batch 167/700: Discriminator loss = 1.144208550453186, GAN loss = [3.0514286, 1.0725195, 1.1662195]\n",
      "Batch 168/700: Discriminator loss = 1.1491233110427856, GAN loss = [3.008755, 1.0554147, 1.1406826]\n",
      "Batch 169/700: Discriminator loss = 1.1420271396636963, GAN loss = [2.9146976, 1.066524, 1.0355445]\n",
      "Batch 170/700: Discriminator loss = 1.1391786336898804, GAN loss = [3.014082, 1.097462, 1.1040189]\n",
      "Batch 171/700: Discriminator loss = 1.1141822338104248, GAN loss = [3.0223315, 1.0898519, 1.1199025]\n",
      "Batch 172/700: Discriminator loss = 1.1820610761642456, GAN loss = [2.9255152, 1.0399417, 1.0730193]\n",
      "Batch 173/700: Discriminator loss = 1.1609569787979126, GAN loss = [2.9847, 1.0578774, 1.1142893]\n",
      "Batch 174/700: Discriminator loss = 1.155957579612732, GAN loss = [3.0326319, 1.10242, 1.1177061]\n",
      "Batch 175/700: Discriminator loss = 1.1663342714309692, GAN loss = [2.9600527, 1.0654924, 1.0820757]\n",
      "Batch 176/700: Discriminator loss = 1.1988072395324707, GAN loss = [2.9890864, 1.054218, 1.1224076]\n",
      "Batch 177/700: Discriminator loss = 1.1384201049804688, GAN loss = [3.027756, 1.070287, 1.1450268]\n",
      "Batch 178/700: Discriminator loss = 1.1439242362976074, GAN loss = [2.8558197, 1.0519881, 0.9914102]\n",
      "Batch 179/700: Discriminator loss = 1.163731575012207, GAN loss = [2.9073026, 1.0721085, 1.0227913]\n",
      "Batch 180/700: Discriminator loss = 1.159562349319458, GAN loss = [2.862015, 1.0579759, 0.99165606]\n",
      "Batch 181/700: Discriminator loss = 1.1717429161071777, GAN loss = [2.9760203, 1.0296738, 1.1339879]\n",
      "Batch 182/700: Discriminator loss = 1.170974850654602, GAN loss = [2.939092, 1.0902193, 1.0365351]\n",
      "Batch 183/700: Discriminator loss = 1.1536670923233032, GAN loss = [3.0251849, 1.0864913, 1.1263806]\n",
      "Batch 184/700: Discriminator loss = 1.1755510568618774, GAN loss = [2.9759195, 1.0482659, 1.1153702]\n",
      "Batch 185/700: Discriminator loss = 1.1462587118148804, GAN loss = [2.993952, 1.0835547, 1.0981357]\n",
      "Batch 186/700: Discriminator loss = 1.1160203218460083, GAN loss = [3.1547267, 1.0977376, 1.244745]\n",
      "Batch 187/700: Discriminator loss = 1.1185381412506104, GAN loss = [3.0655546, 1.1002381, 1.1530911]\n",
      "Batch 188/700: Discriminator loss = 1.116530418395996, GAN loss = [3.1029375, 1.119176, 1.171554]\n",
      "Batch 189/700: Discriminator loss = 1.1576385498046875, GAN loss = [3.0146646, 1.0739666, 1.1285132]\n",
      "Batch 190/700: Discriminator loss = 1.1024903059005737, GAN loss = [3.1431272, 1.1303535, 1.2006125]\n",
      "Batch 191/700: Discriminator loss = 1.1057770252227783, GAN loss = [3.2285402, 1.1139462, 1.3024588]\n",
      "Batch 192/700: Discriminator loss = 1.1208851337432861, GAN loss = [3.1979775, 1.1192552, 1.2666087]\n",
      "Batch 193/700: Discriminator loss = 1.1295894384384155, GAN loss = [3.0584857, 1.103152, 1.143238]\n",
      "Batch 194/700: Discriminator loss = 1.1353663206100464, GAN loss = [3.274343, 1.1002713, 1.3619975]\n",
      "Batch 195/700: Discriminator loss = 1.1564515829086304, GAN loss = [2.9561124, 1.047644, 1.0964162]\n",
      "Batch 196/700: Discriminator loss = 1.149863362312317, GAN loss = [3.1463308, 1.0486897, 1.2856106]\n",
      "Batch 197/700: Discriminator loss = 1.1389535665512085, GAN loss = [3.143383, 1.0714166, 1.2599543]\n",
      "Batch 198/700: Discriminator loss = 1.1637191772460938, GAN loss = [3.1031842, 1.0603929, 1.2308011]\n",
      "Batch 199/700: Discriminator loss = 1.1445538997650146, GAN loss = [2.9659054, 1.0647402, 1.0891994]\n",
      "Batch 200/700: Discriminator loss = 1.1711808443069458, GAN loss = [3.0274723, 1.071644, 1.143889]\n",
      "Batch 201/700: Discriminator loss = 1.1287444829940796, GAN loss = [3.2637339, 1.0867459, 1.3650724]\n",
      "Batch 202/700: Discriminator loss = 1.1720857620239258, GAN loss = [3.1111755, 1.0887142, 1.210568]\n",
      "Batch 203/700: Discriminator loss = 1.1495308876037598, GAN loss = [3.0978966, 1.0682882, 1.2177366]\n",
      "Batch 204/700: Discriminator loss = 1.0992934703826904, GAN loss = [3.142729, 1.1377039, 1.1931702]\n",
      "Batch 205/700: Discriminator loss = 1.1416857242584229, GAN loss = [3.117179, 1.0870339, 1.2183259]\n",
      "Batch 206/700: Discriminator loss = 1.1348079442977905, GAN loss = [3.0682497, 1.097891, 1.1585685]\n",
      "Batch 207/700: Discriminator loss = 1.1692317724227905, GAN loss = [3.0731943, 1.0599707, 1.2014647]\n",
      "Batch 208/700: Discriminator loss = 1.1360872983932495, GAN loss = [3.1179595, 1.1405507, 1.1656852]\n",
      "Batch 209/700: Discriminator loss = 1.1305557489395142, GAN loss = [3.2493563, 1.1134814, 1.3241812]\n",
      "Batch 210/700: Discriminator loss = 1.0917056798934937, GAN loss = [3.268515, 1.1526945, 1.304158]\n",
      "Batch 211/700: Discriminator loss = 1.1538386344909668, GAN loss = [3.1168861, 1.1096191, 1.1956362]\n",
      "Batch 212/700: Discriminator loss = 1.1452044248580933, GAN loss = [3.0412164, 1.1171724, 1.1124493]\n",
      "Batch 213/700: Discriminator loss = 1.1315463781356812, GAN loss = [3.1529043, 1.1439976, 1.1973476]\n",
      "Batch 214/700: Discriminator loss = 1.1961222887039185, GAN loss = [2.972981, 1.0576701, 1.1037811]\n",
      "Batch 215/700: Discriminator loss = 1.1354575157165527, GAN loss = [3.028802, 1.1315552, 1.0857431]\n",
      "Batch 216/700: Discriminator loss = 1.1753307580947876, GAN loss = [3.1302085, 1.1120416, 1.2066911]\n",
      "Batch 217/700: Discriminator loss = 1.1431742906570435, GAN loss = [3.1625166, 1.1299658, 1.2210999]\n",
      "Batch 218/700: Discriminator loss = 1.1397531032562256, GAN loss = [3.00411, 1.127004, 1.0656834]\n",
      "Batch 219/700: Discriminator loss = 1.1471363306045532, GAN loss = [3.1143174, 1.1302556, 1.1726835]\n",
      "Batch 220/700: Discriminator loss = 1.1414512395858765, GAN loss = [3.0659995, 1.1416632, 1.1129979]\n",
      "Batch 221/700: Discriminator loss = 1.1118593215942383, GAN loss = [3.168824, 1.1434453, 1.2140818]\n",
      "Batch 222/700: Discriminator loss = 1.1851673126220703, GAN loss = [3.0244956, 1.0875747, 1.1256696]\n",
      "Batch 223/700: Discriminator loss = 1.1599093675613403, GAN loss = [3.006201, 1.0905938, 1.1043991]\n",
      "Batch 224/700: Discriminator loss = 1.1209766864776611, GAN loss = [3.0309696, 1.1221912, 1.0976155]\n",
      "Batch 225/700: Discriminator loss = 1.1508771181106567, GAN loss = [3.0502825, 1.0695194, 1.1696426]\n",
      "Batch 226/700: Discriminator loss = 1.1287719011306763, GAN loss = [3.1523767, 1.1236413, 1.217651]\n",
      "Batch 227/700: Discriminator loss = 1.1671817302703857, GAN loss = [3.0583694, 1.0712768, 1.1760482]\n",
      "Batch 228/700: Discriminator loss = 1.1963940858840942, GAN loss = [2.9700992, 1.0873243, 1.0717683]\n",
      "Batch 229/700: Discriminator loss = 1.1573154926300049, GAN loss = [2.9936647, 1.0912888, 1.0914159]\n",
      "Batch 230/700: Discriminator loss = 1.1828680038452148, GAN loss = [2.9574318, 1.0393132, 1.1072025]\n",
      "Batch 231/700: Discriminator loss = 1.1860798597335815, GAN loss = [2.9335911, 1.0401481, 1.0825706]\n",
      "Batch 232/700: Discriminator loss = 1.1478543281555176, GAN loss = [2.9783392, 1.0430746, 1.1244305]\n",
      "Batch 233/700: Discriminator loss = 1.1493804454803467, GAN loss = [2.952246, 1.0447705, 1.0966793]\n",
      "Batch 234/700: Discriminator loss = 1.1693485975265503, GAN loss = [3.0195398, 1.0692948, 1.1394849]\n",
      "Batch 235/700: Discriminator loss = 1.1379764080047607, GAN loss = [3.0875602, 1.1236846, 1.1531581]\n",
      "Batch 236/700: Discriminator loss = 1.1653571128845215, GAN loss = [3.0475347, 1.083131, 1.153729]\n",
      "Batch 237/700: Discriminator loss = 1.144029140472412, GAN loss = [2.985907, 1.0730749, 1.1021956]\n",
      "Batch 238/700: Discriminator loss = 1.1948695182800293, GAN loss = [2.879416, 1.0500125, 1.0188004]\n",
      "Batch 239/700: Discriminator loss = 1.1733025312423706, GAN loss = [3.0151033, 1.1007826, 1.1037518]\n",
      "Batch 240/700: Discriminator loss = 1.1878989934921265, GAN loss = [2.9295623, 1.0386164, 1.0804062]\n",
      "Batch 241/700: Discriminator loss = 1.1725081205368042, GAN loss = [3.0159073, 1.0590985, 1.1463002]\n",
      "Batch 242/700: Discriminator loss = 1.1591893434524536, GAN loss = [3.0458453, 1.0792542, 1.1561142]\n",
      "Batch 243/700: Discriminator loss = 1.1949995756149292, GAN loss = [2.8749506, 1.0514495, 1.0130545]\n",
      "Batch 244/700: Discriminator loss = 1.1390830278396606, GAN loss = [3.1223342, 1.1364892, 1.1754299]\n",
      "Batch 245/700: Discriminator loss = 1.1399815082550049, GAN loss = [2.9678807, 1.0808274, 1.0766668]\n",
      "Batch 246/700: Discriminator loss = 1.1798228025436401, GAN loss = [2.9409611, 1.0752921, 1.0553077]\n",
      "Batch 247/700: Discriminator loss = 1.1463704109191895, GAN loss = [3.0023987, 1.0829005, 1.1091623]\n",
      "Batch 248/700: Discriminator loss = 1.219015121459961, GAN loss = [2.9478824, 1.1115062, 1.0260606]\n",
      "Batch 249/700: Discriminator loss = 1.130685806274414, GAN loss = [3.0538256, 1.1387937, 1.1047368]\n",
      "Batch 250/700: Discriminator loss = 1.137861967086792, GAN loss = [2.9713573, 1.104819, 1.0562704]\n",
      "Batch 251/700: Discriminator loss = 1.1892611980438232, GAN loss = [2.9884772, 1.077811, 1.1004245]\n",
      "Batch 252/700: Discriminator loss = 1.1352838277816772, GAN loss = [2.9638922, 1.1354856, 1.0181923]\n",
      "Batch 253/700: Discriminator loss = 1.1338995695114136, GAN loss = [2.9882972, 1.0994681, 1.078646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 254/700: Discriminator loss = 1.131384015083313, GAN loss = [2.9500742, 1.128817, 1.0111057]\n",
      "Batch 255/700: Discriminator loss = 1.1114134788513184, GAN loss = [3.0065377, 1.137084, 1.0593278]\n",
      "Batch 256/700: Discriminator loss = 1.0893617868423462, GAN loss = [3.1004875, 1.1350073, 1.1553836]\n",
      "Batch 257/700: Discriminator loss = 1.129014492034912, GAN loss = [3.0086358, 1.1387178, 1.0598434]\n",
      "Batch 258/700: Discriminator loss = 1.1311688423156738, GAN loss = [2.9883623, 1.1147522, 1.0635582]\n",
      "Batch 259/700: Discriminator loss = 1.1239941120147705, GAN loss = [2.940413, 1.0965598, 1.0338149]\n",
      "Batch 260/700: Discriminator loss = 1.1417936086654663, GAN loss = [2.8995755, 1.0950382, 0.99451333]\n",
      "Batch 261/700: Discriminator loss = 1.1654465198516846, GAN loss = [2.9529662, 1.0555334, 1.0874172]\n",
      "Batch 262/700: Discriminator loss = 1.151983380317688, GAN loss = [2.9066687, 1.0787932, 1.0178775]\n",
      "Batch 263/700: Discriminator loss = 1.1427243947982788, GAN loss = [2.940441, 1.0664274, 1.0640386]\n",
      "Batch 264/700: Discriminator loss = 1.1369965076446533, GAN loss = [3.0019543, 1.0827343, 1.109273]\n",
      "Batch 265/700: Discriminator loss = 1.1133644580841064, GAN loss = [3.059862, 1.094654, 1.1552877]\n",
      "Batch 266/700: Discriminator loss = 1.1401914358139038, GAN loss = [2.9297657, 1.0447679, 1.0751103]\n",
      "Batch 267/700: Discriminator loss = 1.1523319482803345, GAN loss = [2.9755726, 1.032834, 1.1328849]\n",
      "Batch 268/700: Discriminator loss = 1.1351075172424316, GAN loss = [3.0085034, 1.0563517, 1.1423277]\n",
      "Batch 269/700: Discriminator loss = 1.1472100019454956, GAN loss = [2.9416041, 1.0413456, 1.0904677]\n",
      "Batch 270/700: Discriminator loss = 1.1243709325790405, GAN loss = [3.0165098, 1.0646274, 1.1421202]\n",
      "Batch 271/700: Discriminator loss = 1.1429318189620972, GAN loss = [2.9677653, 1.0631653, 1.0948687]\n",
      "Batch 272/700: Discriminator loss = 1.1033324003219604, GAN loss = [3.0197654, 1.0833279, 1.1267362]\n",
      "Batch 273/700: Discriminator loss = 1.1096638441085815, GAN loss = [2.9718544, 1.0552189, 1.1069646]\n",
      "Batch 274/700: Discriminator loss = 1.1303480863571167, GAN loss = [3.0697432, 1.0849627, 1.1751417]\n",
      "Batch 275/700: Discriminator loss = 1.1608872413635254, GAN loss = [2.8998425, 1.030476, 1.0597619]\n",
      "Batch 276/700: Discriminator loss = 1.130884051322937, GAN loss = [2.9150367, 1.0324358, 1.0730286]\n",
      "Batch 277/700: Discriminator loss = 1.1538183689117432, GAN loss = [3.0370257, 1.0295573, 1.1979233]\n",
      "Batch 278/700: Discriminator loss = 1.1102815866470337, GAN loss = [2.9979472, 1.0906956, 1.0977333]\n",
      "Batch 279/700: Discriminator loss = 1.1086338758468628, GAN loss = [3.1132038, 1.0986189, 1.2051011]\n",
      "Batch 280/700: Discriminator loss = 1.1367031335830688, GAN loss = [3.0354726, 1.113102, 1.112916]\n",
      "Batch 281/700: Discriminator loss = 1.1153576374053955, GAN loss = [2.9175723, 1.0523422, 1.0558043]\n",
      "Batch 282/700: Discriminator loss = 1.1285362243652344, GAN loss = [2.913349, 1.0560437, 1.0479087]\n",
      "Batch 283/700: Discriminator loss = 1.1464545726776123, GAN loss = [2.9296958, 1.078669, 1.0416653]\n",
      "Batch 284/700: Discriminator loss = 1.1211116313934326, GAN loss = [2.9240215, 1.076802, 1.037885]\n",
      "Batch 285/700: Discriminator loss = 1.1649730205535889, GAN loss = [2.8896818, 1.0339347, 1.0464406]\n",
      "Batch 286/700: Discriminator loss = 1.1018983125686646, GAN loss = [2.9564188, 1.1068515, 1.0402899]\n",
      "Batch 287/700: Discriminator loss = 1.1533929109573364, GAN loss = [2.9240305, 1.0588988, 1.0558848]\n",
      "Batch 288/700: Discriminator loss = 1.146126389503479, GAN loss = [2.9013865, 1.0649824, 1.0271796]\n",
      "Batch 289/700: Discriminator loss = 1.1608492136001587, GAN loss = [2.8912895, 1.0447122, 1.0373784]\n",
      "Batch 290/700: Discriminator loss = 1.129332423210144, GAN loss = [2.9135003, 1.077045, 1.0272877]\n",
      "Batch 291/700: Discriminator loss = 1.0785505771636963, GAN loss = [3.163139, 1.1433651, 1.2106328]\n",
      "Batch 292/700: Discriminator loss = 1.139140248298645, GAN loss = [2.985278, 1.085372, 1.0907967]\n",
      "Batch 293/700: Discriminator loss = 1.1164240837097168, GAN loss = [2.9492846, 1.0806714, 1.0595351]\n",
      "Batch 294/700: Discriminator loss = 1.1673150062561035, GAN loss = [2.9973576, 1.0691055, 1.1192001]\n",
      "Batch 295/700: Discriminator loss = 1.162992000579834, GAN loss = [2.9812574, 1.1150855, 1.0571362]\n",
      "Batch 296/700: Discriminator loss = 1.1501438617706299, GAN loss = [2.9142723, 1.0688225, 1.0364381]\n",
      "Batch 297/700: Discriminator loss = 1.1560882329940796, GAN loss = [2.962068, 1.071717, 1.0813625]\n",
      "Batch 298/700: Discriminator loss = 1.1518009901046753, GAN loss = [2.9248428, 1.0397524, 1.0761266]\n",
      "Batch 299/700: Discriminator loss = 1.1550049781799316, GAN loss = [2.8696506, 1.0719277, 0.98878026]\n",
      "Batch 300/700: Discriminator loss = 1.1265895366668701, GAN loss = [2.9895296, 1.0666591, 1.113955]\n",
      "Batch 301/700: Discriminator loss = 1.117669701576233, GAN loss = [2.8982348, 1.058559, 1.030786]\n",
      "Batch 302/700: Discriminator loss = 1.1218507289886475, GAN loss = [3.075685, 1.0773442, 1.1894749]\n",
      "Batch 303/700: Discriminator loss = 1.1060645580291748, GAN loss = [2.9768174, 1.0761011, 1.0918785]\n",
      "Batch 304/700: Discriminator loss = 1.1403732299804688, GAN loss = [2.9886487, 1.0856107, 1.0942308]\n",
      "Batch 305/700: Discriminator loss = 1.1040452718734741, GAN loss = [3.0552921, 1.1032511, 1.1432586]\n",
      "Batch 306/700: Discriminator loss = 1.145000696182251, GAN loss = [3.0294363, 1.0742707, 1.1464078]\n",
      "Batch 307/700: Discriminator loss = 1.1273047924041748, GAN loss = [3.0586483, 1.1202093, 1.1297055]\n",
      "Batch 308/700: Discriminator loss = 1.1765315532684326, GAN loss = [2.9318607, 1.0393466, 1.0838114]\n",
      "Batch 309/700: Discriminator loss = 1.0916846990585327, GAN loss = [3.025986, 1.0760512, 1.1412611]\n",
      "Batch 310/700: Discriminator loss = 1.1237187385559082, GAN loss = [2.9887595, 1.0806458, 1.0994647]\n",
      "Batch 311/700: Discriminator loss = 1.104259729385376, GAN loss = [3.1980488, 1.1091243, 1.2803011]\n",
      "Batch 312/700: Discriminator loss = 1.1141846179962158, GAN loss = [3.0165732, 1.0802653, 1.1277026]\n",
      "Batch 313/700: Discriminator loss = 1.1516304016113281, GAN loss = [2.9731252, 1.0751232, 1.0894097]\n",
      "Batch 314/700: Discriminator loss = 1.1229513883590698, GAN loss = [3.157029, 1.0881649, 1.2602983]\n",
      "Batch 315/700: Discriminator loss = 1.1282930374145508, GAN loss = [3.1003003, 1.1125351, 1.1792186]\n",
      "Batch 316/700: Discriminator loss = 1.1070054769515991, GAN loss = [3.0177712, 1.0752379, 1.1340035]\n",
      "Batch 317/700: Discriminator loss = 1.1032695770263672, GAN loss = [3.0796854, 1.0870001, 1.184176]\n",
      "Batch 318/700: Discriminator loss = 1.140190839767456, GAN loss = [2.9908547, 1.0747427, 1.1076311]\n",
      "Batch 319/700: Discriminator loss = 1.120473861694336, GAN loss = [3.0887358, 1.1182634, 1.1620237]\n",
      "Batch 320/700: Discriminator loss = 1.1194487810134888, GAN loss = [3.1238759, 1.0891415, 1.2263166]\n",
      "Batch 321/700: Discriminator loss = 1.1586858034133911, GAN loss = [3.0247908, 1.0721345, 1.1442676]\n",
      "Batch 322/700: Discriminator loss = 1.1763087511062622, GAN loss = [2.955138, 1.0626292, 1.0841527]\n",
      "Batch 323/700: Discriminator loss = 1.1622358560562134, GAN loss = [2.9662223, 1.0686669, 1.0892344]\n",
      "Batch 324/700: Discriminator loss = 1.1340663433074951, GAN loss = [2.996409, 1.0972354, 1.0908787]\n",
      "Batch 325/700: Discriminator loss = 1.1173797845840454, GAN loss = [3.0008278, 1.0833178, 1.1092428]\n",
      "Batch 326/700: Discriminator loss = 1.119614601135254, GAN loss = [3.2037292, 1.1228447, 1.2726502]\n",
      "Batch 327/700: Discriminator loss = 1.1710633039474487, GAN loss = [2.9454017, 1.0711876, 1.0660138]\n",
      "Batch 328/700: Discriminator loss = 1.15998113155365, GAN loss = [2.9661713, 1.0918213, 1.0661845]\n",
      "Batch 329/700: Discriminator loss = 1.2045844793319702, GAN loss = [2.9434724, 1.0512419, 1.0840966]\n",
      "Batch 330/700: Discriminator loss = 1.1788610219955444, GAN loss = [2.947113, 1.0949395, 1.0440661]\n",
      "Batch 331/700: Discriminator loss = 1.168434977531433, GAN loss = [3.0171287, 1.0984668, 1.1105777]\n",
      "Batch 332/700: Discriminator loss = 1.162330150604248, GAN loss = [2.9685173, 1.0682977, 1.0921587]\n",
      "Batch 333/700: Discriminator loss = 1.1770079135894775, GAN loss = [2.932508, 1.0797411, 1.0447305]\n",
      "Batch 334/700: Discriminator loss = 1.243605375289917, GAN loss = [2.9440815, 1.0401812, 1.0958987]\n",
      "Batch 335/700: Discriminator loss = 1.221908688545227, GAN loss = [2.787889, 1.0505846, 0.9293317]\n",
      "Batch 336/700: Discriminator loss = 1.198830008506775, GAN loss = [2.875106, 1.0937685, 0.97339904]\n",
      "Batch 337/700: Discriminator loss = 1.1650160551071167, GAN loss = [3.0122085, 1.0777532, 1.1265434]\n",
      "Batch 338/700: Discriminator loss = 1.2158564329147339, GAN loss = [2.8696232, 1.0861206, 0.97562224]\n",
      "Batch 339/700: Discriminator loss = 1.167988896369934, GAN loss = [2.9700568, 1.107881, 1.0543205]\n",
      "Batch 340/700: Discriminator loss = 1.1959196329116821, GAN loss = [2.8770192, 1.0416057, 1.027582]\n",
      "Batch 341/700: Discriminator loss = 1.1477590799331665, GAN loss = [2.956322, 1.0856454, 1.0628673]\n",
      "Batch 342/700: Discriminator loss = 1.1993992328643799, GAN loss = [2.8787751, 1.0472419, 1.0237483]\n",
      "Batch 343/700: Discriminator loss = 1.1688841581344604, GAN loss = [2.9737196, 1.0958817, 1.0700756]\n",
      "Batch 344/700: Discriminator loss = 1.1662095785140991, GAN loss = [2.8409338, 1.0389113, 0.9942802]\n",
      "Batch 345/700: Discriminator loss = 1.1416552066802979, GAN loss = [2.99785, 1.1059327, 1.0841881]\n",
      "Batch 346/700: Discriminator loss = 1.1716830730438232, GAN loss = [2.9477365, 1.0634649, 1.0765644]\n",
      "Batch 347/700: Discriminator loss = 1.137158751487732, GAN loss = [2.900832, 1.0626019, 1.0305446]\n",
      "Batch 348/700: Discriminator loss = 1.2138510942459106, GAN loss = [2.8190806, 1.0372531, 0.9741682]\n",
      "Batch 349/700: Discriminator loss = 1.1292221546173096, GAN loss = [3.007979, 1.0650452, 1.1353078]\n",
      "Batch 350/700: Discriminator loss = 1.1599276065826416, GAN loss = [3.0293832, 1.0529833, 1.1687988]\n",
      "Batch 351/700: Discriminator loss = 1.1477261781692505, GAN loss = [2.9317472, 1.0313575, 1.0928102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 352/700: Discriminator loss = 1.164859652519226, GAN loss = [2.8825362, 1.0184501, 1.0565228]\n",
      "Batch 353/700: Discriminator loss = 1.143347144126892, GAN loss = [2.913897, 1.0454679, 1.0608906]\n",
      "Batch 354/700: Discriminator loss = 1.1120238304138184, GAN loss = [3.081039, 1.0942749, 1.1792575]\n",
      "Batch 355/700: Discriminator loss = 1.139660358428955, GAN loss = [3.0533326, 1.0653648, 1.1804935]\n",
      "Batch 356/700: Discriminator loss = 1.157117486000061, GAN loss = [3.005781, 1.0227895, 1.1755507]\n",
      "Batch 357/700: Discriminator loss = 1.1532748937606812, GAN loss = [3.000384, 1.0540274, 1.138946]\n",
      "Batch 358/700: Discriminator loss = 1.130993366241455, GAN loss = [3.034564, 1.0626445, 1.1645337]\n",
      "Batch 359/700: Discriminator loss = 1.1147141456604004, GAN loss = [3.1030216, 1.0844772, 1.2111897]\n",
      "Batch 360/700: Discriminator loss = 1.1329327821731567, GAN loss = [3.0464878, 1.042403, 1.1967565]\n",
      "Batch 361/700: Discriminator loss = 1.1400772333145142, GAN loss = [3.1951041, 1.0386357, 1.3491616]\n",
      "Batch 362/700: Discriminator loss = 1.1081609725952148, GAN loss = [3.0138273, 1.0934551, 1.1130779]\n",
      "Batch 363/700: Discriminator loss = 1.1787821054458618, GAN loss = [3.0181932, 1.0519934, 1.1589321]\n",
      "Batch 364/700: Discriminator loss = 1.1380962133407593, GAN loss = [3.0935183, 1.050119, 1.2361661]\n",
      "Batch 365/700: Discriminator loss = 1.1254971027374268, GAN loss = [3.0930247, 1.0764118, 1.2094063]\n",
      "Batch 366/700: Discriminator loss = 1.1335667371749878, GAN loss = [2.9884233, 1.0666107, 1.1146321]\n",
      "Batch 367/700: Discriminator loss = 1.114928960800171, GAN loss = [3.1412535, 1.0980504, 1.236044]\n",
      "Batch 368/700: Discriminator loss = 1.1154232025146484, GAN loss = [3.0784125, 1.0805403, 1.1907399]\n",
      "Batch 369/700: Discriminator loss = 1.1108511686325073, GAN loss = [3.1430247, 1.1151558, 1.2207655]\n",
      "Batch 370/700: Discriminator loss = 1.1402720212936401, GAN loss = [2.965628, 1.0551177, 1.1034347]\n",
      "Batch 371/700: Discriminator loss = 1.1000120639801025, GAN loss = [3.1341908, 1.112922, 1.2142205]\n",
      "Batch 372/700: Discriminator loss = 1.1252893209457397, GAN loss = [3.0779448, 1.098404, 1.1725192]\n",
      "Batch 373/700: Discriminator loss = 1.1551434993743896, GAN loss = [2.9778478, 1.0612024, 1.1096438]\n",
      "Batch 374/700: Discriminator loss = 1.1673086881637573, GAN loss = [2.9891758, 1.0826968, 1.0994987]\n",
      "Batch 375/700: Discriminator loss = 1.1141488552093506, GAN loss = [3.031397, 1.1070026, 1.1174544]\n",
      "Batch 376/700: Discriminator loss = 1.128844141960144, GAN loss = [3.1478896, 1.154931, 1.1860564]\n",
      "Batch 377/700: Discriminator loss = 1.0954526662826538, GAN loss = [3.1090887, 1.1657926, 1.1364241]\n",
      "Batch 378/700: Discriminator loss = 1.101062536239624, GAN loss = [3.1235957, 1.111784, 1.2049665]\n",
      "Batch 379/700: Discriminator loss = 1.1228669881820679, GAN loss = [3.011986, 1.0987377, 1.1064332]\n",
      "Batch 380/700: Discriminator loss = 1.1152892112731934, GAN loss = [3.0607333, 1.1172255, 1.1367285]\n",
      "Batch 381/700: Discriminator loss = 1.0919994115829468, GAN loss = [3.19619, 1.128808, 1.2606426]\n",
      "Batch 382/700: Discriminator loss = 1.1201002597808838, GAN loss = [3.0698884, 1.0873624, 1.1758176]\n",
      "Batch 383/700: Discriminator loss = 1.12624990940094, GAN loss = [3.0815008, 1.0934654, 1.1813596]\n",
      "Batch 384/700: Discriminator loss = 1.1747868061065674, GAN loss = [3.034486, 1.0734153, 1.1544285]\n",
      "Batch 385/700: Discriminator loss = 1.1993699073791504, GAN loss = [3.0354578, 1.0699385, 1.1589062]\n",
      "Batch 386/700: Discriminator loss = 1.1392005681991577, GAN loss = [3.0038033, 1.0928295, 1.1043978]\n",
      "Batch 387/700: Discriminator loss = 1.1427072286605835, GAN loss = [3.0561876, 1.0869163, 1.1627368]\n",
      "Batch 388/700: Discriminator loss = 1.1386395692825317, GAN loss = [3.013626, 1.0904759, 1.1166482]\n",
      "Batch 389/700: Discriminator loss = 1.1527262926101685, GAN loss = [2.9926531, 1.0867823, 1.0994066]\n",
      "Batch 390/700: Discriminator loss = 1.1714067459106445, GAN loss = [2.8804016, 1.0451102, 1.0288612]\n",
      "Batch 391/700: Discriminator loss = 1.1547554731369019, GAN loss = [2.8851633, 1.029293, 1.0494719]\n",
      "Batch 392/700: Discriminator loss = 1.1295063495635986, GAN loss = [3.0563004, 1.0964211, 1.1535114]\n",
      "Batch 393/700: Discriminator loss = 1.1383618116378784, GAN loss = [2.9450636, 1.0684971, 1.070221]\n",
      "Batch 394/700: Discriminator loss = 1.1684023141860962, GAN loss = [3.0538435, 1.0799782, 1.1675515]\n",
      "Batch 395/700: Discriminator loss = 1.180962324142456, GAN loss = [2.9642034, 1.0425755, 1.1153483]\n",
      "Batch 396/700: Discriminator loss = 1.1227242946624756, GAN loss = [3.022013, 1.1082826, 1.107491]\n",
      "Batch 397/700: Discriminator loss = 1.1188788414001465, GAN loss = [3.0431175, 1.1028473, 1.1340744]\n",
      "Batch 398/700: Discriminator loss = 1.182473063468933, GAN loss = [2.894105, 1.0483575, 1.0395948]\n",
      "Batch 399/700: Discriminator loss = 1.1628241539001465, GAN loss = [3.1005564, 1.1234382, 1.1710114]\n",
      "Batch 400/700: Discriminator loss = 1.1649754047393799, GAN loss = [3.0087185, 1.0808338, 1.1218166]\n",
      "Batch 401/700: Discriminator loss = 1.1498041152954102, GAN loss = [3.0408742, 1.1223738, 1.1124606]\n",
      "Batch 402/700: Discriminator loss = 1.1720582246780396, GAN loss = [2.9127376, 1.0527538, 1.0539685]\n",
      "Batch 403/700: Discriminator loss = 1.173559546470642, GAN loss = [3.074608, 1.0902079, 1.1784095]\n",
      "Batch 404/700: Discriminator loss = 1.1301956176757812, GAN loss = [2.9569948, 1.1154317, 1.0355961]\n",
      "Batch 405/700: Discriminator loss = 1.1155973672866821, GAN loss = [3.0653012, 1.1243004, 1.1350735]\n",
      "Batch 406/700: Discriminator loss = 1.1525447368621826, GAN loss = [2.9519544, 1.078825, 1.067241]\n",
      "Batch 407/700: Discriminator loss = 1.1722029447555542, GAN loss = [2.9178956, 1.049743, 1.0623013]\n",
      "Batch 408/700: Discriminator loss = 1.1531593799591064, GAN loss = [2.900252, 1.0587819, 1.0356565]\n",
      "Batch 409/700: Discriminator loss = 1.161216378211975, GAN loss = [2.9381037, 1.0741328, 1.0581912]\n",
      "Batch 410/700: Discriminator loss = 1.1593612432479858, GAN loss = [2.9368672, 1.0565388, 1.0745847]\n",
      "Batch 411/700: Discriminator loss = 1.1491928100585938, GAN loss = [2.9581857, 1.0910172, 1.0614557]\n",
      "Batch 412/700: Discriminator loss = 1.1758346557617188, GAN loss = [2.8984718, 1.0602065, 1.0325929]\n",
      "Batch 413/700: Discriminator loss = 1.1963298320770264, GAN loss = [2.9371872, 1.0981002, 1.033463]\n",
      "Batch 414/700: Discriminator loss = 1.1104685068130493, GAN loss = [2.9359639, 1.1023041, 1.0280774]\n",
      "Batch 415/700: Discriminator loss = 1.1728246212005615, GAN loss = [2.8710358, 1.0588712, 1.0066203]\n",
      "Batch 416/700: Discriminator loss = 1.1154899597167969, GAN loss = [2.9893115, 1.0973222, 1.0864767]\n",
      "Batch 417/700: Discriminator loss = 1.1546274423599243, GAN loss = [2.9386466, 1.0729578, 1.060207]\n",
      "Batch 418/700: Discriminator loss = 1.1624866724014282, GAN loss = [2.9811132, 1.0447125, 1.1309485]\n",
      "Batch 419/700: Discriminator loss = 1.1481742858886719, GAN loss = [2.9076107, 1.0453744, 1.0568162]\n",
      "Batch 420/700: Discriminator loss = 1.1545497179031372, GAN loss = [3.0351155, 1.034839, 1.1948903]\n",
      "Batch 421/700: Discriminator loss = 1.1992465257644653, GAN loss = [2.908699, 1.0521245, 1.051231]\n",
      "Batch 422/700: Discriminator loss = 1.151085376739502, GAN loss = [2.9604497, 1.0728909, 1.0822554]\n",
      "Batch 423/700: Discriminator loss = 1.13567054271698, GAN loss = [2.9821188, 1.0839069, 1.0929456]\n",
      "Batch 424/700: Discriminator loss = 1.1367700099945068, GAN loss = [2.9876056, 1.0821551, 1.1002103]\n",
      "Batch 425/700: Discriminator loss = 1.1450749635696411, GAN loss = [3.0344443, 1.0728903, 1.1563573]\n",
      "Batch 426/700: Discriminator loss = 1.155759572982788, GAN loss = [2.873362, 1.0741186, 0.994086]\n",
      "Batch 427/700: Discriminator loss = 1.1425923109054565, GAN loss = [3.0561352, 1.0558654, 1.1951461]\n",
      "Batch 428/700: Discriminator loss = 1.1381921768188477, GAN loss = [3.0035167, 1.0929309, 1.1054863]\n",
      "Batch 429/700: Discriminator loss = 1.1647820472717285, GAN loss = [2.8771057, 1.0364529, 1.0355754]\n",
      "Batch 430/700: Discriminator loss = 1.1934764385223389, GAN loss = [2.8229134, 1.0348855, 0.98296875]\n",
      "Batch 431/700: Discriminator loss = 1.1443817615509033, GAN loss = [2.888361, 1.0508386, 1.032487]\n",
      "Batch 432/700: Discriminator loss = 1.162841796875, GAN loss = [2.8787394, 1.0418777, 1.0318553]\n",
      "Batch 433/700: Discriminator loss = 1.1803184747695923, GAN loss = [2.9446664, 1.0621718, 1.0775169]\n",
      "Batch 434/700: Discriminator loss = 1.182226538658142, GAN loss = [2.9161277, 1.0228122, 1.0883735]\n",
      "Batch 435/700: Discriminator loss = 1.1780319213867188, GAN loss = [2.924919, 1.0699638, 1.050046]\n",
      "Batch 436/700: Discriminator loss = 1.176253318786621, GAN loss = [2.933184, 1.0472991, 1.0810021]\n",
      "Batch 437/700: Discriminator loss = 1.1475932598114014, GAN loss = [2.9013712, 1.0967932, 0.9997267]\n",
      "Batch 438/700: Discriminator loss = 1.1619032621383667, GAN loss = [2.982875, 1.0434109, 1.1346464]\n",
      "Batch 439/700: Discriminator loss = 1.1742066144943237, GAN loss = [2.9920895, 1.1081808, 1.0791203]\n",
      "Batch 440/700: Discriminator loss = 1.1252481937408447, GAN loss = [2.9923694, 1.0945779, 1.0930281]\n",
      "Batch 441/700: Discriminator loss = 1.1424922943115234, GAN loss = [3.006795, 1.0563488, 1.1457158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 442/700: Discriminator loss = 1.1487152576446533, GAN loss = [2.9746585, 1.0900816, 1.0798767]\n",
      "Batch 443/700: Discriminator loss = 1.1509076356887817, GAN loss = [2.9198322, 1.0757524, 1.0394158]\n",
      "Batch 444/700: Discriminator loss = 1.1111083030700684, GAN loss = [3.1398273, 1.1447676, 1.1904292]\n",
      "Batch 445/700: Discriminator loss = 1.1417895555496216, GAN loss = [3.1226506, 1.123747, 1.194315]\n",
      "Batch 446/700: Discriminator loss = 1.148321270942688, GAN loss = [3.0076349, 1.0854936, 1.117594]\n",
      "Batch 447/700: Discriminator loss = 1.1617892980575562, GAN loss = [2.9819522, 1.0798314, 1.0976083]\n",
      "Batch 448/700: Discriminator loss = 1.1483004093170166, GAN loss = [3.0139108, 1.0907099, 1.1187236]\n",
      "Batch 449/700: Discriminator loss = 1.142401933670044, GAN loss = [3.0780632, 1.1201088, 1.1535093]\n",
      "Batch 450/700: Discriminator loss = 1.1874792575836182, GAN loss = [2.862155, 1.0780736, 0.9796578]\n",
      "Batch 451/700: Discriminator loss = 1.1795583963394165, GAN loss = [2.9147499, 1.0710912, 1.0392548]\n",
      "Batch 452/700: Discriminator loss = 1.1969839334487915, GAN loss = [2.9287302, 1.052037, 1.0723144]\n",
      "Batch 453/700: Discriminator loss = 1.2174153327941895, GAN loss = [2.8019109, 1.0273445, 0.9702124]\n",
      "Batch 454/700: Discriminator loss = 1.2041438817977905, GAN loss = [3.0332017, 1.1226573, 1.1062117]\n",
      "Batch 455/700: Discriminator loss = 1.2502882480621338, GAN loss = [2.8597484, 1.0315853, 1.023848]\n",
      "Batch 456/700: Discriminator loss = 1.2419689893722534, GAN loss = [2.8533115, 1.0516609, 0.99735564]\n",
      "Batch 457/700: Discriminator loss = 1.197259783744812, GAN loss = [2.9441705, 1.0890132, 1.0508821]\n",
      "Batch 458/700: Discriminator loss = 1.1914832592010498, GAN loss = [2.8539014, 1.0668178, 0.9828254]\n",
      "Batch 459/700: Discriminator loss = 1.1826083660125732, GAN loss = [2.902212, 1.063898, 1.0340755]\n",
      "Batch 460/700: Discriminator loss = 1.1952704191207886, GAN loss = [2.737544, 1.040942, 0.89238626]\n",
      "Batch 461/700: Discriminator loss = 1.217604398727417, GAN loss = [2.8966036, 1.036903, 1.055508]\n",
      "Batch 462/700: Discriminator loss = 1.190726399421692, GAN loss = [2.8248153, 1.0475703, 0.9730769]\n",
      "Batch 463/700: Discriminator loss = 1.2165729999542236, GAN loss = [2.6825223, 1.0125374, 0.86584437]\n",
      "Batch 464/700: Discriminator loss = 1.2232753038406372, GAN loss = [2.8671856, 1.0075058, 1.0555751]\n",
      "Batch 465/700: Discriminator loss = 1.1431736946105957, GAN loss = [2.8626204, 1.0342624, 1.024279]\n",
      "Batch 466/700: Discriminator loss = 1.1684023141860962, GAN loss = [2.8268032, 1.0338223, 0.9889352]\n",
      "Batch 467/700: Discriminator loss = 1.1428570747375488, GAN loss = [2.890027, 1.0138775, 1.0721387]\n",
      "Batch 468/700: Discriminator loss = 1.1578662395477295, GAN loss = [2.8966806, 1.0157517, 1.0769496]\n",
      "Batch 469/700: Discriminator loss = 1.1711732149124146, GAN loss = [2.8825026, 1.0364769, 1.0420822]\n",
      "Batch 470/700: Discriminator loss = 1.1288211345672607, GAN loss = [2.956646, 1.0768349, 1.0759015]\n",
      "Batch 471/700: Discriminator loss = 1.1416218280792236, GAN loss = [2.925594, 1.048034, 1.0736827]\n",
      "Batch 472/700: Discriminator loss = 1.1559728384017944, GAN loss = [2.9585247, 1.0102801, 1.1443937]\n",
      "Batch 473/700: Discriminator loss = 1.1482404470443726, GAN loss = [2.9756339, 1.0399584, 1.131848]\n",
      "Batch 474/700: Discriminator loss = 1.1462279558181763, GAN loss = [3.0137029, 1.0426455, 1.167256]\n",
      "Batch 475/700: Discriminator loss = 1.1225718259811401, GAN loss = [2.8821084, 1.0620917, 1.0162363]\n",
      "Batch 476/700: Discriminator loss = 1.1876308917999268, GAN loss = [2.8127825, 0.9900436, 1.0189891]\n",
      "Batch 477/700: Discriminator loss = 1.1442490816116333, GAN loss = [3.0479398, 1.0306059, 1.2136182]\n",
      "Batch 478/700: Discriminator loss = 1.1572377681732178, GAN loss = [2.8562586, 1.0235493, 1.0290229]\n",
      "Batch 479/700: Discriminator loss = 1.1552612781524658, GAN loss = [2.9132836, 1.0264469, 1.0831763]\n",
      "Batch 480/700: Discriminator loss = 1.1733877658843994, GAN loss = [2.925754, 1.0061482, 1.1159725]\n",
      "Batch 481/700: Discriminator loss = 1.1577510833740234, GAN loss = [3.0508435, 1.0316503, 1.2155987]\n",
      "Batch 482/700: Discriminator loss = 1.1671844720840454, GAN loss = [2.8792026, 1.0230371, 1.0526059]\n",
      "Batch 483/700: Discriminator loss = 1.1293725967407227, GAN loss = [2.9663856, 1.0329545, 1.129904]\n",
      "Batch 484/700: Discriminator loss = 1.2239491939544678, GAN loss = [2.7743227, 1.0034372, 0.96739113]\n",
      "Batch 485/700: Discriminator loss = 1.1758067607879639, GAN loss = [2.9417818, 1.0163888, 1.1219347]\n",
      "Batch 486/700: Discriminator loss = 1.1587674617767334, GAN loss = [2.9103625, 0.9984682, 1.1084754]\n",
      "Batch 487/700: Discriminator loss = 1.1610491275787354, GAN loss = [2.9381056, 1.019859, 1.1148646]\n",
      "Batch 488/700: Discriminator loss = 1.169612169265747, GAN loss = [2.837005, 0.98826957, 1.0453887]\n",
      "Batch 489/700: Discriminator loss = 1.1794092655181885, GAN loss = [2.9057913, 0.99457014, 1.107907]\n",
      "Batch 490/700: Discriminator loss = 1.1594113111495972, GAN loss = [2.9976752, 1.0438958, 1.150501]\n",
      "Batch 491/700: Discriminator loss = 1.1426196098327637, GAN loss = [2.888793, 1.0122116, 1.0733429]\n",
      "Batch 492/700: Discriminator loss = 1.1620656251907349, GAN loss = [3.054074, 1.0288045, 1.222078]\n",
      "Batch 493/700: Discriminator loss = 1.1468133926391602, GAN loss = [2.889583, 1.0409827, 1.0454596]\n",
      "Batch 494/700: Discriminator loss = 1.121023416519165, GAN loss = [2.9099815, 1.024571, 1.0823175]\n",
      "Batch 495/700: Discriminator loss = 1.115007758140564, GAN loss = [3.0311027, 0.99340415, 1.2346516]\n",
      "Batch 496/700: Discriminator loss = 1.150177240371704, GAN loss = [3.0599453, 1.0360657, 1.2208711]\n",
      "Batch 497/700: Discriminator loss = 1.1479264497756958, GAN loss = [2.9529598, 1.0105611, 1.1394279]\n",
      "Batch 498/700: Discriminator loss = 1.140875220298767, GAN loss = [2.935429, 1.0100977, 1.1223991]\n",
      "Batch 499/700: Discriminator loss = 1.1415294408798218, GAN loss = [2.920564, 1.0184071, 1.099267]\n",
      "Batch 500/700: Discriminator loss = 1.1625488996505737, GAN loss = [2.9810224, 1.0170684, 1.1611077]\n",
      "Batch 501/700: Discriminator loss = 1.1535316705703735, GAN loss = [2.8348994, 1.0063653, 1.0257343]\n",
      "Batch 502/700: Discriminator loss = 1.1748454570770264, GAN loss = [2.924473, 0.98790115, 1.1338139]\n",
      "Batch 503/700: Discriminator loss = 1.1818040609359741, GAN loss = [2.9506955, 0.97390103, 1.1740736]\n",
      "Batch 504/700: Discriminator loss = 1.139028549194336, GAN loss = [2.8741994, 1.0037361, 1.0677775]\n",
      "Batch 505/700: Discriminator loss = 1.1645008325576782, GAN loss = [2.8915267, 1.0145224, 1.0743519]\n",
      "Batch 506/700: Discriminator loss = 1.1523878574371338, GAN loss = [2.898636, 1.0012126, 1.0948075]\n",
      "Batch 507/700: Discriminator loss = 1.1164802312850952, GAN loss = [3.1053047, 1.0555149, 1.247211]\n",
      "Batch 508/700: Discriminator loss = 1.169390082359314, GAN loss = [2.9672043, 1.0086082, 1.1560634]\n",
      "Batch 509/700: Discriminator loss = 1.112363576889038, GAN loss = [3.041915, 1.0603647, 1.179055]\n",
      "Batch 510/700: Discriminator loss = 1.1222596168518066, GAN loss = [2.8662074, 1.0391163, 1.024628]\n",
      "Batch 511/700: Discriminator loss = 1.1550298929214478, GAN loss = [2.9939847, 1.0175006, 1.1740526]\n",
      "Batch 512/700: Discriminator loss = 1.1537702083587646, GAN loss = [2.8321261, 1.0287598, 1.0009648]\n",
      "Batch 513/700: Discriminator loss = 1.1237022876739502, GAN loss = [2.969409, 1.0549195, 1.1121166]\n",
      "Batch 514/700: Discriminator loss = 1.126551628112793, GAN loss = [3.0030015, 1.0525495, 1.1481153]\n",
      "Batch 515/700: Discriminator loss = 1.1520800590515137, GAN loss = [2.8758426, 1.0243244, 1.0492144]\n",
      "Batch 516/700: Discriminator loss = 1.1368088722229004, GAN loss = [2.8639405, 1.0243245, 1.0373392]\n",
      "Batch 517/700: Discriminator loss = 1.1624435186386108, GAN loss = [2.8746836, 1.0014539, 1.0709797]\n",
      "Batch 518/700: Discriminator loss = 1.1817331314086914, GAN loss = [2.8825955, 0.9881933, 1.092184]\n",
      "Batch 519/700: Discriminator loss = 1.146247148513794, GAN loss = [2.902356, 1.0292652, 1.070898]\n",
      "Batch 520/700: Discriminator loss = 1.1380492448806763, GAN loss = [2.8280768, 1.0007817, 1.0251256]\n",
      "Batch 521/700: Discriminator loss = 1.1544182300567627, GAN loss = [2.88231, 0.9818424, 1.0983201]\n",
      "Batch 522/700: Discriminator loss = 1.2068560123443604, GAN loss = [2.7717319, 0.9592599, 1.0103481]\n",
      "Batch 523/700: Discriminator loss = 1.1364952325820923, GAN loss = [3.0376852, 1.004746, 1.230849]\n",
      "Batch 524/700: Discriminator loss = 1.1642322540283203, GAN loss = [2.892709, 0.99972427, 1.0909314]\n",
      "Batch 525/700: Discriminator loss = 1.118255376815796, GAN loss = [2.9564154, 1.0388705, 1.1155263]\n",
      "Batch 526/700: Discriminator loss = 1.170804738998413, GAN loss = [2.9886775, 1.012136, 1.1745585]\n",
      "Batch 527/700: Discriminator loss = 1.147399663925171, GAN loss = [2.9560027, 1.0237134, 1.1303401]\n",
      "Batch 528/700: Discriminator loss = 1.1291252374649048, GAN loss = [2.9958053, 1.0544175, 1.1394752]\n",
      "Batch 529/700: Discriminator loss = 1.1245909929275513, GAN loss = [3.0058918, 1.0171814, 1.1868343]\n",
      "Batch 530/700: Discriminator loss = 1.1505560874938965, GAN loss = [2.9913661, 0.98121613, 1.2083089]\n",
      "Batch 531/700: Discriminator loss = 1.1504188776016235, GAN loss = [2.9493806, 1.0111241, 1.1364391]\n",
      "Batch 532/700: Discriminator loss = 1.1363996267318726, GAN loss = [3.0399663, 1.0218499, 1.216319]\n",
      "Batch 533/700: Discriminator loss = 1.113747000694275, GAN loss = [3.032663, 1.0468233, 1.1840638]\n",
      "Batch 534/700: Discriminator loss = 1.148528814315796, GAN loss = [2.9949024, 1.0258864, 1.1672549]\n",
      "Batch 535/700: Discriminator loss = 1.1521365642547607, GAN loss = [2.936032, 0.9971452, 1.1371431]\n",
      "Batch 536/700: Discriminator loss = 1.1283937692642212, GAN loss = [3.0190916, 1.0258224, 1.1915432]\n",
      "Batch 537/700: Discriminator loss = 1.1742031574249268, GAN loss = [2.9287374, 0.99768454, 1.1293484]\n",
      "Batch 538/700: Discriminator loss = 1.1206519603729248, GAN loss = [3.1073904, 1.0496032, 1.2561008]\n",
      "Batch 539/700: Discriminator loss = 1.112802267074585, GAN loss = [3.0597289, 1.073222, 1.1848432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 540/700: Discriminator loss = 1.1110810041427612, GAN loss = [3.0938163, 1.0694869, 1.2226934]\n",
      "Batch 541/700: Discriminator loss = 1.1915359497070312, GAN loss = [2.9899306, 1.008202, 1.1801202]\n",
      "Batch 542/700: Discriminator loss = 1.1114745140075684, GAN loss = [2.9966254, 1.0515229, 1.1435137]\n",
      "Batch 543/700: Discriminator loss = 1.1447439193725586, GAN loss = [2.9516575, 1.036655, 1.113439]\n",
      "Batch 544/700: Discriminator loss = 1.1388651132583618, GAN loss = [3.0790195, 1.0482272, 1.229248]\n",
      "Batch 545/700: Discriminator loss = 1.1383098363876343, GAN loss = [3.0965238, 1.0652944, 1.2297086]\n",
      "Batch 546/700: Discriminator loss = 1.113810420036316, GAN loss = [3.000465, 1.0703777, 1.1285852]\n",
      "Batch 547/700: Discriminator loss = 1.1415659189224243, GAN loss = [3.0065923, 1.0567433, 1.1483715]\n",
      "Batch 548/700: Discriminator loss = 1.1355834007263184, GAN loss = [3.1368835, 1.06068, 1.274747]\n",
      "Batch 549/700: Discriminator loss = 1.130929708480835, GAN loss = [3.0398746, 1.0646558, 1.1737789]\n",
      "Batch 550/700: Discriminator loss = 1.140663504600525, GAN loss = [3.0101678, 1.0230439, 1.1857021]\n",
      "Batch 551/700: Discriminator loss = 1.1105300188064575, GAN loss = [3.0545633, 1.074014, 1.179142]\n",
      "Batch 552/700: Discriminator loss = 1.136675477027893, GAN loss = [2.9994178, 1.0464356, 1.1516019]\n",
      "Batch 553/700: Discriminator loss = 1.1597023010253906, GAN loss = [2.9507253, 1.0120825, 1.1372851]\n",
      "Batch 554/700: Discriminator loss = 1.1440311670303345, GAN loss = [3.0903535, 1.0535059, 1.235504]\n",
      "Batch 555/700: Discriminator loss = 1.1752210855484009, GAN loss = [3.0269783, 1.0519023, 1.1737531]\n",
      "Batch 556/700: Discriminator loss = 1.152106523513794, GAN loss = [2.8568735, 1.025945, 1.0296305]\n",
      "Batch 557/700: Discriminator loss = 1.206691026687622, GAN loss = [2.9058359, 1.0351015, 1.0694652]\n",
      "Batch 558/700: Discriminator loss = 1.1341619491577148, GAN loss = [3.0787504, 1.0447228, 1.232778]\n",
      "Batch 559/700: Discriminator loss = 1.1198832988739014, GAN loss = [3.1128943, 1.0938025, 1.2178602]\n",
      "Batch 560/700: Discriminator loss = 1.1304832696914673, GAN loss = [3.079125, 1.1088645, 1.1690392]\n",
      "Batch 561/700: Discriminator loss = 1.146026611328125, GAN loss = [3.0182064, 1.0858691, 1.1311383]\n",
      "Batch 562/700: Discriminator loss = 1.1478219032287598, GAN loss = [3.026722, 1.065437, 1.1601152]\n",
      "Batch 563/700: Discriminator loss = 1.1110925674438477, GAN loss = [3.0111642, 1.0725707, 1.137445]\n",
      "Batch 564/700: Discriminator loss = 1.1332260370254517, GAN loss = [3.0447457, 1.0927652, 1.1508571]\n",
      "Batch 565/700: Discriminator loss = 1.171475887298584, GAN loss = [3.0160792, 1.0568601, 1.1581314]\n",
      "Batch 566/700: Discriminator loss = 1.1296894550323486, GAN loss = [3.0824585, 1.0502053, 1.2312015]\n",
      "Batch 567/700: Discriminator loss = 1.1659969091415405, GAN loss = [3.0256279, 1.025778, 1.1988268]\n",
      "Batch 568/700: Discriminator loss = 1.1464848518371582, GAN loss = [3.0996494, 1.043618, 1.2550359]\n",
      "Batch 569/700: Discriminator loss = 1.1324384212493896, GAN loss = [3.0804741, 1.0667812, 1.2127255]\n",
      "Batch 570/700: Discriminator loss = 1.1281753778457642, GAN loss = [2.919732, 1.0534974, 1.065298]\n",
      "Batch 571/700: Discriminator loss = 1.1592289209365845, GAN loss = [3.0337784, 1.0503767, 1.1825001]\n",
      "Batch 572/700: Discriminator loss = 1.108630657196045, GAN loss = [3.0853577, 1.0750632, 1.2094314]\n",
      "Batch 573/700: Discriminator loss = 1.1224548816680908, GAN loss = [3.1047144, 1.0543345, 1.2495532]\n",
      "Batch 574/700: Discriminator loss = 1.104337453842163, GAN loss = [3.0356152, 1.0637554, 1.1710706]\n",
      "Batch 575/700: Discriminator loss = 1.1468979120254517, GAN loss = [2.9050899, 1.0418179, 1.0625144]\n",
      "Batch 576/700: Discriminator loss = 1.157930612564087, GAN loss = [2.9712164, 1.0370461, 1.1334499]\n",
      "Batch 577/700: Discriminator loss = 1.1460829973220825, GAN loss = [2.882364, 1.046488, 1.0351915]\n",
      "Batch 578/700: Discriminator loss = 1.1390634775161743, GAN loss = [2.976413, 1.0630386, 1.1127168]\n",
      "Batch 579/700: Discriminator loss = 1.167046070098877, GAN loss = [2.9806464, 1.0394791, 1.140538]\n",
      "Batch 580/700: Discriminator loss = 1.1370314359664917, GAN loss = [3.0225623, 1.0596482, 1.1623164]\n",
      "Batch 581/700: Discriminator loss = 1.1444586515426636, GAN loss = [2.982167, 1.0497773, 1.1318295]\n",
      "Batch 582/700: Discriminator loss = 1.134162187576294, GAN loss = [2.9718313, 1.0653043, 1.1060059]\n",
      "Batch 583/700: Discriminator loss = 1.1468886137008667, GAN loss = [2.8840816, 1.0152167, 1.0683812]\n",
      "Batch 584/700: Discriminator loss = 1.1475533246994019, GAN loss = [3.0214596, 1.0611047, 1.1599119]\n",
      "Batch 585/700: Discriminator loss = 1.1158206462860107, GAN loss = [3.0119145, 1.0680867, 1.14342]\n",
      "Batch 586/700: Discriminator loss = 1.1866767406463623, GAN loss = [2.9111679, 1.0128576, 1.0979327]\n",
      "Batch 587/700: Discriminator loss = 1.15763258934021, GAN loss = [2.7942808, 0.9908522, 1.003079]\n",
      "Batch 588/700: Discriminator loss = 1.2448135614395142, GAN loss = [2.8084512, 0.9358327, 1.0723003]\n",
      "Batch 589/700: Discriminator loss = 1.191083312034607, GAN loss = [2.769666, 0.96064866, 1.0087223]\n",
      "Batch 590/700: Discriminator loss = 1.2036833763122559, GAN loss = [2.8494055, 0.9727398, 1.0763958]\n",
      "Batch 591/700: Discriminator loss = 1.236109733581543, GAN loss = [2.8150773, 0.9833596, 1.0314752]\n",
      "Batch 592/700: Discriminator loss = 1.170791745185852, GAN loss = [2.8743942, 0.9937655, 1.0804139]\n",
      "Batch 593/700: Discriminator loss = 1.1624958515167236, GAN loss = [2.925761, 1.0302265, 1.0953463]\n",
      "Batch 594/700: Discriminator loss = 1.1888649463653564, GAN loss = [2.893182, 1.0395542, 1.0534767]\n",
      "Batch 595/700: Discriminator loss = 1.1486096382141113, GAN loss = [2.7782154, 0.9916959, 0.98640496]\n",
      "Batch 596/700: Discriminator loss = 1.165580153465271, GAN loss = [2.8860629, 1.0088404, 1.07714]\n",
      "Batch 597/700: Discriminator loss = 1.1716268062591553, GAN loss = [2.8523602, 0.9988674, 1.0534476]\n",
      "Batch 598/700: Discriminator loss = 1.166927456855774, GAN loss = [2.9945846, 1.0247257, 1.1698506]\n",
      "Batch 599/700: Discriminator loss = 1.1807324886322021, GAN loss = [2.8649952, 1.0017437, 1.0632818]\n",
      "Batch 600/700: Discriminator loss = 1.156304955482483, GAN loss = [2.880676, 1.0094802, 1.0712645]\n",
      "Batch 601/700: Discriminator loss = 1.1498631238937378, GAN loss = [2.9255655, 1.0259182, 1.0997485]\n",
      "Batch 602/700: Discriminator loss = 1.1670031547546387, GAN loss = [2.951777, 0.99993986, 1.1519746]\n",
      "Batch 603/700: Discriminator loss = 1.1560324430465698, GAN loss = [2.977163, 1.0061561, 1.1711774]\n",
      "Batch 604/700: Discriminator loss = 1.1382486820220947, GAN loss = [3.0650585, 1.0290303, 1.2362354]\n",
      "Batch 605/700: Discriminator loss = 1.195673942565918, GAN loss = [3.0101287, 1.025171, 1.1852059]\n",
      "Batch 606/700: Discriminator loss = 1.1758451461791992, GAN loss = [2.9485507, 1.0219126, 1.126929]\n",
      "Batch 607/700: Discriminator loss = 1.1618646383285522, GAN loss = [2.9608736, 1.0178668, 1.1433387]\n",
      "Batch 608/700: Discriminator loss = 1.1092008352279663, GAN loss = [3.1440332, 1.1032081, 1.2411915]\n",
      "Batch 609/700: Discriminator loss = 1.1750057935714722, GAN loss = [2.939751, 1.0587324, 1.0814211]\n",
      "Batch 610/700: Discriminator loss = 1.1715322732925415, GAN loss = [2.8719914, 1.0280831, 1.0443476]\n",
      "Batch 611/700: Discriminator loss = 1.134529948234558, GAN loss = [2.9603934, 1.0203009, 1.1405666]\n",
      "Batch 612/700: Discriminator loss = 1.1654072999954224, GAN loss = [3.0808172, 1.04721, 1.23411]\n",
      "Batch 613/700: Discriminator loss = 1.1120765209197998, GAN loss = [3.0410266, 1.0763556, 1.1652032]\n",
      "Batch 614/700: Discriminator loss = 1.1782094240188599, GAN loss = [2.996141, 1.0271131, 1.1695924]\n",
      "Batch 615/700: Discriminator loss = 1.1869536638259888, GAN loss = [2.9325347, 1.0249536, 1.1081754]\n",
      "Batch 616/700: Discriminator loss = 1.1822421550750732, GAN loss = [3.02853, 1.0408428, 1.1883107]\n",
      "Batch 617/700: Discriminator loss = 1.1802159547805786, GAN loss = [3.02444, 1.0419253, 1.1831642]\n",
      "Batch 618/700: Discriminator loss = 1.1635384559631348, GAN loss = [2.95878, 1.0610065, 1.0984577]\n",
      "Batch 619/700: Discriminator loss = 1.153176188468933, GAN loss = [2.9825947, 1.0721374, 1.1111622]\n",
      "Batch 620/700: Discriminator loss = 1.1739542484283447, GAN loss = [3.0203571, 1.0937235, 1.1273609]\n",
      "Batch 621/700: Discriminator loss = 1.1776480674743652, GAN loss = [3.001089, 1.0564595, 1.1453882]\n",
      "Batch 622/700: Discriminator loss = 1.1472524404525757, GAN loss = [2.9733891, 1.061232, 1.1129433]\n",
      "Batch 623/700: Discriminator loss = 1.1855573654174805, GAN loss = [2.9070766, 1.0750356, 1.0328559]\n",
      "Batch 624/700: Discriminator loss = 1.2154295444488525, GAN loss = [2.8339636, 1.015579, 1.0192413]\n",
      "Batch 625/700: Discriminator loss = 1.1759248971939087, GAN loss = [2.9787955, 1.0358586, 1.1438289]\n",
      "Batch 626/700: Discriminator loss = 1.1496167182922363, GAN loss = [3.0982187, 1.0731491, 1.2259923]\n",
      "Batch 627/700: Discriminator loss = 1.1544889211654663, GAN loss = [2.9509099, 1.0648822, 1.0869762]\n",
      "Batch 628/700: Discriminator loss = 1.1516577005386353, GAN loss = [2.981306, 1.0680513, 1.1142249]\n",
      "Batch 629/700: Discriminator loss = 1.1917359828948975, GAN loss = [2.887378, 1.0369823, 1.0513905]\n",
      "Batch 630/700: Discriminator loss = 1.1503092050552368, GAN loss = [2.9509895, 1.0911382, 1.0608649]\n",
      "Batch 631/700: Discriminator loss = 1.2040092945098877, GAN loss = [2.8494825, 1.028081, 1.0224335]\n",
      "Batch 632/700: Discriminator loss = 1.1615102291107178, GAN loss = [2.986872, 1.0492356, 1.1386931]\n",
      "Batch 633/700: Discriminator loss = 1.1498143672943115, GAN loss = [2.984989, 1.0897537, 1.0963079]\n",
      "Batch 634/700: Discriminator loss = 1.1866400241851807, GAN loss = [2.946197, 1.0618758, 1.0854186]\n",
      "Batch 635/700: Discriminator loss = 1.17500638961792, GAN loss = [2.9614348, 1.0458059, 1.1167593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 636/700: Discriminator loss = 1.17487370967865, GAN loss = [2.9874446, 1.0271617, 1.1614466]\n",
      "Batch 637/700: Discriminator loss = 1.1559252738952637, GAN loss = [3.085932, 1.0513188, 1.2357965]\n",
      "Batch 638/700: Discriminator loss = 1.1387873888015747, GAN loss = [3.0019166, 1.0903735, 1.1127429]\n",
      "Batch 639/700: Discriminator loss = 1.1753911972045898, GAN loss = [3.0268495, 1.0328933, 1.195181]\n",
      "Batch 640/700: Discriminator loss = 1.1614184379577637, GAN loss = [2.9559488, 1.0243053, 1.1328943]\n",
      "Batch 641/700: Discriminator loss = 1.1484887599945068, GAN loss = [2.8949742, 1.032047, 1.0642129]\n",
      "Batch 642/700: Discriminator loss = 1.1908552646636963, GAN loss = [2.8828347, 1.0046337, 1.079524]\n",
      "Batch 643/700: Discriminator loss = 1.1730186939239502, GAN loss = [2.8444319, 1.000185, 1.0455974]\n",
      "Batch 644/700: Discriminator loss = 1.227948784828186, GAN loss = [2.8812063, 0.9979084, 1.0846704]\n",
      "Batch 645/700: Discriminator loss = 1.161232590675354, GAN loss = [2.851083, 1.0018592, 1.0506114]\n",
      "Batch 646/700: Discriminator loss = 1.1702805757522583, GAN loss = [2.894997, 1.0140673, 1.0823328]\n",
      "Batch 647/700: Discriminator loss = 1.115739107131958, GAN loss = [3.0029383, 1.0712131, 1.1331416]\n",
      "Batch 648/700: Discriminator loss = 1.18494713306427, GAN loss = [2.966911, 0.9934436, 1.1748904]\n",
      "Batch 649/700: Discriminator loss = 1.1876808404922485, GAN loss = [2.8878765, 1.00201, 1.0873085]\n",
      "Batch 650/700: Discriminator loss = 1.1802446842193604, GAN loss = [2.9334576, 1.0194507, 1.1154712]\n",
      "Batch 651/700: Discriminator loss = 1.1655223369598389, GAN loss = [2.8929129, 1.0283529, 1.0660454]\n",
      "Batch 652/700: Discriminator loss = 1.2210965156555176, GAN loss = [2.7063646, 0.9611354, 0.9467269]\n",
      "Batch 653/700: Discriminator loss = 1.161181092262268, GAN loss = [2.8947985, 1.0015639, 1.0947529]\n",
      "Batch 654/700: Discriminator loss = 1.151881217956543, GAN loss = [2.948767, 0.98440933, 1.165898]\n",
      "Batch 655/700: Discriminator loss = 1.1713513135910034, GAN loss = [2.8193989, 0.9878981, 1.0330647]\n",
      "Batch 656/700: Discriminator loss = 1.1839419603347778, GAN loss = [2.8183756, 0.9843335, 1.0356311]\n",
      "Batch 657/700: Discriminator loss = 1.1467297077178955, GAN loss = [2.8832471, 1.0059696, 1.0788932]\n",
      "Batch 658/700: Discriminator loss = 1.1290132999420166, GAN loss = [3.1881654, 1.0472106, 1.3426003]\n",
      "Batch 659/700: Discriminator loss = 1.1407383680343628, GAN loss = [2.9483452, 1.0161022, 1.1339064]\n",
      "Batch 660/700: Discriminator loss = 1.1812247037887573, GAN loss = [2.9096992, 0.9970159, 1.1143641]\n",
      "Batch 661/700: Discriminator loss = 1.1364389657974243, GAN loss = [2.9572215, 1.0429597, 1.1159741]\n",
      "Batch 662/700: Discriminator loss = 1.1520754098892212, GAN loss = [3.002783, 1.0083996, 1.1961199]\n",
      "Batch 663/700: Discriminator loss = 1.158703327178955, GAN loss = [2.91385, 0.98818076, 1.1274238]\n",
      "Batch 664/700: Discriminator loss = 1.163697600364685, GAN loss = [2.9613223, 1.0059625, 1.1571374]\n",
      "Batch 665/700: Discriminator loss = 1.1576626300811768, GAN loss = [2.9446442, 1.0166972, 1.1297462]\n",
      "Batch 666/700: Discriminator loss = 1.1051290035247803, GAN loss = [3.00054, 1.0521445, 1.1502228]\n",
      "Batch 667/700: Discriminator loss = 1.146407961845398, GAN loss = [3.076799, 1.0305037, 1.2481486]\n",
      "Batch 668/700: Discriminator loss = 1.133916974067688, GAN loss = [3.0664597, 1.042197, 1.2261499]\n",
      "Batch 669/700: Discriminator loss = 1.1457802057266235, GAN loss = [2.884112, 0.9921849, 1.0938376]\n",
      "Batch 670/700: Discriminator loss = 1.0982716083526611, GAN loss = [3.0412045, 1.0436772, 1.1994672]\n",
      "Batch 671/700: Discriminator loss = 1.1393518447875977, GAN loss = [2.8865945, 1.0083483, 1.0802044]\n",
      "Batch 672/700: Discriminator loss = 1.1702710390090942, GAN loss = [2.9525588, 1.0151194, 1.1394175]\n",
      "Batch 673/700: Discriminator loss = 1.164602518081665, GAN loss = [2.919929, 1.0019484, 1.1199759]\n",
      "Batch 674/700: Discriminator loss = 1.1285167932510376, GAN loss = [3.089437, 1.0565767, 1.2348737]\n",
      "Batch 675/700: Discriminator loss = 1.117862582206726, GAN loss = [3.0404687, 1.0712576, 1.1712489]\n",
      "Batch 676/700: Discriminator loss = 1.1372770071029663, GAN loss = [2.9056633, 1.0148878, 1.0928363]\n",
      "Batch 677/700: Discriminator loss = 1.137719750404358, GAN loss = [2.9596748, 1.0157477, 1.1460074]\n",
      "Batch 678/700: Discriminator loss = 1.1664159297943115, GAN loss = [3.087456, 1.0187243, 1.2708355]\n",
      "Batch 679/700: Discriminator loss = 1.1517642736434937, GAN loss = [3.0131223, 1.0209578, 1.1942884]\n",
      "Batch 680/700: Discriminator loss = 1.110966444015503, GAN loss = [3.2029927, 1.068692, 1.336446]\n",
      "Batch 681/700: Discriminator loss = 1.1139531135559082, GAN loss = [3.0539184, 1.0530236, 1.2030637]\n",
      "Batch 682/700: Discriminator loss = 1.141576886177063, GAN loss = [2.8964634, 1.0398476, 1.058804]\n",
      "Batch 683/700: Discriminator loss = 1.1170778274536133, GAN loss = [2.998686, 1.0352244, 1.1656681]\n",
      "Batch 684/700: Discriminator loss = 1.1327767372131348, GAN loss = [3.0377986, 1.0720947, 1.1679264]\n",
      "Batch 685/700: Discriminator loss = 1.1252517700195312, GAN loss = [3.1623187, 1.0485107, 1.3160553]\n",
      "Batch 686/700: Discriminator loss = 1.1391756534576416, GAN loss = [3.1221406, 1.041719, 1.2826978]\n",
      "Batch 687/700: Discriminator loss = 1.1140408515930176, GAN loss = [3.106846, 1.0664784, 1.2426727]\n",
      "Batch 688/700: Discriminator loss = 1.1109236478805542, GAN loss = [3.126434, 1.0562807, 1.272482]\n",
      "Batch 689/700: Discriminator loss = 1.1332831382751465, GAN loss = [3.0194697, 1.0527203, 1.1691004]\n",
      "Batch 690/700: Discriminator loss = 1.1481629610061646, GAN loss = [2.992823, 1.071259, 1.123941]\n",
      "Batch 691/700: Discriminator loss = 1.1042251586914062, GAN loss = [3.16418, 1.0896533, 1.276928]\n",
      "Batch 692/700: Discriminator loss = 1.1079394817352295, GAN loss = [3.2354972, 1.1204085, 1.3175162]\n",
      "Batch 693/700: Discriminator loss = 1.1301695108413696, GAN loss = [3.1397533, 1.0445367, 1.2976716]\n",
      "Batch 694/700: Discriminator loss = 1.1460667848587036, GAN loss = [3.0258906, 1.0361553, 1.1922208]\n",
      "Batch 695/700: Discriminator loss = 1.15212881565094, GAN loss = [2.9711392, 1.0402113, 1.1334518]\n",
      "Batch 696/700: Discriminator loss = 1.1408416032791138, GAN loss = [3.0185583, 1.0469613, 1.1741607]\n",
      "Batch 697/700: Discriminator loss = 1.138947606086731, GAN loss = [3.0708673, 1.0823631, 1.1911118]\n",
      "Batch 698/700: Discriminator loss = 1.1003201007843018, GAN loss = [3.1783252, 1.0902262, 1.290746]\n",
      "Batch 699/700: Discriminator loss = 1.126558542251587, GAN loss = [2.9969997, 1.0626606, 1.1370224]\n",
      "Batch 700/700: Discriminator loss = 1.1403759717941284, GAN loss = [2.890718, 1.0302621, 1.0631801]\n",
      "Epoch 9/30\n",
      "Batch 1/700: Discriminator loss = 1.1351079940795898, GAN loss = [2.9627857, 1.0352052, 1.1303462]\n",
      "Batch 2/700: Discriminator loss = 1.170333981513977, GAN loss = [2.991972, 0.99892557, 1.1958447]\n",
      "Batch 3/700: Discriminator loss = 1.1349072456359863, GAN loss = [3.0123782, 1.0239706, 1.1912358]\n",
      "Batch 4/700: Discriminator loss = 1.1721069812774658, GAN loss = [3.1613212, 1.0136927, 1.3504877]\n",
      "Batch 5/700: Discriminator loss = 1.1800134181976318, GAN loss = [2.8825114, 1.0431077, 1.0422921]\n",
      "Batch 6/700: Discriminator loss = 1.1249140501022339, GAN loss = [3.0929065, 1.0688182, 1.2270101]\n",
      "Batch 7/700: Discriminator loss = 1.1216106414794922, GAN loss = [3.250772, 1.0593152, 1.3944153]\n",
      "Batch 8/700: Discriminator loss = 1.1160145998001099, GAN loss = [3.0884683, 1.0834233, 1.2080344]\n",
      "Batch 9/700: Discriminator loss = 1.114284873008728, GAN loss = [3.043243, 1.040412, 1.2058516]\n",
      "Batch 10/700: Discriminator loss = 1.1639138460159302, GAN loss = [3.0613086, 1.0214701, 1.242893]\n",
      "Batch 11/700: Discriminator loss = 1.1456581354141235, GAN loss = [2.9830117, 1.0434815, 1.1426139]\n",
      "Batch 12/700: Discriminator loss = 1.136032223701477, GAN loss = [2.9325943, 1.0728517, 1.0628587]\n",
      "Batch 13/700: Discriminator loss = 1.1297260522842407, GAN loss = [3.0348887, 1.0796859, 1.1583529]\n",
      "Batch 14/700: Discriminator loss = 1.1369390487670898, GAN loss = [2.9429355, 1.0216389, 1.1244787]\n",
      "Batch 15/700: Discriminator loss = 1.1293424367904663, GAN loss = [3.0490527, 1.050329, 1.2019404]\n",
      "Batch 16/700: Discriminator loss = 1.1287280321121216, GAN loss = [3.1420672, 1.0710957, 1.2742169]\n",
      "Batch 17/700: Discriminator loss = 1.139785647392273, GAN loss = [3.033371, 1.0476103, 1.1890335]\n",
      "Batch 18/700: Discriminator loss = 1.1511576175689697, GAN loss = [3.026236, 1.0479082, 1.1816403]\n",
      "Batch 19/700: Discriminator loss = 1.1407023668289185, GAN loss = [3.0634108, 1.0527048, 1.2140572]\n",
      "Batch 20/700: Discriminator loss = 1.1502411365509033, GAN loss = [3.0421827, 1.0172442, 1.2283239]\n",
      "Batch 21/700: Discriminator loss = 1.1580333709716797, GAN loss = [2.9539165, 1.0329789, 1.1243601]\n",
      "Batch 22/700: Discriminator loss = 1.1714248657226562, GAN loss = [2.9973423, 1.050101, 1.1506989]\n",
      "Batch 23/700: Discriminator loss = 1.167084813117981, GAN loss = [2.9091043, 1.0172383, 1.0953525]\n",
      "Batch 24/700: Discriminator loss = 1.1713346242904663, GAN loss = [2.9931772, 1.0448886, 1.1518065]\n",
      "Batch 25/700: Discriminator loss = 1.1901251077651978, GAN loss = [2.870127, 0.99957675, 1.0740994]\n",
      "Batch 26/700: Discriminator loss = 1.1115772724151611, GAN loss = [3.143536, 1.0644182, 1.2826935]\n",
      "Batch 27/700: Discriminator loss = 1.162184715270996, GAN loss = [2.9729915, 1.0240496, 1.1525472]\n",
      "Batch 28/700: Discriminator loss = 1.1627131700515747, GAN loss = [3.0103571, 1.0687181, 1.1452739]\n",
      "Batch 29/700: Discriminator loss = 1.2116516828536987, GAN loss = [2.8143623, 0.980618, 1.0374041]\n",
      "Batch 30/700: Discriminator loss = 1.1522881984710693, GAN loss = [2.924445, 1.0451086, 1.0830204]\n",
      "Batch 31/700: Discriminator loss = 1.1593488454818726, GAN loss = [3.0016437, 1.0202252, 1.185131]\n",
      "Batch 32/700: Discriminator loss = 1.1816273927688599, GAN loss = [2.7709007, 0.98272234, 0.99191386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 33/700: Discriminator loss = 1.1410654783248901, GAN loss = [2.8525593, 1.0282445, 1.0280674]\n",
      "Batch 34/700: Discriminator loss = 1.1339120864868164, GAN loss = [3.056331, 1.0565368, 1.2035714]\n",
      "Batch 35/700: Discriminator loss = 1.2355762720108032, GAN loss = [2.7880044, 0.9988065, 0.99300104]\n",
      "Batch 36/700: Discriminator loss = 1.1388846635818481, GAN loss = [2.9459524, 1.0537639, 1.0960188]\n",
      "Batch 37/700: Discriminator loss = 1.1365060806274414, GAN loss = [3.0274992, 1.0665864, 1.1647692]\n",
      "Batch 38/700: Discriminator loss = 1.1364624500274658, GAN loss = [2.9733524, 1.0609729, 1.1162683]\n",
      "Batch 39/700: Discriminator loss = 1.199522614479065, GAN loss = [2.929753, 1.0263684, 1.1073033]\n",
      "Batch 40/700: Discriminator loss = 1.1548452377319336, GAN loss = [2.9713416, 1.1011277, 1.0741472]\n",
      "Batch 41/700: Discriminator loss = 1.1417516469955444, GAN loss = [2.9059958, 1.054159, 1.0557892]\n",
      "Batch 42/700: Discriminator loss = 1.1338744163513184, GAN loss = [2.9100068, 1.0435665, 1.070409]\n",
      "Batch 43/700: Discriminator loss = 1.1368424892425537, GAN loss = [2.8495872, 1.0688505, 0.9847248]\n",
      "Batch 44/700: Discriminator loss = 1.1687315702438354, GAN loss = [2.9831886, 1.0636879, 1.1235093]\n",
      "Batch 45/700: Discriminator loss = 1.148385763168335, GAN loss = [2.9124508, 1.0754817, 1.0409989]\n",
      "Batch 46/700: Discriminator loss = 1.1518300771713257, GAN loss = [2.8961725, 1.0067118, 1.0935159]\n",
      "Batch 47/700: Discriminator loss = 1.1572082042694092, GAN loss = [2.9937797, 1.041167, 1.156687]\n",
      "Batch 48/700: Discriminator loss = 1.134412407875061, GAN loss = [3.0229237, 1.0746057, 1.1524128]\n",
      "Batch 49/700: Discriminator loss = 1.1674740314483643, GAN loss = [2.921075, 1.046515, 1.078674]\n",
      "Batch 50/700: Discriminator loss = 1.131882905960083, GAN loss = [2.936959, 1.0489193, 1.0921687]\n",
      "Batch 51/700: Discriminator loss = 1.1548247337341309, GAN loss = [3.013891, 1.0413244, 1.1767228]\n",
      "Batch 52/700: Discriminator loss = 1.1277143955230713, GAN loss = [2.8553028, 1.0423154, 1.017173]\n",
      "Batch 53/700: Discriminator loss = 1.1652437448501587, GAN loss = [2.8781328, 1.0415117, 1.0408332]\n",
      "Batch 54/700: Discriminator loss = 1.1349133253097534, GAN loss = [2.891303, 1.0459367, 1.0496126]\n",
      "Batch 55/700: Discriminator loss = 1.0976498126983643, GAN loss = [3.073893, 1.0998876, 1.1782874]\n",
      "Batch 56/700: Discriminator loss = 1.1348906755447388, GAN loss = [2.8558464, 1.0574623, 1.0026889]\n",
      "Batch 57/700: Discriminator loss = 1.1392946243286133, GAN loss = [3.0149355, 1.0335801, 1.1856846]\n",
      "Batch 58/700: Discriminator loss = 1.13357675075531, GAN loss = [3.0047543, 1.0771652, 1.1319381]\n",
      "Batch 59/700: Discriminator loss = 1.1301087141036987, GAN loss = [2.979742, 1.0422332, 1.141879]\n",
      "Batch 60/700: Discriminator loss = 1.0984939336776733, GAN loss = [3.0363007, 1.0943348, 1.1463643]\n",
      "Batch 61/700: Discriminator loss = 1.1433042287826538, GAN loss = [2.9387248, 1.0093774, 1.1337734]\n",
      "Batch 62/700: Discriminator loss = 1.132351279258728, GAN loss = [2.97643, 1.0462632, 1.134621]\n",
      "Batch 63/700: Discriminator loss = 1.151346206665039, GAN loss = [2.8539898, 1.0275365, 1.0309311]\n",
      "Batch 64/700: Discriminator loss = 1.1446533203125, GAN loss = [3.0402799, 1.0459344, 1.1988553]\n",
      "Batch 65/700: Discriminator loss = 1.1531637907028198, GAN loss = [2.9139245, 1.030938, 1.0875267]\n",
      "Batch 66/700: Discriminator loss = 1.1561557054519653, GAN loss = [2.868701, 1.0302004, 1.043068]\n",
      "Batch 67/700: Discriminator loss = 1.1762624979019165, GAN loss = [2.9898632, 1.0484765, 1.1459837]\n",
      "Batch 68/700: Discriminator loss = 1.115564227104187, GAN loss = [2.8971946, 1.0889436, 1.0128897]\n",
      "Batch 69/700: Discriminator loss = 1.116734504699707, GAN loss = [2.9961896, 1.0773371, 1.1235396]\n",
      "Batch 70/700: Discriminator loss = 1.104274034500122, GAN loss = [3.0219076, 1.070747, 1.1558874]\n",
      "Batch 71/700: Discriminator loss = 1.175266981124878, GAN loss = [3.0036068, 1.0279965, 1.180377]\n",
      "Batch 72/700: Discriminator loss = 1.1424015760421753, GAN loss = [2.9816802, 1.0732152, 1.1132655]\n",
      "Batch 73/700: Discriminator loss = 1.1349332332611084, GAN loss = [3.0926504, 1.1262553, 1.1712246]\n",
      "Batch 74/700: Discriminator loss = 1.140546441078186, GAN loss = [2.8853712, 1.0652056, 1.0250337]\n",
      "Batch 75/700: Discriminator loss = 1.1215128898620605, GAN loss = [2.9295228, 1.0823131, 1.0521142]\n",
      "Batch 76/700: Discriminator loss = 1.108393907546997, GAN loss = [2.9727297, 1.0892339, 1.0884335]\n",
      "Batch 77/700: Discriminator loss = 1.1458930969238281, GAN loss = [2.91437, 1.0575708, 1.0617713]\n",
      "Batch 78/700: Discriminator loss = 1.1525630950927734, GAN loss = [3.024633, 1.0369314, 1.1927112]\n",
      "Batch 79/700: Discriminator loss = 1.16642165184021, GAN loss = [2.9673953, 1.0369161, 1.1355199]\n",
      "Batch 80/700: Discriminator loss = 1.1348042488098145, GAN loss = [3.0382273, 1.0713383, 1.171967]\n",
      "Batch 81/700: Discriminator loss = 1.117249846458435, GAN loss = [3.0561824, 1.0669761, 1.1943203]\n",
      "Batch 82/700: Discriminator loss = 1.0790618658065796, GAN loss = [3.0741313, 1.1106626, 1.1686215]\n",
      "Batch 83/700: Discriminator loss = 1.1373008489608765, GAN loss = [3.045672, 1.0675838, 1.1832772]\n",
      "Batch 84/700: Discriminator loss = 1.1197271347045898, GAN loss = [2.9957118, 1.0676702, 1.1332666]\n",
      "Batch 85/700: Discriminator loss = 1.103358507156372, GAN loss = [3.0731876, 1.0725845, 1.2058585]\n",
      "Batch 86/700: Discriminator loss = 1.1576719284057617, GAN loss = [2.9357834, 1.0455118, 1.0955594]\n",
      "Batch 87/700: Discriminator loss = 1.1365845203399658, GAN loss = [3.0861895, 1.0528692, 1.2386463]\n",
      "Batch 88/700: Discriminator loss = 1.1566847562789917, GAN loss = [2.9325104, 1.0122695, 1.1256044]\n",
      "Batch 89/700: Discriminator loss = 1.1252772808074951, GAN loss = [3.0464246, 1.0379959, 1.2138317]\n",
      "Batch 90/700: Discriminator loss = 1.1124491691589355, GAN loss = [3.1372116, 1.0809284, 1.2617197]\n",
      "Batch 91/700: Discriminator loss = 1.1363025903701782, GAN loss = [2.9741025, 1.0358295, 1.143753]\n",
      "Batch 92/700: Discriminator loss = 1.1856313943862915, GAN loss = [3.0082998, 1.0322613, 1.1815599]\n",
      "Batch 93/700: Discriminator loss = 1.1628113985061646, GAN loss = [2.9892104, 1.0269386, 1.1678317]\n",
      "Batch 94/700: Discriminator loss = 1.2168885469436646, GAN loss = [3.0039551, 0.988903, 1.2206348]\n",
      "Batch 95/700: Discriminator loss = 1.1414731740951538, GAN loss = [2.9490557, 1.0366652, 1.1180056]\n",
      "Batch 96/700: Discriminator loss = 1.114518404006958, GAN loss = [2.9393494, 1.0405626, 1.1044327]\n",
      "Batch 97/700: Discriminator loss = 1.147335171699524, GAN loss = [2.923661, 1.0438119, 1.0855163]\n",
      "Batch 98/700: Discriminator loss = 1.1642987728118896, GAN loss = [3.0394568, 1.0528511, 1.1922932]\n",
      "Batch 99/700: Discriminator loss = 1.119368076324463, GAN loss = [3.0298615, 1.0684128, 1.1671644]\n",
      "Batch 100/700: Discriminator loss = 1.1074492931365967, GAN loss = [3.0438826, 1.0601318, 1.1894829]\n",
      "Batch 101/700: Discriminator loss = 1.1300603151321411, GAN loss = [3.1559079, 1.0637772, 1.2978932]\n",
      "Batch 102/700: Discriminator loss = 1.1210483312606812, GAN loss = [3.1084852, 1.0692515, 1.245026]\n",
      "Batch 103/700: Discriminator loss = 1.161765694618225, GAN loss = [3.0302591, 1.047157, 1.1889329]\n",
      "Batch 104/700: Discriminator loss = 1.1829259395599365, GAN loss = [2.9412882, 1.0225208, 1.1246363]\n",
      "Batch 105/700: Discriminator loss = 1.1028953790664673, GAN loss = [3.051667, 1.0737662, 1.1838002]\n",
      "Batch 106/700: Discriminator loss = 1.106029987335205, GAN loss = [3.0678804, 1.0570694, 1.2167426]\n",
      "Batch 107/700: Discriminator loss = 1.1432387828826904, GAN loss = [3.0865526, 1.0350856, 1.2574288]\n",
      "Batch 108/700: Discriminator loss = 1.1743379831314087, GAN loss = [2.9031808, 1.0556601, 1.0535188]\n",
      "Batch 109/700: Discriminator loss = 1.1337611675262451, GAN loss = [3.0324292, 1.0327013, 1.2057701]\n",
      "Batch 110/700: Discriminator loss = 1.1707658767700195, GAN loss = [3.070604, 1.0167409, 1.2599423]\n",
      "Batch 111/700: Discriminator loss = 1.1281012296676636, GAN loss = [2.9938524, 1.1052556, 1.0947182]\n",
      "Batch 112/700: Discriminator loss = 1.141831398010254, GAN loss = [3.0800757, 1.0173908, 1.2688514]\n",
      "Batch 113/700: Discriminator loss = 1.1342191696166992, GAN loss = [3.2705564, 1.0680459, 1.4087269]\n",
      "Batch 114/700: Discriminator loss = 1.1873655319213867, GAN loss = [2.9945304, 1.0105293, 1.1902524]\n",
      "Batch 115/700: Discriminator loss = 1.1061286926269531, GAN loss = [3.183264, 1.0980376, 1.2915254]\n",
      "Batch 116/700: Discriminator loss = 1.094300627708435, GAN loss = [3.1493936, 1.0789347, 1.2768058]\n",
      "Batch 117/700: Discriminator loss = 1.1235485076904297, GAN loss = [3.0763729, 1.0708103, 1.211943]\n",
      "Batch 118/700: Discriminator loss = 1.1421444416046143, GAN loss = [3.0777998, 1.0585012, 1.2257307]\n",
      "Batch 119/700: Discriminator loss = 1.097656488418579, GAN loss = [3.2276103, 1.1148783, 1.3192127]\n",
      "Batch 120/700: Discriminator loss = 1.104230284690857, GAN loss = [3.0303683, 1.0612588, 1.175645]\n",
      "Batch 121/700: Discriminator loss = 1.13612699508667, GAN loss = [3.1864922, 1.0435225, 1.3495636]\n",
      "Batch 122/700: Discriminator loss = 1.1412839889526367, GAN loss = [3.0367444, 1.0563799, 1.1870055]\n",
      "Batch 123/700: Discriminator loss = 1.1412850618362427, GAN loss = [2.9158428, 1.0273058, 1.0952139]\n",
      "Batch 124/700: Discriminator loss = 1.1138097047805786, GAN loss = [3.0811348, 1.0850564, 1.2027887]\n",
      "Batch 125/700: Discriminator loss = 1.1261826753616333, GAN loss = [3.028617, 1.0457721, 1.1895955]\n",
      "Batch 126/700: Discriminator loss = 1.227254033088684, GAN loss = [3.0906422, 1.0265481, 1.2708936]\n",
      "Batch 127/700: Discriminator loss = 1.1630010604858398, GAN loss = [2.9699836, 1.0686871, 1.10814]\n",
      "Batch 128/700: Discriminator loss = 1.1423499584197998, GAN loss = [2.9406343, 1.0567431, 1.0907786]\n",
      "Batch 129/700: Discriminator loss = 1.166502594947815, GAN loss = [2.9373276, 1.0422435, 1.1020142]\n",
      "Batch 130/700: Discriminator loss = 1.1555038690567017, GAN loss = [3.0476289, 1.0513318, 1.2032714]\n",
      "Batch 131/700: Discriminator loss = 1.1786668300628662, GAN loss = [2.9478772, 1.0262406, 1.128659]\n",
      "Batch 132/700: Discriminator loss = 1.1748474836349487, GAN loss = [3.0491984, 1.0766257, 1.1796489]\n",
      "Batch 133/700: Discriminator loss = 1.163578748703003, GAN loss = [3.083731, 1.0497783, 1.241082]\n",
      "Batch 134/700: Discriminator loss = 1.1434743404388428, GAN loss = [2.8804226, 1.0468903, 1.0407104]\n",
      "Batch 135/700: Discriminator loss = 1.1688487529754639, GAN loss = [2.9234138, 1.0394294, 1.0912166]\n",
      "Batch 136/700: Discriminator loss = 1.1664025783538818, GAN loss = [3.0406911, 1.0532053, 1.1947572]\n",
      "Batch 137/700: Discriminator loss = 1.1332168579101562, GAN loss = [3.131775, 1.0792882, 1.2597958]\n",
      "Batch 138/700: Discriminator loss = 1.1396183967590332, GAN loss = [2.9828188, 1.0340102, 1.1561586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 139/700: Discriminator loss = 1.1548445224761963, GAN loss = [3.056455, 1.0213172, 1.2425244]\n",
      "Batch 140/700: Discriminator loss = 1.1726324558258057, GAN loss = [3.0059414, 1.0444046, 1.1689528]\n",
      "Batch 141/700: Discriminator loss = 1.160894513130188, GAN loss = [3.0240078, 1.0259124, 1.2055409]\n",
      "Batch 142/700: Discriminator loss = 1.1813961267471313, GAN loss = [2.9272196, 1.0487987, 1.0859028]\n",
      "Batch 143/700: Discriminator loss = 1.1610666513442993, GAN loss = [3.043186, 1.0432991, 1.2073992]\n",
      "Batch 144/700: Discriminator loss = 1.154533863067627, GAN loss = [3.0040977, 1.0917243, 1.1199124]\n",
      "Batch 145/700: Discriminator loss = 1.1966900825500488, GAN loss = [2.8564792, 1.0312088, 1.0328468]\n",
      "Batch 146/700: Discriminator loss = 1.1341286897659302, GAN loss = [2.8349338, 1.0185249, 1.0240189]\n",
      "Batch 147/700: Discriminator loss = 1.1925171613693237, GAN loss = [2.851275, 0.98249465, 1.0764244]\n",
      "Batch 148/700: Discriminator loss = 1.1577749252319336, GAN loss = [2.9843838, 1.0632242, 1.1288303]\n",
      "Batch 149/700: Discriminator loss = 1.1409929990768433, GAN loss = [2.9858463, 1.081985, 1.1115664]\n",
      "Batch 150/700: Discriminator loss = 1.1878843307495117, GAN loss = [2.8875074, 1.070005, 1.0252507]\n",
      "Batch 151/700: Discriminator loss = 1.118110179901123, GAN loss = [3.0795157, 1.0733654, 1.2139472]\n",
      "Batch 152/700: Discriminator loss = 1.1500283479690552, GAN loss = [2.9990437, 1.0263308, 1.1805542]\n",
      "Batch 153/700: Discriminator loss = 1.175255298614502, GAN loss = [2.8859813, 1.0047848, 1.0890794]\n",
      "Batch 154/700: Discriminator loss = 1.1214019060134888, GAN loss = [3.0190568, 1.0579165, 1.1690595]\n",
      "Batch 155/700: Discriminator loss = 1.1640169620513916, GAN loss = [2.854709, 1.0254427, 1.0372106]\n",
      "Batch 156/700: Discriminator loss = 1.1373834609985352, GAN loss = [2.9632325, 1.0656962, 1.1055188]\n",
      "Batch 157/700: Discriminator loss = 1.1352640390396118, GAN loss = [2.9010825, 1.0524144, 1.0566938]\n",
      "Batch 158/700: Discriminator loss = 1.1416499614715576, GAN loss = [2.9628377, 1.0747542, 1.096147]\n",
      "Batch 159/700: Discriminator loss = 1.1933250427246094, GAN loss = [2.7744057, 1.023592, 0.958927]\n",
      "Batch 160/700: Discriminator loss = 1.178506851196289, GAN loss = [2.920179, 1.0234869, 1.1048487]\n",
      "Batch 161/700: Discriminator loss = 1.1204757690429688, GAN loss = [2.974349, 1.0454965, 1.1370481]\n",
      "Batch 162/700: Discriminator loss = 1.1624023914337158, GAN loss = [2.9009633, 1.0087792, 1.100412]\n",
      "Batch 163/700: Discriminator loss = 1.1483272314071655, GAN loss = [2.9219751, 1.046223, 1.0840236]\n",
      "Batch 164/700: Discriminator loss = 1.1540000438690186, GAN loss = [2.8771458, 1.0069882, 1.0784694]\n",
      "Batch 165/700: Discriminator loss = 1.1805765628814697, GAN loss = [2.9422626, 1.007391, 1.1432171]\n",
      "Batch 166/700: Discriminator loss = 1.1402264833450317, GAN loss = [2.9944434, 1.0431328, 1.1596946]\n",
      "Batch 167/700: Discriminator loss = 1.1168617010116577, GAN loss = [3.0075905, 1.0496792, 1.1663306]\n",
      "Batch 168/700: Discriminator loss = 1.2130579948425293, GAN loss = [2.987255, 0.99388117, 1.2018379]\n",
      "Batch 169/700: Discriminator loss = 1.2016921043395996, GAN loss = [2.7276852, 1.0110489, 0.92513585]\n",
      "Batch 170/700: Discriminator loss = 1.1873774528503418, GAN loss = [2.9256573, 0.9944659, 1.1397328]\n",
      "Batch 171/700: Discriminator loss = 1.14131498336792, GAN loss = [2.9694352, 1.0329837, 1.1450344]\n",
      "Batch 172/700: Discriminator loss = 1.1874847412109375, GAN loss = [2.891096, 1.0175622, 1.0821606]\n",
      "Batch 173/700: Discriminator loss = 1.1655094623565674, GAN loss = [2.874995, 1.0057023, 1.0779552]\n",
      "Batch 174/700: Discriminator loss = 1.1254866123199463, GAN loss = [3.1141653, 1.065268, 1.2575868]\n",
      "Batch 175/700: Discriminator loss = 1.2169601917266846, GAN loss = [2.8542423, 0.97467685, 1.0882782]\n",
      "Batch 176/700: Discriminator loss = 1.19087815284729, GAN loss = [2.8106778, 0.97115296, 1.0482761]\n",
      "Batch 177/700: Discriminator loss = 1.210417628288269, GAN loss = [2.8509586, 0.9506333, 1.109122]\n",
      "Batch 178/700: Discriminator loss = 1.1509536504745483, GAN loss = [3.0029466, 1.0088314, 1.202947]\n",
      "Batch 179/700: Discriminator loss = 1.1746208667755127, GAN loss = [2.9805477, 0.99110854, 1.1983039]\n",
      "Batch 180/700: Discriminator loss = 1.1642038822174072, GAN loss = [2.7901258, 0.99691284, 1.0021067]\n",
      "Batch 181/700: Discriminator loss = 1.172423005104065, GAN loss = [3.1293418, 1.0224581, 1.3158079]\n",
      "Batch 182/700: Discriminator loss = 1.1669976711273193, GAN loss = [2.9744895, 1.0147166, 1.1687279]\n",
      "Batch 183/700: Discriminator loss = 1.1804198026657104, GAN loss = [2.7843316, 0.9931398, 1.0001819]\n",
      "Batch 184/700: Discriminator loss = 1.142216682434082, GAN loss = [2.9688203, 1.0373702, 1.140475]\n",
      "Batch 185/700: Discriminator loss = 1.2010902166366577, GAN loss = [2.9240088, 0.9826826, 1.1503804]\n",
      "Batch 186/700: Discriminator loss = 1.2013497352600098, GAN loss = [2.9241397, 0.9858879, 1.1473317]\n",
      "Batch 187/700: Discriminator loss = 1.1593008041381836, GAN loss = [2.7451506, 1.0079772, 0.94628584]\n",
      "Batch 188/700: Discriminator loss = 1.1714164018630981, GAN loss = [2.9018598, 0.98557276, 1.1254342]\n",
      "Batch 189/700: Discriminator loss = 1.1694979667663574, GAN loss = [3.0675657, 1.0000001, 1.2767442]\n",
      "Batch 190/700: Discriminator loss = 1.181951642036438, GAN loss = [2.8232968, 0.9817961, 1.0507126]\n",
      "Batch 191/700: Discriminator loss = 1.1630473136901855, GAN loss = [2.9969306, 1.0198461, 1.1863313]\n",
      "Batch 192/700: Discriminator loss = 1.1668654680252075, GAN loss = [2.8412838, 1.0287303, 1.0218385]\n",
      "Batch 193/700: Discriminator loss = 1.1325805187225342, GAN loss = [2.8581955, 1.0101398, 1.0573772]\n",
      "Batch 194/700: Discriminator loss = 1.165754795074463, GAN loss = [2.8963823, 1.005733, 1.0999908]\n",
      "Batch 195/700: Discriminator loss = 1.1793217658996582, GAN loss = [3.0063117, 0.9902291, 1.225449]\n",
      "Batch 196/700: Discriminator loss = 1.1467851400375366, GAN loss = [2.9678502, 1.0277576, 1.1494927]\n",
      "Batch 197/700: Discriminator loss = 1.1244840621948242, GAN loss = [2.9365842, 1.0445324, 1.1014866]\n",
      "Batch 198/700: Discriminator loss = 1.1687278747558594, GAN loss = [2.9795532, 0.98049647, 1.2085159]\n",
      "Batch 199/700: Discriminator loss = 1.1681368350982666, GAN loss = [2.9596176, 0.99921167, 1.1698902]\n",
      "Batch 200/700: Discriminator loss = 1.1494503021240234, GAN loss = [2.9648843, 1.0049081, 1.169486]\n",
      "Batch 201/700: Discriminator loss = 1.212501049041748, GAN loss = [2.7370367, 0.9424561, 1.0041178]\n",
      "Batch 202/700: Discriminator loss = 1.214456558227539, GAN loss = [2.8507164, 0.9956659, 1.0646185]\n",
      "Batch 203/700: Discriminator loss = 1.1785273551940918, GAN loss = [2.7895741, 0.96902394, 1.030154]\n",
      "Batch 204/700: Discriminator loss = 1.163652777671814, GAN loss = [2.8287742, 0.988141, 1.050272]\n",
      "Batch 205/700: Discriminator loss = 1.1536790132522583, GAN loss = [2.8573282, 0.9815301, 1.0854667]\n",
      "Batch 206/700: Discriminator loss = 1.2353527545928955, GAN loss = [2.6658988, 0.93262637, 0.9429678]\n",
      "Batch 207/700: Discriminator loss = 1.1635843515396118, GAN loss = [2.943365, 1.0079315, 1.1451635]\n",
      "Batch 208/700: Discriminator loss = 1.1735848188400269, GAN loss = [2.8140085, 0.98127794, 1.0425051]\n",
      "Batch 209/700: Discriminator loss = 1.1731891632080078, GAN loss = [2.811638, 0.9792235, 1.0422382]\n",
      "Batch 210/700: Discriminator loss = 1.1809816360473633, GAN loss = [2.9228206, 0.95038384, 1.1823038]\n",
      "Batch 211/700: Discriminator loss = 1.2079657316207886, GAN loss = [2.7895174, 0.94936675, 1.0500584]\n",
      "Batch 212/700: Discriminator loss = 1.194624423980713, GAN loss = [2.7921782, 0.9735895, 1.0285267]\n",
      "Batch 213/700: Discriminator loss = 1.1760753393173218, GAN loss = [2.8523757, 0.97408235, 1.0882547]\n",
      "Batch 214/700: Discriminator loss = 1.173781394958496, GAN loss = [2.8453596, 0.96567506, 1.089669]\n",
      "Batch 215/700: Discriminator loss = 1.1942601203918457, GAN loss = [2.7477312, 0.95260406, 1.0051415]\n",
      "Batch 216/700: Discriminator loss = 1.1616424322128296, GAN loss = [2.8194866, 0.97865105, 1.0508804]\n",
      "Batch 217/700: Discriminator loss = 1.1755439043045044, GAN loss = [2.7699883, 0.9723115, 1.0077486]\n",
      "Batch 218/700: Discriminator loss = 1.180788278579712, GAN loss = [2.8253996, 0.9831324, 1.0523725]\n",
      "Batch 219/700: Discriminator loss = 1.188414454460144, GAN loss = [2.729688, 0.94580114, 0.99403006]\n",
      "Batch 220/700: Discriminator loss = 1.2078375816345215, GAN loss = [2.7110062, 0.9497873, 0.97139907]\n",
      "Batch 221/700: Discriminator loss = 1.2276523113250732, GAN loss = [2.7911093, 0.92607903, 1.0752504]\n",
      "Batch 222/700: Discriminator loss = 1.158501148223877, GAN loss = [2.8268933, 0.96621466, 1.070924]\n",
      "Batch 223/700: Discriminator loss = 1.186248540878296, GAN loss = [2.8441248, 0.9583606, 1.0960374]\n",
      "Batch 224/700: Discriminator loss = 1.2086031436920166, GAN loss = [2.7266011, 0.9422303, 0.99466777]\n",
      "Batch 225/700: Discriminator loss = 1.1751821041107178, GAN loss = [2.789532, 0.9858981, 1.0139534]\n",
      "Batch 226/700: Discriminator loss = 1.2071977853775024, GAN loss = [2.7760482, 0.93367904, 1.0527052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 227/700: Discriminator loss = 1.2248262166976929, GAN loss = [2.8352911, 0.92247534, 1.123165]\n",
      "Batch 228/700: Discriminator loss = 1.180949330329895, GAN loss = [2.7819602, 0.9767969, 1.0155308]\n",
      "Batch 229/700: Discriminator loss = 1.2266265153884888, GAN loss = [2.7693596, 0.9353273, 1.0444195]\n",
      "Batch 230/700: Discriminator loss = 1.185757040977478, GAN loss = [2.6959317, 1.0021882, 0.9041614]\n",
      "Batch 231/700: Discriminator loss = 1.2204915285110474, GAN loss = [2.7767727, 0.9616738, 1.0255494]\n",
      "Batch 232/700: Discriminator loss = 1.2129311561584473, GAN loss = [2.7267134, 0.9486844, 0.988515]\n",
      "Batch 233/700: Discriminator loss = 1.189615249633789, GAN loss = [2.7716532, 0.9603226, 1.0218472]\n",
      "Batch 234/700: Discriminator loss = 1.1590094566345215, GAN loss = [2.7687087, 1.0165898, 0.96266335]\n",
      "Batch 235/700: Discriminator loss = 1.2204551696777344, GAN loss = [2.7665925, 0.9433097, 1.0338495]\n",
      "Batch 236/700: Discriminator loss = 1.2469233274459839, GAN loss = [2.7411602, 0.94167656, 1.0100743]\n",
      "Batch 237/700: Discriminator loss = 1.2201437950134277, GAN loss = [2.7140455, 0.9633487, 0.9613117]\n",
      "Batch 238/700: Discriminator loss = 1.2018921375274658, GAN loss = [2.710819, 0.9773112, 0.94414407]\n",
      "Batch 239/700: Discriminator loss = 1.1657569408416748, GAN loss = [2.8027124, 0.99001336, 1.0233573]\n",
      "Batch 240/700: Discriminator loss = 1.2469784021377563, GAN loss = [2.7118618, 0.9215524, 1.0009952]\n",
      "Batch 241/700: Discriminator loss = 1.188288688659668, GAN loss = [2.7873223, 0.9827071, 1.0153325]\n",
      "Batch 242/700: Discriminator loss = 1.195578932762146, GAN loss = [2.707624, 0.9584415, 0.95992875]\n",
      "Batch 243/700: Discriminator loss = 1.198351263999939, GAN loss = [2.744775, 0.9665687, 0.9889834]\n",
      "Batch 244/700: Discriminator loss = 1.2019630670547485, GAN loss = [2.674352, 0.9606061, 0.9245535]\n",
      "Batch 245/700: Discriminator loss = 1.1884965896606445, GAN loss = [2.7733216, 0.9675754, 1.0165825]\n",
      "Batch 246/700: Discriminator loss = 1.1788623332977295, GAN loss = [2.7784162, 0.9940031, 0.99527514]\n",
      "Batch 247/700: Discriminator loss = 1.1499426364898682, GAN loss = [2.7414134, 0.99804145, 0.9542743]\n",
      "Batch 248/700: Discriminator loss = 1.2124372720718384, GAN loss = [2.752925, 0.94847697, 1.0153844]\n",
      "Batch 249/700: Discriminator loss = 1.2075737714767456, GAN loss = [2.6935859, 0.969511, 0.9350517]\n",
      "Batch 250/700: Discriminator loss = 1.1398378610610962, GAN loss = [2.8207076, 0.9841417, 1.0475776]\n",
      "Batch 251/700: Discriminator loss = 1.1866183280944824, GAN loss = [2.6906688, 0.9466954, 0.9550141]\n",
      "Batch 252/700: Discriminator loss = 1.1755701303482056, GAN loss = [2.759747, 0.9603917, 1.0104338]\n",
      "Batch 253/700: Discriminator loss = 1.1421643495559692, GAN loss = [2.832341, 0.9830394, 1.06042]\n",
      "Batch 254/700: Discriminator loss = 1.148458480834961, GAN loss = [2.7358708, 0.97244126, 0.9745947]\n",
      "Batch 255/700: Discriminator loss = 1.18723464012146, GAN loss = [2.7755103, 0.9737217, 1.0129973]\n",
      "Batch 256/700: Discriminator loss = 1.1481521129608154, GAN loss = [2.706871, 0.98286337, 0.9352507]\n",
      "Batch 257/700: Discriminator loss = 1.1212892532348633, GAN loss = [2.7951586, 1.0075598, 0.99887687]\n",
      "Batch 258/700: Discriminator loss = 1.1796586513519287, GAN loss = [2.718662, 0.94289917, 0.9870788]\n",
      "Batch 259/700: Discriminator loss = 1.1505190134048462, GAN loss = [2.7867, 0.98010665, 1.0179428]\n",
      "Batch 260/700: Discriminator loss = 1.1427931785583496, GAN loss = [2.7972782, 0.9777101, 1.030955]\n",
      "Batch 261/700: Discriminator loss = 1.1970264911651611, GAN loss = [2.7434077, 0.957472, 0.997366]\n",
      "Batch 262/700: Discriminator loss = 1.1395864486694336, GAN loss = [2.82907, 1.0104871, 1.0300556]\n",
      "Batch 263/700: Discriminator loss = 1.1542302370071411, GAN loss = [2.795023, 0.9978646, 1.0086675]\n",
      "Batch 264/700: Discriminator loss = 1.1814154386520386, GAN loss = [2.765815, 0.9732618, 1.0041028]\n",
      "Batch 265/700: Discriminator loss = 1.153296709060669, GAN loss = [2.8149388, 0.99383485, 1.0326878]\n",
      "Batch 266/700: Discriminator loss = 1.1664506196975708, GAN loss = [2.7913961, 0.9652446, 1.0377595]\n",
      "Batch 267/700: Discriminator loss = 1.1695184707641602, GAN loss = [2.754406, 0.97698957, 0.9890428]\n",
      "Batch 268/700: Discriminator loss = 1.1645113229751587, GAN loss = [2.7829118, 0.9703979, 1.0241634]\n",
      "Batch 269/700: Discriminator loss = 1.2007380723953247, GAN loss = [2.7709222, 0.94281197, 1.0397713]\n",
      "Batch 270/700: Discriminator loss = 1.2013641595840454, GAN loss = [2.761287, 0.95327115, 1.0197014]\n",
      "Batch 271/700: Discriminator loss = 1.2094461917877197, GAN loss = [2.705801, 0.95135, 0.9661691]\n",
      "Batch 272/700: Discriminator loss = 1.1546865701675415, GAN loss = [2.8020718, 0.99441063, 1.019418]\n",
      "Batch 273/700: Discriminator loss = 1.1435182094573975, GAN loss = [2.7823286, 0.9944756, 0.9996471]\n",
      "Batch 274/700: Discriminator loss = 1.168867588043213, GAN loss = [2.7852561, 0.9995379, 0.9975452]\n",
      "Batch 275/700: Discriminator loss = 1.1640626192092896, GAN loss = [2.761292, 0.96273285, 1.0104145]\n",
      "Batch 276/700: Discriminator loss = 1.1730018854141235, GAN loss = [2.799115, 0.96220434, 1.0487918]\n",
      "Batch 277/700: Discriminator loss = 1.178856611251831, GAN loss = [2.772641, 0.97453856, 1.0100113]\n",
      "Batch 278/700: Discriminator loss = 1.159074306488037, GAN loss = [2.8017817, 0.9720383, 1.0416815]\n",
      "Batch 279/700: Discriminator loss = 1.208196997642517, GAN loss = [2.788066, 0.94087243, 1.0591655]\n",
      "Batch 280/700: Discriminator loss = 1.1493682861328125, GAN loss = [2.8731244, 0.9988406, 1.0862881]\n",
      "Batch 281/700: Discriminator loss = 1.2144263982772827, GAN loss = [2.7732818, 0.96952975, 1.0157783]\n",
      "Batch 282/700: Discriminator loss = 1.1591074466705322, GAN loss = [2.9362652, 1.0168387, 1.1314751]\n",
      "Batch 283/700: Discriminator loss = 1.1465975046157837, GAN loss = [2.7947328, 1.0009251, 1.0058955]\n",
      "Batch 284/700: Discriminator loss = 1.1400485038757324, GAN loss = [2.8998036, 1.0222838, 1.0896455]\n",
      "Batch 285/700: Discriminator loss = 1.1502288579940796, GAN loss = [2.8943915, 1.0176812, 1.088882]\n",
      "Batch 286/700: Discriminator loss = 1.173267126083374, GAN loss = [2.8217428, 0.9962366, 1.0377122]\n",
      "Batch 287/700: Discriminator loss = 1.1764347553253174, GAN loss = [2.8065376, 0.9591443, 1.0596247]\n",
      "Batch 288/700: Discriminator loss = 1.1778424978256226, GAN loss = [2.797747, 0.9872987, 1.0227089]\n",
      "Batch 289/700: Discriminator loss = 1.1919339895248413, GAN loss = [2.7964191, 0.95941436, 1.0492995]\n",
      "Batch 290/700: Discriminator loss = 1.1687471866607666, GAN loss = [2.8444512, 0.9855121, 1.0712723]\n",
      "Batch 291/700: Discriminator loss = 1.1703107357025146, GAN loss = [2.6876824, 0.9591514, 0.9408869]\n",
      "Batch 292/700: Discriminator loss = 1.2255911827087402, GAN loss = [2.6459987, 0.91125274, 0.9471206]\n",
      "Batch 293/700: Discriminator loss = 1.1796907186508179, GAN loss = [2.7430058, 0.95851755, 0.9968809]\n",
      "Batch 294/700: Discriminator loss = 1.1490399837493896, GAN loss = [2.8503067, 0.9806855, 1.0820358]\n",
      "Batch 295/700: Discriminator loss = 1.1995131969451904, GAN loss = [2.6275792, 0.9261963, 0.9138063]\n",
      "Batch 296/700: Discriminator loss = 1.2030881643295288, GAN loss = [2.6413138, 0.94296175, 0.91079164]\n",
      "Batch 297/700: Discriminator loss = 1.1488655805587769, GAN loss = [2.7399347, 0.9606841, 0.99170434]\n",
      "Batch 298/700: Discriminator loss = 1.1870962381362915, GAN loss = [2.771174, 0.9281531, 1.0554862]\n",
      "Batch 299/700: Discriminator loss = 1.191792607307434, GAN loss = [2.7333155, 0.9317943, 1.0140058]\n",
      "Batch 300/700: Discriminator loss = 1.171227216720581, GAN loss = [2.725842, 0.94513077, 0.9932172]\n",
      "Batch 301/700: Discriminator loss = 1.1999346017837524, GAN loss = [2.7259724, 0.94633645, 0.9921725]\n",
      "Batch 302/700: Discriminator loss = 1.1794872283935547, GAN loss = [2.7690234, 0.9541347, 1.0274459]\n",
      "Batch 303/700: Discriminator loss = 1.12722647190094, GAN loss = [2.7638278, 0.9802167, 0.9961782]\n",
      "Batch 304/700: Discriminator loss = 1.1934174299240112, GAN loss = [2.8080752, 0.9435936, 1.0770531]\n",
      "Batch 305/700: Discriminator loss = 1.2008980512619019, GAN loss = [2.6632984, 0.9360229, 0.93985635]\n",
      "Batch 306/700: Discriminator loss = 1.1946090459823608, GAN loss = [2.7713263, 0.9579165, 1.0260129]\n",
      "Batch 307/700: Discriminator loss = 1.1991004943847656, GAN loss = [2.7402496, 0.9254419, 1.027427]\n",
      "Batch 308/700: Discriminator loss = 1.142187476158142, GAN loss = [2.8128417, 0.97539335, 1.0500801]\n",
      "Batch 309/700: Discriminator loss = 1.1637341976165771, GAN loss = [2.8096325, 0.9754511, 1.0468283]\n",
      "Batch 310/700: Discriminator loss = 1.1894116401672363, GAN loss = [2.7257288, 0.9374084, 1.0009915]\n",
      "Batch 311/700: Discriminator loss = 1.1628540754318237, GAN loss = [2.7772949, 0.9855216, 1.0044707]\n",
      "Batch 312/700: Discriminator loss = 1.178455114364624, GAN loss = [2.6993983, 0.9531991, 0.95893097]\n",
      "Batch 313/700: Discriminator loss = 1.1543859243392944, GAN loss = [2.7799077, 0.98124987, 1.0114228]\n",
      "Batch 314/700: Discriminator loss = 1.1524908542633057, GAN loss = [2.8917456, 0.99817365, 1.1063617]\n",
      "Batch 315/700: Discriminator loss = 1.1867334842681885, GAN loss = [2.7314548, 0.93289816, 1.0113726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 316/700: Discriminator loss = 1.1692222356796265, GAN loss = [2.6810946, 0.9589753, 0.9349709]\n",
      "Batch 317/700: Discriminator loss = 1.1258488893508911, GAN loss = [2.8124516, 0.987985, 1.0373559]\n",
      "Batch 318/700: Discriminator loss = 1.1636205911636353, GAN loss = [2.7619853, 0.97433, 1.0005823]\n",
      "Batch 319/700: Discriminator loss = 1.1452915668487549, GAN loss = [2.814249, 1.0073069, 1.019903]\n",
      "Batch 320/700: Discriminator loss = 1.1291906833648682, GAN loss = [2.7846582, 1.0227146, 0.97493875]\n",
      "Batch 321/700: Discriminator loss = 1.1534907817840576, GAN loss = [2.8400586, 1.0221171, 1.03097]\n",
      "Batch 322/700: Discriminator loss = 1.1203575134277344, GAN loss = [2.7635865, 1.0059696, 0.9706887]\n",
      "Batch 323/700: Discriminator loss = 1.214468240737915, GAN loss = [2.7121344, 0.9513049, 0.97393936]\n",
      "Batch 324/700: Discriminator loss = 1.1674295663833618, GAN loss = [2.8554983, 0.9606944, 1.1079538]\n",
      "Batch 325/700: Discriminator loss = 1.1658564805984497, GAN loss = [2.813643, 0.9890891, 1.0377359]\n",
      "Batch 326/700: Discriminator loss = 1.1886866092681885, GAN loss = [2.7924573, 0.95008016, 1.0555923]\n",
      "Batch 327/700: Discriminator loss = 1.146311640739441, GAN loss = [2.8039536, 0.968492, 1.04871]\n",
      "Batch 328/700: Discriminator loss = 1.1612918376922607, GAN loss = [2.827158, 0.9572797, 1.0831611]\n",
      "Batch 329/700: Discriminator loss = 1.1501438617706299, GAN loss = [2.8608658, 0.9869537, 1.0872263]\n",
      "Batch 330/700: Discriminator loss = 1.1338917016983032, GAN loss = [2.8845778, 0.98341507, 1.1145066]\n",
      "Batch 331/700: Discriminator loss = 1.1442201137542725, GAN loss = [2.867465, 1.0120444, 1.0687996]\n",
      "Batch 332/700: Discriminator loss = 1.1615647077560425, GAN loss = [2.7035127, 0.9997052, 0.9172232]\n",
      "Batch 333/700: Discriminator loss = 1.162358283996582, GAN loss = [2.9248154, 0.9980681, 1.1402117]\n",
      "Batch 334/700: Discriminator loss = 1.157623291015625, GAN loss = [2.8501334, 0.99489975, 1.068738]\n",
      "Batch 335/700: Discriminator loss = 1.2019997835159302, GAN loss = [2.7168822, 0.92279834, 1.0076144]\n",
      "Batch 336/700: Discriminator loss = 1.1693260669708252, GAN loss = [3.0129342, 1.008331, 1.2181655]\n",
      "Batch 337/700: Discriminator loss = 1.1409721374511719, GAN loss = [2.9051354, 1.0239109, 1.0948136]\n",
      "Batch 338/700: Discriminator loss = 1.1822673082351685, GAN loss = [2.8635724, 0.95754266, 1.11965]\n",
      "Batch 339/700: Discriminator loss = 1.1760449409484863, GAN loss = [2.8470492, 0.98331565, 1.0773903]\n",
      "Batch 340/700: Discriminator loss = 1.1773533821105957, GAN loss = [2.899676, 0.98089236, 1.1324667]\n",
      "Batch 341/700: Discriminator loss = 1.1839311122894287, GAN loss = [2.769121, 0.96648926, 1.0163543]\n",
      "Batch 342/700: Discriminator loss = 1.1664739847183228, GAN loss = [2.7388043, 0.9794628, 0.9730968]\n",
      "Batch 343/700: Discriminator loss = 1.2000765800476074, GAN loss = [2.7239866, 0.9236196, 1.0141565]\n",
      "Batch 344/700: Discriminator loss = 1.1713154315948486, GAN loss = [2.752685, 0.97238314, 0.99412954]\n",
      "Batch 345/700: Discriminator loss = 1.139418125152588, GAN loss = [2.8710575, 1.0004072, 1.0845113]\n",
      "Batch 346/700: Discriminator loss = 1.2190407514572144, GAN loss = [2.7004414, 0.9421432, 0.9721884]\n",
      "Batch 347/700: Discriminator loss = 1.1974631547927856, GAN loss = [2.7553668, 0.95346254, 1.0158261]\n",
      "Batch 348/700: Discriminator loss = 1.1670619249343872, GAN loss = [2.755616, 0.96535003, 1.0042312]\n",
      "Batch 349/700: Discriminator loss = 1.1816840171813965, GAN loss = [2.8097763, 0.9536329, 1.0701332]\n",
      "Batch 350/700: Discriminator loss = 1.1884108781814575, GAN loss = [2.7796993, 0.93516403, 1.0585456]\n",
      "Batch 351/700: Discriminator loss = 1.1824414730072021, GAN loss = [2.8542113, 0.970961, 1.0972897]\n",
      "Batch 352/700: Discriminator loss = 1.1997498273849487, GAN loss = [2.7123806, 0.95189005, 0.97455716]\n",
      "Batch 353/700: Discriminator loss = 1.1824183464050293, GAN loss = [2.8509889, 0.9763033, 1.0887799]\n",
      "Batch 354/700: Discriminator loss = 1.1701858043670654, GAN loss = [2.790501, 0.97873324, 1.0258873]\n",
      "Batch 355/700: Discriminator loss = 1.2210273742675781, GAN loss = [2.6789925, 0.93804187, 0.95510757]\n",
      "Batch 356/700: Discriminator loss = 1.216471552848816, GAN loss = [2.6897397, 0.94534844, 0.95857435]\n",
      "Batch 357/700: Discriminator loss = 1.1945061683654785, GAN loss = [2.7419865, 0.93802375, 1.018175]\n",
      "Batch 358/700: Discriminator loss = 1.1889885663986206, GAN loss = [2.7814443, 0.9544242, 1.0412558]\n",
      "Batch 359/700: Discriminator loss = 1.1656618118286133, GAN loss = [2.8420794, 0.99795175, 1.0583843]\n",
      "Batch 360/700: Discriminator loss = 1.1811705827713013, GAN loss = [2.8108182, 0.9817318, 1.0433694]\n",
      "Batch 361/700: Discriminator loss = 1.2291024923324585, GAN loss = [2.722139, 0.92018807, 1.0162556]\n",
      "Batch 362/700: Discriminator loss = 1.2282781600952148, GAN loss = [2.7646968, 0.95987993, 1.0191442]\n",
      "Batch 363/700: Discriminator loss = 1.2169289588928223, GAN loss = [2.792476, 0.9549024, 1.0519267]\n",
      "Batch 364/700: Discriminator loss = 1.263792872428894, GAN loss = [2.6118648, 0.900317, 0.92593104]\n",
      "Batch 365/700: Discriminator loss = 1.206581711769104, GAN loss = [2.7217674, 0.9580787, 0.9781004]\n",
      "Batch 366/700: Discriminator loss = 1.2038503885269165, GAN loss = [2.8675382, 0.99954987, 1.0824132]\n",
      "Batch 367/700: Discriminator loss = 1.2197721004486084, GAN loss = [2.772399, 0.9555038, 1.0313419]\n",
      "Batch 368/700: Discriminator loss = 1.2039276361465454, GAN loss = [2.7568731, 0.9385866, 1.0327597]\n",
      "Batch 369/700: Discriminator loss = 1.2329370975494385, GAN loss = [2.6399965, 0.93331265, 0.92117906]\n",
      "Batch 370/700: Discriminator loss = 1.1786282062530518, GAN loss = [2.639644, 0.95852655, 0.89564204]\n",
      "Batch 371/700: Discriminator loss = 1.2212926149368286, GAN loss = [2.6967468, 0.9638892, 0.94740874]\n",
      "Batch 372/700: Discriminator loss = 1.1935402154922485, GAN loss = [2.7836084, 0.97031593, 1.0278673]\n",
      "Batch 373/700: Discriminator loss = 1.1858241558074951, GAN loss = [2.7605333, 0.96048903, 1.0146492]\n",
      "Batch 374/700: Discriminator loss = 1.1331439018249512, GAN loss = [2.7614477, 1.0085104, 0.9675788]\n",
      "Batch 375/700: Discriminator loss = 1.2108805179595947, GAN loss = [2.7058065, 0.94305533, 0.9774206]\n",
      "Batch 376/700: Discriminator loss = 1.2080066204071045, GAN loss = [2.7142906, 0.947955, 0.9810311]\n",
      "Batch 377/700: Discriminator loss = 1.1943769454956055, GAN loss = [2.7023664, 0.9559748, 0.9611228]\n",
      "Batch 378/700: Discriminator loss = 1.1765631437301636, GAN loss = [2.7445383, 0.9716579, 0.9876402]\n",
      "Batch 379/700: Discriminator loss = 1.1911357641220093, GAN loss = [2.6773229, 0.9272343, 0.9648712]\n",
      "Batch 380/700: Discriminator loss = 1.2317739725112915, GAN loss = [2.6312842, 0.9075129, 0.9385813]\n",
      "Batch 381/700: Discriminator loss = 1.1588983535766602, GAN loss = [2.7932258, 0.98230225, 1.0257695]\n",
      "Batch 382/700: Discriminator loss = 1.1805830001831055, GAN loss = [2.7733476, 0.9661622, 1.0220734]\n",
      "Batch 383/700: Discriminator loss = 1.1572771072387695, GAN loss = [2.8235202, 0.9968534, 1.0415915]\n",
      "Batch 384/700: Discriminator loss = 1.1724399328231812, GAN loss = [2.8291512, 0.97128457, 1.0728339]\n",
      "Batch 385/700: Discriminator loss = 1.1749435663223267, GAN loss = [2.7346122, 0.9642573, 0.9853623]\n",
      "Batch 386/700: Discriminator loss = 1.163520097732544, GAN loss = [2.73114, 0.9709304, 0.9752595]\n",
      "Batch 387/700: Discriminator loss = 1.1636278629302979, GAN loss = [2.851177, 0.97267425, 1.0935879]\n",
      "Batch 388/700: Discriminator loss = 1.2126636505126953, GAN loss = [2.750976, 0.93956697, 1.0265356]\n",
      "Batch 389/700: Discriminator loss = 1.161744475364685, GAN loss = [2.751829, 0.95280504, 1.0141945]\n",
      "Batch 390/700: Discriminator loss = 1.1940759420394897, GAN loss = [2.6804936, 0.9517391, 0.94396865]\n",
      "Batch 391/700: Discriminator loss = 1.172559380531311, GAN loss = [2.8227317, 0.96894395, 1.0690475]\n",
      "Batch 392/700: Discriminator loss = 1.1722335815429688, GAN loss = [2.7137675, 0.9843181, 0.94475657]\n",
      "Batch 393/700: Discriminator loss = 1.1750224828720093, GAN loss = [2.7471037, 0.95810175, 1.0043514]\n",
      "Batch 394/700: Discriminator loss = 1.15385103225708, GAN loss = [2.7006183, 0.97911614, 0.9368899]\n",
      "Batch 395/700: Discriminator loss = 1.1738554239273071, GAN loss = [2.7805321, 0.94873595, 1.0472296]\n",
      "Batch 396/700: Discriminator loss = 1.144811749458313, GAN loss = [2.7144403, 0.97994703, 0.9499618]\n",
      "Batch 397/700: Discriminator loss = 1.1241720914840698, GAN loss = [2.8076634, 1.000089, 1.0230782]\n",
      "Batch 398/700: Discriminator loss = 1.1557657718658447, GAN loss = [2.7800062, 0.9763508, 1.0191993]\n",
      "Batch 399/700: Discriminator loss = 1.2044878005981445, GAN loss = [2.7312222, 0.9364605, 1.0103431]\n",
      "Batch 400/700: Discriminator loss = 1.1585482358932495, GAN loss = [2.8316603, 0.99290574, 1.0543712]\n",
      "Batch 401/700: Discriminator loss = 1.1676679849624634, GAN loss = [2.7546067, 0.95580983, 1.0144547]\n",
      "Batch 402/700: Discriminator loss = 1.1548359394073486, GAN loss = [2.7298982, 0.9668862, 0.9787052]\n",
      "Batch 403/700: Discriminator loss = 1.1757819652557373, GAN loss = [2.7907684, 0.93095034, 1.0755466]\n",
      "Batch 404/700: Discriminator loss = 1.1585934162139893, GAN loss = [2.8170912, 0.98757577, 1.0452695]\n",
      "Batch 405/700: Discriminator loss = 1.1512411832809448, GAN loss = [2.7445233, 0.98092294, 0.9793883]\n",
      "Batch 406/700: Discriminator loss = 1.189662218093872, GAN loss = [2.7728474, 0.9547646, 1.0339]\n",
      "Batch 407/700: Discriminator loss = 1.17708420753479, GAN loss = [2.7579923, 0.99504715, 0.97879744]\n",
      "Batch 408/700: Discriminator loss = 1.155638337135315, GAN loss = [2.7295086, 0.9516754, 0.99372774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 409/700: Discriminator loss = 1.152137279510498, GAN loss = [2.778611, 0.96367097, 1.0308685]\n",
      "Batch 410/700: Discriminator loss = 1.2126476764678955, GAN loss = [2.7032988, 0.9096605, 1.0095999]\n",
      "Batch 411/700: Discriminator loss = 1.1779876947402954, GAN loss = [2.849185, 0.94655156, 1.1186249]\n",
      "Batch 412/700: Discriminator loss = 1.1388710737228394, GAN loss = [2.830721, 0.98077995, 1.06597]\n",
      "Batch 413/700: Discriminator loss = 1.163298487663269, GAN loss = [2.7703228, 0.95682263, 1.0295744]\n",
      "Batch 414/700: Discriminator loss = 1.1657590866088867, GAN loss = [2.7504127, 0.9818442, 0.9846777]\n",
      "Batch 415/700: Discriminator loss = 1.1515240669250488, GAN loss = [2.831123, 0.9824417, 1.0648235]\n",
      "Batch 416/700: Discriminator loss = 1.1659342050552368, GAN loss = [2.7519383, 0.93790746, 1.0302112]\n",
      "Batch 417/700: Discriminator loss = 1.1533936262130737, GAN loss = [2.7513344, 0.96568316, 1.0018563]\n",
      "Batch 418/700: Discriminator loss = 1.161765217781067, GAN loss = [2.7106938, 0.9525239, 0.97440493]\n",
      "Batch 419/700: Discriminator loss = 1.165053129196167, GAN loss = [2.7372804, 0.9374875, 1.016063]\n",
      "Batch 420/700: Discriminator loss = 1.1887637376785278, GAN loss = [2.7119277, 0.9730274, 0.95520186]\n",
      "Batch 421/700: Discriminator loss = 1.2019000053405762, GAN loss = [2.6672678, 0.93823236, 0.9453635]\n",
      "Batch 422/700: Discriminator loss = 1.1547142267227173, GAN loss = [2.7268946, 0.9495331, 0.9937202]\n",
      "Batch 423/700: Discriminator loss = 1.1858289241790771, GAN loss = [2.7084708, 0.93203956, 0.99282235]\n",
      "Batch 424/700: Discriminator loss = 1.1762757301330566, GAN loss = [2.7693026, 0.9466684, 1.039056]\n",
      "Batch 425/700: Discriminator loss = 1.2028639316558838, GAN loss = [2.7284315, 0.9404255, 1.0044552]\n",
      "Batch 426/700: Discriminator loss = 1.188080072402954, GAN loss = [2.6898704, 0.9508752, 0.9554659]\n",
      "Batch 427/700: Discriminator loss = 1.2344168424606323, GAN loss = [2.6843882, 0.91454375, 0.98633844]\n",
      "Batch 428/700: Discriminator loss = 1.172374963760376, GAN loss = [2.8204038, 0.9536278, 1.083305]\n",
      "Batch 429/700: Discriminator loss = 1.1801923513412476, GAN loss = [2.7553105, 0.9886474, 0.98323137]\n",
      "Batch 430/700: Discriminator loss = 1.1437313556671143, GAN loss = [2.7625458, 0.96778655, 1.0113655]\n",
      "Batch 431/700: Discriminator loss = 1.2041270732879639, GAN loss = [2.7528145, 0.9496098, 1.0198327]\n",
      "Batch 432/700: Discriminator loss = 1.2104254961013794, GAN loss = [2.68385, 0.9268116, 0.973689]\n",
      "Batch 433/700: Discriminator loss = 1.1837631464004517, GAN loss = [2.7085192, 0.9303719, 0.99482745]\n",
      "Batch 434/700: Discriminator loss = 1.208198070526123, GAN loss = [2.7061615, 0.9417999, 0.9810583]\n",
      "Batch 435/700: Discriminator loss = 1.1909558773040771, GAN loss = [2.747429, 0.94707465, 1.0170677]\n",
      "Batch 436/700: Discriminator loss = 1.1984124183654785, GAN loss = [2.7364419, 0.95803154, 0.99514544]\n",
      "Batch 437/700: Discriminator loss = 1.1614857912063599, GAN loss = [2.79774, 0.9858959, 1.028604]\n",
      "Batch 438/700: Discriminator loss = 1.181265950202942, GAN loss = [2.8583546, 0.9604576, 1.1146863]\n",
      "Batch 439/700: Discriminator loss = 1.202335238456726, GAN loss = [2.7254248, 0.9420589, 1.0001813]\n",
      "Batch 440/700: Discriminator loss = 1.1870274543762207, GAN loss = [2.693925, 0.9656113, 0.9451465]\n",
      "Batch 441/700: Discriminator loss = 1.1842013597488403, GAN loss = [2.6329129, 0.95521516, 0.89455205]\n",
      "Batch 442/700: Discriminator loss = 1.2313822507858276, GAN loss = [2.7196078, 0.9511414, 0.9853496]\n",
      "Batch 443/700: Discriminator loss = 1.1645214557647705, GAN loss = [2.8674483, 0.9836211, 1.1007327]\n",
      "Batch 444/700: Discriminator loss = 1.1584384441375732, GAN loss = [2.730963, 0.9861962, 0.9616948]\n",
      "Batch 445/700: Discriminator loss = 1.1592074632644653, GAN loss = [2.7344654, 0.9909861, 0.9604332]\n",
      "Batch 446/700: Discriminator loss = 1.1611788272857666, GAN loss = [2.8218892, 0.9762218, 1.0626506]\n",
      "Batch 447/700: Discriminator loss = 1.1816046237945557, GAN loss = [2.7402692, 0.9318706, 1.025416]\n",
      "Batch 448/700: Discriminator loss = 1.1686153411865234, GAN loss = [2.796277, 0.9639546, 1.0493542]\n",
      "Batch 449/700: Discriminator loss = 1.16843843460083, GAN loss = [2.758925, 0.9564225, 1.0195547]\n",
      "Batch 450/700: Discriminator loss = 1.1652190685272217, GAN loss = [2.850632, 0.96280426, 1.1048977]\n",
      "Batch 451/700: Discriminator loss = 1.2289561033248901, GAN loss = [2.6573598, 0.8970385, 0.9774102]\n",
      "Batch 452/700: Discriminator loss = 1.233935832977295, GAN loss = [2.8025203, 0.9256453, 1.0939912]\n",
      "Batch 453/700: Discriminator loss = 1.1247996091842651, GAN loss = [2.9146464, 0.9845701, 1.1472175]\n",
      "Batch 454/700: Discriminator loss = 1.1715394258499146, GAN loss = [2.7121696, 0.9543046, 0.9750227]\n",
      "Batch 455/700: Discriminator loss = 1.1866416931152344, GAN loss = [2.8011506, 0.97594213, 1.0423845]\n",
      "Batch 456/700: Discriminator loss = 1.1490341424942017, GAN loss = [2.8049433, 0.97955793, 1.0425904]\n",
      "Batch 457/700: Discriminator loss = 1.1944775581359863, GAN loss = [2.786364, 0.96838135, 1.0352093]\n",
      "Batch 458/700: Discriminator loss = 1.1889568567276, GAN loss = [2.7998776, 0.95450693, 1.0626208]\n",
      "Batch 459/700: Discriminator loss = 1.1462634801864624, GAN loss = [2.819131, 0.98678404, 1.0496037]\n",
      "Batch 460/700: Discriminator loss = 1.1861826181411743, GAN loss = [2.7248466, 0.94005716, 1.0020609]\n",
      "Batch 461/700: Discriminator loss = 1.2006185054779053, GAN loss = [2.789259, 0.9469003, 1.059651]\n",
      "Batch 462/700: Discriminator loss = 1.1493333578109741, GAN loss = [2.773791, 0.9869523, 1.0041478]\n",
      "Batch 463/700: Discriminator loss = 1.2073583602905273, GAN loss = [2.7145376, 0.9106284, 1.0212445]\n",
      "Batch 464/700: Discriminator loss = 1.1815999746322632, GAN loss = [2.7468908, 0.9562151, 1.0080255]\n",
      "Batch 465/700: Discriminator loss = 1.202397108078003, GAN loss = [2.7482097, 0.9404506, 1.0251275]\n",
      "Batch 466/700: Discriminator loss = 1.1353399753570557, GAN loss = [2.9564178, 0.99303246, 1.1807778]\n",
      "Batch 467/700: Discriminator loss = 1.1681039333343506, GAN loss = [2.910061, 1.0062164, 1.1212678]\n",
      "Batch 468/700: Discriminator loss = 1.167899489402771, GAN loss = [2.8100119, 0.9766684, 1.0507964]\n",
      "Batch 469/700: Discriminator loss = 1.1491327285766602, GAN loss = [2.8593962, 0.97818047, 1.098698]\n",
      "Batch 470/700: Discriminator loss = 1.1715763807296753, GAN loss = [2.671601, 0.96489555, 0.92421967]\n",
      "Batch 471/700: Discriminator loss = 1.1491049528121948, GAN loss = [2.8527927, 0.98049045, 1.0898422]\n",
      "Batch 472/700: Discriminator loss = 1.1823245286941528, GAN loss = [2.7481098, 0.9493153, 1.0163652]\n",
      "Batch 473/700: Discriminator loss = 1.145458459854126, GAN loss = [2.8642266, 0.96776575, 1.1140602]\n",
      "Batch 474/700: Discriminator loss = 1.2093735933303833, GAN loss = [2.6517062, 0.9616405, 0.9076865]\n",
      "Batch 475/700: Discriminator loss = 1.1409251689910889, GAN loss = [2.839606, 0.9975798, 1.0596819]\n",
      "Batch 476/700: Discriminator loss = 1.191159963607788, GAN loss = [2.758901, 0.93165207, 1.0449396]\n",
      "Batch 477/700: Discriminator loss = 1.1887069940567017, GAN loss = [2.7712634, 0.9519378, 1.0370508]\n",
      "Batch 478/700: Discriminator loss = 1.1519653797149658, GAN loss = [2.7535617, 0.96590745, 1.0054162]\n",
      "Batch 479/700: Discriminator loss = 1.172499418258667, GAN loss = [2.828145, 0.9692291, 1.0767175]\n",
      "Batch 480/700: Discriminator loss = 1.1508971452713013, GAN loss = [2.8554397, 0.9950825, 1.0781921]\n",
      "Batch 481/700: Discriminator loss = 1.1729600429534912, GAN loss = [2.757394, 0.9592879, 1.0159767]\n",
      "Batch 482/700: Discriminator loss = 1.1594077348709106, GAN loss = [2.7745028, 0.9792691, 1.0131446]\n",
      "Batch 483/700: Discriminator loss = 1.1313154697418213, GAN loss = [2.762178, 0.97061783, 1.0095167]\n",
      "Batch 484/700: Discriminator loss = 1.1381101608276367, GAN loss = [2.8576272, 0.96556044, 1.1100638]\n",
      "Batch 485/700: Discriminator loss = 1.1610677242279053, GAN loss = [2.9116812, 0.9729902, 1.1567235]\n",
      "Batch 486/700: Discriminator loss = 1.1734733581542969, GAN loss = [2.8130412, 0.95470756, 1.07639]\n",
      "Batch 487/700: Discriminator loss = 1.1484071016311646, GAN loss = [2.7132993, 0.96559584, 0.9657833]\n",
      "Batch 488/700: Discriminator loss = 1.1431291103363037, GAN loss = [2.8581178, 0.9747729, 1.1014503]\n",
      "Batch 489/700: Discriminator loss = 1.1346745491027832, GAN loss = [2.794082, 0.98200125, 1.0302131]\n",
      "Batch 490/700: Discriminator loss = 1.1588938236236572, GAN loss = [2.9903176, 0.98272735, 1.2257408]\n",
      "Batch 491/700: Discriminator loss = 1.135055661201477, GAN loss = [2.7571476, 0.97662055, 0.9986957]\n",
      "Batch 492/700: Discriminator loss = 1.1486586332321167, GAN loss = [2.8776233, 0.9670077, 1.1287974]\n",
      "Batch 493/700: Discriminator loss = 1.1606745719909668, GAN loss = [2.926016, 0.94819677, 1.1960113]\n",
      "Batch 494/700: Discriminator loss = 1.1296497583389282, GAN loss = [2.9615269, 0.97986627, 1.1998701]\n",
      "Batch 495/700: Discriminator loss = 1.1419789791107178, GAN loss = [2.8961396, 0.9693688, 1.145002]\n",
      "Batch 496/700: Discriminator loss = 1.1344867944717407, GAN loss = [2.7991738, 0.98148733, 1.035939]\n",
      "Batch 497/700: Discriminator loss = 1.1468755006790161, GAN loss = [2.9973466, 0.9969682, 1.2186544]\n",
      "Batch 498/700: Discriminator loss = 1.1513651609420776, GAN loss = [2.7576177, 0.9750067, 1.0009015]\n",
      "Batch 499/700: Discriminator loss = 1.168819785118103, GAN loss = [2.8428104, 0.9828011, 1.078327]\n",
      "Batch 500/700: Discriminator loss = 1.1596853733062744, GAN loss = [2.8780973, 1.013912, 1.0825278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 501/700: Discriminator loss = 1.1633617877960205, GAN loss = [2.742948, 0.95240176, 1.0089265]\n",
      "Batch 502/700: Discriminator loss = 1.158056616783142, GAN loss = [2.8568444, 0.9755235, 1.0997223]\n",
      "Batch 503/700: Discriminator loss = 1.1478670835494995, GAN loss = [2.7019, 0.9517207, 0.9686009]\n",
      "Batch 504/700: Discriminator loss = 1.1693028211593628, GAN loss = [2.7912526, 0.9421763, 1.0675052]\n",
      "Batch 505/700: Discriminator loss = 1.1732628345489502, GAN loss = [2.8833327, 0.9490651, 1.1527086]\n",
      "Batch 506/700: Discriminator loss = 1.163806676864624, GAN loss = [2.8513138, 0.9653376, 1.1044436]\n",
      "Batch 507/700: Discriminator loss = 1.1746739149093628, GAN loss = [2.7170565, 0.9485523, 0.9870011]\n",
      "Batch 508/700: Discriminator loss = 1.1372945308685303, GAN loss = [2.806197, 0.9838996, 1.0408188]\n",
      "Batch 509/700: Discriminator loss = 1.1926523447036743, GAN loss = [2.741134, 0.96414435, 0.9955357]\n",
      "Batch 510/700: Discriminator loss = 1.1343894004821777, GAN loss = [2.823697, 0.99526423, 1.0470085]\n",
      "Batch 511/700: Discriminator loss = 1.1750134229660034, GAN loss = [2.8336632, 0.9561127, 1.0961525]\n",
      "Batch 512/700: Discriminator loss = 1.17807137966156, GAN loss = [2.7392402, 0.9493081, 1.0085598]\n",
      "Batch 513/700: Discriminator loss = 1.1578972339630127, GAN loss = [2.7469065, 0.9589446, 1.0066096]\n",
      "Batch 514/700: Discriminator loss = 1.1403359174728394, GAN loss = [2.9404647, 1.004104, 1.1550301]\n",
      "Batch 515/700: Discriminator loss = 1.128166913986206, GAN loss = [2.8013902, 0.9918684, 1.0282193]\n",
      "Batch 516/700: Discriminator loss = 1.1691852807998657, GAN loss = [2.8578773, 0.981662, 1.0949405]\n",
      "Batch 517/700: Discriminator loss = 1.1801849603652954, GAN loss = [2.8212183, 0.9583629, 1.0816191]\n",
      "Batch 518/700: Discriminator loss = 1.1907532215118408, GAN loss = [2.7735307, 0.94632226, 1.0460013]\n",
      "Batch 519/700: Discriminator loss = 1.1629750728607178, GAN loss = [2.8473752, 0.9644117, 1.1017826]\n",
      "Batch 520/700: Discriminator loss = 1.1931984424591064, GAN loss = [2.7677906, 0.9665716, 1.0200694]\n",
      "Batch 521/700: Discriminator loss = 1.143696904182434, GAN loss = [2.8172755, 1.001186, 1.03497]\n",
      "Batch 522/700: Discriminator loss = 1.147620677947998, GAN loss = [2.852055, 0.9718423, 1.0991298]\n",
      "Batch 523/700: Discriminator loss = 1.174530267715454, GAN loss = [2.791545, 0.9574921, 1.0530015]\n",
      "Batch 524/700: Discriminator loss = 1.1503078937530518, GAN loss = [2.864029, 0.956313, 1.1266836]\n",
      "Batch 525/700: Discriminator loss = 1.1816037893295288, GAN loss = [2.7724068, 0.9657611, 1.0256425]\n",
      "Batch 526/700: Discriminator loss = 1.183974266052246, GAN loss = [2.7518644, 0.9485992, 1.0222912]\n",
      "Batch 527/700: Discriminator loss = 1.1866589784622192, GAN loss = [2.7531784, 0.9293293, 1.0429101]\n",
      "Batch 528/700: Discriminator loss = 1.167342185974121, GAN loss = [2.7297451, 0.96666056, 0.9821726]\n",
      "Batch 529/700: Discriminator loss = 1.1732155084609985, GAN loss = [2.8060477, 0.962359, 1.0628134]\n",
      "Batch 530/700: Discriminator loss = 1.168586015701294, GAN loss = [2.7718692, 0.9549636, 1.0360668]\n",
      "Batch 531/700: Discriminator loss = 1.1959668397903442, GAN loss = [2.7234855, 0.9422434, 1.0004373]\n",
      "Batch 532/700: Discriminator loss = 1.190192461013794, GAN loss = [2.7018921, 0.9508301, 0.970295]\n",
      "Batch 533/700: Discriminator loss = 1.1562104225158691, GAN loss = [2.7779036, 0.95789564, 1.039279]\n",
      "Batch 534/700: Discriminator loss = 1.1887078285217285, GAN loss = [2.84914, 0.96075684, 1.1077019]\n",
      "Batch 535/700: Discriminator loss = 1.1710914373397827, GAN loss = [2.8213284, 0.9536677, 1.0870153]\n",
      "Batch 536/700: Discriminator loss = 1.156571626663208, GAN loss = [2.8116772, 0.96002036, 1.0710378]\n",
      "Batch 537/700: Discriminator loss = 1.1546801328659058, GAN loss = [2.8019407, 0.9636702, 1.0576718]\n",
      "Batch 538/700: Discriminator loss = 1.147624135017395, GAN loss = [2.7437828, 0.9588058, 1.0044056]\n",
      "Batch 539/700: Discriminator loss = 1.1670187711715698, GAN loss = [2.7802746, 0.94687796, 1.0528485]\n",
      "Batch 540/700: Discriminator loss = 1.149654746055603, GAN loss = [2.666379, 0.9514806, 0.93435717]\n",
      "Batch 541/700: Discriminator loss = 1.1488876342773438, GAN loss = [2.8039284, 0.95275164, 1.0706531]\n",
      "Batch 542/700: Discriminator loss = 1.184086799621582, GAN loss = [2.7618988, 0.9352904, 1.046101]\n",
      "Batch 543/700: Discriminator loss = 1.1753512620925903, GAN loss = [2.6716292, 0.92477244, 0.9663732]\n",
      "Batch 544/700: Discriminator loss = 1.2028347253799438, GAN loss = [2.7658484, 0.92526156, 1.0601317]\n",
      "Batch 545/700: Discriminator loss = 1.2043277025222778, GAN loss = [2.7909381, 0.94724077, 1.0632836]\n",
      "Batch 546/700: Discriminator loss = 1.156419038772583, GAN loss = [2.9866471, 0.96701235, 1.2392501]\n",
      "Batch 547/700: Discriminator loss = 1.1434754133224487, GAN loss = [2.9024618, 0.9710886, 1.1510053]\n",
      "Batch 548/700: Discriminator loss = 1.1859649419784546, GAN loss = [2.9403667, 0.9726546, 1.1873552]\n",
      "Batch 549/700: Discriminator loss = 1.1610034704208374, GAN loss = [2.8804042, 0.9715574, 1.1285156]\n",
      "Batch 550/700: Discriminator loss = 1.1360901594161987, GAN loss = [2.8198912, 0.9915339, 1.0480607]\n",
      "Batch 551/700: Discriminator loss = 1.1317353248596191, GAN loss = [2.879396, 0.98808753, 1.1110364]\n",
      "Batch 552/700: Discriminator loss = 1.1543149948120117, GAN loss = [2.7768672, 0.961083, 1.0355304]\n",
      "Batch 553/700: Discriminator loss = 1.1953239440917969, GAN loss = [2.818899, 0.96322286, 1.0754448]\n",
      "Batch 554/700: Discriminator loss = 1.1286964416503906, GAN loss = [2.8181803, 0.9965094, 1.0414672]\n",
      "Batch 555/700: Discriminator loss = 1.188974142074585, GAN loss = [2.8442135, 0.93549734, 1.1285406]\n",
      "Batch 556/700: Discriminator loss = 1.156299352645874, GAN loss = [2.8804975, 0.973981, 1.1263825]\n",
      "Batch 557/700: Discriminator loss = 1.1042377948760986, GAN loss = [2.8631046, 1.0238734, 1.0591347]\n",
      "Batch 558/700: Discriminator loss = 1.135857343673706, GAN loss = [2.8200805, 0.99222946, 1.047779]\n",
      "Batch 559/700: Discriminator loss = 1.1544780731201172, GAN loss = [2.790433, 0.975586, 1.0347885]\n",
      "Batch 560/700: Discriminator loss = 1.2100497484207153, GAN loss = [2.8039339, 0.9351696, 1.0887213]\n",
      "Batch 561/700: Discriminator loss = 1.215959906578064, GAN loss = [2.667219, 0.9384959, 0.94869965]\n",
      "Batch 562/700: Discriminator loss = 1.202116847038269, GAN loss = [2.8081787, 0.9464782, 1.0817071]\n",
      "Batch 563/700: Discriminator loss = 1.1902135610580444, GAN loss = [2.752045, 0.9766824, 0.9953971]\n",
      "Batch 564/700: Discriminator loss = 1.1634762287139893, GAN loss = [2.9118927, 0.99476844, 1.137199]\n",
      "Batch 565/700: Discriminator loss = 1.1311675310134888, GAN loss = [2.8679473, 0.99947375, 1.0885907]\n",
      "Batch 566/700: Discriminator loss = 1.1918705701828003, GAN loss = [2.8023627, 0.9659166, 1.0566014]\n",
      "Batch 567/700: Discriminator loss = 1.1890697479248047, GAN loss = [2.7403958, 0.96446127, 0.99612653]\n",
      "Batch 568/700: Discriminator loss = 1.1944471597671509, GAN loss = [2.7616143, 0.95133126, 1.0305011]\n",
      "Batch 569/700: Discriminator loss = 1.1928654909133911, GAN loss = [2.7637208, 0.9482758, 1.0356883]\n",
      "Batch 570/700: Discriminator loss = 1.1810210943222046, GAN loss = [2.766321, 0.9693396, 1.0172455]\n",
      "Batch 571/700: Discriminator loss = 1.174407958984375, GAN loss = [2.795869, 0.9500996, 1.0660703]\n",
      "Batch 572/700: Discriminator loss = 1.1552623510360718, GAN loss = [2.818056, 0.95489687, 1.0834951]\n",
      "Batch 573/700: Discriminator loss = 1.1953233480453491, GAN loss = [2.8098137, 0.95835406, 1.071811]\n",
      "Batch 574/700: Discriminator loss = 1.2039023637771606, GAN loss = [2.682501, 0.91348463, 0.9893839]\n",
      "Batch 575/700: Discriminator loss = 1.1821192502975464, GAN loss = [2.8307254, 0.9444774, 1.1066362]\n",
      "Batch 576/700: Discriminator loss = 1.2099478244781494, GAN loss = [2.7605107, 0.9786812, 1.0022392]\n",
      "Batch 577/700: Discriminator loss = 1.1870018243789673, GAN loss = [2.6708283, 0.9429155, 0.9483443]\n",
      "Batch 578/700: Discriminator loss = 1.1945809125900269, GAN loss = [2.729015, 0.9373882, 1.0120857]\n",
      "Batch 579/700: Discriminator loss = 1.1799262762069702, GAN loss = [2.76927, 0.9775593, 1.0121993]\n",
      "Batch 580/700: Discriminator loss = 1.1823583841323853, GAN loss = [2.7412999, 0.9390615, 1.022751]\n",
      "Batch 581/700: Discriminator loss = 1.1586192846298218, GAN loss = [2.754377, 0.96731424, 1.0076174]\n",
      "Batch 582/700: Discriminator loss = 1.1810520887374878, GAN loss = [2.773656, 0.9372746, 1.05698]\n",
      "Batch 583/700: Discriminator loss = 1.1385067701339722, GAN loss = [2.7634833, 0.96990067, 1.0142093]\n",
      "Batch 584/700: Discriminator loss = 1.155255675315857, GAN loss = [2.8159924, 0.9619404, 1.0747156]\n",
      "Batch 585/700: Discriminator loss = 1.1755064725875854, GAN loss = [2.7241077, 0.9445156, 1.0002835]\n",
      "Batch 586/700: Discriminator loss = 1.184356451034546, GAN loss = [2.72917, 0.9314483, 1.0184429]\n",
      "Batch 587/700: Discriminator loss = 1.1603184938430786, GAN loss = [2.7615104, 0.9444119, 1.037854]\n",
      "Batch 588/700: Discriminator loss = 1.172218918800354, GAN loss = [2.8807201, 0.97908103, 1.1224093]\n",
      "Batch 589/700: Discriminator loss = 1.164876103401184, GAN loss = [2.758277, 0.9518285, 1.0272324]\n",
      "Batch 590/700: Discriminator loss = 1.1589182615280151, GAN loss = [2.8181703, 0.9516203, 1.0873393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 591/700: Discriminator loss = 1.1745734214782715, GAN loss = [2.80637, 0.95737785, 1.0698053]\n",
      "Batch 592/700: Discriminator loss = 1.1901315450668335, GAN loss = [2.7044308, 0.93937075, 0.98590255]\n",
      "Batch 593/700: Discriminator loss = 1.160116195678711, GAN loss = [2.7869864, 0.9650486, 1.0428058]\n",
      "Batch 594/700: Discriminator loss = 1.1638191938400269, GAN loss = [2.8004153, 0.93893385, 1.0823753]\n",
      "Batch 595/700: Discriminator loss = 1.1310688257217407, GAN loss = [2.7426784, 0.97512794, 0.98846835]\n",
      "Batch 596/700: Discriminator loss = 1.1679962873458862, GAN loss = [2.7291734, 0.94140434, 1.0087132]\n",
      "Batch 597/700: Discriminator loss = 1.1415454149246216, GAN loss = [2.8583732, 0.9464834, 1.1328721]\n",
      "Batch 598/700: Discriminator loss = 1.1302103996276855, GAN loss = [2.848485, 0.9701533, 1.0993426]\n",
      "Batch 599/700: Discriminator loss = 1.1329154968261719, GAN loss = [2.8620837, 0.9593821, 1.1237334]\n",
      "Batch 600/700: Discriminator loss = 1.1230007410049438, GAN loss = [2.9108782, 0.98099595, 1.1509323]\n",
      "Batch 601/700: Discriminator loss = 1.1135413646697998, GAN loss = [2.955516, 1.0145103, 1.1620711]\n",
      "Batch 602/700: Discriminator loss = 1.17058527469635, GAN loss = [2.764406, 0.95721716, 1.0282826]\n",
      "Batch 603/700: Discriminator loss = 1.1252894401550293, GAN loss = [2.8355722, 0.9725494, 1.0841471]\n",
      "Batch 604/700: Discriminator loss = 1.1631193161010742, GAN loss = [2.8108742, 0.9598049, 1.0722235]\n",
      "Batch 605/700: Discriminator loss = 1.0981212854385376, GAN loss = [2.9567153, 0.99493295, 1.1829668]\n",
      "Batch 606/700: Discriminator loss = 1.1383737325668335, GAN loss = [2.7324271, 0.95110494, 1.002538]\n",
      "Batch 607/700: Discriminator loss = 1.133400559425354, GAN loss = [2.9305182, 0.9686524, 1.183117]\n",
      "Batch 608/700: Discriminator loss = 1.1467313766479492, GAN loss = [2.8355596, 0.9753111, 1.0815339]\n",
      "Batch 609/700: Discriminator loss = 1.1082485914230347, GAN loss = [2.8529444, 1.0014666, 1.0727985]\n",
      "Batch 610/700: Discriminator loss = 1.1533379554748535, GAN loss = [2.8025734, 0.9480513, 1.0758775]\n",
      "Batch 611/700: Discriminator loss = 1.1504406929016113, GAN loss = [2.8675258, 0.9570234, 1.1318905]\n",
      "Batch 612/700: Discriminator loss = 1.1757105588912964, GAN loss = [2.820137, 0.96776336, 1.0737938]\n",
      "Batch 613/700: Discriminator loss = 1.1291775703430176, GAN loss = [3.0151966, 0.9669094, 1.2697417]\n",
      "Batch 614/700: Discriminator loss = 1.1305463314056396, GAN loss = [2.9359581, 0.969314, 1.1881187]\n",
      "Batch 615/700: Discriminator loss = 1.148882269859314, GAN loss = [2.8884969, 0.9806739, 1.129308]\n",
      "Batch 616/700: Discriminator loss = 1.127118468284607, GAN loss = [2.8254416, 0.9651694, 1.0817807]\n",
      "Batch 617/700: Discriminator loss = 1.1418852806091309, GAN loss = [2.8721306, 0.97776407, 1.1159021]\n",
      "Batch 618/700: Discriminator loss = 1.1502695083618164, GAN loss = [2.829956, 0.9911851, 1.0603448]\n",
      "Batch 619/700: Discriminator loss = 1.1705594062805176, GAN loss = [2.9037452, 0.95290464, 1.1724418]\n",
      "Batch 620/700: Discriminator loss = 1.1456842422485352, GAN loss = [2.91173, 0.9677708, 1.1655809]\n",
      "Batch 621/700: Discriminator loss = 1.1721895933151245, GAN loss = [2.8171988, 0.9544546, 1.0843822]\n",
      "Batch 622/700: Discriminator loss = 1.1591018438339233, GAN loss = [2.8421001, 0.9728487, 1.0909007]\n",
      "Batch 623/700: Discriminator loss = 1.1372483968734741, GAN loss = [2.9254994, 0.9844343, 1.162734]\n",
      "Batch 624/700: Discriminator loss = 1.1488547325134277, GAN loss = [2.8978155, 0.97116125, 1.14834]\n",
      "Batch 625/700: Discriminator loss = 1.148363471031189, GAN loss = [2.9322546, 0.9941597, 1.1597989]\n",
      "Batch 626/700: Discriminator loss = 1.1420565843582153, GAN loss = [2.9331863, 0.9761689, 1.1787436]\n",
      "Batch 627/700: Discriminator loss = 1.195332407951355, GAN loss = [2.8580925, 0.96081847, 1.1190299]\n",
      "Batch 628/700: Discriminator loss = 1.123370885848999, GAN loss = [2.8258522, 0.9765069, 1.0711184]\n",
      "Batch 629/700: Discriminator loss = 1.159261703491211, GAN loss = [2.802191, 0.97088736, 1.0530941]\n",
      "Batch 630/700: Discriminator loss = 1.163406252861023, GAN loss = [2.8466403, 0.9601016, 1.1083469]\n",
      "Batch 631/700: Discriminator loss = 1.1627342700958252, GAN loss = [2.87933, 0.9460599, 1.1550981]\n",
      "Batch 632/700: Discriminator loss = 1.1965233087539673, GAN loss = [2.8067358, 0.9463728, 1.0822102]\n",
      "Batch 633/700: Discriminator loss = 1.2137377262115479, GAN loss = [2.8418014, 0.93997467, 1.1236968]\n",
      "Batch 634/700: Discriminator loss = 1.1312882900238037, GAN loss = [2.9754326, 0.9922831, 1.2050443]\n",
      "Batch 635/700: Discriminator loss = 1.143943428993225, GAN loss = [2.7888665, 0.97263145, 1.0381496]\n",
      "Batch 636/700: Discriminator loss = 1.134148359298706, GAN loss = [2.8318954, 1.0249069, 1.0289387]\n",
      "Batch 637/700: Discriminator loss = 1.1575812101364136, GAN loss = [2.8910775, 0.9956548, 1.1173928]\n",
      "Batch 638/700: Discriminator loss = 1.1392308473587036, GAN loss = [2.8362257, 1.0143912, 1.0438222]\n",
      "Batch 639/700: Discriminator loss = 1.1929904222488403, GAN loss = [2.836505, 0.9672829, 1.0912224]\n",
      "Batch 640/700: Discriminator loss = 1.1932883262634277, GAN loss = [2.8059423, 0.95528275, 1.0726805]\n",
      "Batch 641/700: Discriminator loss = 1.1495041847229004, GAN loss = [2.8236246, 0.96986204, 1.0758116]\n",
      "Batch 642/700: Discriminator loss = 1.1676126718521118, GAN loss = [2.879612, 0.9830714, 1.1186043]\n",
      "Batch 643/700: Discriminator loss = 1.150515079498291, GAN loss = [2.7671683, 0.97699815, 1.0122494]\n",
      "Batch 644/700: Discriminator loss = 1.1434980630874634, GAN loss = [2.8656676, 0.98568094, 1.1020733]\n",
      "Batch 645/700: Discriminator loss = 1.1732189655303955, GAN loss = [2.8498, 0.9981279, 1.0737658]\n",
      "Batch 646/700: Discriminator loss = 1.1533501148223877, GAN loss = [2.809207, 0.9841423, 1.0471722]\n",
      "Batch 647/700: Discriminator loss = 1.1523990631103516, GAN loss = [2.8047915, 0.9956174, 1.0312985]\n",
      "Batch 648/700: Discriminator loss = 1.1490980386734009, GAN loss = [2.7732325, 0.9863309, 1.0090426]\n",
      "Batch 649/700: Discriminator loss = 1.1507294178009033, GAN loss = [2.8745868, 0.9990167, 1.0977411]\n",
      "Batch 650/700: Discriminator loss = 1.152366042137146, GAN loss = [2.793629, 0.9761856, 1.0396421]\n",
      "Batch 651/700: Discriminator loss = 1.1410948038101196, GAN loss = [2.8582401, 0.98097765, 1.0994964]\n",
      "Batch 652/700: Discriminator loss = 1.1437915563583374, GAN loss = [3.0511754, 1.0010467, 1.272391]\n",
      "Batch 653/700: Discriminator loss = 1.1255160570144653, GAN loss = [3.0318222, 1.0338066, 1.220309]\n",
      "Batch 654/700: Discriminator loss = 1.1608635187149048, GAN loss = [2.9610088, 0.96675605, 1.2165672]\n",
      "Batch 655/700: Discriminator loss = 1.2153974771499634, GAN loss = [2.8575783, 0.9408264, 1.1390935]\n",
      "Batch 656/700: Discriminator loss = 1.233291506767273, GAN loss = [2.7852502, 0.9785108, 1.0290965]\n",
      "Batch 657/700: Discriminator loss = 1.1284921169281006, GAN loss = [2.9670405, 1.000016, 1.1894065]\n",
      "Batch 658/700: Discriminator loss = 1.1374058723449707, GAN loss = [2.8839188, 1.0147111, 1.0916283]\n",
      "Batch 659/700: Discriminator loss = 1.1636706590652466, GAN loss = [2.8061461, 0.97069514, 1.0579029]\n",
      "Batch 660/700: Discriminator loss = 1.1512740850448608, GAN loss = [2.892153, 0.99516433, 1.1194707]\n",
      "Batch 661/700: Discriminator loss = 1.1306172609329224, GAN loss = [2.8454309, 1.0105462, 1.0573983]\n",
      "Batch 662/700: Discriminator loss = 1.2104063034057617, GAN loss = [2.870214, 0.97744745, 1.1153107]\n",
      "Batch 663/700: Discriminator loss = 1.1468461751937866, GAN loss = [2.9147322, 1.0025402, 1.1347693]\n",
      "Batch 664/700: Discriminator loss = 1.1364110708236694, GAN loss = [2.8393455, 1.0021461, 1.0598141]\n",
      "Batch 665/700: Discriminator loss = 1.1437804698944092, GAN loss = [2.8531125, 0.9856082, 1.0901572]\n",
      "Batch 666/700: Discriminator loss = 1.1711794137954712, GAN loss = [2.8318005, 0.9978588, 1.0566398]\n",
      "Batch 667/700: Discriminator loss = 1.1818262338638306, GAN loss = [2.8044813, 0.9735025, 1.0537146]\n",
      "Batch 668/700: Discriminator loss = 1.144533634185791, GAN loss = [2.8620589, 1.0017142, 1.0831124]\n",
      "Batch 669/700: Discriminator loss = 1.1836025714874268, GAN loss = [2.8075798, 0.95259583, 1.0777771]\n",
      "Batch 670/700: Discriminator loss = 1.1922593116760254, GAN loss = [2.835776, 0.95679975, 1.1017983]\n",
      "Batch 671/700: Discriminator loss = 1.1436502933502197, GAN loss = [2.811204, 1.007514, 1.0265326]\n",
      "Batch 672/700: Discriminator loss = 1.163512945175171, GAN loss = [2.8342807, 1.0079608, 1.0491782]\n",
      "Batch 673/700: Discriminator loss = 1.1490503549575806, GAN loss = [2.8479042, 0.9807516, 1.0900437]\n",
      "Batch 674/700: Discriminator loss = 1.1607805490493774, GAN loss = [2.9065847, 0.9865289, 1.1429933]\n",
      "Batch 675/700: Discriminator loss = 1.1476634740829468, GAN loss = [2.7420142, 0.9640561, 1.0009332]\n",
      "Batch 676/700: Discriminator loss = 1.1513590812683105, GAN loss = [2.9749784, 1.0233109, 1.1746749]\n",
      "Batch 677/700: Discriminator loss = 1.162320852279663, GAN loss = [2.7113416, 0.97807235, 0.9563048]\n",
      "Batch 678/700: Discriminator loss = 1.1864948272705078, GAN loss = [2.716636, 0.9371759, 1.0025252]\n",
      "Batch 679/700: Discriminator loss = 1.1679699420928955, GAN loss = [2.88636, 0.97848237, 1.1309627]\n",
      "Batch 680/700: Discriminator loss = 1.1375319957733154, GAN loss = [2.8600497, 0.99840736, 1.0847435]\n",
      "Batch 681/700: Discriminator loss = 1.1963155269622803, GAN loss = [2.895794, 0.9630746, 1.1558417]\n",
      "Batch 682/700: Discriminator loss = 1.1741825342178345, GAN loss = [2.7164638, 0.97321963, 0.9664048]\n",
      "Batch 683/700: Discriminator loss = 1.1769052743911743, GAN loss = [2.835796, 0.9612616, 1.0977294]\n",
      "Batch 684/700: Discriminator loss = 1.144195795059204, GAN loss = [2.8482587, 1.0177073, 1.0537772]\n",
      "Batch 685/700: Discriminator loss = 1.1572153568267822, GAN loss = [2.801531, 0.9853082, 1.0394925]\n",
      "Batch 686/700: Discriminator loss = 1.1430712938308716, GAN loss = [2.8173804, 0.995126, 1.0455681]\n",
      "Batch 687/700: Discriminator loss = 1.155841588973999, GAN loss = [2.7790127, 0.9652037, 1.0371699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 688/700: Discriminator loss = 1.1547374725341797, GAN loss = [2.7652073, 0.953856, 1.0347526]\n",
      "Batch 689/700: Discriminator loss = 1.143583059310913, GAN loss = [2.7964962, 0.97401506, 1.0459169]\n",
      "Batch 690/700: Discriminator loss = 1.1658921241760254, GAN loss = [2.7843246, 0.95173323, 1.05605]\n",
      "Batch 691/700: Discriminator loss = 1.1544040441513062, GAN loss = [2.8218613, 0.9673402, 1.0780045]\n",
      "Batch 692/700: Discriminator loss = 1.1863244771957397, GAN loss = [2.7909925, 0.9559977, 1.0585178]\n",
      "Batch 693/700: Discriminator loss = 1.1416294574737549, GAN loss = [2.7963257, 0.9751497, 1.0447428]\n",
      "Batch 694/700: Discriminator loss = 1.132617712020874, GAN loss = [2.9306026, 0.98498833, 1.1692306]\n",
      "Batch 695/700: Discriminator loss = 1.1532379388809204, GAN loss = [2.8692389, 1.0162407, 1.076668]\n",
      "Batch 696/700: Discriminator loss = 1.1236742734909058, GAN loss = [2.8212588, 1.0016216, 1.0433646]\n",
      "Batch 697/700: Discriminator loss = 1.1189457178115845, GAN loss = [2.9898918, 1.0239956, 1.1896815]\n",
      "Batch 698/700: Discriminator loss = 1.1203038692474365, GAN loss = [2.8281522, 0.98501617, 1.0669701]\n",
      "Batch 699/700: Discriminator loss = 1.1393275260925293, GAN loss = [2.8321667, 1.0000505, 1.0559936]\n",
      "Batch 700/700: Discriminator loss = 1.1112618446350098, GAN loss = [2.9204628, 1.0278682, 1.1165215]\n",
      "Epoch 10/30\n",
      "Batch 1/700: Discriminator loss = 1.172347903251648, GAN loss = [2.8768394, 0.9727417, 1.1280712]\n",
      "Batch 2/700: Discriminator loss = 1.1484386920928955, GAN loss = [2.8262374, 0.9766939, 1.073559]\n",
      "Batch 3/700: Discriminator loss = 1.1161961555480957, GAN loss = [2.8735807, 0.9973106, 1.1003349]\n",
      "Batch 4/700: Discriminator loss = 1.1229255199432373, GAN loss = [3.0593839, 1.0113837, 1.2721145]\n",
      "Batch 5/700: Discriminator loss = 1.1558032035827637, GAN loss = [2.853061, 0.97279173, 1.1044203]\n",
      "Batch 6/700: Discriminator loss = 1.135453462600708, GAN loss = [2.9636621, 1.0363308, 1.1515161]\n",
      "Batch 7/700: Discriminator loss = 1.1206490993499756, GAN loss = [3.047691, 1.0366117, 1.2352952]\n",
      "Batch 8/700: Discriminator loss = 1.1636282205581665, GAN loss = [2.8459282, 0.99910456, 1.0710856]\n",
      "Batch 9/700: Discriminator loss = 1.1171002388000488, GAN loss = [2.870424, 1.027055, 1.0676748]\n",
      "Batch 10/700: Discriminator loss = 1.1735526323318481, GAN loss = [2.9190235, 1.0028557, 1.14052]\n",
      "Batch 11/700: Discriminator loss = 1.1546818017959595, GAN loss = [2.934716, 0.99721074, 1.1619114]\n",
      "Batch 12/700: Discriminator loss = 1.1370398998260498, GAN loss = [2.914857, 1.0060778, 1.1332241]\n",
      "Batch 13/700: Discriminator loss = 1.1386432647705078, GAN loss = [2.8511963, 1.0004765, 1.0751936]\n",
      "Batch 14/700: Discriminator loss = 1.1138674020767212, GAN loss = [2.932908, 1.0286605, 1.1287467]\n",
      "Batch 15/700: Discriminator loss = 1.127277135848999, GAN loss = [2.9902182, 1.0353152, 1.1794325]\n",
      "Batch 16/700: Discriminator loss = 1.1360844373703003, GAN loss = [2.894466, 1.0019057, 1.1171206]\n",
      "Batch 17/700: Discriminator loss = 1.1466714143753052, GAN loss = [2.936735, 0.99283785, 1.168489]\n",
      "Batch 18/700: Discriminator loss = 1.1747568845748901, GAN loss = [2.8744848, 0.99279046, 1.1063225]\n",
      "Batch 19/700: Discriminator loss = 1.1563702821731567, GAN loss = [2.852132, 1.0283312, 1.0484678]\n",
      "Batch 20/700: Discriminator loss = 1.1656285524368286, GAN loss = [2.912534, 0.997633, 1.139599]\n",
      "Batch 21/700: Discriminator loss = 1.1358919143676758, GAN loss = [2.8224204, 0.9899777, 1.0571705]\n",
      "Batch 22/700: Discriminator loss = 1.1476985216140747, GAN loss = [2.8461046, 1.0053726, 1.0654923]\n",
      "Batch 23/700: Discriminator loss = 1.1590421199798584, GAN loss = [2.7968948, 0.97063833, 1.0510552]\n",
      "Batch 24/700: Discriminator loss = 1.1246821880340576, GAN loss = [2.7648597, 0.9936826, 0.9960062]\n",
      "Batch 25/700: Discriminator loss = 1.1693453788757324, GAN loss = [2.8050144, 0.96483046, 1.0650415]\n",
      "Batch 26/700: Discriminator loss = 1.1595104932785034, GAN loss = [2.9481108, 0.9952109, 1.1777819]\n",
      "Batch 27/700: Discriminator loss = 1.1724474430084229, GAN loss = [2.7969055, 1.0116426, 1.0101699]\n",
      "Batch 28/700: Discriminator loss = 1.196118712425232, GAN loss = [2.7140772, 0.9754545, 0.9635576]\n",
      "Batch 29/700: Discriminator loss = 1.1562480926513672, GAN loss = [2.8868692, 1.0037361, 1.1081024]\n",
      "Batch 30/700: Discriminator loss = 1.1816965341567993, GAN loss = [2.7624378, 0.9663241, 1.0211208]\n",
      "Batch 31/700: Discriminator loss = 1.1268285512924194, GAN loss = [2.7635937, 1.006989, 0.98165154]\n",
      "Batch 32/700: Discriminator loss = 1.1312543153762817, GAN loss = [2.825246, 1.0069487, 1.0433849]\n",
      "Batch 33/700: Discriminator loss = 1.1199219226837158, GAN loss = [2.939602, 1.012746, 1.1519856]\n",
      "Batch 34/700: Discriminator loss = 1.1108529567718506, GAN loss = [2.9345188, 1.0146186, 1.1450644]\n",
      "Batch 35/700: Discriminator loss = 1.1023207902908325, GAN loss = [2.9534018, 1.01952, 1.1590755]\n",
      "Batch 36/700: Discriminator loss = 1.1661537885665894, GAN loss = [2.839014, 0.98824155, 1.0760028]\n",
      "Batch 37/700: Discriminator loss = 1.1045265197753906, GAN loss = [3.0236535, 1.0330375, 1.2158779]\n",
      "Batch 38/700: Discriminator loss = 1.1248180866241455, GAN loss = [2.7950752, 0.9884412, 1.0319228]\n",
      "Batch 39/700: Discriminator loss = 1.1214501857757568, GAN loss = [3.0985293, 1.0171779, 1.3066677]\n",
      "Batch 40/700: Discriminator loss = 1.137574315071106, GAN loss = [2.9432795, 1.0536402, 1.1149948]\n",
      "Batch 41/700: Discriminator loss = 1.1256076097488403, GAN loss = [2.8436952, 1.03, 1.0390898]\n",
      "Batch 42/700: Discriminator loss = 1.1280683279037476, GAN loss = [2.9399571, 1.0138851, 1.1515087]\n",
      "Batch 43/700: Discriminator loss = 1.105539083480835, GAN loss = [2.9164512, 1.0234011, 1.1185293]\n",
      "Batch 44/700: Discriminator loss = 1.1278800964355469, GAN loss = [3.029523, 0.99594086, 1.2590966]\n",
      "Batch 45/700: Discriminator loss = 1.1396337747573853, GAN loss = [2.8261163, 0.9983892, 1.0532752]\n",
      "Batch 46/700: Discriminator loss = 1.1474568843841553, GAN loss = [2.9439662, 0.9794492, 1.1900982]\n",
      "Batch 47/700: Discriminator loss = 1.1525661945343018, GAN loss = [2.8029447, 0.9776917, 1.050866]\n",
      "Batch 48/700: Discriminator loss = 1.1382834911346436, GAN loss = [2.9149628, 1.0093217, 1.131293]\n",
      "Batch 49/700: Discriminator loss = 1.2162714004516602, GAN loss = [2.7288973, 0.94923097, 1.0053573]\n",
      "Batch 50/700: Discriminator loss = 1.1491819620132446, GAN loss = [2.8967705, 1.0257299, 1.0967602]\n",
      "Batch 51/700: Discriminator loss = 1.134882926940918, GAN loss = [3.033262, 0.99408644, 1.2649244]\n",
      "Batch 52/700: Discriminator loss = 1.1284918785095215, GAN loss = [2.8242836, 0.9811018, 1.0689461]\n",
      "Batch 53/700: Discriminator loss = 1.1753531694412231, GAN loss = [2.9027069, 0.979341, 1.1491505]\n",
      "Batch 54/700: Discriminator loss = 1.1687486171722412, GAN loss = [2.920139, 0.9818423, 1.1640916]\n",
      "Batch 55/700: Discriminator loss = 1.1644505262374878, GAN loss = [2.7415414, 0.9754409, 0.9919091]\n",
      "Batch 56/700: Discriminator loss = 1.1649370193481445, GAN loss = [2.7373722, 0.9738595, 0.9893464]\n",
      "Batch 57/700: Discriminator loss = 1.1663061380386353, GAN loss = [2.8595855, 0.9710655, 1.1143808]\n",
      "Batch 58/700: Discriminator loss = 1.155045986175537, GAN loss = [2.8619268, 0.97876513, 1.1090585]\n",
      "Batch 59/700: Discriminator loss = 1.2099642753601074, GAN loss = [2.778315, 0.96667844, 1.0375714]\n",
      "Batch 60/700: Discriminator loss = 1.198290228843689, GAN loss = [2.9510832, 0.99721557, 1.1798439]\n",
      "Batch 61/700: Discriminator loss = 1.1147234439849854, GAN loss = [2.911795, 1.035817, 1.1019847]\n",
      "Batch 62/700: Discriminator loss = 1.177875280380249, GAN loss = [2.8177502, 0.98175216, 1.0620319]\n",
      "Batch 63/700: Discriminator loss = 1.145981788635254, GAN loss = [2.8225355, 1.0078012, 1.0407965]\n",
      "Batch 64/700: Discriminator loss = 1.1880706548690796, GAN loss = [2.8626611, 1.009595, 1.0791507]\n",
      "Batch 65/700: Discriminator loss = 1.150615930557251, GAN loss = [2.8209884, 0.99134743, 1.0557522]\n",
      "Batch 66/700: Discriminator loss = 1.2026216983795166, GAN loss = [2.7520583, 0.9411574, 1.0370545]\n",
      "Batch 67/700: Discriminator loss = 1.159501552581787, GAN loss = [2.9929786, 1.0097264, 1.2094479]\n",
      "Batch 68/700: Discriminator loss = 1.1431750059127808, GAN loss = [2.90842, 0.9885637, 1.1460867]\n",
      "Batch 69/700: Discriminator loss = 1.1409494876861572, GAN loss = [2.859662, 1.0142758, 1.0716428]\n",
      "Batch 70/700: Discriminator loss = 1.1812671422958374, GAN loss = [2.752457, 0.98748076, 0.9912734]\n",
      "Batch 71/700: Discriminator loss = 1.1475684642791748, GAN loss = [2.9157953, 1.0214058, 1.1207372]\n",
      "Batch 72/700: Discriminator loss = 1.1446778774261475, GAN loss = [2.772735, 0.99684435, 1.0022786]\n",
      "Batch 73/700: Discriminator loss = 1.1521815061569214, GAN loss = [2.8109264, 0.9884159, 1.0489377]\n",
      "Batch 74/700: Discriminator loss = 1.1639983654022217, GAN loss = [2.8795214, 0.9778729, 1.1281111]\n",
      "Batch 75/700: Discriminator loss = 1.1726306676864624, GAN loss = [2.8012536, 0.9733797, 1.0543593]\n",
      "Batch 76/700: Discriminator loss = 1.1822967529296875, GAN loss = [2.8264802, 0.9952398, 1.057761]\n",
      "Batch 77/700: Discriminator loss = 1.1644271612167358, GAN loss = [2.8836362, 0.9918543, 1.1183351]\n",
      "Batch 78/700: Discriminator loss = 1.1470504999160767, GAN loss = [2.8750794, 1.011941, 1.0897282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 79/700: Discriminator loss = 1.164184808731079, GAN loss = [2.746904, 0.98040444, 0.99313116]\n",
      "Batch 80/700: Discriminator loss = 1.1576414108276367, GAN loss = [2.8879762, 1.0257404, 1.0889086]\n",
      "Batch 81/700: Discriminator loss = 1.1485724449157715, GAN loss = [2.7936656, 1.0055709, 1.0148163]\n",
      "Batch 82/700: Discriminator loss = 1.1797624826431274, GAN loss = [2.7468832, 1.013217, 0.96043015]\n",
      "Batch 83/700: Discriminator loss = 1.1625155210494995, GAN loss = [2.8881085, 0.9922448, 1.122681]\n",
      "Batch 84/700: Discriminator loss = 1.1402100324630737, GAN loss = [2.9236605, 1.0275079, 1.1230246]\n",
      "Batch 85/700: Discriminator loss = 1.1190038919448853, GAN loss = [2.7272117, 1.0164137, 0.93772346]\n",
      "Batch 86/700: Discriminator loss = 1.1088240146636963, GAN loss = [2.848894, 1.0011897, 1.074684]\n",
      "Batch 87/700: Discriminator loss = 1.1745283603668213, GAN loss = [2.9375644, 1.0138396, 1.1507574]\n",
      "Batch 88/700: Discriminator loss = 1.1160860061645508, GAN loss = [2.798456, 1.0250163, 1.0005184]\n",
      "Batch 89/700: Discriminator loss = 1.1623300313949585, GAN loss = [2.8025334, 0.9690536, 1.0606055]\n",
      "Batch 90/700: Discriminator loss = 1.1418052911758423, GAN loss = [2.8722854, 1.0111301, 1.0883329]\n",
      "Batch 91/700: Discriminator loss = 1.1342865228652954, GAN loss = [2.8134067, 1.0005465, 1.0400975]\n",
      "Batch 92/700: Discriminator loss = 1.1674630641937256, GAN loss = [2.745384, 0.98744094, 0.98523825]\n",
      "Batch 93/700: Discriminator loss = 1.1059954166412354, GAN loss = [2.951968, 1.0447243, 1.1345878]\n",
      "Batch 94/700: Discriminator loss = 1.1335077285766602, GAN loss = [2.8314512, 1.0036528, 1.0551878]\n",
      "Batch 95/700: Discriminator loss = 1.1487339735031128, GAN loss = [2.8948414, 0.9812534, 1.141024]\n",
      "Batch 96/700: Discriminator loss = 1.1304147243499756, GAN loss = [2.8317747, 0.99671865, 1.0625377]\n",
      "Batch 97/700: Discriminator loss = 1.1223646402359009, GAN loss = [3.0419793, 1.0426652, 1.2268405]\n",
      "Batch 98/700: Discriminator loss = 1.1257116794586182, GAN loss = [2.9050794, 1.0314962, 1.1011566]\n",
      "Batch 99/700: Discriminator loss = 1.1092960834503174, GAN loss = [3.074403, 1.0552125, 1.2468201]\n",
      "Batch 100/700: Discriminator loss = 1.1197729110717773, GAN loss = [2.938672, 1.0070255, 1.1593343]\n",
      "Batch 101/700: Discriminator loss = 1.1312460899353027, GAN loss = [2.8349435, 0.98978746, 1.0728977]\n",
      "Batch 102/700: Discriminator loss = 1.1310131549835205, GAN loss = [2.8644793, 1.0093056, 1.0829608]\n",
      "Batch 103/700: Discriminator loss = 1.143636703491211, GAN loss = [2.775878, 0.98969984, 1.0140116]\n",
      "Batch 104/700: Discriminator loss = 1.1573904752731323, GAN loss = [2.88504, 0.99087524, 1.1220405]\n",
      "Batch 105/700: Discriminator loss = 1.166977882385254, GAN loss = [2.8211055, 1.0075464, 1.0414779]\n",
      "Batch 106/700: Discriminator loss = 1.172365427017212, GAN loss = [2.9085097, 1.0184914, 1.1179787]\n",
      "Batch 107/700: Discriminator loss = 1.1345446109771729, GAN loss = [2.820129, 0.99998045, 1.0481548]\n",
      "Batch 108/700: Discriminator loss = 1.134928822517395, GAN loss = [2.7830863, 1.0240874, 0.9870519]\n",
      "Batch 109/700: Discriminator loss = 1.133196473121643, GAN loss = [2.894895, 1.0180923, 1.1048943]\n",
      "Batch 110/700: Discriminator loss = 1.1560792922973633, GAN loss = [2.8197708, 0.9818797, 1.0660162]\n",
      "Batch 111/700: Discriminator loss = 1.1546063423156738, GAN loss = [2.8304617, 0.9794598, 1.0791646]\n",
      "Batch 112/700: Discriminator loss = 1.144471287727356, GAN loss = [2.8993773, 0.9899715, 1.1376108]\n",
      "Batch 113/700: Discriminator loss = 1.1183149814605713, GAN loss = [2.9912326, 1.0235586, 1.1959194]\n",
      "Batch 114/700: Discriminator loss = 1.101995587348938, GAN loss = [2.9638033, 1.0331627, 1.1589297]\n",
      "Batch 115/700: Discriminator loss = 1.120600700378418, GAN loss = [2.8191292, 0.9969219, 1.0505413]\n",
      "Batch 116/700: Discriminator loss = 1.1514394283294678, GAN loss = [2.8587976, 0.97359705, 1.1135806]\n",
      "Batch 117/700: Discriminator loss = 1.1214916706085205, GAN loss = [2.9189117, 1.0032783, 1.1440587]\n",
      "Batch 118/700: Discriminator loss = 1.1693999767303467, GAN loss = [2.9012969, 0.95587265, 1.173895]\n",
      "Batch 119/700: Discriminator loss = 1.1631654500961304, GAN loss = [2.825652, 0.98410016, 1.0700611]\n",
      "Batch 120/700: Discriminator loss = 1.1455918550491333, GAN loss = [2.8275607, 0.9891809, 1.0669239]\n",
      "Batch 121/700: Discriminator loss = 1.1518971920013428, GAN loss = [2.9095783, 0.996521, 1.1416287]\n",
      "Batch 122/700: Discriminator loss = 1.14127516746521, GAN loss = [2.8406684, 0.99823904, 1.0710415]\n",
      "Batch 123/700: Discriminator loss = 1.139731526374817, GAN loss = [2.8173401, 0.9830205, 1.062974]\n",
      "Batch 124/700: Discriminator loss = 1.1392848491668701, GAN loss = [2.7252243, 0.9617219, 0.992202]\n",
      "Batch 125/700: Discriminator loss = 1.1634981632232666, GAN loss = [2.8099475, 0.9948889, 1.0437888]\n",
      "Batch 126/700: Discriminator loss = 1.1677968502044678, GAN loss = [2.7913957, 1.0070487, 1.0131167]\n",
      "Batch 127/700: Discriminator loss = 1.132511854171753, GAN loss = [2.8856742, 1.0135298, 1.1009468]\n",
      "Batch 128/700: Discriminator loss = 1.1584177017211914, GAN loss = [2.773445, 0.95922244, 1.0430523]\n",
      "Batch 129/700: Discriminator loss = 1.1374948024749756, GAN loss = [2.786669, 1.0177938, 0.99773514]\n",
      "Batch 130/700: Discriminator loss = 1.1305955648422241, GAN loss = [2.8302689, 0.99986386, 1.0593013]\n",
      "Batch 131/700: Discriminator loss = 1.1709619760513306, GAN loss = [2.8541079, 0.9869505, 1.0960921]\n",
      "Batch 132/700: Discriminator loss = 1.1583315134048462, GAN loss = [2.798956, 0.99663794, 1.0312995]\n",
      "Batch 133/700: Discriminator loss = 1.1539143323898315, GAN loss = [2.811732, 0.96204776, 1.0787177]\n",
      "Batch 134/700: Discriminator loss = 1.2083595991134644, GAN loss = [2.6951, 0.9468769, 0.97730005]\n",
      "Batch 135/700: Discriminator loss = 1.1997671127319336, GAN loss = [2.7141047, 0.95417404, 0.9890541]\n",
      "Batch 136/700: Discriminator loss = 1.1555417776107788, GAN loss = [2.8527622, 0.99965537, 1.0822664]\n",
      "Batch 137/700: Discriminator loss = 1.2067278623580933, GAN loss = [2.7410254, 0.9344204, 1.0357989]\n",
      "Batch 138/700: Discriminator loss = 1.1173783540725708, GAN loss = [2.7305274, 1.0168759, 0.9428807]\n",
      "Batch 139/700: Discriminator loss = 1.1575908660888672, GAN loss = [2.8496585, 0.9982344, 1.0806991]\n",
      "Batch 140/700: Discriminator loss = 1.152071475982666, GAN loss = [2.8202558, 0.9938002, 1.0557733]\n",
      "Batch 141/700: Discriminator loss = 1.1432552337646484, GAN loss = [2.9473803, 1.0367463, 1.1399913]\n",
      "Batch 142/700: Discriminator loss = 1.1421715021133423, GAN loss = [2.8575845, 1.0260522, 1.0609274]\n",
      "Batch 143/700: Discriminator loss = 1.1468230485916138, GAN loss = [2.863594, 1.0103822, 1.0826612]\n",
      "Batch 144/700: Discriminator loss = 1.1766153573989868, GAN loss = [2.813226, 0.98313195, 1.0595928]\n",
      "Batch 145/700: Discriminator loss = 1.18084716796875, GAN loss = [2.791791, 0.97648156, 1.0448536]\n",
      "Batch 146/700: Discriminator loss = 1.1621198654174805, GAN loss = [2.7637868, 0.985573, 1.0078003]\n",
      "Batch 147/700: Discriminator loss = 1.10873544216156, GAN loss = [2.8300047, 1.0423663, 1.01726]\n",
      "Batch 148/700: Discriminator loss = 1.143572211265564, GAN loss = [2.8470297, 1.0202848, 1.0563968]\n",
      "Batch 149/700: Discriminator loss = 1.1877557039260864, GAN loss = [2.7869308, 0.9899085, 1.0267031]\n",
      "Batch 150/700: Discriminator loss = 1.1932939291000366, GAN loss = [2.7758777, 0.9943494, 1.0112418]\n",
      "Batch 151/700: Discriminator loss = 1.1437023878097534, GAN loss = [2.8158002, 1.0367997, 1.0087612]\n",
      "Batch 152/700: Discriminator loss = 1.1780731678009033, GAN loss = [2.7989464, 1.006089, 1.0226506]\n",
      "Batch 153/700: Discriminator loss = 1.147764801979065, GAN loss = [2.8332524, 1.0099798, 1.0530936]\n",
      "Batch 154/700: Discriminator loss = 1.1569898128509521, GAN loss = [2.7548928, 0.9907652, 0.9939757]\n",
      "Batch 155/700: Discriminator loss = 1.1385295391082764, GAN loss = [2.8147614, 1.0536569, 0.9909928]\n",
      "Batch 156/700: Discriminator loss = 1.1864761114120483, GAN loss = [2.7555394, 0.9969113, 0.98854524]\n",
      "Batch 157/700: Discriminator loss = 1.1559507846832275, GAN loss = [2.722056, 0.97405684, 0.97794116]\n",
      "Batch 158/700: Discriminator loss = 1.1896982192993164, GAN loss = [2.690076, 0.9358687, 0.9841714]\n",
      "Batch 159/700: Discriminator loss = 1.1947150230407715, GAN loss = [2.6538694, 0.94502413, 0.93882805]\n",
      "Batch 160/700: Discriminator loss = 1.153822660446167, GAN loss = [2.7927108, 1.0127265, 1.0099889]\n",
      "Batch 161/700: Discriminator loss = 1.2147250175476074, GAN loss = [2.6571345, 0.9287524, 0.9583975]\n",
      "Batch 162/700: Discriminator loss = 1.1877789497375488, GAN loss = [2.7196984, 0.96871436, 0.98100615]\n",
      "Batch 163/700: Discriminator loss = 1.1593631505966187, GAN loss = [2.7139733, 0.9640974, 0.97991294]\n",
      "Batch 164/700: Discriminator loss = 1.2132896184921265, GAN loss = [2.6640842, 0.9646264, 0.9295141]\n",
      "Batch 165/700: Discriminator loss = 1.2201718091964722, GAN loss = [2.7060118, 0.94549024, 0.99059016]\n",
      "Batch 166/700: Discriminator loss = 1.2217564582824707, GAN loss = [2.6488075, 0.8981073, 0.98077893]\n",
      "Batch 167/700: Discriminator loss = 1.2338818311691284, GAN loss = [2.5619292, 0.88695145, 0.9050683]\n",
      "Batch 168/700: Discriminator loss = 1.2117619514465332, GAN loss = [2.6424527, 0.930149, 0.9424107]\n",
      "Batch 169/700: Discriminator loss = 1.2264450788497925, GAN loss = [2.5676706, 0.9072677, 0.8905424]\n",
      "Batch 170/700: Discriminator loss = 1.169697880744934, GAN loss = [2.7115102, 0.936945, 1.0047373]\n",
      "Batch 171/700: Discriminator loss = 1.1832116842269897, GAN loss = [2.7220397, 0.9663588, 0.98587805]\n",
      "Batch 172/700: Discriminator loss = 1.1910803318023682, GAN loss = [2.674143, 0.9527068, 0.9516534]\n",
      "Batch 173/700: Discriminator loss = 1.1721923351287842, GAN loss = [2.650868, 0.9727131, 0.90839785]\n",
      "Batch 174/700: Discriminator loss = 1.141928791999817, GAN loss = [2.8304274, 0.99086684, 1.0698383]\n",
      "Batch 175/700: Discriminator loss = 1.1576036214828491, GAN loss = [2.7578197, 0.9730623, 1.0150703]\n",
      "Batch 176/700: Discriminator loss = 1.152713418006897, GAN loss = [2.7913902, 0.96060586, 1.0611255]\n",
      "Batch 177/700: Discriminator loss = 1.1531121730804443, GAN loss = [2.8676553, 0.97934294, 1.1186814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 178/700: Discriminator loss = 1.169187068939209, GAN loss = [2.7563312, 0.9493401, 1.0373793]\n",
      "Batch 179/700: Discriminator loss = 1.1514726877212524, GAN loss = [2.74488, 0.9802584, 0.9950374]\n",
      "Batch 180/700: Discriminator loss = 1.1759101152420044, GAN loss = [2.8005667, 0.971375, 1.0596421]\n",
      "Batch 181/700: Discriminator loss = 1.1803202629089355, GAN loss = [2.7446442, 0.95504576, 1.0200939]\n",
      "Batch 182/700: Discriminator loss = 1.1914726495742798, GAN loss = [2.7996416, 0.9730361, 1.0571406]\n",
      "Batch 183/700: Discriminator loss = 1.121004343032837, GAN loss = [2.8269658, 1.0015584, 1.0559733]\n",
      "Batch 184/700: Discriminator loss = 1.1417180299758911, GAN loss = [2.8062227, 1.0020183, 1.034806]\n",
      "Batch 185/700: Discriminator loss = 1.1624457836151123, GAN loss = [2.798882, 0.9851025, 1.0444179]\n",
      "Batch 186/700: Discriminator loss = 1.1713314056396484, GAN loss = [2.7903764, 0.9817234, 1.0393364]\n",
      "Batch 187/700: Discriminator loss = 1.1490734815597534, GAN loss = [2.7628243, 0.9787881, 1.0147741]\n",
      "Batch 188/700: Discriminator loss = 1.1743617057800293, GAN loss = [2.8024824, 0.966048, 1.0672222]\n",
      "Batch 189/700: Discriminator loss = 1.0998797416687012, GAN loss = [2.8755074, 1.0414417, 1.0649099]\n",
      "Batch 190/700: Discriminator loss = 1.11647367477417, GAN loss = [2.8970568, 1.0250462, 1.1029116]\n",
      "Batch 191/700: Discriminator loss = 1.122277855873108, GAN loss = [2.8056848, 1.0049347, 1.0317045]\n",
      "Batch 192/700: Discriminator loss = 1.1992632150650024, GAN loss = [2.75123, 0.9574441, 1.0247954]\n",
      "Batch 193/700: Discriminator loss = 1.1672099828720093, GAN loss = [2.8065434, 0.98578525, 1.0518119]\n",
      "Batch 194/700: Discriminator loss = 1.1344820261001587, GAN loss = [2.7626545, 0.99041677, 1.0033336]\n",
      "Batch 195/700: Discriminator loss = 1.1136317253112793, GAN loss = [2.8770938, 1.0374864, 1.0707377]\n",
      "Batch 196/700: Discriminator loss = 1.1281309127807617, GAN loss = [2.809061, 1.0013809, 1.0388384]\n",
      "Batch 197/700: Discriminator loss = 1.1326985359191895, GAN loss = [2.8441706, 1.0277616, 1.047591]\n",
      "Batch 198/700: Discriminator loss = 1.1457825899124146, GAN loss = [2.746992, 0.98818153, 0.9900244]\n",
      "Batch 199/700: Discriminator loss = 1.138629674911499, GAN loss = [2.8398664, 0.9987397, 1.0723766]\n",
      "Batch 200/700: Discriminator loss = 1.1619493961334229, GAN loss = [2.8762937, 0.97278905, 1.1347922]\n",
      "Batch 201/700: Discriminator loss = 1.1278177499771118, GAN loss = [2.9128966, 1.0124011, 1.1318319]\n",
      "Batch 202/700: Discriminator loss = 1.1625124216079712, GAN loss = [2.7766535, 0.9774427, 1.0305855]\n",
      "Batch 203/700: Discriminator loss = 1.1619616746902466, GAN loss = [2.7683775, 0.9833709, 1.0164185]\n",
      "Batch 204/700: Discriminator loss = 1.1375569105148315, GAN loss = [2.8917975, 1.0136406, 1.1095958]\n",
      "Batch 205/700: Discriminator loss = 1.1054630279541016, GAN loss = [2.868212, 1.0166262, 1.0830507]\n",
      "Batch 206/700: Discriminator loss = 1.1673730611801147, GAN loss = [2.8612669, 0.97696996, 1.1157823]\n",
      "Batch 207/700: Discriminator loss = 1.1572669744491577, GAN loss = [2.8938966, 1.0055224, 1.1198907]\n",
      "Batch 208/700: Discriminator loss = 1.1461595296859741, GAN loss = [2.8042736, 0.9774412, 1.0583946]\n",
      "Batch 209/700: Discriminator loss = 1.1706079244613647, GAN loss = [2.8093696, 0.98734885, 1.053625]\n",
      "Batch 210/700: Discriminator loss = 1.1623152494430542, GAN loss = [2.7791204, 0.95131284, 1.0594474]\n",
      "Batch 211/700: Discriminator loss = 1.1324236392974854, GAN loss = [2.8236997, 0.98904455, 1.0663352]\n",
      "Batch 212/700: Discriminator loss = 1.193402886390686, GAN loss = [2.667563, 0.94174886, 0.95753443]\n",
      "Batch 213/700: Discriminator loss = 1.1784924268722534, GAN loss = [2.7505238, 0.9457656, 1.0365127]\n",
      "Batch 214/700: Discriminator loss = 1.1476224660873413, GAN loss = [2.8321881, 0.9655029, 1.0984719]\n",
      "Batch 215/700: Discriminator loss = 1.1535288095474243, GAN loss = [2.7681782, 0.96155113, 1.0384403]\n",
      "Batch 216/700: Discriminator loss = 1.2008962631225586, GAN loss = [2.7707198, 0.9318373, 1.0707225]\n",
      "Batch 217/700: Discriminator loss = 1.1755990982055664, GAN loss = [2.7764487, 0.96230775, 1.0460187]\n",
      "Batch 218/700: Discriminator loss = 1.1511709690093994, GAN loss = [2.7765105, 0.9670607, 1.041367]\n",
      "Batch 219/700: Discriminator loss = 1.146670937538147, GAN loss = [2.7219045, 0.97236013, 0.9814993]\n",
      "Batch 220/700: Discriminator loss = 1.1913589239120483, GAN loss = [2.7457669, 0.9469904, 1.0307565]\n",
      "Batch 221/700: Discriminator loss = 1.1643896102905273, GAN loss = [2.8470163, 0.9644994, 1.1145285]\n",
      "Batch 222/700: Discriminator loss = 1.1624962091445923, GAN loss = [2.8410127, 0.96060896, 1.1124424]\n",
      "Batch 223/700: Discriminator loss = 1.1693401336669922, GAN loss = [2.7548316, 0.9693099, 1.0175818]\n",
      "Batch 224/700: Discriminator loss = 1.1454896926879883, GAN loss = [2.7653124, 0.97967225, 1.0177209]\n",
      "Batch 225/700: Discriminator loss = 1.1657590866088867, GAN loss = [2.6653092, 0.95413214, 0.94327676]\n",
      "Batch 226/700: Discriminator loss = 1.1776165962219238, GAN loss = [2.7353523, 0.9618109, 1.0056677]\n",
      "Batch 227/700: Discriminator loss = 1.176877737045288, GAN loss = [2.8158681, 0.95768064, 1.0903299]\n",
      "Batch 228/700: Discriminator loss = 1.1306475400924683, GAN loss = [2.8011067, 0.9775195, 1.0557466]\n",
      "Batch 229/700: Discriminator loss = 1.193129301071167, GAN loss = [2.6691573, 0.94250596, 0.9588367]\n",
      "Batch 230/700: Discriminator loss = 1.135101318359375, GAN loss = [2.8707075, 0.96330035, 1.1396143]\n",
      "Batch 231/700: Discriminator loss = 1.1288996934890747, GAN loss = [2.850898, 0.9703238, 1.1128066]\n",
      "Batch 232/700: Discriminator loss = 1.1636685132980347, GAN loss = [2.8019178, 0.9503688, 1.083804]\n",
      "Batch 233/700: Discriminator loss = 1.1530801057815552, GAN loss = [2.8260047, 0.9636824, 1.0946078]\n",
      "Batch 234/700: Discriminator loss = 1.1468110084533691, GAN loss = [2.8315384, 0.9619262, 1.1019177]\n",
      "Batch 235/700: Discriminator loss = 1.1330949068069458, GAN loss = [2.7954023, 0.9882084, 1.0395212]\n",
      "Batch 236/700: Discriminator loss = 1.1340882778167725, GAN loss = [2.9700327, 0.9906387, 1.2117491]\n",
      "Batch 237/700: Discriminator loss = 1.1668862104415894, GAN loss = [2.9432387, 0.95697725, 1.2186389]\n",
      "Batch 238/700: Discriminator loss = 1.1622984409332275, GAN loss = [2.7609434, 0.9653846, 1.0279496]\n",
      "Batch 239/700: Discriminator loss = 1.1377226114273071, GAN loss = [2.8208392, 0.98981935, 1.0634212]\n",
      "Batch 240/700: Discriminator loss = 1.1683292388916016, GAN loss = [2.8989372, 0.9444178, 1.1869466]\n",
      "Batch 241/700: Discriminator loss = 1.1280990839004517, GAN loss = [2.8223636, 0.98404396, 1.0707774]\n",
      "Batch 242/700: Discriminator loss = 1.142584204673767, GAN loss = [2.8500226, 0.9798608, 1.1026433]\n",
      "Batch 243/700: Discriminator loss = 1.1496115922927856, GAN loss = [2.84916, 0.9837393, 1.0979226]\n",
      "Batch 244/700: Discriminator loss = 1.1308308839797974, GAN loss = [2.89145, 0.99123055, 1.1327423]\n",
      "Batch 245/700: Discriminator loss = 1.13235604763031, GAN loss = [3.028703, 0.9823747, 1.2788614]\n",
      "Batch 246/700: Discriminator loss = 1.1824777126312256, GAN loss = [2.797501, 0.9219416, 1.1081021]\n",
      "Batch 247/700: Discriminator loss = 1.152161717414856, GAN loss = [2.937975, 0.9487699, 1.221758]\n",
      "Batch 248/700: Discriminator loss = 1.1773427724838257, GAN loss = [2.721677, 0.9405197, 1.01372]\n",
      "Batch 249/700: Discriminator loss = 1.1686129570007324, GAN loss = [2.9395604, 0.93629354, 1.2358462]\n",
      "Batch 250/700: Discriminator loss = 1.1402404308319092, GAN loss = [2.9360957, 0.98517096, 1.183529]\n",
      "Batch 251/700: Discriminator loss = 1.1266525983810425, GAN loss = [3.141453, 0.98019165, 1.3938875]\n",
      "Batch 252/700: Discriminator loss = 1.1469087600708008, GAN loss = [2.9425216, 0.9827813, 1.1923964]\n",
      "Batch 253/700: Discriminator loss = 1.1702744960784912, GAN loss = [3.0676167, 0.9915464, 1.3087564]\n",
      "Batch 254/700: Discriminator loss = 1.1610254049301147, GAN loss = [2.9279165, 0.9894403, 1.1711895]\n",
      "Batch 255/700: Discriminator loss = 1.153591513633728, GAN loss = [2.7142673, 0.96998656, 0.9770235]\n",
      "Batch 256/700: Discriminator loss = 1.147969365119934, GAN loss = [2.8304226, 0.9817203, 1.0814587]\n",
      "Batch 257/700: Discriminator loss = 1.1170047521591187, GAN loss = [3.020011, 0.976529, 1.2762504]\n",
      "Batch 258/700: Discriminator loss = 1.1424789428710938, GAN loss = [3.020253, 0.9509501, 1.302081]\n",
      "Batch 259/700: Discriminator loss = 1.1265252828598022, GAN loss = [2.9630342, 0.9840213, 1.2118071]\n",
      "Batch 260/700: Discriminator loss = 1.1111775636672974, GAN loss = [2.9667323, 0.97712165, 1.2224334]\n",
      "Batch 261/700: Discriminator loss = 1.1809368133544922, GAN loss = [2.760242, 0.9418487, 1.0512422]\n",
      "Batch 262/700: Discriminator loss = 1.1753132343292236, GAN loss = [2.8455076, 0.95780337, 1.1205945]\n",
      "Batch 263/700: Discriminator loss = 1.1448752880096436, GAN loss = [2.8940868, 0.96615815, 1.1608561]\n",
      "Batch 264/700: Discriminator loss = 1.1369216442108154, GAN loss = [2.8345382, 0.97186464, 1.0956204]\n",
      "Batch 265/700: Discriminator loss = 1.1814601421356201, GAN loss = [2.8580337, 0.946494, 1.1444992]\n",
      "Batch 266/700: Discriminator loss = 1.209022045135498, GAN loss = [2.869022, 0.94405264, 1.1579351]\n",
      "Batch 267/700: Discriminator loss = 1.1696069240570068, GAN loss = [2.8907392, 0.9563737, 1.1673493]\n",
      "Batch 268/700: Discriminator loss = 1.1583912372589111, GAN loss = [2.814704, 0.9826319, 1.0650791]\n",
      "Batch 269/700: Discriminator loss = 1.1898419857025146, GAN loss = [2.820189, 0.98715377, 1.0660664]\n",
      "Batch 270/700: Discriminator loss = 1.1955060958862305, GAN loss = [2.919963, 0.94799006, 1.2050312]\n",
      "Batch 271/700: Discriminator loss = 1.1527878046035767, GAN loss = [2.8410773, 1.0089242, 1.0652401]\n",
      "Batch 272/700: Discriminator loss = 1.1799780130386353, GAN loss = [2.8214362, 0.97445375, 1.0800933]\n",
      "Batch 273/700: Discriminator loss = 1.16920804977417, GAN loss = [2.87762, 0.9462974, 1.1644709]\n",
      "Batch 274/700: Discriminator loss = 1.1637550592422485, GAN loss = [2.7646637, 0.9518934, 1.0459503]\n",
      "Batch 275/700: Discriminator loss = 1.1537983417510986, GAN loss = [2.7556536, 0.9666734, 1.0221852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 276/700: Discriminator loss = 1.1662099361419678, GAN loss = [2.9538083, 0.962843, 1.2241975]\n",
      "Batch 277/700: Discriminator loss = 1.1655478477478027, GAN loss = [2.847212, 0.97670996, 1.1037599]\n",
      "Batch 278/700: Discriminator loss = 1.1949553489685059, GAN loss = [2.7094607, 0.91113496, 1.0316085]\n",
      "Batch 279/700: Discriminator loss = 1.1575696468353271, GAN loss = [2.8211303, 0.9651016, 1.0893292]\n",
      "Batch 280/700: Discriminator loss = 1.1884621381759644, GAN loss = [2.876952, 0.9361241, 1.1741585]\n",
      "Batch 281/700: Discriminator loss = 1.1770151853561401, GAN loss = [2.882325, 0.9383422, 1.1773368]\n",
      "Batch 282/700: Discriminator loss = 1.2023296356201172, GAN loss = [2.7902346, 0.93210846, 1.0914934]\n",
      "Batch 283/700: Discriminator loss = 1.2130749225616455, GAN loss = [2.7531188, 0.89975476, 1.0867453]\n",
      "Batch 284/700: Discriminator loss = 1.1985950469970703, GAN loss = [2.855515, 0.9508966, 1.1380124]\n",
      "Batch 285/700: Discriminator loss = 1.164417028427124, GAN loss = [2.7779105, 0.95033145, 1.060988]\n",
      "Batch 286/700: Discriminator loss = 1.193715214729309, GAN loss = [2.7061465, 0.9389822, 1.0006034]\n",
      "Batch 287/700: Discriminator loss = 1.173217535018921, GAN loss = [2.8802853, 0.97878385, 1.1349531]\n",
      "Batch 288/700: Discriminator loss = 1.1835212707519531, GAN loss = [2.8957865, 0.9827095, 1.1465424]\n",
      "Batch 289/700: Discriminator loss = 1.2014797925949097, GAN loss = [2.9393094, 0.973066, 1.199727]\n",
      "Batch 290/700: Discriminator loss = 1.1018588542938232, GAN loss = [2.9578831, 1.0126371, 1.1787401]\n",
      "Batch 291/700: Discriminator loss = 1.2034211158752441, GAN loss = [2.7940412, 0.93556154, 1.0919753]\n",
      "Batch 292/700: Discriminator loss = 1.195723533630371, GAN loss = [2.7224655, 0.9333017, 1.0226545]\n",
      "Batch 293/700: Discriminator loss = 1.185158133506775, GAN loss = [2.7762792, 0.9567059, 1.053066]\n",
      "Batch 294/700: Discriminator loss = 1.231091856956482, GAN loss = [2.7644558, 0.9020612, 1.0959011]\n",
      "Batch 295/700: Discriminator loss = 1.1786044836044312, GAN loss = [2.8563938, 0.9570212, 1.1328974]\n",
      "Batch 296/700: Discriminator loss = 1.2325270175933838, GAN loss = [2.6533728, 0.91814226, 0.9687756]\n",
      "Batch 297/700: Discriminator loss = 1.1850650310516357, GAN loss = [2.831551, 0.9596961, 1.1054187]\n",
      "Batch 298/700: Discriminator loss = 1.1790692806243896, GAN loss = [2.6824732, 0.95150656, 0.9645482]\n",
      "Batch 299/700: Discriminator loss = 1.1911211013793945, GAN loss = [2.7222188, 0.91345876, 1.0423542]\n",
      "Batch 300/700: Discriminator loss = 1.187831163406372, GAN loss = [2.7156997, 0.92855024, 1.0207616]\n",
      "Batch 301/700: Discriminator loss = 1.2136000394821167, GAN loss = [2.7913656, 0.9445247, 1.0804678]\n",
      "Batch 302/700: Discriminator loss = 1.210671067237854, GAN loss = [2.8093417, 0.95126504, 1.0917168]\n",
      "Batch 303/700: Discriminator loss = 1.127851963043213, GAN loss = [2.8699267, 1.0445541, 1.0590355]\n",
      "Batch 304/700: Discriminator loss = 1.205731987953186, GAN loss = [2.707538, 0.92816305, 1.0130665]\n",
      "Batch 305/700: Discriminator loss = 1.203866958618164, GAN loss = [2.7033062, 0.92813027, 1.0088996]\n",
      "Batch 306/700: Discriminator loss = 1.1406375169754028, GAN loss = [2.83093, 0.9945507, 1.070115]\n",
      "Batch 307/700: Discriminator loss = 1.2525900602340698, GAN loss = [2.6575232, 0.90252686, 0.988744]\n",
      "Batch 308/700: Discriminator loss = 1.1805775165557861, GAN loss = [2.7723694, 0.981565, 1.0245641]\n",
      "Batch 309/700: Discriminator loss = 1.1766538619995117, GAN loss = [2.7053785, 0.952243, 0.9869129]\n",
      "Batch 310/700: Discriminator loss = 1.173213243484497, GAN loss = [2.8150694, 0.95639586, 1.092461]\n",
      "Batch 311/700: Discriminator loss = 1.1811399459838867, GAN loss = [2.7383666, 0.9542614, 1.0178914]\n",
      "Batch 312/700: Discriminator loss = 1.2150837182998657, GAN loss = [2.7369502, 0.9597757, 1.0109658]\n",
      "Batch 313/700: Discriminator loss = 1.1608514785766602, GAN loss = [2.6932516, 0.95891523, 0.96814]\n",
      "Batch 314/700: Discriminator loss = 1.1639596223831177, GAN loss = [2.7246892, 0.96736383, 0.99113375]\n",
      "Batch 315/700: Discriminator loss = 1.1678978204727173, GAN loss = [2.640216, 0.9472153, 0.92681867]\n",
      "Batch 316/700: Discriminator loss = 1.1683727502822876, GAN loss = [2.7053375, 0.9613326, 0.97783965]\n",
      "Batch 317/700: Discriminator loss = 1.1762821674346924, GAN loss = [2.7862785, 0.96932775, 1.0508218]\n",
      "Batch 318/700: Discriminator loss = 1.1363723278045654, GAN loss = [2.7369733, 0.97264093, 0.9982336]\n",
      "Batch 319/700: Discriminator loss = 1.1611328125, GAN loss = [2.8011992, 0.96704775, 1.0680789]\n",
      "Batch 320/700: Discriminator loss = 1.160375952720642, GAN loss = [2.7917295, 0.9748013, 1.0508909]\n",
      "Batch 321/700: Discriminator loss = 1.161099910736084, GAN loss = [2.7262812, 0.9770935, 0.9831818]\n",
      "Batch 322/700: Discriminator loss = 1.1271467208862305, GAN loss = [2.8585448, 1.0020074, 1.0905719]\n",
      "Batch 323/700: Discriminator loss = 1.13886296749115, GAN loss = [2.8152003, 1.0042824, 1.0449841]\n",
      "Batch 324/700: Discriminator loss = 1.1479003429412842, GAN loss = [2.7580884, 0.9764914, 1.0156981]\n",
      "Batch 325/700: Discriminator loss = 1.1065150499343872, GAN loss = [2.854714, 1.0216815, 1.0671608]\n",
      "Batch 326/700: Discriminator loss = 1.1501011848449707, GAN loss = [2.7736235, 0.98002136, 1.027758]\n",
      "Batch 327/700: Discriminator loss = 1.160483717918396, GAN loss = [2.7245529, 0.95326877, 1.0054595]\n",
      "Batch 328/700: Discriminator loss = 1.155670404434204, GAN loss = [2.8869267, 1.0409309, 1.0801964]\n",
      "Batch 329/700: Discriminator loss = 1.1716840267181396, GAN loss = [2.767983, 0.9691356, 1.0330795]\n",
      "Batch 330/700: Discriminator loss = 1.1466463804244995, GAN loss = [2.8679302, 1.0060948, 1.0960891]\n",
      "Batch 331/700: Discriminator loss = 1.1243137121200562, GAN loss = [2.8751974, 0.9943515, 1.1151241]\n",
      "Batch 332/700: Discriminator loss = 1.1878070831298828, GAN loss = [2.772507, 0.94667006, 1.060147]\n",
      "Batch 333/700: Discriminator loss = 1.1602164506912231, GAN loss = [2.8457243, 0.97226614, 1.1077938]\n",
      "Batch 334/700: Discriminator loss = 1.197840690612793, GAN loss = [2.8163304, 0.94775313, 1.1029458]\n",
      "Batch 335/700: Discriminator loss = 1.0996233224868774, GAN loss = [2.8431828, 1.0457362, 1.0318538]\n",
      "Batch 336/700: Discriminator loss = 1.1246905326843262, GAN loss = [2.883082, 1.0308967, 1.0866205]\n",
      "Batch 337/700: Discriminator loss = 1.159922480583191, GAN loss = [2.7739637, 0.96503174, 1.0433842]\n",
      "Batch 338/700: Discriminator loss = 1.1946508884429932, GAN loss = [2.7279239, 0.93461263, 1.0277961]\n",
      "Batch 339/700: Discriminator loss = 1.1317455768585205, GAN loss = [2.8303487, 0.99953794, 1.0653268]\n",
      "Batch 340/700: Discriminator loss = 1.1932861804962158, GAN loss = [2.863909, 0.96815735, 1.1302949]\n",
      "Batch 341/700: Discriminator loss = 1.1589739322662354, GAN loss = [2.7211437, 0.98869926, 0.9670204]\n",
      "Batch 342/700: Discriminator loss = 1.1469746828079224, GAN loss = [2.8343015, 1.0186158, 1.0502988]\n",
      "Batch 343/700: Discriminator loss = 1.1056644916534424, GAN loss = [2.8774478, 1.0073477, 1.1047438]\n",
      "Batch 344/700: Discriminator loss = 1.212654709815979, GAN loss = [2.7332876, 0.93786025, 1.0300916]\n",
      "Batch 345/700: Discriminator loss = 1.1531574726104736, GAN loss = [2.7755444, 0.96932876, 1.0409111]\n",
      "Batch 346/700: Discriminator loss = 1.1560956239700317, GAN loss = [2.805538, 0.9825714, 1.0576949]\n",
      "Batch 347/700: Discriminator loss = 1.163236141204834, GAN loss = [2.9024212, 0.99778956, 1.1393905]\n",
      "Batch 348/700: Discriminator loss = 1.1421606540679932, GAN loss = [2.7983186, 0.96666026, 1.0664492]\n",
      "Batch 349/700: Discriminator loss = 1.136979103088379, GAN loss = [2.7669759, 0.9746605, 1.0271378]\n",
      "Batch 350/700: Discriminator loss = 1.1274986267089844, GAN loss = [2.8861349, 0.9835006, 1.137484]\n",
      "Batch 351/700: Discriminator loss = 1.1415736675262451, GAN loss = [2.7884512, 0.9744111, 1.0489211]\n",
      "Batch 352/700: Discriminator loss = 1.1172298192977905, GAN loss = [2.9856741, 1.0241987, 1.1963886]\n",
      "Batch 353/700: Discriminator loss = 1.1507493257522583, GAN loss = [2.7874675, 0.9680808, 1.0543327]\n",
      "Batch 354/700: Discriminator loss = 1.1209726333618164, GAN loss = [2.8624122, 1.0042695, 1.0931163]\n",
      "Batch 355/700: Discriminator loss = 1.1401721239089966, GAN loss = [2.9028168, 1.0065314, 1.1312797]\n",
      "Batch 356/700: Discriminator loss = 1.135053277015686, GAN loss = [2.815445, 0.9928801, 1.0575889]\n",
      "Batch 357/700: Discriminator loss = 1.1782636642456055, GAN loss = [2.7274523, 0.9293864, 1.0331126]\n",
      "Batch 358/700: Discriminator loss = 1.1656097173690796, GAN loss = [2.7856832, 0.9611944, 1.0595644]\n",
      "Batch 359/700: Discriminator loss = 1.1135352849960327, GAN loss = [3.0177386, 1.0075182, 1.2453216]\n",
      "Batch 360/700: Discriminator loss = 1.1459081172943115, GAN loss = [2.8464024, 0.9848005, 1.0967419]\n",
      "Batch 361/700: Discriminator loss = 1.1823793649673462, GAN loss = [2.7358272, 0.9400864, 1.0309006]\n",
      "Batch 362/700: Discriminator loss = 1.1643755435943604, GAN loss = [2.844066, 0.9564711, 1.1227833]\n",
      "Batch 363/700: Discriminator loss = 1.164724588394165, GAN loss = [2.7814398, 0.9476836, 1.0689794]\n",
      "Batch 364/700: Discriminator loss = 1.174135446548462, GAN loss = [2.7090764, 0.95472693, 0.9895862]\n",
      "Batch 365/700: Discriminator loss = 1.1279298067092896, GAN loss = [2.7787788, 0.9824946, 1.0315373]\n",
      "Batch 366/700: Discriminator loss = 1.1761317253112793, GAN loss = [2.7849252, 0.9656561, 1.0545442]\n",
      "Batch 367/700: Discriminator loss = 1.1447012424468994, GAN loss = [2.9044313, 0.9865557, 1.1531788]\n",
      "Batch 368/700: Discriminator loss = 1.162703037261963, GAN loss = [2.70757, 0.95894027, 0.98394156]\n",
      "Batch 369/700: Discriminator loss = 1.1830041408538818, GAN loss = [2.8002694, 0.9689678, 1.0666184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 370/700: Discriminator loss = 1.1863577365875244, GAN loss = [2.77795, 0.9730446, 1.040227]\n",
      "Batch 371/700: Discriminator loss = 1.1783632040023804, GAN loss = [2.8314457, 0.9632584, 1.1035303]\n",
      "Batch 372/700: Discriminator loss = 1.1914900541305542, GAN loss = [2.7769318, 0.95117354, 1.0611105]\n",
      "Batch 373/700: Discriminator loss = 1.2120980024337769, GAN loss = [2.6740403, 0.9325962, 0.97680223]\n",
      "Batch 374/700: Discriminator loss = 1.1861761808395386, GAN loss = [2.8159862, 0.92914146, 1.122226]\n",
      "Batch 375/700: Discriminator loss = 1.1879092454910278, GAN loss = [2.742845, 0.93619, 1.0420531]\n",
      "Batch 376/700: Discriminator loss = 1.1942552328109741, GAN loss = [2.7029016, 0.92993027, 1.008384]\n",
      "Batch 377/700: Discriminator loss = 1.205002784729004, GAN loss = [2.75247, 0.9326033, 1.0552955]\n",
      "Batch 378/700: Discriminator loss = 1.2472598552703857, GAN loss = [2.7050617, 0.92097205, 1.0195268]\n",
      "Batch 379/700: Discriminator loss = 1.1875433921813965, GAN loss = [2.731632, 0.9437159, 1.0233676]\n",
      "Batch 380/700: Discriminator loss = 1.2062660455703735, GAN loss = [2.721217, 0.93585706, 1.0208296]\n",
      "Batch 381/700: Discriminator loss = 1.2194068431854248, GAN loss = [2.6645167, 0.9180649, 0.98194045]\n",
      "Batch 382/700: Discriminator loss = 1.1719014644622803, GAN loss = [2.6227858, 0.9502839, 0.90799195]\n",
      "Batch 383/700: Discriminator loss = 1.176304817199707, GAN loss = [2.7353847, 0.953862, 1.0170268]\n",
      "Batch 384/700: Discriminator loss = 1.2063443660736084, GAN loss = [2.6011853, 0.9174088, 0.91930246]\n",
      "Batch 385/700: Discriminator loss = 1.2107869386672974, GAN loss = [2.6536384, 0.9258028, 0.96337265]\n",
      "Batch 386/700: Discriminator loss = 1.1413196325302124, GAN loss = [2.7413702, 0.9719549, 1.0049623]\n",
      "Batch 387/700: Discriminator loss = 1.1907265186309814, GAN loss = [2.7429612, 0.9644277, 1.0140897]\n",
      "Batch 388/700: Discriminator loss = 1.1693294048309326, GAN loss = [2.6401746, 0.95419914, 0.92154753]\n",
      "Batch 389/700: Discriminator loss = 1.2209067344665527, GAN loss = [2.6261857, 0.9098089, 0.95195955]\n",
      "Batch 390/700: Discriminator loss = 1.2042458057403564, GAN loss = [2.676066, 0.93156874, 0.9801041]\n",
      "Batch 391/700: Discriminator loss = 1.214752435684204, GAN loss = [2.6503913, 0.93275225, 0.953268]\n",
      "Batch 392/700: Discriminator loss = 1.140008807182312, GAN loss = [2.7407253, 0.96984816, 1.0065287]\n",
      "Batch 393/700: Discriminator loss = 1.1626861095428467, GAN loss = [2.8358488, 0.97256655, 1.0989519]\n",
      "Batch 394/700: Discriminator loss = 1.1746381521224976, GAN loss = [2.7597134, 0.9619647, 1.033445]\n",
      "Batch 395/700: Discriminator loss = 1.2088814973831177, GAN loss = [2.6319315, 0.93393826, 0.93370605]\n",
      "Batch 396/700: Discriminator loss = 1.214410424232483, GAN loss = [2.6942549, 0.92745256, 1.00253]\n",
      "Batch 397/700: Discriminator loss = 1.183916687965393, GAN loss = [2.6597154, 0.947357, 0.9481037]\n",
      "Batch 398/700: Discriminator loss = 1.1818556785583496, GAN loss = [2.7897708, 0.9721923, 1.053344]\n",
      "Batch 399/700: Discriminator loss = 1.1920685768127441, GAN loss = [2.6861467, 0.9814886, 0.94044405]\n",
      "Batch 400/700: Discriminator loss = 1.2253391742706299, GAN loss = [2.5924907, 0.8945525, 0.9337524]\n",
      "Batch 401/700: Discriminator loss = 1.2353020906448364, GAN loss = [2.5850642, 0.9162823, 0.9046145]\n",
      "Batch 402/700: Discriminator loss = 1.189849615097046, GAN loss = [2.6587646, 0.94173807, 0.95288604]\n",
      "Batch 403/700: Discriminator loss = 1.1541725397109985, GAN loss = [2.7494621, 0.956184, 1.0291692]\n",
      "Batch 404/700: Discriminator loss = 1.1513540744781494, GAN loss = [2.6292706, 0.94142157, 0.92375916]\n",
      "Batch 405/700: Discriminator loss = 1.185361385345459, GAN loss = [2.6378381, 0.92238724, 0.95137167]\n",
      "Batch 406/700: Discriminator loss = 1.1600180864334106, GAN loss = [2.8883362, 0.9864835, 1.1377919]\n",
      "Batch 407/700: Discriminator loss = 1.1868648529052734, GAN loss = [2.643727, 0.92121917, 0.9584751]\n",
      "Batch 408/700: Discriminator loss = 1.1701149940490723, GAN loss = [2.674931, 0.9312899, 0.97962457]\n",
      "Batch 409/700: Discriminator loss = 1.210308313369751, GAN loss = [2.725942, 0.91260713, 1.0493466]\n",
      "Batch 410/700: Discriminator loss = 1.183456540107727, GAN loss = [2.7278552, 0.91765696, 1.0462272]\n",
      "Batch 411/700: Discriminator loss = 1.1470787525177002, GAN loss = [2.7482648, 0.95801026, 1.0263008]\n",
      "Batch 412/700: Discriminator loss = 1.2038592100143433, GAN loss = [2.7142653, 0.9182177, 1.032106]\n",
      "Batch 413/700: Discriminator loss = 1.1507824659347534, GAN loss = [2.7576504, 0.95491046, 1.0388106]\n",
      "Batch 414/700: Discriminator loss = 1.144239902496338, GAN loss = [2.7653596, 0.948833, 1.0526232]\n",
      "Batch 415/700: Discriminator loss = 1.199303388595581, GAN loss = [2.6860754, 0.9140584, 1.0081401]\n",
      "Batch 416/700: Discriminator loss = 1.1589034795761108, GAN loss = [2.716169, 0.9422803, 1.0100383]\n",
      "Batch 417/700: Discriminator loss = 1.1685116291046143, GAN loss = [2.8026135, 0.9352984, 1.1034869]\n",
      "Batch 418/700: Discriminator loss = 1.1680971384048462, GAN loss = [2.7579813, 0.9555629, 1.0386101]\n",
      "Batch 419/700: Discriminator loss = 1.1848087310791016, GAN loss = [2.776221, 0.9501709, 1.0622548]\n",
      "Batch 420/700: Discriminator loss = 1.1824086904525757, GAN loss = [2.7637677, 0.9468757, 1.0531083]\n",
      "Batch 421/700: Discriminator loss = 1.1598050594329834, GAN loss = [2.7594628, 0.97139853, 1.024301]\n",
      "Batch 422/700: Discriminator loss = 1.1625394821166992, GAN loss = [2.7681782, 0.9683561, 1.0360839]\n",
      "Batch 423/700: Discriminator loss = 1.154045581817627, GAN loss = [2.7258224, 0.9375058, 1.0246003]\n",
      "Batch 424/700: Discriminator loss = 1.129555344581604, GAN loss = [2.7792873, 0.9810322, 1.0345657]\n",
      "Batch 425/700: Discriminator loss = 1.1512166261672974, GAN loss = [2.85854, 0.9860192, 1.1088519]\n",
      "Batch 426/700: Discriminator loss = 1.1517237424850464, GAN loss = [2.7503383, 0.9701497, 1.0165452]\n",
      "Batch 427/700: Discriminator loss = 1.1570385694503784, GAN loss = [2.692162, 0.96745056, 0.96110123]\n",
      "Batch 428/700: Discriminator loss = 1.1565229892730713, GAN loss = [2.7643535, 0.9529173, 1.0478449]\n",
      "Batch 429/700: Discriminator loss = 1.178828239440918, GAN loss = [2.7426662, 0.94904405, 1.0300587]\n",
      "Batch 430/700: Discriminator loss = 1.1666600704193115, GAN loss = [2.7517395, 0.9511212, 1.0370815]\n",
      "Batch 431/700: Discriminator loss = 1.1662116050720215, GAN loss = [2.8071904, 0.94957495, 1.0941004]\n",
      "Batch 432/700: Discriminator loss = 1.137550950050354, GAN loss = [2.8716738, 0.95958847, 1.1485786]\n",
      "Batch 433/700: Discriminator loss = 1.144128680229187, GAN loss = [2.8154197, 0.9619288, 1.0899963]\n",
      "Batch 434/700: Discriminator loss = 1.1611140966415405, GAN loss = [2.7793958, 0.96484584, 1.0510685]\n",
      "Batch 435/700: Discriminator loss = 1.1693923473358154, GAN loss = [2.7413948, 0.95894706, 1.0189899]\n",
      "Batch 436/700: Discriminator loss = 1.1419672966003418, GAN loss = [2.8187606, 0.9651182, 1.0902053]\n",
      "Batch 437/700: Discriminator loss = 1.176659345626831, GAN loss = [2.73821, 0.9458253, 1.0289634]\n",
      "Batch 438/700: Discriminator loss = 1.1840391159057617, GAN loss = [2.7539935, 0.9575058, 1.0330812]\n",
      "Batch 439/700: Discriminator loss = 1.1276811361312866, GAN loss = [2.8964527, 0.9691816, 1.1638864]\n",
      "Batch 440/700: Discriminator loss = 1.1587440967559814, GAN loss = [2.820174, 0.9522575, 1.1045566]\n",
      "Batch 441/700: Discriminator loss = 1.1404556035995483, GAN loss = [2.82924, 0.9717171, 1.0941844]\n",
      "Batch 442/700: Discriminator loss = 1.1775869131088257, GAN loss = [2.708111, 0.94116503, 1.0036278]\n",
      "Batch 443/700: Discriminator loss = 1.1494123935699463, GAN loss = [2.729637, 0.9425089, 1.0238466]\n",
      "Batch 444/700: Discriminator loss = 1.1571017503738403, GAN loss = [2.767849, 0.9459722, 1.0586233]\n",
      "Batch 445/700: Discriminator loss = 1.211266040802002, GAN loss = [2.7258182, 0.9259098, 1.0366882]\n",
      "Batch 446/700: Discriminator loss = 1.1382219791412354, GAN loss = [2.824491, 0.97238123, 1.0889066]\n",
      "Batch 447/700: Discriminator loss = 1.2031843662261963, GAN loss = [2.637299, 0.91170007, 0.9624077]\n",
      "Batch 448/700: Discriminator loss = 1.1726977825164795, GAN loss = [2.7598484, 0.96670634, 1.0299796]\n",
      "Batch 449/700: Discriminator loss = 1.1454583406448364, GAN loss = [2.6511261, 0.9519259, 0.9360675]\n",
      "Batch 450/700: Discriminator loss = 1.215954065322876, GAN loss = [2.6686618, 0.9309749, 0.9745751]\n",
      "Batch 451/700: Discriminator loss = 1.160016655921936, GAN loss = [2.6976695, 0.9687519, 0.9658394]\n",
      "Batch 452/700: Discriminator loss = 1.1400922536849976, GAN loss = [2.8888674, 0.9928433, 1.1329895]\n",
      "Batch 453/700: Discriminator loss = 1.1281245946884155, GAN loss = [2.844971, 0.99336004, 1.0886127]\n",
      "Batch 454/700: Discriminator loss = 1.1828359365463257, GAN loss = [2.7709718, 0.96068245, 1.0473272]\n",
      "Batch 455/700: Discriminator loss = 1.143290638923645, GAN loss = [2.7913952, 0.9618232, 1.0666363]\n",
      "Batch 456/700: Discriminator loss = 1.1401575803756714, GAN loss = [2.7834656, 0.9705131, 1.0500383]\n",
      "Batch 457/700: Discriminator loss = 1.2212284803390503, GAN loss = [2.634716, 0.90440476, 0.96741843]\n",
      "Batch 458/700: Discriminator loss = 1.1662596464157104, GAN loss = [2.8443427, 0.95476335, 1.1267078]\n",
      "Batch 459/700: Discriminator loss = 1.144574761390686, GAN loss = [2.8665872, 0.96241975, 1.1413205]\n",
      "Batch 460/700: Discriminator loss = 1.1770696640014648, GAN loss = [2.7622018, 0.9581663, 1.0412189]\n",
      "Batch 461/700: Discriminator loss = 1.2116960287094116, GAN loss = [2.6576796, 0.9266715, 0.9682149]\n",
      "Batch 462/700: Discriminator loss = 1.221885323524475, GAN loss = [2.8252459, 0.9197532, 1.1427228]\n",
      "Batch 463/700: Discriminator loss = 1.1617826223373413, GAN loss = [2.7480557, 0.9644347, 1.0208753]\n",
      "Batch 464/700: Discriminator loss = 1.1567158699035645, GAN loss = [2.750661, 0.9815575, 1.0063865]\n",
      "Batch 465/700: Discriminator loss = 1.1405534744262695, GAN loss = [2.8351238, 0.99260765, 1.0798198]\n",
      "Batch 466/700: Discriminator loss = 1.18105947971344, GAN loss = [2.7582657, 0.9353164, 1.0602658]\n",
      "Batch 467/700: Discriminator loss = 1.1941814422607422, GAN loss = [2.7587366, 0.9593546, 1.0367272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 468/700: Discriminator loss = 1.1733120679855347, GAN loss = [2.70068, 0.9553027, 0.9827484]\n",
      "Batch 469/700: Discriminator loss = 1.1735622882843018, GAN loss = [2.7933369, 0.998004, 1.0327156]\n",
      "Batch 470/700: Discriminator loss = 1.1976860761642456, GAN loss = [2.6769063, 0.9242913, 0.99001825]\n",
      "Batch 471/700: Discriminator loss = 1.169740080833435, GAN loss = [2.7811182, 0.9517011, 1.0668519]\n",
      "Batch 472/700: Discriminator loss = 1.1671661138534546, GAN loss = [2.7295039, 0.9736829, 0.99328214]\n",
      "Batch 473/700: Discriminator loss = 1.142191767692566, GAN loss = [2.8424523, 1.0159011, 1.0640389]\n",
      "Batch 474/700: Discriminator loss = 1.225282073020935, GAN loss = [2.7488534, 0.9312975, 1.055067]\n",
      "Batch 475/700: Discriminator loss = 1.1953189373016357, GAN loss = [2.7879262, 0.96846986, 1.0569931]\n",
      "Batch 476/700: Discriminator loss = 1.1268500089645386, GAN loss = [2.8575203, 1.0222015, 1.0728797]\n",
      "Batch 477/700: Discriminator loss = 1.1455549001693726, GAN loss = [2.779242, 0.99066985, 1.0261537]\n",
      "Batch 478/700: Discriminator loss = 1.1402329206466675, GAN loss = [2.7696807, 0.98762655, 1.0196583]\n",
      "Batch 479/700: Discriminator loss = 1.144216775894165, GAN loss = [2.8225029, 1.0097982, 1.0503242]\n",
      "Batch 480/700: Discriminator loss = 1.1789368391036987, GAN loss = [2.6628876, 0.9346722, 0.96584857]\n",
      "Batch 481/700: Discriminator loss = 1.1820417642593384, GAN loss = [2.7986836, 0.95149714, 1.0848345]\n",
      "Batch 482/700: Discriminator loss = 1.1855226755142212, GAN loss = [2.7506592, 0.9639885, 1.024338]\n",
      "Batch 483/700: Discriminator loss = 1.1379140615463257, GAN loss = [2.6932964, 0.9923742, 0.9386136]\n",
      "Batch 484/700: Discriminator loss = 1.1527979373931885, GAN loss = [2.7637966, 0.9786301, 1.0228891]\n",
      "Batch 485/700: Discriminator loss = 1.1693012714385986, GAN loss = [2.7340658, 0.93684983, 1.0349555]\n",
      "Batch 486/700: Discriminator loss = 1.1817952394485474, GAN loss = [2.7754352, 0.9452762, 1.0679076]\n",
      "Batch 487/700: Discriminator loss = 1.1564879417419434, GAN loss = [2.8657465, 0.9601332, 1.1433837]\n",
      "Batch 488/700: Discriminator loss = 1.1447067260742188, GAN loss = [2.754516, 0.9719486, 1.0203615]\n",
      "Batch 489/700: Discriminator loss = 1.1659952402114868, GAN loss = [2.732158, 0.97217184, 0.99781144]\n",
      "Batch 490/700: Discriminator loss = 1.1818397045135498, GAN loss = [2.8333654, 0.96793884, 1.1032914]\n",
      "Batch 491/700: Discriminator loss = 1.150303840637207, GAN loss = [2.743855, 1.0126052, 0.96915925]\n",
      "Batch 492/700: Discriminator loss = 1.1358458995819092, GAN loss = [2.7947834, 0.97506195, 1.0576724]\n",
      "Batch 493/700: Discriminator loss = 1.1312825679779053, GAN loss = [2.779665, 0.9854802, 1.032169]\n",
      "Batch 494/700: Discriminator loss = 1.1858304738998413, GAN loss = [2.7561514, 0.94021547, 1.0539492]\n",
      "Batch 495/700: Discriminator loss = 1.137326955795288, GAN loss = [2.925173, 1.0247233, 1.1384903]\n",
      "Batch 496/700: Discriminator loss = 1.1413383483886719, GAN loss = [2.830164, 0.9746377, 1.0935951]\n",
      "Batch 497/700: Discriminator loss = 1.1622644662857056, GAN loss = [2.7912295, 0.98584783, 1.0434861]\n",
      "Batch 498/700: Discriminator loss = 1.1261439323425293, GAN loss = [2.7564373, 1.0051593, 0.9894131]\n",
      "Batch 499/700: Discriminator loss = 1.1257028579711914, GAN loss = [2.7440736, 0.9766407, 1.0056013]\n",
      "Batch 500/700: Discriminator loss = 1.1729108095169067, GAN loss = [2.8149304, 0.96315217, 1.0899756]\n",
      "Batch 501/700: Discriminator loss = 1.1207466125488281, GAN loss = [2.982324, 0.97847426, 1.2420816]\n",
      "Batch 502/700: Discriminator loss = 1.1218516826629639, GAN loss = [2.9100695, 1.0029776, 1.1453487]\n",
      "Batch 503/700: Discriminator loss = 1.1498595476150513, GAN loss = [2.7882597, 0.9808619, 1.0456845]\n",
      "Batch 504/700: Discriminator loss = 1.1507747173309326, GAN loss = [2.7972755, 0.9651089, 1.070468]\n",
      "Batch 505/700: Discriminator loss = 1.1572185754776, GAN loss = [2.826791, 0.9560599, 1.1090556]\n",
      "Batch 506/700: Discriminator loss = 1.1846535205841064, GAN loss = [2.7338314, 0.9512095, 1.0209671]\n",
      "Batch 507/700: Discriminator loss = 1.1818166971206665, GAN loss = [2.708843, 0.9371736, 1.0100442]\n",
      "Batch 508/700: Discriminator loss = 1.1350680589675903, GAN loss = [2.8421404, 0.9993194, 1.0812318]\n",
      "Batch 509/700: Discriminator loss = 1.1635444164276123, GAN loss = [2.7611444, 0.97174, 1.0278434]\n",
      "Batch 510/700: Discriminator loss = 1.1410900354385376, GAN loss = [2.9189951, 0.9731361, 1.184322]\n",
      "Batch 511/700: Discriminator loss = 1.1628965139389038, GAN loss = [2.7928646, 0.9633857, 1.0679668]\n",
      "Batch 512/700: Discriminator loss = 1.1595635414123535, GAN loss = [2.7598987, 0.9666887, 1.0317307]\n",
      "Batch 513/700: Discriminator loss = 1.1632919311523438, GAN loss = [2.7494884, 0.9490091, 1.0390308]\n",
      "Batch 514/700: Discriminator loss = 1.1614959239959717, GAN loss = [2.8407764, 0.9679541, 1.1113988]\n",
      "Batch 515/700: Discriminator loss = 1.1307884454727173, GAN loss = [2.9749274, 1.0307006, 1.1828341]\n",
      "Batch 516/700: Discriminator loss = 1.1556458473205566, GAN loss = [2.781999, 0.9710805, 1.0495584]\n",
      "Batch 517/700: Discriminator loss = 1.1489068269729614, GAN loss = [2.7872028, 0.9779493, 1.0479188]\n",
      "Batch 518/700: Discriminator loss = 1.164266586303711, GAN loss = [2.7421684, 0.950653, 1.0302048]\n",
      "Batch 519/700: Discriminator loss = 1.174856185913086, GAN loss = [2.7503023, 0.9573796, 1.0316288]\n",
      "Batch 520/700: Discriminator loss = 1.162748098373413, GAN loss = [2.7971694, 0.9669132, 1.0689892]\n",
      "Batch 521/700: Discriminator loss = 1.137467861175537, GAN loss = [2.8832045, 1.0096059, 1.1123619]\n",
      "Batch 522/700: Discriminator loss = 1.171040415763855, GAN loss = [2.8160877, 0.9658544, 1.0890204]\n",
      "Batch 523/700: Discriminator loss = 1.180949091911316, GAN loss = [2.8744943, 0.9747826, 1.1385378]\n",
      "Batch 524/700: Discriminator loss = 1.1701291799545288, GAN loss = [2.8368244, 0.98269945, 1.0929854]\n",
      "Batch 525/700: Discriminator loss = 1.1501028537750244, GAN loss = [2.9261477, 1.0079249, 1.1571132]\n",
      "Batch 526/700: Discriminator loss = 1.1683290004730225, GAN loss = [2.745506, 0.9515072, 1.0329131]\n",
      "Batch 527/700: Discriminator loss = 1.177113652229309, GAN loss = [2.7004685, 0.9592526, 0.980157]\n",
      "Batch 528/700: Discriminator loss = 1.1555112600326538, GAN loss = [2.744293, 0.96444815, 1.0187981]\n",
      "Batch 529/700: Discriminator loss = 1.1521390676498413, GAN loss = [2.7806983, 0.96777093, 1.0519078]\n",
      "Batch 530/700: Discriminator loss = 1.1537785530090332, GAN loss = [2.7508574, 0.9655254, 1.0243322]\n",
      "Batch 531/700: Discriminator loss = 1.139973521232605, GAN loss = [2.7374408, 0.9763753, 1.0000955]\n",
      "Batch 532/700: Discriminator loss = 1.1404125690460205, GAN loss = [2.8254411, 0.9777553, 1.086742]\n",
      "Batch 533/700: Discriminator loss = 1.1479195356369019, GAN loss = [2.918515, 1.0069925, 1.1505978]\n",
      "Batch 534/700: Discriminator loss = 1.1594536304473877, GAN loss = [2.8564744, 0.9595214, 1.1360524]\n",
      "Batch 535/700: Discriminator loss = 1.1829661130905151, GAN loss = [2.794179, 0.9645157, 1.0687759]\n",
      "Batch 536/700: Discriminator loss = 1.1916866302490234, GAN loss = [2.8172367, 0.9567308, 1.0996349]\n",
      "Batch 537/700: Discriminator loss = 1.1417803764343262, GAN loss = [2.8507977, 1.0093293, 1.0806137]\n",
      "Batch 538/700: Discriminator loss = 1.1429110765457153, GAN loss = [2.8074903, 0.99225026, 1.054412]\n",
      "Batch 539/700: Discriminator loss = 1.1988998651504517, GAN loss = [2.850334, 0.96074384, 1.1287879]\n",
      "Batch 540/700: Discriminator loss = 1.150161623954773, GAN loss = [2.8198016, 1.0239452, 1.0350788]\n",
      "Batch 541/700: Discriminator loss = 1.1803067922592163, GAN loss = [2.731356, 0.94341385, 1.0271913]\n",
      "Batch 542/700: Discriminator loss = 1.1807547807693481, GAN loss = [2.790735, 0.95257425, 1.0774355]\n",
      "Batch 543/700: Discriminator loss = 1.1893091201782227, GAN loss = [2.8309085, 0.96779174, 1.1024218]\n",
      "Batch 544/700: Discriminator loss = 1.117374300956726, GAN loss = [2.9451985, 1.0244793, 1.1600424]\n",
      "Batch 545/700: Discriminator loss = 1.142115592956543, GAN loss = [2.8804927, 1.0060269, 1.1138039]\n",
      "Batch 546/700: Discriminator loss = 1.1410770416259766, GAN loss = [2.7822692, 0.9781446, 1.0434855]\n",
      "Batch 547/700: Discriminator loss = 1.1560392379760742, GAN loss = [2.8516512, 1.0288355, 1.0622027]\n",
      "Batch 548/700: Discriminator loss = 1.1819247007369995, GAN loss = [2.761849, 0.9618528, 1.0394202]\n",
      "Batch 549/700: Discriminator loss = 1.1903033256530762, GAN loss = [2.8114524, 0.9701108, 1.0807796]\n",
      "Batch 550/700: Discriminator loss = 1.1588975191116333, GAN loss = [2.7915034, 0.9777121, 1.0532587]\n",
      "Batch 551/700: Discriminator loss = 1.1368987560272217, GAN loss = [2.9130862, 1.0282438, 1.1243302]\n",
      "Batch 552/700: Discriminator loss = 1.1385183334350586, GAN loss = [2.8288991, 1.0246068, 1.0437915]\n",
      "Batch 553/700: Discriminator loss = 1.1790982484817505, GAN loss = [2.7524924, 0.9639981, 1.0280167]\n",
      "Batch 554/700: Discriminator loss = 1.1836124658584595, GAN loss = [2.712583, 0.9389987, 1.0131428]\n",
      "Batch 555/700: Discriminator loss = 1.1780107021331787, GAN loss = [2.8390307, 0.9569715, 1.1216577]\n",
      "Batch 556/700: Discriminator loss = 1.1482492685317993, GAN loss = [2.7782016, 0.96550095, 1.0523423]\n",
      "Batch 557/700: Discriminator loss = 1.169082760810852, GAN loss = [2.7881904, 0.9616073, 1.0662628]\n",
      "Batch 558/700: Discriminator loss = 1.1361536979675293, GAN loss = [2.8428068, 1.0050448, 1.0774783]\n",
      "Batch 559/700: Discriminator loss = 1.1519752740859985, GAN loss = [2.7868135, 0.96048856, 1.0660816]\n",
      "Batch 560/700: Discriminator loss = 1.1464390754699707, GAN loss = [2.8700292, 0.9970962, 1.1127223]\n",
      "Batch 561/700: Discriminator loss = 1.1814948320388794, GAN loss = [2.7383864, 0.95666784, 1.0215358]\n",
      "Batch 562/700: Discriminator loss = 1.1805518865585327, GAN loss = [2.73933, 0.95630205, 1.0228671]\n",
      "Batch 563/700: Discriminator loss = 1.1431459188461304, GAN loss = [2.815025, 0.9953568, 1.059539]\n",
      "Batch 564/700: Discriminator loss = 1.1271538734436035, GAN loss = [2.8395388, 1.0020041, 1.0774314]\n",
      "Batch 565/700: Discriminator loss = 1.166172742843628, GAN loss = [2.8157074, 0.95853376, 1.0971069]\n",
      "Batch 566/700: Discriminator loss = 1.1400312185287476, GAN loss = [3.0016003, 0.972818, 1.2687576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 567/700: Discriminator loss = 1.1207975149154663, GAN loss = [2.8105426, 1.0107594, 1.0397992]\n",
      "Batch 568/700: Discriminator loss = 1.1670937538146973, GAN loss = [2.7621093, 0.9498369, 1.0523118]\n",
      "Batch 569/700: Discriminator loss = 1.1970077753067017, GAN loss = [2.730983, 0.920486, 1.0505581]\n",
      "Batch 570/700: Discriminator loss = 1.223353385925293, GAN loss = [2.7098007, 0.90156686, 1.0483265]\n",
      "Batch 571/700: Discriminator loss = 1.1442536115646362, GAN loss = [2.8035355, 0.9817428, 1.0619122]\n",
      "Batch 572/700: Discriminator loss = 1.1613200902938843, GAN loss = [2.713757, 0.9375454, 1.016375]\n",
      "Batch 573/700: Discriminator loss = 1.1416168212890625, GAN loss = [2.8081222, 0.9617863, 1.0865414]\n",
      "Batch 574/700: Discriminator loss = 1.1591074466705322, GAN loss = [2.806563, 0.96707696, 1.0797248]\n",
      "Batch 575/700: Discriminator loss = 1.2035106420516968, GAN loss = [2.6564844, 0.9414901, 0.95528007]\n",
      "Batch 576/700: Discriminator loss = 1.165398359298706, GAN loss = [2.8208375, 0.93787795, 1.1232837]\n",
      "Batch 577/700: Discriminator loss = 1.1830414533615112, GAN loss = [2.776889, 0.9553703, 1.0618736]\n",
      "Batch 578/700: Discriminator loss = 1.1995609998703003, GAN loss = [2.7152503, 0.91941893, 1.0362072]\n",
      "Batch 579/700: Discriminator loss = 1.1833058595657349, GAN loss = [2.722339, 0.9160933, 1.0466375]\n",
      "Batch 580/700: Discriminator loss = 1.1733074188232422, GAN loss = [2.891496, 0.95874286, 1.1731716]\n",
      "Batch 581/700: Discriminator loss = 1.2054263353347778, GAN loss = [2.7540383, 0.95841265, 1.0360833]\n",
      "Batch 582/700: Discriminator loss = 1.1829633712768555, GAN loss = [2.738627, 0.9391823, 1.0399274]\n",
      "Batch 583/700: Discriminator loss = 1.168850302696228, GAN loss = [2.7739377, 0.94170547, 1.0727408]\n",
      "Batch 584/700: Discriminator loss = 1.1943762302398682, GAN loss = [2.741901, 0.94298285, 1.039436]\n",
      "Batch 585/700: Discriminator loss = 1.1567063331604004, GAN loss = [2.771354, 0.96651894, 1.0453688]\n",
      "Batch 586/700: Discriminator loss = 1.1441082954406738, GAN loss = [2.7824557, 0.9832172, 1.0397937]\n",
      "Batch 587/700: Discriminator loss = 1.1502679586410522, GAN loss = [2.7312543, 0.98838377, 0.9834536]\n",
      "Batch 588/700: Discriminator loss = 1.2016499042510986, GAN loss = [2.6561487, 0.9560269, 0.9407191]\n",
      "Batch 589/700: Discriminator loss = 1.1595011949539185, GAN loss = [2.6870103, 0.94021684, 0.9874188]\n",
      "Batch 590/700: Discriminator loss = 1.1470882892608643, GAN loss = [2.7799442, 0.95667684, 1.0639149]\n",
      "Batch 591/700: Discriminator loss = 1.152029275894165, GAN loss = [2.7486281, 0.9580385, 1.0312657]\n",
      "Batch 592/700: Discriminator loss = 1.1286998987197876, GAN loss = [2.8411534, 0.973071, 1.1087819]\n",
      "Batch 593/700: Discriminator loss = 1.1600439548492432, GAN loss = [2.8284585, 0.97422236, 1.0949727]\n",
      "Batch 594/700: Discriminator loss = 1.1358046531677246, GAN loss = [2.882701, 0.9677315, 1.1557379]\n",
      "Batch 595/700: Discriminator loss = 1.156420350074768, GAN loss = [2.837861, 0.96445626, 1.1142005]\n",
      "Batch 596/700: Discriminator loss = 1.1699849367141724, GAN loss = [2.8404765, 0.9279172, 1.1533645]\n",
      "Batch 597/700: Discriminator loss = 1.1336231231689453, GAN loss = [2.76144, 0.939854, 1.0624177]\n",
      "Batch 598/700: Discriminator loss = 1.1623958349227905, GAN loss = [2.8286924, 0.94665533, 1.1228971]\n",
      "Batch 599/700: Discriminator loss = 1.152218222618103, GAN loss = [2.8226767, 0.9697813, 1.0937843]\n",
      "Batch 600/700: Discriminator loss = 1.1564693450927734, GAN loss = [2.832539, 0.9591787, 1.1142807]\n",
      "Batch 601/700: Discriminator loss = 1.1433159112930298, GAN loss = [2.8528934, 0.969189, 1.1246556]\n",
      "Batch 602/700: Discriminator loss = 1.1347373723983765, GAN loss = [2.7582653, 0.979218, 1.0200231]\n",
      "Batch 603/700: Discriminator loss = 1.1381676197052002, GAN loss = [2.8331754, 0.97887003, 1.0953038]\n",
      "Batch 604/700: Discriminator loss = 1.1580619812011719, GAN loss = [2.7772512, 0.94537836, 1.0728962]\n",
      "Batch 605/700: Discriminator loss = 1.1692657470703125, GAN loss = [2.7626715, 0.92942405, 1.0742949]\n",
      "Batch 606/700: Discriminator loss = 1.1445517539978027, GAN loss = [2.869653, 0.9830897, 1.1276257]\n",
      "Batch 607/700: Discriminator loss = 1.1986958980560303, GAN loss = [2.7812903, 0.94031, 1.0820698]\n",
      "Batch 608/700: Discriminator loss = 1.1550309658050537, GAN loss = [2.7297645, 0.9537225, 1.0171627]\n",
      "Batch 609/700: Discriminator loss = 1.1699563264846802, GAN loss = [2.7453678, 0.9810556, 1.0054623]\n",
      "Batch 610/700: Discriminator loss = 1.1612783670425415, GAN loss = [2.8096156, 0.9724663, 1.0783325]\n",
      "Batch 611/700: Discriminator loss = 1.1572240591049194, GAN loss = [2.7835348, 0.9629246, 1.0618358]\n",
      "Batch 612/700: Discriminator loss = 1.1778156757354736, GAN loss = [2.771586, 0.9527533, 1.0600882]\n",
      "Batch 613/700: Discriminator loss = 1.1817127466201782, GAN loss = [2.8115535, 0.93915313, 1.1136863]\n",
      "Batch 614/700: Discriminator loss = 1.1925923824310303, GAN loss = [2.7639518, 0.9301628, 1.0751005]\n",
      "Batch 615/700: Discriminator loss = 1.1675602197647095, GAN loss = [2.8102305, 0.97863525, 1.072934]\n",
      "Batch 616/700: Discriminator loss = 1.1429821252822876, GAN loss = [2.8162596, 0.9800744, 1.0775456]\n",
      "Batch 617/700: Discriminator loss = 1.1678193807601929, GAN loss = [2.7811553, 0.9454539, 1.0770781]\n",
      "Batch 618/700: Discriminator loss = 1.1583681106567383, GAN loss = [2.7296336, 0.9489417, 1.0220822]\n",
      "Batch 619/700: Discriminator loss = 1.1861717700958252, GAN loss = [2.644691, 0.910705, 0.97538966]\n",
      "Batch 620/700: Discriminator loss = 1.1704314947128296, GAN loss = [2.809698, 0.9644146, 1.0867165]\n",
      "Batch 621/700: Discriminator loss = 1.1640899181365967, GAN loss = [2.766529, 0.9567283, 1.0512857]\n",
      "Batch 622/700: Discriminator loss = 1.1692538261413574, GAN loss = [2.7840729, 0.9428931, 1.0826956]\n",
      "Batch 623/700: Discriminator loss = 1.1539212465286255, GAN loss = [2.8532288, 0.9779187, 1.1168591]\n",
      "Batch 624/700: Discriminator loss = 1.1709153652191162, GAN loss = [2.812723, 0.97230875, 1.0819794]\n",
      "Batch 625/700: Discriminator loss = 1.182923436164856, GAN loss = [2.7835948, 0.94883364, 1.0763464]\n",
      "Batch 626/700: Discriminator loss = 1.1146103143692017, GAN loss = [2.9074945, 1.0114361, 1.1376722]\n",
      "Batch 627/700: Discriminator loss = 1.165930986404419, GAN loss = [2.7833354, 0.97067523, 1.0542969]\n",
      "Batch 628/700: Discriminator loss = 1.168039321899414, GAN loss = [2.8273091, 0.9607135, 1.1082639]\n",
      "Batch 629/700: Discriminator loss = 1.1737632751464844, GAN loss = [2.7770472, 0.9695107, 1.0492369]\n",
      "Batch 630/700: Discriminator loss = 1.1707426309585571, GAN loss = [2.7419531, 0.9795237, 1.0041488]\n",
      "Batch 631/700: Discriminator loss = 1.154173731803894, GAN loss = [2.7287626, 0.96335214, 1.0071375]\n",
      "Batch 632/700: Discriminator loss = 1.1572872400283813, GAN loss = [2.8102348, 0.95257574, 1.0993929]\n",
      "Batch 633/700: Discriminator loss = 1.1855648756027222, GAN loss = [2.751121, 0.9257424, 1.067126]\n",
      "Batch 634/700: Discriminator loss = 1.164247989654541, GAN loss = [2.770389, 0.9680154, 1.0441372]\n",
      "Batch 635/700: Discriminator loss = 1.1754175424575806, GAN loss = [2.6875618, 0.9766887, 0.9526458]\n",
      "Batch 636/700: Discriminator loss = 1.2100212574005127, GAN loss = [2.685723, 0.93633443, 0.9911768]\n",
      "Batch 637/700: Discriminator loss = 1.1251839399337769, GAN loss = [2.876858, 1.0048, 1.1138661]\n",
      "Batch 638/700: Discriminator loss = 1.1517648696899414, GAN loss = [2.720337, 0.97442025, 0.98773]\n",
      "Batch 639/700: Discriminator loss = 1.1577309370040894, GAN loss = [2.7630239, 0.955814, 1.0490378]\n",
      "Batch 640/700: Discriminator loss = 1.1253610849380493, GAN loss = [2.7873504, 0.9728292, 1.0563595]\n",
      "Batch 641/700: Discriminator loss = 1.1314952373504639, GAN loss = [2.7858758, 0.999778, 1.027941]\n",
      "Batch 642/700: Discriminator loss = 1.1538715362548828, GAN loss = [2.8631332, 1.0115275, 1.093468]\n",
      "Batch 643/700: Discriminator loss = 1.1540805101394653, GAN loss = [2.8352401, 0.99358314, 1.0835273]\n",
      "Batch 644/700: Discriminator loss = 1.1403182744979858, GAN loss = [2.7681806, 0.9610344, 1.0490338]\n",
      "Batch 645/700: Discriminator loss = 1.1735670566558838, GAN loss = [2.6674554, 0.94968104, 0.9596754]\n",
      "Batch 646/700: Discriminator loss = 1.1938259601593018, GAN loss = [2.631011, 0.95700204, 0.91592485]\n",
      "Batch 647/700: Discriminator loss = 1.1547350883483887, GAN loss = [2.7387364, 0.9588402, 1.021839]\n",
      "Batch 648/700: Discriminator loss = 1.1501766443252563, GAN loss = [2.7698915, 0.9597424, 1.0521234]\n",
      "Batch 649/700: Discriminator loss = 1.1682835817337036, GAN loss = [2.6885827, 0.95236635, 0.9782113]\n",
      "Batch 650/700: Discriminator loss = 1.1936646699905396, GAN loss = [2.7445724, 0.9521596, 1.0344381]\n",
      "Batch 651/700: Discriminator loss = 1.153088927268982, GAN loss = [2.7898774, 0.9565143, 1.0754071]\n",
      "Batch 652/700: Discriminator loss = 1.145714282989502, GAN loss = [2.8596716, 0.972405, 1.1293286]\n",
      "Batch 653/700: Discriminator loss = 1.1467562913894653, GAN loss = [2.7144535, 0.9752282, 0.98130584]\n",
      "Batch 654/700: Discriminator loss = 1.1188510656356812, GAN loss = [2.6691284, 0.9794001, 0.9318388]\n",
      "Batch 655/700: Discriminator loss = 1.1640105247497559, GAN loss = [2.8233151, 0.9538548, 1.1115956]\n",
      "Batch 656/700: Discriminator loss = 1.1235402822494507, GAN loss = [2.8547554, 1.0004411, 1.0964725]\n",
      "Batch 657/700: Discriminator loss = 1.152453899383545, GAN loss = [2.8232236, 0.97836095, 1.0870472]\n",
      "Batch 658/700: Discriminator loss = 1.1717073917388916, GAN loss = [2.847138, 0.9481782, 1.1411674]\n",
      "Batch 659/700: Discriminator loss = 1.1399142742156982, GAN loss = [2.8078067, 0.99474126, 1.0552841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 660/700: Discriminator loss = 1.181402325630188, GAN loss = [2.7832806, 0.96440536, 1.0611091]\n",
      "Batch 661/700: Discriminator loss = 1.1343834400177002, GAN loss = [2.9310324, 0.9941485, 1.1791434]\n",
      "Batch 662/700: Discriminator loss = 1.1741399765014648, GAN loss = [2.6882088, 0.96954954, 0.9609363]\n",
      "Batch 663/700: Discriminator loss = 1.1705397367477417, GAN loss = [2.8252013, 0.96140367, 1.1061008]\n",
      "Batch 664/700: Discriminator loss = 1.1603753566741943, GAN loss = [2.8490374, 0.9868298, 1.1045443]\n",
      "Batch 665/700: Discriminator loss = 1.1334218978881836, GAN loss = [2.9085612, 0.9935802, 1.1573395]\n",
      "Batch 666/700: Discriminator loss = 1.1884692907333374, GAN loss = [2.82263, 0.9698885, 1.0951371]\n",
      "Batch 667/700: Discriminator loss = 1.1628738641738892, GAN loss = [2.833919, 0.9726344, 1.1037271]\n",
      "Batch 668/700: Discriminator loss = 1.1585097312927246, GAN loss = [2.8272235, 0.98391986, 1.0858027]\n",
      "Batch 669/700: Discriminator loss = 1.1275103092193604, GAN loss = [2.8254683, 0.98683566, 1.081181]\n",
      "Batch 670/700: Discriminator loss = 1.1734181642532349, GAN loss = [2.833634, 0.9514081, 1.1248167]\n",
      "Batch 671/700: Discriminator loss = 1.1812875270843506, GAN loss = [2.8557253, 0.98130393, 1.1170465]\n",
      "Batch 672/700: Discriminator loss = 1.1844593286514282, GAN loss = [2.7555444, 0.9514762, 1.0467194]\n",
      "Batch 673/700: Discriminator loss = 1.131385326385498, GAN loss = [2.8456008, 1.0041577, 1.0841233]\n",
      "Batch 674/700: Discriminator loss = 1.1256020069122314, GAN loss = [2.833777, 1.0230701, 1.0534239]\n",
      "Batch 675/700: Discriminator loss = 1.1591310501098633, GAN loss = [2.814572, 0.96671784, 1.0906208]\n",
      "Batch 676/700: Discriminator loss = 1.1637954711914062, GAN loss = [2.777488, 0.9614589, 1.0588344]\n",
      "Batch 677/700: Discriminator loss = 1.198436975479126, GAN loss = [2.6322827, 0.94521576, 0.9298964]\n",
      "Batch 678/700: Discriminator loss = 1.1970170736312866, GAN loss = [2.763169, 0.9589857, 1.0470498]\n",
      "Batch 679/700: Discriminator loss = 1.134529709815979, GAN loss = [2.7811656, 0.9902756, 1.0337998]\n",
      "Batch 680/700: Discriminator loss = 1.1356112957000732, GAN loss = [2.8589416, 0.9709262, 1.130968]\n",
      "Batch 681/700: Discriminator loss = 1.1652909517288208, GAN loss = [2.851371, 0.9914328, 1.1029266]\n",
      "Batch 682/700: Discriminator loss = 1.1779975891113281, GAN loss = [2.7747784, 0.95635253, 1.0614533]\n",
      "Batch 683/700: Discriminator loss = 1.1317026615142822, GAN loss = [2.8814242, 1.0080712, 1.1164216]\n",
      "Batch 684/700: Discriminator loss = 1.1427794694900513, GAN loss = [2.9282284, 1.0066563, 1.164681]\n",
      "Batch 685/700: Discriminator loss = 1.1578946113586426, GAN loss = [2.7634938, 0.96679217, 1.0398501]\n",
      "Batch 686/700: Discriminator loss = 1.1972113847732544, GAN loss = [2.8337638, 0.94130486, 1.1356387]\n",
      "Batch 687/700: Discriminator loss = 1.165890097618103, GAN loss = [2.771075, 0.9725129, 1.0417644]\n",
      "Batch 688/700: Discriminator loss = 1.192881464958191, GAN loss = [2.7186897, 0.9406384, 1.021273]\n",
      "Batch 689/700: Discriminator loss = 1.1870806217193604, GAN loss = [2.7952757, 0.94433355, 1.094185]\n",
      "Batch 690/700: Discriminator loss = 1.1785790920257568, GAN loss = [2.8282468, 0.9671461, 1.1043656]\n",
      "Batch 691/700: Discriminator loss = 1.2207391262054443, GAN loss = [2.7815664, 0.95885336, 1.0660088]\n",
      "Batch 692/700: Discriminator loss = 1.1908314228057861, GAN loss = [2.8062394, 0.97912616, 1.0704442]\n",
      "Batch 693/700: Discriminator loss = 1.1752721071243286, GAN loss = [2.784877, 0.9785458, 1.0496897]\n",
      "Batch 694/700: Discriminator loss = 1.1753183603286743, GAN loss = [2.756217, 0.98678666, 1.0128086]\n",
      "Batch 695/700: Discriminator loss = 1.1642999649047852, GAN loss = [2.7215424, 0.99210274, 0.9728262]\n",
      "Batch 696/700: Discriminator loss = 1.1912761926651, GAN loss = [2.6663153, 0.95997244, 0.9497538]\n",
      "Batch 697/700: Discriminator loss = 1.2083865404129028, GAN loss = [2.7500992, 0.95864946, 1.0348891]\n",
      "Batch 698/700: Discriminator loss = 1.1744121313095093, GAN loss = [2.791522, 0.9896883, 1.0452964]\n",
      "Batch 699/700: Discriminator loss = 1.217312216758728, GAN loss = [2.77518, 0.9375952, 1.0810581]\n",
      "Batch 700/700: Discriminator loss = 1.1757559776306152, GAN loss = [2.7350452, 0.9812513, 0.99728715]\n",
      "Epoch 11/30\n",
      "Batch 1/700: Discriminator loss = 1.1431527137756348, GAN loss = [2.7743933, 0.9840854, 1.0338143]\n",
      "Batch 2/700: Discriminator loss = 1.168713092803955, GAN loss = [2.7708857, 0.9634228, 1.050981]\n",
      "Batch 3/700: Discriminator loss = 1.1918997764587402, GAN loss = [2.6804602, 0.9457515, 0.9782257]\n",
      "Batch 4/700: Discriminator loss = 1.158434271812439, GAN loss = [2.6893466, 0.9548745, 0.97799623]\n",
      "Batch 5/700: Discriminator loss = 1.194103479385376, GAN loss = [2.7887928, 0.96177083, 1.0705554]\n",
      "Batch 6/700: Discriminator loss = 1.1873104572296143, GAN loss = [2.6937034, 0.9324674, 1.0047829]\n",
      "Batch 7/700: Discriminator loss = 1.1897592544555664, GAN loss = [2.800724, 0.9743339, 1.0699496]\n",
      "Batch 8/700: Discriminator loss = 1.1555802822113037, GAN loss = [2.748687, 0.95385015, 1.0384159]\n",
      "Batch 9/700: Discriminator loss = 1.150209665298462, GAN loss = [2.7510827, 0.9509756, 1.0436964]\n",
      "Batch 10/700: Discriminator loss = 1.1968520879745483, GAN loss = [2.6219935, 0.9475027, 0.91809976]\n",
      "Batch 11/700: Discriminator loss = 1.153939127922058, GAN loss = [2.8103042, 0.981025, 1.0728973]\n",
      "Batch 12/700: Discriminator loss = 1.1777188777923584, GAN loss = [2.759476, 0.9324806, 1.0706209]\n",
      "Batch 13/700: Discriminator loss = 1.15549635887146, GAN loss = [2.7623727, 0.9538078, 1.0522045]\n",
      "Batch 14/700: Discriminator loss = 1.1501330137252808, GAN loss = [2.7735403, 0.96203595, 1.055149]\n",
      "Batch 15/700: Discriminator loss = 1.1722925901412964, GAN loss = [2.7569504, 0.95110345, 1.0495087]\n",
      "Batch 16/700: Discriminator loss = 1.1591002941131592, GAN loss = [2.7121859, 0.96973073, 0.9861319]\n",
      "Batch 17/700: Discriminator loss = 1.1383328437805176, GAN loss = [2.766348, 0.9782064, 1.031831]\n",
      "Batch 18/700: Discriminator loss = 1.1625051498413086, GAN loss = [2.6359146, 0.9432714, 0.93635994]\n",
      "Batch 19/700: Discriminator loss = 1.1983973979949951, GAN loss = [2.6515095, 0.9542492, 0.94100976]\n",
      "Batch 20/700: Discriminator loss = 1.146399736404419, GAN loss = [2.6634967, 0.95884305, 0.94842225]\n",
      "Batch 21/700: Discriminator loss = 1.1809457540512085, GAN loss = [2.6455114, 0.94135684, 0.9479443]\n",
      "Batch 22/700: Discriminator loss = 1.1877187490463257, GAN loss = [2.677638, 0.96239835, 0.9590445]\n",
      "Batch 23/700: Discriminator loss = 1.2185099124908447, GAN loss = [2.658857, 0.9266395, 0.9760458]\n",
      "Batch 24/700: Discriminator loss = 1.181215524673462, GAN loss = [2.5941396, 0.97302276, 0.86496246]\n",
      "Batch 25/700: Discriminator loss = 1.1801092624664307, GAN loss = [2.672643, 0.9329237, 0.98357964]\n",
      "Batch 26/700: Discriminator loss = 1.1119920015335083, GAN loss = [2.7738588, 1.0273496, 0.9903946]\n",
      "Batch 27/700: Discriminator loss = 1.1468369960784912, GAN loss = [2.746122, 0.98478144, 1.0052481]\n",
      "Batch 28/700: Discriminator loss = 1.1520657539367676, GAN loss = [2.8152614, 0.97747284, 1.081714]\n",
      "Batch 29/700: Discriminator loss = 1.1533591747283936, GAN loss = [2.7228448, 0.9337836, 1.0330043]\n",
      "Batch 30/700: Discriminator loss = 1.1880638599395752, GAN loss = [2.7489147, 0.92593, 1.0669476]\n",
      "Batch 31/700: Discriminator loss = 1.1635316610336304, GAN loss = [2.8071554, 0.9694164, 1.0817177]\n",
      "Batch 32/700: Discriminator loss = 1.1401726007461548, GAN loss = [2.765086, 0.9929027, 1.0161926]\n",
      "Batch 33/700: Discriminator loss = 1.1827062368392944, GAN loss = [2.7387793, 0.9598737, 1.0229434]\n",
      "Batch 34/700: Discriminator loss = 1.1652956008911133, GAN loss = [2.8186326, 0.9531768, 1.1095092]\n",
      "Batch 35/700: Discriminator loss = 1.1639690399169922, GAN loss = [2.8403974, 0.9642136, 1.1202558]\n",
      "Batch 36/700: Discriminator loss = 1.1548453569412231, GAN loss = [2.8019133, 0.9652413, 1.0807668]\n",
      "Batch 37/700: Discriminator loss = 1.1701469421386719, GAN loss = [2.7654932, 0.9629404, 1.0466594]\n",
      "Batch 38/700: Discriminator loss = 1.1449075937271118, GAN loss = [2.7381158, 0.9721525, 1.0100799]\n",
      "Batch 39/700: Discriminator loss = 1.1260950565338135, GAN loss = [2.8353531, 1.0218272, 1.0576577]\n",
      "Batch 40/700: Discriminator loss = 1.194325566291809, GAN loss = [2.7144914, 0.9423152, 1.0163196]\n",
      "Batch 41/700: Discriminator loss = 1.1958258152008057, GAN loss = [2.740074, 0.9481342, 1.0361003]\n",
      "Batch 42/700: Discriminator loss = 1.1724257469177246, GAN loss = [2.6756907, 0.9230857, 0.996791]\n",
      "Batch 43/700: Discriminator loss = 1.1796860694885254, GAN loss = [2.7025723, 0.9298442, 1.0169317]\n",
      "Batch 44/700: Discriminator loss = 1.1561602354049683, GAN loss = [2.7778242, 0.9501211, 1.071922]\n",
      "Batch 45/700: Discriminator loss = 1.155770182609558, GAN loss = [2.7551243, 0.9574268, 1.0419383]\n",
      "Batch 46/700: Discriminator loss = 1.1930973529815674, GAN loss = [2.6198828, 0.89936966, 0.96477056]\n",
      "Batch 47/700: Discriminator loss = 1.1919941902160645, GAN loss = [2.6927507, 0.94379884, 0.9932296]\n",
      "Batch 48/700: Discriminator loss = 1.1688364744186401, GAN loss = [2.6698022, 0.97222155, 0.94188637]\n",
      "Batch 49/700: Discriminator loss = 1.1779428720474243, GAN loss = [2.7188177, 0.94380045, 1.0193548]\n",
      "Batch 50/700: Discriminator loss = 1.1476095914840698, GAN loss = [2.7053015, 0.9450732, 1.0045933]\n",
      "Batch 51/700: Discriminator loss = 1.1412017345428467, GAN loss = [2.7464721, 0.98494315, 1.0059105]\n",
      "Batch 52/700: Discriminator loss = 1.1020984649658203, GAN loss = [2.6914093, 0.983366, 0.9524376]\n",
      "Batch 53/700: Discriminator loss = 1.180964469909668, GAN loss = [2.677669, 0.9264951, 0.99558973]\n",
      "Batch 54/700: Discriminator loss = 1.1610668897628784, GAN loss = [2.8595035, 0.96104485, 1.1428946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 55/700: Discriminator loss = 1.1610496044158936, GAN loss = [2.675978, 0.95497304, 0.96545744]\n",
      "Batch 56/700: Discriminator loss = 1.1877986192703247, GAN loss = [2.6916156, 0.92151, 1.0145706]\n",
      "Batch 57/700: Discriminator loss = 1.1682937145233154, GAN loss = [2.6815343, 0.9535891, 0.9724399]\n",
      "Batch 58/700: Discriminator loss = 1.1760036945343018, GAN loss = [2.7209353, 0.9635775, 1.0018795]\n",
      "Batch 59/700: Discriminator loss = 1.1364701986312866, GAN loss = [2.744557, 0.96631104, 1.0227826]\n",
      "Batch 60/700: Discriminator loss = 1.151391863822937, GAN loss = [2.7418401, 0.940028, 1.0463729]\n",
      "Batch 61/700: Discriminator loss = 1.1484434604644775, GAN loss = [2.8096745, 0.9975722, 1.0566944]\n",
      "Batch 62/700: Discriminator loss = 1.1720795631408691, GAN loss = [2.6603353, 0.94197327, 0.9629747]\n",
      "Batch 63/700: Discriminator loss = 1.1813023090362549, GAN loss = [2.7276068, 0.94556993, 1.0266786]\n",
      "Batch 64/700: Discriminator loss = 1.1948957443237305, GAN loss = [2.6027582, 0.9023969, 0.94502175]\n",
      "Batch 65/700: Discriminator loss = 1.142561674118042, GAN loss = [2.730854, 0.97056067, 1.0049762]\n",
      "Batch 66/700: Discriminator loss = 1.1784422397613525, GAN loss = [2.6755877, 0.9317572, 0.9885353]\n",
      "Batch 67/700: Discriminator loss = 1.1638214588165283, GAN loss = [2.6653447, 0.9296883, 0.9803905]\n",
      "Batch 68/700: Discriminator loss = 1.1671534776687622, GAN loss = [2.715651, 0.95472085, 1.00569]\n",
      "Batch 69/700: Discriminator loss = 1.1203242540359497, GAN loss = [2.765345, 0.97204745, 1.0380746]\n",
      "Batch 70/700: Discriminator loss = 1.1583937406539917, GAN loss = [2.6706307, 0.93613267, 0.9792859]\n",
      "Batch 71/700: Discriminator loss = 1.18049955368042, GAN loss = [2.6963573, 0.9367708, 1.0043856]\n",
      "Batch 72/700: Discriminator loss = 1.158876895904541, GAN loss = [2.7676506, 0.94740176, 1.065065]\n",
      "Batch 73/700: Discriminator loss = 1.174797773361206, GAN loss = [2.767128, 0.94483054, 1.0671357]\n",
      "Batch 74/700: Discriminator loss = 1.1765191555023193, GAN loss = [2.7644742, 0.9572263, 1.052109]\n",
      "Batch 75/700: Discriminator loss = 1.1608967781066895, GAN loss = [2.7607267, 0.9502621, 1.0553463]\n",
      "Batch 76/700: Discriminator loss = 1.1524758338928223, GAN loss = [2.6992452, 0.93616587, 1.0079765]\n",
      "Batch 77/700: Discriminator loss = 1.147426962852478, GAN loss = [2.707362, 0.96166503, 0.9906079]\n",
      "Batch 78/700: Discriminator loss = 1.1770644187927246, GAN loss = [2.759369, 0.94531363, 1.0589923]\n",
      "Batch 79/700: Discriminator loss = 1.177860975265503, GAN loss = [2.689469, 0.93399864, 1.0004364]\n",
      "Batch 80/700: Discriminator loss = 1.1277880668640137, GAN loss = [2.7465951, 0.9759095, 1.0156828]\n",
      "Batch 81/700: Discriminator loss = 1.169907569885254, GAN loss = [2.669377, 0.94398504, 0.9704103]\n",
      "Batch 82/700: Discriminator loss = 1.1535649299621582, GAN loss = [2.7608447, 0.9691059, 1.0367777]\n",
      "Batch 83/700: Discriminator loss = 1.190298318862915, GAN loss = [2.7454388, 0.95547205, 1.0350404]\n",
      "Batch 84/700: Discriminator loss = 1.1383216381072998, GAN loss = [2.7411876, 0.9441304, 1.0421745]\n",
      "Batch 85/700: Discriminator loss = 1.155920147895813, GAN loss = [2.7455368, 0.9366088, 1.0540752]\n",
      "Batch 86/700: Discriminator loss = 1.166162133216858, GAN loss = [2.7133374, 0.9306192, 1.0278935]\n",
      "Batch 87/700: Discriminator loss = 1.1910916566848755, GAN loss = [2.6475022, 0.9204045, 0.97228724]\n",
      "Batch 88/700: Discriminator loss = 1.1206579208374023, GAN loss = [2.8516738, 0.9957084, 1.1011722]\n",
      "Batch 89/700: Discriminator loss = 1.1399941444396973, GAN loss = [2.825825, 0.972212, 1.0988395]\n",
      "Batch 90/700: Discriminator loss = 1.159472942352295, GAN loss = [2.7600136, 0.9616723, 1.0435872]\n",
      "Batch 91/700: Discriminator loss = 1.147070050239563, GAN loss = [2.745758, 0.9655328, 1.0255109]\n",
      "Batch 92/700: Discriminator loss = 1.17499577999115, GAN loss = [2.6789532, 0.9418621, 0.98241514]\n",
      "Batch 93/700: Discriminator loss = 1.1189302206039429, GAN loss = [2.865168, 0.9933491, 1.117185]\n",
      "Batch 94/700: Discriminator loss = 1.1494941711425781, GAN loss = [2.7111406, 0.9431066, 1.0134333]\n",
      "Batch 95/700: Discriminator loss = 1.1702675819396973, GAN loss = [2.7489517, 0.9293794, 1.0649976]\n",
      "Batch 96/700: Discriminator loss = 1.14400053024292, GAN loss = [2.8442504, 0.96218467, 1.1275171]\n",
      "Batch 97/700: Discriminator loss = 1.1480634212493896, GAN loss = [2.8371017, 0.9497204, 1.132857]\n",
      "Batch 98/700: Discriminator loss = 1.1471816301345825, GAN loss = [2.83464, 0.9663039, 1.1138372]\n",
      "Batch 99/700: Discriminator loss = 1.1492873430252075, GAN loss = [2.844249, 0.95348066, 1.1362789]\n",
      "Batch 100/700: Discriminator loss = 1.159669280052185, GAN loss = [2.7623749, 0.95732474, 1.0505888]\n",
      "Batch 101/700: Discriminator loss = 1.1606566905975342, GAN loss = [2.8112564, 0.98382074, 1.0730107]\n",
      "Batch 102/700: Discriminator loss = 1.1432218551635742, GAN loss = [2.7842045, 0.9675585, 1.0622592]\n",
      "Batch 103/700: Discriminator loss = 1.1870170831680298, GAN loss = [2.726434, 0.95884985, 1.0132291]\n",
      "Batch 104/700: Discriminator loss = 1.1497706174850464, GAN loss = [2.8150706, 0.9747778, 1.0859827]\n",
      "Batch 105/700: Discriminator loss = 1.1726770401000977, GAN loss = [2.7365975, 0.9537751, 1.0285608]\n",
      "Batch 106/700: Discriminator loss = 1.1690022945404053, GAN loss = [2.7335567, 0.97471124, 1.0046169]\n",
      "Batch 107/700: Discriminator loss = 1.1695988178253174, GAN loss = [2.6669726, 0.95807165, 0.9547074]\n",
      "Batch 108/700: Discriminator loss = 1.1008460521697998, GAN loss = [2.8132374, 1.0246367, 1.0344464]\n",
      "Batch 109/700: Discriminator loss = 1.1549384593963623, GAN loss = [2.8538456, 1.0033664, 1.0963662]\n",
      "Batch 110/700: Discriminator loss = 1.1400694847106934, GAN loss = [2.8093367, 1.0003031, 1.0549538]\n",
      "Batch 111/700: Discriminator loss = 1.1494947671890259, GAN loss = [2.7831907, 0.977205, 1.05195]\n",
      "Batch 112/700: Discriminator loss = 1.1227022409439087, GAN loss = [2.8322797, 1.0036814, 1.0745927]\n",
      "Batch 113/700: Discriminator loss = 1.1254693269729614, GAN loss = [2.8353894, 0.99443793, 1.086974]\n",
      "Batch 114/700: Discriminator loss = 1.1523443460464478, GAN loss = [2.8235755, 1.0247467, 1.0448596]\n",
      "Batch 115/700: Discriminator loss = 1.098495602607727, GAN loss = [2.911164, 1.0442604, 1.1129537]\n",
      "Batch 116/700: Discriminator loss = 1.127808690071106, GAN loss = [2.7979326, 1.0095776, 1.0344253]\n",
      "Batch 117/700: Discriminator loss = 1.1248263120651245, GAN loss = [2.800142, 0.99079674, 1.0554439]\n",
      "Batch 118/700: Discriminator loss = 1.106705904006958, GAN loss = [2.977497, 1.0256138, 1.1980124]\n",
      "Batch 119/700: Discriminator loss = 1.1009769439697266, GAN loss = [2.8553057, 1.0342469, 1.0672345]\n",
      "Batch 120/700: Discriminator loss = 1.1198503971099854, GAN loss = [2.785687, 0.9970327, 1.0348746]\n",
      "Batch 121/700: Discriminator loss = 1.144463062286377, GAN loss = [2.8569317, 1.0187095, 1.0844957]\n",
      "Batch 122/700: Discriminator loss = 1.1212005615234375, GAN loss = [2.8212752, 1.0124121, 1.0551704]\n",
      "Batch 123/700: Discriminator loss = 1.1018807888031006, GAN loss = [2.9953668, 1.020431, 1.2212687]\n",
      "Batch 124/700: Discriminator loss = 1.1415574550628662, GAN loss = [2.8925169, 0.9688206, 1.1700481]\n",
      "Batch 125/700: Discriminator loss = 1.1471261978149414, GAN loss = [2.7608314, 0.9574821, 1.0497253]\n",
      "Batch 126/700: Discriminator loss = 1.1873178482055664, GAN loss = [2.750124, 0.94185036, 1.0546737]\n",
      "Batch 127/700: Discriminator loss = 1.093268632888794, GAN loss = [2.8719997, 1.0082116, 1.1102128]\n",
      "Batch 128/700: Discriminator loss = 1.1919050216674805, GAN loss = [2.757737, 0.9723232, 1.0318664]\n",
      "Batch 129/700: Discriminator loss = 1.152234435081482, GAN loss = [2.7797062, 0.951192, 1.0749907]\n",
      "Batch 130/700: Discriminator loss = 1.151761531829834, GAN loss = [2.9055247, 0.9694754, 1.1825513]\n",
      "Batch 131/700: Discriminator loss = 1.163798451423645, GAN loss = [2.8178532, 0.95064765, 1.1137124]\n",
      "Batch 132/700: Discriminator loss = 1.1384084224700928, GAN loss = [2.8796508, 0.99416053, 1.1320019]\n",
      "Batch 133/700: Discriminator loss = 1.145732045173645, GAN loss = [2.8927464, 0.9794148, 1.1598529]\n",
      "Batch 134/700: Discriminator loss = 1.2337323427200317, GAN loss = [2.65079, 0.894933, 1.0023961]\n",
      "Batch 135/700: Discriminator loss = 1.1700092554092407, GAN loss = [2.8002121, 0.9346931, 1.1120708]\n",
      "Batch 136/700: Discriminator loss = 1.1423553228378296, GAN loss = [2.7637115, 0.98597383, 1.0243137]\n",
      "Batch 137/700: Discriminator loss = 1.1785073280334473, GAN loss = [2.81464, 0.9564631, 1.1047689]\n",
      "Batch 138/700: Discriminator loss = 1.1250041723251343, GAN loss = [2.8725076, 0.980739, 1.1383747]\n",
      "Batch 139/700: Discriminator loss = 1.1479722261428833, GAN loss = [2.727603, 0.9807285, 0.99350524]\n",
      "Batch 140/700: Discriminator loss = 1.1287051439285278, GAN loss = [2.823044, 0.9756878, 1.0940259]\n",
      "Batch 141/700: Discriminator loss = 1.1640546321868896, GAN loss = [2.8299508, 0.9598937, 1.1167402]\n",
      "Batch 142/700: Discriminator loss = 1.1427558660507202, GAN loss = [2.9094718, 0.9565374, 1.199633]\n",
      "Batch 143/700: Discriminator loss = 1.1706528663635254, GAN loss = [2.8662047, 0.9565179, 1.156407]\n",
      "Batch 144/700: Discriminator loss = 1.1585510969161987, GAN loss = [2.6918092, 0.9350095, 1.0035267]\n",
      "Batch 145/700: Discriminator loss = 1.159440517425537, GAN loss = [2.7826648, 0.9568467, 1.0725565]\n",
      "Batch 146/700: Discriminator loss = 1.1827152967453003, GAN loss = [2.728382, 0.94159716, 1.0335335]\n",
      "Batch 147/700: Discriminator loss = 1.1733579635620117, GAN loss = [2.7353783, 0.9491272, 1.0330144]\n",
      "Batch 148/700: Discriminator loss = 1.1983438730239868, GAN loss = [2.7664034, 0.9367234, 1.0764642]\n",
      "Batch 149/700: Discriminator loss = 1.16607666015625, GAN loss = [2.7812276, 0.957124, 1.0709007]\n",
      "Batch 150/700: Discriminator loss = 1.2191073894500732, GAN loss = [2.6616635, 0.9154123, 0.9930553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 151/700: Discriminator loss = 1.1984493732452393, GAN loss = [2.7638216, 0.92788124, 1.0827489]\n",
      "Batch 152/700: Discriminator loss = 1.1813353300094604, GAN loss = [2.6740425, 0.9095697, 1.011308]\n",
      "Batch 153/700: Discriminator loss = 1.1336135864257812, GAN loss = [2.8642466, 0.9706845, 1.1404121]\n",
      "Batch 154/700: Discriminator loss = 1.1774073839187622, GAN loss = [2.6390722, 0.9217233, 0.9642303]\n",
      "Batch 155/700: Discriminator loss = 1.2114386558532715, GAN loss = [2.7499917, 0.8888441, 1.1080555]\n",
      "Batch 156/700: Discriminator loss = 1.2090044021606445, GAN loss = [2.709811, 0.90453005, 1.0522083]\n",
      "Batch 157/700: Discriminator loss = 1.2106181383132935, GAN loss = [2.739242, 0.9120557, 1.0741307]\n",
      "Batch 158/700: Discriminator loss = 1.1647268533706665, GAN loss = [2.7199373, 0.9508036, 1.0161072]\n",
      "Batch 159/700: Discriminator loss = 1.206078290939331, GAN loss = [2.74289, 0.91695696, 1.0729394]\n",
      "Batch 160/700: Discriminator loss = 1.1729192733764648, GAN loss = [2.7741966, 0.9662895, 1.0549477]\n",
      "Batch 161/700: Discriminator loss = 1.1794830560684204, GAN loss = [2.682949, 0.92117465, 1.0088582]\n",
      "Batch 162/700: Discriminator loss = 1.2095937728881836, GAN loss = [2.7352138, 0.92988974, 1.0524446]\n",
      "Batch 163/700: Discriminator loss = 1.2208212614059448, GAN loss = [2.61171, 0.9172658, 0.94160616]\n",
      "Batch 164/700: Discriminator loss = 1.157427191734314, GAN loss = [2.7858977, 0.9623169, 1.0707732]\n",
      "Batch 165/700: Discriminator loss = 1.171777367591858, GAN loss = [2.6945803, 0.944247, 0.9975532]\n",
      "Batch 166/700: Discriminator loss = 1.1428754329681396, GAN loss = [2.8440068, 0.96188825, 1.1293477]\n",
      "Batch 167/700: Discriminator loss = 1.193334937095642, GAN loss = [2.6972134, 0.93933386, 1.0051198]\n",
      "Batch 168/700: Discriminator loss = 1.1766445636749268, GAN loss = [2.6853516, 0.92047334, 1.012135]\n",
      "Batch 169/700: Discriminator loss = 1.189726710319519, GAN loss = [2.8294713, 0.9424672, 1.1342851]\n",
      "Batch 170/700: Discriminator loss = 1.1394575834274292, GAN loss = [2.7328904, 0.96037817, 1.0198201]\n",
      "Batch 171/700: Discriminator loss = 1.1423423290252686, GAN loss = [2.8482428, 0.95666456, 1.1389177]\n",
      "Batch 172/700: Discriminator loss = 1.1292805671691895, GAN loss = [2.8297057, 0.9568672, 1.1202186]\n",
      "Batch 173/700: Discriminator loss = 1.1335780620574951, GAN loss = [2.8239005, 0.9884014, 1.082916]\n",
      "Batch 174/700: Discriminator loss = 1.141079306602478, GAN loss = [2.7920747, 0.96547884, 1.0740347]\n",
      "Batch 175/700: Discriminator loss = 1.1472580432891846, GAN loss = [2.7401285, 0.95638204, 1.0311935]\n",
      "Batch 176/700: Discriminator loss = 1.1722607612609863, GAN loss = [2.803124, 0.93643934, 1.1141348]\n",
      "Batch 177/700: Discriminator loss = 1.1756330728530884, GAN loss = [2.7567375, 0.9706941, 1.0334961]\n",
      "Batch 178/700: Discriminator loss = 1.1793850660324097, GAN loss = [2.6833916, 0.9352109, 0.99562883]\n",
      "Batch 179/700: Discriminator loss = 1.1762127876281738, GAN loss = [2.7762637, 0.95852226, 1.0651884]\n",
      "Batch 180/700: Discriminator loss = 1.18313729763031, GAN loss = [2.6396055, 0.9123383, 0.97471327]\n",
      "Batch 181/700: Discriminator loss = 1.1546626091003418, GAN loss = [2.78175, 0.94807744, 1.0811325]\n",
      "Batch 182/700: Discriminator loss = 1.1962875127792358, GAN loss = [2.7289379, 0.9054706, 1.0709517]\n",
      "Batch 183/700: Discriminator loss = 1.1746931076049805, GAN loss = [2.6550503, 0.93066424, 0.9718944]\n",
      "Batch 184/700: Discriminator loss = 1.2096418142318726, GAN loss = [2.649333, 0.91015947, 0.98670095]\n",
      "Batch 185/700: Discriminator loss = 1.1988627910614014, GAN loss = [2.6930046, 0.92526835, 1.015271]\n",
      "Batch 186/700: Discriminator loss = 1.1527063846588135, GAN loss = [2.714233, 0.9484144, 1.0133694]\n",
      "Batch 187/700: Discriminator loss = 1.1966971158981323, GAN loss = [2.7298899, 1.0064632, 0.97098684]\n",
      "Batch 188/700: Discriminator loss = 1.1447397470474243, GAN loss = [2.693492, 0.9875625, 0.95350486]\n",
      "Batch 189/700: Discriminator loss = 1.1271464824676514, GAN loss = [2.7932787, 0.98474604, 1.0561302]\n",
      "Batch 190/700: Discriminator loss = 1.146533727645874, GAN loss = [2.8421226, 0.990311, 1.0994242]\n",
      "Batch 191/700: Discriminator loss = 1.1853643655776978, GAN loss = [2.6914797, 0.9318867, 1.0072086]\n",
      "Batch 192/700: Discriminator loss = 1.175156831741333, GAN loss = [2.6830914, 0.91073316, 1.0199825]\n",
      "Batch 193/700: Discriminator loss = 1.1867403984069824, GAN loss = [2.7417104, 0.93445534, 1.0548851]\n",
      "Batch 194/700: Discriminator loss = 1.1669015884399414, GAN loss = [2.7574384, 0.9357137, 1.0693728]\n",
      "Batch 195/700: Discriminator loss = 1.1763155460357666, GAN loss = [2.8170776, 0.97050416, 1.0942373]\n",
      "Batch 196/700: Discriminator loss = 1.1720603704452515, GAN loss = [2.79416, 0.95277596, 1.0890635]\n",
      "Batch 197/700: Discriminator loss = 1.1568245887756348, GAN loss = [2.740054, 0.95988744, 1.02786]\n",
      "Batch 198/700: Discriminator loss = 1.1542766094207764, GAN loss = [2.646821, 0.9634644, 0.93107057]\n",
      "Batch 199/700: Discriminator loss = 1.1538864374160767, GAN loss = [2.8161542, 0.96054876, 1.1033481]\n",
      "Batch 200/700: Discriminator loss = 1.147559642791748, GAN loss = [2.8936937, 0.9686148, 1.1728638]\n",
      "Batch 201/700: Discriminator loss = 1.1461613178253174, GAN loss = [2.9005065, 1.0017143, 1.1465983]\n",
      "Batch 202/700: Discriminator loss = 1.1459108591079712, GAN loss = [2.820384, 1.0133681, 1.0548519]\n",
      "Batch 203/700: Discriminator loss = 1.124105453491211, GAN loss = [2.8585143, 0.99504614, 1.111338]\n",
      "Batch 204/700: Discriminator loss = 1.1498781442642212, GAN loss = [2.8470695, 0.96594125, 1.1290301]\n",
      "Batch 205/700: Discriminator loss = 1.1523635387420654, GAN loss = [2.8495023, 0.96018946, 1.1372377]\n",
      "Batch 206/700: Discriminator loss = 1.132556438446045, GAN loss = [2.7906091, 0.9691462, 1.0694115]\n",
      "Batch 207/700: Discriminator loss = 1.170737385749817, GAN loss = [2.8194587, 0.95272744, 1.1146864]\n",
      "Batch 208/700: Discriminator loss = 1.1108342409133911, GAN loss = [2.8680398, 1.0112728, 1.1047333]\n",
      "Batch 209/700: Discriminator loss = 1.1737167835235596, GAN loss = [2.74612, 0.9328869, 1.0612156]\n",
      "Batch 210/700: Discriminator loss = 1.1699262857437134, GAN loss = [2.7843375, 0.9504786, 1.0818495]\n",
      "Batch 211/700: Discriminator loss = 1.1736958026885986, GAN loss = [2.8487914, 0.98343486, 1.1133517]\n",
      "Batch 212/700: Discriminator loss = 1.1536383628845215, GAN loss = [2.8808482, 0.97140443, 1.1574727]\n",
      "Batch 213/700: Discriminator loss = 1.1736587285995483, GAN loss = [2.8506434, 0.95382667, 1.1448785]\n",
      "Batch 214/700: Discriminator loss = 1.19255793094635, GAN loss = [2.723156, 0.9490233, 1.0222245]\n",
      "Batch 215/700: Discriminator loss = 1.168850302696228, GAN loss = [2.76426, 0.96137923, 1.0510088]\n",
      "Batch 216/700: Discriminator loss = 1.187971591949463, GAN loss = [2.8163297, 0.9915712, 1.0729192]\n",
      "Batch 217/700: Discriminator loss = 1.197259545326233, GAN loss = [2.854746, 0.9500643, 1.1528709]\n",
      "Batch 218/700: Discriminator loss = 1.168407678604126, GAN loss = [2.8129668, 0.97379035, 1.0873957]\n",
      "Batch 219/700: Discriminator loss = 1.1390881538391113, GAN loss = [2.9061635, 1.0064079, 1.1480029]\n",
      "Batch 220/700: Discriminator loss = 1.1401371955871582, GAN loss = [2.820275, 1.004535, 1.0640169]\n",
      "Batch 221/700: Discriminator loss = 1.124801516532898, GAN loss = [2.845912, 1.0159794, 1.0782485]\n",
      "Batch 222/700: Discriminator loss = 1.1388825178146362, GAN loss = [2.9341674, 0.9702475, 1.2122585]\n",
      "Batch 223/700: Discriminator loss = 1.1555602550506592, GAN loss = [2.7972426, 0.9770895, 1.0685128]\n",
      "Batch 224/700: Discriminator loss = 1.1500271558761597, GAN loss = [2.795178, 0.97180194, 1.0717556]\n",
      "Batch 225/700: Discriminator loss = 1.1583696603775024, GAN loss = [2.8495805, 0.9784039, 1.119581]\n",
      "Batch 226/700: Discriminator loss = 1.1494497060775757, GAN loss = [2.8753705, 1.0063653, 1.1174357]\n",
      "Batch 227/700: Discriminator loss = 1.1376020908355713, GAN loss = [2.7753205, 0.9962889, 1.0274911]\n",
      "Batch 228/700: Discriminator loss = 1.1698278188705444, GAN loss = [2.7263153, 0.94347274, 1.0313295]\n",
      "Batch 229/700: Discriminator loss = 1.15067720413208, GAN loss = [2.8282855, 0.95379204, 1.1230167]\n",
      "Batch 230/700: Discriminator loss = 1.175145149230957, GAN loss = [2.8433316, 0.9540204, 1.1378791]\n",
      "Batch 231/700: Discriminator loss = 1.12174654006958, GAN loss = [2.8366892, 1.0585785, 1.0267003]\n",
      "Batch 232/700: Discriminator loss = 1.1395658254623413, GAN loss = [2.8127868, 0.98069745, 1.0807028]\n",
      "Batch 233/700: Discriminator loss = 1.1716722249984741, GAN loss = [2.70448, 0.9648133, 0.98829085]\n",
      "Batch 234/700: Discriminator loss = 1.151239275932312, GAN loss = [2.7796748, 0.98268265, 1.0456203]\n",
      "Batch 235/700: Discriminator loss = 1.1805298328399658, GAN loss = [2.842691, 0.98642045, 1.104899]\n",
      "Batch 236/700: Discriminator loss = 1.1682703495025635, GAN loss = [2.6817458, 0.9575805, 0.9728183]\n",
      "Batch 237/700: Discriminator loss = 1.1370806694030762, GAN loss = [2.8002336, 1.0084941, 1.0404248]\n",
      "Batch 238/700: Discriminator loss = 1.1680748462677002, GAN loss = [2.7312338, 0.9548408, 1.0250962]\n",
      "Batch 239/700: Discriminator loss = 1.1235175132751465, GAN loss = [2.822678, 0.98590314, 1.0854905]\n",
      "Batch 240/700: Discriminator loss = 1.1424692869186401, GAN loss = [2.8261473, 1.0173861, 1.057488]\n",
      "Batch 241/700: Discriminator loss = 1.149493932723999, GAN loss = [2.8896005, 1.0180535, 1.1202899]\n",
      "Batch 242/700: Discriminator loss = 1.1362159252166748, GAN loss = [2.7899442, 0.9742003, 1.0645211]\n",
      "Batch 243/700: Discriminator loss = 1.160883903503418, GAN loss = [2.838815, 0.9899801, 1.09764]\n",
      "Batch 244/700: Discriminator loss = 1.1538641452789307, GAN loss = [2.7643123, 0.99508315, 1.0180655]\n",
      "Batch 245/700: Discriminator loss = 1.14858078956604, GAN loss = [2.8975403, 0.98517627, 1.1612417]\n",
      "Batch 246/700: Discriminator loss = 1.155999779701233, GAN loss = [2.7313993, 0.9756824, 1.0046276]\n",
      "Batch 247/700: Discriminator loss = 1.1231075525283813, GAN loss = [2.7956376, 0.9940307, 1.0505354]\n",
      "Batch 248/700: Discriminator loss = 1.1342967748641968, GAN loss = [2.7893403, 0.99630094, 1.0419703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 249/700: Discriminator loss = 1.156453013420105, GAN loss = [2.8038743, 0.9737939, 1.0790225]\n",
      "Batch 250/700: Discriminator loss = 1.164467692375183, GAN loss = [2.7249084, 0.980092, 0.9937692]\n",
      "Batch 251/700: Discriminator loss = 1.2013921737670898, GAN loss = [2.7550876, 0.94294447, 1.0611173]\n",
      "Batch 252/700: Discriminator loss = 1.1634920835494995, GAN loss = [2.8523762, 0.9529599, 1.1483961]\n",
      "Batch 253/700: Discriminator loss = 1.136887788772583, GAN loss = [2.7942145, 1.0099151, 1.033285]\n",
      "Batch 254/700: Discriminator loss = 1.1352744102478027, GAN loss = [2.768138, 1.0059785, 1.0111573]\n",
      "Batch 255/700: Discriminator loss = 1.142256259918213, GAN loss = [2.9149642, 0.9908167, 1.1731644]\n",
      "Batch 256/700: Discriminator loss = 1.1058597564697266, GAN loss = [2.9636343, 1.0210078, 1.1916698]\n",
      "Batch 257/700: Discriminator loss = 1.1265275478363037, GAN loss = [2.9282134, 1.0024819, 1.1747967]\n",
      "Batch 258/700: Discriminator loss = 1.143984079360962, GAN loss = [2.991256, 1.0049075, 1.2354282]\n",
      "Batch 259/700: Discriminator loss = 1.1230049133300781, GAN loss = [2.8566992, 0.9931186, 1.1126797]\n",
      "Batch 260/700: Discriminator loss = 1.1880470514297485, GAN loss = [2.8410265, 0.9458586, 1.1442856]\n",
      "Batch 261/700: Discriminator loss = 1.1572293043136597, GAN loss = [2.7769146, 0.9712672, 1.0547765]\n",
      "Batch 262/700: Discriminator loss = 1.1297607421875, GAN loss = [2.8301644, 1.0040932, 1.0752149]\n",
      "Batch 263/700: Discriminator loss = 1.18001127243042, GAN loss = [2.7725475, 0.95233953, 1.0693699]\n",
      "Batch 264/700: Discriminator loss = 1.1341837644577026, GAN loss = [2.8034856, 0.969325, 1.0833409]\n",
      "Batch 265/700: Discriminator loss = 1.1823720932006836, GAN loss = [2.8658383, 0.94081146, 1.1742182]\n",
      "Batch 266/700: Discriminator loss = 1.1473219394683838, GAN loss = [3.0341973, 0.976448, 1.3069571]\n",
      "Batch 267/700: Discriminator loss = 1.1844823360443115, GAN loss = [2.742236, 0.9407466, 1.0507357]\n",
      "Batch 268/700: Discriminator loss = 1.1649788618087769, GAN loss = [2.7268019, 0.99125016, 0.98482203]\n",
      "Batch 269/700: Discriminator loss = 1.1593204736709595, GAN loss = [2.8936334, 0.9828579, 1.1600684]\n",
      "Batch 270/700: Discriminator loss = 1.169086217880249, GAN loss = [2.82766, 0.9804197, 1.0965439]\n",
      "Batch 271/700: Discriminator loss = 1.1507660150527954, GAN loss = [2.9036124, 0.9829562, 1.1699721]\n",
      "Batch 272/700: Discriminator loss = 1.164035439491272, GAN loss = [2.8599055, 0.96919096, 1.1400437]\n",
      "Batch 273/700: Discriminator loss = 1.113288164138794, GAN loss = [2.864821, 1.006, 1.1081673]\n",
      "Batch 274/700: Discriminator loss = 1.1581487655639648, GAN loss = [2.792834, 1.0038933, 1.0382981]\n",
      "Batch 275/700: Discriminator loss = 1.151472568511963, GAN loss = [2.9254405, 0.99571174, 1.179097]\n",
      "Batch 276/700: Discriminator loss = 1.1246552467346191, GAN loss = [2.9052622, 0.9802045, 1.1744548]\n",
      "Batch 277/700: Discriminator loss = 1.1414339542388916, GAN loss = [2.8462143, 0.97866684, 1.1169786]\n",
      "Batch 278/700: Discriminator loss = 1.1516437530517578, GAN loss = [2.9185925, 0.9859355, 1.1821184]\n",
      "Batch 279/700: Discriminator loss = 1.1684383153915405, GAN loss = [2.7593272, 0.9462759, 1.0625405]\n",
      "Batch 280/700: Discriminator loss = 1.1557018756866455, GAN loss = [2.797272, 1.0048335, 1.0419457]\n",
      "Batch 281/700: Discriminator loss = 1.22657310962677, GAN loss = [2.7992125, 0.9429164, 1.1058277]\n",
      "Batch 282/700: Discriminator loss = 1.1816476583480835, GAN loss = [2.810047, 0.96684813, 1.0927418]\n",
      "Batch 283/700: Discriminator loss = 1.1508584022521973, GAN loss = [2.921974, 0.95803314, 1.2134964]\n",
      "Batch 284/700: Discriminator loss = 1.1350455284118652, GAN loss = [2.9380605, 0.9743962, 1.2132537]\n",
      "Batch 285/700: Discriminator loss = 1.1385068893432617, GAN loss = [2.8118713, 0.9836568, 1.0778439]\n",
      "Batch 286/700: Discriminator loss = 1.1392391920089722, GAN loss = [2.8974087, 0.99113846, 1.1559398]\n",
      "Batch 287/700: Discriminator loss = 1.1639647483825684, GAN loss = [2.825052, 0.9827857, 1.0919771]\n",
      "Batch 288/700: Discriminator loss = 1.2078715562820435, GAN loss = [2.7340174, 0.93666375, 1.0471169]\n",
      "Batch 289/700: Discriminator loss = 1.1281145811080933, GAN loss = [2.8021407, 0.9743747, 1.0775663]\n",
      "Batch 290/700: Discriminator loss = 1.1570273637771606, GAN loss = [2.7502024, 0.9572683, 1.0427694]\n",
      "Batch 291/700: Discriminator loss = 1.1649304628372192, GAN loss = [2.895036, 0.96145225, 1.1834381]\n",
      "Batch 292/700: Discriminator loss = 1.1348109245300293, GAN loss = [2.9014037, 1.0112089, 1.1400677]\n",
      "Batch 293/700: Discriminator loss = 1.2053924798965454, GAN loss = [2.7925584, 0.9473571, 1.0950956]\n",
      "Batch 294/700: Discriminator loss = 1.1337326765060425, GAN loss = [2.7979336, 1.025346, 1.0225071]\n",
      "Batch 295/700: Discriminator loss = 1.17523992061615, GAN loss = [2.7563329, 0.95402646, 1.0522642]\n",
      "Batch 296/700: Discriminator loss = 1.1397788524627686, GAN loss = [2.8347716, 0.98571825, 1.0990424]\n",
      "Batch 297/700: Discriminator loss = 1.1946921348571777, GAN loss = [2.8300612, 0.9514389, 1.1286361]\n",
      "Batch 298/700: Discriminator loss = 1.1889731884002686, GAN loss = [2.6595564, 0.9708101, 0.9387873]\n",
      "Batch 299/700: Discriminator loss = 1.1435229778289795, GAN loss = [2.7781012, 0.9985133, 1.0296572]\n",
      "Batch 300/700: Discriminator loss = 1.1407073736190796, GAN loss = [2.792629, 1.01099, 1.0317554]\n",
      "Batch 301/700: Discriminator loss = 1.204418420791626, GAN loss = [2.7113533, 0.9642366, 0.997272]\n",
      "Batch 302/700: Discriminator loss = 1.1549590826034546, GAN loss = [2.6910267, 0.96011496, 0.98108953]\n",
      "Batch 303/700: Discriminator loss = 1.1596348285675049, GAN loss = [2.7653992, 0.9886788, 1.0269185]\n",
      "Batch 304/700: Discriminator loss = 1.1718552112579346, GAN loss = [2.7414708, 0.9613405, 1.030352]\n",
      "Batch 305/700: Discriminator loss = 1.139586329460144, GAN loss = [2.7714918, 0.98106265, 1.0406787]\n",
      "Batch 306/700: Discriminator loss = 1.1665210723876953, GAN loss = [2.8361418, 0.985573, 1.1008486]\n",
      "Batch 307/700: Discriminator loss = 1.2120378017425537, GAN loss = [2.659436, 0.947448, 0.96229994]\n",
      "Batch 308/700: Discriminator loss = 1.2069729566574097, GAN loss = [2.6115696, 0.92574835, 0.9361704]\n",
      "Batch 309/700: Discriminator loss = 1.1993838548660278, GAN loss = [2.717088, 0.93649095, 1.0309796]\n",
      "Batch 310/700: Discriminator loss = 1.1646307706832886, GAN loss = [2.6764238, 0.9528682, 0.97396624]\n",
      "Batch 311/700: Discriminator loss = 1.1824489831924438, GAN loss = [2.7551775, 0.979312, 1.0263107]\n",
      "Batch 312/700: Discriminator loss = 1.1393917798995972, GAN loss = [2.8010423, 1.007406, 1.044134]\n",
      "Batch 313/700: Discriminator loss = 1.138412594795227, GAN loss = [2.7538698, 0.9936589, 1.0107538]\n",
      "Batch 314/700: Discriminator loss = 1.1993293762207031, GAN loss = [2.6946325, 0.9401656, 1.0050435]\n",
      "Batch 315/700: Discriminator loss = 1.158172369003296, GAN loss = [2.8380554, 1.0152007, 1.0734563]\n",
      "Batch 316/700: Discriminator loss = 1.1322996616363525, GAN loss = [2.806097, 1.0378206, 1.0189123]\n",
      "Batch 317/700: Discriminator loss = 1.1436718702316284, GAN loss = [2.8105066, 1.0015569, 1.0596161]\n",
      "Batch 318/700: Discriminator loss = 1.1423375606536865, GAN loss = [2.7978551, 0.99575734, 1.0527838]\n",
      "Batch 319/700: Discriminator loss = 1.1653287410736084, GAN loss = [2.6743476, 0.9824829, 0.9425836]\n",
      "Batch 320/700: Discriminator loss = 1.1564024686813354, GAN loss = [2.8289888, 0.99710816, 1.0826415]\n",
      "Batch 321/700: Discriminator loss = 1.1552910804748535, GAN loss = [2.710708, 0.96938086, 0.99213594]\n",
      "Batch 322/700: Discriminator loss = 1.1324526071548462, GAN loss = [2.8224216, 1.0211957, 1.0520777]\n",
      "Batch 323/700: Discriminator loss = 1.1537392139434814, GAN loss = [2.7210994, 1.003579, 0.9684093]\n",
      "Batch 324/700: Discriminator loss = 1.1231944561004639, GAN loss = [2.7988167, 1.0175275, 1.0322192]\n",
      "Batch 325/700: Discriminator loss = 1.1594939231872559, GAN loss = [2.735889, 0.9972236, 0.9896273]\n",
      "Batch 326/700: Discriminator loss = 1.1359037160873413, GAN loss = [2.7225466, 0.96728086, 1.0062617]\n",
      "Batch 327/700: Discriminator loss = 1.199357509613037, GAN loss = [2.6048262, 0.93260163, 0.9232622]\n",
      "Batch 328/700: Discriminator loss = 1.1128796339035034, GAN loss = [2.7619677, 1.0091674, 1.0038683]\n",
      "Batch 329/700: Discriminator loss = 1.1775280237197876, GAN loss = [2.7110682, 0.99747443, 0.96469545]\n",
      "Batch 330/700: Discriminator loss = 1.164229393005371, GAN loss = [2.8846178, 0.9839006, 1.1518706]\n",
      "Batch 331/700: Discriminator loss = 1.1770455837249756, GAN loss = [2.6224189, 0.9417975, 0.9318305]\n",
      "Batch 332/700: Discriminator loss = 1.1512584686279297, GAN loss = [2.6963308, 0.97510546, 0.9724769]\n",
      "Batch 333/700: Discriminator loss = 1.1215852499008179, GAN loss = [2.8172522, 1.0135895, 1.0549393]\n",
      "Batch 334/700: Discriminator loss = 1.1568175554275513, GAN loss = [2.7056038, 0.9559806, 1.0009307]\n",
      "Batch 335/700: Discriminator loss = 1.1193982362747192, GAN loss = [2.8304982, 1.0067769, 1.0750656]\n",
      "Batch 336/700: Discriminator loss = 1.1592081785202026, GAN loss = [2.7804267, 0.9404545, 1.0913458]\n",
      "Batch 337/700: Discriminator loss = 1.1508474349975586, GAN loss = [2.7814875, 0.9530536, 1.0798373]\n",
      "Batch 338/700: Discriminator loss = 1.1027967929840088, GAN loss = [2.8409657, 1.0170164, 1.0753847]\n",
      "Batch 339/700: Discriminator loss = 1.1440671682357788, GAN loss = [2.8186293, 1.0145664, 1.0555253]\n",
      "Batch 340/700: Discriminator loss = 1.1580970287322998, GAN loss = [2.7978644, 0.96772885, 1.0816361]\n",
      "Batch 341/700: Discriminator loss = 1.1208189725875854, GAN loss = [2.8437963, 1.0283295, 1.0670152]\n",
      "Batch 342/700: Discriminator loss = 1.1831051111221313, GAN loss = [2.7065496, 0.96135736, 0.9967733]\n",
      "Batch 343/700: Discriminator loss = 1.1282539367675781, GAN loss = [2.8312404, 0.98721784, 1.0956397]\n",
      "Batch 344/700: Discriminator loss = 1.1570194959640503, GAN loss = [2.807148, 0.9749901, 1.0838124]\n",
      "Batch 345/700: Discriminator loss = 1.137342929840088, GAN loss = [2.726265, 0.9782372, 0.99971944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 346/700: Discriminator loss = 1.1783103942871094, GAN loss = [2.7207105, 0.95806426, 1.0143733]\n",
      "Batch 347/700: Discriminator loss = 1.1064257621765137, GAN loss = [2.8837535, 1.0251911, 1.1103266]\n",
      "Batch 348/700: Discriminator loss = 1.1814874410629272, GAN loss = [2.760016, 0.97002524, 1.0417935]\n",
      "Batch 349/700: Discriminator loss = 1.1570682525634766, GAN loss = [2.8659208, 0.9926522, 1.125102]\n",
      "Batch 350/700: Discriminator loss = 1.1342506408691406, GAN loss = [2.8158298, 1.0026834, 1.0650104]\n",
      "Batch 351/700: Discriminator loss = 1.1330506801605225, GAN loss = [2.854363, 1.0039456, 1.1023183]\n",
      "Batch 352/700: Discriminator loss = 1.192607045173645, GAN loss = [2.6661031, 0.97193474, 0.9460948]\n",
      "Batch 353/700: Discriminator loss = 1.194527268409729, GAN loss = [2.8291845, 0.9843998, 1.0967427]\n",
      "Batch 354/700: Discriminator loss = 1.1406593322753906, GAN loss = [2.7616506, 0.9908964, 1.0227367]\n",
      "Batch 355/700: Discriminator loss = 1.1469863653182983, GAN loss = [2.7120023, 1.0119823, 0.9520206]\n",
      "Batch 356/700: Discriminator loss = 1.1683752536773682, GAN loss = [2.6742482, 0.95454514, 0.97171533]\n",
      "Batch 357/700: Discriminator loss = 1.1947377920150757, GAN loss = [2.789642, 0.97999907, 1.0616603]\n",
      "Batch 358/700: Discriminator loss = 1.1570390462875366, GAN loss = [2.7833543, 1.0071535, 1.028232]\n",
      "Batch 359/700: Discriminator loss = 1.173302412033081, GAN loss = [2.793615, 0.9701712, 1.0755004]\n",
      "Batch 360/700: Discriminator loss = 1.1520103216171265, GAN loss = [2.771106, 1.0163332, 1.0068443]\n",
      "Batch 361/700: Discriminator loss = 1.1527822017669678, GAN loss = [2.7641592, 0.98673356, 1.0295122]\n",
      "Batch 362/700: Discriminator loss = 1.1084426641464233, GAN loss = [2.7725267, 1.0182774, 1.0063577]\n",
      "Batch 363/700: Discriminator loss = 1.175620198249817, GAN loss = [2.7194204, 0.97222114, 0.99932396]\n",
      "Batch 364/700: Discriminator loss = 1.1117628812789917, GAN loss = [2.8620222, 1.0226643, 1.0914894]\n",
      "Batch 365/700: Discriminator loss = 1.144019365310669, GAN loss = [2.8345854, 0.99787, 1.0888535]\n",
      "Batch 366/700: Discriminator loss = 1.168516993522644, GAN loss = [2.758236, 0.9773088, 1.033066]\n",
      "Batch 367/700: Discriminator loss = 1.172572374343872, GAN loss = [2.6784527, 0.95042396, 0.9801755]\n",
      "Batch 368/700: Discriminator loss = 1.160258173942566, GAN loss = [2.8144538, 0.96233934, 1.104265]\n",
      "Batch 369/700: Discriminator loss = 1.1379600763320923, GAN loss = [2.736396, 0.9868068, 1.0017385]\n",
      "Batch 370/700: Discriminator loss = 1.1794767379760742, GAN loss = [2.7528338, 0.9564362, 1.0485402]\n",
      "Batch 371/700: Discriminator loss = 1.2127102613449097, GAN loss = [2.7099736, 0.9594435, 1.0026846]\n",
      "Batch 372/700: Discriminator loss = 1.178339958190918, GAN loss = [2.6680439, 0.97221065, 0.947994]\n",
      "Batch 373/700: Discriminator loss = 1.1539520025253296, GAN loss = [2.7467089, 0.9889837, 1.0098987]\n",
      "Batch 374/700: Discriminator loss = 1.1456271409988403, GAN loss = [2.8369572, 0.97241515, 1.1167222]\n",
      "Batch 375/700: Discriminator loss = 1.1759830713272095, GAN loss = [2.715533, 0.9391405, 1.0285649]\n",
      "Batch 376/700: Discriminator loss = 1.1595789194107056, GAN loss = [2.8514798, 0.99340814, 1.1102498]\n",
      "Batch 377/700: Discriminator loss = 1.1928794384002686, GAN loss = [2.7751775, 0.9744378, 1.0529394]\n",
      "Batch 378/700: Discriminator loss = 1.178566575050354, GAN loss = [2.7245867, 0.97606766, 1.0007563]\n",
      "Batch 379/700: Discriminator loss = 1.1589570045471191, GAN loss = [2.7805564, 0.9995082, 1.0333096]\n",
      "Batch 380/700: Discriminator loss = 1.1379444599151611, GAN loss = [2.7349598, 0.99902236, 0.98822075]\n",
      "Batch 381/700: Discriminator loss = 1.165841817855835, GAN loss = [2.8410578, 0.97648066, 1.1168786]\n",
      "Batch 382/700: Discriminator loss = 1.1496275663375854, GAN loss = [2.7719378, 1.0019246, 1.0223407]\n",
      "Batch 383/700: Discriminator loss = 1.130501389503479, GAN loss = [2.7915838, 0.9937806, 1.0501555]\n",
      "Batch 384/700: Discriminator loss = 1.1777576208114624, GAN loss = [2.7323601, 0.9793699, 1.0053679]\n",
      "Batch 385/700: Discriminator loss = 1.2126973867416382, GAN loss = [2.6562643, 0.93614244, 0.9725238]\n",
      "Batch 386/700: Discriminator loss = 1.153943657875061, GAN loss = [2.8449297, 0.9765743, 1.120787]\n",
      "Batch 387/700: Discriminator loss = 1.149989128112793, GAN loss = [2.693474, 0.94852114, 0.99739873]\n",
      "Batch 388/700: Discriminator loss = 1.1742678880691528, GAN loss = [2.7789001, 0.949981, 1.0813674]\n",
      "Batch 389/700: Discriminator loss = 1.117475986480713, GAN loss = [2.9238658, 0.99752736, 1.1787926]\n",
      "Batch 390/700: Discriminator loss = 1.130063772201538, GAN loss = [2.8168912, 1.0084434, 1.0609206]\n",
      "Batch 391/700: Discriminator loss = 1.1274104118347168, GAN loss = [2.8040867, 1.0254644, 1.0310997]\n",
      "Batch 392/700: Discriminator loss = 1.2082632780075073, GAN loss = [2.77181, 0.94556665, 1.0787141]\n",
      "Batch 393/700: Discriminator loss = 1.1273378133773804, GAN loss = [2.7675948, 1.0049824, 1.0150892]\n",
      "Batch 394/700: Discriminator loss = 1.1048601865768433, GAN loss = [2.8120909, 1.0199494, 1.044627]\n",
      "Batch 395/700: Discriminator loss = 1.1672043800354004, GAN loss = [2.7882469, 0.98900545, 1.0517428]\n",
      "Batch 396/700: Discriminator loss = 1.1457852125167847, GAN loss = [2.70602, 0.9742792, 0.98426765]\n",
      "Batch 397/700: Discriminator loss = 1.1320698261260986, GAN loss = [2.8068683, 1.0354668, 1.0239521]\n",
      "Batch 398/700: Discriminator loss = 1.1401218175888062, GAN loss = [2.8125725, 1.004991, 1.0601693]\n",
      "Batch 399/700: Discriminator loss = 1.1422425508499146, GAN loss = [2.8325882, 1.0106201, 1.0745878]\n",
      "Batch 400/700: Discriminator loss = 1.1600749492645264, GAN loss = [2.8232555, 0.96802926, 1.1078695]\n",
      "Batch 401/700: Discriminator loss = 1.1504249572753906, GAN loss = [2.7621167, 0.9646535, 1.0501165]\n",
      "Batch 402/700: Discriminator loss = 1.1553102731704712, GAN loss = [2.7556548, 0.98307174, 1.025248]\n",
      "Batch 403/700: Discriminator loss = 1.1401023864746094, GAN loss = [2.8750923, 0.97750115, 1.1502696]\n",
      "Batch 404/700: Discriminator loss = 1.1383002996444702, GAN loss = [2.7233338, 0.9830744, 0.99295545]\n",
      "Batch 405/700: Discriminator loss = 1.1334487199783325, GAN loss = [2.8476722, 0.9874512, 1.1129386]\n",
      "Batch 406/700: Discriminator loss = 1.15794837474823, GAN loss = [2.7209442, 0.9363265, 1.0373545]\n",
      "Batch 407/700: Discriminator loss = 1.1136318445205688, GAN loss = [2.7955256, 1.0268888, 1.0213776]\n",
      "Batch 408/700: Discriminator loss = 1.1823409795761108, GAN loss = [2.7185543, 0.9519, 1.0193944]\n",
      "Batch 409/700: Discriminator loss = 1.1258890628814697, GAN loss = [2.8209267, 1.0090295, 1.0646363]\n",
      "Batch 410/700: Discriminator loss = 1.1773041486740112, GAN loss = [2.7697527, 0.96949434, 1.0530119]\n",
      "Batch 411/700: Discriminator loss = 1.180037260055542, GAN loss = [2.7253916, 0.9760608, 1.0020952]\n",
      "Batch 412/700: Discriminator loss = 1.1819003820419312, GAN loss = [2.754215, 0.94015497, 1.0668354]\n",
      "Batch 413/700: Discriminator loss = 1.2008764743804932, GAN loss = [2.7864473, 0.9515547, 1.0876744]\n",
      "Batch 414/700: Discriminator loss = 1.1163434982299805, GAN loss = [2.8193352, 1.004699, 1.0674357]\n",
      "Batch 415/700: Discriminator loss = 1.1815425157546997, GAN loss = [2.70185, 0.9439472, 1.0107148]\n",
      "Batch 416/700: Discriminator loss = 1.1593490839004517, GAN loss = [2.6001334, 0.960215, 0.89271903]\n",
      "Batch 417/700: Discriminator loss = 1.1658909320831299, GAN loss = [2.69308, 0.9708367, 0.9750402]\n",
      "Batch 418/700: Discriminator loss = 1.1580761671066284, GAN loss = [2.7387834, 0.9845483, 1.0070592]\n",
      "Batch 419/700: Discriminator loss = 1.1664505004882812, GAN loss = [2.7989264, 0.97255677, 1.0792133]\n",
      "Batch 420/700: Discriminator loss = 1.1490516662597656, GAN loss = [2.7382703, 0.9836445, 1.0074778]\n",
      "Batch 421/700: Discriminator loss = 1.1437695026397705, GAN loss = [2.7007563, 0.98054415, 0.9730616]\n",
      "Batch 422/700: Discriminator loss = 1.133892297744751, GAN loss = [2.7966459, 0.9893246, 1.0601708]\n",
      "Batch 423/700: Discriminator loss = 1.1842520236968994, GAN loss = [2.6340742, 0.94535804, 0.9415701]\n",
      "Batch 424/700: Discriminator loss = 1.1536110639572144, GAN loss = [2.7168722, 0.979504, 0.9902231]\n",
      "Batch 425/700: Discriminator loss = 1.153853178024292, GAN loss = [2.7596095, 0.9578512, 1.0546225]\n",
      "Batch 426/700: Discriminator loss = 1.140975832939148, GAN loss = [2.8653288, 0.9852659, 1.1329428]\n",
      "Batch 427/700: Discriminator loss = 1.186108946800232, GAN loss = [2.8165655, 0.9696843, 1.0997589]\n",
      "Batch 428/700: Discriminator loss = 1.1768627166748047, GAN loss = [2.7641222, 1.0127429, 1.0042562]\n",
      "Batch 429/700: Discriminator loss = 1.1444590091705322, GAN loss = [2.7979782, 0.968951, 1.0819122]\n",
      "Batch 430/700: Discriminator loss = 1.16147780418396, GAN loss = [2.646259, 0.9747262, 0.9244197]\n",
      "Batch 431/700: Discriminator loss = 1.1392732858657837, GAN loss = [2.7416308, 0.9907682, 1.0037571]\n",
      "Batch 432/700: Discriminator loss = 1.1179869174957275, GAN loss = [2.8825598, 1.0113215, 1.1241348]\n",
      "Batch 433/700: Discriminator loss = 1.1643636226654053, GAN loss = [2.7298455, 0.96082544, 1.0219283]\n",
      "Batch 434/700: Discriminator loss = 1.1873412132263184, GAN loss = [2.7880466, 0.9312252, 1.1097418]\n",
      "Batch 435/700: Discriminator loss = 1.1224473714828491, GAN loss = [2.8363519, 1.0006518, 1.0886393]\n",
      "Batch 436/700: Discriminator loss = 1.180616021156311, GAN loss = [2.7859826, 0.9503966, 1.0885459]\n",
      "Batch 437/700: Discriminator loss = 1.1463686227798462, GAN loss = [2.8248487, 1.0005543, 1.0772696]\n",
      "Batch 438/700: Discriminator loss = 1.1743004322052002, GAN loss = [2.717973, 0.9829157, 0.9880518]\n",
      "Batch 439/700: Discriminator loss = 1.1258478164672852, GAN loss = [2.759509, 0.98872095, 1.0237839]\n",
      "Batch 440/700: Discriminator loss = 1.1393173933029175, GAN loss = [2.7834134, 0.98131007, 1.0551012]\n",
      "Batch 441/700: Discriminator loss = 1.1108953952789307, GAN loss = [2.8136027, 1.0075893, 1.0590135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 442/700: Discriminator loss = 1.1537097692489624, GAN loss = [2.8082087, 0.94570374, 1.1155056]\n",
      "Batch 443/700: Discriminator loss = 1.1633011102676392, GAN loss = [2.7441576, 0.9476231, 1.049524]\n",
      "Batch 444/700: Discriminator loss = 1.193169355392456, GAN loss = [2.764522, 0.9545948, 1.0629216]\n",
      "Batch 445/700: Discriminator loss = 1.2169928550720215, GAN loss = [2.684166, 0.9190306, 1.0181558]\n",
      "Batch 446/700: Discriminator loss = 1.1741091012954712, GAN loss = [2.7500916, 0.9820736, 1.0210651]\n",
      "Batch 447/700: Discriminator loss = 1.1512084007263184, GAN loss = [2.7254431, 0.9861357, 0.992387]\n",
      "Batch 448/700: Discriminator loss = 1.1531902551651, GAN loss = [2.8755598, 0.9893399, 1.1393154]\n",
      "Batch 449/700: Discriminator loss = 1.1480871438980103, GAN loss = [2.8178418, 0.96626735, 1.1046827]\n",
      "Batch 450/700: Discriminator loss = 1.1960978507995605, GAN loss = [2.7135298, 0.9333184, 1.0333289]\n",
      "Batch 451/700: Discriminator loss = 1.167746663093567, GAN loss = [2.80189, 0.96831816, 1.086684]\n",
      "Batch 452/700: Discriminator loss = 1.1782246828079224, GAN loss = [2.7329986, 0.97105384, 1.0150627]\n",
      "Batch 453/700: Discriminator loss = 1.1699928045272827, GAN loss = [2.7830951, 0.96699584, 1.0692393]\n",
      "Batch 454/700: Discriminator loss = 1.1241364479064941, GAN loss = [2.8576884, 0.9805562, 1.1303064]\n",
      "Batch 455/700: Discriminator loss = 1.1887938976287842, GAN loss = [2.683997, 0.92384726, 1.0133475]\n",
      "Batch 456/700: Discriminator loss = 1.140504002571106, GAN loss = [2.7924783, 0.9808437, 1.0648559]\n",
      "Batch 457/700: Discriminator loss = 1.1842139959335327, GAN loss = [2.7545815, 0.9622971, 1.0455166]\n",
      "Batch 458/700: Discriminator loss = 1.162300705909729, GAN loss = [2.6697397, 0.9322237, 0.9907648]\n",
      "Batch 459/700: Discriminator loss = 1.1717512607574463, GAN loss = [2.7076848, 0.9513004, 1.0096375]\n",
      "Batch 460/700: Discriminator loss = 1.178906798362732, GAN loss = [2.6751156, 0.95004946, 0.97832507]\n",
      "Batch 461/700: Discriminator loss = 1.2153960466384888, GAN loss = [2.78106, 0.94296515, 1.0913739]\n",
      "Batch 462/700: Discriminator loss = 1.2174760103225708, GAN loss = [2.718875, 0.9361803, 1.0359852]\n",
      "Batch 463/700: Discriminator loss = 1.1082675457000732, GAN loss = [2.8285377, 1.0239143, 1.0579355]\n",
      "Batch 464/700: Discriminator loss = 1.1543967723846436, GAN loss = [2.7023773, 0.97706497, 0.9786368]\n",
      "Batch 465/700: Discriminator loss = 1.2239714860916138, GAN loss = [2.6500063, 0.9100783, 0.9932641]\n",
      "Batch 466/700: Discriminator loss = 1.1777516603469849, GAN loss = [2.749913, 0.9731896, 1.0300562]\n",
      "Batch 467/700: Discriminator loss = 1.1569815874099731, GAN loss = [2.80606, 0.9940865, 1.065305]\n",
      "Batch 468/700: Discriminator loss = 1.1425596475601196, GAN loss = [2.8484569, 1.00894, 1.092857]\n",
      "Batch 469/700: Discriminator loss = 1.1417407989501953, GAN loss = [2.8176281, 0.9865252, 1.0844413]\n",
      "Batch 470/700: Discriminator loss = 1.122671127319336, GAN loss = [2.816093, 0.9980089, 1.0714136]\n",
      "Batch 471/700: Discriminator loss = 1.1323304176330566, GAN loss = [2.762719, 1.0131407, 1.0029055]\n",
      "Batch 472/700: Discriminator loss = 1.159016489982605, GAN loss = [2.862428, 0.98740906, 1.1283683]\n",
      "Batch 473/700: Discriminator loss = 1.1333098411560059, GAN loss = [2.769755, 1.0004617, 1.0226573]\n",
      "Batch 474/700: Discriminator loss = 1.1696867942810059, GAN loss = [2.8154423, 0.99666405, 1.0721447]\n",
      "Batch 475/700: Discriminator loss = 1.1342889070510864, GAN loss = [2.814277, 1.0134077, 1.0542495]\n",
      "Batch 476/700: Discriminator loss = 1.1519279479980469, GAN loss = [2.8093529, 1.0097369, 1.0529994]\n",
      "Batch 477/700: Discriminator loss = 1.1258918046951294, GAN loss = [2.7564924, 0.9978212, 1.0120589]\n",
      "Batch 478/700: Discriminator loss = 1.134940505027771, GAN loss = [2.7928503, 0.99999136, 1.0462699]\n",
      "Batch 479/700: Discriminator loss = 1.1386017799377441, GAN loss = [2.80653, 0.97685385, 1.0831065]\n",
      "Batch 480/700: Discriminator loss = 1.1516128778457642, GAN loss = [2.8265314, 0.97500193, 1.104987]\n",
      "Batch 481/700: Discriminator loss = 1.1454830169677734, GAN loss = [2.7785554, 0.9929576, 1.0390679]\n",
      "Batch 482/700: Discriminator loss = 1.1523287296295166, GAN loss = [2.806487, 0.96593475, 1.0940373]\n",
      "Batch 483/700: Discriminator loss = 1.1291654109954834, GAN loss = [2.8333807, 1.0243964, 1.062499]\n",
      "Batch 484/700: Discriminator loss = 1.1296144723892212, GAN loss = [2.846546, 1.0189929, 1.0811055]\n",
      "Batch 485/700: Discriminator loss = 1.1790392398834229, GAN loss = [2.7766085, 0.9537814, 1.0764071]\n",
      "Batch 486/700: Discriminator loss = 1.1726734638214111, GAN loss = [2.805254, 0.9844913, 1.074367]\n",
      "Batch 487/700: Discriminator loss = 1.1529872417449951, GAN loss = [2.83966, 0.97823745, 1.1150419]\n",
      "Batch 488/700: Discriminator loss = 1.1376267671585083, GAN loss = [2.8596332, 1.0031465, 1.1101161]\n",
      "Batch 489/700: Discriminator loss = 1.151129126548767, GAN loss = [2.7914963, 0.97397894, 1.0711399]\n",
      "Batch 490/700: Discriminator loss = 1.1334675550460815, GAN loss = [2.8407977, 0.99858946, 1.0958203]\n",
      "Batch 491/700: Discriminator loss = 1.1459441184997559, GAN loss = [2.8076022, 0.9947429, 1.0664825]\n",
      "Batch 492/700: Discriminator loss = 1.1608866453170776, GAN loss = [2.7639482, 0.97942144, 1.0381709]\n",
      "Batch 493/700: Discriminator loss = 1.1441935300827026, GAN loss = [2.829723, 1.0055882, 1.077791]\n",
      "Batch 494/700: Discriminator loss = 1.1589229106903076, GAN loss = [2.707243, 0.95111847, 1.0098003]\n",
      "Batch 495/700: Discriminator loss = 1.1853176355361938, GAN loss = [2.7207527, 0.97257125, 1.0018706]\n",
      "Batch 496/700: Discriminator loss = 1.1460282802581787, GAN loss = [2.857343, 0.9909885, 1.1200609]\n",
      "Batch 497/700: Discriminator loss = 1.1679258346557617, GAN loss = [2.7672985, 0.97798556, 1.0430413]\n",
      "Batch 498/700: Discriminator loss = 1.169744610786438, GAN loss = [2.7308464, 0.9797372, 1.0048587]\n",
      "Batch 499/700: Discriminator loss = 1.1902135610580444, GAN loss = [2.802789, 0.96563417, 1.0909162]\n",
      "Batch 500/700: Discriminator loss = 1.1548327207565308, GAN loss = [2.7380576, 0.991082, 1.0007613]\n",
      "Batch 501/700: Discriminator loss = 1.1256976127624512, GAN loss = [2.770074, 1.0019369, 1.0219442]\n",
      "Batch 502/700: Discriminator loss = 1.1228162050247192, GAN loss = [2.8706515, 1.0338347, 1.0906327]\n",
      "Batch 503/700: Discriminator loss = 1.1825964450836182, GAN loss = [2.7621086, 0.9727518, 1.0431867]\n",
      "Batch 504/700: Discriminator loss = 1.1322797536849976, GAN loss = [2.786275, 0.99837714, 1.0417498]\n",
      "Batch 505/700: Discriminator loss = 1.1279077529907227, GAN loss = [2.8262858, 1.0060937, 1.074054]\n",
      "Batch 506/700: Discriminator loss = 1.1365970373153687, GAN loss = [2.8865955, 1.0240856, 1.116384]\n",
      "Batch 507/700: Discriminator loss = 1.1395639181137085, GAN loss = [2.8914378, 0.97753936, 1.1677843]\n",
      "Batch 508/700: Discriminator loss = 1.1519044637680054, GAN loss = [2.8153036, 0.99615854, 1.0730331]\n",
      "Batch 509/700: Discriminator loss = 1.1133322715759277, GAN loss = [2.8555057, 1.0147698, 1.0946413]\n",
      "Batch 510/700: Discriminator loss = 1.1408827304840088, GAN loss = [2.8144789, 0.9930765, 1.075331]\n",
      "Batch 511/700: Discriminator loss = 1.1259361505508423, GAN loss = [2.8620036, 1.0249684, 1.0910008]\n",
      "Batch 512/700: Discriminator loss = 1.1665756702423096, GAN loss = [2.891802, 0.9998089, 1.145981]\n",
      "Batch 513/700: Discriminator loss = 1.1299597024917603, GAN loss = [3.0346036, 0.9907418, 1.2978599]\n",
      "Batch 514/700: Discriminator loss = 1.1082675457000732, GAN loss = [2.853019, 1.0074985, 1.0995294]\n",
      "Batch 515/700: Discriminator loss = 1.1413427591323853, GAN loss = [2.8436956, 0.976233, 1.1214974]\n",
      "Batch 516/700: Discriminator loss = 1.0967975854873657, GAN loss = [2.9253235, 1.0350122, 1.1443853]\n",
      "Batch 517/700: Discriminator loss = 1.1565583944320679, GAN loss = [2.782011, 0.97237664, 1.0637304]\n",
      "Batch 518/700: Discriminator loss = 1.1302764415740967, GAN loss = [2.7465894, 0.99522364, 1.0054762]\n",
      "Batch 519/700: Discriminator loss = 1.1290733814239502, GAN loss = [2.9446151, 1.0118864, 1.186873]\n",
      "Batch 520/700: Discriminator loss = 1.1206382513046265, GAN loss = [2.868909, 0.98538285, 1.1377108]\n",
      "Batch 521/700: Discriminator loss = 1.1542056798934937, GAN loss = [2.8473818, 0.9849608, 1.1166255]\n",
      "Batch 522/700: Discriminator loss = 1.12489914894104, GAN loss = [2.795583, 1.0024595, 1.0473515]\n",
      "Batch 523/700: Discriminator loss = 1.133858561515808, GAN loss = [2.7512016, 0.9951016, 1.010358]\n",
      "Batch 524/700: Discriminator loss = 1.127582311630249, GAN loss = [2.8145154, 0.9850218, 1.083772]\n",
      "Batch 525/700: Discriminator loss = 1.1586546897888184, GAN loss = [2.8366668, 1.0179237, 1.0730416]\n",
      "Batch 526/700: Discriminator loss = 1.103093147277832, GAN loss = [2.8576856, 1.0284456, 1.0835649]\n",
      "Batch 527/700: Discriminator loss = 1.160743236541748, GAN loss = [2.8914137, 1.019759, 1.1259903]\n",
      "Batch 528/700: Discriminator loss = 1.2084029912948608, GAN loss = [2.7260315, 0.94045824, 1.0399325]\n",
      "Batch 529/700: Discriminator loss = 1.1086931228637695, GAN loss = [2.8766396, 1.0529269, 1.0780995]\n",
      "Batch 530/700: Discriminator loss = 1.1573227643966675, GAN loss = [2.820049, 0.9861162, 1.0883572]\n",
      "Batch 531/700: Discriminator loss = 1.1279959678649902, GAN loss = [2.9465384, 1.0107578, 1.19023]\n",
      "Batch 532/700: Discriminator loss = 1.1484097242355347, GAN loss = [2.8307548, 1.0119382, 1.0732871]\n",
      "Batch 533/700: Discriminator loss = 1.1478759050369263, GAN loss = [2.8490722, 0.9970341, 1.106534]\n",
      "Batch 534/700: Discriminator loss = 1.137349247932434, GAN loss = [2.789688, 0.9778045, 1.0663977]\n",
      "Batch 535/700: Discriminator loss = 1.1191881895065308, GAN loss = [2.783791, 0.981627, 1.0567071]\n",
      "Batch 536/700: Discriminator loss = 1.1499440670013428, GAN loss = [2.858445, 0.95569426, 1.1573162]\n",
      "Batch 537/700: Discriminator loss = 1.133076786994934, GAN loss = [2.812097, 1.0073216, 1.059353]\n",
      "Batch 538/700: Discriminator loss = 1.1318004131317139, GAN loss = [2.829433, 0.99139285, 1.0926392]\n",
      "Batch 539/700: Discriminator loss = 1.1507670879364014, GAN loss = [2.8171074, 0.98353267, 1.0881901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 540/700: Discriminator loss = 1.127360224723816, GAN loss = [2.9490113, 1.0010991, 1.2025481]\n",
      "Batch 541/700: Discriminator loss = 1.1638543605804443, GAN loss = [2.939717, 1.0154853, 1.1788766]\n",
      "Batch 542/700: Discriminator loss = 1.1689152717590332, GAN loss = [2.8289175, 0.9826542, 1.1009389]\n",
      "Batch 543/700: Discriminator loss = 1.1150727272033691, GAN loss = [2.912823, 1.0470512, 1.1204737]\n",
      "Batch 544/700: Discriminator loss = 1.1571288108825684, GAN loss = [2.9061952, 1.0092711, 1.1516547]\n",
      "Batch 545/700: Discriminator loss = 1.1457090377807617, GAN loss = [2.8124256, 1.0237646, 1.0434122]\n",
      "Batch 546/700: Discriminator loss = 1.1096118688583374, GAN loss = [2.873646, 1.0174297, 1.1110085]\n",
      "Batch 547/700: Discriminator loss = 1.1342096328735352, GAN loss = [2.9414072, 1.0221289, 1.17409]\n",
      "Batch 548/700: Discriminator loss = 1.1866952180862427, GAN loss = [2.7582264, 0.93431383, 1.0787437]\n",
      "Batch 549/700: Discriminator loss = 1.0982208251953125, GAN loss = [2.8875315, 1.0323057, 1.1100893]\n",
      "Batch 550/700: Discriminator loss = 1.1012622117996216, GAN loss = [2.9485135, 1.0425653, 1.1608559]\n",
      "Batch 551/700: Discriminator loss = 1.1218796968460083, GAN loss = [2.9419336, 1.0156279, 1.1812637]\n",
      "Batch 552/700: Discriminator loss = 1.1479191780090332, GAN loss = [2.8570824, 1.0056369, 1.1064384]\n",
      "Batch 553/700: Discriminator loss = 1.1437995433807373, GAN loss = [2.9036996, 1.0171275, 1.1416025]\n",
      "Batch 554/700: Discriminator loss = 1.1032495498657227, GAN loss = [2.9855917, 1.0575613, 1.1830969]\n",
      "Batch 555/700: Discriminator loss = 1.1297056674957275, GAN loss = [2.974812, 1.0365789, 1.1933426]\n",
      "Batch 556/700: Discriminator loss = 1.1125420331954956, GAN loss = [2.902955, 1.0408623, 1.1172404]\n",
      "Batch 557/700: Discriminator loss = 1.1062289476394653, GAN loss = [2.857915, 1.0351975, 1.0779068]\n",
      "Batch 558/700: Discriminator loss = 1.1153357028961182, GAN loss = [2.9794927, 1.066496, 1.1682106]\n",
      "Batch 559/700: Discriminator loss = 1.0978219509124756, GAN loss = [2.9889016, 1.0855198, 1.158621]\n",
      "Batch 560/700: Discriminator loss = 1.1094166040420532, GAN loss = [2.943422, 1.0274482, 1.1712433]\n",
      "Batch 561/700: Discriminator loss = 1.0861999988555908, GAN loss = [2.9873054, 1.0614871, 1.18112]\n",
      "Batch 562/700: Discriminator loss = 1.1005275249481201, GAN loss = [2.872891, 1.0536503, 1.0745713]\n",
      "Batch 563/700: Discriminator loss = 1.1199833154678345, GAN loss = [2.9195323, 1.0144508, 1.1604469]\n",
      "Batch 564/700: Discriminator loss = 1.1103229522705078, GAN loss = [2.936965, 1.0403807, 1.1519655]\n",
      "Batch 565/700: Discriminator loss = 1.0935419797897339, GAN loss = [2.9364498, 1.0673058, 1.1245301]\n",
      "Batch 566/700: Discriminator loss = 1.122922420501709, GAN loss = [2.8979945, 1.0373511, 1.11605]\n",
      "Batch 567/700: Discriminator loss = 1.0992928743362427, GAN loss = [2.906768, 1.0576876, 1.1045073]\n",
      "Batch 568/700: Discriminator loss = 1.1181342601776123, GAN loss = [2.8541129, 1.0377728, 1.0718006]\n",
      "Batch 569/700: Discriminator loss = 1.1568520069122314, GAN loss = [2.8213105, 0.9954026, 1.0814023]\n",
      "Batch 570/700: Discriminator loss = 1.1400576829910278, GAN loss = [2.8289652, 0.96932214, 1.1151673]\n",
      "Batch 571/700: Discriminator loss = 1.151723861694336, GAN loss = [2.8256829, 0.995523, 1.0856843]\n",
      "Batch 572/700: Discriminator loss = 1.1324214935302734, GAN loss = [2.9343295, 1.012692, 1.1771604]\n",
      "Batch 573/700: Discriminator loss = 1.1266615390777588, GAN loss = [2.927689, 1.0080104, 1.1752055]\n",
      "Batch 574/700: Discriminator loss = 1.1173312664031982, GAN loss = [2.9703832, 1.0381684, 1.187747]\n",
      "Batch 575/700: Discriminator loss = 1.130462646484375, GAN loss = [2.8181248, 1.0453296, 1.0283428]\n",
      "Batch 576/700: Discriminator loss = 1.114902138710022, GAN loss = [2.8236425, 1.0204359, 1.0587696]\n",
      "Batch 577/700: Discriminator loss = 1.153059959411621, GAN loss = [2.8901694, 1.0037541, 1.1419883]\n",
      "Batch 578/700: Discriminator loss = 1.0966118574142456, GAN loss = [2.9255373, 1.0482912, 1.1328256]\n",
      "Batch 579/700: Discriminator loss = 1.0969148874282837, GAN loss = [2.9130013, 1.0484781, 1.1201047]\n",
      "Batch 580/700: Discriminator loss = 1.1026747226715088, GAN loss = [2.9135375, 1.0389277, 1.1302034]\n",
      "Batch 581/700: Discriminator loss = 1.1324127912521362, GAN loss = [3.013134, 1.0413455, 1.2274067]\n",
      "Batch 582/700: Discriminator loss = 1.125920295715332, GAN loss = [2.8643465, 1.0316523, 1.0883352]\n",
      "Batch 583/700: Discriminator loss = 1.1114648580551147, GAN loss = [2.9151635, 1.0551497, 1.1156722]\n",
      "Batch 584/700: Discriminator loss = 1.095458984375, GAN loss = [2.8837907, 1.0496266, 1.089832]\n",
      "Batch 585/700: Discriminator loss = 1.1159690618515015, GAN loss = [2.9742181, 1.0576469, 1.1722646]\n",
      "Batch 586/700: Discriminator loss = 1.088818907737732, GAN loss = [3.0343008, 1.0702707, 1.2197343]\n",
      "Batch 587/700: Discriminator loss = 1.1010477542877197, GAN loss = [2.9302573, 1.0231701, 1.1628089]\n",
      "Batch 588/700: Discriminator loss = 1.1429699659347534, GAN loss = [2.8979142, 1.0340523, 1.1196178]\n",
      "Batch 589/700: Discriminator loss = 1.0914188623428345, GAN loss = [2.9180572, 1.0368848, 1.136939]\n",
      "Batch 590/700: Discriminator loss = 1.129020094871521, GAN loss = [2.9276953, 0.9976028, 1.1858647]\n",
      "Batch 591/700: Discriminator loss = 1.125030517578125, GAN loss = [2.9402506, 1.0643369, 1.1316998]\n",
      "Batch 592/700: Discriminator loss = 1.1170778274536133, GAN loss = [2.8062944, 1.0273631, 1.03474]\n",
      "Batch 593/700: Discriminator loss = 1.1231390237808228, GAN loss = [2.916776, 1.0763463, 1.0962521]\n",
      "Batch 594/700: Discriminator loss = 1.1565700769424438, GAN loss = [2.8238626, 1.0023336, 1.0773842]\n",
      "Batch 595/700: Discriminator loss = 1.103816032409668, GAN loss = [2.9097683, 1.0341672, 1.1314781]\n",
      "Batch 596/700: Discriminator loss = 1.1286839246749878, GAN loss = [2.9696946, 1.0248656, 1.2007154]\n",
      "Batch 597/700: Discriminator loss = 1.1417834758758545, GAN loss = [2.9504893, 1.0331405, 1.1732558]\n",
      "Batch 598/700: Discriminator loss = 1.1201131343841553, GAN loss = [2.860117, 1.0181998, 1.097855]\n",
      "Batch 599/700: Discriminator loss = 1.1985852718353271, GAN loss = [2.8933191, 0.9858412, 1.1634485]\n",
      "Batch 600/700: Discriminator loss = 1.1432291269302368, GAN loss = [2.9765885, 1.033676, 1.1989194]\n",
      "Batch 601/700: Discriminator loss = 1.125244140625, GAN loss = [3.0928426, 1.0669122, 1.2819769]\n",
      "Batch 602/700: Discriminator loss = 1.1025888919830322, GAN loss = [2.9510474, 1.0463068, 1.1608291]\n",
      "Batch 603/700: Discriminator loss = 1.1085599660873413, GAN loss = [2.9555962, 1.0503677, 1.1613332]\n",
      "Batch 604/700: Discriminator loss = 1.1617765426635742, GAN loss = [2.9009686, 1.0061549, 1.1509235]\n",
      "Batch 605/700: Discriminator loss = 1.1470717191696167, GAN loss = [3.009683, 1.0784621, 1.1873349]\n",
      "Batch 606/700: Discriminator loss = 1.1092768907546997, GAN loss = [2.8155642, 1.0339961, 1.0377033]\n",
      "Batch 607/700: Discriminator loss = 1.1644190549850464, GAN loss = [2.818974, 1.0065213, 1.06861]\n",
      "Batch 608/700: Discriminator loss = 1.1208583116531372, GAN loss = [2.901805, 1.0524416, 1.1055415]\n",
      "Batch 609/700: Discriminator loss = 1.1472855806350708, GAN loss = [2.8234556, 1.0253857, 1.0542668]\n",
      "Batch 610/700: Discriminator loss = 1.1014772653579712, GAN loss = [2.980165, 1.0703197, 1.1660687]\n",
      "Batch 611/700: Discriminator loss = 1.182818055152893, GAN loss = [2.952285, 1.0054399, 1.2030765]\n",
      "Batch 612/700: Discriminator loss = 1.176372766494751, GAN loss = [2.8833559, 1.0151099, 1.1244887]\n",
      "Batch 613/700: Discriminator loss = 1.1251425743103027, GAN loss = [2.9782507, 1.0451683, 1.1893377]\n",
      "Batch 614/700: Discriminator loss = 1.1844509840011597, GAN loss = [2.768622, 1.0029397, 1.0219501]\n",
      "Batch 615/700: Discriminator loss = 1.1735186576843262, GAN loss = [2.9114547, 1.030966, 1.1367582]\n",
      "Batch 616/700: Discriminator loss = 1.149369239807129, GAN loss = [2.8376386, 1.0160533, 1.0778736]\n",
      "Batch 617/700: Discriminator loss = 1.1418941020965576, GAN loss = [2.882435, 1.0230341, 1.1157053]\n",
      "Batch 618/700: Discriminator loss = 1.157239556312561, GAN loss = [2.7832923, 1.0220336, 1.0175709]\n",
      "Batch 619/700: Discriminator loss = 1.1629780530929565, GAN loss = [2.8977165, 1.0235088, 1.1305245]\n",
      "Batch 620/700: Discriminator loss = 1.1475591659545898, GAN loss = [2.934887, 1.0495262, 1.1416805]\n",
      "Batch 621/700: Discriminator loss = 1.1181459426879883, GAN loss = [3.08754, 1.060817, 1.2830613]\n",
      "Batch 622/700: Discriminator loss = 1.1677958965301514, GAN loss = [2.8168938, 1.0161049, 1.0571499]\n",
      "Batch 623/700: Discriminator loss = 1.151745319366455, GAN loss = [2.9362109, 1.0222242, 1.1703682]\n",
      "Batch 624/700: Discriminator loss = 1.137142539024353, GAN loss = [2.9206643, 1.0126854, 1.1643817]\n",
      "Batch 625/700: Discriminator loss = 1.1309312582015991, GAN loss = [2.9352725, 1.0202491, 1.1714507]\n",
      "Batch 626/700: Discriminator loss = 1.1127172708511353, GAN loss = [3.0632217, 1.0563378, 1.2633314]\n",
      "Batch 627/700: Discriminator loss = 1.130719542503357, GAN loss = [2.962448, 1.0389681, 1.1799446]\n",
      "Batch 628/700: Discriminator loss = 1.1057255268096924, GAN loss = [3.0185852, 1.0333292, 1.2417349]\n",
      "Batch 629/700: Discriminator loss = 1.1404192447662354, GAN loss = [3.1237314, 1.0283793, 1.351855]\n",
      "Batch 630/700: Discriminator loss = 1.1067159175872803, GAN loss = [3.0153646, 1.0673391, 1.2045436]\n",
      "Batch 631/700: Discriminator loss = 1.1111398935317993, GAN loss = [3.0521047, 1.073254, 1.2353835]\n",
      "Batch 632/700: Discriminator loss = 1.0903302431106567, GAN loss = [2.9264076, 1.0698956, 1.1130582]\n",
      "Batch 633/700: Discriminator loss = 1.1713467836380005, GAN loss = [3.0332544, 1.0564358, 1.2333802]\n",
      "Batch 634/700: Discriminator loss = 1.1114894151687622, GAN loss = [2.9383345, 1.0437373, 1.1511647]\n",
      "Batch 635/700: Discriminator loss = 1.1409785747528076, GAN loss = [3.0288174, 1.0361083, 1.2492855]\n",
      "Batch 636/700: Discriminator loss = 1.1594825983047485, GAN loss = [2.9550283, 1.024414, 1.1871924]\n",
      "Batch 637/700: Discriminator loss = 1.1359565258026123, GAN loss = [2.8562737, 1.0305028, 1.0823613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 638/700: Discriminator loss = 1.1340312957763672, GAN loss = [2.8787742, 1.0173583, 1.1180397]\n",
      "Batch 639/700: Discriminator loss = 1.1517550945281982, GAN loss = [3.0321503, 1.0185114, 1.2702976]\n",
      "Batch 640/700: Discriminator loss = 1.1352999210357666, GAN loss = [2.9822848, 1.0396144, 1.1993492]\n",
      "Batch 641/700: Discriminator loss = 1.1294903755187988, GAN loss = [3.1931145, 1.0483422, 1.4014807]\n",
      "Batch 642/700: Discriminator loss = 1.1275957822799683, GAN loss = [2.9736352, 1.0430958, 1.1872838]\n",
      "Batch 643/700: Discriminator loss = 1.0835033655166626, GAN loss = [3.1611407, 1.0623835, 1.3555351]\n",
      "Batch 644/700: Discriminator loss = 1.0977122783660889, GAN loss = [2.9786577, 1.0617236, 1.1737403]\n",
      "Batch 645/700: Discriminator loss = 1.1493287086486816, GAN loss = [2.878637, 1.0035552, 1.1319255]\n",
      "Batch 646/700: Discriminator loss = 1.120847463607788, GAN loss = [3.0091386, 1.0269186, 1.2390852]\n",
      "Batch 647/700: Discriminator loss = 1.0932581424713135, GAN loss = [3.1734953, 1.1026, 1.3277838]\n",
      "Batch 648/700: Discriminator loss = 1.12235689163208, GAN loss = [2.904388, 1.0336287, 1.127686]\n",
      "Batch 649/700: Discriminator loss = 1.102766513824463, GAN loss = [3.0035, 1.0662516, 1.1942115]\n",
      "Batch 650/700: Discriminator loss = 1.1511352062225342, GAN loss = [3.0048575, 1.0308143, 1.2310404]\n",
      "Batch 651/700: Discriminator loss = 1.0912398099899292, GAN loss = [3.0860968, 1.0899568, 1.2531819]\n",
      "Batch 652/700: Discriminator loss = 1.1380847692489624, GAN loss = [2.8812227, 1.0507329, 1.0875834]\n",
      "Batch 653/700: Discriminator loss = 1.116353988647461, GAN loss = [3.0424955, 1.045736, 1.2538873]\n",
      "Batch 654/700: Discriminator loss = 1.1225165128707886, GAN loss = [2.9546266, 1.0268779, 1.1849167]\n",
      "Batch 655/700: Discriminator loss = 1.0700305700302124, GAN loss = [3.1197, 1.1098504, 1.2670708]\n",
      "Batch 656/700: Discriminator loss = 1.1355470418930054, GAN loss = [2.972109, 1.0386186, 1.1907537]\n",
      "Batch 657/700: Discriminator loss = 1.1159589290618896, GAN loss = [2.9909716, 1.0677539, 1.1805099]\n",
      "Batch 658/700: Discriminator loss = 1.0877541303634644, GAN loss = [3.0380294, 1.0662559, 1.2291062]\n",
      "Batch 659/700: Discriminator loss = 1.1237461566925049, GAN loss = [3.0302846, 1.0372754, 1.2503773]\n",
      "Batch 660/700: Discriminator loss = 1.1023961305618286, GAN loss = [3.090119, 1.0620794, 1.2854403]\n",
      "Batch 661/700: Discriminator loss = 1.085355281829834, GAN loss = [3.094904, 1.0755907, 1.276735]\n",
      "Batch 662/700: Discriminator loss = 1.0669444799423218, GAN loss = [3.1179807, 1.1171588, 1.2582691]\n",
      "Batch 663/700: Discriminator loss = 1.1504369974136353, GAN loss = [2.9350154, 1.0351272, 1.1573526]\n",
      "Batch 664/700: Discriminator loss = 1.1301121711730957, GAN loss = [3.1270192, 1.0582157, 1.3262821]\n",
      "Batch 665/700: Discriminator loss = 1.1193768978118896, GAN loss = [3.0694582, 1.1388118, 1.188144]\n",
      "Batch 666/700: Discriminator loss = 1.0729013681411743, GAN loss = [3.0112128, 1.1069348, 1.1618142]\n",
      "Batch 667/700: Discriminator loss = 1.0945807695388794, GAN loss = [3.075532, 1.1269075, 1.2062037]\n",
      "Batch 668/700: Discriminator loss = 1.1228275299072266, GAN loss = [3.0298307, 1.0742227, 1.2132267]\n",
      "Batch 669/700: Discriminator loss = 1.0898561477661133, GAN loss = [3.0707824, 1.0749812, 1.2534611]\n",
      "Batch 670/700: Discriminator loss = 1.1174073219299316, GAN loss = [3.071493, 1.0593811, 1.2697968]\n",
      "Batch 671/700: Discriminator loss = 1.1521435976028442, GAN loss = [2.9499104, 1.038061, 1.1695545]\n",
      "Batch 672/700: Discriminator loss = 1.1475794315338135, GAN loss = [2.9304938, 1.0726748, 1.1155522]\n",
      "Batch 673/700: Discriminator loss = 1.0948586463928223, GAN loss = [2.923582, 1.0844145, 1.0969445]\n",
      "Batch 674/700: Discriminator loss = 1.1617565155029297, GAN loss = [3.1096818, 1.0662123, 1.301294]\n",
      "Batch 675/700: Discriminator loss = 1.093184232711792, GAN loss = [3.1064153, 1.1245642, 1.2397273]\n",
      "Batch 676/700: Discriminator loss = 1.1594886779785156, GAN loss = [2.8655443, 1.0648639, 1.0586091]\n",
      "Batch 677/700: Discriminator loss = 1.1456505060195923, GAN loss = [2.9177659, 1.0314676, 1.1442701]\n",
      "Batch 678/700: Discriminator loss = 1.1816823482513428, GAN loss = [2.8914342, 1.0624238, 1.0870268]\n",
      "Batch 679/700: Discriminator loss = 1.0980716943740845, GAN loss = [2.9793768, 1.1086205, 1.1288216]\n",
      "Batch 680/700: Discriminator loss = 1.1004266738891602, GAN loss = [2.9892626, 1.0788671, 1.1684989]\n",
      "Batch 681/700: Discriminator loss = 1.1025499105453491, GAN loss = [2.940088, 1.0528489, 1.1453886]\n",
      "Batch 682/700: Discriminator loss = 1.2025614976882935, GAN loss = [2.894646, 0.99882096, 1.154005]\n",
      "Batch 683/700: Discriminator loss = 1.1601512432098389, GAN loss = [2.9257271, 1.0322269, 1.1517136]\n",
      "Batch 684/700: Discriminator loss = 1.1998099088668823, GAN loss = [2.873564, 1.0671487, 1.0646564]\n",
      "Batch 685/700: Discriminator loss = 1.1489299535751343, GAN loss = [2.7517047, 1.0169036, 0.99308074]\n",
      "Batch 686/700: Discriminator loss = 1.1960742473602295, GAN loss = [2.744912, 0.9813044, 1.021917]\n",
      "Batch 687/700: Discriminator loss = 1.1567271947860718, GAN loss = [2.881852, 1.0321332, 1.1080569]\n",
      "Batch 688/700: Discriminator loss = 1.1595872640609741, GAN loss = [2.791355, 1.0342981, 1.0154412]\n",
      "Batch 689/700: Discriminator loss = 1.1493310928344727, GAN loss = [2.8527958, 1.05181, 1.059412]\n",
      "Batch 690/700: Discriminator loss = 1.1805342435836792, GAN loss = [2.6793187, 1.0067688, 0.93099886]\n",
      "Batch 691/700: Discriminator loss = 1.177381992340088, GAN loss = [2.7544298, 1.0001715, 1.0127525]\n",
      "Batch 692/700: Discriminator loss = 1.1951605081558228, GAN loss = [2.793732, 0.99687165, 1.0553962]\n",
      "Batch 693/700: Discriminator loss = 1.1813284158706665, GAN loss = [2.6730819, 0.9827521, 0.94889903]\n",
      "Batch 694/700: Discriminator loss = 1.1386698484420776, GAN loss = [2.8299394, 1.0527952, 1.0357499]\n",
      "Batch 695/700: Discriminator loss = 1.1468384265899658, GAN loss = [2.8333101, 1.0524552, 1.039503]\n",
      "Batch 696/700: Discriminator loss = 1.1621865034103394, GAN loss = [2.7937102, 1.0083843, 1.0440049]\n",
      "Batch 697/700: Discriminator loss = 1.1639506816864014, GAN loss = [2.7692485, 1.0031042, 1.0248562]\n",
      "Batch 698/700: Discriminator loss = 1.1208159923553467, GAN loss = [2.8474472, 1.0451, 1.0610976]\n",
      "Batch 699/700: Discriminator loss = 1.141270637512207, GAN loss = [2.8129075, 1.0345348, 1.0371618]\n",
      "Batch 700/700: Discriminator loss = 1.1174713373184204, GAN loss = [2.847985, 1.042346, 1.0644678]\n",
      "Epoch 12/30\n",
      "Batch 1/700: Discriminator loss = 1.1618403196334839, GAN loss = [2.8308935, 1.0189595, 1.070806]\n",
      "Batch 2/700: Discriminator loss = 1.1626964807510376, GAN loss = [2.842203, 1.0284356, 1.0726691]\n",
      "Batch 3/700: Discriminator loss = 1.15078866481781, GAN loss = [2.8333068, 1.0052204, 1.0870177]\n",
      "Batch 4/700: Discriminator loss = 1.1124963760375977, GAN loss = [2.8994272, 1.0332283, 1.1251649]\n",
      "Batch 5/700: Discriminator loss = 1.140813946723938, GAN loss = [2.7890368, 0.99658084, 1.0514514]\n",
      "Batch 6/700: Discriminator loss = 1.241858959197998, GAN loss = [2.7943504, 0.9622459, 1.0911201]\n",
      "Batch 7/700: Discriminator loss = 1.203304409980774, GAN loss = [2.8191648, 1.0349511, 1.0432559]\n",
      "Batch 8/700: Discriminator loss = 1.1350536346435547, GAN loss = [2.9242787, 1.0820156, 1.1013324]\n",
      "Batch 9/700: Discriminator loss = 1.1766960620880127, GAN loss = [2.7409182, 1.0233757, 0.9766386]\n",
      "Batch 10/700: Discriminator loss = 1.1314672231674194, GAN loss = [2.7591314, 1.0138057, 1.0044417]\n",
      "Batch 11/700: Discriminator loss = 1.1505697965621948, GAN loss = [2.8119042, 1.0515318, 1.0195085]\n",
      "Batch 12/700: Discriminator loss = 1.147960901260376, GAN loss = [2.901324, 1.0324193, 1.1280714]\n",
      "Batch 13/700: Discriminator loss = 1.1356675624847412, GAN loss = [2.8267581, 1.0408151, 1.0451283]\n",
      "Batch 14/700: Discriminator loss = 1.1636626720428467, GAN loss = [2.697958, 0.99107796, 0.9660768]\n",
      "Batch 15/700: Discriminator loss = 1.1476718187332153, GAN loss = [2.8540726, 1.0174088, 1.0958736]\n",
      "Batch 16/700: Discriminator loss = 1.1216626167297363, GAN loss = [2.8319702, 1.0492646, 1.0419201]\n",
      "Batch 17/700: Discriminator loss = 1.1063528060913086, GAN loss = [2.9581602, 1.0754339, 1.1419423]\n",
      "Batch 18/700: Discriminator loss = 1.1419501304626465, GAN loss = [2.875594, 1.026473, 1.1083348]\n",
      "Batch 19/700: Discriminator loss = 1.0993019342422485, GAN loss = [2.8637416, 1.0533048, 1.0696499]\n",
      "Batch 20/700: Discriminator loss = 1.1250547170639038, GAN loss = [2.8567896, 1.0445302, 1.0714875]\n",
      "Batch 21/700: Discriminator loss = 1.1125304698944092, GAN loss = [2.7798731, 1.0438293, 0.9952937]\n",
      "Batch 22/700: Discriminator loss = 1.0903652906417847, GAN loss = [2.8196557, 1.0400714, 1.0388732]\n",
      "Batch 23/700: Discriminator loss = 1.1369378566741943, GAN loss = [2.7536447, 0.98075366, 1.032207]\n",
      "Batch 24/700: Discriminator loss = 1.1517181396484375, GAN loss = [2.873432, 1.0202377, 1.1125338]\n",
      "Batch 25/700: Discriminator loss = 1.1393978595733643, GAN loss = [2.8369076, 0.9958447, 1.1004252]\n",
      "Batch 26/700: Discriminator loss = 1.1360445022583008, GAN loss = [2.8116064, 1.0300804, 1.0409076]\n",
      "Batch 27/700: Discriminator loss = 1.1327537298202515, GAN loss = [2.8996623, 1.0211672, 1.137901]\n",
      "Batch 28/700: Discriminator loss = 1.151055932044983, GAN loss = [2.8069155, 1.0127051, 1.0536332]\n",
      "Batch 29/700: Discriminator loss = 1.1724332571029663, GAN loss = [2.8418772, 0.97940063, 1.1219064]\n",
      "Batch 30/700: Discriminator loss = 1.1074270009994507, GAN loss = [2.9445438, 1.03434, 1.1696466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 31/700: Discriminator loss = 1.1333470344543457, GAN loss = [2.9437292, 1.0643792, 1.1388121]\n",
      "Batch 32/700: Discriminator loss = 1.2152962684631348, GAN loss = [2.764789, 0.99977803, 1.0244801]\n",
      "Batch 33/700: Discriminator loss = 1.1443167924880981, GAN loss = [2.8885756, 1.034479, 1.1135724]\n",
      "Batch 34/700: Discriminator loss = 1.1338576078414917, GAN loss = [2.950788, 1.0182756, 1.1920099]\n",
      "Batch 35/700: Discriminator loss = 1.1184227466583252, GAN loss = [2.8705187, 1.0178585, 1.1121813]\n",
      "Batch 36/700: Discriminator loss = 1.1232680082321167, GAN loss = [2.8554852, 0.9989123, 1.1161195]\n",
      "Batch 37/700: Discriminator loss = 1.1068918704986572, GAN loss = [2.7969916, 1.0086718, 1.0478811]\n",
      "Batch 38/700: Discriminator loss = 1.096727728843689, GAN loss = [2.9785838, 1.0367793, 1.2013726]\n",
      "Batch 39/700: Discriminator loss = 1.1132501363754272, GAN loss = [2.8992586, 1.0086321, 1.1502]\n",
      "Batch 40/700: Discriminator loss = 1.1582523584365845, GAN loss = [2.8190954, 0.9890903, 1.0895894]\n",
      "Batch 41/700: Discriminator loss = 1.1782339811325073, GAN loss = [2.8335125, 1.0088972, 1.0842028]\n",
      "Batch 42/700: Discriminator loss = 1.1795955896377563, GAN loss = [2.6838744, 0.98864776, 0.9548227]\n",
      "Batch 43/700: Discriminator loss = 1.1553484201431274, GAN loss = [2.8139937, 0.9814143, 1.0921947]\n",
      "Batch 44/700: Discriminator loss = 1.1728836297988892, GAN loss = [2.7625508, 0.98920244, 1.0329921]\n",
      "Batch 45/700: Discriminator loss = 1.1651970148086548, GAN loss = [2.7166224, 0.9874861, 0.9888222]\n",
      "Batch 46/700: Discriminator loss = 1.1553694009780884, GAN loss = [2.75658, 0.9890079, 1.0272818]\n",
      "Batch 47/700: Discriminator loss = 1.1256452798843384, GAN loss = [2.8922129, 1.0167956, 1.1351466]\n",
      "Batch 48/700: Discriminator loss = 1.1332036256790161, GAN loss = [2.8346684, 1.0124519, 1.0819616]\n",
      "Batch 49/700: Discriminator loss = 1.095609426498413, GAN loss = [2.8937795, 1.0361066, 1.1174293]\n",
      "Batch 50/700: Discriminator loss = 1.1465643644332886, GAN loss = [2.8197868, 0.99090856, 1.088636]\n",
      "Batch 51/700: Discriminator loss = 1.1708736419677734, GAN loss = [2.8641448, 1.0035595, 1.1203554]\n",
      "Batch 52/700: Discriminator loss = 1.1202820539474487, GAN loss = [2.8036504, 1.0260714, 1.037369]\n",
      "Batch 53/700: Discriminator loss = 1.1376749277114868, GAN loss = [2.7499769, 1.0285678, 0.98122525]\n",
      "Batch 54/700: Discriminator loss = 1.1492044925689697, GAN loss = [2.8505511, 1.0150206, 1.0953673]\n",
      "Batch 55/700: Discriminator loss = 1.105924367904663, GAN loss = [2.8853474, 1.032202, 1.112993]\n",
      "Batch 56/700: Discriminator loss = 1.1493573188781738, GAN loss = [2.8784657, 1.0129498, 1.1253899]\n",
      "Batch 57/700: Discriminator loss = 1.1433054208755493, GAN loss = [2.844066, 1.0244564, 1.0795095]\n",
      "Batch 58/700: Discriminator loss = 1.133784294128418, GAN loss = [2.9181519, 1.0489748, 1.1290946]\n",
      "Batch 59/700: Discriminator loss = 1.103263258934021, GAN loss = [2.8499765, 1.059409, 1.0505086]\n",
      "Batch 60/700: Discriminator loss = 1.136662483215332, GAN loss = [2.9674294, 1.0503336, 1.1770489]\n",
      "Batch 61/700: Discriminator loss = 1.1265455484390259, GAN loss = [2.9001307, 1.0543921, 1.1057]\n",
      "Batch 62/700: Discriminator loss = 1.117418885231018, GAN loss = [2.9685295, 1.0859113, 1.1425885]\n",
      "Batch 63/700: Discriminator loss = 1.1169077157974243, GAN loss = [2.8517225, 1.0550308, 1.0566776]\n",
      "Batch 64/700: Discriminator loss = 1.1127198934555054, GAN loss = [2.9084783, 1.0487486, 1.1197301]\n",
      "Batch 65/700: Discriminator loss = 1.121880054473877, GAN loss = [2.8548517, 1.0565971, 1.0582614]\n",
      "Batch 66/700: Discriminator loss = 1.1138420104980469, GAN loss = [2.8328998, 1.0550203, 1.0379101]\n",
      "Batch 67/700: Discriminator loss = 1.1252212524414062, GAN loss = [2.8864074, 1.0081298, 1.1383474]\n",
      "Batch 68/700: Discriminator loss = 1.101007342338562, GAN loss = [2.9548218, 1.0482386, 1.1666814]\n",
      "Batch 69/700: Discriminator loss = 1.144229531288147, GAN loss = [2.9019458, 1.0411108, 1.1209542]\n",
      "Batch 70/700: Discriminator loss = 1.1676708459854126, GAN loss = [2.782001, 1.0140036, 1.0281211]\n",
      "Batch 71/700: Discriminator loss = 1.1312617063522339, GAN loss = [2.840523, 1.0484815, 1.0521637]\n",
      "Batch 72/700: Discriminator loss = 1.1831756830215454, GAN loss = [2.7413776, 0.9756318, 1.0258727]\n",
      "Batch 73/700: Discriminator loss = 1.1737306118011475, GAN loss = [2.7666504, 1.0260752, 1.0007324]\n",
      "Batch 74/700: Discriminator loss = 1.1298037767410278, GAN loss = [2.924999, 1.0381566, 1.1470258]\n",
      "Batch 75/700: Discriminator loss = 1.147868275642395, GAN loss = [2.9203734, 1.056293, 1.1242841]\n",
      "Batch 76/700: Discriminator loss = 1.161013126373291, GAN loss = [2.8699887, 1.0325499, 1.0976607]\n",
      "Batch 77/700: Discriminator loss = 1.1506428718566895, GAN loss = [2.779623, 1.0614339, 0.9784319]\n",
      "Batch 78/700: Discriminator loss = 1.1405798196792603, GAN loss = [2.8369367, 1.0244945, 1.0726901]\n",
      "Batch 79/700: Discriminator loss = 1.0595327615737915, GAN loss = [2.9635494, 1.0579093, 1.1659037]\n",
      "Batch 80/700: Discriminator loss = 1.0999987125396729, GAN loss = [2.88937, 1.0553501, 1.0942947]\n",
      "Batch 81/700: Discriminator loss = 1.111396312713623, GAN loss = [2.9571426, 1.0438074, 1.1736143]\n",
      "Batch 82/700: Discriminator loss = 1.1643338203430176, GAN loss = [2.8350918, 1.0500795, 1.0452975]\n",
      "Batch 83/700: Discriminator loss = 1.1337165832519531, GAN loss = [2.8947787, 1.0070041, 1.1480935]\n",
      "Batch 84/700: Discriminator loss = 1.1266252994537354, GAN loss = [2.8334718, 1.0101364, 1.0836986]\n",
      "Batch 85/700: Discriminator loss = 1.1590068340301514, GAN loss = [2.8227658, 1.0131822, 1.0700011]\n",
      "Batch 86/700: Discriminator loss = 1.0973682403564453, GAN loss = [2.9335256, 1.0575306, 1.1364565]\n",
      "Batch 87/700: Discriminator loss = 1.113669991493225, GAN loss = [2.8991919, 1.0499521, 1.1097419]\n",
      "Batch 88/700: Discriminator loss = 1.0996183156967163, GAN loss = [3.0226905, 1.0795051, 1.2037237]\n",
      "Batch 89/700: Discriminator loss = 1.1335623264312744, GAN loss = [2.8985403, 1.0389438, 1.1201785]\n",
      "Batch 90/700: Discriminator loss = 1.0728962421417236, GAN loss = [2.9758427, 1.0968698, 1.13959]\n",
      "Batch 91/700: Discriminator loss = 1.0912964344024658, GAN loss = [2.9355016, 1.0639317, 1.1322083]\n",
      "Batch 92/700: Discriminator loss = 1.0961120128631592, GAN loss = [2.937201, 1.0565153, 1.1413335]\n",
      "Batch 93/700: Discriminator loss = 1.1176406145095825, GAN loss = [2.9780443, 1.0566684, 1.1820366]\n",
      "Batch 94/700: Discriminator loss = 1.1497217416763306, GAN loss = [2.889499, 1.0248265, 1.125355]\n",
      "Batch 95/700: Discriminator loss = 1.1202720403671265, GAN loss = [3.0011685, 1.0371261, 1.2247525]\n",
      "Batch 96/700: Discriminator loss = 1.0913889408111572, GAN loss = [2.9831662, 1.0418692, 1.2020198]\n",
      "Batch 97/700: Discriminator loss = 1.1018611192703247, GAN loss = [3.0385685, 1.0379375, 1.2613724]\n",
      "Batch 98/700: Discriminator loss = 1.1229004859924316, GAN loss = [3.0240977, 1.0600449, 1.2248089]\n",
      "Batch 99/700: Discriminator loss = 1.1181570291519165, GAN loss = [2.9244447, 1.0724282, 1.1127896]\n",
      "Batch 100/700: Discriminator loss = 1.1065531969070435, GAN loss = [2.9871576, 1.0349499, 1.2129952]\n",
      "Batch 101/700: Discriminator loss = 1.1062204837799072, GAN loss = [2.9295576, 1.0491722, 1.1412001]\n",
      "Batch 102/700: Discriminator loss = 1.1548352241516113, GAN loss = [2.8497226, 1.0333409, 1.0772346]\n",
      "Batch 103/700: Discriminator loss = 1.0792156457901, GAN loss = [2.9558642, 1.0998853, 1.1168636]\n",
      "Batch 104/700: Discriminator loss = 1.1416707038879395, GAN loss = [2.8790755, 1.0282924, 1.1116842]\n",
      "Batch 105/700: Discriminator loss = 1.1198556423187256, GAN loss = [2.962948, 1.0627614, 1.1611048]\n",
      "Batch 106/700: Discriminator loss = 1.0914522409439087, GAN loss = [3.056149, 1.0540677, 1.2630163]\n",
      "Batch 107/700: Discriminator loss = 1.066871166229248, GAN loss = [3.027175, 1.1004373, 1.1876901]\n",
      "Batch 108/700: Discriminator loss = 1.0844511985778809, GAN loss = [3.0255952, 1.1009479, 1.1856143]\n",
      "Batch 109/700: Discriminator loss = 1.0939598083496094, GAN loss = [2.9063213, 1.0627617, 1.1045517]\n",
      "Batch 110/700: Discriminator loss = 1.0879876613616943, GAN loss = [2.9917452, 1.0791491, 1.1736252]\n",
      "Batch 111/700: Discriminator loss = 1.1078823804855347, GAN loss = [2.7903547, 1.0346555, 1.016747]\n",
      "Batch 112/700: Discriminator loss = 1.1330018043518066, GAN loss = [2.8928506, 1.0317314, 1.122182]\n",
      "Batch 113/700: Discriminator loss = 1.0938799381256104, GAN loss = [3.083982, 1.0720782, 1.2729796]\n",
      "Batch 114/700: Discriminator loss = 1.1059331893920898, GAN loss = [3.0240214, 1.0542741, 1.2308371]\n",
      "Batch 115/700: Discriminator loss = 1.1815259456634521, GAN loss = [2.969375, 1.0687305, 1.1617488]\n",
      "Batch 116/700: Discriminator loss = 1.109861135482788, GAN loss = [2.9882727, 1.0818242, 1.1675708]\n",
      "Batch 117/700: Discriminator loss = 1.0937262773513794, GAN loss = [3.1097572, 1.0922265, 1.2786686]\n",
      "Batch 118/700: Discriminator loss = 1.1102370023727417, GAN loss = [2.9602516, 1.0346823, 1.1867206]\n",
      "Batch 119/700: Discriminator loss = 1.1293082237243652, GAN loss = [2.869636, 1.0133457, 1.1174521]\n",
      "Batch 120/700: Discriminator loss = 1.1020034551620483, GAN loss = [3.2347653, 1.0798824, 1.4160485]\n",
      "Batch 121/700: Discriminator loss = 1.1359525918960571, GAN loss = [2.9460113, 1.0323316, 1.1748438]\n",
      "Batch 122/700: Discriminator loss = 1.1409043073654175, GAN loss = [3.096666, 1.0131985, 1.3446524]\n",
      "Batch 123/700: Discriminator loss = 1.0862016677856445, GAN loss = [3.0254989, 1.0675031, 1.2191981]\n",
      "Batch 124/700: Discriminator loss = 1.121485710144043, GAN loss = [2.9568033, 1.0061029, 1.2119093]\n",
      "Batch 125/700: Discriminator loss = 1.1284605264663696, GAN loss = [3.139795, 1.0326505, 1.3683652]\n",
      "Batch 126/700: Discriminator loss = 1.112565279006958, GAN loss = [3.0006042, 1.0764619, 1.1853689]\n",
      "Batch 127/700: Discriminator loss = 1.1151961088180542, GAN loss = [3.155565, 1.0368937, 1.3799064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 128/700: Discriminator loss = 1.077634572982788, GAN loss = [3.1456625, 1.059506, 1.3473985]\n",
      "Batch 129/700: Discriminator loss = 1.1541861295700073, GAN loss = [2.8803396, 1.0252703, 1.1163168]\n",
      "Batch 130/700: Discriminator loss = 1.157134771347046, GAN loss = [2.983302, 0.99798155, 1.2465862]\n",
      "Batch 131/700: Discriminator loss = 1.1523889303207397, GAN loss = [2.914047, 1.0181825, 1.1571362]\n",
      "Batch 132/700: Discriminator loss = 1.1103758811950684, GAN loss = [3.0719366, 1.0221543, 1.3110527]\n",
      "Batch 133/700: Discriminator loss = 1.1196173429489136, GAN loss = [3.1536186, 1.0517732, 1.3631166]\n",
      "Batch 134/700: Discriminator loss = 1.1715593338012695, GAN loss = [2.8678913, 0.9938148, 1.1353456]\n",
      "Batch 135/700: Discriminator loss = 1.1447606086730957, GAN loss = [2.8223422, 1.0118883, 1.0717261]\n",
      "Batch 136/700: Discriminator loss = 1.1424691677093506, GAN loss = [2.9095223, 0.9868004, 1.1840179]\n",
      "Batch 137/700: Discriminator loss = 1.1076545715332031, GAN loss = [3.0841172, 1.0664685, 1.2789644]\n",
      "Batch 138/700: Discriminator loss = 1.1234122514724731, GAN loss = [3.0047097, 1.0323613, 1.23368]\n",
      "Batch 139/700: Discriminator loss = 1.1557387113571167, GAN loss = [3.0745888, 1.0267112, 1.3092197]\n",
      "Batch 140/700: Discriminator loss = 1.1374917030334473, GAN loss = [2.8876886, 1.0223645, 1.1266692]\n",
      "Batch 141/700: Discriminator loss = 1.150243878364563, GAN loss = [3.0886402, 1.0159955, 1.3339833]\n",
      "Batch 142/700: Discriminator loss = 1.1642965078353882, GAN loss = [3.0088952, 1.0483906, 1.2218348]\n",
      "Batch 143/700: Discriminator loss = 1.129158854484558, GAN loss = [2.9217086, 1.0465006, 1.136546]\n",
      "Batch 144/700: Discriminator loss = 1.1529127359390259, GAN loss = [2.839803, 1.0357147, 1.0654365]\n",
      "Batch 145/700: Discriminator loss = 1.1375536918640137, GAN loss = [3.0291548, 1.0707262, 1.2197945]\n",
      "Batch 146/700: Discriminator loss = 1.1436108350753784, GAN loss = [2.929204, 1.0415736, 1.1490102]\n",
      "Batch 147/700: Discriminator loss = 1.151429533958435, GAN loss = [2.9516764, 1.0444627, 1.168624]\n",
      "Batch 148/700: Discriminator loss = 1.0855821371078491, GAN loss = [3.1193788, 1.1002904, 1.2805156]\n",
      "Batch 149/700: Discriminator loss = 1.1267558336257935, GAN loss = [2.8145812, 1.0430695, 1.0329531]\n",
      "Batch 150/700: Discriminator loss = 1.1554850339889526, GAN loss = [2.9123714, 1.041991, 1.1318208]\n",
      "Batch 151/700: Discriminator loss = 1.1307991743087769, GAN loss = [2.9924736, 1.0398437, 1.2140965]\n",
      "Batch 152/700: Discriminator loss = 1.2042019367218018, GAN loss = [2.8244348, 0.97779787, 1.1081247]\n",
      "Batch 153/700: Discriminator loss = 1.1172829866409302, GAN loss = [3.0297306, 1.0612322, 1.2300107]\n",
      "Batch 154/700: Discriminator loss = 1.1162922382354736, GAN loss = [3.0122552, 1.0426162, 1.2311814]\n",
      "Batch 155/700: Discriminator loss = 1.1117645502090454, GAN loss = [2.9820402, 1.0404431, 1.2031722]\n",
      "Batch 156/700: Discriminator loss = 1.1366304159164429, GAN loss = [3.0184252, 1.0742502, 1.2057716]\n",
      "Batch 157/700: Discriminator loss = 1.1242947578430176, GAN loss = [2.9723258, 1.0540553, 1.1798859]\n",
      "Batch 158/700: Discriminator loss = 1.1522539854049683, GAN loss = [2.8880935, 1.0034099, 1.1463385]\n",
      "Batch 159/700: Discriminator loss = 1.1208237409591675, GAN loss = [2.9308856, 1.0649195, 1.1276554]\n",
      "Batch 160/700: Discriminator loss = 1.1386497020721436, GAN loss = [2.8400428, 1.0207925, 1.0809677]\n",
      "Batch 161/700: Discriminator loss = 1.1620097160339355, GAN loss = [2.91319, 0.9720114, 1.2029284]\n",
      "Batch 162/700: Discriminator loss = 1.1671522855758667, GAN loss = [2.8396208, 0.9993971, 1.1019938]\n",
      "Batch 163/700: Discriminator loss = 1.1531060934066772, GAN loss = [2.8791327, 0.9866059, 1.1543177]\n",
      "Batch 164/700: Discriminator loss = 1.2152924537658691, GAN loss = [2.8780913, 0.9559994, 1.1838902]\n",
      "Batch 165/700: Discriminator loss = 1.1666438579559326, GAN loss = [2.8804607, 1.0007666, 1.141509]\n",
      "Batch 166/700: Discriminator loss = 1.1350053548812866, GAN loss = [2.8121388, 1.0189553, 1.0550114]\n",
      "Batch 167/700: Discriminator loss = 1.1181563138961792, GAN loss = [2.926013, 1.0438342, 1.144017]\n",
      "Batch 168/700: Discriminator loss = 1.1295032501220703, GAN loss = [2.9497707, 1.0333914, 1.1782212]\n",
      "Batch 169/700: Discriminator loss = 1.1789275407791138, GAN loss = [2.771836, 0.9899734, 1.0437137]\n",
      "Batch 170/700: Discriminator loss = 1.1383694410324097, GAN loss = [2.909816, 1.0252672, 1.1463971]\n",
      "Batch 171/700: Discriminator loss = 1.1527734994888306, GAN loss = [2.8830016, 1.0277734, 1.1170609]\n",
      "Batch 172/700: Discriminator loss = 1.118503212928772, GAN loss = [2.9655879, 1.0464566, 1.1809778]\n",
      "Batch 173/700: Discriminator loss = 1.1625919342041016, GAN loss = [2.8223617, 1.0205524, 1.0636706]\n",
      "Batch 174/700: Discriminator loss = 1.156426191329956, GAN loss = [2.7795396, 0.97960097, 1.0618167]\n",
      "Batch 175/700: Discriminator loss = 1.100859522819519, GAN loss = [2.9480202, 1.0557246, 1.154197]\n",
      "Batch 176/700: Discriminator loss = 1.1095280647277832, GAN loss = [3.0013463, 1.0518432, 1.2114267]\n",
      "Batch 177/700: Discriminator loss = 1.1632014513015747, GAN loss = [2.9238698, 0.99864054, 1.1871666]\n",
      "Batch 178/700: Discriminator loss = 1.1211888790130615, GAN loss = [2.9797826, 1.0307947, 1.2109425]\n",
      "Batch 179/700: Discriminator loss = 1.1120251417160034, GAN loss = [2.8065703, 1.020116, 1.0484147]\n",
      "Batch 180/700: Discriminator loss = 1.1818063259124756, GAN loss = [2.8940349, 0.9821521, 1.1738648]\n",
      "Batch 181/700: Discriminator loss = 1.1211504936218262, GAN loss = [2.9130957, 1.0302645, 1.1448412]\n",
      "Batch 182/700: Discriminator loss = 1.1393940448760986, GAN loss = [2.8102677, 1.0130067, 1.0593046]\n",
      "Batch 183/700: Discriminator loss = 1.1254302263259888, GAN loss = [2.9320476, 1.0576421, 1.1364745]\n",
      "Batch 184/700: Discriminator loss = 1.1436221599578857, GAN loss = [2.9881399, 1.0257788, 1.2244717]\n",
      "Batch 185/700: Discriminator loss = 1.1551530361175537, GAN loss = [2.8655987, 1.0205271, 1.1072073]\n",
      "Batch 186/700: Discriminator loss = 1.1213929653167725, GAN loss = [2.9511316, 1.027881, 1.1854084]\n",
      "Batch 187/700: Discriminator loss = 1.188457727432251, GAN loss = [2.7893264, 0.9545795, 1.0969263]\n",
      "Batch 188/700: Discriminator loss = 1.1146702766418457, GAN loss = [3.0217123, 1.0764344, 1.2074715]\n",
      "Batch 189/700: Discriminator loss = 1.1094720363616943, GAN loss = [2.8998563, 1.0607852, 1.1012748]\n",
      "Batch 190/700: Discriminator loss = 1.166810393333435, GAN loss = [2.9018648, 0.9991386, 1.1649269]\n",
      "Batch 191/700: Discriminator loss = 1.143533706665039, GAN loss = [2.8180156, 1.0094256, 1.0707933]\n",
      "Batch 192/700: Discriminator loss = 1.1115506887435913, GAN loss = [2.8814137, 1.0147847, 1.1288311]\n",
      "Batch 193/700: Discriminator loss = 1.1188174486160278, GAN loss = [2.8497314, 1.0188417, 1.093103]\n",
      "Batch 194/700: Discriminator loss = 1.1637576818466187, GAN loss = [2.8696315, 0.9806484, 1.1512232]\n",
      "Batch 195/700: Discriminator loss = 1.2015759944915771, GAN loss = [2.7239747, 0.93752295, 1.0487057]\n",
      "Batch 196/700: Discriminator loss = 1.1282899379730225, GAN loss = [2.9156911, 1.0281373, 1.1498034]\n",
      "Batch 197/700: Discriminator loss = 1.1623769998550415, GAN loss = [2.7994242, 0.9690354, 1.0926311]\n",
      "Batch 198/700: Discriminator loss = 1.1670262813568115, GAN loss = [2.920296, 1.0211991, 1.1613382]\n",
      "Batch 199/700: Discriminator loss = 1.1427403688430786, GAN loss = [2.83503, 1.0026271, 1.0946703]\n",
      "Batch 200/700: Discriminator loss = 1.1700372695922852, GAN loss = [2.764818, 0.96875924, 1.0583622]\n",
      "Batch 201/700: Discriminator loss = 1.1125327348709106, GAN loss = [2.9453576, 1.0453264, 1.1623589]\n",
      "Batch 202/700: Discriminator loss = 1.1454583406448364, GAN loss = [2.9208834, 0.99689615, 1.186318]\n",
      "Batch 203/700: Discriminator loss = 1.1807236671447754, GAN loss = [2.7921536, 0.9789822, 1.0755265]\n",
      "Batch 204/700: Discriminator loss = 1.1468794345855713, GAN loss = [2.8389008, 0.9870592, 1.1142179]\n",
      "Batch 205/700: Discriminator loss = 1.1555674076080322, GAN loss = [2.7731113, 0.98450965, 1.051003]\n",
      "Batch 206/700: Discriminator loss = 1.1589608192443848, GAN loss = [2.7305381, 0.9895084, 1.0034463]\n",
      "Batch 207/700: Discriminator loss = 1.1801421642303467, GAN loss = [2.804238, 0.9951815, 1.0714688]\n",
      "Batch 208/700: Discriminator loss = 1.1848331689834595, GAN loss = [2.845363, 0.98839587, 1.1193895]\n",
      "Batch 209/700: Discriminator loss = 1.1551276445388794, GAN loss = [2.9354312, 1.0211352, 1.1767428]\n",
      "Batch 210/700: Discriminator loss = 1.1726924180984497, GAN loss = [2.7415812, 0.9879173, 1.0161073]\n",
      "Batch 211/700: Discriminator loss = 1.1268647909164429, GAN loss = [2.8394701, 1.0132961, 1.0886283]\n",
      "Batch 212/700: Discriminator loss = 1.1803045272827148, GAN loss = [2.8140066, 0.9700893, 1.1064026]\n",
      "Batch 213/700: Discriminator loss = 1.1518183946609497, GAN loss = [2.8234637, 1.0095904, 1.0763801]\n",
      "Batch 214/700: Discriminator loss = 1.13644540309906, GAN loss = [2.7785373, 0.9970266, 1.0440298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 215/700: Discriminator loss = 1.1643507480621338, GAN loss = [2.8524601, 0.9698287, 1.145154]\n",
      "Batch 216/700: Discriminator loss = 1.1308702230453491, GAN loss = [2.8808644, 1.0188624, 1.1245337]\n",
      "Batch 217/700: Discriminator loss = 1.1339895725250244, GAN loss = [2.7779825, 0.9746759, 1.0658402]\n",
      "Batch 218/700: Discriminator loss = 1.196848750114441, GAN loss = [2.869522, 0.9825971, 1.1494598]\n",
      "Batch 219/700: Discriminator loss = 1.1708922386169434, GAN loss = [2.7809148, 0.9793151, 1.0641539]\n",
      "Batch 220/700: Discriminator loss = 1.1051952838897705, GAN loss = [2.95082, 1.0159376, 1.1974607]\n",
      "Batch 221/700: Discriminator loss = 1.1830919981002808, GAN loss = [2.8853414, 0.993085, 1.1548507]\n",
      "Batch 222/700: Discriminator loss = 1.107407808303833, GAN loss = [2.9178154, 1.0246159, 1.1558076]\n",
      "Batch 223/700: Discriminator loss = 1.0961331129074097, GAN loss = [2.9289107, 1.053328, 1.1382123]\n",
      "Batch 224/700: Discriminator loss = 1.1335991621017456, GAN loss = [2.8450541, 1.0063819, 1.1012987]\n",
      "Batch 225/700: Discriminator loss = 1.1234736442565918, GAN loss = [2.9540174, 1.0332286, 1.1834332]\n",
      "Batch 226/700: Discriminator loss = 1.1369080543518066, GAN loss = [2.9016938, 0.99461067, 1.1697494]\n",
      "Batch 227/700: Discriminator loss = 1.121171474456787, GAN loss = [2.8662734, 1.0189635, 1.1099898]\n",
      "Batch 228/700: Discriminator loss = 1.0934730768203735, GAN loss = [3.0869026, 1.0362153, 1.3133807]\n",
      "Batch 229/700: Discriminator loss = 1.1669471263885498, GAN loss = [2.8658078, 0.9766256, 1.1518979]\n",
      "Batch 230/700: Discriminator loss = 1.113182544708252, GAN loss = [2.9375682, 1.0249262, 1.1753756]\n",
      "Batch 231/700: Discriminator loss = 1.1426409482955933, GAN loss = [2.933641, 1.0126363, 1.1837775]\n",
      "Batch 232/700: Discriminator loss = 1.1909211874008179, GAN loss = [2.8845081, 1.0179678, 1.1293595]\n",
      "Batch 233/700: Discriminator loss = 1.109220027923584, GAN loss = [3.0281067, 1.0635632, 1.2273945]\n",
      "Batch 234/700: Discriminator loss = 1.0915428400039673, GAN loss = [2.9564269, 1.0730112, 1.146297]\n",
      "Batch 235/700: Discriminator loss = 1.1215438842773438, GAN loss = [2.8604088, 1.0222287, 1.1010841]\n",
      "Batch 236/700: Discriminator loss = 1.1500061750411987, GAN loss = [2.8933895, 1.0351259, 1.1211863]\n",
      "Batch 237/700: Discriminator loss = 1.1075968742370605, GAN loss = [2.8750298, 1.0500207, 1.0879532]\n",
      "Batch 238/700: Discriminator loss = 1.163476586341858, GAN loss = [2.796405, 1.0105677, 1.0488015]\n",
      "Batch 239/700: Discriminator loss = 1.0984156131744385, GAN loss = [2.919406, 1.0703965, 1.1119977]\n",
      "Batch 240/700: Discriminator loss = 1.131270170211792, GAN loss = [2.877937, 1.0137266, 1.127227]\n",
      "Batch 241/700: Discriminator loss = 1.1110936403274536, GAN loss = [2.9045634, 1.0657175, 1.1018826]\n",
      "Batch 242/700: Discriminator loss = 1.1135395765304565, GAN loss = [2.9844582, 1.0288804, 1.2186325]\n",
      "Batch 243/700: Discriminator loss = 1.128138542175293, GAN loss = [2.8492312, 1.0233144, 1.0890008]\n",
      "Batch 244/700: Discriminator loss = 1.1363612413406372, GAN loss = [2.8187497, 1.0421716, 1.0396847]\n",
      "Batch 245/700: Discriminator loss = 1.101358413696289, GAN loss = [2.8975365, 1.0683861, 1.0922679]\n",
      "Batch 246/700: Discriminator loss = 1.0852761268615723, GAN loss = [2.989031, 1.0986638, 1.1535163]\n",
      "Batch 247/700: Discriminator loss = 1.1231870651245117, GAN loss = [2.830369, 1.0211089, 1.0724355]\n",
      "Batch 248/700: Discriminator loss = 1.1488621234893799, GAN loss = [2.9076545, 1.0036645, 1.1671897]\n",
      "Batch 249/700: Discriminator loss = 1.162985920906067, GAN loss = [2.8776412, 1.0198376, 1.1210309]\n",
      "Batch 250/700: Discriminator loss = 1.1230140924453735, GAN loss = [2.893444, 1.0279795, 1.1287124]\n",
      "Batch 251/700: Discriminator loss = 1.1236958503723145, GAN loss = [2.8357134, 1.0133736, 1.08561]\n",
      "Batch 252/700: Discriminator loss = 1.1412220001220703, GAN loss = [2.9374073, 1.0188526, 1.1818432]\n",
      "Batch 253/700: Discriminator loss = 1.1640706062316895, GAN loss = [2.7991395, 1.004419, 1.0580248]\n",
      "Batch 254/700: Discriminator loss = 1.137895107269287, GAN loss = [2.9396958, 1.0492722, 1.1537448]\n",
      "Batch 255/700: Discriminator loss = 1.1573841571807861, GAN loss = [3.0390575, 1.0542568, 1.2481394]\n",
      "Batch 256/700: Discriminator loss = 1.1008949279785156, GAN loss = [2.9455237, 1.0671682, 1.1417191]\n",
      "Batch 257/700: Discriminator loss = 1.1488696336746216, GAN loss = [2.7620108, 1.0313728, 0.99403113]\n",
      "Batch 258/700: Discriminator loss = 1.1439208984375, GAN loss = [2.8151243, 1.0335869, 1.0449669]\n",
      "Batch 259/700: Discriminator loss = 1.1862461566925049, GAN loss = [2.8867762, 1.0272645, 1.122973]\n",
      "Batch 260/700: Discriminator loss = 1.0952492952346802, GAN loss = [2.8787017, 1.0666833, 1.0754981]\n",
      "Batch 261/700: Discriminator loss = 1.0842068195343018, GAN loss = [3.0010042, 1.0592622, 1.2052554]\n",
      "Batch 262/700: Discriminator loss = 1.1482083797454834, GAN loss = [2.9924538, 1.0719417, 1.1840495]\n",
      "Batch 263/700: Discriminator loss = 1.1045106649398804, GAN loss = [3.0561006, 1.0680819, 1.2515826]\n",
      "Batch 264/700: Discriminator loss = 1.0991705656051636, GAN loss = [2.9482033, 1.0311625, 1.1806183]\n",
      "Batch 265/700: Discriminator loss = 1.1813584566116333, GAN loss = [2.8816104, 1.0113724, 1.1338264]\n",
      "Batch 266/700: Discriminator loss = 1.160110354423523, GAN loss = [2.79601, 1.0136513, 1.0459466]\n",
      "Batch 267/700: Discriminator loss = 1.1033076047897339, GAN loss = [2.9383187, 1.0502356, 1.1516613]\n",
      "Batch 268/700: Discriminator loss = 1.1343433856964111, GAN loss = [2.9541392, 1.0191478, 1.1985626]\n",
      "Batch 269/700: Discriminator loss = 1.0903759002685547, GAN loss = [2.8962774, 1.0455593, 1.1142825]\n",
      "Batch 270/700: Discriminator loss = 1.1397044658660889, GAN loss = [2.7990358, 1.0051516, 1.0574335]\n",
      "Batch 271/700: Discriminator loss = 1.1464182138442993, GAN loss = [2.9726148, 1.0191411, 1.2170202]\n",
      "Batch 272/700: Discriminator loss = 1.1294777393341064, GAN loss = [2.9777122, 1.0669891, 1.1742572]\n",
      "Batch 273/700: Discriminator loss = 1.1346396207809448, GAN loss = [2.9293532, 1.0410666, 1.1518326]\n",
      "Batch 274/700: Discriminator loss = 1.1025456190109253, GAN loss = [2.924381, 1.0367064, 1.1512175]\n",
      "Batch 275/700: Discriminator loss = 1.177346110343933, GAN loss = [2.820833, 1.0179042, 1.0664704]\n",
      "Batch 276/700: Discriminator loss = 1.1486034393310547, GAN loss = [2.7618084, 1.0091475, 1.0162175]\n",
      "Batch 277/700: Discriminator loss = 1.135589599609375, GAN loss = [2.88095, 1.0594212, 1.0850822]\n",
      "Batch 278/700: Discriminator loss = 1.160613775253296, GAN loss = [2.7825649, 0.9916578, 1.0544485]\n",
      "Batch 279/700: Discriminator loss = 1.1316628456115723, GAN loss = [2.8661723, 1.0076431, 1.1220556]\n",
      "Batch 280/700: Discriminator loss = 1.142958641052246, GAN loss = [2.9359684, 1.0408379, 1.1586338]\n",
      "Batch 281/700: Discriminator loss = 1.1637581586837769, GAN loss = [2.8872762, 1.0125271, 1.1382375]\n",
      "Batch 282/700: Discriminator loss = 1.1690338850021362, GAN loss = [2.850059, 1.032233, 1.0812938]\n",
      "Batch 283/700: Discriminator loss = 1.1346142292022705, GAN loss = [2.9092684, 1.0413514, 1.1313505]\n",
      "Batch 284/700: Discriminator loss = 1.1649218797683716, GAN loss = [2.7394598, 0.99311113, 1.0097629]\n",
      "Batch 285/700: Discriminator loss = 1.129757046699524, GAN loss = [2.8811638, 1.0095848, 1.134969]\n",
      "Batch 286/700: Discriminator loss = 1.2404804229736328, GAN loss = [2.7250817, 0.98866194, 0.99978036]\n",
      "Batch 287/700: Discriminator loss = 1.1457496881484985, GAN loss = [2.826353, 0.9989822, 1.0907156]\n",
      "Batch 288/700: Discriminator loss = 1.1772254705429077, GAN loss = [2.7675476, 0.9724486, 1.0584404]\n",
      "Batch 289/700: Discriminator loss = 1.1161904335021973, GAN loss = [2.9166806, 1.0476809, 1.1323432]\n",
      "Batch 290/700: Discriminator loss = 1.1900615692138672, GAN loss = [2.743561, 0.9844268, 1.0224829]\n",
      "Batch 291/700: Discriminator loss = 1.1872977018356323, GAN loss = [2.8389823, 1.0232078, 1.0791246]\n",
      "Batch 292/700: Discriminator loss = 1.1608864068984985, GAN loss = [2.8799329, 1.0391728, 1.1041063]\n",
      "Batch 293/700: Discriminator loss = 1.2034900188446045, GAN loss = [2.7616837, 0.9692453, 1.0557821]\n",
      "Batch 294/700: Discriminator loss = 1.1338216066360474, GAN loss = [2.7959912, 1.0117011, 1.0476289]\n",
      "Batch 295/700: Discriminator loss = 1.1582200527191162, GAN loss = [2.7713876, 1.0091892, 1.0255529]\n",
      "Batch 296/700: Discriminator loss = 1.225063681602478, GAN loss = [2.7507815, 1.0139453, 1.0002137]\n",
      "Batch 297/700: Discriminator loss = 1.1088005304336548, GAN loss = [2.83894, 1.0365297, 1.0657917]\n",
      "Batch 298/700: Discriminator loss = 1.1674305200576782, GAN loss = [2.7402656, 0.9995785, 1.0040598]\n",
      "Batch 299/700: Discriminator loss = 1.207180142402649, GAN loss = [2.8079686, 1.0466938, 1.0246445]\n",
      "Batch 300/700: Discriminator loss = 1.1894593238830566, GAN loss = [2.722563, 1.0143702, 0.9715805]\n",
      "Batch 301/700: Discriminator loss = 1.176353096961975, GAN loss = [2.7910814, 0.9922363, 1.0622549]\n",
      "Batch 302/700: Discriminator loss = 1.115885615348816, GAN loss = [2.778299, 1.0488024, 0.99292]\n",
      "Batch 303/700: Discriminator loss = 1.0822224617004395, GAN loss = [2.8455436, 1.0752845, 1.0336921]\n",
      "Batch 304/700: Discriminator loss = 1.185325264930725, GAN loss = [2.7845502, 1.0152237, 1.0327615]\n",
      "Batch 305/700: Discriminator loss = 1.1898854970932007, GAN loss = [2.8270173, 0.9891235, 1.1013317]\n",
      "Batch 306/700: Discriminator loss = 1.1170324087142944, GAN loss = [2.9382722, 1.0685905, 1.1331385]\n",
      "Batch 307/700: Discriminator loss = 1.171762228012085, GAN loss = [2.7982843, 1.0096399, 1.0521089]\n",
      "Batch 308/700: Discriminator loss = 1.1204431056976318, GAN loss = [2.8578897, 1.0579907, 1.0633824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 309/700: Discriminator loss = 1.1477223634719849, GAN loss = [2.7898266, 0.99246734, 1.0608702]\n",
      "Batch 310/700: Discriminator loss = 1.139325737953186, GAN loss = [2.8835437, 1.0591956, 1.0878894]\n",
      "Batch 311/700: Discriminator loss = 1.1406294107437134, GAN loss = [2.876752, 1.0274955, 1.1128407]\n",
      "Batch 312/700: Discriminator loss = 1.142199993133545, GAN loss = [2.8899796, 1.0279381, 1.1256549]\n",
      "Batch 313/700: Discriminator loss = 1.1257327795028687, GAN loss = [2.8897018, 1.0225786, 1.1307486]\n",
      "Batch 314/700: Discriminator loss = 1.1525088548660278, GAN loss = [2.9383333, 1.0247102, 1.1772616]\n",
      "Batch 315/700: Discriminator loss = 1.1309155225753784, GAN loss = [2.827747, 1.0569675, 1.034444]\n",
      "Batch 316/700: Discriminator loss = 1.1553159952163696, GAN loss = [2.8206704, 1.0225182, 1.0618435]\n",
      "Batch 317/700: Discriminator loss = 1.1726387739181519, GAN loss = [2.8742623, 1.0072333, 1.1307502]\n",
      "Batch 318/700: Discriminator loss = 1.1147679090499878, GAN loss = [3.0308032, 1.0648036, 1.2297391]\n",
      "Batch 319/700: Discriminator loss = 1.208935022354126, GAN loss = [2.7869034, 0.9970273, 1.0536535]\n",
      "Batch 320/700: Discriminator loss = 1.082187533378601, GAN loss = [2.9294524, 1.0605519, 1.1326879]\n",
      "Batch 321/700: Discriminator loss = 1.1657741069793701, GAN loss = [3.0125816, 1.0335813, 1.2428075]\n",
      "Batch 322/700: Discriminator loss = 1.122388243675232, GAN loss = [2.9719503, 1.0622268, 1.1735566]\n",
      "Batch 323/700: Discriminator loss = 1.1410173177719116, GAN loss = [3.06026, 1.0815766, 1.242553]\n",
      "Batch 324/700: Discriminator loss = 1.1508680582046509, GAN loss = [2.8498132, 1.0369325, 1.076769]\n",
      "Batch 325/700: Discriminator loss = 1.1558115482330322, GAN loss = [2.8513203, 1.0612415, 1.0539931]\n",
      "Batch 326/700: Discriminator loss = 1.2201452255249023, GAN loss = [2.803544, 1.0383563, 1.0291041]\n",
      "Batch 327/700: Discriminator loss = 1.1338902711868286, GAN loss = [2.899277, 1.0603876, 1.1028327]\n",
      "Batch 328/700: Discriminator loss = 1.1349536180496216, GAN loss = [3.0268965, 1.077967, 1.2129]\n",
      "Batch 329/700: Discriminator loss = 1.11845862865448, GAN loss = [2.9282877, 1.0594816, 1.13279]\n",
      "Batch 330/700: Discriminator loss = 1.09938383102417, GAN loss = [3.0098143, 1.0857341, 1.1880646]\n",
      "Batch 331/700: Discriminator loss = 1.1377321481704712, GAN loss = [2.9504871, 1.0561492, 1.1583266]\n",
      "Batch 332/700: Discriminator loss = 1.1410540342330933, GAN loss = [3.0420096, 1.0677335, 1.2382656]\n",
      "Batch 333/700: Discriminator loss = 1.1468945741653442, GAN loss = [2.9112816, 1.0084962, 1.166763]\n",
      "Batch 334/700: Discriminator loss = 1.1563084125518799, GAN loss = [3.0253212, 1.0274687, 1.2618315]\n",
      "Batch 335/700: Discriminator loss = 1.1139689683914185, GAN loss = [2.9288468, 1.0590862, 1.1337491]\n",
      "Batch 336/700: Discriminator loss = 1.1402736902236938, GAN loss = [3.0256002, 1.0525862, 1.2370166]\n",
      "Batch 337/700: Discriminator loss = 1.1180198192596436, GAN loss = [2.9264371, 1.0165346, 1.1739306]\n",
      "Batch 338/700: Discriminator loss = 1.1431987285614014, GAN loss = [2.9365127, 1.0173216, 1.1832376]\n",
      "Batch 339/700: Discriminator loss = 1.1276549100875854, GAN loss = [2.9682236, 1.0464358, 1.185838]\n",
      "Batch 340/700: Discriminator loss = 1.1186163425445557, GAN loss = [3.007753, 1.0938853, 1.1779386]\n",
      "Batch 341/700: Discriminator loss = 1.1449378728866577, GAN loss = [2.961335, 1.0421283, 1.1833048]\n",
      "Batch 342/700: Discriminator loss = 1.1625709533691406, GAN loss = [2.901146, 1.0343006, 1.1309679]\n",
      "Batch 343/700: Discriminator loss = 1.1284862756729126, GAN loss = [2.8666756, 1.0427136, 1.0881128]\n",
      "Batch 344/700: Discriminator loss = 1.1184009313583374, GAN loss = [2.8681123, 1.0613327, 1.0709738]\n",
      "Batch 345/700: Discriminator loss = 1.102429747581482, GAN loss = [2.980952, 1.041032, 1.2041651]\n",
      "Batch 346/700: Discriminator loss = 1.0996676683425903, GAN loss = [2.8995187, 1.0933707, 1.0704265]\n",
      "Batch 347/700: Discriminator loss = 1.0979067087173462, GAN loss = [3.1030042, 1.0513349, 1.3159702]\n",
      "Batch 348/700: Discriminator loss = 1.1090607643127441, GAN loss = [2.86104, 1.0441616, 1.0812118]\n",
      "Batch 349/700: Discriminator loss = 1.125839114189148, GAN loss = [2.9199162, 0.99217874, 1.1920993]\n",
      "Batch 350/700: Discriminator loss = 1.1220204830169678, GAN loss = [2.9336293, 1.0308352, 1.1671809]\n",
      "Batch 351/700: Discriminator loss = 1.1219353675842285, GAN loss = [2.995244, 1.0392833, 1.2203733]\n",
      "Batch 352/700: Discriminator loss = 1.1639424562454224, GAN loss = [2.8638701, 1.0246978, 1.1036084]\n",
      "Batch 353/700: Discriminator loss = 1.1339612007141113, GAN loss = [3.0130963, 1.0315847, 1.2459946]\n",
      "Batch 354/700: Discriminator loss = 1.0931907892227173, GAN loss = [2.9508572, 1.0537925, 1.1616137]\n",
      "Batch 355/700: Discriminator loss = 1.091999888420105, GAN loss = [3.0692987, 1.0513158, 1.282577]\n",
      "Batch 356/700: Discriminator loss = 1.1025434732437134, GAN loss = [2.987664, 1.080451, 1.1718414]\n",
      "Batch 357/700: Discriminator loss = 1.084378719329834, GAN loss = [2.9220538, 1.0828571, 1.1038626]\n",
      "Batch 358/700: Discriminator loss = 1.1401994228363037, GAN loss = [2.9365957, 1.0271484, 1.1741495]\n",
      "Batch 359/700: Discriminator loss = 1.1180214881896973, GAN loss = [2.9909954, 1.0411142, 1.2146113]\n",
      "Batch 360/700: Discriminator loss = 1.096226692199707, GAN loss = [2.973763, 1.0490762, 1.1894554]\n",
      "Batch 361/700: Discriminator loss = 1.1219189167022705, GAN loss = [3.1066263, 1.0635942, 1.3078454]\n",
      "Batch 362/700: Discriminator loss = 1.137292504310608, GAN loss = [2.8724575, 1.0493519, 1.0879515]\n",
      "Batch 363/700: Discriminator loss = 1.1374220848083496, GAN loss = [2.8963249, 1.0248151, 1.136377]\n",
      "Batch 364/700: Discriminator loss = 1.116226315498352, GAN loss = [2.9712212, 1.0336171, 1.2025036]\n",
      "Batch 365/700: Discriminator loss = 1.132451057434082, GAN loss = [2.904062, 1.0385311, 1.1304417]\n",
      "Batch 366/700: Discriminator loss = 1.11195969581604, GAN loss = [2.9461813, 1.0679638, 1.1431388]\n",
      "Batch 367/700: Discriminator loss = 1.1161996126174927, GAN loss = [2.895936, 1.0543964, 1.1064861]\n",
      "Batch 368/700: Discriminator loss = 1.1268894672393799, GAN loss = [2.9584265, 1.0759234, 1.1474756]\n",
      "Batch 369/700: Discriminator loss = 1.1652215719223022, GAN loss = [2.9253018, 1.0279453, 1.1623679]\n",
      "Batch 370/700: Discriminator loss = 1.0794204473495483, GAN loss = [2.940707, 1.0874367, 1.1183056]\n",
      "Batch 371/700: Discriminator loss = 1.1523830890655518, GAN loss = [2.9398036, 1.0313165, 1.17355]\n",
      "Batch 372/700: Discriminator loss = 1.1487466096878052, GAN loss = [2.9517539, 1.0248904, 1.191948]\n",
      "Batch 373/700: Discriminator loss = 1.1309256553649902, GAN loss = [2.8695884, 1.0557379, 1.0789597]\n",
      "Batch 374/700: Discriminator loss = 1.1424132585525513, GAN loss = [2.900058, 1.0338987, 1.1312889]\n",
      "Batch 375/700: Discriminator loss = 1.117485523223877, GAN loss = [2.96452, 1.0978098, 1.1318744]\n",
      "Batch 376/700: Discriminator loss = 1.142490267753601, GAN loss = [2.8301232, 1.0025301, 1.0927833]\n",
      "Batch 377/700: Discriminator loss = 1.1494166851043701, GAN loss = [2.7967267, 0.9885537, 1.0733838]\n",
      "Batch 378/700: Discriminator loss = 1.1219574213027954, GAN loss = [2.9593844, 1.0418844, 1.1827255]\n",
      "Batch 379/700: Discriminator loss = 1.1869738101959229, GAN loss = [2.9331996, 0.98621446, 1.2122449]\n",
      "Batch 380/700: Discriminator loss = 1.1259928941726685, GAN loss = [2.7847137, 1.004656, 1.0453372]\n",
      "Batch 381/700: Discriminator loss = 1.123515009880066, GAN loss = [2.9070985, 1.0246078, 1.1477927]\n",
      "Batch 382/700: Discriminator loss = 1.122532606124878, GAN loss = [2.9212775, 1.043027, 1.1435764]\n",
      "Batch 383/700: Discriminator loss = 1.1831759214401245, GAN loss = [2.822942, 0.96901995, 1.1192808]\n",
      "Batch 384/700: Discriminator loss = 1.130611538887024, GAN loss = [2.8439395, 1.0023127, 1.1070267]\n",
      "Batch 385/700: Discriminator loss = 1.139400601387024, GAN loss = [2.915073, 1.0306321, 1.149872]\n",
      "Batch 386/700: Discriminator loss = 1.1117185354232788, GAN loss = [2.8850496, 1.0212396, 1.1292771]\n",
      "Batch 387/700: Discriminator loss = 1.1201215982437134, GAN loss = [2.9047654, 1.0186166, 1.151648]\n",
      "Batch 388/700: Discriminator loss = 1.1328270435333252, GAN loss = [2.8932471, 1.0379984, 1.1207758]\n",
      "Batch 389/700: Discriminator loss = 1.1595596075057983, GAN loss = [2.8075206, 0.9900101, 1.0830674]\n",
      "Batch 390/700: Discriminator loss = 1.122107744216919, GAN loss = [2.962584, 1.0363412, 1.1918228]\n",
      "Batch 391/700: Discriminator loss = 1.1740961074829102, GAN loss = [2.8036163, 0.9834594, 1.0857475]\n",
      "Batch 392/700: Discriminator loss = 1.1969120502471924, GAN loss = [2.8013299, 0.98583734, 1.0810935]\n",
      "Batch 393/700: Discriminator loss = 1.1262357234954834, GAN loss = [2.8441873, 1.0151552, 1.0946436]\n",
      "Batch 394/700: Discriminator loss = 1.2096806764602661, GAN loss = [2.8128605, 0.96119994, 1.1172844]\n",
      "Batch 395/700: Discriminator loss = 1.1514211893081665, GAN loss = [2.8818088, 1.0365133, 1.110931]\n",
      "Batch 396/700: Discriminator loss = 1.1133486032485962, GAN loss = [2.9602485, 1.034203, 1.19169]\n",
      "Batch 397/700: Discriminator loss = 1.133520483970642, GAN loss = [2.9007168, 1.0064328, 1.1599361]\n",
      "Batch 398/700: Discriminator loss = 1.1698698997497559, GAN loss = [2.8279653, 0.9538915, 1.139735]\n",
      "Batch 399/700: Discriminator loss = 1.1510170698165894, GAN loss = [2.8808656, 1.0146165, 1.131924]\n",
      "Batch 400/700: Discriminator loss = 1.0974525213241577, GAN loss = [2.9687152, 1.0510033, 1.1834023]\n",
      "Batch 401/700: Discriminator loss = 1.1633156538009644, GAN loss = [2.8032115, 1.0005127, 1.0684026]\n",
      "Batch 402/700: Discriminator loss = 1.1184717416763306, GAN loss = [2.8411663, 1.0200931, 1.0867965]\n",
      "Batch 403/700: Discriminator loss = 1.1358588933944702, GAN loss = [2.9323857, 1.0000749, 1.198063]\n",
      "Batch 404/700: Discriminator loss = 1.1370916366577148, GAN loss = [2.8379495, 0.99436104, 1.1093522]\n",
      "Batch 405/700: Discriminator loss = 1.1796884536743164, GAN loss = [2.9000378, 0.9663307, 1.1994789]\n",
      "Batch 406/700: Discriminator loss = 1.1197540760040283, GAN loss = [2.8416874, 1.0019554, 1.1055045]\n",
      "Batch 407/700: Discriminator loss = 1.1697969436645508, GAN loss = [2.8909092, 1.0058967, 1.1507924]\n",
      "Batch 408/700: Discriminator loss = 1.1300194263458252, GAN loss = [2.911309, 1.029639, 1.1474551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 409/700: Discriminator loss = 1.0996177196502686, GAN loss = [2.951064, 1.0358297, 1.1810141]\n",
      "Batch 410/700: Discriminator loss = 1.1201800107955933, GAN loss = [3.0277412, 1.0432984, 1.2502244]\n",
      "Batch 411/700: Discriminator loss = 1.1371198892593384, GAN loss = [2.853747, 0.9935031, 1.126036]\n",
      "Batch 412/700: Discriminator loss = 1.1501801013946533, GAN loss = [2.8506932, 0.99208534, 1.1243997]\n",
      "Batch 413/700: Discriminator loss = 1.1524401903152466, GAN loss = [2.8865154, 0.992193, 1.1601124]\n",
      "Batch 414/700: Discriminator loss = 1.2060567140579224, GAN loss = [2.8509157, 0.94713694, 1.1695725]\n",
      "Batch 415/700: Discriminator loss = 1.1455687284469604, GAN loss = [2.8807504, 0.97794324, 1.168611]\n",
      "Batch 416/700: Discriminator loss = 1.171142578125, GAN loss = [2.8977332, 0.9996262, 1.1639141]\n",
      "Batch 417/700: Discriminator loss = 1.1339422464370728, GAN loss = [2.852704, 0.9928172, 1.1257035]\n",
      "Batch 418/700: Discriminator loss = 1.1800538301467896, GAN loss = [2.8463986, 0.9571129, 1.1551123]\n",
      "Batch 419/700: Discriminator loss = 1.1797679662704468, GAN loss = [2.7993214, 0.9448566, 1.1203036]\n",
      "Batch 420/700: Discriminator loss = 1.1443108320236206, GAN loss = [2.9409773, 1.0231398, 1.1836958]\n",
      "Batch 421/700: Discriminator loss = 1.159345030784607, GAN loss = [2.8114138, 0.99684495, 1.0804548]\n",
      "Batch 422/700: Discriminator loss = 1.195080280303955, GAN loss = [2.8712957, 0.9645122, 1.1726757]\n",
      "Batch 423/700: Discriminator loss = 1.1263983249664307, GAN loss = [2.9416146, 1.0439413, 1.1635733]\n",
      "Batch 424/700: Discriminator loss = 1.1627447605133057, GAN loss = [2.8193548, 0.9682942, 1.1169847]\n",
      "Batch 425/700: Discriminator loss = 1.104016661643982, GAN loss = [3.0115623, 1.0593851, 1.2181252]\n",
      "Batch 426/700: Discriminator loss = 1.1455587148666382, GAN loss = [2.9189842, 1.0353895, 1.1495664]\n",
      "Batch 427/700: Discriminator loss = 1.1467312574386597, GAN loss = [2.9330502, 1.040913, 1.1581355]\n",
      "Batch 428/700: Discriminator loss = 1.1051337718963623, GAN loss = [2.9909966, 1.0731899, 1.1838146]\n",
      "Batch 429/700: Discriminator loss = 1.1059852838516235, GAN loss = [2.992504, 1.0567541, 1.2017777]\n",
      "Batch 430/700: Discriminator loss = 1.0888067483901978, GAN loss = [3.0995975, 1.0840921, 1.2815601]\n",
      "Batch 431/700: Discriminator loss = 1.1398870944976807, GAN loss = [2.8190713, 1.0230937, 1.0620487]\n",
      "Batch 432/700: Discriminator loss = 1.1341125965118408, GAN loss = [3.0957148, 1.0587882, 1.3030323]\n",
      "Batch 433/700: Discriminator loss = 1.1492840051651, GAN loss = [2.9138777, 1.0173998, 1.1626098]\n",
      "Batch 434/700: Discriminator loss = 1.1423945426940918, GAN loss = [2.9033203, 1.0252718, 1.1442055]\n",
      "Batch 435/700: Discriminator loss = 1.067175030708313, GAN loss = [3.1047087, 1.0606589, 1.3102298]\n",
      "Batch 436/700: Discriminator loss = 1.1610642671585083, GAN loss = [2.9587407, 1.0363752, 1.1885685]\n",
      "Batch 437/700: Discriminator loss = 1.1709365844726562, GAN loss = [3.0087073, 1.0366411, 1.2382913]\n",
      "Batch 438/700: Discriminator loss = 1.1743927001953125, GAN loss = [2.9923103, 1.0284265, 1.2301415]\n",
      "Batch 439/700: Discriminator loss = 1.117022156715393, GAN loss = [3.036817, 1.0584062, 1.2446991]\n",
      "Batch 440/700: Discriminator loss = 1.1136938333511353, GAN loss = [2.966823, 1.0749704, 1.1581695]\n",
      "Batch 441/700: Discriminator loss = 1.1227872371673584, GAN loss = [2.9258456, 1.073002, 1.1191767]\n",
      "Batch 442/700: Discriminator loss = 1.221665859222412, GAN loss = [2.8369527, 1.006856, 1.0964472]\n",
      "Batch 443/700: Discriminator loss = 1.1451982259750366, GAN loss = [2.8988588, 1.0413827, 1.1238451]\n",
      "Batch 444/700: Discriminator loss = 1.1013747453689575, GAN loss = [3.0175533, 1.113499, 1.1704468]\n",
      "Batch 445/700: Discriminator loss = 1.1092674732208252, GAN loss = [2.9674003, 1.0747834, 1.1590183]\n",
      "Batch 446/700: Discriminator loss = 1.1481432914733887, GAN loss = [2.9212656, 1.0231088, 1.164563]\n",
      "Batch 447/700: Discriminator loss = 1.1849578619003296, GAN loss = [2.7508295, 1.0144805, 1.0027617]\n",
      "Batch 448/700: Discriminator loss = 1.1463412046432495, GAN loss = [2.9389966, 1.0798929, 1.1255245]\n",
      "Batch 449/700: Discriminator loss = 1.1714835166931152, GAN loss = [2.7780986, 1.0343451, 1.0101902]\n",
      "Batch 450/700: Discriminator loss = 1.2171788215637207, GAN loss = [2.8223498, 0.9977058, 1.0911213]\n",
      "Batch 451/700: Discriminator loss = 1.1493234634399414, GAN loss = [2.8457937, 1.0410368, 1.0712502]\n",
      "Batch 452/700: Discriminator loss = 1.201186180114746, GAN loss = [2.7869954, 0.9983235, 1.0551789]\n",
      "Batch 453/700: Discriminator loss = 1.1912691593170166, GAN loss = [2.7506533, 1.031181, 0.98599577]\n",
      "Batch 454/700: Discriminator loss = 1.2293881177902222, GAN loss = [2.7083783, 1.0081728, 0.9667373]\n",
      "Batch 455/700: Discriminator loss = 1.2226022481918335, GAN loss = [2.7606063, 1.0062022, 1.0209628]\n",
      "Batch 456/700: Discriminator loss = 1.177011489868164, GAN loss = [2.7537494, 1.0088211, 1.0115007]\n",
      "Batch 457/700: Discriminator loss = 1.1839263439178467, GAN loss = [2.7986085, 1.0096742, 1.0555227]\n",
      "Batch 458/700: Discriminator loss = 1.1468838453292847, GAN loss = [2.7863636, 1.0664574, 0.9865034]\n",
      "Batch 459/700: Discriminator loss = 1.1198399066925049, GAN loss = [2.8804433, 1.0798202, 1.067226]\n",
      "Batch 460/700: Discriminator loss = 1.1912540197372437, GAN loss = [2.756899, 1.0053457, 1.0181623]\n",
      "Batch 461/700: Discriminator loss = 1.1636477708816528, GAN loss = [2.8118725, 1.0009975, 1.0775036]\n",
      "Batch 462/700: Discriminator loss = 1.1950443983078003, GAN loss = [2.7754066, 0.98588485, 1.056166]\n",
      "Batch 463/700: Discriminator loss = 1.1704754829406738, GAN loss = [2.7288952, 1.0460777, 0.94947696]\n",
      "Batch 464/700: Discriminator loss = 1.1509311199188232, GAN loss = [2.7430441, 1.0270995, 0.9826145]\n",
      "Batch 465/700: Discriminator loss = 1.1600019931793213, GAN loss = [2.7672513, 1.0237576, 1.0101678]\n",
      "Batch 466/700: Discriminator loss = 1.159991979598999, GAN loss = [2.7875884, 1.0166813, 1.0375912]\n",
      "Batch 467/700: Discriminator loss = 1.1378545761108398, GAN loss = [2.7240026, 1.0058981, 0.98479325]\n",
      "Batch 468/700: Discriminator loss = 1.1553559303283691, GAN loss = [2.7483873, 0.9838692, 1.0312063]\n",
      "Batch 469/700: Discriminator loss = 1.1336054801940918, GAN loss = [2.8864293, 1.0639218, 1.089182]\n",
      "Batch 470/700: Discriminator loss = 1.1420588493347168, GAN loss = [2.9178104, 1.0510821, 1.1334007]\n",
      "Batch 471/700: Discriminator loss = 1.1123970746994019, GAN loss = [2.9612732, 1.0495038, 1.1784427]\n",
      "Batch 472/700: Discriminator loss = 1.1732035875320435, GAN loss = [2.918561, 1.023272, 1.1619983]\n",
      "Batch 473/700: Discriminator loss = 1.1338889598846436, GAN loss = [2.933491, 1.0277351, 1.1725082]\n",
      "Batch 474/700: Discriminator loss = 1.2011030912399292, GAN loss = [2.816975, 1.0098336, 1.0739259]\n",
      "Batch 475/700: Discriminator loss = 1.211611270904541, GAN loss = [2.822889, 0.9823496, 1.1073589]\n",
      "Batch 476/700: Discriminator loss = 1.1440231800079346, GAN loss = [2.7249773, 1.0126224, 0.9792091]\n",
      "Batch 477/700: Discriminator loss = 1.103140950202942, GAN loss = [2.9328783, 1.0695399, 1.1302363]\n",
      "Batch 478/700: Discriminator loss = 1.075914740562439, GAN loss = [3.0158849, 1.0529487, 1.2298617]\n",
      "Batch 479/700: Discriminator loss = 1.1381868124008179, GAN loss = [2.7538233, 1.0259608, 0.9948093]\n",
      "Batch 480/700: Discriminator loss = 1.1613428592681885, GAN loss = [2.8001606, 0.99599177, 1.0711328]\n",
      "Batch 481/700: Discriminator loss = 1.1621431112289429, GAN loss = [2.835572, 1.03289, 1.0696713]\n",
      "Batch 482/700: Discriminator loss = 1.1283200979232788, GAN loss = [2.7885194, 1.0234278, 1.0321103]\n",
      "Batch 483/700: Discriminator loss = 1.1275159120559692, GAN loss = [2.7673962, 1.0224863, 1.0119478]\n",
      "Batch 484/700: Discriminator loss = 1.1736910343170166, GAN loss = [2.7902644, 1.0163469, 1.0409904]\n",
      "Batch 485/700: Discriminator loss = 1.1284315586090088, GAN loss = [2.8820617, 1.0194902, 1.1296779]\n",
      "Batch 486/700: Discriminator loss = 1.1183655261993408, GAN loss = [2.8887756, 1.0228134, 1.1331137]\n",
      "Batch 487/700: Discriminator loss = 1.1415690183639526, GAN loss = [2.8246996, 0.9990166, 1.0928657]\n",
      "Batch 488/700: Discriminator loss = 1.12819504737854, GAN loss = [2.8853686, 1.0367938, 1.1157973]\n",
      "Batch 489/700: Discriminator loss = 1.1390036344528198, GAN loss = [2.8016112, 0.9972693, 1.0716032]\n",
      "Batch 490/700: Discriminator loss = 1.1525415182113647, GAN loss = [2.8782601, 1.0277873, 1.1177663]\n",
      "Batch 491/700: Discriminator loss = 1.2008057832717896, GAN loss = [2.7726038, 1.0174506, 1.0224857]\n",
      "Batch 492/700: Discriminator loss = 1.1402106285095215, GAN loss = [2.9053268, 1.0120482, 1.1606561]\n",
      "Batch 493/700: Discriminator loss = 1.1713029146194458, GAN loss = [2.8216188, 0.99604815, 1.0929825]\n",
      "Batch 494/700: Discriminator loss = 1.1349762678146362, GAN loss = [2.8625908, 1.0177186, 1.1123121]\n",
      "Batch 495/700: Discriminator loss = 1.1446119546890259, GAN loss = [2.6700277, 0.98077506, 0.9567288]\n",
      "Batch 496/700: Discriminator loss = 1.131906509399414, GAN loss = [2.86916, 1.0456288, 1.0910307]\n",
      "Batch 497/700: Discriminator loss = 1.1568363904953003, GAN loss = [2.7945237, 0.9865572, 1.0754728]\n",
      "Batch 498/700: Discriminator loss = 1.2035210132598877, GAN loss = [2.8189542, 0.9706867, 1.1157714]\n",
      "Batch 499/700: Discriminator loss = 1.224086046218872, GAN loss = [2.6875508, 0.94358003, 1.0114807]\n",
      "Batch 500/700: Discriminator loss = 1.160578966140747, GAN loss = [2.82968, 0.98224497, 1.1149487]\n",
      "Batch 501/700: Discriminator loss = 1.143227458000183, GAN loss = [2.9273775, 0.9976909, 1.1972104]\n",
      "Batch 502/700: Discriminator loss = 1.1288214921951294, GAN loss = [2.873717, 1.0113941, 1.129852]\n",
      "Batch 503/700: Discriminator loss = 1.1228225231170654, GAN loss = [2.8280423, 1.0093548, 1.0862154]\n",
      "Batch 504/700: Discriminator loss = 1.1663262844085693, GAN loss = [2.7944984, 0.9851267, 1.0769111]\n",
      "Batch 505/700: Discriminator loss = 1.1403757333755493, GAN loss = [2.9199836, 1.0214363, 1.1661018]\n",
      "Batch 506/700: Discriminator loss = 1.1501972675323486, GAN loss = [2.781227, 1.0004112, 1.0483632]\n",
      "Batch 507/700: Discriminator loss = 1.1306915283203125, GAN loss = [2.8489738, 0.99872744, 1.1177906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 508/700: Discriminator loss = 1.1349225044250488, GAN loss = [2.9819183, 1.0098832, 1.2395852]\n",
      "Batch 509/700: Discriminator loss = 1.1599880456924438, GAN loss = [2.8343515, 0.96654475, 1.1353678]\n",
      "Batch 510/700: Discriminator loss = 1.1338179111480713, GAN loss = [2.8684418, 0.98946166, 1.146557]\n",
      "Batch 511/700: Discriminator loss = 1.125219464302063, GAN loss = [2.9930477, 1.0202957, 1.2403421]\n",
      "Batch 512/700: Discriminator loss = 1.1420851945877075, GAN loss = [2.758732, 0.9971986, 1.0291326]\n",
      "Batch 513/700: Discriminator loss = 1.128048062324524, GAN loss = [2.9453313, 1.0011723, 1.2117722]\n",
      "Batch 514/700: Discriminator loss = 1.1104083061218262, GAN loss = [2.9138246, 1.037276, 1.1441929]\n",
      "Batch 515/700: Discriminator loss = 1.1154062747955322, GAN loss = [2.983671, 1.0383122, 1.2130294]\n",
      "Batch 516/700: Discriminator loss = 1.1312178373336792, GAN loss = [2.9485083, 1.0130615, 1.2031473]\n",
      "Batch 517/700: Discriminator loss = 1.1193478107452393, GAN loss = [2.9795, 1.0346018, 1.2126324]\n",
      "Batch 518/700: Discriminator loss = 1.154799222946167, GAN loss = [2.7426722, 0.983757, 1.0266875]\n",
      "Batch 519/700: Discriminator loss = 1.1650232076644897, GAN loss = [2.8993652, 0.9843012, 1.1828725]\n",
      "Batch 520/700: Discriminator loss = 1.122717261314392, GAN loss = [3.05691, 1.04456, 1.2801688]\n",
      "Batch 521/700: Discriminator loss = 1.15345299243927, GAN loss = [2.8206868, 0.98446345, 1.1040337]\n",
      "Batch 522/700: Discriminator loss = 1.1459481716156006, GAN loss = [2.9804583, 1.0028698, 1.2454188]\n",
      "Batch 523/700: Discriminator loss = 1.140864372253418, GAN loss = [2.9386551, 0.9930371, 1.2134815]\n",
      "Batch 524/700: Discriminator loss = 1.164943814277649, GAN loss = [2.927685, 1.0051392, 1.1904415]\n",
      "Batch 525/700: Discriminator loss = 1.157166838645935, GAN loss = [2.8969247, 0.99218017, 1.1726722]\n",
      "Batch 526/700: Discriminator loss = 1.125852346420288, GAN loss = [2.866187, 1.0306082, 1.1035304]\n",
      "Batch 527/700: Discriminator loss = 1.1167627573013306, GAN loss = [2.9399123, 1.0266567, 1.181245]\n",
      "Batch 528/700: Discriminator loss = 1.1187701225280762, GAN loss = [2.9937415, 1.0510018, 1.2107524]\n",
      "Batch 529/700: Discriminator loss = 1.0917540788650513, GAN loss = [3.0282297, 1.0912511, 1.2050174]\n",
      "Batch 530/700: Discriminator loss = 1.1103744506835938, GAN loss = [2.9055843, 1.0006222, 1.1730312]\n",
      "Batch 531/700: Discriminator loss = 1.1801811456680298, GAN loss = [2.954958, 0.99739707, 1.225649]\n",
      "Batch 532/700: Discriminator loss = 1.1075985431671143, GAN loss = [3.0001366, 1.0600723, 1.2081897]\n",
      "Batch 533/700: Discriminator loss = 1.1482712030410767, GAN loss = [2.823484, 1.0084151, 1.0832213]\n",
      "Batch 534/700: Discriminator loss = 1.1338151693344116, GAN loss = [2.9569154, 1.0100503, 1.2150341]\n",
      "Batch 535/700: Discriminator loss = 1.0946377515792847, GAN loss = [2.9440753, 1.0358583, 1.1764057]\n",
      "Batch 536/700: Discriminator loss = 1.1445865631103516, GAN loss = [2.8661392, 1.0265496, 1.1077986]\n",
      "Batch 537/700: Discriminator loss = 1.1927764415740967, GAN loss = [2.7569866, 0.9997436, 1.0254711]\n",
      "Batch 538/700: Discriminator loss = 1.1114853620529175, GAN loss = [3.0023403, 1.041119, 1.2294725]\n",
      "Batch 539/700: Discriminator loss = 1.1220648288726807, GAN loss = [3.0528982, 1.0801272, 1.2410396]\n",
      "Batch 540/700: Discriminator loss = 1.128090739250183, GAN loss = [2.8892422, 1.0115184, 1.1460068]\n",
      "Batch 541/700: Discriminator loss = 1.1303009986877441, GAN loss = [3.0267446, 1.0142524, 1.2807966]\n",
      "Batch 542/700: Discriminator loss = 1.1261276006698608, GAN loss = [3.0685453, 1.0361265, 1.3007436]\n",
      "Batch 543/700: Discriminator loss = 1.112282395362854, GAN loss = [3.0078206, 1.0488247, 1.2273399]\n",
      "Batch 544/700: Discriminator loss = 1.1102396249771118, GAN loss = [2.9884543, 1.0899374, 1.1668924]\n",
      "Batch 545/700: Discriminator loss = 1.120485544204712, GAN loss = [2.8822412, 1.032364, 1.1182789]\n",
      "Batch 546/700: Discriminator loss = 1.148697018623352, GAN loss = [3.0608304, 1.0224997, 1.3067384]\n",
      "Batch 547/700: Discriminator loss = 1.1352455615997314, GAN loss = [3.0347834, 1.0371293, 1.2660601]\n",
      "Batch 548/700: Discriminator loss = 1.1178566217422485, GAN loss = [2.9818044, 1.0618896, 1.1883363]\n",
      "Batch 549/700: Discriminator loss = 1.1058331727981567, GAN loss = [3.0407214, 1.06277, 1.2463924]\n",
      "Batch 550/700: Discriminator loss = 1.1384493112564087, GAN loss = [2.8954945, 1.0277925, 1.1361614]\n",
      "Batch 551/700: Discriminator loss = 1.182325839996338, GAN loss = [2.9092681, 1.0119804, 1.1657672]\n",
      "Batch 552/700: Discriminator loss = 1.0989450216293335, GAN loss = [3.0192711, 1.0553441, 1.2324326]\n",
      "Batch 553/700: Discriminator loss = 1.1468476057052612, GAN loss = [2.952669, 1.0371466, 1.1840429]\n",
      "Batch 554/700: Discriminator loss = 1.1161811351776123, GAN loss = [2.9520514, 1.0699898, 1.1505904]\n",
      "Batch 555/700: Discriminator loss = 1.198872685432434, GAN loss = [2.7801185, 0.97747743, 1.0711786]\n",
      "Batch 556/700: Discriminator loss = 1.2090269327163696, GAN loss = [2.930759, 0.9890578, 1.2102569]\n",
      "Batch 557/700: Discriminator loss = 1.1539121866226196, GAN loss = [3.0363326, 1.0464883, 1.2584172]\n",
      "Batch 558/700: Discriminator loss = 1.1367063522338867, GAN loss = [2.8983922, 1.0426892, 1.1242961]\n",
      "Batch 559/700: Discriminator loss = 1.1703834533691406, GAN loss = [2.903985, 1.0331452, 1.1394448]\n",
      "Batch 560/700: Discriminator loss = 1.1763073205947876, GAN loss = [2.8745499, 1.0132532, 1.129917]\n",
      "Batch 561/700: Discriminator loss = 1.1178250312805176, GAN loss = [2.8979616, 1.0368637, 1.1297354]\n",
      "Batch 562/700: Discriminator loss = 1.1112234592437744, GAN loss = [2.888645, 1.057481, 1.0998175]\n",
      "Batch 563/700: Discriminator loss = 1.166392207145691, GAN loss = [2.9354506, 1.033277, 1.1708435]\n",
      "Batch 564/700: Discriminator loss = 1.174019694328308, GAN loss = [2.77062, 1.0122365, 1.0270687]\n",
      "Batch 565/700: Discriminator loss = 1.1247297525405884, GAN loss = [2.8990567, 1.0918934, 1.0758443]\n",
      "Batch 566/700: Discriminator loss = 1.111474871635437, GAN loss = [2.8499668, 1.0344306, 1.0842377]\n",
      "Batch 567/700: Discriminator loss = 1.1204315423965454, GAN loss = [2.8609514, 1.0646776, 1.0649931]\n",
      "Batch 568/700: Discriminator loss = 1.1300781965255737, GAN loss = [2.862113, 1.0418596, 1.0889925]\n",
      "Batch 569/700: Discriminator loss = 1.1213029623031616, GAN loss = [3.0526943, 1.0422251, 1.2792313]\n",
      "Batch 570/700: Discriminator loss = 1.1402060985565186, GAN loss = [2.866105, 1.0447247, 1.0901588]\n",
      "Batch 571/700: Discriminator loss = 1.111171007156372, GAN loss = [2.9933524, 1.0930711, 1.1690702]\n",
      "Batch 572/700: Discriminator loss = 1.1213366985321045, GAN loss = [2.8833964, 1.0467129, 1.1054891]\n",
      "Batch 573/700: Discriminator loss = 1.1589326858520508, GAN loss = [2.8476846, 1.0659844, 1.050521]\n",
      "Batch 574/700: Discriminator loss = 1.095338225364685, GAN loss = [2.9141474, 1.0704207, 1.1125509]\n",
      "Batch 575/700: Discriminator loss = 1.1410908699035645, GAN loss = [2.9976695, 1.0776188, 1.1888815]\n",
      "Batch 576/700: Discriminator loss = 1.1026828289031982, GAN loss = [2.8815508, 1.0462502, 1.1041435]\n",
      "Batch 577/700: Discriminator loss = 1.1616016626358032, GAN loss = [2.9568675, 1.0324063, 1.193319]\n",
      "Batch 578/700: Discriminator loss = 1.1138352155685425, GAN loss = [2.8677287, 1.0249498, 1.1116508]\n",
      "Batch 579/700: Discriminator loss = 1.0902109146118164, GAN loss = [3.013145, 1.0768058, 1.2052423]\n",
      "Batch 580/700: Discriminator loss = 1.094817042350769, GAN loss = [3.0480719, 1.0739125, 1.2430866]\n",
      "Batch 581/700: Discriminator loss = 1.1227890253067017, GAN loss = [2.925495, 1.0293466, 1.1650983]\n",
      "Batch 582/700: Discriminator loss = 1.1251848936080933, GAN loss = [2.8326597, 1.024157, 1.0774652]\n",
      "Batch 583/700: Discriminator loss = 1.0853692293167114, GAN loss = [3.0533051, 1.0592473, 1.2630289]\n",
      "Batch 584/700: Discriminator loss = 1.1645032167434692, GAN loss = [2.9132268, 1.0159276, 1.1662678]\n",
      "Batch 585/700: Discriminator loss = 1.1293636560440063, GAN loss = [2.9321365, 1.0352077, 1.1659222]\n",
      "Batch 586/700: Discriminator loss = 1.0814472436904907, GAN loss = [3.0659142, 1.1316772, 1.2032545]\n",
      "Batch 587/700: Discriminator loss = 1.1222381591796875, GAN loss = [2.9079316, 1.0425972, 1.1343614]\n",
      "Batch 588/700: Discriminator loss = 1.1531717777252197, GAN loss = [2.9087126, 1.0136838, 1.1640567]\n",
      "Batch 589/700: Discriminator loss = 1.1752842664718628, GAN loss = [2.959417, 1.0199342, 1.2085123]\n",
      "Batch 590/700: Discriminator loss = 1.1424611806869507, GAN loss = [2.951169, 1.0572915, 1.1629058]\n",
      "Batch 591/700: Discriminator loss = 1.1208637952804565, GAN loss = [2.9969308, 1.0587842, 1.2071874]\n",
      "Batch 592/700: Discriminator loss = 1.1569063663482666, GAN loss = [2.8310459, 1.0457811, 1.0543227]\n",
      "Batch 593/700: Discriminator loss = 1.075737476348877, GAN loss = [3.0357985, 1.1002661, 1.2046134]\n",
      "Batch 594/700: Discriminator loss = 1.0898892879486084, GAN loss = [2.943562, 1.0572444, 1.155422]\n",
      "Batch 595/700: Discriminator loss = 1.134202241897583, GAN loss = [2.9897776, 1.0456775, 1.2131966]\n",
      "Batch 596/700: Discriminator loss = 1.1379892826080322, GAN loss = [2.8394277, 1.0264033, 1.0821236]\n",
      "Batch 597/700: Discriminator loss = 1.1640348434448242, GAN loss = [2.8011534, 1.0335946, 1.03666]\n",
      "Batch 598/700: Discriminator loss = 1.144643783569336, GAN loss = [2.9219122, 1.0468493, 1.1441857]\n",
      "Batch 599/700: Discriminator loss = 1.1799370050430298, GAN loss = [2.7618508, 0.9947539, 1.0362355]\n",
      "Batch 600/700: Discriminator loss = 1.1335145235061646, GAN loss = [2.8462162, 1.0390084, 1.0763562]\n",
      "Batch 601/700: Discriminator loss = 1.1255083084106445, GAN loss = [2.8901613, 1.0507809, 1.1085279]\n",
      "Batch 602/700: Discriminator loss = 1.1824246644973755, GAN loss = [2.8070104, 1.0479866, 1.0281825]\n",
      "Batch 603/700: Discriminator loss = 1.1341369152069092, GAN loss = [2.8559823, 1.072588, 1.0525751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 604/700: Discriminator loss = 1.0859484672546387, GAN loss = [3.0887735, 1.0899948, 1.2679752]\n",
      "Batch 605/700: Discriminator loss = 1.1669366359710693, GAN loss = [2.9979277, 1.0385896, 1.2285539]\n",
      "Batch 606/700: Discriminator loss = 1.0473427772521973, GAN loss = [3.1655653, 1.1422886, 1.2925028]\n",
      "Batch 607/700: Discriminator loss = 1.1559100151062012, GAN loss = [2.991164, 1.0270925, 1.2332934]\n",
      "Batch 608/700: Discriminator loss = 1.1917725801467896, GAN loss = [2.877626, 1.0254815, 1.1213605]\n",
      "Batch 609/700: Discriminator loss = 1.1172890663146973, GAN loss = [2.909175, 1.0772895, 1.1011021]\n",
      "Batch 610/700: Discriminator loss = 1.1632040739059448, GAN loss = [2.8703177, 1.0306003, 1.1089351]\n",
      "Batch 611/700: Discriminator loss = 1.1071585416793823, GAN loss = [2.994456, 1.0413501, 1.2223343]\n",
      "Batch 612/700: Discriminator loss = 1.1847054958343506, GAN loss = [2.8906016, 1.0012407, 1.1585864]\n",
      "Batch 613/700: Discriminator loss = 1.195631504058838, GAN loss = [2.9741983, 1.0157543, 1.2276798]\n",
      "Batch 614/700: Discriminator loss = 1.0866578817367554, GAN loss = [2.990443, 1.1036758, 1.1560025]\n",
      "Batch 615/700: Discriminator loss = 1.1893250942230225, GAN loss = [2.8482513, 1.0994098, 1.0180802]\n",
      "Batch 616/700: Discriminator loss = 1.149277925491333, GAN loss = [2.8571575, 1.0794746, 1.0469306]\n",
      "Batch 617/700: Discriminator loss = 1.0951869487762451, GAN loss = [3.0341244, 1.0815002, 1.2218962]\n",
      "Batch 618/700: Discriminator loss = 1.1596624851226807, GAN loss = [3.0264378, 1.0542445, 1.2414823]\n",
      "Batch 619/700: Discriminator loss = 1.1385369300842285, GAN loss = [2.8736575, 1.0543051, 1.0886707]\n",
      "Batch 620/700: Discriminator loss = 1.2209014892578125, GAN loss = [2.8738852, 1.0723214, 1.0709118]\n",
      "Batch 621/700: Discriminator loss = 1.1727690696716309, GAN loss = [2.8320713, 1.0469334, 1.0545261]\n",
      "Batch 622/700: Discriminator loss = 1.1296749114990234, GAN loss = [2.9350803, 1.0613685, 1.1431276]\n",
      "Batch 623/700: Discriminator loss = 1.128393530845642, GAN loss = [2.9241846, 1.0634457, 1.1301775]\n",
      "Batch 624/700: Discriminator loss = 1.1391620635986328, GAN loss = [2.9419634, 1.039551, 1.1718563]\n",
      "Batch 625/700: Discriminator loss = 1.176348328590393, GAN loss = [2.8173697, 1.0036936, 1.0831237]\n",
      "Batch 626/700: Discriminator loss = 1.2285569906234741, GAN loss = [2.8029926, 1.0069791, 1.0654788]\n",
      "Batch 627/700: Discriminator loss = 1.217363953590393, GAN loss = [2.940198, 1.0162483, 1.1934272]\n",
      "Batch 628/700: Discriminator loss = 1.22084641456604, GAN loss = [2.740825, 1.0036505, 1.0066639]\n",
      "Batch 629/700: Discriminator loss = 1.1885713338851929, GAN loss = [2.864937, 1.0484195, 1.0860164]\n",
      "Batch 630/700: Discriminator loss = 1.1638846397399902, GAN loss = [2.9773796, 1.0695549, 1.17734]\n",
      "Batch 631/700: Discriminator loss = 1.125014305114746, GAN loss = [2.945415, 1.0748782, 1.1400628]\n",
      "Batch 632/700: Discriminator loss = 1.1569238901138306, GAN loss = [2.8932645, 1.0335828, 1.1292236]\n",
      "Batch 633/700: Discriminator loss = 1.1766985654830933, GAN loss = [2.768189, 1.0083777, 1.0293679]\n",
      "Batch 634/700: Discriminator loss = 1.212311029434204, GAN loss = [2.9395635, 1.0258315, 1.1832945]\n",
      "Batch 635/700: Discriminator loss = 1.1222755908966064, GAN loss = [3.0043852, 1.0665458, 1.207418]\n",
      "Batch 636/700: Discriminator loss = 1.2163985967636108, GAN loss = [2.7661512, 1.0011617, 1.0345901]\n",
      "Batch 637/700: Discriminator loss = 1.1850727796554565, GAN loss = [2.7792184, 0.9861534, 1.0627024]\n",
      "Batch 638/700: Discriminator loss = 1.2328705787658691, GAN loss = [2.7987335, 0.9967109, 1.0716842]\n",
      "Batch 639/700: Discriminator loss = 1.143263816833496, GAN loss = [2.939274, 1.0696871, 1.1392756]\n",
      "Batch 640/700: Discriminator loss = 1.162693977355957, GAN loss = [2.8296776, 1.0211706, 1.0782181]\n",
      "Batch 641/700: Discriminator loss = 1.1692383289337158, GAN loss = [2.8282309, 1.0378672, 1.0600947]\n",
      "Batch 642/700: Discriminator loss = 1.1146847009658813, GAN loss = [2.8457131, 1.0982059, 1.0172603]\n",
      "Batch 643/700: Discriminator loss = 1.1093193292617798, GAN loss = [2.9705899, 1.0366379, 1.2037342]\n",
      "Batch 644/700: Discriminator loss = 1.1696370840072632, GAN loss = [2.9544785, 1.0424547, 1.1818256]\n",
      "Batch 645/700: Discriminator loss = 1.1337287425994873, GAN loss = [2.8213196, 1.0509245, 1.0402248]\n",
      "Batch 646/700: Discriminator loss = 1.1404629945755005, GAN loss = [2.7682323, 1.001865, 1.036219]\n",
      "Batch 647/700: Discriminator loss = 1.185213327407837, GAN loss = [2.688176, 0.98312867, 0.9749312]\n",
      "Batch 648/700: Discriminator loss = 1.1676808595657349, GAN loss = [2.7524557, 1.0051503, 1.0172112]\n",
      "Batch 649/700: Discriminator loss = 1.1011505126953125, GAN loss = [2.8959768, 1.0406795, 1.1252415]\n",
      "Batch 650/700: Discriminator loss = 1.1220648288726807, GAN loss = [2.855877, 1.0432682, 1.0825821]\n",
      "Batch 651/700: Discriminator loss = 1.1141122579574585, GAN loss = [2.8722844, 1.031051, 1.1112293]\n",
      "Batch 652/700: Discriminator loss = 1.1375856399536133, GAN loss = [2.7954514, 1.0030599, 1.0624102]\n",
      "Batch 653/700: Discriminator loss = 1.1219828128814697, GAN loss = [2.7951648, 1.0179405, 1.0472662]\n",
      "Batch 654/700: Discriminator loss = 1.1715666055679321, GAN loss = [2.8363872, 1.0038564, 1.1025907]\n",
      "Batch 655/700: Discriminator loss = 1.1168736219406128, GAN loss = [3.014692, 1.072256, 1.2124873]\n",
      "Batch 656/700: Discriminator loss = 1.1443629264831543, GAN loss = [2.905861, 1.0400589, 1.1358398]\n",
      "Batch 657/700: Discriminator loss = 1.1513512134552002, GAN loss = [2.8372812, 1.0415081, 1.0658088]\n",
      "Batch 658/700: Discriminator loss = 1.151665210723877, GAN loss = [2.7869718, 0.99087983, 1.066133]\n",
      "Batch 659/700: Discriminator loss = 1.1535403728485107, GAN loss = [2.7736082, 0.98570955, 1.057946]\n",
      "Batch 660/700: Discriminator loss = 1.114428162574768, GAN loss = [2.7985148, 1.0058143, 1.0627528]\n",
      "Batch 661/700: Discriminator loss = 1.1301020383834839, GAN loss = [2.9259105, 1.0487372, 1.1472306]\n",
      "Batch 662/700: Discriminator loss = 1.1435563564300537, GAN loss = [2.7934911, 0.97703165, 1.0865302]\n",
      "Batch 663/700: Discriminator loss = 1.1430277824401855, GAN loss = [2.8353658, 1.0056645, 1.0997788]\n",
      "Batch 664/700: Discriminator loss = 1.1401853561401367, GAN loss = [2.8728712, 1.0123053, 1.1306425]\n",
      "Batch 665/700: Discriminator loss = 1.1245841979980469, GAN loss = [2.948714, 1.0250925, 1.1937109]\n",
      "Batch 666/700: Discriminator loss = 1.1638927459716797, GAN loss = [2.914969, 1.0321177, 1.1529596]\n",
      "Batch 667/700: Discriminator loss = 1.1272070407867432, GAN loss = [2.9622595, 1.0441972, 1.1881813]\n",
      "Batch 668/700: Discriminator loss = 1.147026538848877, GAN loss = [2.8534372, 0.994402, 1.1291704]\n",
      "Batch 669/700: Discriminator loss = 1.1289891004562378, GAN loss = [2.8650606, 0.9972891, 1.1379124]\n",
      "Batch 670/700: Discriminator loss = 1.116050124168396, GAN loss = [2.8870606, 1.0452534, 1.1119549]\n",
      "Batch 671/700: Discriminator loss = 1.1162372827529907, GAN loss = [2.964242, 1.0089595, 1.2254595]\n",
      "Batch 672/700: Discriminator loss = 1.160017490386963, GAN loss = [2.7587454, 0.99561256, 1.0333153]\n",
      "Batch 673/700: Discriminator loss = 1.1127115488052368, GAN loss = [2.9918916, 1.0298009, 1.2322824]\n",
      "Batch 674/700: Discriminator loss = 1.1166603565216064, GAN loss = [2.9308577, 1.0292434, 1.1718122]\n",
      "Batch 675/700: Discriminator loss = 1.1423546075820923, GAN loss = [2.8480206, 1.0214065, 1.09683]\n",
      "Batch 676/700: Discriminator loss = 1.1325873136520386, GAN loss = [2.9270682, 1.0366162, 1.1606835]\n",
      "Batch 677/700: Discriminator loss = 1.1136763095855713, GAN loss = [2.9465425, 1.0212963, 1.1954753]\n",
      "Batch 678/700: Discriminator loss = 1.1463757753372192, GAN loss = [2.905831, 1.0232186, 1.1528394]\n",
      "Batch 679/700: Discriminator loss = 1.134414792060852, GAN loss = [2.860176, 1.0088587, 1.1215725]\n",
      "Batch 680/700: Discriminator loss = 1.1214463710784912, GAN loss = [2.905099, 1.0261602, 1.149223]\n",
      "Batch 681/700: Discriminator loss = 1.1628824472427368, GAN loss = [2.8997447, 0.97936773, 1.1906759]\n",
      "Batch 682/700: Discriminator loss = 1.1392532587051392, GAN loss = [2.7086225, 0.9834853, 0.9954483]\n",
      "Batch 683/700: Discriminator loss = 1.1104693412780762, GAN loss = [2.9817991, 1.0673105, 1.1848042]\n",
      "Batch 684/700: Discriminator loss = 1.0862231254577637, GAN loss = [2.882075, 1.0603408, 1.0920589]\n",
      "Batch 685/700: Discriminator loss = 1.1213724613189697, GAN loss = [2.8667545, 1.0555918, 1.0814924]\n",
      "Batch 686/700: Discriminator loss = 1.0918318033218384, GAN loss = [3.0095801, 1.0874305, 1.1925114]\n",
      "Batch 687/700: Discriminator loss = 1.053391695022583, GAN loss = [3.0452464, 1.0982395, 1.2174207]\n",
      "Batch 688/700: Discriminator loss = 1.1129518747329712, GAN loss = [2.9649634, 1.0713923, 1.1640092]\n",
      "Batch 689/700: Discriminator loss = 1.066784381866455, GAN loss = [3.013785, 1.1044877, 1.1797583]\n",
      "Batch 690/700: Discriminator loss = 1.1116173267364502, GAN loss = [2.8820472, 1.0327067, 1.1198255]\n",
      "Batch 691/700: Discriminator loss = 1.1361852884292603, GAN loss = [2.830548, 1.0311677, 1.0698884]\n",
      "Batch 692/700: Discriminator loss = 1.1293489933013916, GAN loss = [2.8884346, 1.0549827, 1.1039939]\n",
      "Batch 693/700: Discriminator loss = 1.1645245552062988, GAN loss = [2.878503, 1.0161, 1.1329772]\n",
      "Batch 694/700: Discriminator loss = 1.119765281677246, GAN loss = [2.8903131, 1.0731418, 1.0877575]\n",
      "Batch 695/700: Discriminator loss = 1.0959118604660034, GAN loss = [2.9473693, 1.1089587, 1.1090101]\n",
      "Batch 696/700: Discriminator loss = 1.1340155601501465, GAN loss = [2.813128, 1.0271442, 1.0566126]\n",
      "Batch 697/700: Discriminator loss = 1.0894689559936523, GAN loss = [2.9266322, 1.0372329, 1.1600543]\n",
      "Batch 698/700: Discriminator loss = 1.087539792060852, GAN loss = [2.892225, 1.0709391, 1.091967]\n",
      "Batch 699/700: Discriminator loss = 1.1159875392913818, GAN loss = [2.8931904, 1.0499979, 1.113908]\n",
      "Batch 700/700: Discriminator loss = 1.1406809091567993, GAN loss = [2.7729666, 0.99378276, 1.0499343]\n",
      "Epoch 13/30\n",
      "Batch 1/700: Discriminator loss = 1.137909173965454, GAN loss = [2.8750565, 1.0378643, 1.1079912]\n",
      "Batch 2/700: Discriminator loss = 1.1113684177398682, GAN loss = [2.8470607, 1.0564141, 1.0614846]\n",
      "Batch 3/700: Discriminator loss = 1.1237752437591553, GAN loss = [2.770945, 1.0300864, 1.0117323]\n",
      "Batch 4/700: Discriminator loss = 1.0816916227340698, GAN loss = [2.923859, 1.0997105, 1.0950608]\n",
      "Batch 5/700: Discriminator loss = 1.1636040210723877, GAN loss = [2.8477695, 1.0046729, 1.114035]\n",
      "Batch 6/700: Discriminator loss = 1.1286306381225586, GAN loss = [2.7853842, 1.012411, 1.0439434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7/700: Discriminator loss = 1.1747541427612305, GAN loss = [2.7700667, 1.0110474, 1.030029]\n",
      "Batch 8/700: Discriminator loss = 1.1101535558700562, GAN loss = [2.8829608, 1.0606998, 1.0932983]\n",
      "Batch 9/700: Discriminator loss = 1.2150391340255737, GAN loss = [2.8185403, 0.9588144, 1.1307957]\n",
      "Batch 10/700: Discriminator loss = 1.1505063772201538, GAN loss = [2.890126, 1.0739669, 1.0872468]\n",
      "Batch 11/700: Discriminator loss = 1.125749945640564, GAN loss = [2.8498516, 1.0620406, 1.0589435]\n",
      "Batch 12/700: Discriminator loss = 1.1444110870361328, GAN loss = [2.8985965, 1.0337269, 1.1360418]\n",
      "Batch 13/700: Discriminator loss = 1.1202991008758545, GAN loss = [2.8502474, 1.0566589, 1.0647787]\n",
      "Batch 14/700: Discriminator loss = 1.1685528755187988, GAN loss = [2.800866, 0.99734217, 1.0747432]\n",
      "Batch 15/700: Discriminator loss = 1.1300268173217773, GAN loss = [2.872681, 1.0613503, 1.0825646]\n",
      "Batch 16/700: Discriminator loss = 1.103919506072998, GAN loss = [2.8985543, 1.06913, 1.1006842]\n",
      "Batch 17/700: Discriminator loss = 1.1635069847106934, GAN loss = [2.8160043, 1.0444574, 1.042834]\n",
      "Batch 18/700: Discriminator loss = 1.1127817630767822, GAN loss = [2.9574902, 1.0520697, 1.176717]\n",
      "Batch 19/700: Discriminator loss = 1.156930923461914, GAN loss = [2.7925713, 0.9850649, 1.0788115]\n",
      "Batch 20/700: Discriminator loss = 1.1351027488708496, GAN loss = [2.8702517, 1.0065335, 1.1350446]\n",
      "Batch 21/700: Discriminator loss = 1.103586196899414, GAN loss = [2.8413713, 1.0444853, 1.0682048]\n",
      "Batch 22/700: Discriminator loss = 1.194222092628479, GAN loss = [2.858029, 0.97082824, 1.1585052]\n",
      "Batch 23/700: Discriminator loss = 1.1931142807006836, GAN loss = [2.734503, 0.9868259, 1.0189619]\n",
      "Batch 24/700: Discriminator loss = 1.1722296476364136, GAN loss = [2.8135, 1.0093106, 1.0754641]\n",
      "Batch 25/700: Discriminator loss = 1.1496480703353882, GAN loss = [2.8522027, 1.0073893, 1.1160905]\n",
      "Batch 26/700: Discriminator loss = 1.2193259000778198, GAN loss = [2.7946098, 0.9641546, 1.1017231]\n",
      "Batch 27/700: Discriminator loss = 1.1966972351074219, GAN loss = [2.740452, 0.9799658, 1.0317475]\n",
      "Batch 28/700: Discriminator loss = 1.1417088508605957, GAN loss = [2.9212356, 1.0229535, 1.1695346]\n",
      "Batch 29/700: Discriminator loss = 1.1936830282211304, GAN loss = [2.7318177, 0.97755706, 1.0255218]\n",
      "Batch 30/700: Discriminator loss = 1.1859538555145264, GAN loss = [2.7495575, 0.9917547, 1.029085]\n",
      "Batch 31/700: Discriminator loss = 1.2023299932479858, GAN loss = [2.7026494, 0.9546913, 1.0192655]\n",
      "Batch 32/700: Discriminator loss = 1.1792484521865845, GAN loss = [2.7422497, 0.9865897, 1.0269976]\n",
      "Batch 33/700: Discriminator loss = 1.1455696821212769, GAN loss = [2.7524679, 1.0037521, 1.0200654]\n",
      "Batch 34/700: Discriminator loss = 1.1526187658309937, GAN loss = [2.7313013, 1.0156351, 0.9870256]\n",
      "Batch 35/700: Discriminator loss = 1.1879260540008545, GAN loss = [2.7028646, 0.96304834, 1.0111889]\n",
      "Batch 36/700: Discriminator loss = 1.1253682374954224, GAN loss = [2.881063, 1.028007, 1.1244379]\n",
      "Batch 37/700: Discriminator loss = 1.128480076789856, GAN loss = [2.8261745, 1.0423883, 1.0551858]\n",
      "Batch 38/700: Discriminator loss = 1.1413936614990234, GAN loss = [2.8660362, 0.9843169, 1.1531292]\n",
      "Batch 39/700: Discriminator loss = 1.1757915019989014, GAN loss = [2.8324373, 0.9704476, 1.1334096]\n",
      "Batch 40/700: Discriminator loss = 1.1301014423370361, GAN loss = [2.927245, 1.0237767, 1.1748863]\n",
      "Batch 41/700: Discriminator loss = 1.1763242483139038, GAN loss = [2.8412416, 0.97412246, 1.1385432]\n",
      "Batch 42/700: Discriminator loss = 1.172929286956787, GAN loss = [2.7175548, 0.9613972, 1.0275799]\n",
      "Batch 43/700: Discriminator loss = 1.1632494926452637, GAN loss = [2.8365383, 1.0154905, 1.0924728]\n",
      "Batch 44/700: Discriminator loss = 1.1830103397369385, GAN loss = [2.8303766, 0.98650664, 1.1153309]\n",
      "Batch 45/700: Discriminator loss = 1.1614100933074951, GAN loss = [2.7984304, 1.0049148, 1.0650046]\n",
      "Batch 46/700: Discriminator loss = 1.1303315162658691, GAN loss = [2.8178842, 1.0107108, 1.0786843]\n",
      "Batch 47/700: Discriminator loss = 1.1553893089294434, GAN loss = [2.7693787, 0.99550855, 1.0453866]\n",
      "Batch 48/700: Discriminator loss = 1.120512843132019, GAN loss = [2.9788542, 1.0256912, 1.2246896]\n",
      "Batch 49/700: Discriminator loss = 1.1368658542633057, GAN loss = [2.7687793, 1.0020412, 1.0382768]\n",
      "Batch 50/700: Discriminator loss = 1.1602835655212402, GAN loss = [2.968116, 1.0120934, 1.2275822]\n",
      "Batch 51/700: Discriminator loss = 1.1618671417236328, GAN loss = [2.7556324, 0.9916346, 1.0355809]\n",
      "Batch 52/700: Discriminator loss = 1.079177737236023, GAN loss = [2.9603672, 1.0470005, 1.184964]\n",
      "Batch 53/700: Discriminator loss = 1.1234662532806396, GAN loss = [2.8599017, 1.0215065, 1.1100041]\n",
      "Batch 54/700: Discriminator loss = 1.0974881649017334, GAN loss = [2.9102905, 1.0388671, 1.1430442]\n",
      "Batch 55/700: Discriminator loss = 1.1241633892059326, GAN loss = [2.9357154, 1.0099818, 1.1973749]\n",
      "Batch 56/700: Discriminator loss = 1.1099820137023926, GAN loss = [2.9258502, 1.0271957, 1.1702933]\n",
      "Batch 57/700: Discriminator loss = 1.1239285469055176, GAN loss = [3.0360153, 1.0569198, 1.2507275]\n",
      "Batch 58/700: Discriminator loss = 1.1174217462539673, GAN loss = [2.9642336, 1.0664707, 1.169395]\n",
      "Batch 59/700: Discriminator loss = 1.1268911361694336, GAN loss = [2.8391304, 1.0350055, 1.0757564]\n",
      "Batch 60/700: Discriminator loss = 1.1166523694992065, GAN loss = [2.9949718, 1.0347482, 1.231868]\n",
      "Batch 61/700: Discriminator loss = 1.134023666381836, GAN loss = [2.9006925, 1.036206, 1.1361308]\n",
      "Batch 62/700: Discriminator loss = 1.0984342098236084, GAN loss = [2.9129424, 1.0441349, 1.1404573]\n",
      "Batch 63/700: Discriminator loss = 1.1013928651809692, GAN loss = [2.9790158, 1.0415555, 1.2090971]\n",
      "Batch 64/700: Discriminator loss = 1.1281261444091797, GAN loss = [2.972368, 1.0371184, 1.2068735]\n",
      "Batch 65/700: Discriminator loss = 1.1598212718963623, GAN loss = [2.9180157, 1.0186673, 1.1709602]\n",
      "Batch 66/700: Discriminator loss = 1.1277856826782227, GAN loss = [3.001922, 1.0259488, 1.2475764]\n",
      "Batch 67/700: Discriminator loss = 1.0887612104415894, GAN loss = [3.0569265, 1.0949008, 1.2336292]\n",
      "Batch 68/700: Discriminator loss = 1.1183995008468628, GAN loss = [2.8900437, 1.0282556, 1.133402]\n",
      "Batch 69/700: Discriminator loss = 1.1221481561660767, GAN loss = [2.9784987, 1.0371866, 1.2129344]\n",
      "Batch 70/700: Discriminator loss = 1.0913065671920776, GAN loss = [3.036116, 1.0710397, 1.236703]\n",
      "Batch 71/700: Discriminator loss = 1.159913420677185, GAN loss = [2.9947836, 1.0125908, 1.2538248]\n",
      "Batch 72/700: Discriminator loss = 1.112310767173767, GAN loss = [2.996897, 1.071823, 1.1967281]\n",
      "Batch 73/700: Discriminator loss = 1.0971312522888184, GAN loss = [3.0771956, 1.0894487, 1.259411]\n",
      "Batch 74/700: Discriminator loss = 1.064525842666626, GAN loss = [3.113107, 1.0811892, 1.3035932]\n",
      "Batch 75/700: Discriminator loss = 1.097013235092163, GAN loss = [2.9333837, 1.0223088, 1.1827688]\n",
      "Batch 76/700: Discriminator loss = 1.1671041250228882, GAN loss = [2.8607883, 0.9930532, 1.1394345]\n",
      "Batch 77/700: Discriminator loss = 1.0873465538024902, GAN loss = [3.0787208, 1.0632713, 1.2871507]\n",
      "Batch 78/700: Discriminator loss = 1.1595525741577148, GAN loss = [2.9721055, 1.0219061, 1.2219067]\n",
      "Batch 79/700: Discriminator loss = 1.1661094427108765, GAN loss = [2.9405372, 1.0020851, 1.2101749]\n",
      "Batch 80/700: Discriminator loss = 1.105089783668518, GAN loss = [3.0221357, 1.0747654, 1.219091]\n",
      "Batch 81/700: Discriminator loss = 1.118583083152771, GAN loss = [3.0998788, 1.0715919, 1.2999864]\n",
      "Batch 82/700: Discriminator loss = 1.1026840209960938, GAN loss = [2.9863539, 1.057364, 1.200676]\n",
      "Batch 83/700: Discriminator loss = 1.1325113773345947, GAN loss = [2.8668199, 1.033522, 1.1049743]\n",
      "Batch 84/700: Discriminator loss = 1.1344205141067505, GAN loss = [2.9899197, 1.0258256, 1.2357583]\n",
      "Batch 85/700: Discriminator loss = 1.1072379350662231, GAN loss = [3.0159516, 1.0958512, 1.1917604]\n",
      "Batch 86/700: Discriminator loss = 1.1163817644119263, GAN loss = [3.052936, 1.1030964, 1.2214899]\n",
      "Batch 87/700: Discriminator loss = 1.1529678106307983, GAN loss = [2.8240156, 1.0160382, 1.0796229]\n",
      "Batch 88/700: Discriminator loss = 1.1221222877502441, GAN loss = [2.9955842, 1.0782186, 1.1890059]\n",
      "Batch 89/700: Discriminator loss = 1.0695003271102905, GAN loss = [2.9245071, 1.1026703, 1.0934687]\n",
      "Batch 90/700: Discriminator loss = 1.0984375476837158, GAN loss = [2.9604614, 1.047325, 1.1847568]\n",
      "Batch 91/700: Discriminator loss = 1.1315971612930298, GAN loss = [2.8775523, 1.0215657, 1.1276048]\n",
      "Batch 92/700: Discriminator loss = 1.1644526720046997, GAN loss = [2.8957868, 1.0376811, 1.1297352]\n",
      "Batch 93/700: Discriminator loss = 1.0919523239135742, GAN loss = [2.9164603, 1.071688, 1.1164031]\n",
      "Batch 94/700: Discriminator loss = 1.117664098739624, GAN loss = [2.8575895, 1.0388882, 1.0903378]\n",
      "Batch 95/700: Discriminator loss = 1.1410799026489258, GAN loss = [2.8406658, 1.0019809, 1.1103293]\n",
      "Batch 96/700: Discriminator loss = 1.120336651802063, GAN loss = [2.946496, 1.1179718, 1.1001686]\n",
      "Batch 97/700: Discriminator loss = 1.0683033466339111, GAN loss = [3.0742524, 1.1440673, 1.2018203]\n",
      "Batch 98/700: Discriminator loss = 1.1188790798187256, GAN loss = [2.9237273, 1.0736015, 1.1217364]\n",
      "Batch 99/700: Discriminator loss = 1.1053788661956787, GAN loss = [2.9232318, 1.0586649, 1.1361536]\n",
      "Batch 100/700: Discriminator loss = 1.1021062135696411, GAN loss = [2.9222565, 1.0619442, 1.1319017]\n",
      "Batch 101/700: Discriminator loss = 1.1119256019592285, GAN loss = [2.8756237, 1.0517052, 1.0955106]\n",
      "Batch 102/700: Discriminator loss = 1.145488977432251, GAN loss = [2.8868427, 1.0245739, 1.1338633]\n",
      "Batch 103/700: Discriminator loss = 1.1182703971862793, GAN loss = [2.9169273, 1.0538582, 1.1346853]\n",
      "Batch 104/700: Discriminator loss = 1.111760139465332, GAN loss = [2.96548, 1.1030278, 1.1340958]\n",
      "Batch 105/700: Discriminator loss = 1.1354800462722778, GAN loss = [2.939611, 1.0491332, 1.1621388]\n",
      "Batch 106/700: Discriminator loss = 1.1591548919677734, GAN loss = [2.8631346, 1.0714004, 1.0634133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 107/700: Discriminator loss = 1.0766981840133667, GAN loss = [2.9447207, 1.1045617, 1.1118529]\n",
      "Batch 108/700: Discriminator loss = 1.1246601343154907, GAN loss = [2.9852986, 1.0773774, 1.1796192]\n",
      "Batch 109/700: Discriminator loss = 1.076661467552185, GAN loss = [2.927886, 1.0730684, 1.1265218]\n",
      "Batch 110/700: Discriminator loss = 1.135438084602356, GAN loss = [2.9268448, 1.0356418, 1.1629025]\n",
      "Batch 111/700: Discriminator loss = 1.0878206491470337, GAN loss = [3.0893672, 1.1127993, 1.2482877]\n",
      "Batch 112/700: Discriminator loss = 1.1050827503204346, GAN loss = [2.993914, 1.0726192, 1.1930254]\n",
      "Batch 113/700: Discriminator loss = 1.10975182056427, GAN loss = [2.9154747, 1.056424, 1.1307756]\n",
      "Batch 114/700: Discriminator loss = 1.139485239982605, GAN loss = [2.782459, 1.032019, 1.0221779]\n",
      "Batch 115/700: Discriminator loss = 1.1285393238067627, GAN loss = [2.9055383, 1.0954741, 1.0818309]\n",
      "Batch 116/700: Discriminator loss = 1.1543493270874023, GAN loss = [2.937907, 1.0721979, 1.137496]\n",
      "Batch 117/700: Discriminator loss = 1.1468573808670044, GAN loss = [2.9439816, 1.0797876, 1.1360012]\n",
      "Batch 118/700: Discriminator loss = 1.1323678493499756, GAN loss = [2.9337554, 1.0431541, 1.1624134]\n",
      "Batch 119/700: Discriminator loss = 1.1005909442901611, GAN loss = [2.9617627, 1.089035, 1.144556]\n",
      "Batch 120/700: Discriminator loss = 1.1140283346176147, GAN loss = [2.9139504, 1.0858, 1.1000093]\n",
      "Batch 121/700: Discriminator loss = 1.1254651546478271, GAN loss = [2.9092333, 1.0884732, 1.0926144]\n",
      "Batch 122/700: Discriminator loss = 1.1098711490631104, GAN loss = [2.9998517, 1.1036016, 1.1681082]\n",
      "Batch 123/700: Discriminator loss = 1.1111332178115845, GAN loss = [3.0055816, 1.0950079, 1.182445]\n",
      "Batch 124/700: Discriminator loss = 1.1728183031082153, GAN loss = [2.8528616, 1.0465326, 1.0782166]\n",
      "Batch 125/700: Discriminator loss = 1.117086410522461, GAN loss = [2.9368904, 1.0660229, 1.1427813]\n",
      "Batch 126/700: Discriminator loss = 1.116672396659851, GAN loss = [2.931441, 1.0773212, 1.1260523]\n",
      "Batch 127/700: Discriminator loss = 1.1372992992401123, GAN loss = [2.9135997, 1.0870081, 1.0985389]\n",
      "Batch 128/700: Discriminator loss = 1.1145200729370117, GAN loss = [2.9153686, 1.0441763, 1.143163]\n",
      "Batch 129/700: Discriminator loss = 1.0852158069610596, GAN loss = [2.9952228, 1.0809768, 1.1862314]\n",
      "Batch 130/700: Discriminator loss = 1.2076256275177002, GAN loss = [2.844253, 1.0242372, 1.0920084]\n",
      "Batch 131/700: Discriminator loss = 1.1841603517532349, GAN loss = [2.7631378, 1.0059587, 1.0291927]\n",
      "Batch 132/700: Discriminator loss = 1.135962724685669, GAN loss = [2.8662493, 1.0639715, 1.0742964]\n",
      "Batch 133/700: Discriminator loss = 1.2022721767425537, GAN loss = [2.8131685, 1.0214927, 1.0637034]\n",
      "Batch 134/700: Discriminator loss = 1.1056933403015137, GAN loss = [2.982271, 1.1051594, 1.1491542]\n",
      "Batch 135/700: Discriminator loss = 1.164931297302246, GAN loss = [2.8106751, 1.0747573, 1.0079819]\n",
      "Batch 136/700: Discriminator loss = 1.1538385152816772, GAN loss = [2.898778, 1.0798575, 1.0909984]\n",
      "Batch 137/700: Discriminator loss = 1.1518032550811768, GAN loss = [2.8024046, 1.0631704, 1.0113243]\n",
      "Batch 138/700: Discriminator loss = 1.160847783088684, GAN loss = [2.7119093, 1.0426711, 0.9413424]\n",
      "Batch 139/700: Discriminator loss = 1.0983697175979614, GAN loss = [2.9189126, 1.0984296, 1.0926076]\n",
      "Batch 140/700: Discriminator loss = 1.1247165203094482, GAN loss = [2.8242984, 1.0993785, 0.99704325]\n",
      "Batch 141/700: Discriminator loss = 1.1392039060592651, GAN loss = [2.9264092, 1.0491815, 1.149357]\n",
      "Batch 142/700: Discriminator loss = 1.1326804161071777, GAN loss = [2.8357997, 1.0667843, 1.0411147]\n",
      "Batch 143/700: Discriminator loss = 1.115179419517517, GAN loss = [3.0488157, 1.0893179, 1.2315923]\n",
      "Batch 144/700: Discriminator loss = 1.1595525741577148, GAN loss = [2.8881145, 1.0948342, 1.0653615]\n",
      "Batch 145/700: Discriminator loss = 1.151759147644043, GAN loss = [2.969982, 1.1001923, 1.1418788]\n",
      "Batch 146/700: Discriminator loss = 1.0982365608215332, GAN loss = [2.883622, 1.0820093, 1.0737009]\n",
      "Batch 147/700: Discriminator loss = 1.134329915046692, GAN loss = [2.8882818, 1.01763, 1.1427592]\n",
      "Batch 148/700: Discriminator loss = 1.1224843263626099, GAN loss = [2.8059, 1.0856558, 0.99237496]\n",
      "Batch 149/700: Discriminator loss = 1.1572074890136719, GAN loss = [2.88831, 1.0489652, 1.1115167]\n",
      "Batch 150/700: Discriminator loss = 1.1683038473129272, GAN loss = [2.8019915, 1.020059, 1.05414]\n",
      "Batch 151/700: Discriminator loss = 1.1123098134994507, GAN loss = [2.99163, 1.064187, 1.1996876]\n",
      "Batch 152/700: Discriminator loss = 1.1334196329116821, GAN loss = [2.9250238, 1.0536171, 1.1436917]\n",
      "Batch 153/700: Discriminator loss = 1.1424164772033691, GAN loss = [2.9248683, 1.050672, 1.1465153]\n",
      "Batch 154/700: Discriminator loss = 1.0767182111740112, GAN loss = [2.9176414, 1.1448102, 1.0451738]\n",
      "Batch 155/700: Discriminator loss = 1.089403510093689, GAN loss = [3.0556595, 1.117738, 1.2102808]\n",
      "Batch 156/700: Discriminator loss = 1.1276171207427979, GAN loss = [2.9364235, 1.0553811, 1.1534134]\n",
      "Batch 157/700: Discriminator loss = 1.1185413599014282, GAN loss = [2.958137, 1.0770494, 1.153479]\n",
      "Batch 158/700: Discriminator loss = 1.0879757404327393, GAN loss = [3.019753, 1.0902772, 1.201876]\n",
      "Batch 159/700: Discriminator loss = 1.1407443284988403, GAN loss = [2.8690393, 1.0153563, 1.126082]\n",
      "Batch 160/700: Discriminator loss = 1.0773897171020508, GAN loss = [2.996621, 1.1107274, 1.1583056]\n",
      "Batch 161/700: Discriminator loss = 1.1651378870010376, GAN loss = [2.9612153, 1.0534495, 1.1801827]\n",
      "Batch 162/700: Discriminator loss = 1.125861644744873, GAN loss = [2.9539866, 1.062471, 1.1639711]\n",
      "Batch 163/700: Discriminator loss = 1.139946699142456, GAN loss = [2.9676685, 1.0781872, 1.1619594]\n",
      "Batch 164/700: Discriminator loss = 1.109498381614685, GAN loss = [3.015682, 1.1131405, 1.1750256]\n",
      "Batch 165/700: Discriminator loss = 1.1140198707580566, GAN loss = [2.883747, 1.0457376, 1.1104993]\n",
      "Batch 166/700: Discriminator loss = 1.1358919143676758, GAN loss = [2.9443798, 1.0706124, 1.1462673]\n",
      "Batch 167/700: Discriminator loss = 1.1107633113861084, GAN loss = [3.0446687, 1.1209048, 1.196259]\n",
      "Batch 168/700: Discriminator loss = 1.0747889280319214, GAN loss = [2.9373345, 1.1212792, 1.0885377]\n",
      "Batch 169/700: Discriminator loss = 1.118756890296936, GAN loss = [3.0111446, 1.0823444, 1.201284]\n",
      "Batch 170/700: Discriminator loss = 1.1057393550872803, GAN loss = [2.9910183, 1.1032566, 1.1602411]\n",
      "Batch 171/700: Discriminator loss = 1.1285213232040405, GAN loss = [2.8666697, 1.050135, 1.0890191]\n",
      "Batch 172/700: Discriminator loss = 1.1409361362457275, GAN loss = [2.9544518, 1.0488849, 1.178049]\n",
      "Batch 173/700: Discriminator loss = 1.1569945812225342, GAN loss = [2.8515491, 1.0446442, 1.0793722]\n",
      "Batch 174/700: Discriminator loss = 1.163770318031311, GAN loss = [2.902396, 1.0667021, 1.1081446]\n",
      "Batch 175/700: Discriminator loss = 1.14889395236969, GAN loss = [2.934359, 1.097285, 1.1095121]\n",
      "Batch 176/700: Discriminator loss = 1.1156587600708008, GAN loss = [2.9271584, 1.1055318, 1.0940688]\n",
      "Batch 177/700: Discriminator loss = 1.1247451305389404, GAN loss = [2.9205, 1.0959985, 1.0969418]\n",
      "Batch 178/700: Discriminator loss = 1.1890208721160889, GAN loss = [2.9912682, 1.0772157, 1.1864814]\n",
      "Batch 179/700: Discriminator loss = 1.1032894849777222, GAN loss = [2.950731, 1.1060029, 1.1171438]\n",
      "Batch 180/700: Discriminator loss = 1.1404001712799072, GAN loss = [2.9683383, 1.0749483, 1.1658326]\n",
      "Batch 181/700: Discriminator loss = 1.1061760187149048, GAN loss = [2.9326503, 1.082036, 1.1230844]\n",
      "Batch 182/700: Discriminator loss = 1.1373263597488403, GAN loss = [2.8295789, 1.0381837, 1.0638719]\n",
      "Batch 183/700: Discriminator loss = 1.1059635877609253, GAN loss = [2.9696662, 1.1019361, 1.1402155]\n",
      "Batch 184/700: Discriminator loss = 1.1779676675796509, GAN loss = [2.8383985, 0.9950893, 1.115813]\n",
      "Batch 185/700: Discriminator loss = 1.1385996341705322, GAN loss = [3.0781102, 1.071936, 1.278684]\n",
      "Batch 186/700: Discriminator loss = 1.1430127620697021, GAN loss = [2.9281416, 1.0373348, 1.1633251]\n",
      "Batch 187/700: Discriminator loss = 1.1312317848205566, GAN loss = [2.8861797, 1.0514547, 1.1072716]\n",
      "Batch 188/700: Discriminator loss = 1.1735788583755493, GAN loss = [2.8061666, 1.0149574, 1.0637732]\n",
      "Batch 189/700: Discriminator loss = 1.1210589408874512, GAN loss = [2.9668217, 1.0889307, 1.1504656]\n",
      "Batch 190/700: Discriminator loss = 1.1412185430526733, GAN loss = [2.987893, 1.0901767, 1.170316]\n",
      "Batch 191/700: Discriminator loss = 1.1863913536071777, GAN loss = [2.8829184, 1.0634077, 1.0921417]\n",
      "Batch 192/700: Discriminator loss = 1.1045223474502563, GAN loss = [2.8748286, 1.1061535, 1.0413337]\n",
      "Batch 193/700: Discriminator loss = 1.143821358680725, GAN loss = [3.0043557, 1.0539134, 1.2231221]\n",
      "Batch 194/700: Discriminator loss = 1.115281343460083, GAN loss = [2.976463, 1.0669578, 1.1822098]\n",
      "Batch 195/700: Discriminator loss = 1.1355249881744385, GAN loss = [2.9855444, 1.0692046, 1.1890737]\n",
      "Batch 196/700: Discriminator loss = 1.1459769010543823, GAN loss = [2.8944678, 1.0782459, 1.088971]\n",
      "Batch 197/700: Discriminator loss = 1.1487624645233154, GAN loss = [2.9122434, 1.0441158, 1.1408924]\n",
      "Batch 198/700: Discriminator loss = 1.156889796257019, GAN loss = [2.788163, 1.0232764, 1.037681]\n",
      "Batch 199/700: Discriminator loss = 1.1072615385055542, GAN loss = [2.9954784, 1.0826671, 1.1856408]\n",
      "Batch 200/700: Discriminator loss = 1.0980167388916016, GAN loss = [3.0508037, 1.09061, 1.2330291]\n",
      "Batch 201/700: Discriminator loss = 1.1050615310668945, GAN loss = [2.973379, 1.090391, 1.1558381]\n",
      "Batch 202/700: Discriminator loss = 1.131197214126587, GAN loss = [2.9125776, 1.0494294, 1.1360093]\n",
      "Batch 203/700: Discriminator loss = 1.1164699792861938, GAN loss = [3.1021018, 1.0948721, 1.2801161]\n",
      "Batch 204/700: Discriminator loss = 1.1062787771224976, GAN loss = [3.0489104, 1.0717224, 1.2500786]\n",
      "Batch 205/700: Discriminator loss = 1.1160438060760498, GAN loss = [3.0552588, 1.1325142, 1.1956398]\n",
      "Batch 206/700: Discriminator loss = 1.1036916971206665, GAN loss = [3.1166732, 1.1162722, 1.2733098]\n",
      "Batch 207/700: Discriminator loss = 1.1078588962554932, GAN loss = [2.9829617, 1.0778476, 1.1780277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 208/700: Discriminator loss = 1.1000587940216064, GAN loss = [2.9843786, 1.0648588, 1.192455]\n",
      "Batch 209/700: Discriminator loss = 1.116244912147522, GAN loss = [3.0366342, 1.0829982, 1.2265751]\n",
      "Batch 210/700: Discriminator loss = 1.0827513933181763, GAN loss = [2.9972093, 1.0860101, 1.1841251]\n",
      "Batch 211/700: Discriminator loss = 1.1176152229309082, GAN loss = [3.037323, 1.0698043, 1.2404305]\n",
      "Batch 212/700: Discriminator loss = 1.2016234397888184, GAN loss = [2.905975, 1.0270532, 1.1518468]\n",
      "Batch 213/700: Discriminator loss = 1.0825082063674927, GAN loss = [3.1367748, 1.1058075, 1.3039075]\n",
      "Batch 214/700: Discriminator loss = 1.0881214141845703, GAN loss = [3.0108917, 1.1185435, 1.1652931]\n",
      "Batch 215/700: Discriminator loss = 1.1255701780319214, GAN loss = [2.972084, 1.0640694, 1.1809754]\n",
      "Batch 216/700: Discriminator loss = 1.1035785675048828, GAN loss = [3.0678797, 1.0538847, 1.2869502]\n",
      "Batch 217/700: Discriminator loss = 1.154486894607544, GAN loss = [2.9401934, 1.0617577, 1.1513984]\n",
      "Batch 218/700: Discriminator loss = 1.1415605545043945, GAN loss = [2.9597623, 1.0712216, 1.1615036]\n",
      "Batch 219/700: Discriminator loss = 1.0925838947296143, GAN loss = [3.1218688, 1.1091378, 1.285682]\n",
      "Batch 220/700: Discriminator loss = 1.0783777236938477, GAN loss = [3.0128958, 1.1304263, 1.1554012]\n",
      "Batch 221/700: Discriminator loss = 1.081409215927124, GAN loss = [3.1597192, 1.1405411, 1.2921017]\n",
      "Batch 222/700: Discriminator loss = 1.0892456769943237, GAN loss = [3.0498784, 1.1262143, 1.1965952]\n",
      "Batch 223/700: Discriminator loss = 1.1537930965423584, GAN loss = [3.0777726, 1.097882, 1.2528262]\n",
      "Batch 224/700: Discriminator loss = 1.070581078529358, GAN loss = [3.25003, 1.2028561, 1.3201225]\n",
      "Batch 225/700: Discriminator loss = 1.116298794746399, GAN loss = [3.1590486, 1.1421995, 1.2897981]\n",
      "Batch 226/700: Discriminator loss = 1.1306884288787842, GAN loss = [2.9872606, 1.1330001, 1.1272126]\n",
      "Batch 227/700: Discriminator loss = 1.0950945615768433, GAN loss = [3.0550773, 1.1640338, 1.1640209]\n",
      "Batch 228/700: Discriminator loss = 1.0779976844787598, GAN loss = [3.1229742, 1.1433736, 1.2525951]\n",
      "Batch 229/700: Discriminator loss = 1.101591944694519, GAN loss = [3.1169412, 1.1490155, 1.2409416]\n",
      "Batch 230/700: Discriminator loss = 1.1480108499526978, GAN loss = [3.1027398, 1.1362195, 1.2395552]\n",
      "Batch 231/700: Discriminator loss = 1.0934377908706665, GAN loss = [3.1231847, 1.1388035, 1.2574178]\n",
      "Batch 232/700: Discriminator loss = 1.097664713859558, GAN loss = [3.1888447, 1.1255748, 1.336311]\n",
      "Batch 233/700: Discriminator loss = 1.1188693046569824, GAN loss = [3.0917583, 1.1025313, 1.262284]\n",
      "Batch 234/700: Discriminator loss = 1.1412426233291626, GAN loss = [3.0625472, 1.0748748, 1.2607479]\n",
      "Batch 235/700: Discriminator loss = 1.1513912677764893, GAN loss = [2.930452, 1.0672247, 1.1363306]\n",
      "Batch 236/700: Discriminator loss = 1.1266283988952637, GAN loss = [3.005347, 1.0693702, 1.2091172]\n",
      "Batch 237/700: Discriminator loss = 1.1790213584899902, GAN loss = [2.9512553, 1.0584441, 1.165974]\n",
      "Batch 238/700: Discriminator loss = 1.1245847940444946, GAN loss = [2.935938, 1.060991, 1.1481355]\n",
      "Batch 239/700: Discriminator loss = 1.1559991836547852, GAN loss = [2.99994, 1.1224171, 1.1507325]\n",
      "Batch 240/700: Discriminator loss = 1.2008392810821533, GAN loss = [2.8954618, 1.04365, 1.1250442]\n",
      "Batch 241/700: Discriminator loss = 1.0980440378189087, GAN loss = [3.1114106, 1.1073347, 1.2773418]\n",
      "Batch 242/700: Discriminator loss = 1.1618491411209106, GAN loss = [2.8788106, 1.0235599, 1.1285335]\n",
      "Batch 243/700: Discriminator loss = 1.1609814167022705, GAN loss = [2.9058464, 1.0492797, 1.1298664]\n",
      "Batch 244/700: Discriminator loss = 1.1707763671875, GAN loss = [2.9176114, 1.045307, 1.1456146]\n",
      "Batch 245/700: Discriminator loss = 1.091828465461731, GAN loss = [2.987138, 1.0866135, 1.1738691]\n",
      "Batch 246/700: Discriminator loss = 1.110877513885498, GAN loss = [3.0518463, 1.083265, 1.2419573]\n",
      "Batch 247/700: Discriminator loss = 1.1123948097229004, GAN loss = [2.9921603, 1.1086702, 1.1569024]\n",
      "Batch 248/700: Discriminator loss = 1.076305627822876, GAN loss = [2.9765987, 1.1184914, 1.1315465]\n",
      "Batch 249/700: Discriminator loss = 1.1194043159484863, GAN loss = [2.9095058, 1.0648386, 1.118141]\n",
      "Batch 250/700: Discriminator loss = 1.1009490489959717, GAN loss = [3.0079157, 1.0905434, 1.190864]\n",
      "Batch 251/700: Discriminator loss = 1.15562105178833, GAN loss = [2.8666487, 1.0526307, 1.0875149]\n",
      "Batch 252/700: Discriminator loss = 1.1522514820098877, GAN loss = [2.917902, 1.0386229, 1.1528047]\n",
      "Batch 253/700: Discriminator loss = 1.0827018022537231, GAN loss = [2.9988692, 1.132163, 1.1402622]\n",
      "Batch 254/700: Discriminator loss = 1.151079535484314, GAN loss = [2.8576329, 1.0587865, 1.0724216]\n",
      "Batch 255/700: Discriminator loss = 1.1218318939208984, GAN loss = [2.9233112, 1.0411795, 1.1557391]\n",
      "Batch 256/700: Discriminator loss = 1.1347988843917847, GAN loss = [2.9082837, 1.0258768, 1.1560366]\n",
      "Batch 257/700: Discriminator loss = 1.0846943855285645, GAN loss = [2.8855834, 1.1021578, 1.0570775]\n",
      "Batch 258/700: Discriminator loss = 1.1480222940444946, GAN loss = [2.8713162, 1.0443736, 1.1006153]\n",
      "Batch 259/700: Discriminator loss = 1.0748727321624756, GAN loss = [3.1780457, 1.1295846, 1.3221496]\n",
      "Batch 260/700: Discriminator loss = 1.1326442956924438, GAN loss = [2.904765, 1.0834875, 1.0949894]\n",
      "Batch 261/700: Discriminator loss = 1.1572015285491943, GAN loss = [2.787695, 1.0177627, 1.0436792]\n",
      "Batch 262/700: Discriminator loss = 1.0899102687835693, GAN loss = [3.0417314, 1.1038356, 1.2116638]\n",
      "Batch 263/700: Discriminator loss = 1.1049017906188965, GAN loss = [2.8566163, 1.0733701, 1.0570533]\n",
      "Batch 264/700: Discriminator loss = 1.1742042303085327, GAN loss = [2.956279, 1.0416771, 1.1884464]\n",
      "Batch 265/700: Discriminator loss = 1.1290110349655151, GAN loss = [2.9002209, 1.0627673, 1.1113304]\n",
      "Batch 266/700: Discriminator loss = 1.113632082939148, GAN loss = [2.9929028, 1.1068373, 1.1599523]\n",
      "Batch 267/700: Discriminator loss = 1.121492862701416, GAN loss = [2.9049242, 1.0571398, 1.1216838]\n",
      "Batch 268/700: Discriminator loss = 1.147100567817688, GAN loss = [2.9151003, 1.0914043, 1.0976206]\n",
      "Batch 269/700: Discriminator loss = 1.114159345626831, GAN loss = [3.0264518, 1.0834479, 1.2169398]\n",
      "Batch 270/700: Discriminator loss = 1.1502065658569336, GAN loss = [2.9208317, 1.0572051, 1.137572]\n",
      "Batch 271/700: Discriminator loss = 1.1435856819152832, GAN loss = [2.7680664, 1.0115159, 1.0305017]\n",
      "Batch 272/700: Discriminator loss = 1.1851234436035156, GAN loss = [2.909889, 1.0342673, 1.149578]\n",
      "Batch 273/700: Discriminator loss = 1.1313024759292603, GAN loss = [2.903388, 1.0614703, 1.1158853]\n",
      "Batch 274/700: Discriminator loss = 1.212127447128296, GAN loss = [2.935765, 1.0231706, 1.18659]\n",
      "Batch 275/700: Discriminator loss = 1.0958141088485718, GAN loss = [2.9791906, 1.1035035, 1.1497142]\n",
      "Batch 276/700: Discriminator loss = 1.1530519723892212, GAN loss = [2.8843682, 1.0370823, 1.1213192]\n",
      "Batch 277/700: Discriminator loss = 1.1017252206802368, GAN loss = [2.9495008, 1.0980473, 1.125493]\n",
      "Batch 278/700: Discriminator loss = 1.0507049560546875, GAN loss = [3.1300473, 1.1584806, 1.2456249]\n",
      "Batch 279/700: Discriminator loss = 1.0961992740631104, GAN loss = [3.0509322, 1.1201091, 1.2049282]\n",
      "Batch 280/700: Discriminator loss = 1.0771337747573853, GAN loss = [3.053221, 1.1417962, 1.1855706]\n",
      "Batch 281/700: Discriminator loss = 1.1141092777252197, GAN loss = [2.9888005, 1.096138, 1.1668507]\n",
      "Batch 282/700: Discriminator loss = 1.1122651100158691, GAN loss = [3.033713, 1.0796437, 1.2282842]\n",
      "Batch 283/700: Discriminator loss = 1.124794363975525, GAN loss = [2.9778655, 1.0946163, 1.1575007]\n",
      "Batch 284/700: Discriminator loss = 1.1111023426055908, GAN loss = [2.9586065, 1.1147759, 1.1181163]\n",
      "Batch 285/700: Discriminator loss = 1.1147735118865967, GAN loss = [3.002067, 1.0827186, 1.1936646]\n",
      "Batch 286/700: Discriminator loss = 1.1043150424957275, GAN loss = [2.8538563, 1.0640459, 1.0641633]\n",
      "Batch 287/700: Discriminator loss = 1.117323398590088, GAN loss = [3.0380607, 1.077651, 1.2348062]\n",
      "Batch 288/700: Discriminator loss = 1.1501580476760864, GAN loss = [2.9930522, 1.0898268, 1.1776445]\n",
      "Batch 289/700: Discriminator loss = 1.0953348875045776, GAN loss = [3.1254573, 1.1206154, 1.2792852]\n",
      "Batch 290/700: Discriminator loss = 1.1061474084854126, GAN loss = [2.9345655, 1.0880685, 1.120964]\n",
      "Batch 291/700: Discriminator loss = 1.1429393291473389, GAN loss = [2.8594902, 1.0551102, 1.0788664]\n",
      "Batch 292/700: Discriminator loss = 1.1390283107757568, GAN loss = [2.9633944, 1.0590607, 1.1788399]\n",
      "Batch 293/700: Discriminator loss = 1.1536785364151, GAN loss = [2.9578059, 1.0225586, 1.2097777]\n",
      "Batch 294/700: Discriminator loss = 1.1178972721099854, GAN loss = [3.0432684, 1.0674007, 1.250421]\n",
      "Batch 295/700: Discriminator loss = 1.1324268579483032, GAN loss = [2.9716885, 1.0546331, 1.1916394]\n",
      "Batch 296/700: Discriminator loss = 1.077060341835022, GAN loss = [3.0797486, 1.1024939, 1.2518563]\n",
      "Batch 297/700: Discriminator loss = 1.1070482730865479, GAN loss = [3.12317, 1.0525234, 1.3452654]\n",
      "Batch 298/700: Discriminator loss = 1.155726432800293, GAN loss = [2.8766234, 0.9898867, 1.1613612]\n",
      "Batch 299/700: Discriminator loss = 1.0941349267959595, GAN loss = [2.9980717, 1.0889177, 1.1837742]\n",
      "Batch 300/700: Discriminator loss = 1.1276949644088745, GAN loss = [2.9797738, 1.0842624, 1.1701255]\n",
      "Batch 301/700: Discriminator loss = 1.1020684242248535, GAN loss = [3.0057273, 1.0833455, 1.1969695]\n",
      "Batch 302/700: Discriminator loss = 1.126226782798767, GAN loss = [3.0561619, 1.0719087, 1.2588135]\n",
      "Batch 303/700: Discriminator loss = 1.1643989086151123, GAN loss = [2.9715183, 1.0130228, 1.2330267]\n",
      "Batch 304/700: Discriminator loss = 1.125045895576477, GAN loss = [3.000482, 1.0299104, 1.2450993]\n",
      "Batch 305/700: Discriminator loss = 1.1253832578659058, GAN loss = [2.9766018, 1.0441208, 1.2070191]\n",
      "Batch 306/700: Discriminator loss = 1.154444694519043, GAN loss = [3.0225935, 1.0152391, 1.2819029]\n",
      "Batch 307/700: Discriminator loss = 1.1083006858825684, GAN loss = [3.0219433, 1.0512751, 1.2452269]\n",
      "Batch 308/700: Discriminator loss = 1.118106484413147, GAN loss = [3.0030844, 1.0753802, 1.2022724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 309/700: Discriminator loss = 1.1180685758590698, GAN loss = [3.044776, 1.0645362, 1.2548094]\n",
      "Batch 310/700: Discriminator loss = 1.1244899034500122, GAN loss = [2.996985, 1.0469851, 1.2245919]\n",
      "Batch 311/700: Discriminator loss = 1.1427206993103027, GAN loss = [3.0631747, 1.044545, 1.2932478]\n",
      "Batch 312/700: Discriminator loss = 1.1654682159423828, GAN loss = [2.8973238, 1.0620059, 1.1099648]\n",
      "Batch 313/700: Discriminator loss = 1.1172257661819458, GAN loss = [2.9605892, 1.0796149, 1.1556381]\n",
      "Batch 314/700: Discriminator loss = 1.1618231534957886, GAN loss = [3.0761073, 1.0542594, 1.2965285]\n",
      "Batch 315/700: Discriminator loss = 1.1022690534591675, GAN loss = [3.0020761, 1.0747769, 1.2020009]\n",
      "Batch 316/700: Discriminator loss = 1.1103973388671875, GAN loss = [3.0285714, 1.0716629, 1.2316364]\n",
      "Batch 317/700: Discriminator loss = 1.0923908948898315, GAN loss = [3.0093505, 1.0810714, 1.2030278]\n",
      "Batch 318/700: Discriminator loss = 1.0945159196853638, GAN loss = [3.1211827, 1.0993124, 1.2966346]\n",
      "Batch 319/700: Discriminator loss = 1.1487078666687012, GAN loss = [3.131377, 1.063155, 1.3429937]\n",
      "Batch 320/700: Discriminator loss = 1.1166446208953857, GAN loss = [3.12038, 1.1082531, 1.2869132]\n",
      "Batch 321/700: Discriminator loss = 1.1100351810455322, GAN loss = [3.0198724, 1.0951911, 1.1994907]\n",
      "Batch 322/700: Discriminator loss = 1.1257987022399902, GAN loss = [2.9664648, 1.0521559, 1.1891263]\n",
      "Batch 323/700: Discriminator loss = 1.1427671909332275, GAN loss = [2.9215374, 1.0238147, 1.1725487]\n",
      "Batch 324/700: Discriminator loss = 1.1205581426620483, GAN loss = [2.9971805, 1.0495751, 1.2224339]\n",
      "Batch 325/700: Discriminator loss = 1.1505601406097412, GAN loss = [2.8403854, 1.0155225, 1.0996817]\n",
      "Batch 326/700: Discriminator loss = 1.133339285850525, GAN loss = [3.0104861, 1.033119, 1.2521973]\n",
      "Batch 327/700: Discriminator loss = 1.0941319465637207, GAN loss = [3.0496001, 1.0855353, 1.2389051]\n",
      "Batch 328/700: Discriminator loss = 1.096771001815796, GAN loss = [2.9995332, 1.0730056, 1.2013816]\n",
      "Batch 329/700: Discriminator loss = 1.1122194528579712, GAN loss = [3.0445042, 1.0668222, 1.2525424]\n",
      "Batch 330/700: Discriminator loss = 1.1775753498077393, GAN loss = [2.88268, 0.99083024, 1.1667093]\n",
      "Batch 331/700: Discriminator loss = 1.137961745262146, GAN loss = [2.9943094, 1.0851446, 1.184038]\n",
      "Batch 332/700: Discriminator loss = 1.1333321332931519, GAN loss = [2.8494766, 1.0073333, 1.1170318]\n",
      "Batch 333/700: Discriminator loss = 1.1383178234100342, GAN loss = [2.9068327, 1.0394338, 1.1423028]\n",
      "Batch 334/700: Discriminator loss = 1.1191600561141968, GAN loss = [2.84381, 1.0497202, 1.0689875]\n",
      "Batch 335/700: Discriminator loss = 1.1049503087997437, GAN loss = [2.9295907, 1.0759652, 1.1285192]\n",
      "Batch 336/700: Discriminator loss = 1.207303524017334, GAN loss = [2.8451176, 0.99430156, 1.1257253]\n",
      "Batch 337/700: Discriminator loss = 1.1928400993347168, GAN loss = [3.0412517, 1.0462581, 1.269915]\n",
      "Batch 338/700: Discriminator loss = 1.1266286373138428, GAN loss = [3.046784, 1.0777761, 1.2439373]\n",
      "Batch 339/700: Discriminator loss = 1.1656255722045898, GAN loss = [2.8320558, 1.0452541, 1.0617148]\n",
      "Batch 340/700: Discriminator loss = 1.0808416604995728, GAN loss = [3.0366158, 1.1013024, 1.2102325]\n",
      "Batch 341/700: Discriminator loss = 1.0995737314224243, GAN loss = [3.0572615, 1.0861363, 1.2460252]\n",
      "Batch 342/700: Discriminator loss = 1.0891605615615845, GAN loss = [3.198211, 1.0986422, 1.3744513]\n",
      "Batch 343/700: Discriminator loss = 1.1069881916046143, GAN loss = [3.061924, 1.0477921, 1.2889999]\n",
      "Batch 344/700: Discriminator loss = 1.1235918998718262, GAN loss = [2.966524, 1.0249796, 1.2164111]\n",
      "Batch 345/700: Discriminator loss = 1.1163411140441895, GAN loss = [2.883347, 1.0621936, 1.096017]\n",
      "Batch 346/700: Discriminator loss = 1.1280145645141602, GAN loss = [2.8735838, 1.0549543, 1.0934929]\n",
      "Batch 347/700: Discriminator loss = 1.1318079233169556, GAN loss = [2.8058634, 1.020947, 1.0597928]\n",
      "Batch 348/700: Discriminator loss = 1.1152695417404175, GAN loss = [2.9863405, 1.0676527, 1.1935866]\n",
      "Batch 349/700: Discriminator loss = 1.1203677654266357, GAN loss = [2.8872516, 1.0336089, 1.1285677]\n",
      "Batch 350/700: Discriminator loss = 1.1059097051620483, GAN loss = [2.8351512, 1.0508238, 1.0592655]\n",
      "Batch 351/700: Discriminator loss = 1.1072250604629517, GAN loss = [3.0401878, 1.0631903, 1.2519536]\n",
      "Batch 352/700: Discriminator loss = 1.1263644695281982, GAN loss = [2.999842, 1.0331199, 1.2416834]\n",
      "Batch 353/700: Discriminator loss = 1.111934781074524, GAN loss = [2.845429, 1.0501618, 1.0702225]\n",
      "Batch 354/700: Discriminator loss = 1.1026686429977417, GAN loss = [2.9589796, 1.0669265, 1.167004]\n",
      "Batch 355/700: Discriminator loss = 1.0800049304962158, GAN loss = [2.978644, 1.079269, 1.1743392]\n",
      "Batch 356/700: Discriminator loss = 1.133805751800537, GAN loss = [2.9016273, 1.0306867, 1.1459082]\n",
      "Batch 357/700: Discriminator loss = 1.1221063137054443, GAN loss = [2.8977485, 1.0261705, 1.1465493]\n",
      "Batch 358/700: Discriminator loss = 1.1176663637161255, GAN loss = [3.0178106, 1.0791385, 1.2136513]\n",
      "Batch 359/700: Discriminator loss = 1.1145610809326172, GAN loss = [2.9701884, 1.0683999, 1.1768003]\n",
      "Batch 360/700: Discriminator loss = 1.1390784978866577, GAN loss = [2.920803, 1.012797, 1.183031]\n",
      "Batch 361/700: Discriminator loss = 1.1181741952896118, GAN loss = [3.028935, 1.0517895, 1.2521846]\n",
      "Batch 362/700: Discriminator loss = 1.1329952478408813, GAN loss = [2.8788526, 1.0039295, 1.1499974]\n",
      "Batch 363/700: Discriminator loss = 1.115697979927063, GAN loss = [2.9351344, 1.0471005, 1.1631263]\n",
      "Batch 364/700: Discriminator loss = 1.1040706634521484, GAN loss = [2.9497128, 1.0405418, 1.1842843]\n",
      "Batch 365/700: Discriminator loss = 1.1259663105010986, GAN loss = [2.9498243, 1.028561, 1.1963857]\n",
      "Batch 366/700: Discriminator loss = 1.120784878730774, GAN loss = [2.8373842, 1.0185211, 1.0939919]\n",
      "Batch 367/700: Discriminator loss = 1.1055001020431519, GAN loss = [3.1171703, 1.076493, 1.315822]\n",
      "Batch 368/700: Discriminator loss = 1.1207114458084106, GAN loss = [2.9019601, 1.0312662, 1.1458502]\n",
      "Batch 369/700: Discriminator loss = 1.124324917793274, GAN loss = [2.9277663, 1.0405332, 1.1624038]\n",
      "Batch 370/700: Discriminator loss = 1.14877188205719, GAN loss = [2.8651197, 1.0419645, 1.0983407]\n",
      "Batch 371/700: Discriminator loss = 1.1236931085586548, GAN loss = [2.9704795, 1.0396255, 1.2060448]\n",
      "Batch 372/700: Discriminator loss = 1.126942753791809, GAN loss = [2.9280574, 1.0336913, 1.1695603]\n",
      "Batch 373/700: Discriminator loss = 1.1161344051361084, GAN loss = [3.2145004, 1.0554906, 1.4341992]\n",
      "Batch 374/700: Discriminator loss = 1.1506004333496094, GAN loss = [3.026913, 1.0059048, 1.2961948]\n",
      "Batch 375/700: Discriminator loss = 1.1126590967178345, GAN loss = [3.02304, 1.0811137, 1.2170992]\n",
      "Batch 376/700: Discriminator loss = 1.1235594749450684, GAN loss = [3.132905, 1.1092875, 1.2987665]\n",
      "Batch 377/700: Discriminator loss = 1.1104042530059814, GAN loss = [3.025368, 1.105126, 1.1953688]\n",
      "Batch 378/700: Discriminator loss = 1.1392927169799805, GAN loss = [2.9168847, 1.0324234, 1.1595837]\n",
      "Batch 379/700: Discriminator loss = 1.1052961349487305, GAN loss = [3.002857, 1.0632039, 1.214754]\n",
      "Batch 380/700: Discriminator loss = 1.152915596961975, GAN loss = [2.9036849, 1.0024388, 1.1763412]\n",
      "Batch 381/700: Discriminator loss = 1.100499153137207, GAN loss = [2.9121535, 1.0476135, 1.1396297]\n",
      "Batch 382/700: Discriminator loss = 1.0997616052627563, GAN loss = [2.8781996, 1.0347463, 1.1185397]\n",
      "Batch 383/700: Discriminator loss = 1.137819766998291, GAN loss = [3.046857, 1.0050071, 1.3169469]\n",
      "Batch 384/700: Discriminator loss = 1.1321051120758057, GAN loss = [2.9884305, 1.0486648, 1.2148583]\n",
      "Batch 385/700: Discriminator loss = 1.0965399742126465, GAN loss = [3.0061061, 1.0706816, 1.2105194]\n",
      "Batch 386/700: Discriminator loss = 1.1236820220947266, GAN loss = [2.9027584, 1.0453181, 1.1325362]\n",
      "Batch 387/700: Discriminator loss = 1.133075475692749, GAN loss = [2.9493263, 1.0511955, 1.1732225]\n",
      "Batch 388/700: Discriminator loss = 1.11270272731781, GAN loss = [3.0589256, 1.050466, 1.283559]\n",
      "Batch 389/700: Discriminator loss = 1.0852197408676147, GAN loss = [3.0212197, 1.0784982, 1.217826]\n",
      "Batch 390/700: Discriminator loss = 1.1969252824783325, GAN loss = [2.8031604, 0.96733546, 1.1109465]\n",
      "Batch 391/700: Discriminator loss = 1.1270256042480469, GAN loss = [3.1620698, 1.0646715, 1.3725438]\n",
      "Batch 392/700: Discriminator loss = 1.1508270502090454, GAN loss = [3.0185847, 1.0443609, 1.2493868]\n",
      "Batch 393/700: Discriminator loss = 1.1054999828338623, GAN loss = [2.9873984, 1.0748712, 1.1877028]\n",
      "Batch 394/700: Discriminator loss = 1.0992066860198975, GAN loss = [3.0451167, 1.0669838, 1.2533182]\n",
      "Batch 395/700: Discriminator loss = 1.0630691051483154, GAN loss = [2.8884888, 1.0793128, 1.0843608]\n",
      "Batch 396/700: Discriminator loss = 1.0986278057098389, GAN loss = [2.9890332, 1.042531, 1.2216845]\n",
      "Batch 397/700: Discriminator loss = 1.1460336446762085, GAN loss = [2.9817228, 1.0429686, 1.2139386]\n",
      "Batch 398/700: Discriminator loss = 1.1267147064208984, GAN loss = [3.0742035, 1.1301132, 1.2192802]\n",
      "Batch 399/700: Discriminator loss = 1.1656168699264526, GAN loss = [2.8448246, 1.0398141, 1.0802083]\n",
      "Batch 400/700: Discriminator loss = 1.1208516359329224, GAN loss = [2.919006, 1.092557, 1.1016517]\n",
      "Batch 401/700: Discriminator loss = 1.1626110076904297, GAN loss = [2.8649702, 1.0305768, 1.1096213]\n",
      "Batch 402/700: Discriminator loss = 1.1451358795166016, GAN loss = [2.8996885, 1.0552738, 1.1196741]\n",
      "Batch 403/700: Discriminator loss = 1.1796011924743652, GAN loss = [2.8352628, 0.9985893, 1.1119317]\n",
      "Batch 404/700: Discriminator loss = 1.1831289529800415, GAN loss = [2.8777406, 0.9810758, 1.1719071]\n",
      "Batch 405/700: Discriminator loss = 1.2130441665649414, GAN loss = [2.8927708, 1.0657403, 1.1022724]\n",
      "Batch 406/700: Discriminator loss = 1.1378668546676636, GAN loss = [2.8525138, 1.033801, 1.0939796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 407/700: Discriminator loss = 1.1630003452301025, GAN loss = [2.750273, 1.0328945, 0.9926635]\n",
      "Batch 408/700: Discriminator loss = 1.1573034524917603, GAN loss = [2.8786914, 1.068072, 1.0859183]\n",
      "Batch 409/700: Discriminator loss = 1.1564992666244507, GAN loss = [2.8681176, 0.9914339, 1.1519951]\n",
      "Batch 410/700: Discriminator loss = 1.1667615175247192, GAN loss = [2.8823175, 1.0316573, 1.1259849]\n",
      "Batch 411/700: Discriminator loss = 1.144513726234436, GAN loss = [2.8581846, 1.0167394, 1.1167814]\n",
      "Batch 412/700: Discriminator loss = 1.1942901611328125, GAN loss = [2.8039544, 0.97514284, 1.1041585]\n",
      "Batch 413/700: Discriminator loss = 1.172383189201355, GAN loss = [2.802326, 1.0238336, 1.053859]\n",
      "Batch 414/700: Discriminator loss = 1.0967276096343994, GAN loss = [3.0062435, 1.0845265, 1.1971266]\n",
      "Batch 415/700: Discriminator loss = 1.1113698482513428, GAN loss = [2.8327014, 1.0014004, 1.1067456]\n",
      "Batch 416/700: Discriminator loss = 1.1740403175354004, GAN loss = [2.813649, 0.97763354, 1.1114745]\n",
      "Batch 417/700: Discriminator loss = 1.168711543083191, GAN loss = [2.8917828, 1.008359, 1.1588969]\n",
      "Batch 418/700: Discriminator loss = 1.1114481687545776, GAN loss = [2.9472778, 1.0643787, 1.1583861]\n",
      "Batch 419/700: Discriminator loss = 1.158562421798706, GAN loss = [2.9130132, 1.0229648, 1.1655461]\n",
      "Batch 420/700: Discriminator loss = 1.1209537982940674, GAN loss = [2.94578, 1.0380802, 1.1832249]\n",
      "Batch 421/700: Discriminator loss = 1.1993006467819214, GAN loss = [2.8391259, 1.0129722, 1.1017123]\n",
      "Batch 422/700: Discriminator loss = 1.1459667682647705, GAN loss = [2.8915908, 1.0087767, 1.1583884]\n",
      "Batch 423/700: Discriminator loss = 1.1710832118988037, GAN loss = [2.8803513, 1.0328975, 1.1230724]\n",
      "Batch 424/700: Discriminator loss = 1.1514230966567993, GAN loss = [2.9061427, 1.0152034, 1.1665893]\n",
      "Batch 425/700: Discriminator loss = 1.1474006175994873, GAN loss = [2.7960024, 0.98425835, 1.0874244]\n",
      "Batch 426/700: Discriminator loss = 1.080420732498169, GAN loss = [3.0537195, 1.0753441, 1.2540824]\n",
      "Batch 427/700: Discriminator loss = 1.1465647220611572, GAN loss = [2.8710475, 0.9904608, 1.1563191]\n",
      "Batch 428/700: Discriminator loss = 1.1229608058929443, GAN loss = [2.9073703, 1.0022246, 1.1809058]\n",
      "Batch 429/700: Discriminator loss = 1.1508053541183472, GAN loss = [3.0444791, 1.0175464, 1.3027053]\n",
      "Batch 430/700: Discriminator loss = 1.1614137887954712, GAN loss = [2.8377361, 1.0294131, 1.0841027]\n",
      "Batch 431/700: Discriminator loss = 1.1589787006378174, GAN loss = [2.8984447, 1.0197792, 1.1544601]\n",
      "Batch 432/700: Discriminator loss = 1.1513116359710693, GAN loss = [2.9262319, 1.0257115, 1.1763415]\n",
      "Batch 433/700: Discriminator loss = 1.1596251726150513, GAN loss = [2.905792, 1.0055256, 1.1761088]\n",
      "Batch 434/700: Discriminator loss = 1.1858006715774536, GAN loss = [2.768909, 0.96264327, 1.0821304]\n",
      "Batch 435/700: Discriminator loss = 1.1370618343353271, GAN loss = [2.854401, 0.99876803, 1.131512]\n",
      "Batch 436/700: Discriminator loss = 1.1338187456130981, GAN loss = [2.8325024, 1.0332983, 1.0750862]\n",
      "Batch 437/700: Discriminator loss = 1.1392133235931396, GAN loss = [2.9801066, 1.0504743, 1.2055202]\n",
      "Batch 438/700: Discriminator loss = 1.1400446891784668, GAN loss = [2.9150298, 1.090017, 1.1009109]\n",
      "Batch 439/700: Discriminator loss = 1.1479231119155884, GAN loss = [2.9111896, 1.0635575, 1.1235402]\n",
      "Batch 440/700: Discriminator loss = 1.1648173332214355, GAN loss = [2.9445457, 1.0211884, 1.1992791]\n",
      "Batch 441/700: Discriminator loss = 1.1509501934051514, GAN loss = [2.8724747, 1.0154898, 1.1329045]\n",
      "Batch 442/700: Discriminator loss = 1.1268012523651123, GAN loss = [2.7869203, 1.0544548, 1.0083696]\n",
      "Batch 443/700: Discriminator loss = 1.182435154914856, GAN loss = [2.7969275, 0.9674607, 1.1053593]\n",
      "Batch 444/700: Discriminator loss = 1.1596314907073975, GAN loss = [2.9228306, 0.99699175, 1.2017293]\n",
      "Batch 445/700: Discriminator loss = 1.140086054801941, GAN loss = [2.9178405, 1.031957, 1.161774]\n",
      "Batch 446/700: Discriminator loss = 1.0754482746124268, GAN loss = [2.939197, 1.0990872, 1.1160126]\n",
      "Batch 447/700: Discriminator loss = 1.1595021486282349, GAN loss = [2.798153, 1.0151794, 1.058884]\n",
      "Batch 448/700: Discriminator loss = 1.115675687789917, GAN loss = [2.9809036, 1.057811, 1.198999]\n",
      "Batch 449/700: Discriminator loss = 1.1201026439666748, GAN loss = [2.9355013, 1.0585773, 1.1528211]\n",
      "Batch 450/700: Discriminator loss = 1.1652036905288696, GAN loss = [2.9512749, 1.0215601, 1.2056056]\n",
      "Batch 451/700: Discriminator loss = 1.0555723905563354, GAN loss = [2.9664912, 1.1180394, 1.1243267]\n",
      "Batch 452/700: Discriminator loss = 1.1337575912475586, GAN loss = [2.9656749, 1.0273441, 1.2142136]\n",
      "Batch 453/700: Discriminator loss = 1.0955764055252075, GAN loss = [3.0114095, 1.0768925, 1.2103887]\n",
      "Batch 454/700: Discriminator loss = 1.1187071800231934, GAN loss = [2.9850855, 1.0393283, 1.2216374]\n",
      "Batch 455/700: Discriminator loss = 1.1461633443832397, GAN loss = [2.8816872, 1.0239856, 1.1335963]\n",
      "Batch 456/700: Discriminator loss = 1.1620829105377197, GAN loss = [2.6758628, 0.9784664, 0.9733175]\n",
      "Batch 457/700: Discriminator loss = 1.1835612058639526, GAN loss = [2.8790061, 0.9830502, 1.1719027]\n",
      "Batch 458/700: Discriminator loss = 1.1064509153366089, GAN loss = [3.0113268, 1.0640633, 1.2232301]\n",
      "Batch 459/700: Discriminator loss = 1.1119682788848877, GAN loss = [2.9017594, 1.0787414, 1.0990062]\n",
      "Batch 460/700: Discriminator loss = 1.1548237800598145, GAN loss = [2.9136121, 1.0425242, 1.1470823]\n",
      "Batch 461/700: Discriminator loss = 1.2101930379867554, GAN loss = [2.8822546, 0.9986201, 1.1596484]\n",
      "Batch 462/700: Discriminator loss = 1.0851285457611084, GAN loss = [3.1014035, 1.0824009, 1.2950252]\n",
      "Batch 463/700: Discriminator loss = 1.0602445602416992, GAN loss = [3.1314251, 1.1119918, 1.2954713]\n",
      "Batch 464/700: Discriminator loss = 1.1545088291168213, GAN loss = [2.987895, 1.0198215, 1.2441283]\n",
      "Batch 465/700: Discriminator loss = 1.1248914003372192, GAN loss = [2.983743, 1.0703256, 1.1894922]\n",
      "Batch 466/700: Discriminator loss = 1.1146128177642822, GAN loss = [3.0102515, 1.0623853, 1.2239587]\n",
      "Batch 467/700: Discriminator loss = 1.1622395515441895, GAN loss = [2.9969165, 1.0084357, 1.2645906]\n",
      "Batch 468/700: Discriminator loss = 1.1259292364120483, GAN loss = [3.139711, 1.0530671, 1.3627869]\n",
      "Batch 469/700: Discriminator loss = 1.164345383644104, GAN loss = [2.8508096, 1.0330793, 1.093887]\n",
      "Batch 470/700: Discriminator loss = 1.1333565711975098, GAN loss = [2.9264417, 1.0442123, 1.1583997]\n",
      "Batch 471/700: Discriminator loss = 1.1011462211608887, GAN loss = [3.1302829, 1.1024537, 1.3040116]\n",
      "Batch 472/700: Discriminator loss = 1.1435784101486206, GAN loss = [2.9788232, 1.0470524, 1.2079568]\n",
      "Batch 473/700: Discriminator loss = 1.117647647857666, GAN loss = [2.9655018, 1.0452038, 1.1964846]\n",
      "Batch 474/700: Discriminator loss = 1.157482385635376, GAN loss = [3.056158, 1.0323812, 1.2999763]\n",
      "Batch 475/700: Discriminator loss = 1.1477543115615845, GAN loss = [2.999289, 1.069335, 1.2061816]\n",
      "Batch 476/700: Discriminator loss = 1.116681694984436, GAN loss = [3.0133085, 1.1059072, 1.1836187]\n",
      "Batch 477/700: Discriminator loss = 1.1138312816619873, GAN loss = [3.0530932, 1.0456437, 1.2836772]\n",
      "Batch 478/700: Discriminator loss = 1.083495855331421, GAN loss = [3.0690458, 1.1224736, 1.2228162]\n",
      "Batch 479/700: Discriminator loss = 1.1045114994049072, GAN loss = [2.968662, 1.0549883, 1.1899194]\n",
      "Batch 480/700: Discriminator loss = 1.1188606023788452, GAN loss = [2.9077985, 1.0782099, 1.105842]\n",
      "Batch 481/700: Discriminator loss = 1.1354217529296875, GAN loss = [2.8261812, 1.062361, 1.0400878]\n",
      "Batch 482/700: Discriminator loss = 1.1931036710739136, GAN loss = [2.780605, 1.0123295, 1.0445502]\n",
      "Batch 483/700: Discriminator loss = 1.197149395942688, GAN loss = [2.718851, 0.98986244, 1.0052526]\n",
      "Batch 484/700: Discriminator loss = 1.1382337808609009, GAN loss = [2.8586745, 1.0294849, 1.1054672]\n",
      "Batch 485/700: Discriminator loss = 1.1654478311538696, GAN loss = [2.8349555, 1.0279875, 1.0832546]\n",
      "Batch 486/700: Discriminator loss = 1.1828043460845947, GAN loss = [2.8628573, 1.0085455, 1.1306136]\n",
      "Batch 487/700: Discriminator loss = 1.1498030424118042, GAN loss = [2.9105709, 1.054258, 1.1326172]\n",
      "Batch 488/700: Discriminator loss = 1.1367496252059937, GAN loss = [2.898357, 1.0446637, 1.1300162]\n",
      "Batch 489/700: Discriminator loss = 1.1131831407546997, GAN loss = [2.9397578, 1.0787829, 1.1373034]\n",
      "Batch 490/700: Discriminator loss = 1.1624162197113037, GAN loss = [2.9447374, 1.0533491, 1.1677357]\n",
      "Batch 491/700: Discriminator loss = 1.1327180862426758, GAN loss = [2.9597151, 1.0555695, 1.180532]\n",
      "Batch 492/700: Discriminator loss = 1.0806019306182861, GAN loss = [3.0774844, 1.0764108, 1.2774813]\n",
      "Batch 493/700: Discriminator loss = 1.1486369371414185, GAN loss = [2.9115367, 1.0042489, 1.1837163]\n",
      "Batch 494/700: Discriminator loss = 1.143383264541626, GAN loss = [2.8866804, 1.0424207, 1.1206923]\n",
      "Batch 495/700: Discriminator loss = 1.1388076543807983, GAN loss = [3.0005846, 1.0381861, 1.2388523]\n",
      "Batch 496/700: Discriminator loss = 1.1222254037857056, GAN loss = [2.942976, 1.049192, 1.1702588]\n",
      "Batch 497/700: Discriminator loss = 1.1655869483947754, GAN loss = [2.822611, 1.0008203, 1.0982795]\n",
      "Batch 498/700: Discriminator loss = 1.139978289604187, GAN loss = [2.9730802, 1.0682635, 1.1813179]\n",
      "Batch 499/700: Discriminator loss = 1.1730996370315552, GAN loss = [2.8469167, 1.0283492, 1.095082]\n",
      "Batch 500/700: Discriminator loss = 1.0947980880737305, GAN loss = [3.0055327, 1.0860382, 1.1959965]\n",
      "Batch 501/700: Discriminator loss = 1.1732797622680664, GAN loss = [2.725567, 0.9892887, 1.0127679]\n",
      "Batch 502/700: Discriminator loss = 1.1368703842163086, GAN loss = [2.8200982, 1.0339868, 1.0625892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 503/700: Discriminator loss = 1.172308087348938, GAN loss = [2.7778952, 0.9922459, 1.0621225]\n",
      "Batch 504/700: Discriminator loss = 1.174373984336853, GAN loss = [2.834501, 1.0128597, 1.0981063]\n",
      "Batch 505/700: Discriminator loss = 1.1434142589569092, GAN loss = [2.9187336, 1.0119518, 1.1832482]\n",
      "Batch 506/700: Discriminator loss = 1.1615146398544312, GAN loss = [2.7722676, 1.0490551, 0.9996844]\n",
      "Batch 507/700: Discriminator loss = 1.1616981029510498, GAN loss = [2.9005566, 1.0463376, 1.1306969]\n",
      "Batch 508/700: Discriminator loss = 1.087286353111267, GAN loss = [3.0159404, 1.0822735, 1.2101489]\n",
      "Batch 509/700: Discriminator loss = 1.1073503494262695, GAN loss = [2.9570367, 1.063977, 1.1695379]\n",
      "Batch 510/700: Discriminator loss = 1.125617265701294, GAN loss = [2.8848245, 1.0272487, 1.1340443]\n",
      "Batch 511/700: Discriminator loss = 1.1816959381103516, GAN loss = [2.7482092, 0.9953015, 1.029369]\n",
      "Batch 512/700: Discriminator loss = 1.184881567955017, GAN loss = [2.9014478, 1.0161316, 1.1617743]\n",
      "Batch 513/700: Discriminator loss = 1.1298564672470093, GAN loss = [2.854681, 1.0032843, 1.1278558]\n",
      "Batch 514/700: Discriminator loss = 1.1741876602172852, GAN loss = [2.9346707, 1.0220397, 1.1890849]\n",
      "Batch 515/700: Discriminator loss = 1.1561694145202637, GAN loss = [2.8753593, 1.0205766, 1.1312277]\n",
      "Batch 516/700: Discriminator loss = 1.1387101411819458, GAN loss = [2.8869798, 1.0479509, 1.1154759]\n",
      "Batch 517/700: Discriminator loss = 1.1594518423080444, GAN loss = [2.7849944, 1.0236821, 1.0377635]\n",
      "Batch 518/700: Discriminator loss = 1.147965908050537, GAN loss = [2.7591374, 1.0283275, 1.0072421]\n",
      "Batch 519/700: Discriminator loss = 1.1553436517715454, GAN loss = [2.9068663, 1.0549418, 1.1283404]\n",
      "Batch 520/700: Discriminator loss = 1.1505051851272583, GAN loss = [2.8238616, 1.0588409, 1.0414345]\n",
      "Batch 521/700: Discriminator loss = 1.2279589176177979, GAN loss = [2.7721632, 1.0081208, 1.0404465]\n",
      "Batch 522/700: Discriminator loss = 1.1565808057785034, GAN loss = [2.892237, 1.0737473, 1.0948708]\n",
      "Batch 523/700: Discriminator loss = 1.1280421018600464, GAN loss = [2.8157718, 1.0421171, 1.0500116]\n",
      "Batch 524/700: Discriminator loss = 1.147736668586731, GAN loss = [2.8448818, 1.0335839, 1.0876464]\n",
      "Batch 525/700: Discriminator loss = 1.1595004796981812, GAN loss = [2.877248, 1.0417699, 1.1118072]\n",
      "Batch 526/700: Discriminator loss = 1.143432378768921, GAN loss = [2.8988698, 1.0318289, 1.1433406]\n",
      "Batch 527/700: Discriminator loss = 1.1297340393066406, GAN loss = [2.8757699, 1.051493, 1.1005498]\n",
      "Batch 528/700: Discriminator loss = 1.1495261192321777, GAN loss = [2.958447, 1.0542207, 1.1804882]\n",
      "Batch 529/700: Discriminator loss = 1.093346357345581, GAN loss = [2.9227085, 1.0790122, 1.1199654]\n",
      "Batch 530/700: Discriminator loss = 1.1420782804489136, GAN loss = [2.9154332, 1.0373822, 1.1543282]\n",
      "Batch 531/700: Discriminator loss = 1.1042799949645996, GAN loss = [2.9911826, 1.0480441, 1.2194171]\n",
      "Batch 532/700: Discriminator loss = 1.1650049686431885, GAN loss = [2.7907677, 0.9997727, 1.0672812]\n",
      "Batch 533/700: Discriminator loss = 1.123987078666687, GAN loss = [2.9346116, 1.0545065, 1.156403]\n",
      "Batch 534/700: Discriminator loss = 1.0816781520843506, GAN loss = [2.8468885, 1.0629302, 1.0602579]\n",
      "Batch 535/700: Discriminator loss = 1.1576331853866577, GAN loss = [2.9495087, 0.9984242, 1.2273847]\n",
      "Batch 536/700: Discriminator loss = 1.1011604070663452, GAN loss = [3.1458013, 1.0838127, 1.3382971]\n",
      "Batch 537/700: Discriminator loss = 1.111560583114624, GAN loss = [3.0093787, 1.0530863, 1.2326093]\n",
      "Batch 538/700: Discriminator loss = 1.127339243888855, GAN loss = [2.9446883, 1.0397536, 1.1812546]\n",
      "Batch 539/700: Discriminator loss = 1.1697781085968018, GAN loss = [2.9585054, 1.0290977, 1.205714]\n",
      "Batch 540/700: Discriminator loss = 1.1550148725509644, GAN loss = [2.9305458, 1.0119066, 1.1949515]\n",
      "Batch 541/700: Discriminator loss = 1.1140248775482178, GAN loss = [3.1571984, 1.0466406, 1.3868725]\n",
      "Batch 542/700: Discriminator loss = 1.1078845262527466, GAN loss = [2.9262698, 1.0463748, 1.1561975]\n",
      "Batch 543/700: Discriminator loss = 1.1390966176986694, GAN loss = [2.978291, 1.0095603, 1.2450111]\n",
      "Batch 544/700: Discriminator loss = 1.0971306562423706, GAN loss = [3.0154545, 1.0941954, 1.1975298]\n",
      "Batch 545/700: Discriminator loss = 1.214882254600525, GAN loss = [2.8148918, 0.9762909, 1.1148666]\n",
      "Batch 546/700: Discriminator loss = 1.18562912940979, GAN loss = [2.9112594, 0.9735445, 1.2139813]\n",
      "Batch 547/700: Discriminator loss = 1.1878300905227661, GAN loss = [2.7519326, 1.0199919, 1.0082191]\n",
      "Batch 548/700: Discriminator loss = 1.164170503616333, GAN loss = [2.8050613, 1.028156, 1.053191]\n",
      "Batch 549/700: Discriminator loss = 1.1174525022506714, GAN loss = [2.821197, 1.0567008, 1.0407653]\n",
      "Batch 550/700: Discriminator loss = 1.1676656007766724, GAN loss = [2.9356844, 1.0176232, 1.1942868]\n",
      "Batch 551/700: Discriminator loss = 1.1545956134796143, GAN loss = [2.8405974, 1.0319314, 1.0848576]\n",
      "Batch 552/700: Discriminator loss = 1.1676342487335205, GAN loss = [2.818312, 0.99323934, 1.1012496]\n",
      "Batch 553/700: Discriminator loss = 1.1442068815231323, GAN loss = [2.9604273, 1.047008, 1.1895937]\n",
      "Batch 554/700: Discriminator loss = 1.1744937896728516, GAN loss = [2.7757201, 1.0075984, 1.0442889]\n",
      "Batch 555/700: Discriminator loss = 1.1260602474212646, GAN loss = [3.0265563, 1.117347, 1.1853619]\n",
      "Batch 556/700: Discriminator loss = 1.1655806303024292, GAN loss = [2.8513064, 1.0232323, 1.1042279]\n",
      "Batch 557/700: Discriminator loss = 1.1058151721954346, GAN loss = [3.0271993, 1.1116407, 1.1917192]\n",
      "Batch 558/700: Discriminator loss = 1.150120496749878, GAN loss = [2.90524, 1.0304844, 1.1509061]\n",
      "Batch 559/700: Discriminator loss = 1.162880778312683, GAN loss = [2.8791597, 1.0111133, 1.1441976]\n",
      "Batch 560/700: Discriminator loss = 1.1601320505142212, GAN loss = [2.8481162, 1.0330038, 1.0912697]\n",
      "Batch 561/700: Discriminator loss = 1.158898949623108, GAN loss = [2.943754, 1.0105914, 1.2093433]\n",
      "Batch 562/700: Discriminator loss = 1.1341561079025269, GAN loss = [2.9017708, 1.0148188, 1.1631372]\n",
      "Batch 563/700: Discriminator loss = 1.1608026027679443, GAN loss = [3.0804145, 1.0211984, 1.3354063]\n",
      "Batch 564/700: Discriminator loss = 1.1865993738174438, GAN loss = [2.987443, 1.002944, 1.2606988]\n",
      "Batch 565/700: Discriminator loss = 1.1344624757766724, GAN loss = [2.946697, 1.0650979, 1.1578408]\n",
      "Batch 566/700: Discriminator loss = 1.0894746780395508, GAN loss = [3.0602095, 1.1160498, 1.2204428]\n",
      "Batch 567/700: Discriminator loss = 1.0652544498443604, GAN loss = [2.9943748, 1.0930433, 1.1776426]\n",
      "Batch 568/700: Discriminator loss = 1.087480068206787, GAN loss = [2.964657, 1.0952893, 1.1456925]\n",
      "Batch 569/700: Discriminator loss = 1.1534771919250488, GAN loss = [2.9089737, 1.0122242, 1.1730953]\n",
      "Batch 570/700: Discriminator loss = 1.0998106002807617, GAN loss = [3.1204846, 1.10522, 1.2916185]\n",
      "Batch 571/700: Discriminator loss = 1.1180977821350098, GAN loss = [3.096575, 1.1034523, 1.2694916]\n",
      "Batch 572/700: Discriminator loss = 1.105843186378479, GAN loss = [2.9347236, 1.0665479, 1.1445711]\n",
      "Batch 573/700: Discriminator loss = 1.1172491312026978, GAN loss = [2.8999348, 1.0761381, 1.1002258]\n",
      "Batch 574/700: Discriminator loss = 1.1238561868667603, GAN loss = [2.954496, 1.0758312, 1.1551231]\n",
      "Batch 575/700: Discriminator loss = 1.0897092819213867, GAN loss = [2.964347, 1.1055708, 1.1352718]\n",
      "Batch 576/700: Discriminator loss = 1.1256073713302612, GAN loss = [2.9510329, 1.0613582, 1.1661936]\n",
      "Batch 577/700: Discriminator loss = 1.1602970361709595, GAN loss = [2.9932086, 1.0835248, 1.186229]\n",
      "Batch 578/700: Discriminator loss = 1.1409399509429932, GAN loss = [2.87111, 1.075295, 1.0723965]\n",
      "Batch 579/700: Discriminator loss = 1.1180428266525269, GAN loss = [2.8639889, 1.104855, 1.0357488]\n",
      "Batch 580/700: Discriminator loss = 1.1670432090759277, GAN loss = [2.8019557, 1.034946, 1.0436591]\n",
      "Batch 581/700: Discriminator loss = 1.0987995862960815, GAN loss = [3.001805, 1.0843631, 1.1941003]\n",
      "Batch 582/700: Discriminator loss = 1.1418735980987549, GAN loss = [2.8935792, 1.056504, 1.1137421]\n",
      "Batch 583/700: Discriminator loss = 1.0842304229736328, GAN loss = [3.0354896, 1.1055346, 1.2066208]\n",
      "Batch 584/700: Discriminator loss = 1.1177539825439453, GAN loss = [2.9485147, 1.0731549, 1.1520467]\n",
      "Batch 585/700: Discriminator loss = 1.1587659120559692, GAN loss = [2.9206924, 1.074099, 1.1233153]\n",
      "Batch 586/700: Discriminator loss = 1.0930770635604858, GAN loss = [2.943587, 1.0749325, 1.1454065]\n",
      "Batch 587/700: Discriminator loss = 1.0925648212432861, GAN loss = [2.9767406, 1.1053253, 1.1481943]\n",
      "Batch 588/700: Discriminator loss = 1.1941379308700562, GAN loss = [2.8689098, 1.0279123, 1.1177995]\n",
      "Batch 589/700: Discriminator loss = 1.134495735168457, GAN loss = [2.8261058, 1.0608816, 1.0420612]\n",
      "Batch 590/700: Discriminator loss = 1.081652283668518, GAN loss = [3.096994, 1.1260277, 1.2478054]\n",
      "Batch 591/700: Discriminator loss = 1.1342295408248901, GAN loss = [2.9112318, 1.0916853, 1.0963755]\n",
      "Batch 592/700: Discriminator loss = 1.1703263521194458, GAN loss = [2.9693506, 1.0355904, 1.2105873]\n",
      "Batch 593/700: Discriminator loss = 1.1068246364593506, GAN loss = [3.0444472, 1.1031364, 1.218152]\n",
      "Batch 594/700: Discriminator loss = 1.1378610134124756, GAN loss = [2.8353608, 1.0333765, 1.0788463]\n",
      "Batch 595/700: Discriminator loss = 1.1195268630981445, GAN loss = [2.88599, 1.0612822, 1.101585]\n",
      "Batch 596/700: Discriminator loss = 1.1345815658569336, GAN loss = [2.8150897, 1.0554227, 1.0365608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 597/700: Discriminator loss = 1.1683138608932495, GAN loss = [2.8634567, 1.0637418, 1.0766089]\n",
      "Batch 598/700: Discriminator loss = 1.1475706100463867, GAN loss = [2.9428954, 1.0370498, 1.1827292]\n",
      "Batch 599/700: Discriminator loss = 1.1270725727081299, GAN loss = [2.9737597, 1.0777661, 1.1728673]\n",
      "Batch 600/700: Discriminator loss = 1.1153309345245361, GAN loss = [2.9005077, 1.0746489, 1.1027173]\n",
      "Batch 601/700: Discriminator loss = 1.127868413925171, GAN loss = [2.9100766, 1.0625317, 1.1244218]\n",
      "Batch 602/700: Discriminator loss = 1.1256635189056396, GAN loss = [2.9074264, 1.0594009, 1.124941]\n",
      "Batch 603/700: Discriminator loss = 1.1168522834777832, GAN loss = [2.880263, 1.0787002, 1.0784922]\n",
      "Batch 604/700: Discriminator loss = 1.1496108770370483, GAN loss = [2.8911474, 1.080616, 1.0874671]\n",
      "Batch 605/700: Discriminator loss = 1.1599445343017578, GAN loss = [2.8404465, 0.99241275, 1.1249775]\n",
      "Batch 606/700: Discriminator loss = 1.164275050163269, GAN loss = [2.859134, 1.0306418, 1.1054435]\n",
      "Batch 607/700: Discriminator loss = 1.175585389137268, GAN loss = [2.8747897, 1.0403566, 1.1113814]\n",
      "Batch 608/700: Discriminator loss = 1.146931529045105, GAN loss = [2.9014347, 1.0567313, 1.1216636]\n",
      "Batch 609/700: Discriminator loss = 1.115020513534546, GAN loss = [3.0219536, 1.10286, 1.1960667]\n",
      "Batch 610/700: Discriminator loss = 1.1012136936187744, GAN loss = [2.8854003, 1.0797073, 1.0826882]\n",
      "Batch 611/700: Discriminator loss = 1.1208385229110718, GAN loss = [2.8565648, 1.0585784, 1.0750017]\n",
      "Batch 612/700: Discriminator loss = 1.1647512912750244, GAN loss = [2.830195, 1.0432458, 1.0640091]\n",
      "Batch 613/700: Discriminator loss = 1.1283998489379883, GAN loss = [2.9973931, 1.0710568, 1.2034218]\n",
      "Batch 614/700: Discriminator loss = 1.0999705791473389, GAN loss = [3.0333345, 1.0993075, 1.2111334]\n",
      "Batch 615/700: Discriminator loss = 1.0832886695861816, GAN loss = [3.0184581, 1.1019479, 1.1936407]\n",
      "Batch 616/700: Discriminator loss = 1.1419494152069092, GAN loss = [2.9210887, 1.0332258, 1.1650108]\n",
      "Batch 617/700: Discriminator loss = 1.1052790880203247, GAN loss = [2.9281893, 1.0699503, 1.1354012]\n",
      "Batch 618/700: Discriminator loss = 1.1616029739379883, GAN loss = [2.9548805, 1.0308981, 1.2011536]\n",
      "Batch 619/700: Discriminator loss = 1.1392300128936768, GAN loss = [2.9703548, 1.0571898, 1.1903552]\n",
      "Batch 620/700: Discriminator loss = 1.1306359767913818, GAN loss = [2.8620584, 1.0904354, 1.0488497]\n",
      "Batch 621/700: Discriminator loss = 1.1026345491409302, GAN loss = [3.0335343, 1.0640755, 1.2466998]\n",
      "Batch 622/700: Discriminator loss = 1.1257554292678833, GAN loss = [2.932271, 1.1144031, 1.0951188]\n",
      "Batch 623/700: Discriminator loss = 1.1181148290634155, GAN loss = [2.9125798, 1.0608902, 1.1289741]\n",
      "Batch 624/700: Discriminator loss = 1.1348968744277954, GAN loss = [3.004714, 1.0787708, 1.2032585]\n",
      "Batch 625/700: Discriminator loss = 1.1478052139282227, GAN loss = [2.9833858, 1.056571, 1.204163]\n",
      "Batch 626/700: Discriminator loss = 1.095925211906433, GAN loss = [2.8712986, 1.0883621, 1.0603046]\n",
      "Batch 627/700: Discriminator loss = 1.0943773984909058, GAN loss = [3.0332038, 1.1041788, 1.2064068]\n",
      "Batch 628/700: Discriminator loss = 1.1349409818649292, GAN loss = [2.9768236, 1.0729659, 1.1812564]\n",
      "Batch 629/700: Discriminator loss = 1.0969243049621582, GAN loss = [2.9235976, 1.0537536, 1.1472553]\n",
      "Batch 630/700: Discriminator loss = 1.1288981437683105, GAN loss = [2.8817744, 1.0181392, 1.1410675]\n",
      "Batch 631/700: Discriminator loss = 1.1298723220825195, GAN loss = [3.0422306, 1.0757397, 1.2439489]\n",
      "Batch 632/700: Discriminator loss = 1.1343820095062256, GAN loss = [2.93464, 1.0618477, 1.1502712]\n",
      "Batch 633/700: Discriminator loss = 1.0955655574798584, GAN loss = [2.9696088, 1.0958351, 1.151275]\n",
      "Batch 634/700: Discriminator loss = 1.135450005531311, GAN loss = [3.0002337, 1.0443012, 1.2334372]\n",
      "Batch 635/700: Discriminator loss = 1.1442519426345825, GAN loss = [2.937145, 1.0658197, 1.1488299]\n",
      "Batch 636/700: Discriminator loss = 1.12730872631073, GAN loss = [2.890099, 1.0672283, 1.1003828]\n",
      "Batch 637/700: Discriminator loss = 1.1307711601257324, GAN loss = [2.8815627, 1.0521076, 1.1069715]\n",
      "Batch 638/700: Discriminator loss = 1.1141371726989746, GAN loss = [3.015484, 1.1083486, 1.1846615]\n",
      "Batch 639/700: Discriminator loss = 1.1207693815231323, GAN loss = [3.0138972, 1.0828838, 1.2085723]\n",
      "Batch 640/700: Discriminator loss = 1.15839421749115, GAN loss = [2.81714, 1.0744015, 1.020318]\n",
      "Batch 641/700: Discriminator loss = 1.1117603778839111, GAN loss = [2.8528552, 1.0581274, 1.0723095]\n",
      "Batch 642/700: Discriminator loss = 1.1571077108383179, GAN loss = [2.7585387, 1.032995, 1.0031208]\n",
      "Batch 643/700: Discriminator loss = 1.1444742679595947, GAN loss = [2.876378, 1.0634048, 1.0905393]\n",
      "Batch 644/700: Discriminator loss = 1.1346766948699951, GAN loss = [2.9070415, 1.0533226, 1.1312742]\n",
      "Batch 645/700: Discriminator loss = 1.118747591972351, GAN loss = [3.059633, 1.0688531, 1.268334]\n",
      "Batch 646/700: Discriminator loss = 1.1119351387023926, GAN loss = [3.062369, 1.0948722, 1.2450532]\n",
      "Batch 647/700: Discriminator loss = 1.13248610496521, GAN loss = [2.9426575, 1.0521078, 1.1681185]\n",
      "Batch 648/700: Discriminator loss = 1.1084727048873901, GAN loss = [3.01202, 1.0833386, 1.2062497]\n",
      "Batch 649/700: Discriminator loss = 1.1521140336990356, GAN loss = [2.941581, 1.0346749, 1.1844703]\n",
      "Batch 650/700: Discriminator loss = 1.1132241487503052, GAN loss = [3.0280929, 1.0860428, 1.2196034]\n",
      "Batch 651/700: Discriminator loss = 1.1514869928359985, GAN loss = [2.9187684, 1.0416176, 1.1546884]\n",
      "Batch 652/700: Discriminator loss = 1.1114041805267334, GAN loss = [2.9305124, 1.0575467, 1.1504899]\n",
      "Batch 653/700: Discriminator loss = 1.1702065467834473, GAN loss = [2.9138684, 1.0214506, 1.169949]\n",
      "Batch 654/700: Discriminator loss = 1.1352505683898926, GAN loss = [2.8613744, 1.0352399, 1.1036708]\n",
      "Batch 655/700: Discriminator loss = 1.178167462348938, GAN loss = [2.8679636, 1.0297716, 1.1157324]\n",
      "Batch 656/700: Discriminator loss = 1.1272211074829102, GAN loss = [2.9588308, 1.0896312, 1.1467521]\n",
      "Batch 657/700: Discriminator loss = 1.0925674438476562, GAN loss = [2.890767, 1.0613751, 1.1069571]\n",
      "Batch 658/700: Discriminator loss = 1.1193181276321411, GAN loss = [2.9974077, 1.0600132, 1.2149485]\n",
      "Batch 659/700: Discriminator loss = 1.1091824769973755, GAN loss = [2.9781547, 1.1070408, 1.1486622]\n",
      "Batch 660/700: Discriminator loss = 1.1108450889587402, GAN loss = [2.9231215, 1.029612, 1.1710525]\n",
      "Batch 661/700: Discriminator loss = 1.116703748703003, GAN loss = [2.9532006, 1.0393686, 1.1913778]\n",
      "Batch 662/700: Discriminator loss = 1.1360775232315063, GAN loss = [2.8450387, 1.0200065, 1.1025684]\n",
      "Batch 663/700: Discriminator loss = 1.144146203994751, GAN loss = [3.0033376, 1.0303904, 1.250482]\n",
      "Batch 664/700: Discriminator loss = 1.1147644519805908, GAN loss = [2.995135, 1.0730897, 1.1995856]\n",
      "Batch 665/700: Discriminator loss = 1.0923426151275635, GAN loss = [2.9434366, 1.0665784, 1.154411]\n",
      "Batch 666/700: Discriminator loss = 1.152466058731079, GAN loss = [2.8965914, 1.0383269, 1.1358192]\n",
      "Batch 667/700: Discriminator loss = 1.105122685432434, GAN loss = [3.0012112, 1.0354904, 1.2433013]\n",
      "Batch 668/700: Discriminator loss = 1.1271262168884277, GAN loss = [2.9796083, 1.0652394, 1.1919603]\n",
      "Batch 669/700: Discriminator loss = 1.1199984550476074, GAN loss = [2.9048843, 1.0452486, 1.1372439]\n",
      "Batch 670/700: Discriminator loss = 1.1674708127975464, GAN loss = [2.8647354, 0.99682647, 1.1455376]\n",
      "Batch 671/700: Discriminator loss = 1.146600365638733, GAN loss = [2.860995, 1.0482649, 1.0903702]\n",
      "Batch 672/700: Discriminator loss = 1.126318097114563, GAN loss = [3.0020268, 1.0567522, 1.2229387]\n",
      "Batch 673/700: Discriminator loss = 1.126505732536316, GAN loss = [2.954414, 1.0454544, 1.186617]\n",
      "Batch 674/700: Discriminator loss = 1.1433874368667603, GAN loss = [2.8626502, 1.0343187, 1.1059694]\n",
      "Batch 675/700: Discriminator loss = 1.1430511474609375, GAN loss = [2.96609, 1.0578438, 1.1858873]\n",
      "Batch 676/700: Discriminator loss = 1.1083840131759644, GAN loss = [2.9918077, 1.0550723, 1.2143698]\n",
      "Batch 677/700: Discriminator loss = 1.1420135498046875, GAN loss = [2.8600545, 1.0327935, 1.1048976]\n",
      "Batch 678/700: Discriminator loss = 1.1230504512786865, GAN loss = [2.8430495, 1.0013924, 1.1192886]\n",
      "Batch 679/700: Discriminator loss = 1.0925663709640503, GAN loss = [2.9260204, 1.06241, 1.1412572]\n",
      "Batch 680/700: Discriminator loss = 1.1055244207382202, GAN loss = [3.0253212, 1.0574977, 1.2454644]\n",
      "Batch 681/700: Discriminator loss = 1.1303304433822632, GAN loss = [3.039325, 1.0406247, 1.2763442]\n",
      "Batch 682/700: Discriminator loss = 1.1088680028915405, GAN loss = [2.988672, 1.0684407, 1.1978809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 683/700: Discriminator loss = 1.1188161373138428, GAN loss = [3.146982, 1.0323846, 1.3922334]\n",
      "Batch 684/700: Discriminator loss = 1.1563928127288818, GAN loss = [2.8075264, 1.0184834, 1.0666904]\n",
      "Batch 685/700: Discriminator loss = 1.1172479391098022, GAN loss = [3.0145054, 1.0512215, 1.2409307]\n",
      "Batch 686/700: Discriminator loss = 1.1321909427642822, GAN loss = [2.9637923, 1.0665156, 1.1749156]\n",
      "Batch 687/700: Discriminator loss = 1.1006053686141968, GAN loss = [3.086404, 1.0666817, 1.2973443]\n",
      "Batch 688/700: Discriminator loss = 1.1567953824996948, GAN loss = [2.9375827, 0.9885868, 1.2265849]\n",
      "Batch 689/700: Discriminator loss = 1.0862244367599487, GAN loss = [3.0004392, 1.0414245, 1.2365936]\n",
      "Batch 690/700: Discriminator loss = 1.1195212602615356, GAN loss = [2.9310951, 1.0336689, 1.1749983]\n",
      "Batch 691/700: Discriminator loss = 1.1102789640426636, GAN loss = [3.0256655, 1.0473876, 1.2558576]\n",
      "Batch 692/700: Discriminator loss = 1.1246980428695679, GAN loss = [2.9896758, 1.0400674, 1.2272002]\n",
      "Batch 693/700: Discriminator loss = 1.1318696737289429, GAN loss = [3.0467632, 1.0675855, 1.2567884]\n",
      "Batch 694/700: Discriminator loss = 1.1528445482254028, GAN loss = [2.9912965, 1.0509636, 1.2179624]\n",
      "Batch 695/700: Discriminator loss = 1.1336053609848022, GAN loss = [2.9318752, 1.0401055, 1.1694187]\n",
      "Batch 696/700: Discriminator loss = 1.1339647769927979, GAN loss = [2.9594893, 1.0383079, 1.1988502]\n",
      "Batch 697/700: Discriminator loss = 1.1136093139648438, GAN loss = [3.0248535, 1.0563279, 1.2462151]\n",
      "Batch 698/700: Discriminator loss = 1.1514792442321777, GAN loss = [2.9353342, 1.0114805, 1.2015576]\n",
      "Batch 699/700: Discriminator loss = 1.1365317106246948, GAN loss = [2.966841, 1.0293694, 1.215192]\n",
      "Batch 700/700: Discriminator loss = 1.1634259223937988, GAN loss = [2.8273396, 1.0080738, 1.0970181]\n",
      "Epoch 14/30\n",
      "Batch 1/700: Discriminator loss = 1.1254804134368896, GAN loss = [2.9629767, 1.0198443, 1.2209134]\n",
      "Batch 2/700: Discriminator loss = 1.1191065311431885, GAN loss = [2.9065845, 1.0365055, 1.147889]\n",
      "Batch 3/700: Discriminator loss = 1.1509366035461426, GAN loss = [2.854781, 1.0149146, 1.117678]\n",
      "Batch 4/700: Discriminator loss = 1.1590378284454346, GAN loss = [2.8553157, 0.9689043, 1.1642251]\n",
      "Batch 5/700: Discriminator loss = 1.1682701110839844, GAN loss = [2.8066216, 1.0022415, 1.0822057]\n",
      "Batch 6/700: Discriminator loss = 1.2528116703033447, GAN loss = [2.9759572, 1.0237696, 1.2300339]\n",
      "Batch 7/700: Discriminator loss = 1.0861501693725586, GAN loss = [2.9832287, 1.0475339, 1.2135763]\n",
      "Batch 8/700: Discriminator loss = 1.1524314880371094, GAN loss = [2.824789, 0.9967297, 1.1059675]\n",
      "Batch 9/700: Discriminator loss = 1.1089422702789307, GAN loss = [2.9265044, 1.0549996, 1.1494288]\n",
      "Batch 10/700: Discriminator loss = 1.166436791419983, GAN loss = [2.9175928, 1.0073551, 1.1881808]\n",
      "Batch 11/700: Discriminator loss = 1.098256230354309, GAN loss = [3.0308104, 1.0636551, 1.2451122]\n",
      "Batch 12/700: Discriminator loss = 1.1289945840835571, GAN loss = [3.0177462, 1.0480696, 1.2476274]\n",
      "Batch 13/700: Discriminator loss = 1.1756340265274048, GAN loss = [2.829969, 0.98790205, 1.1200399]\n",
      "Batch 14/700: Discriminator loss = 1.2246745824813843, GAN loss = [2.6796758, 0.9802096, 0.9774597]\n",
      "Batch 15/700: Discriminator loss = 1.1682169437408447, GAN loss = [2.8523688, 1.0608244, 1.0695567]\n",
      "Batch 16/700: Discriminator loss = 1.1612391471862793, GAN loss = [2.8250234, 1.0435593, 1.0594953]\n",
      "Batch 17/700: Discriminator loss = 1.2285606861114502, GAN loss = [2.703028, 0.9523214, 1.0287561]\n",
      "Batch 18/700: Discriminator loss = 1.1546931266784668, GAN loss = [2.8258333, 1.039755, 1.064139]\n",
      "Batch 19/700: Discriminator loss = 1.133480191230774, GAN loss = [2.692357, 1.0423851, 0.92803156]\n",
      "Batch 20/700: Discriminator loss = 1.1337281465530396, GAN loss = [2.906985, 1.0869238, 1.0981194]\n",
      "Batch 21/700: Discriminator loss = 1.1679952144622803, GAN loss = [2.9262733, 1.0683385, 1.135987]\n",
      "Batch 22/700: Discriminator loss = 1.1678664684295654, GAN loss = [2.827298, 1.0300338, 1.0753105]\n",
      "Batch 23/700: Discriminator loss = 1.148935079574585, GAN loss = [2.9065266, 1.110633, 1.0739491]\n",
      "Batch 24/700: Discriminator loss = 1.1571077108383179, GAN loss = [2.8428488, 1.0799494, 1.0409646]\n",
      "Batch 25/700: Discriminator loss = 1.1429747343063354, GAN loss = [3.0247371, 1.0774372, 1.2253797]\n",
      "Batch 26/700: Discriminator loss = 1.1304596662521362, GAN loss = [2.860853, 1.0494205, 1.0895205]\n",
      "Batch 27/700: Discriminator loss = 1.1407955884933472, GAN loss = [2.9364007, 1.081859, 1.13266]\n",
      "Batch 28/700: Discriminator loss = 1.2043068408966064, GAN loss = [2.737402, 1.0178165, 0.9977125]\n",
      "Batch 29/700: Discriminator loss = 1.1862133741378784, GAN loss = [2.8219743, 1.0164714, 1.0836335]\n",
      "Batch 30/700: Discriminator loss = 1.163293480873108, GAN loss = [2.890768, 1.0906684, 1.0782378]\n",
      "Batch 31/700: Discriminator loss = 1.1817697286605835, GAN loss = [2.8331158, 1.0634358, 1.0478196]\n",
      "Batch 32/700: Discriminator loss = 1.1429979801177979, GAN loss = [2.9142225, 1.0822827, 1.1100931]\n",
      "Batch 33/700: Discriminator loss = 1.1363719701766968, GAN loss = [2.81913, 1.0746009, 1.0226976]\n",
      "Batch 34/700: Discriminator loss = 1.171280860900879, GAN loss = [2.857087, 1.0547953, 1.0804756]\n",
      "Batch 35/700: Discriminator loss = 1.1413829326629639, GAN loss = [2.7940154, 1.0688977, 1.0033128]\n",
      "Batch 36/700: Discriminator loss = 1.1737512350082397, GAN loss = [2.7106624, 1.0206634, 0.9682017]\n",
      "Batch 37/700: Discriminator loss = 1.1939282417297363, GAN loss = [2.9026787, 1.0545237, 1.1263782]\n",
      "Batch 38/700: Discriminator loss = 1.1532282829284668, GAN loss = [2.8196006, 1.0238671, 1.0739691]\n",
      "Batch 39/700: Discriminator loss = 1.1201080083847046, GAN loss = [2.8319285, 1.037812, 1.0723678]\n",
      "Batch 40/700: Discriminator loss = 1.1299163103103638, GAN loss = [2.8867776, 1.0590737, 1.1059644]\n",
      "Batch 41/700: Discriminator loss = 1.1329890489578247, GAN loss = [2.9034066, 1.0583798, 1.1232944]\n",
      "Batch 42/700: Discriminator loss = 1.182854413986206, GAN loss = [2.8893328, 1.0526962, 1.1149288]\n",
      "Batch 43/700: Discriminator loss = 1.116394281387329, GAN loss = [2.8590648, 1.0775267, 1.0598518]\n",
      "Batch 44/700: Discriminator loss = 1.1542887687683105, GAN loss = [2.8341386, 1.0429379, 1.0695333]\n",
      "Batch 45/700: Discriminator loss = 1.0863646268844604, GAN loss = [2.9923425, 1.1032994, 1.167378]\n",
      "Batch 46/700: Discriminator loss = 1.1811169385910034, GAN loss = [2.8694055, 1.0122793, 1.1354667]\n",
      "Batch 47/700: Discriminator loss = 1.1929569244384766, GAN loss = [2.707142, 0.9933121, 0.99217385]\n",
      "Batch 48/700: Discriminator loss = 1.1056891679763794, GAN loss = [2.8787355, 1.0684152, 1.0886749]\n",
      "Batch 49/700: Discriminator loss = 1.1596125364303589, GAN loss = [2.8285215, 1.0252767, 1.0815946]\n",
      "Batch 50/700: Discriminator loss = 1.1961688995361328, GAN loss = [2.7297192, 1.017624, 0.99046224]\n",
      "Batch 51/700: Discriminator loss = 1.1609410047531128, GAN loss = [2.9164336, 1.0509716, 1.1438437]\n",
      "Batch 52/700: Discriminator loss = 1.0966557264328003, GAN loss = [2.9427001, 1.0893267, 1.1317631]\n",
      "Batch 53/700: Discriminator loss = 1.1103096008300781, GAN loss = [2.9363806, 1.0801259, 1.1346371]\n",
      "Batch 54/700: Discriminator loss = 1.1490471363067627, GAN loss = [2.9564383, 1.0729268, 1.1619004]\n",
      "Batch 55/700: Discriminator loss = 1.0967233180999756, GAN loss = [2.853375, 1.0626347, 1.0691495]\n",
      "Batch 56/700: Discriminator loss = 1.1584532260894775, GAN loss = [2.806826, 1.0122017, 1.0730479]\n",
      "Batch 57/700: Discriminator loss = 1.1653660535812378, GAN loss = [2.7967474, 1.0317719, 1.043412]\n",
      "Batch 58/700: Discriminator loss = 1.1339980363845825, GAN loss = [2.8538742, 1.0460252, 1.0863036]\n",
      "Batch 59/700: Discriminator loss = 1.0925108194351196, GAN loss = [2.9533405, 1.0628037, 1.1689981]\n",
      "Batch 60/700: Discriminator loss = 1.127773642539978, GAN loss = [2.855097, 1.074802, 1.0587525]\n",
      "Batch 61/700: Discriminator loss = 1.175666093826294, GAN loss = [2.8417227, 0.9904053, 1.129807]\n",
      "Batch 62/700: Discriminator loss = 1.1373789310455322, GAN loss = [2.9474096, 1.0240067, 1.2019271]\n",
      "Batch 63/700: Discriminator loss = 1.1151421070098877, GAN loss = [3.073799, 1.0902191, 1.2621411]\n",
      "Batch 64/700: Discriminator loss = 1.1121536493301392, GAN loss = [3.1121876, 1.08102, 1.309741]\n",
      "Batch 65/700: Discriminator loss = 1.0996357202529907, GAN loss = [2.952756, 1.070849, 1.1605008]\n",
      "Batch 66/700: Discriminator loss = 1.1304028034210205, GAN loss = [2.9536016, 1.0201263, 1.2120924]\n",
      "Batch 67/700: Discriminator loss = 1.114728331565857, GAN loss = [2.9972496, 1.0511988, 1.2246917]\n",
      "Batch 68/700: Discriminator loss = 1.1055793762207031, GAN loss = [3.0125332, 1.0674399, 1.2237635]\n",
      "Batch 69/700: Discriminator loss = 1.1461989879608154, GAN loss = [2.9644167, 1.1181366, 1.1249709]\n",
      "Batch 70/700: Discriminator loss = 1.0766462087631226, GAN loss = [3.057395, 1.078637, 1.2574719]\n",
      "Batch 71/700: Discriminator loss = 1.1067715883255005, GAN loss = [2.8749056, 1.0700195, 1.0836148]\n",
      "Batch 72/700: Discriminator loss = 1.1196931600570679, GAN loss = [2.9214182, 1.0466958, 1.15346]\n",
      "Batch 73/700: Discriminator loss = 1.1405588388442993, GAN loss = [2.8284335, 1.0540624, 1.0531301]\n",
      "Batch 74/700: Discriminator loss = 1.1415470838546753, GAN loss = [2.8561823, 1.0034696, 1.1314974]\n",
      "Batch 75/700: Discriminator loss = 1.1096657514572144, GAN loss = [2.9376485, 1.0486598, 1.167808]\n",
      "Batch 76/700: Discriminator loss = 1.1495177745819092, GAN loss = [2.7793086, 1.0289445, 1.0292014]\n",
      "Batch 77/700: Discriminator loss = 1.0985918045043945, GAN loss = [2.9052484, 1.0356531, 1.1484505]\n",
      "Batch 78/700: Discriminator loss = 1.1125010251998901, GAN loss = [2.9631534, 1.0272483, 1.2147865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 79/700: Discriminator loss = 1.106712818145752, GAN loss = [2.9571428, 1.086165, 1.149869]\n",
      "Batch 80/700: Discriminator loss = 1.1230309009552002, GAN loss = [2.9683654, 1.0243511, 1.2229252]\n",
      "Batch 81/700: Discriminator loss = 1.1463451385498047, GAN loss = [2.9733198, 1.0278401, 1.2243925]\n",
      "Batch 82/700: Discriminator loss = 1.1526384353637695, GAN loss = [2.8059561, 0.99836546, 1.0865134]\n",
      "Batch 83/700: Discriminator loss = 1.150570034980774, GAN loss = [2.9028082, 1.0485789, 1.13316]\n",
      "Batch 84/700: Discriminator loss = 1.1611113548278809, GAN loss = [2.7773948, 1.0081909, 1.0481408]\n",
      "Batch 85/700: Discriminator loss = 1.1351505517959595, GAN loss = [2.976627, 1.0232806, 1.2323095]\n",
      "Batch 86/700: Discriminator loss = 1.1501860618591309, GAN loss = [2.9021735, 1.0419137, 1.1392442]\n",
      "Batch 87/700: Discriminator loss = 1.146992564201355, GAN loss = [2.9106295, 1.0593803, 1.1302537]\n",
      "Batch 88/700: Discriminator loss = 1.1758947372436523, GAN loss = [2.821054, 1.0510831, 1.0490102]\n",
      "Batch 89/700: Discriminator loss = 1.1164195537567139, GAN loss = [2.8796022, 1.0807732, 1.0779076]\n",
      "Batch 90/700: Discriminator loss = 1.16231369972229, GAN loss = [2.8543224, 1.0288334, 1.1046002]\n",
      "Batch 91/700: Discriminator loss = 1.1497769355773926, GAN loss = [2.82377, 1.0393332, 1.063572]\n",
      "Batch 92/700: Discriminator loss = 1.1013586521148682, GAN loss = [3.0384712, 1.0599885, 1.2576507]\n",
      "Batch 93/700: Discriminator loss = 1.1272248029708862, GAN loss = [2.8197546, 1.0420817, 1.0568827]\n",
      "Batch 94/700: Discriminator loss = 1.0809342861175537, GAN loss = [3.0886536, 1.1001146, 1.2677643]\n",
      "Batch 95/700: Discriminator loss = 1.1074016094207764, GAN loss = [2.867357, 1.0366249, 1.1099716]\n",
      "Batch 96/700: Discriminator loss = 1.1283866167068481, GAN loss = [2.8574116, 1.0363548, 1.1003014]\n",
      "Batch 97/700: Discriminator loss = 1.0848908424377441, GAN loss = [2.9684172, 1.0581653, 1.1895039]\n",
      "Batch 98/700: Discriminator loss = 1.1177748441696167, GAN loss = [2.9467359, 1.038671, 1.1873286]\n",
      "Batch 99/700: Discriminator loss = 1.14718759059906, GAN loss = [2.9359138, 1.0226927, 1.1925088]\n",
      "Batch 100/700: Discriminator loss = 1.1670551300048828, GAN loss = [2.7150955, 1.0079722, 0.98643494]\n",
      "Batch 101/700: Discriminator loss = 1.1290615797042847, GAN loss = [2.9782143, 1.0238384, 1.2337162]\n",
      "Batch 102/700: Discriminator loss = 1.1380527019500732, GAN loss = [2.9235609, 1.047478, 1.1554494]\n",
      "Batch 103/700: Discriminator loss = 1.1850262880325317, GAN loss = [2.7700708, 1.0097967, 1.039639]\n",
      "Batch 104/700: Discriminator loss = 1.1060643196105957, GAN loss = [2.9791899, 1.0537361, 1.2048254]\n",
      "Batch 105/700: Discriminator loss = 1.1383129358291626, GAN loss = [2.9553473, 1.0752494, 1.1594619]\n",
      "Batch 106/700: Discriminator loss = 1.125881552696228, GAN loss = [2.9006283, 1.0563523, 1.1236271]\n",
      "Batch 107/700: Discriminator loss = 1.1387683153152466, GAN loss = [2.8226633, 1.0177423, 1.0842595]\n",
      "Batch 108/700: Discriminator loss = 1.172580361366272, GAN loss = [2.8332574, 1.0054654, 1.1071163]\n",
      "Batch 109/700: Discriminator loss = 1.1361175775527954, GAN loss = [2.9461524, 1.0468829, 1.1785868]\n",
      "Batch 110/700: Discriminator loss = 1.1287012100219727, GAN loss = [2.92312, 1.0751604, 1.1272696]\n",
      "Batch 111/700: Discriminator loss = 1.155885934829712, GAN loss = [2.8711395, 1.0810273, 1.0694222]\n",
      "Batch 112/700: Discriminator loss = 1.0965107679367065, GAN loss = [2.9436536, 1.0733215, 1.1496266]\n",
      "Batch 113/700: Discriminator loss = 1.126955509185791, GAN loss = [2.9870088, 1.0703909, 1.1959025]\n",
      "Batch 114/700: Discriminator loss = 1.1266567707061768, GAN loss = [2.8753166, 1.042916, 1.1116563]\n",
      "Batch 115/700: Discriminator loss = 1.171417236328125, GAN loss = [3.0258372, 1.044022, 1.2610555]\n",
      "Batch 116/700: Discriminator loss = 1.1388442516326904, GAN loss = [2.9362743, 1.052104, 1.1634063]\n",
      "Batch 117/700: Discriminator loss = 1.1378732919692993, GAN loss = [2.807598, 1.0444146, 1.0424408]\n",
      "Batch 118/700: Discriminator loss = 1.1189030408859253, GAN loss = [2.920388, 1.0629685, 1.1366813]\n",
      "Batch 119/700: Discriminator loss = 1.0863522291183472, GAN loss = [3.057458, 1.0918907, 1.2448293]\n",
      "Batch 120/700: Discriminator loss = 1.1649478673934937, GAN loss = [2.8996255, 1.0211376, 1.1577626]\n",
      "Batch 121/700: Discriminator loss = 1.0988502502441406, GAN loss = [2.9784446, 1.0695168, 1.1882242]\n",
      "Batch 122/700: Discriminator loss = 1.1144003868103027, GAN loss = [2.9768636, 1.0584084, 1.1977625]\n",
      "Batch 123/700: Discriminator loss = 1.1167705059051514, GAN loss = [2.9873576, 1.0830183, 1.18366]\n",
      "Batch 124/700: Discriminator loss = 1.1006423234939575, GAN loss = [3.0369296, 1.0642399, 1.252029]\n",
      "Batch 125/700: Discriminator loss = 1.1580193042755127, GAN loss = [2.944704, 1.0191668, 1.2048951]\n",
      "Batch 126/700: Discriminator loss = 1.1190348863601685, GAN loss = [3.0451674, 1.0584277, 1.2661055]\n",
      "Batch 127/700: Discriminator loss = 1.162179946899414, GAN loss = [2.8869617, 1.0156919, 1.150651]\n",
      "Batch 128/700: Discriminator loss = 1.101934790611267, GAN loss = [3.0495598, 1.1019686, 1.2269876]\n",
      "Batch 129/700: Discriminator loss = 1.1469082832336426, GAN loss = [2.8147519, 1.0431308, 1.051026]\n",
      "Batch 130/700: Discriminator loss = 1.1480168104171753, GAN loss = [2.9863749, 1.0536937, 1.2121022]\n",
      "Batch 131/700: Discriminator loss = 1.1615078449249268, GAN loss = [2.9473193, 1.0216035, 1.2051256]\n",
      "Batch 132/700: Discriminator loss = 1.151160717010498, GAN loss = [2.8521466, 1.0418888, 1.0896708]\n",
      "Batch 133/700: Discriminator loss = 1.1648564338684082, GAN loss = [2.9363477, 1.0385728, 1.1772044]\n",
      "Batch 134/700: Discriminator loss = 1.2240550518035889, GAN loss = [2.875454, 1.0316479, 1.1232548]\n",
      "Batch 135/700: Discriminator loss = 1.1548455953598022, GAN loss = [2.9471955, 1.0614014, 1.1652564]\n",
      "Batch 136/700: Discriminator loss = 1.1083582639694214, GAN loss = [2.957105, 1.0776591, 1.1589317]\n",
      "Batch 137/700: Discriminator loss = 1.1757086515426636, GAN loss = [2.8545313, 1.0340492, 1.099985]\n",
      "Batch 138/700: Discriminator loss = 1.1396948099136353, GAN loss = [2.931851, 1.0577927, 1.1535786]\n",
      "Batch 139/700: Discriminator loss = 1.1442415714263916, GAN loss = [2.9526703, 1.0143988, 1.2178131]\n",
      "Batch 140/700: Discriminator loss = 1.1472811698913574, GAN loss = [2.8739305, 1.0140039, 1.1394701]\n",
      "Batch 141/700: Discriminator loss = 1.0863200426101685, GAN loss = [2.9660897, 1.0941619, 1.1514676]\n",
      "Batch 142/700: Discriminator loss = 1.1256252527236938, GAN loss = [2.9485834, 1.0632669, 1.1648605]\n",
      "Batch 143/700: Discriminator loss = 1.1296768188476562, GAN loss = [2.9401948, 1.0736108, 1.1461483]\n",
      "Batch 144/700: Discriminator loss = 1.10588538646698, GAN loss = [2.9765255, 1.0499628, 1.2061421]\n",
      "Batch 145/700: Discriminator loss = 1.1253066062927246, GAN loss = [2.921544, 1.0760864, 1.125044]\n",
      "Batch 146/700: Discriminator loss = 1.1184495687484741, GAN loss = [2.8938768, 1.0205266, 1.1529453]\n",
      "Batch 147/700: Discriminator loss = 1.1638861894607544, GAN loss = [2.8881161, 1.0330453, 1.1346895]\n",
      "Batch 148/700: Discriminator loss = 1.146586537361145, GAN loss = [3.0313745, 1.1311452, 1.1798713]\n",
      "Batch 149/700: Discriminator loss = 1.140748381614685, GAN loss = [2.9004598, 1.0529308, 1.1272023]\n",
      "Batch 150/700: Discriminator loss = 1.1392841339111328, GAN loss = [2.886166, 1.0371629, 1.1287044]\n",
      "Batch 151/700: Discriminator loss = 1.1163239479064941, GAN loss = [3.0447855, 1.1039637, 1.2205529]\n",
      "Batch 152/700: Discriminator loss = 1.1379450559616089, GAN loss = [2.8766751, 1.0365081, 1.1199273]\n",
      "Batch 153/700: Discriminator loss = 1.0857822895050049, GAN loss = [3.0488002, 1.0798118, 1.2487648]\n",
      "Batch 154/700: Discriminator loss = 1.167317271232605, GAN loss = [3.0155828, 1.06915, 1.2262259]\n",
      "Batch 155/700: Discriminator loss = 1.1316778659820557, GAN loss = [2.904551, 1.0728859, 1.1114831]\n",
      "Batch 156/700: Discriminator loss = 1.1110535860061646, GAN loss = [2.8645513, 1.0624948, 1.0819074]\n",
      "Batch 157/700: Discriminator loss = 1.0991721153259277, GAN loss = [2.9050741, 1.0540795, 1.1308756]\n",
      "Batch 158/700: Discriminator loss = 1.141198754310608, GAN loss = [2.8399558, 1.0408102, 1.0790485]\n",
      "Batch 159/700: Discriminator loss = 1.1205247640609741, GAN loss = [2.9270356, 1.0769231, 1.1300395]\n",
      "Batch 160/700: Discriminator loss = 1.1389826536178589, GAN loss = [2.9869866, 1.0765973, 1.1903353]\n",
      "Batch 161/700: Discriminator loss = 1.115746021270752, GAN loss = [3.0016713, 1.0648828, 1.2167556]\n",
      "Batch 162/700: Discriminator loss = 1.1629599332809448, GAN loss = [2.9574904, 1.0635246, 1.1739498]\n",
      "Batch 163/700: Discriminator loss = 1.1394902467727661, GAN loss = [2.7896943, 1.0542647, 1.0154293]\n",
      "Batch 164/700: Discriminator loss = 1.1896506547927856, GAN loss = [2.790405, 0.98113954, 1.0892701]\n",
      "Batch 165/700: Discriminator loss = 1.0999696254730225, GAN loss = [2.956714, 1.0741832, 1.1625466]\n",
      "Batch 166/700: Discriminator loss = 1.1547855138778687, GAN loss = [2.9060616, 1.0335371, 1.1525466]\n",
      "Batch 167/700: Discriminator loss = 1.1594831943511963, GAN loss = [2.7684004, 1.000038, 1.0484067]\n",
      "Batch 168/700: Discriminator loss = 1.160983920097351, GAN loss = [2.9190528, 1.0427433, 1.1563723]\n",
      "Batch 169/700: Discriminator loss = 1.1485352516174316, GAN loss = [2.8814056, 1.0477645, 1.1137333]\n",
      "Batch 170/700: Discriminator loss = 1.1137374639511108, GAN loss = [3.0120292, 1.0529478, 1.2392037]\n",
      "Batch 171/700: Discriminator loss = 1.1776503324508667, GAN loss = [2.9413087, 1.0081666, 1.2132916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 172/700: Discriminator loss = 1.1422622203826904, GAN loss = [2.7601686, 1.0454638, 0.99487334]\n",
      "Batch 173/700: Discriminator loss = 1.1720305681228638, GAN loss = [2.855932, 1.0016497, 1.1344646]\n",
      "Batch 174/700: Discriminator loss = 1.1611028909683228, GAN loss = [2.8637621, 1.004079, 1.1398808]\n",
      "Batch 175/700: Discriminator loss = 1.1491889953613281, GAN loss = [2.859354, 1.0321529, 1.1074014]\n",
      "Batch 176/700: Discriminator loss = 1.1659756898880005, GAN loss = [2.7689395, 0.98502564, 1.0641179]\n",
      "Batch 177/700: Discriminator loss = 1.1751148700714111, GAN loss = [2.8301113, 1.019454, 1.0908746]\n",
      "Batch 178/700: Discriminator loss = 1.1431111097335815, GAN loss = [2.767242, 1.006102, 1.0413648]\n",
      "Batch 179/700: Discriminator loss = 1.1469627618789673, GAN loss = [2.8711724, 1.0150877, 1.1363281]\n",
      "Batch 180/700: Discriminator loss = 1.1079485416412354, GAN loss = [3.007643, 1.0597225, 1.2281829]\n",
      "Batch 181/700: Discriminator loss = 1.1122568845748901, GAN loss = [3.0702326, 1.031775, 1.3187509]\n",
      "Batch 182/700: Discriminator loss = 1.131644368171692, GAN loss = [3.0984554, 1.0196947, 1.3590564]\n",
      "Batch 183/700: Discriminator loss = 1.1397262811660767, GAN loss = [2.8967495, 1.0403564, 1.1366925]\n",
      "Batch 184/700: Discriminator loss = 1.1242300271987915, GAN loss = [2.9043672, 1.0476351, 1.1370426]\n",
      "Batch 185/700: Discriminator loss = 1.1482833623886108, GAN loss = [2.8155973, 0.9874273, 1.1084899]\n",
      "Batch 186/700: Discriminator loss = 1.0947858095169067, GAN loss = [3.0726092, 1.0225275, 1.3303957]\n",
      "Batch 187/700: Discriminator loss = 1.153892159461975, GAN loss = [2.8882637, 1.0145574, 1.1540185]\n",
      "Batch 188/700: Discriminator loss = 1.1575889587402344, GAN loss = [2.8685217, 1.0517812, 1.0970594]\n",
      "Batch 189/700: Discriminator loss = 1.1400146484375, GAN loss = [2.9484382, 0.9810259, 1.2477356]\n",
      "Batch 190/700: Discriminator loss = 1.133795142173767, GAN loss = [2.8535395, 1.0249457, 1.1089315]\n",
      "Batch 191/700: Discriminator loss = 1.168617606163025, GAN loss = [2.9994657, 1.0321487, 1.2476645]\n",
      "Batch 192/700: Discriminator loss = 1.1286824941635132, GAN loss = [2.733406, 1.0205923, 0.99317026]\n",
      "Batch 193/700: Discriminator loss = 1.1586161851882935, GAN loss = [2.9282193, 1.0229926, 1.1856064]\n",
      "Batch 194/700: Discriminator loss = 1.1259567737579346, GAN loss = [2.9561086, 1.0152149, 1.2213013]\n",
      "Batch 195/700: Discriminator loss = 1.167948603630066, GAN loss = [2.7288222, 0.9861757, 1.0230799]\n",
      "Batch 196/700: Discriminator loss = 1.2198355197906494, GAN loss = [2.823203, 0.94287354, 1.1607875]\n",
      "Batch 197/700: Discriminator loss = 1.198388695716858, GAN loss = [2.7220733, 0.97225577, 1.0302953]\n",
      "Batch 198/700: Discriminator loss = 1.1254026889801025, GAN loss = [2.8587058, 1.0254143, 1.1137911]\n",
      "Batch 199/700: Discriminator loss = 1.1717406511306763, GAN loss = [2.8343923, 1.0403777, 1.074506]\n",
      "Batch 200/700: Discriminator loss = 1.1609394550323486, GAN loss = [2.8284686, 1.0104086, 1.0985533]\n",
      "Batch 201/700: Discriminator loss = 1.1340651512145996, GAN loss = [2.802707, 1.0553783, 1.0278405]\n",
      "Batch 202/700: Discriminator loss = 1.158096432685852, GAN loss = [2.9702065, 1.0184749, 1.2322448]\n",
      "Batch 203/700: Discriminator loss = 1.1451255083084106, GAN loss = [2.9542353, 1.0344487, 1.2003]\n",
      "Batch 204/700: Discriminator loss = 1.1381405591964722, GAN loss = [2.7642763, 1.0050184, 1.0397774]\n",
      "Batch 205/700: Discriminator loss = 1.1332826614379883, GAN loss = [2.9226625, 0.99088013, 1.2123094]\n",
      "Batch 206/700: Discriminator loss = 1.1414848566055298, GAN loss = [2.971896, 0.9929346, 1.2595006]\n",
      "Batch 207/700: Discriminator loss = 1.1887421607971191, GAN loss = [2.824271, 0.9543828, 1.1504327]\n",
      "Batch 208/700: Discriminator loss = 1.1584677696228027, GAN loss = [2.9473035, 0.996511, 1.2313282]\n",
      "Batch 209/700: Discriminator loss = 1.1532660722732544, GAN loss = [2.9188554, 1.0283706, 1.1710228]\n",
      "Batch 210/700: Discriminator loss = 1.1695356369018555, GAN loss = [2.8716433, 0.9836956, 1.168486]\n",
      "Batch 211/700: Discriminator loss = 1.1777474880218506, GAN loss = [2.6977704, 0.9807225, 0.9975826]\n",
      "Batch 212/700: Discriminator loss = 1.145987868309021, GAN loss = [2.8042529, 0.9882925, 1.0964949]\n",
      "Batch 213/700: Discriminator loss = 1.2109144926071167, GAN loss = [2.7289815, 0.96258473, 1.0469288]\n",
      "Batch 214/700: Discriminator loss = 1.2032802104949951, GAN loss = [2.8116434, 0.9826485, 1.109532]\n",
      "Batch 215/700: Discriminator loss = 1.1957998275756836, GAN loss = [2.7266817, 0.9760657, 1.0311393]\n",
      "Batch 216/700: Discriminator loss = 1.1901365518569946, GAN loss = [2.739911, 0.97463465, 1.045795]\n",
      "Batch 217/700: Discriminator loss = 1.13798987865448, GAN loss = [2.6955762, 1.0065472, 0.96953607]\n",
      "Batch 218/700: Discriminator loss = 1.1515368223190308, GAN loss = [2.7414935, 1.0011194, 1.0208699]\n",
      "Batch 219/700: Discriminator loss = 1.1744120121002197, GAN loss = [2.7641127, 0.9764465, 1.0681497]\n",
      "Batch 220/700: Discriminator loss = 1.1301349401474, GAN loss = [2.7727723, 1.026699, 1.0265294]\n",
      "Batch 221/700: Discriminator loss = 1.1423572301864624, GAN loss = [2.8124623, 1.0216058, 1.0712979]\n",
      "Batch 222/700: Discriminator loss = 1.1722320318222046, GAN loss = [2.706142, 1.0019135, 0.9846599]\n",
      "Batch 223/700: Discriminator loss = 1.1514226198196411, GAN loss = [2.8417976, 1.0121474, 1.1100674]\n",
      "Batch 224/700: Discriminator loss = 1.1566805839538574, GAN loss = [2.7812579, 1.0325309, 1.0291268]\n",
      "Batch 225/700: Discriminator loss = 1.201246976852417, GAN loss = [2.74271, 0.9625413, 1.0605487]\n",
      "Batch 226/700: Discriminator loss = 1.1944738626480103, GAN loss = [2.66306, 0.9610719, 0.98234886]\n",
      "Batch 227/700: Discriminator loss = 1.148564338684082, GAN loss = [2.6661146, 0.97791123, 0.96854514]\n",
      "Batch 228/700: Discriminator loss = 1.1721010208129883, GAN loss = [2.7595038, 0.99335295, 1.0464761]\n",
      "Batch 229/700: Discriminator loss = 1.1967296600341797, GAN loss = [2.771738, 0.996633, 1.0554162]\n",
      "Batch 230/700: Discriminator loss = 1.189537763595581, GAN loss = [2.647301, 0.9666231, 0.96098936]\n",
      "Batch 231/700: Discriminator loss = 1.13754141330719, GAN loss = [2.9185786, 1.0238888, 1.1750112]\n",
      "Batch 232/700: Discriminator loss = 1.1189519166946411, GAN loss = [2.898484, 1.0329968, 1.1458148]\n",
      "Batch 233/700: Discriminator loss = 1.1596611738204956, GAN loss = [2.8230848, 1.0015472, 1.1018605]\n",
      "Batch 234/700: Discriminator loss = 1.1652929782867432, GAN loss = [2.7361147, 1.027942, 0.9884925]\n",
      "Batch 235/700: Discriminator loss = 1.162302017211914, GAN loss = [2.7350583, 0.9825402, 1.0328318]\n",
      "Batch 236/700: Discriminator loss = 1.1538410186767578, GAN loss = [2.829232, 1.0156503, 1.0938951]\n",
      "Batch 237/700: Discriminator loss = 1.1321218013763428, GAN loss = [2.8463275, 1.0013072, 1.1253296]\n",
      "Batch 238/700: Discriminator loss = 1.151679277420044, GAN loss = [2.7198377, 1.0149453, 0.9851896]\n",
      "Batch 239/700: Discriminator loss = 1.224320650100708, GAN loss = [2.68219, 0.97086453, 0.99161565]\n",
      "Batch 240/700: Discriminator loss = 1.1569329500198364, GAN loss = [2.69756, 1.0062176, 0.9716301]\n",
      "Batch 241/700: Discriminator loss = 1.128867745399475, GAN loss = [2.6927938, 1.0031778, 0.96990746]\n",
      "Batch 242/700: Discriminator loss = 1.1956413984298706, GAN loss = [2.6810513, 0.97730917, 0.9840335]\n",
      "Batch 243/700: Discriminator loss = 1.1637499332427979, GAN loss = [2.6924708, 0.9749628, 0.99780464]\n",
      "Batch 244/700: Discriminator loss = 1.183964729309082, GAN loss = [2.7496712, 0.9662532, 1.0637231]\n",
      "Batch 245/700: Discriminator loss = 1.1775994300842285, GAN loss = [2.664962, 0.96331596, 0.9819703]\n",
      "Batch 246/700: Discriminator loss = 1.188876986503601, GAN loss = [2.700939, 0.9838546, 0.9974234]\n",
      "Batch 247/700: Discriminator loss = 1.1491645574569702, GAN loss = [2.6923215, 1.0173898, 0.95527345]\n",
      "Batch 248/700: Discriminator loss = 1.20360267162323, GAN loss = [2.6335983, 0.97014564, 0.9437938]\n",
      "Batch 249/700: Discriminator loss = 1.1612820625305176, GAN loss = [2.6162817, 0.9670757, 0.92954856]\n",
      "Batch 250/700: Discriminator loss = 1.1575872898101807, GAN loss = [2.7013872, 0.9950328, 0.9867052]\n",
      "Batch 251/700: Discriminator loss = 1.18675696849823, GAN loss = [2.6722906, 0.9854452, 0.96720624]\n",
      "Batch 252/700: Discriminator loss = 1.213515043258667, GAN loss = [2.647814, 0.9542703, 0.97389936]\n",
      "Batch 253/700: Discriminator loss = 1.1370750665664673, GAN loss = [2.7894053, 0.9833671, 1.0863872]\n",
      "Batch 254/700: Discriminator loss = 1.1640769243240356, GAN loss = [2.752458, 0.9922022, 1.0406129]\n",
      "Batch 255/700: Discriminator loss = 1.1185426712036133, GAN loss = [2.9242024, 1.0178963, 1.1866572]\n",
      "Batch 256/700: Discriminator loss = 1.1607717275619507, GAN loss = [2.847326, 1.0190526, 1.1086223]\n",
      "Batch 257/700: Discriminator loss = 1.1479581594467163, GAN loss = [2.8415623, 0.99563026, 1.1262746]\n",
      "Batch 258/700: Discriminator loss = 1.1179970502853394, GAN loss = [2.7912436, 0.9974362, 1.0741392]\n",
      "Batch 259/700: Discriminator loss = 1.1391860246658325, GAN loss = [2.71619, 0.98298, 1.0135309]\n",
      "Batch 260/700: Discriminator loss = 1.18331778049469, GAN loss = [2.568976, 0.9199593, 0.92932975]\n",
      "Batch 261/700: Discriminator loss = 1.2402390241622925, GAN loss = [2.6640818, 0.93744844, 1.006935]\n",
      "Batch 262/700: Discriminator loss = 1.1708179712295532, GAN loss = [2.8070157, 0.9727005, 1.1146133]\n",
      "Batch 263/700: Discriminator loss = 1.1326746940612793, GAN loss = [2.8027492, 0.9607111, 1.1223373]\n",
      "Batch 264/700: Discriminator loss = 1.1458581686019897, GAN loss = [2.8088417, 0.97040075, 1.1187527]\n",
      "Batch 265/700: Discriminator loss = 1.142861008644104, GAN loss = [2.8049285, 0.98333067, 1.1019086]\n",
      "Batch 266/700: Discriminator loss = 1.182464838027954, GAN loss = [2.7757413, 0.92748046, 1.1285732]\n",
      "Batch 267/700: Discriminator loss = 1.1129426956176758, GAN loss = [2.7849438, 1.0030372, 1.0622149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 268/700: Discriminator loss = 1.1702216863632202, GAN loss = [2.739557, 0.9481359, 1.0717373]\n",
      "Batch 269/700: Discriminator loss = 1.1628767251968384, GAN loss = [2.794605, 0.9612694, 1.1136537]\n",
      "Batch 270/700: Discriminator loss = 1.142979383468628, GAN loss = [2.8834815, 0.9870501, 1.1767572]\n",
      "Batch 271/700: Discriminator loss = 1.1156117916107178, GAN loss = [2.8020883, 1.00267, 1.0797518]\n",
      "Batch 272/700: Discriminator loss = 1.1660977602005005, GAN loss = [2.8451276, 0.94716835, 1.1782979]\n",
      "Batch 273/700: Discriminator loss = 1.1533896923065186, GAN loss = [2.9053133, 0.99725324, 1.1884065]\n",
      "Batch 274/700: Discriminator loss = 1.1799434423446655, GAN loss = [2.6948109, 0.97536033, 0.9998039]\n",
      "Batch 275/700: Discriminator loss = 1.1223238706588745, GAN loss = [2.978443, 1.0257851, 1.2330168]\n",
      "Batch 276/700: Discriminator loss = 1.10789954662323, GAN loss = [2.8676856, 1.0123585, 1.1356889]\n",
      "Batch 277/700: Discriminator loss = 1.1351583003997803, GAN loss = [2.85254, 0.9747764, 1.1581172]\n",
      "Batch 278/700: Discriminator loss = 1.1385775804519653, GAN loss = [2.8123417, 0.9929541, 1.09974]\n",
      "Batch 279/700: Discriminator loss = 1.1699095964431763, GAN loss = [2.661028, 0.943915, 0.9974586]\n",
      "Batch 280/700: Discriminator loss = 1.1323648691177368, GAN loss = [2.789515, 1.0227274, 1.0471132]\n",
      "Batch 281/700: Discriminator loss = 1.1479949951171875, GAN loss = [2.774002, 0.9871547, 1.0671531]\n",
      "Batch 282/700: Discriminator loss = 1.1203570365905762, GAN loss = [2.7614553, 1.0235436, 1.0182043]\n",
      "Batch 283/700: Discriminator loss = 1.1787148714065552, GAN loss = [2.7606294, 0.944527, 1.0963731]\n",
      "Batch 284/700: Discriminator loss = 1.1262716054916382, GAN loss = [2.822841, 1.0162748, 1.0868212]\n",
      "Batch 285/700: Discriminator loss = 1.2034257650375366, GAN loss = [2.7923117, 0.96113974, 1.1114298]\n",
      "Batch 286/700: Discriminator loss = 1.1520411968231201, GAN loss = [2.8027987, 0.9813694, 1.1016805]\n",
      "Batch 287/700: Discriminator loss = 1.1024779081344604, GAN loss = [2.8794959, 1.0365242, 1.1232407]\n",
      "Batch 288/700: Discriminator loss = 1.133941411972046, GAN loss = [2.8549922, 1.039084, 1.0961742]\n",
      "Batch 289/700: Discriminator loss = 1.1394453048706055, GAN loss = [2.8558552, 0.9769935, 1.1591228]\n",
      "Batch 290/700: Discriminator loss = 1.144878625869751, GAN loss = [2.7165163, 0.9464184, 1.0503659]\n",
      "Batch 291/700: Discriminator loss = 1.1959228515625, GAN loss = [2.850972, 0.9487654, 1.1824809]\n",
      "Batch 292/700: Discriminator loss = 1.122841238975525, GAN loss = [2.9488857, 1.0040705, 1.2250922]\n",
      "Batch 293/700: Discriminator loss = 1.1847299337387085, GAN loss = [2.8561678, 0.98234797, 1.1540995]\n",
      "Batch 294/700: Discriminator loss = 1.1435335874557495, GAN loss = [2.8608353, 0.99466795, 1.1464617]\n",
      "Batch 295/700: Discriminator loss = 1.177979588508606, GAN loss = [2.7414138, 0.957391, 1.0643266]\n",
      "Batch 296/700: Discriminator loss = 1.1068698167800903, GAN loss = [2.873167, 1.0579424, 1.0955335]\n",
      "Batch 297/700: Discriminator loss = 1.1434433460235596, GAN loss = [2.7842956, 0.98598254, 1.0786325]\n",
      "Batch 298/700: Discriminator loss = 1.11747145652771, GAN loss = [2.9605432, 1.0270199, 1.2138419]\n",
      "Batch 299/700: Discriminator loss = 1.1471368074417114, GAN loss = [2.8853204, 0.9764497, 1.1891832]\n",
      "Batch 300/700: Discriminator loss = 1.182280421257019, GAN loss = [2.8405156, 0.92581886, 1.1949996]\n",
      "Batch 301/700: Discriminator loss = 1.1130805015563965, GAN loss = [2.920467, 1.0373194, 1.1634283]\n",
      "Batch 302/700: Discriminator loss = 1.1365222930908203, GAN loss = [2.853624, 0.9941889, 1.1396885]\n",
      "Batch 303/700: Discriminator loss = 1.179564118385315, GAN loss = [2.7483146, 0.9641672, 1.0643983]\n",
      "Batch 304/700: Discriminator loss = 1.153235912322998, GAN loss = [2.7974024, 0.9934456, 1.0842135]\n",
      "Batch 305/700: Discriminator loss = 1.1892579793930054, GAN loss = [2.742839, 0.9976468, 1.0254644]\n",
      "Batch 306/700: Discriminator loss = 1.1551026105880737, GAN loss = [2.8077457, 0.9866418, 1.1013875]\n",
      "Batch 307/700: Discriminator loss = 1.1157313585281372, GAN loss = [2.9725301, 1.0316243, 1.2212064]\n",
      "Batch 308/700: Discriminator loss = 1.1145049333572388, GAN loss = [2.9328432, 1.0420728, 1.1710895]\n",
      "Batch 309/700: Discriminator loss = 1.1778004169464111, GAN loss = [2.6521537, 0.9790041, 0.95347804]\n",
      "Batch 310/700: Discriminator loss = 1.140535593032837, GAN loss = [2.8513653, 1.035641, 1.096057]\n",
      "Batch 311/700: Discriminator loss = 1.1921473741531372, GAN loss = [2.8107634, 0.9771922, 1.1139176]\n",
      "Batch 312/700: Discriminator loss = 1.1045191287994385, GAN loss = [2.9115036, 1.0479481, 1.1439172]\n",
      "Batch 313/700: Discriminator loss = 1.1192536354064941, GAN loss = [2.8460312, 1.0113066, 1.115074]\n",
      "Batch 314/700: Discriminator loss = 1.2039246559143066, GAN loss = [2.7553415, 0.97547835, 1.0601887]\n",
      "Batch 315/700: Discriminator loss = 1.1753144264221191, GAN loss = [2.7913759, 0.95778775, 1.1139175]\n",
      "Batch 316/700: Discriminator loss = 1.1842663288116455, GAN loss = [2.6487467, 0.953348, 0.975738]\n",
      "Batch 317/700: Discriminator loss = 1.1463818550109863, GAN loss = [2.9439309, 0.98404807, 1.2402136]\n",
      "Batch 318/700: Discriminator loss = 1.1521252393722534, GAN loss = [2.880604, 1.0154306, 1.1455165]\n",
      "Batch 319/700: Discriminator loss = 1.1627622842788696, GAN loss = [2.7859166, 1.0224167, 1.0438457]\n",
      "Batch 320/700: Discriminator loss = 1.125364899635315, GAN loss = [3.0263863, 1.0514531, 1.2552942]\n",
      "Batch 321/700: Discriminator loss = 1.1538615226745605, GAN loss = [2.9056954, 1.0291886, 1.1568646]\n",
      "Batch 322/700: Discriminator loss = 1.1406972408294678, GAN loss = [2.9186432, 1.0093448, 1.1896734]\n",
      "Batch 323/700: Discriminator loss = 1.1800620555877686, GAN loss = [2.877697, 1.0119804, 1.1461043]\n",
      "Batch 324/700: Discriminator loss = 1.1993428468704224, GAN loss = [2.7903259, 0.9618015, 1.1089225]\n",
      "Batch 325/700: Discriminator loss = 1.1132891178131104, GAN loss = [2.830733, 1.0622077, 1.0489389]\n",
      "Batch 326/700: Discriminator loss = 1.1088396310806274, GAN loss = [2.8952894, 1.0263072, 1.1494055]\n",
      "Batch 327/700: Discriminator loss = 1.1793882846832275, GAN loss = [2.8104749, 1.0149331, 1.0759714]\n",
      "Batch 328/700: Discriminator loss = 1.1441757678985596, GAN loss = [2.8096385, 1.0065743, 1.0835007]\n",
      "Batch 329/700: Discriminator loss = 1.1299084424972534, GAN loss = [2.8781955, 1.0284117, 1.1302074]\n",
      "Batch 330/700: Discriminator loss = 1.1493380069732666, GAN loss = [2.8084328, 1.0030086, 1.0858395]\n",
      "Batch 331/700: Discriminator loss = 1.1649948358535767, GAN loss = [2.7770708, 0.9768951, 1.0805877]\n",
      "Batch 332/700: Discriminator loss = 1.1638681888580322, GAN loss = [2.7789242, 0.9740524, 1.0852839]\n",
      "Batch 333/700: Discriminator loss = 1.1644881963729858, GAN loss = [2.7949822, 0.99295706, 1.0824445]\n",
      "Batch 334/700: Discriminator loss = 1.2201650142669678, GAN loss = [2.732122, 0.96286696, 1.049679]\n",
      "Batch 335/700: Discriminator loss = 1.1291559934616089, GAN loss = [2.8550663, 1.0236549, 1.1118358]\n",
      "Batch 336/700: Discriminator loss = 1.1454229354858398, GAN loss = [2.703224, 0.9892033, 0.99442863]\n",
      "Batch 337/700: Discriminator loss = 1.14528226852417, GAN loss = [2.838329, 1.008176, 1.1105497]\n",
      "Batch 338/700: Discriminator loss = 1.153683066368103, GAN loss = [2.7603016, 0.9910238, 1.0496829]\n",
      "Batch 339/700: Discriminator loss = 1.1485049724578857, GAN loss = [2.8916116, 1.0153337, 1.1566806]\n",
      "Batch 340/700: Discriminator loss = 1.1999431848526, GAN loss = [2.8631508, 1.0105647, 1.1329807]\n",
      "Batch 341/700: Discriminator loss = 1.175214409828186, GAN loss = [2.617697, 0.94168943, 0.95641893]\n",
      "Batch 342/700: Discriminator loss = 1.1222532987594604, GAN loss = [2.8571823, 1.017183, 1.1204085]\n",
      "Batch 343/700: Discriminator loss = 1.15550696849823, GAN loss = [2.8910592, 1.0095115, 1.1619518]\n",
      "Batch 344/700: Discriminator loss = 1.1263549327850342, GAN loss = [2.8869216, 1.0246772, 1.1426543]\n",
      "Batch 345/700: Discriminator loss = 1.134369969367981, GAN loss = [2.8371146, 1.0251588, 1.0923681]\n",
      "Batch 346/700: Discriminator loss = 1.1515495777130127, GAN loss = [2.7910087, 0.9792461, 1.0921812]\n",
      "Batch 347/700: Discriminator loss = 1.1643767356872559, GAN loss = [2.7231765, 0.9823523, 1.02126]\n",
      "Batch 348/700: Discriminator loss = 1.167195200920105, GAN loss = [2.8407335, 0.9949437, 1.1262397]\n",
      "Batch 349/700: Discriminator loss = 1.1218546628952026, GAN loss = [2.915233, 1.0137526, 1.1819451]\n",
      "Batch 350/700: Discriminator loss = 1.1674044132232666, GAN loss = [2.841, 0.9828781, 1.1385832]\n",
      "Batch 351/700: Discriminator loss = 1.1485605239868164, GAN loss = [2.82673, 0.9904022, 1.1167727]\n",
      "Batch 352/700: Discriminator loss = 1.173195719718933, GAN loss = [2.726765, 0.9626264, 1.0445625]\n",
      "Batch 353/700: Discriminator loss = 1.1490018367767334, GAN loss = [2.8597383, 1.0054672, 1.1346736]\n",
      "Batch 354/700: Discriminator loss = 1.1394906044006348, GAN loss = [2.8065326, 0.99511576, 1.0918053]\n",
      "Batch 355/700: Discriminator loss = 1.1592051982879639, GAN loss = [2.7712398, 0.99193835, 1.0596801]\n",
      "Batch 356/700: Discriminator loss = 1.1700695753097534, GAN loss = [2.7042356, 0.9738428, 1.0107657]\n",
      "Batch 357/700: Discriminator loss = 1.1624327898025513, GAN loss = [2.7179253, 0.95465356, 1.0436157]\n",
      "Batch 358/700: Discriminator loss = 1.1778264045715332, GAN loss = [2.872915, 0.9882878, 1.1649345]\n",
      "Batch 359/700: Discriminator loss = 1.1565067768096924, GAN loss = [2.800839, 1.0039263, 1.0771719]\n",
      "Batch 360/700: Discriminator loss = 1.137338638305664, GAN loss = [2.7147226, 1.0018138, 0.9931381]\n",
      "Batch 361/700: Discriminator loss = 1.1961078643798828, GAN loss = [2.7453904, 0.96457845, 1.0610331]\n",
      "Batch 362/700: Discriminator loss = 1.1556023359298706, GAN loss = [2.7615383, 0.9689576, 1.0728108]\n",
      "Batch 363/700: Discriminator loss = 1.2438263893127441, GAN loss = [2.6677763, 0.9198911, 1.0281291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 364/700: Discriminator loss = 1.1211869716644287, GAN loss = [2.8814662, 1.0051292, 1.1566011]\n",
      "Batch 365/700: Discriminator loss = 1.246872067451477, GAN loss = [2.6147544, 0.9130365, 0.98198587]\n",
      "Batch 366/700: Discriminator loss = 1.1862668991088867, GAN loss = [2.819124, 0.9486038, 1.150801]\n",
      "Batch 367/700: Discriminator loss = 1.1696856021881104, GAN loss = [2.686856, 0.9712085, 0.995925]\n",
      "Batch 368/700: Discriminator loss = 1.173040509223938, GAN loss = [2.8047109, 0.95545334, 1.1295383]\n",
      "Batch 369/700: Discriminator loss = 1.1446195840835571, GAN loss = [2.876804, 0.9858742, 1.1712213]\n",
      "Batch 370/700: Discriminator loss = 1.1465895175933838, GAN loss = [2.9163792, 0.9921844, 1.2045139]\n",
      "Batch 371/700: Discriminator loss = 1.1887032985687256, GAN loss = [2.6925273, 0.96287537, 1.0099815]\n",
      "Batch 372/700: Discriminator loss = 1.166802167892456, GAN loss = [2.770287, 0.9883448, 1.062269]\n",
      "Batch 373/700: Discriminator loss = 1.1411458253860474, GAN loss = [2.8542306, 0.99904656, 1.1355032]\n",
      "Batch 374/700: Discriminator loss = 1.1616848707199097, GAN loss = [2.8492916, 0.9907527, 1.1388623]\n",
      "Batch 375/700: Discriminator loss = 1.1181541681289673, GAN loss = [3.041063, 1.0111834, 1.3101993]\n",
      "Batch 376/700: Discriminator loss = 1.1690356731414795, GAN loss = [2.8406677, 0.9453052, 1.175673]\n",
      "Batch 377/700: Discriminator loss = 1.1348716020584106, GAN loss = [2.7925115, 0.99049014, 1.0823268]\n",
      "Batch 378/700: Discriminator loss = 1.1927121877670288, GAN loss = [2.7924545, 0.97199583, 1.1007522]\n",
      "Batch 379/700: Discriminator loss = 1.1816725730895996, GAN loss = [2.7107575, 0.9369495, 1.0540975]\n",
      "Batch 380/700: Discriminator loss = 1.111867904663086, GAN loss = [2.939125, 1.0263448, 1.1930803]\n",
      "Batch 381/700: Discriminator loss = 1.2050628662109375, GAN loss = [2.7204762, 0.9557203, 1.0450684]\n",
      "Batch 382/700: Discriminator loss = 1.1239513158798218, GAN loss = [2.9927518, 1.0001876, 1.2728777]\n",
      "Batch 383/700: Discriminator loss = 1.1587297916412354, GAN loss = [2.837951, 0.9611416, 1.1571256]\n",
      "Batch 384/700: Discriminator loss = 1.1345751285552979, GAN loss = [2.766292, 0.9784213, 1.0681857]\n",
      "Batch 385/700: Discriminator loss = 1.1567116975784302, GAN loss = [2.8519504, 0.9518319, 1.1804318]\n",
      "Batch 386/700: Discriminator loss = 1.1313918828964233, GAN loss = [2.8653514, 1.0039333, 1.1417327]\n",
      "Batch 387/700: Discriminator loss = 1.1638840436935425, GAN loss = [2.8287075, 0.97689384, 1.132145]\n",
      "Batch 388/700: Discriminator loss = 1.1695334911346436, GAN loss = [2.74217, 0.9680336, 1.0544678]\n",
      "Batch 389/700: Discriminator loss = 1.1620064973831177, GAN loss = [2.8128421, 1.0046883, 1.0884827]\n",
      "Batch 390/700: Discriminator loss = 1.1310884952545166, GAN loss = [2.8391562, 0.989058, 1.1304337]\n",
      "Batch 391/700: Discriminator loss = 1.1217700242996216, GAN loss = [2.737731, 1.000072, 1.0179833]\n",
      "Batch 392/700: Discriminator loss = 1.1740278005599976, GAN loss = [2.80039, 0.98947227, 1.0912479]\n",
      "Batch 393/700: Discriminator loss = 1.239423394203186, GAN loss = [2.6985338, 0.97036684, 1.0084888]\n",
      "Batch 394/700: Discriminator loss = 1.1411159038543701, GAN loss = [2.7290335, 0.995799, 1.0135491]\n",
      "Batch 395/700: Discriminator loss = 1.1354173421859741, GAN loss = [2.7877839, 0.99908286, 1.0690138]\n",
      "Batch 396/700: Discriminator loss = 1.1392943859100342, GAN loss = [2.7537606, 0.99357635, 1.0405083]\n",
      "Batch 397/700: Discriminator loss = 1.1698757410049438, GAN loss = [2.8647103, 0.9962094, 1.1488639]\n",
      "Batch 398/700: Discriminator loss = 1.1142736673355103, GAN loss = [2.8479655, 1.0535805, 1.0747567]\n",
      "Batch 399/700: Discriminator loss = 1.1550829410552979, GAN loss = [2.755624, 1.0125287, 1.0234711]\n",
      "Batch 400/700: Discriminator loss = 1.1515737771987915, GAN loss = [2.680369, 0.9588929, 1.0018466]\n",
      "Batch 401/700: Discriminator loss = 1.185078501701355, GAN loss = [2.7089674, 0.9399529, 1.0493824]\n",
      "Batch 402/700: Discriminator loss = 1.2348073720932007, GAN loss = [2.5656087, 0.8887194, 0.95726895]\n",
      "Batch 403/700: Discriminator loss = 1.2042577266693115, GAN loss = [2.7800486, 0.9461014, 1.1143304]\n",
      "Batch 404/700: Discriminator loss = 1.1273623704910278, GAN loss = [2.8048763, 1.0051384, 1.0801281]\n",
      "Batch 405/700: Discriminator loss = 1.1927815675735474, GAN loss = [2.7925317, 0.9825086, 1.0904152]\n",
      "Batch 406/700: Discriminator loss = 1.1313493251800537, GAN loss = [2.8141952, 1.0415294, 1.0530618]\n",
      "Batch 407/700: Discriminator loss = 1.1402428150177002, GAN loss = [2.7660592, 0.9982289, 1.0482249]\n",
      "Batch 408/700: Discriminator loss = 1.157461404800415, GAN loss = [2.8081772, 1.0079007, 1.0806739]\n",
      "Batch 409/700: Discriminator loss = 1.1629383563995361, GAN loss = [2.7010958, 0.9958878, 0.9856082]\n",
      "Batch 410/700: Discriminator loss = 1.195829153060913, GAN loss = [2.7156887, 1.0012664, 0.9948085]\n",
      "Batch 411/700: Discriminator loss = 1.1410813331604004, GAN loss = [2.7604706, 1.0027952, 1.0380648]\n",
      "Batch 412/700: Discriminator loss = 1.1258621215820312, GAN loss = [2.752974, 1.0073224, 1.0260371]\n",
      "Batch 413/700: Discriminator loss = 1.1813483238220215, GAN loss = [2.8118184, 0.9667498, 1.1254519]\n",
      "Batch 414/700: Discriminator loss = 1.1845097541809082, GAN loss = [2.6090982, 0.96078473, 0.9287101]\n",
      "Batch 415/700: Discriminator loss = 1.1927956342697144, GAN loss = [2.8911417, 1.0432314, 1.1283184]\n",
      "Batch 416/700: Discriminator loss = 1.177755355834961, GAN loss = [2.6288683, 0.9807445, 0.9285306]\n",
      "Batch 417/700: Discriminator loss = 1.1678768396377563, GAN loss = [2.7357621, 0.9908682, 1.0252753]\n",
      "Batch 418/700: Discriminator loss = 1.1787184476852417, GAN loss = [2.650969, 0.94691604, 0.9844072]\n",
      "Batch 419/700: Discriminator loss = 1.1943931579589844, GAN loss = [2.7185645, 0.96826255, 1.0306351]\n",
      "Batch 420/700: Discriminator loss = 1.2006690502166748, GAN loss = [2.6017976, 0.9473827, 0.934721]\n",
      "Batch 421/700: Discriminator loss = 1.1352486610412598, GAN loss = [2.714188, 1.0014164, 0.9930518]\n",
      "Batch 422/700: Discriminator loss = 1.1894352436065674, GAN loss = [2.7845366, 1.0110079, 1.0538068]\n",
      "Batch 423/700: Discriminator loss = 1.2059099674224854, GAN loss = [2.6751938, 0.96728456, 0.9881783]\n",
      "Batch 424/700: Discriminator loss = 1.2178397178649902, GAN loss = [2.64177, 0.94950736, 0.9725232]\n",
      "Batch 425/700: Discriminator loss = 1.1408368349075317, GAN loss = [2.725484, 1.0037957, 1.001925]\n",
      "Batch 426/700: Discriminator loss = 1.1688686609268188, GAN loss = [2.8173368, 1.0658351, 1.0317158]\n",
      "Batch 427/700: Discriminator loss = 1.159984827041626, GAN loss = [2.7787433, 1.0417856, 1.0171691]\n",
      "Batch 428/700: Discriminator loss = 1.123556137084961, GAN loss = [2.7642148, 1.0714053, 0.9730047]\n",
      "Batch 429/700: Discriminator loss = 1.1436504125595093, GAN loss = [2.8088462, 1.0093441, 1.0796717]\n",
      "Batch 430/700: Discriminator loss = 1.1384727954864502, GAN loss = [2.7673767, 1.0449711, 1.002545]\n",
      "Batch 431/700: Discriminator loss = 1.1522749662399292, GAN loss = [2.7032669, 0.98982084, 0.99356574]\n",
      "Batch 432/700: Discriminator loss = 1.1201897859573364, GAN loss = [2.7930639, 1.0166252, 1.056538]\n",
      "Batch 433/700: Discriminator loss = 1.1421594619750977, GAN loss = [2.7219534, 1.0219444, 0.9800897]\n",
      "Batch 434/700: Discriminator loss = 1.1092981100082397, GAN loss = [2.8725502, 1.0409845, 1.111626]\n",
      "Batch 435/700: Discriminator loss = 1.1317349672317505, GAN loss = [2.7551036, 1.0081124, 1.027048]\n",
      "Batch 436/700: Discriminator loss = 1.1355324983596802, GAN loss = [2.7737548, 1.0308855, 1.0229224]\n",
      "Batch 437/700: Discriminator loss = 1.1663504838943481, GAN loss = [2.7967718, 1.0128415, 1.0639875]\n",
      "Batch 438/700: Discriminator loss = 1.1924909353256226, GAN loss = [2.6315513, 0.9913553, 0.9202434]\n",
      "Batch 439/700: Discriminator loss = 1.1422199010849, GAN loss = [2.723436, 1.0102214, 0.99324685]\n",
      "Batch 440/700: Discriminator loss = 1.1603103876113892, GAN loss = [2.8248158, 1.0256274, 1.0792]\n",
      "Batch 441/700: Discriminator loss = 1.187301516532898, GAN loss = [2.7188168, 1.0460715, 0.95273435]\n",
      "Batch 442/700: Discriminator loss = 1.1042587757110596, GAN loss = [2.8041787, 1.0468444, 1.0373204]\n",
      "Batch 443/700: Discriminator loss = 1.1813981533050537, GAN loss = [2.823119, 0.9817963, 1.1212966]\n",
      "Batch 444/700: Discriminator loss = 1.1350404024124146, GAN loss = [2.7705042, 1.0140346, 1.0364455]\n",
      "Batch 445/700: Discriminator loss = 1.1821694374084473, GAN loss = [2.6853805, 0.9503697, 1.0150008]\n",
      "Batch 446/700: Discriminator loss = 1.1667215824127197, GAN loss = [2.7752059, 0.98336256, 1.0718476]\n",
      "Batch 447/700: Discriminator loss = 1.2117910385131836, GAN loss = [2.6319609, 0.9814006, 0.93055606]\n",
      "Batch 448/700: Discriminator loss = 1.140433669090271, GAN loss = [2.8702536, 1.1299053, 1.0203375]\n",
      "Batch 449/700: Discriminator loss = 1.133498191833496, GAN loss = [2.7102885, 1.0059654, 0.98431975]\n",
      "Batch 450/700: Discriminator loss = 1.1304816007614136, GAN loss = [2.753774, 1.0003123, 1.0334487]\n",
      "Batch 451/700: Discriminator loss = 1.1782832145690918, GAN loss = [2.7528422, 0.982988, 1.0498316]\n",
      "Batch 452/700: Discriminator loss = 1.1436729431152344, GAN loss = [2.7906947, 0.9843847, 1.0862606]\n",
      "Batch 453/700: Discriminator loss = 1.2333980798721313, GAN loss = [2.691057, 0.9361161, 1.0348872]\n",
      "Batch 454/700: Discriminator loss = 1.172195553779602, GAN loss = [2.6942604, 0.99431455, 0.97988373]\n",
      "Batch 455/700: Discriminator loss = 1.1949201822280884, GAN loss = [2.753517, 0.9872718, 1.0461936]\n",
      "Batch 456/700: Discriminator loss = 1.18931245803833, GAN loss = [2.7523777, 1.041277, 0.99104774]\n",
      "Batch 457/700: Discriminator loss = 1.2326871156692505, GAN loss = [2.6948452, 0.96736825, 1.0074208]\n",
      "Batch 458/700: Discriminator loss = 1.1800072193145752, GAN loss = [2.726297, 1.000875, 1.0053682]\n",
      "Batch 459/700: Discriminator loss = 1.121805191040039, GAN loss = [2.7817636, 1.012186, 1.0495187]\n",
      "Batch 460/700: Discriminator loss = 1.1899054050445557, GAN loss = [2.741041, 0.9833595, 1.0376207]\n",
      "Batch 461/700: Discriminator loss = 1.1793951988220215, GAN loss = [2.7849882, 1.0110124, 1.0539175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 462/700: Discriminator loss = 1.2222871780395508, GAN loss = [2.6314657, 0.9663427, 0.9450812]\n",
      "Batch 463/700: Discriminator loss = 1.1153030395507812, GAN loss = [2.7360141, 1.015891, 1.0000813]\n",
      "Batch 464/700: Discriminator loss = 1.177297830581665, GAN loss = [2.749478, 0.9915276, 1.0379103]\n",
      "Batch 465/700: Discriminator loss = 1.1712138652801514, GAN loss = [2.7302206, 0.9518377, 1.0583454]\n",
      "Batch 466/700: Discriminator loss = 1.1442196369171143, GAN loss = [2.7170107, 0.99066716, 1.006318]\n",
      "Batch 467/700: Discriminator loss = 1.1526069641113281, GAN loss = [2.7686203, 0.98688334, 1.0617133]\n",
      "Batch 468/700: Discriminator loss = 1.189219355583191, GAN loss = [2.7577703, 0.96580744, 1.0719368]\n",
      "Batch 469/700: Discriminator loss = 1.1457736492156982, GAN loss = [2.8081295, 1.0317345, 1.0563691]\n",
      "Batch 470/700: Discriminator loss = 1.1909276247024536, GAN loss = [2.722421, 0.9551871, 1.047217]\n",
      "Batch 471/700: Discriminator loss = 1.1728110313415527, GAN loss = [2.6861758, 0.9871795, 0.97897744]\n",
      "Batch 472/700: Discriminator loss = 1.1558855772018433, GAN loss = [2.7675977, 0.9802635, 1.0673178]\n",
      "Batch 473/700: Discriminator loss = 1.1673911809921265, GAN loss = [2.710647, 1.0026015, 0.98803085]\n",
      "Batch 474/700: Discriminator loss = 1.154383659362793, GAN loss = [2.7137272, 1.0078431, 0.98588645]\n",
      "Batch 475/700: Discriminator loss = 1.1601094007492065, GAN loss = [2.7179718, 0.9818264, 1.016164]\n",
      "Batch 476/700: Discriminator loss = 1.1508617401123047, GAN loss = [2.741975, 1.0017941, 1.0202118]\n",
      "Batch 477/700: Discriminator loss = 1.1239947080612183, GAN loss = [2.814573, 1.0421153, 1.0525016]\n",
      "Batch 478/700: Discriminator loss = 1.1234626770019531, GAN loss = [2.7675724, 1.0247004, 1.0229113]\n",
      "Batch 479/700: Discriminator loss = 1.1890462636947632, GAN loss = [2.753517, 0.9148069, 1.1187459]\n",
      "Batch 480/700: Discriminator loss = 1.1465781927108765, GAN loss = [2.7582903, 1.0000465, 1.038278]\n",
      "Batch 481/700: Discriminator loss = 1.1706589460372925, GAN loss = [2.6987638, 0.98849624, 0.9902944]\n",
      "Batch 482/700: Discriminator loss = 1.1470783948898315, GAN loss = [2.7566624, 0.970361, 1.0663276]\n",
      "Batch 483/700: Discriminator loss = 1.1666802167892456, GAN loss = [2.7182493, 0.9753359, 1.0229311]\n",
      "Batch 484/700: Discriminator loss = 1.1940523386001587, GAN loss = [2.8184502, 0.97701645, 1.1214463]\n",
      "Batch 485/700: Discriminator loss = 1.1268773078918457, GAN loss = [2.804296, 1.0489252, 1.0353901]\n",
      "Batch 486/700: Discriminator loss = 1.1176722049713135, GAN loss = [2.787939, 1.035132, 1.0328434]\n",
      "Batch 487/700: Discriminator loss = 1.1675184965133667, GAN loss = [2.8361986, 0.9759793, 1.1402655]\n",
      "Batch 488/700: Discriminator loss = 1.1621103286743164, GAN loss = [2.8341572, 0.99628156, 1.1179268]\n",
      "Batch 489/700: Discriminator loss = 1.141066312789917, GAN loss = [2.734216, 0.97483873, 1.0394207]\n",
      "Batch 490/700: Discriminator loss = 1.1371104717254639, GAN loss = [2.7672296, 1.0020936, 1.0451673]\n",
      "Batch 491/700: Discriminator loss = 1.1762244701385498, GAN loss = [2.6444385, 0.950301, 0.97416365]\n",
      "Batch 492/700: Discriminator loss = 1.1706894636154175, GAN loss = [2.7496734, 0.9814843, 1.048217]\n",
      "Batch 493/700: Discriminator loss = 1.1902648210525513, GAN loss = [2.7695093, 0.996238, 1.0533122]\n",
      "Batch 494/700: Discriminator loss = 1.1620581150054932, GAN loss = [2.745679, 0.99178815, 1.0339397]\n",
      "Batch 495/700: Discriminator loss = 1.133494257926941, GAN loss = [2.7994328, 1.0194219, 1.0600753]\n",
      "Batch 496/700: Discriminator loss = 1.1392855644226074, GAN loss = [2.8154502, 1.0167326, 1.0788126]\n",
      "Batch 497/700: Discriminator loss = 1.1648108959197998, GAN loss = [2.7243161, 0.96190816, 1.0425315]\n",
      "Batch 498/700: Discriminator loss = 1.2258327007293701, GAN loss = [2.6701915, 0.91805196, 1.0322896]\n",
      "Batch 499/700: Discriminator loss = 1.178176999092102, GAN loss = [2.7424545, 0.9655104, 1.0571175]\n",
      "Batch 500/700: Discriminator loss = 1.1717897653579712, GAN loss = [2.7868457, 0.9583287, 1.1087141]\n",
      "Batch 501/700: Discriminator loss = 1.2025436162948608, GAN loss = [2.809436, 0.9596592, 1.1299844]\n",
      "Batch 502/700: Discriminator loss = 1.1439837217330933, GAN loss = [2.834509, 0.98640597, 1.1283282]\n",
      "Batch 503/700: Discriminator loss = 1.1711993217468262, GAN loss = [2.6309133, 0.9467304, 0.96442246]\n",
      "Batch 504/700: Discriminator loss = 1.1638227701187134, GAN loss = [2.6944194, 0.979811, 0.99486077]\n",
      "Batch 505/700: Discriminator loss = 1.164372205734253, GAN loss = [2.741178, 0.972612, 1.0488361]\n",
      "Batch 506/700: Discriminator loss = 1.1770155429840088, GAN loss = [2.755145, 0.9482109, 1.0872217]\n",
      "Batch 507/700: Discriminator loss = 1.152626633644104, GAN loss = [2.7720358, 0.98482984, 1.0675105]\n",
      "Batch 508/700: Discriminator loss = 1.1409945487976074, GAN loss = [2.7754576, 0.9685614, 1.0872139]\n",
      "Batch 509/700: Discriminator loss = 1.2008215188980103, GAN loss = [2.7202065, 0.93898576, 1.0615455]\n",
      "Batch 510/700: Discriminator loss = 1.1638479232788086, GAN loss = [2.6453435, 0.9732624, 0.9524034]\n",
      "Batch 511/700: Discriminator loss = 1.232568621635437, GAN loss = [2.6028087, 0.9195437, 0.9635795]\n",
      "Batch 512/700: Discriminator loss = 1.2264984846115112, GAN loss = [2.7179086, 0.9165982, 1.0816218]\n",
      "Batch 513/700: Discriminator loss = 1.1601479053497314, GAN loss = [2.6335413, 0.9730051, 0.9408487]\n",
      "Batch 514/700: Discriminator loss = 1.2063720226287842, GAN loss = [2.7501576, 0.96226776, 1.068199]\n",
      "Batch 515/700: Discriminator loss = 1.12883460521698, GAN loss = [2.7487202, 0.9880458, 1.0409855]\n",
      "Batch 516/700: Discriminator loss = 1.1426775455474854, GAN loss = [2.7511065, 0.9854042, 1.046021]\n",
      "Batch 517/700: Discriminator loss = 1.1633400917053223, GAN loss = [2.6740742, 0.94020134, 1.0142021]\n",
      "Batch 518/700: Discriminator loss = 1.1768457889556885, GAN loss = [2.7104568, 0.9451618, 1.0456386]\n",
      "Batch 519/700: Discriminator loss = 1.1446138620376587, GAN loss = [2.7563903, 1.0008936, 1.03585]\n",
      "Batch 520/700: Discriminator loss = 1.1872674226760864, GAN loss = [2.6070716, 0.93067986, 0.95674735]\n",
      "Batch 521/700: Discriminator loss = 1.1959295272827148, GAN loss = [2.5519261, 0.9351191, 0.8971703]\n",
      "Batch 522/700: Discriminator loss = 1.129003882408142, GAN loss = [2.7614295, 1.0152994, 1.0265005]\n",
      "Batch 523/700: Discriminator loss = 1.152097463607788, GAN loss = [2.6690083, 0.9445112, 1.0048821]\n",
      "Batch 524/700: Discriminator loss = 1.1588988304138184, GAN loss = [2.7662752, 0.93642455, 1.1102426]\n",
      "Batch 525/700: Discriminator loss = 1.188861608505249, GAN loss = [2.6907985, 0.95440745, 1.0167769]\n",
      "Batch 526/700: Discriminator loss = 1.1651099920272827, GAN loss = [2.7373362, 0.9706957, 1.0470256]\n",
      "Batch 527/700: Discriminator loss = 1.1498198509216309, GAN loss = [2.7353647, 0.9831154, 1.0326254]\n",
      "Batch 528/700: Discriminator loss = 1.1563431024551392, GAN loss = [2.6806448, 0.95963424, 1.0013865]\n",
      "Batch 529/700: Discriminator loss = 1.146768569946289, GAN loss = [2.7555108, 0.9815338, 1.0543574]\n",
      "Batch 530/700: Discriminator loss = 1.1775938272476196, GAN loss = [2.5818753, 0.9264657, 0.9357952]\n",
      "Batch 531/700: Discriminator loss = 1.1550458669662476, GAN loss = [2.6707842, 0.95815736, 0.99301285]\n",
      "Batch 532/700: Discriminator loss = 1.2762229442596436, GAN loss = [2.6224551, 0.9080517, 0.99480116]\n",
      "Batch 533/700: Discriminator loss = 1.1918606758117676, GAN loss = [2.6853545, 0.94949824, 1.0162767]\n",
      "Batch 534/700: Discriminator loss = 1.144439458847046, GAN loss = [2.653343, 0.94807136, 0.9857023]\n",
      "Batch 535/700: Discriminator loss = 1.1650277376174927, GAN loss = [2.681427, 0.98277795, 0.97906876]\n",
      "Batch 536/700: Discriminator loss = 1.2012394666671753, GAN loss = [2.728996, 0.9574791, 1.0519377]\n",
      "Batch 537/700: Discriminator loss = 1.146718978881836, GAN loss = [2.72712, 0.98744154, 1.0201052]\n",
      "Batch 538/700: Discriminator loss = 1.213640809059143, GAN loss = [2.579308, 0.94137293, 0.9183805]\n",
      "Batch 539/700: Discriminator loss = 1.1378092765808105, GAN loss = [2.7262976, 0.98795485, 1.0188006]\n",
      "Batch 540/700: Discriminator loss = 1.1680487394332886, GAN loss = [2.7030709, 0.9663037, 1.017237]\n",
      "Batch 541/700: Discriminator loss = 1.1459439992904663, GAN loss = [2.744138, 0.96680295, 1.0578176]\n",
      "Batch 542/700: Discriminator loss = 1.177579402923584, GAN loss = [2.650451, 0.93381464, 0.9971234]\n",
      "Batch 543/700: Discriminator loss = 1.132796049118042, GAN loss = [2.7672563, 0.99970114, 1.0480479]\n",
      "Batch 544/700: Discriminator loss = 1.1806951761245728, GAN loss = [2.727336, 0.9500235, 1.0578089]\n",
      "Batch 545/700: Discriminator loss = 1.1722015142440796, GAN loss = [2.6945581, 0.9617911, 1.0132852]\n",
      "Batch 546/700: Discriminator loss = 1.209181547164917, GAN loss = [2.6930702, 0.9580432, 1.0155561]\n",
      "Batch 547/700: Discriminator loss = 1.161380410194397, GAN loss = [2.636522, 0.9520909, 0.96497244]\n",
      "Batch 548/700: Discriminator loss = 1.1906553506851196, GAN loss = [2.5809855, 0.9417499, 0.9197952]\n",
      "Batch 549/700: Discriminator loss = 1.2139687538146973, GAN loss = [2.6163478, 0.92117804, 0.9757483]\n",
      "Batch 550/700: Discriminator loss = 1.2295914888381958, GAN loss = [2.8099482, 1.024242, 1.066307]\n",
      "Batch 551/700: Discriminator loss = 1.1925643682479858, GAN loss = [2.5798018, 0.9459884, 0.91443014]\n",
      "Batch 552/700: Discriminator loss = 1.178503394126892, GAN loss = [2.706659, 0.950131, 1.0371531]\n",
      "Batch 553/700: Discriminator loss = 1.180799126625061, GAN loss = [2.7113857, 0.9547656, 1.0372524]\n",
      "Batch 554/700: Discriminator loss = 1.2322427034378052, GAN loss = [2.661585, 0.89791405, 1.0443143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 555/700: Discriminator loss = 1.213065266609192, GAN loss = [2.670355, 0.94408804, 1.0069233]\n",
      "Batch 556/700: Discriminator loss = 1.1881918907165527, GAN loss = [2.6141455, 0.95235515, 0.9424556]\n",
      "Batch 557/700: Discriminator loss = 1.2185570001602173, GAN loss = [2.6599543, 0.96208686, 0.97854185]\n",
      "Batch 558/700: Discriminator loss = 1.242187738418579, GAN loss = [2.602485, 0.9396872, 0.94348466]\n",
      "Batch 559/700: Discriminator loss = 1.179990291595459, GAN loss = [2.6865091, 0.96777284, 0.9994452]\n",
      "Batch 560/700: Discriminator loss = 1.184760570526123, GAN loss = [2.5777364, 0.9273968, 0.93106616]\n",
      "Batch 561/700: Discriminator loss = 1.2063583135604858, GAN loss = [2.6142018, 0.9376878, 0.9572374]\n",
      "Batch 562/700: Discriminator loss = 1.182041883468628, GAN loss = [2.6213262, 0.94092715, 0.96112925]\n",
      "Batch 563/700: Discriminator loss = 1.2550162076950073, GAN loss = [2.649727, 0.9158634, 1.0146093]\n",
      "Batch 564/700: Discriminator loss = 1.1738803386688232, GAN loss = [2.72084, 0.9688051, 1.0327983]\n",
      "Batch 565/700: Discriminator loss = 1.147071123123169, GAN loss = [2.6803308, 1.0134766, 0.947631]\n",
      "Batch 566/700: Discriminator loss = 1.1944063901901245, GAN loss = [2.6486235, 0.9741045, 0.95530045]\n",
      "Batch 567/700: Discriminator loss = 1.2091727256774902, GAN loss = [2.5058074, 0.9130133, 0.8735881]\n",
      "Batch 568/700: Discriminator loss = 1.1848468780517578, GAN loss = [2.6894445, 0.9406389, 1.0296147]\n",
      "Batch 569/700: Discriminator loss = 1.149999737739563, GAN loss = [2.7605138, 0.9805699, 1.0607678]\n",
      "Batch 570/700: Discriminator loss = 1.1944810152053833, GAN loss = [2.672204, 0.9722469, 0.98079216]\n",
      "Batch 571/700: Discriminator loss = 1.2098885774612427, GAN loss = [2.7000034, 0.9173691, 1.0634881]\n",
      "Batch 572/700: Discriminator loss = 1.20664381980896, GAN loss = [2.6508424, 0.9451498, 0.98654824]\n",
      "Batch 573/700: Discriminator loss = 1.2253661155700684, GAN loss = [2.6221197, 0.9287649, 0.9742113]\n",
      "Batch 574/700: Discriminator loss = 1.2243074178695679, GAN loss = [2.6403952, 0.92193526, 0.9993264]\n",
      "Batch 575/700: Discriminator loss = 1.160348892211914, GAN loss = [2.6700323, 0.9869483, 0.9639662]\n",
      "Batch 576/700: Discriminator loss = 1.154529094696045, GAN loss = [2.6674726, 0.9841087, 0.964258]\n",
      "Batch 577/700: Discriminator loss = 1.1933410167694092, GAN loss = [2.6356182, 0.91455126, 1.0019805]\n",
      "Batch 578/700: Discriminator loss = 1.1918978691101074, GAN loss = [2.6545157, 0.9384664, 0.9969799]\n",
      "Batch 579/700: Discriminator loss = 1.210412621498108, GAN loss = [2.669474, 0.9147164, 1.035699]\n",
      "Batch 580/700: Discriminator loss = 1.1544452905654907, GAN loss = [2.59275, 0.9531912, 0.92050177]\n",
      "Batch 581/700: Discriminator loss = 1.2051907777786255, GAN loss = [2.592565, 0.93499255, 0.9385144]\n",
      "Batch 582/700: Discriminator loss = 1.1907490491867065, GAN loss = [2.6982355, 0.9442322, 1.0349574]\n",
      "Batch 583/700: Discriminator loss = 1.2684123516082764, GAN loss = [2.6140041, 0.89393115, 1.0010296]\n",
      "Batch 584/700: Discriminator loss = 1.220833659172058, GAN loss = [2.5752628, 0.9042625, 0.95194435]\n",
      "Batch 585/700: Discriminator loss = 1.1805720329284668, GAN loss = [2.6035278, 0.9187295, 0.96574295]\n",
      "Batch 586/700: Discriminator loss = 1.1881229877471924, GAN loss = [2.7183852, 0.96212596, 1.037203]\n",
      "Batch 587/700: Discriminator loss = 1.1654213666915894, GAN loss = [2.682419, 0.9826801, 0.98067886]\n",
      "Batch 588/700: Discriminator loss = 1.2618930339813232, GAN loss = [2.5915837, 0.91305304, 0.959479]\n",
      "Batch 589/700: Discriminator loss = 1.2335234880447388, GAN loss = [2.6260543, 0.90860444, 0.9984098]\n",
      "Batch 590/700: Discriminator loss = 1.1670652627944946, GAN loss = [2.7048843, 0.98209083, 1.0037636]\n",
      "Batch 591/700: Discriminator loss = 1.1574307680130005, GAN loss = [2.6138766, 0.9637056, 0.9311565]\n",
      "Batch 592/700: Discriminator loss = 1.2180546522140503, GAN loss = [2.645695, 0.95211875, 0.9745781]\n",
      "Batch 593/700: Discriminator loss = 1.1428900957107544, GAN loss = [2.6927714, 1.0083175, 0.96547025]\n",
      "Batch 594/700: Discriminator loss = 1.1238666772842407, GAN loss = [2.7028584, 0.9824221, 1.0014598]\n",
      "Batch 595/700: Discriminator loss = 1.223031997680664, GAN loss = [2.7455835, 0.957253, 1.0693606]\n",
      "Batch 596/700: Discriminator loss = 1.215710997581482, GAN loss = [2.5869613, 0.94878244, 0.91920686]\n",
      "Batch 597/700: Discriminator loss = 1.168902039527893, GAN loss = [2.711871, 0.9542568, 1.0386345]\n",
      "Batch 598/700: Discriminator loss = 1.2120858430862427, GAN loss = [2.5724425, 0.9304229, 0.92304224]\n",
      "Batch 599/700: Discriminator loss = 1.2375333309173584, GAN loss = [2.563747, 0.9354466, 0.90932566]\n",
      "Batch 600/700: Discriminator loss = 1.180274486541748, GAN loss = [2.6644917, 0.9636092, 0.9819118]\n",
      "Batch 601/700: Discriminator loss = 1.2085745334625244, GAN loss = [2.580434, 0.94431907, 0.9171373]\n",
      "Batch 602/700: Discriminator loss = 1.1990598440170288, GAN loss = [2.6328645, 0.9492406, 0.96464324]\n",
      "Batch 603/700: Discriminator loss = 1.1952601671218872, GAN loss = [2.5770807, 0.9879778, 0.87012273]\n",
      "Batch 604/700: Discriminator loss = 1.192518711090088, GAN loss = [2.5914948, 0.9576049, 0.914898]\n",
      "Batch 605/700: Discriminator loss = 1.2119389772415161, GAN loss = [2.5999186, 0.96141917, 0.91948944]\n",
      "Batch 606/700: Discriminator loss = 1.2235878705978394, GAN loss = [2.5438445, 0.9004247, 0.92439026]\n",
      "Batch 607/700: Discriminator loss = 1.2101858854293823, GAN loss = [2.6745172, 0.97276527, 0.9827086]\n",
      "Batch 608/700: Discriminator loss = 1.1754224300384521, GAN loss = [2.61654, 0.9591944, 0.9382926]\n",
      "Batch 609/700: Discriminator loss = 1.1981154680252075, GAN loss = [2.6708066, 1.012745, 0.93898284]\n",
      "Batch 610/700: Discriminator loss = 1.1729159355163574, GAN loss = [2.6180882, 0.9604568, 0.9385286]\n",
      "Batch 611/700: Discriminator loss = 1.188197135925293, GAN loss = [2.6166904, 0.95085126, 0.9467267]\n",
      "Batch 612/700: Discriminator loss = 1.1829841136932373, GAN loss = [2.6389046, 0.92084074, 0.99894065]\n",
      "Batch 613/700: Discriminator loss = 1.2068572044372559, GAN loss = [2.6362498, 0.94103134, 0.97609156]\n",
      "Batch 614/700: Discriminator loss = 1.1548233032226562, GAN loss = [2.7120254, 0.9561438, 1.0367494]\n",
      "Batch 615/700: Discriminator loss = 1.1423250436782837, GAN loss = [2.710586, 0.99347895, 0.9979657]\n",
      "Batch 616/700: Discriminator loss = 1.1872137784957886, GAN loss = [2.707907, 0.9191064, 1.0696201]\n",
      "Batch 617/700: Discriminator loss = 1.1693910360336304, GAN loss = [2.6772554, 0.98996425, 0.96808106]\n",
      "Batch 618/700: Discriminator loss = 1.1437257528305054, GAN loss = [2.7176385, 1.0093014, 0.9891054]\n",
      "Batch 619/700: Discriminator loss = 1.1466929912567139, GAN loss = [2.697149, 0.9690702, 1.0088246]\n",
      "Batch 620/700: Discriminator loss = 1.1650140285491943, GAN loss = [2.715768, 0.96817565, 1.0283188]\n",
      "Batch 621/700: Discriminator loss = 1.1708704233169556, GAN loss = [2.661611, 0.92945296, 1.0128807]\n",
      "Batch 622/700: Discriminator loss = 1.1230196952819824, GAN loss = [2.7701523, 0.9997777, 1.0510855]\n",
      "Batch 623/700: Discriminator loss = 1.1609232425689697, GAN loss = [2.7641156, 0.97283584, 1.0719777]\n",
      "Batch 624/700: Discriminator loss = 1.1415822505950928, GAN loss = [2.785132, 0.9623296, 1.1034837]\n",
      "Batch 625/700: Discriminator loss = 1.2037767171859741, GAN loss = [2.6349616, 0.92079544, 0.99483]\n",
      "Batch 626/700: Discriminator loss = 1.1481459140777588, GAN loss = [2.8129613, 1.0201819, 1.0734265]\n",
      "Batch 627/700: Discriminator loss = 1.1737704277038574, GAN loss = [2.7831938, 0.97374606, 1.0901008]\n",
      "Batch 628/700: Discriminator loss = 1.1583201885223389, GAN loss = [2.765339, 0.97109866, 1.0748875]\n",
      "Batch 629/700: Discriminator loss = 1.1372056007385254, GAN loss = [2.7583156, 1.0136553, 1.0252962]\n",
      "Batch 630/700: Discriminator loss = 1.1425243616104126, GAN loss = [2.9084606, 1.0016679, 1.187426]\n",
      "Batch 631/700: Discriminator loss = 1.1183987855911255, GAN loss = [2.758086, 0.99679726, 1.0419174]\n",
      "Batch 632/700: Discriminator loss = 1.181661605834961, GAN loss = [2.678393, 0.9655623, 0.9934599]\n",
      "Batch 633/700: Discriminator loss = 1.174515962600708, GAN loss = [2.842542, 0.97041965, 1.1527658]\n",
      "Batch 634/700: Discriminator loss = 1.1627562046051025, GAN loss = [2.7260237, 0.9637187, 1.0429631]\n",
      "Batch 635/700: Discriminator loss = 1.1646642684936523, GAN loss = [2.7521024, 0.99570554, 1.0370816]\n",
      "Batch 636/700: Discriminator loss = 1.1366422176361084, GAN loss = [2.9119868, 1.0187201, 1.1739557]\n",
      "Batch 637/700: Discriminator loss = 1.180967092514038, GAN loss = [2.7488523, 0.96082544, 1.0687164]\n",
      "Batch 638/700: Discriminator loss = 1.1715896129608154, GAN loss = [2.7996683, 0.952477, 1.1278759]\n",
      "Batch 639/700: Discriminator loss = 1.1560693979263306, GAN loss = [2.8566213, 0.9965559, 1.1407535]\n",
      "Batch 640/700: Discriminator loss = 1.2363179922103882, GAN loss = [2.8056126, 0.96782637, 1.1184765]\n",
      "Batch 641/700: Discriminator loss = 1.1834903955459595, GAN loss = [2.760281, 0.98202795, 1.0589473]\n",
      "Batch 642/700: Discriminator loss = 1.1813068389892578, GAN loss = [2.6776042, 0.9433786, 1.0149361]\n",
      "Batch 643/700: Discriminator loss = 1.223302960395813, GAN loss = [2.673181, 0.948973, 1.0049294]\n",
      "Batch 644/700: Discriminator loss = 1.2032790184020996, GAN loss = [2.722372, 0.97039396, 1.032703]\n",
      "Batch 645/700: Discriminator loss = 1.2499204874038696, GAN loss = [2.6947258, 0.92760897, 1.0478508]\n",
      "Batch 646/700: Discriminator loss = 1.2774556875228882, GAN loss = [2.603587, 0.907434, 0.9768917]\n",
      "Batch 647/700: Discriminator loss = 1.274693250656128, GAN loss = [2.541253, 0.881421, 0.94056237]\n",
      "Batch 648/700: Discriminator loss = 1.169105052947998, GAN loss = [2.689495, 0.9698208, 1.0004042]\n",
      "Batch 649/700: Discriminator loss = 1.2190011739730835, GAN loss = [2.5495243, 0.9339016, 0.89634466]\n",
      "Batch 650/700: Discriminator loss = 1.2311112880706787, GAN loss = [2.6216242, 0.935189, 0.9671456]\n",
      "Batch 651/700: Discriminator loss = 1.1634656190872192, GAN loss = [2.5642447, 0.952171, 0.8927779]\n",
      "Batch 652/700: Discriminator loss = 1.227850317955017, GAN loss = [2.59088, 0.91855675, 0.9530272]\n",
      "Batch 653/700: Discriminator loss = 1.2206841707229614, GAN loss = [2.6483366, 0.95820427, 0.97083765]\n",
      "Batch 654/700: Discriminator loss = 1.212846279144287, GAN loss = [2.6274707, 0.9675268, 0.94066423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 655/700: Discriminator loss = 1.1709424257278442, GAN loss = [2.6518133, 0.984668, 0.94786775]\n",
      "Batch 656/700: Discriminator loss = 1.183059573173523, GAN loss = [2.7024364, 0.9717612, 1.0113995]\n",
      "Batch 657/700: Discriminator loss = 1.166404128074646, GAN loss = [2.665782, 1.000144, 0.94637144]\n",
      "Batch 658/700: Discriminator loss = 1.2254472970962524, GAN loss = [2.534925, 0.8984204, 0.91725075]\n",
      "Batch 659/700: Discriminator loss = 1.1949737071990967, GAN loss = [2.6381857, 0.909329, 1.0096244]\n",
      "Batch 660/700: Discriminator loss = 1.1816502809524536, GAN loss = [2.5816739, 0.9455746, 0.9168837]\n",
      "Batch 661/700: Discriminator loss = 1.2216590642929077, GAN loss = [2.5636911, 0.9119365, 0.9325665]\n",
      "Batch 662/700: Discriminator loss = 1.1803752183914185, GAN loss = [2.7548816, 0.9577543, 1.0779631]\n",
      "Batch 663/700: Discriminator loss = 1.2262476682662964, GAN loss = [2.5356648, 0.87647605, 0.9400439]\n",
      "Batch 664/700: Discriminator loss = 1.230884313583374, GAN loss = [2.6435323, 0.91813165, 1.0062736]\n",
      "Batch 665/700: Discriminator loss = 1.1524211168289185, GAN loss = [2.7748456, 0.9954612, 1.0602784]\n",
      "Batch 666/700: Discriminator loss = 1.1651599407196045, GAN loss = [2.6188655, 0.955904, 0.9438741]\n",
      "Batch 667/700: Discriminator loss = 1.2140816450119019, GAN loss = [2.554339, 0.92466325, 0.910604]\n",
      "Batch 668/700: Discriminator loss = 1.2088876962661743, GAN loss = [2.5523715, 0.9189554, 0.9143358]\n",
      "Batch 669/700: Discriminator loss = 1.2187420129776, GAN loss = [2.4776545, 0.9058306, 0.8527424]\n",
      "Batch 670/700: Discriminator loss = 1.199668288230896, GAN loss = [2.6801977, 0.9293929, 1.0317427]\n",
      "Batch 671/700: Discriminator loss = 1.1594879627227783, GAN loss = [2.6084497, 0.94623727, 0.943161]\n",
      "Batch 672/700: Discriminator loss = 1.1886996030807495, GAN loss = [2.612357, 0.9104479, 0.98287237]\n",
      "Batch 673/700: Discriminator loss = 1.099989652633667, GAN loss = [2.7353525, 1.012257, 1.0040796]\n",
      "Batch 674/700: Discriminator loss = 1.1521538496017456, GAN loss = [2.5548534, 0.91992563, 0.91593504]\n",
      "Batch 675/700: Discriminator loss = 1.1499437093734741, GAN loss = [2.654689, 0.96574295, 0.9699738]\n",
      "Batch 676/700: Discriminator loss = 1.1876877546310425, GAN loss = [2.6626477, 0.92837924, 1.0152937]\n",
      "Batch 677/700: Discriminator loss = 1.1749927997589111, GAN loss = [2.6214938, 0.953545, 0.94896907]\n",
      "Batch 678/700: Discriminator loss = 1.165588617324829, GAN loss = [2.6210108, 0.9514825, 0.9505526]\n",
      "Batch 679/700: Discriminator loss = 1.200264573097229, GAN loss = [2.7030811, 0.929926, 1.0541985]\n",
      "Batch 680/700: Discriminator loss = 1.1870269775390625, GAN loss = [2.6151843, 0.91960174, 0.9766435]\n",
      "Batch 681/700: Discriminator loss = 1.1785626411437988, GAN loss = [2.6251938, 0.9609835, 0.94527626]\n",
      "Batch 682/700: Discriminator loss = 1.1622081995010376, GAN loss = [2.6906285, 0.9564765, 1.0152241]\n",
      "Batch 683/700: Discriminator loss = 1.132769227027893, GAN loss = [2.6662376, 0.97965735, 0.96766907]\n",
      "Batch 684/700: Discriminator loss = 1.1494779586791992, GAN loss = [2.699504, 0.9736843, 1.0069245]\n",
      "Batch 685/700: Discriminator loss = 1.1400903463363647, GAN loss = [2.764478, 0.97882, 1.0667819]\n",
      "Batch 686/700: Discriminator loss = 1.13665771484375, GAN loss = [2.6994822, 0.98005956, 1.0005683]\n",
      "Batch 687/700: Discriminator loss = 1.184585690498352, GAN loss = [2.5965552, 0.94176394, 0.93595266]\n",
      "Batch 688/700: Discriminator loss = 1.2129325866699219, GAN loss = [2.6644132, 0.9323628, 1.0132208]\n",
      "Batch 689/700: Discriminator loss = 1.2066612243652344, GAN loss = [2.669254, 0.9526281, 0.99781245]\n",
      "Batch 690/700: Discriminator loss = 1.1245399713516235, GAN loss = [2.7843227, 1.0027729, 1.062763]\n",
      "Batch 691/700: Discriminator loss = 1.1865383386611938, GAN loss = [2.5762944, 0.930748, 0.9267729]\n",
      "Batch 692/700: Discriminator loss = 1.2201067209243774, GAN loss = [2.6003668, 0.9404167, 0.9411801]\n",
      "Batch 693/700: Discriminator loss = 1.2117550373077393, GAN loss = [2.589477, 0.9439029, 0.92681915]\n",
      "Batch 694/700: Discriminator loss = 1.1375916004180908, GAN loss = [2.6637063, 0.967771, 0.97718793]\n",
      "Batch 695/700: Discriminator loss = 1.1541470289230347, GAN loss = [2.7171993, 0.99639374, 1.0020471]\n",
      "Batch 696/700: Discriminator loss = 1.1540448665618896, GAN loss = [2.73263, 0.9888054, 1.0250611]\n",
      "Batch 697/700: Discriminator loss = 1.1906609535217285, GAN loss = [2.5713918, 0.93118197, 0.9214346]\n",
      "Batch 698/700: Discriminator loss = 1.1298874616622925, GAN loss = [2.7303646, 1.0088724, 1.0027082]\n",
      "Batch 699/700: Discriminator loss = 1.1658157110214233, GAN loss = [2.60055, 0.9628261, 0.9189459]\n",
      "Batch 700/700: Discriminator loss = 1.1719602346420288, GAN loss = [2.665219, 0.9695206, 0.9769317]\n",
      "Epoch 15/30\n",
      "Batch 1/700: Discriminator loss = 1.1910333633422852, GAN loss = [2.6862082, 0.9664685, 1.0009834]\n",
      "Batch 2/700: Discriminator loss = 1.2451680898666382, GAN loss = [2.6011748, 0.92882216, 0.9536054]\n",
      "Batch 3/700: Discriminator loss = 1.1716516017913818, GAN loss = [2.6393785, 0.94049764, 0.9801342]\n",
      "Batch 4/700: Discriminator loss = 1.160914421081543, GAN loss = [2.6365488, 0.95135057, 0.96644706]\n",
      "Batch 5/700: Discriminator loss = 1.200381875038147, GAN loss = [2.5170162, 0.92257506, 0.87568265]\n",
      "Batch 6/700: Discriminator loss = 1.167133092880249, GAN loss = [2.6644945, 0.95959455, 0.98612547]\n",
      "Batch 7/700: Discriminator loss = 1.2587376832962036, GAN loss = [2.4804506, 0.8589906, 0.9026849]\n",
      "Batch 8/700: Discriminator loss = 1.3015729188919067, GAN loss = [2.5276802, 0.888162, 0.920748]\n",
      "Batch 9/700: Discriminator loss = 1.2168776988983154, GAN loss = [2.5759635, 0.93479913, 0.922389]\n",
      "Batch 10/700: Discriminator loss = 1.2110844850540161, GAN loss = [2.6104608, 0.95498866, 0.93670255]\n",
      "Batch 11/700: Discriminator loss = 1.2086542844772339, GAN loss = [2.6059163, 0.9574602, 0.9296817]\n",
      "Batch 12/700: Discriminator loss = 1.250967025756836, GAN loss = [2.4785302, 0.8916174, 0.8681443]\n",
      "Batch 13/700: Discriminator loss = 1.2356617450714111, GAN loss = [2.4875658, 0.92780596, 0.84098566]\n",
      "Batch 14/700: Discriminator loss = 1.2311581373214722, GAN loss = [2.5566182, 0.94605726, 0.8917801]\n",
      "Batch 15/700: Discriminator loss = 1.1999928951263428, GAN loss = [2.5287979, 0.930722, 0.87930036]\n",
      "Batch 16/700: Discriminator loss = 1.2847875356674194, GAN loss = [2.484734, 0.89505655, 0.870905]\n",
      "Batch 17/700: Discriminator loss = 1.208658218383789, GAN loss = [2.6014435, 0.9186296, 0.96405584]\n",
      "Batch 18/700: Discriminator loss = 1.1744531393051147, GAN loss = [2.5845644, 0.960576, 0.9052617]\n",
      "Batch 19/700: Discriminator loss = 1.1708786487579346, GAN loss = [2.6136315, 0.94783753, 0.9470954]\n",
      "Batch 20/700: Discriminator loss = 1.2178475856781006, GAN loss = [2.4910223, 0.90960866, 0.8627391]\n",
      "Batch 21/700: Discriminator loss = 1.2194768190383911, GAN loss = [2.5379753, 0.90595335, 0.9133772]\n",
      "Batch 22/700: Discriminator loss = 1.2095571756362915, GAN loss = [2.5375307, 0.8837991, 0.93510574]\n",
      "Batch 23/700: Discriminator loss = 1.2525218725204468, GAN loss = [2.5074332, 0.8966768, 0.8921351]\n",
      "Batch 24/700: Discriminator loss = 1.2770054340362549, GAN loss = [2.5117402, 0.88862616, 0.9044986]\n",
      "Batch 25/700: Discriminator loss = 1.1872602701187134, GAN loss = [2.4837914, 0.9230102, 0.8421713]\n",
      "Batch 26/700: Discriminator loss = 1.2370504140853882, GAN loss = [2.570696, 0.9073894, 0.9447006]\n",
      "Batch 27/700: Discriminator loss = 1.2247519493103027, GAN loss = [2.5540657, 0.89437324, 0.94109833]\n",
      "Batch 28/700: Discriminator loss = 1.2477885484695435, GAN loss = [2.5148082, 0.8794275, 0.9167962]\n",
      "Batch 29/700: Discriminator loss = 1.2348576784133911, GAN loss = [2.557989, 0.94117624, 0.8982312]\n",
      "Batch 30/700: Discriminator loss = 1.2190278768539429, GAN loss = [2.5931914, 0.92778367, 0.9468274]\n",
      "Batch 31/700: Discriminator loss = 1.2038962841033936, GAN loss = [2.5319679, 0.9144228, 0.898965]\n",
      "Batch 32/700: Discriminator loss = 1.2081903219223022, GAN loss = [2.5209188, 0.9107299, 0.891607]\n",
      "Batch 33/700: Discriminator loss = 1.1893259286880493, GAN loss = [2.509479, 0.93177664, 0.8591203]\n",
      "Batch 34/700: Discriminator loss = 1.1867198944091797, GAN loss = [2.5048125, 0.96114904, 0.8250986]\n",
      "Batch 35/700: Discriminator loss = 1.1783112287521362, GAN loss = [2.549651, 0.913799, 0.917293]\n",
      "Batch 36/700: Discriminator loss = 1.2251203060150146, GAN loss = [2.524023, 0.9257497, 0.879719]\n",
      "Batch 37/700: Discriminator loss = 1.1883583068847656, GAN loss = [2.5597155, 0.9157612, 0.925392]\n",
      "Batch 38/700: Discriminator loss = 1.2557754516601562, GAN loss = [2.4828687, 0.86205995, 0.9022269]\n",
      "Batch 39/700: Discriminator loss = 1.184569001197815, GAN loss = [2.6062045, 0.93629485, 0.9513248]\n",
      "Batch 40/700: Discriminator loss = 1.2559295892715454, GAN loss = [2.5517678, 0.8989884, 0.93419397]\n",
      "Batch 41/700: Discriminator loss = 1.200182318687439, GAN loss = [2.5185604, 0.9080813, 0.8918752]\n",
      "Batch 42/700: Discriminator loss = 1.2485103607177734, GAN loss = [2.4558074, 0.85664904, 0.88055336]\n",
      "Batch 43/700: Discriminator loss = 1.205922245979309, GAN loss = [2.5313003, 0.90416634, 0.90854394]\n",
      "Batch 44/700: Discriminator loss = 1.2524394989013672, GAN loss = [2.5330849, 0.90288526, 0.9116277]\n",
      "Batch 45/700: Discriminator loss = 1.218899130821228, GAN loss = [2.524996, 0.88674426, 0.9196939]\n",
      "Batch 46/700: Discriminator loss = 1.2403372526168823, GAN loss = [2.4829848, 0.8647965, 0.8996444]\n",
      "Batch 47/700: Discriminator loss = 1.2285957336425781, GAN loss = [2.5615532, 0.877172, 0.96584725]\n",
      "Batch 48/700: Discriminator loss = 1.24667227268219, GAN loss = [2.4257834, 0.8672362, 0.84002435]\n",
      "Batch 49/700: Discriminator loss = 1.281137228012085, GAN loss = [2.4660237, 0.8758336, 0.8716908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50/700: Discriminator loss = 1.2073986530303955, GAN loss = [2.5113575, 0.8820052, 0.9108808]\n",
      "Batch 51/700: Discriminator loss = 1.2051677703857422, GAN loss = [2.5567422, 0.9026582, 0.9356259]\n",
      "Batch 52/700: Discriminator loss = 1.2396745681762695, GAN loss = [2.4776642, 0.8654711, 0.893756]\n",
      "Batch 53/700: Discriminator loss = 1.2004821300506592, GAN loss = [2.551496, 0.88991594, 0.9431679]\n",
      "Batch 54/700: Discriminator loss = 1.1986273527145386, GAN loss = [2.5487957, 0.9022194, 0.9281861]\n",
      "Batch 55/700: Discriminator loss = 1.1931426525115967, GAN loss = [2.468213, 0.914291, 0.83556306]\n",
      "Batch 56/700: Discriminator loss = 1.227651834487915, GAN loss = [2.5037239, 0.877, 0.908396]\n",
      "Batch 57/700: Discriminator loss = 1.257693886756897, GAN loss = [2.5512893, 0.9181093, 0.9148851]\n",
      "Batch 58/700: Discriminator loss = 1.2134236097335815, GAN loss = [2.5419714, 0.88288385, 0.9408073]\n",
      "Batch 59/700: Discriminator loss = 1.1761316061019897, GAN loss = [2.5115411, 0.93188864, 0.8613815]\n",
      "Batch 60/700: Discriminator loss = 1.2487186193466187, GAN loss = [2.4624066, 0.87084574, 0.873303]\n",
      "Batch 61/700: Discriminator loss = 1.2419523000717163, GAN loss = [2.4249475, 0.86511046, 0.84158486]\n",
      "Batch 62/700: Discriminator loss = 1.2450437545776367, GAN loss = [2.4485497, 0.88132125, 0.8489799]\n",
      "Batch 63/700: Discriminator loss = 1.260798692703247, GAN loss = [2.4439383, 0.8656919, 0.8600022]\n",
      "Batch 64/700: Discriminator loss = 1.2366951704025269, GAN loss = [2.4650617, 0.9036141, 0.84319043]\n",
      "Batch 65/700: Discriminator loss = 1.2528671026229858, GAN loss = [2.4575026, 0.8875918, 0.8516504]\n",
      "Batch 66/700: Discriminator loss = 1.2723684310913086, GAN loss = [2.4718218, 0.85243434, 0.90113103]\n",
      "Batch 67/700: Discriminator loss = 1.2122904062271118, GAN loss = [2.4470427, 0.8855672, 0.8432205]\n",
      "Batch 68/700: Discriminator loss = 1.2500137090682983, GAN loss = [2.3647635, 0.8574677, 0.78904814]\n",
      "Batch 69/700: Discriminator loss = 1.2308580875396729, GAN loss = [2.4431372, 0.88821936, 0.8366754]\n",
      "Batch 70/700: Discriminator loss = 1.2335914373397827, GAN loss = [2.4988124, 0.8954463, 0.8851359]\n",
      "Batch 71/700: Discriminator loss = 1.2506672143936157, GAN loss = [2.4678714, 0.88573486, 0.8639205]\n",
      "Batch 72/700: Discriminator loss = 1.169705867767334, GAN loss = [2.5546315, 0.91938806, 0.9170428]\n",
      "Batch 73/700: Discriminator loss = 1.2297782897949219, GAN loss = [2.4435742, 0.8827336, 0.8426471]\n",
      "Batch 74/700: Discriminator loss = 1.2248612642288208, GAN loss = [2.420218, 0.8982254, 0.80381066]\n",
      "Batch 75/700: Discriminator loss = 1.22681725025177, GAN loss = [2.4638422, 0.8773376, 0.8683273]\n",
      "Batch 76/700: Discriminator loss = 1.267548680305481, GAN loss = [2.416691, 0.8771367, 0.8213723]\n",
      "Batch 77/700: Discriminator loss = 1.1792283058166504, GAN loss = [2.5429852, 0.90570223, 0.91908544]\n",
      "Batch 78/700: Discriminator loss = 1.245157241821289, GAN loss = [2.4297943, 0.8545628, 0.85701853]\n",
      "Batch 79/700: Discriminator loss = 1.1897263526916504, GAN loss = [2.4933472, 0.9005339, 0.87458426]\n",
      "Batch 80/700: Discriminator loss = 1.250364065170288, GAN loss = [2.344569, 0.8509227, 0.77540886]\n",
      "Batch 81/700: Discriminator loss = 1.2078484296798706, GAN loss = [2.470175, 0.8737166, 0.8782344]\n",
      "Batch 82/700: Discriminator loss = 1.2475262880325317, GAN loss = [2.4996016, 0.8851177, 0.8962811]\n",
      "Batch 83/700: Discriminator loss = 1.2053340673446655, GAN loss = [2.469605, 0.89225054, 0.8591575]\n",
      "Batch 84/700: Discriminator loss = 1.1954190731048584, GAN loss = [2.4837348, 0.8834215, 0.8821164]\n",
      "Batch 85/700: Discriminator loss = 1.2386995553970337, GAN loss = [2.4048822, 0.8466933, 0.83999926]\n",
      "Batch 86/700: Discriminator loss = 1.2071751356124878, GAN loss = [2.3812363, 0.85327077, 0.80978644]\n",
      "Batch 87/700: Discriminator loss = 1.234487533569336, GAN loss = [2.4260635, 0.8760196, 0.83187103]\n",
      "Batch 88/700: Discriminator loss = 1.225202202796936, GAN loss = [2.4025388, 0.84960556, 0.83476186]\n",
      "Batch 89/700: Discriminator loss = 1.2375186681747437, GAN loss = [2.4215238, 0.8453385, 0.8580126]\n",
      "Batch 90/700: Discriminator loss = 1.205348014831543, GAN loss = [2.4434536, 0.8602474, 0.8650128]\n",
      "Batch 91/700: Discriminator loss = 1.209958791732788, GAN loss = [2.4826121, 0.8733093, 0.89110327]\n",
      "Batch 92/700: Discriminator loss = 1.208004117012024, GAN loss = [2.4384131, 0.8702426, 0.84997636]\n",
      "Batch 93/700: Discriminator loss = 1.2256208658218384, GAN loss = [2.407804, 0.8435514, 0.84606725]\n",
      "Batch 94/700: Discriminator loss = 1.2048070430755615, GAN loss = [2.4132628, 0.88060725, 0.8144713]\n",
      "Batch 95/700: Discriminator loss = 1.2256499528884888, GAN loss = [2.4149683, 0.8356716, 0.8611121]\n",
      "Batch 96/700: Discriminator loss = 1.2136753797531128, GAN loss = [2.4041286, 0.8372255, 0.8487088]\n",
      "Batch 97/700: Discriminator loss = 1.2382696866989136, GAN loss = [2.417189, 0.83543116, 0.8635614]\n",
      "Batch 98/700: Discriminator loss = 1.2039653062820435, GAN loss = [2.4333062, 0.8619287, 0.8531777]\n",
      "Batch 99/700: Discriminator loss = 1.201759696006775, GAN loss = [2.4588706, 0.8603971, 0.8802781]\n",
      "Batch 100/700: Discriminator loss = 1.199047565460205, GAN loss = [2.432124, 0.8669115, 0.8470333]\n",
      "Batch 101/700: Discriminator loss = 1.18230402469635, GAN loss = [2.4208298, 0.8643035, 0.83835965]\n",
      "Batch 102/700: Discriminator loss = 1.181340217590332, GAN loss = [2.4276383, 0.86579776, 0.8436816]\n",
      "Batch 103/700: Discriminator loss = 1.1539310216903687, GAN loss = [2.5579638, 0.9320291, 0.907777]\n",
      "Batch 104/700: Discriminator loss = 1.229353904724121, GAN loss = [2.4021444, 0.8337967, 0.85019267]\n",
      "Batch 105/700: Discriminator loss = 1.1626919507980347, GAN loss = [2.4938674, 0.88423014, 0.89147294]\n",
      "Batch 106/700: Discriminator loss = 1.1848721504211426, GAN loss = [2.5037792, 0.87067676, 0.91493464]\n",
      "Batch 107/700: Discriminator loss = 1.185684084892273, GAN loss = [2.5076277, 0.8629489, 0.9265076]\n",
      "Batch 108/700: Discriminator loss = 1.1724178791046143, GAN loss = [2.5041246, 0.8859912, 0.89995825]\n",
      "Batch 109/700: Discriminator loss = 1.1805782318115234, GAN loss = [2.4711838, 0.8640633, 0.8889383]\n",
      "Batch 110/700: Discriminator loss = 1.2553333044052124, GAN loss = [2.4381168, 0.8141161, 0.90580946]\n",
      "Batch 111/700: Discriminator loss = 1.2152305841445923, GAN loss = [2.4511216, 0.84265345, 0.8902634]\n",
      "Batch 112/700: Discriminator loss = 1.1935770511627197, GAN loss = [2.4858377, 0.86658645, 0.9010341]\n",
      "Batch 113/700: Discriminator loss = 1.2033448219299316, GAN loss = [2.4839296, 0.8574955, 0.90821654]\n",
      "Batch 114/700: Discriminator loss = 1.188773274421692, GAN loss = [2.522422, 0.8714951, 0.93271124]\n",
      "Batch 115/700: Discriminator loss = 1.1646416187286377, GAN loss = [2.4647202, 0.8831834, 0.86331856]\n",
      "Batch 116/700: Discriminator loss = 1.187191128730774, GAN loss = [2.5367162, 0.87022954, 0.94827116]\n",
      "Batch 117/700: Discriminator loss = 1.1534303426742554, GAN loss = [2.5137138, 0.90988994, 0.88562304]\n",
      "Batch 118/700: Discriminator loss = 1.1805710792541504, GAN loss = [2.5844786, 0.8710248, 0.99526423]\n",
      "Batch 119/700: Discriminator loss = 1.1904727220535278, GAN loss = [2.4971223, 0.88581294, 0.893121]\n",
      "Batch 120/700: Discriminator loss = 1.176122784614563, GAN loss = [2.499882, 0.8763158, 0.905377]\n",
      "Batch 121/700: Discriminator loss = 1.2099575996398926, GAN loss = [2.4709206, 0.8605807, 0.8921376]\n",
      "Batch 122/700: Discriminator loss = 1.1793596744537354, GAN loss = [2.523323, 0.8856612, 0.9194545]\n",
      "Batch 123/700: Discriminator loss = 1.1856348514556885, GAN loss = [2.4424005, 0.8703208, 0.8538753]\n",
      "Batch 124/700: Discriminator loss = 1.224416732788086, GAN loss = [2.4350953, 0.83995, 0.8769359]\n",
      "Batch 125/700: Discriminator loss = 1.2534812688827515, GAN loss = [2.3408177, 0.7919649, 0.83064497]\n",
      "Batch 126/700: Discriminator loss = 1.2163361310958862, GAN loss = [2.497314, 0.844846, 0.93427277]\n",
      "Batch 127/700: Discriminator loss = 1.2096900939941406, GAN loss = [2.480538, 0.8539269, 0.90841657]\n",
      "Batch 128/700: Discriminator loss = 1.227732539176941, GAN loss = [2.4575696, 0.83928317, 0.9000985]\n",
      "Batch 129/700: Discriminator loss = 1.2514111995697021, GAN loss = [2.418495, 0.8231156, 0.8771945]\n",
      "Batch 130/700: Discriminator loss = 1.2259680032730103, GAN loss = [2.5063577, 0.8443348, 0.9438444]\n",
      "Batch 131/700: Discriminator loss = 1.2586435079574585, GAN loss = [2.4084058, 0.799921, 0.89029855]\n",
      "Batch 132/700: Discriminator loss = 1.2698527574539185, GAN loss = [2.389516, 0.80153465, 0.8698077]\n",
      "Batch 133/700: Discriminator loss = 1.199339509010315, GAN loss = [2.4286382, 0.8513357, 0.85913324]\n",
      "Batch 134/700: Discriminator loss = 1.220725417137146, GAN loss = [2.4716609, 0.84000885, 0.91349494]\n",
      "Batch 135/700: Discriminator loss = 1.2251849174499512, GAN loss = [2.3860686, 0.8323851, 0.83553123]\n",
      "Batch 136/700: Discriminator loss = 1.210960030555725, GAN loss = [2.4297616, 0.83368033, 0.87793213]\n",
      "Batch 137/700: Discriminator loss = 1.2002716064453125, GAN loss = [2.460429, 0.83867484, 0.9036144]\n",
      "Batch 138/700: Discriminator loss = 1.1997607946395874, GAN loss = [2.5202413, 0.8765393, 0.9255659]\n",
      "Batch 139/700: Discriminator loss = 1.205134391784668, GAN loss = [2.483281, 0.8496897, 0.91545004]\n",
      "Batch 140/700: Discriminator loss = 1.1932250261306763, GAN loss = [2.4208572, 0.85273355, 0.8499829]\n",
      "Batch 141/700: Discriminator loss = 1.2022826671600342, GAN loss = [2.4918227, 0.8869493, 0.88674057]\n",
      "Batch 142/700: Discriminator loss = 1.2166188955307007, GAN loss = [2.455869, 0.8443825, 0.8933495]\n",
      "Batch 143/700: Discriminator loss = 1.2418184280395508, GAN loss = [2.4603918, 0.81546354, 0.92680323]\n",
      "Batch 144/700: Discriminator loss = 1.202975869178772, GAN loss = [2.5131068, 0.86724913, 0.9277389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 145/700: Discriminator loss = 1.2123548984527588, GAN loss = [2.3993185, 0.8366734, 0.844526]\n",
      "Batch 146/700: Discriminator loss = 1.2423450946807861, GAN loss = [2.4344926, 0.832883, 0.8834832]\n",
      "Batch 147/700: Discriminator loss = 1.204352855682373, GAN loss = [2.491617, 0.86211526, 0.91137403]\n",
      "Batch 148/700: Discriminator loss = 1.2174842357635498, GAN loss = [2.4455347, 0.867398, 0.8600259]\n",
      "Batch 149/700: Discriminator loss = 1.1976221799850464, GAN loss = [2.390348, 0.8707106, 0.8015262]\n",
      "Batch 150/700: Discriminator loss = 1.2155754566192627, GAN loss = [2.5063195, 0.86081296, 0.9274015]\n",
      "Batch 151/700: Discriminator loss = 1.2439860105514526, GAN loss = [2.467192, 0.8647757, 0.884324]\n",
      "Batch 152/700: Discriminator loss = 1.2362022399902344, GAN loss = [2.4572752, 0.8309269, 0.90826035]\n",
      "Batch 153/700: Discriminator loss = 1.2421495914459229, GAN loss = [2.4121077, 0.8330601, 0.86096597]\n",
      "Batch 154/700: Discriminator loss = 1.2134464979171753, GAN loss = [2.4691603, 0.8629598, 0.88811475]\n",
      "Batch 155/700: Discriminator loss = 1.2301274538040161, GAN loss = [2.4090383, 0.8216852, 0.8692575]\n",
      "Batch 156/700: Discriminator loss = 1.2336159944534302, GAN loss = [2.4215007, 0.85471296, 0.84868544]\n",
      "Batch 157/700: Discriminator loss = 1.1996296644210815, GAN loss = [2.4974236, 0.8822003, 0.8971188]\n",
      "Batch 158/700: Discriminator loss = 1.2599607706069946, GAN loss = [2.4452252, 0.82605773, 0.9010569]\n",
      "Batch 159/700: Discriminator loss = 1.2115354537963867, GAN loss = [2.477046, 0.8321103, 0.9268105]\n",
      "Batch 160/700: Discriminator loss = 1.2140072584152222, GAN loss = [2.435555, 0.8414734, 0.8759422]\n",
      "Batch 161/700: Discriminator loss = 1.235105037689209, GAN loss = [2.4190001, 0.82124686, 0.8796115]\n",
      "Batch 162/700: Discriminator loss = 1.214994192123413, GAN loss = [2.4317625, 0.84183264, 0.87178874]\n",
      "Batch 163/700: Discriminator loss = 1.1972243785858154, GAN loss = [2.4708328, 0.8395838, 0.91310483]\n",
      "Batch 164/700: Discriminator loss = 1.2412834167480469, GAN loss = [2.4365814, 0.8528829, 0.8655505]\n",
      "Batch 165/700: Discriminator loss = 1.162598729133606, GAN loss = [2.4837725, 0.89868975, 0.8669312]\n",
      "Batch 166/700: Discriminator loss = 1.180971384048462, GAN loss = [2.55915, 0.861935, 0.979067]\n",
      "Batch 167/700: Discriminator loss = 1.2151020765304565, GAN loss = [2.5047722, 0.8585913, 0.92802405]\n",
      "Batch 168/700: Discriminator loss = 1.1903795003890991, GAN loss = [2.5253007, 0.8714783, 0.93564993]\n",
      "Batch 169/700: Discriminator loss = 1.2052464485168457, GAN loss = [2.5159435, 0.87204695, 0.92571104]\n",
      "Batch 170/700: Discriminator loss = 1.2046985626220703, GAN loss = [2.5054195, 0.8658158, 0.9214108]\n",
      "Batch 171/700: Discriminator loss = 1.18659245967865, GAN loss = [2.5408056, 0.88004977, 0.94255507]\n",
      "Batch 172/700: Discriminator loss = 1.2098206281661987, GAN loss = [2.4817092, 0.85500765, 0.90848565]\n",
      "Batch 173/700: Discriminator loss = 1.2171871662139893, GAN loss = [2.5039356, 0.8668917, 0.91880494]\n",
      "Batch 174/700: Discriminator loss = 1.198428988456726, GAN loss = [2.5572925, 0.8832934, 0.9557447]\n",
      "Batch 175/700: Discriminator loss = 1.2016572952270508, GAN loss = [2.4946413, 0.91388685, 0.8624954]\n",
      "Batch 176/700: Discriminator loss = 1.2263829708099365, GAN loss = [2.4754348, 0.8438608, 0.91332376]\n",
      "Batch 177/700: Discriminator loss = 1.2618495225906372, GAN loss = [2.4104626, 0.82699335, 0.8652285]\n",
      "Batch 178/700: Discriminator loss = 1.2351161241531372, GAN loss = [2.4929063, 0.8474205, 0.92726386]\n",
      "Batch 179/700: Discriminator loss = 1.2303022146224976, GAN loss = [2.4520216, 0.8400479, 0.89374954]\n",
      "Batch 180/700: Discriminator loss = 1.1894702911376953, GAN loss = [2.5538092, 0.9136866, 0.9218854]\n",
      "Batch 181/700: Discriminator loss = 1.247611165046692, GAN loss = [2.3881364, 0.82662153, 0.84326446]\n",
      "Batch 182/700: Discriminator loss = 1.2338415384292603, GAN loss = [2.3966644, 0.8202105, 0.8582069]\n",
      "Batch 183/700: Discriminator loss = 1.1930468082427979, GAN loss = [2.4397519, 0.8734942, 0.84802514]\n",
      "Batch 184/700: Discriminator loss = 1.1906523704528809, GAN loss = [2.4805558, 0.87118226, 0.89115053]\n",
      "Batch 185/700: Discriminator loss = 1.2032133340835571, GAN loss = [2.442088, 0.842793, 0.88107675]\n",
      "Batch 186/700: Discriminator loss = 1.2350178956985474, GAN loss = [2.3867028, 0.8217727, 0.8467203]\n",
      "Batch 187/700: Discriminator loss = 1.2304259538650513, GAN loss = [2.4160247, 0.8225961, 0.8752163]\n",
      "Batch 188/700: Discriminator loss = 1.2344499826431274, GAN loss = [2.5366287, 0.82634157, 0.9920763]\n",
      "Batch 189/700: Discriminator loss = 1.2160762548446655, GAN loss = [2.4783387, 0.84372306, 0.9164056]\n",
      "Batch 190/700: Discriminator loss = 1.1900800466537476, GAN loss = [2.4584427, 0.87389404, 0.8663365]\n",
      "Batch 191/700: Discriminator loss = 1.2415677309036255, GAN loss = [2.4059775, 0.8257732, 0.86198443]\n",
      "Batch 192/700: Discriminator loss = 1.2470424175262451, GAN loss = [2.4839425, 0.8245861, 0.94113517]\n",
      "Batch 193/700: Discriminator loss = 1.2242960929870605, GAN loss = [2.4375107, 0.84893876, 0.8703487]\n",
      "Batch 194/700: Discriminator loss = 1.2479552030563354, GAN loss = [2.4423766, 0.80925584, 0.9149028]\n",
      "Batch 195/700: Discriminator loss = 1.2358087301254272, GAN loss = [2.4233325, 0.83361053, 0.87151396]\n",
      "Batch 196/700: Discriminator loss = 1.2319211959838867, GAN loss = [2.433355, 0.8374113, 0.8777528]\n",
      "Batch 197/700: Discriminator loss = 1.2004212141036987, GAN loss = [2.4269414, 0.8634598, 0.8452922]\n",
      "Batch 198/700: Discriminator loss = 1.241753339767456, GAN loss = [2.4425116, 0.8147659, 0.90956426]\n",
      "Batch 199/700: Discriminator loss = 1.2544702291488647, GAN loss = [2.3814168, 0.8088853, 0.8543455]\n",
      "Batch 200/700: Discriminator loss = 1.207560658454895, GAN loss = [2.512391, 0.85171586, 0.9424968]\n",
      "Batch 201/700: Discriminator loss = 1.213771939277649, GAN loss = [2.4396572, 0.8689218, 0.85257345]\n",
      "Batch 202/700: Discriminator loss = 1.251387357711792, GAN loss = [2.4429688, 0.83213156, 0.8926861]\n",
      "Batch 203/700: Discriminator loss = 1.2344001531600952, GAN loss = [2.416227, 0.83684105, 0.86124396]\n",
      "Batch 204/700: Discriminator loss = 1.2056679725646973, GAN loss = [2.416459, 0.8565011, 0.84182197]\n",
      "Batch 205/700: Discriminator loss = 1.2119770050048828, GAN loss = [2.4798017, 0.8665561, 0.89511377]\n",
      "Batch 206/700: Discriminator loss = 1.1863374710083008, GAN loss = [2.4258125, 0.8682421, 0.8394354]\n",
      "Batch 207/700: Discriminator loss = 1.2058131694793701, GAN loss = [2.3756156, 0.84304565, 0.81443167]\n",
      "Batch 208/700: Discriminator loss = 1.2112672328948975, GAN loss = [2.4026103, 0.83253473, 0.851932]\n",
      "Batch 209/700: Discriminator loss = 1.2231632471084595, GAN loss = [2.4334671, 0.8481066, 0.86721724]\n",
      "Batch 210/700: Discriminator loss = 1.1761091947555542, GAN loss = [2.4668233, 0.8840782, 0.8645919]\n",
      "Batch 211/700: Discriminator loss = 1.2216910123825073, GAN loss = [2.4300637, 0.85685694, 0.8550499]\n",
      "Batch 212/700: Discriminator loss = 1.1929632425308228, GAN loss = [2.4369233, 0.86137533, 0.8573966]\n",
      "Batch 213/700: Discriminator loss = 1.2025731801986694, GAN loss = [2.4280348, 0.88349175, 0.82639205]\n",
      "Batch 214/700: Discriminator loss = 1.2279349565505981, GAN loss = [2.4597893, 0.86737543, 0.8742769]\n",
      "Batch 215/700: Discriminator loss = 1.1877089738845825, GAN loss = [2.4968634, 0.87598747, 0.90274024]\n",
      "Batch 216/700: Discriminator loss = 1.1946134567260742, GAN loss = [2.45731, 0.8909978, 0.84817994]\n",
      "Batch 217/700: Discriminator loss = 1.1849586963653564, GAN loss = [2.4648302, 0.87442833, 0.87227625]\n",
      "Batch 218/700: Discriminator loss = 1.2073067426681519, GAN loss = [2.4704463, 0.8570928, 0.89523345]\n",
      "Batch 219/700: Discriminator loss = 1.2558963298797607, GAN loss = [2.4120567, 0.81701475, 0.87692755]\n",
      "Batch 220/700: Discriminator loss = 1.186835765838623, GAN loss = [2.5433319, 0.8829523, 0.9422806]\n",
      "Batch 221/700: Discriminator loss = 1.1838111877441406, GAN loss = [2.4164896, 0.85856384, 0.83983064]\n",
      "Batch 222/700: Discriminator loss = 1.2182430028915405, GAN loss = [2.5140998, 0.87506425, 0.92096555]\n",
      "Batch 223/700: Discriminator loss = 1.20406973361969, GAN loss = [2.4570699, 0.86570555, 0.8733126]\n",
      "Batch 224/700: Discriminator loss = 1.1579941511154175, GAN loss = [2.498001, 0.8967489, 0.8832237]\n",
      "Batch 225/700: Discriminator loss = 1.226719617843628, GAN loss = [2.3997989, 0.8465299, 0.83525443]\n",
      "Batch 226/700: Discriminator loss = 1.2257788181304932, GAN loss = [2.4991813, 0.90989935, 0.8712764]\n",
      "Batch 227/700: Discriminator loss = 1.1862183809280396, GAN loss = [2.51953, 0.89649355, 0.90504164]\n",
      "Batch 228/700: Discriminator loss = 1.1808325052261353, GAN loss = [2.5166454, 0.89265525, 0.90600485]\n",
      "Batch 229/700: Discriminator loss = 1.1765936613082886, GAN loss = [2.5578566, 0.91957873, 0.920293]\n",
      "Batch 230/700: Discriminator loss = 1.1610232591629028, GAN loss = [2.5462039, 0.91660416, 0.9116127]\n",
      "Batch 231/700: Discriminator loss = 1.1799496412277222, GAN loss = [2.4635186, 0.89083, 0.8547006]\n",
      "Batch 232/700: Discriminator loss = 1.1387214660644531, GAN loss = [2.5547602, 0.9242306, 0.9125442]\n",
      "Batch 233/700: Discriminator loss = 1.1933691501617432, GAN loss = [2.4277055, 0.8665967, 0.84312844]\n",
      "Batch 234/700: Discriminator loss = 1.1993613243103027, GAN loss = [2.465529, 0.8665112, 0.8810437]\n",
      "Batch 235/700: Discriminator loss = 1.1794887781143188, GAN loss = [2.4617777, 0.87853783, 0.8652769]\n",
      "Batch 236/700: Discriminator loss = 1.180806279182434, GAN loss = [2.5372217, 0.87455314, 0.94472337]\n",
      "Batch 237/700: Discriminator loss = 1.167242407798767, GAN loss = [2.5045588, 0.90272737, 0.8839076]\n",
      "Batch 238/700: Discriminator loss = 1.165630578994751, GAN loss = [2.4627047, 0.88742167, 0.85737836]\n",
      "Batch 239/700: Discriminator loss = 1.2006644010543823, GAN loss = [2.5617204, 0.86369234, 0.98014086]\n",
      "Batch 240/700: Discriminator loss = 1.1380268335342407, GAN loss = [2.5606701, 0.91286904, 0.929929]\n",
      "Batch 241/700: Discriminator loss = 1.2136600017547607, GAN loss = [2.4488463, 0.859585, 0.87139857]\n",
      "Batch 242/700: Discriminator loss = 1.155210018157959, GAN loss = [2.5950358, 0.8997648, 0.9774203]\n",
      "Batch 243/700: Discriminator loss = 1.2165203094482422, GAN loss = [2.4623141, 0.85123605, 0.89322126]\n",
      "Batch 244/700: Discriminator loss = 1.2043864727020264, GAN loss = [2.4272945, 0.84454024, 0.8649001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 245/700: Discriminator loss = 1.253036379814148, GAN loss = [2.4109051, 0.8455802, 0.847478]\n",
      "Batch 246/700: Discriminator loss = 1.1851836442947388, GAN loss = [2.5821116, 0.8854055, 0.97886366]\n",
      "Batch 247/700: Discriminator loss = 1.2000575065612793, GAN loss = [2.499516, 0.86537474, 0.9163104]\n",
      "Batch 248/700: Discriminator loss = 1.2233645915985107, GAN loss = [2.4650955, 0.8355321, 0.9117497]\n",
      "Batch 249/700: Discriminator loss = 1.2413214445114136, GAN loss = [2.4643323, 0.8422563, 0.9042766]\n",
      "Batch 250/700: Discriminator loss = 1.2716368436813354, GAN loss = [2.4397519, 0.8293763, 0.89259356]\n",
      "Batch 251/700: Discriminator loss = 1.2185876369476318, GAN loss = [2.4297845, 0.8396781, 0.8723356]\n",
      "Batch 252/700: Discriminator loss = 1.231764793395996, GAN loss = [2.3729894, 0.80971205, 0.84551615]\n",
      "Batch 253/700: Discriminator loss = 1.2298654317855835, GAN loss = [2.437351, 0.8226346, 0.8969694]\n",
      "Batch 254/700: Discriminator loss = 1.254040241241455, GAN loss = [2.358993, 0.7978977, 0.8433707]\n",
      "Batch 255/700: Discriminator loss = 1.2251495122909546, GAN loss = [2.4501617, 0.8462952, 0.8861561]\n",
      "Batch 256/700: Discriminator loss = 1.216612458229065, GAN loss = [2.4119499, 0.8472645, 0.8469812]\n",
      "Batch 257/700: Discriminator loss = 1.2579425573349, GAN loss = [2.409282, 0.8294448, 0.86214644]\n",
      "Batch 258/700: Discriminator loss = 1.2857294082641602, GAN loss = [2.3957114, 0.79809934, 0.8799379]\n",
      "Batch 259/700: Discriminator loss = 1.215863585472107, GAN loss = [2.404483, 0.83837354, 0.848452]\n",
      "Batch 260/700: Discriminator loss = 1.2046207189559937, GAN loss = [2.4085884, 0.83912003, 0.8518226]\n",
      "Batch 261/700: Discriminator loss = 1.2791014909744263, GAN loss = [2.3525445, 0.8158687, 0.81905156]\n",
      "Batch 262/700: Discriminator loss = 1.22792649269104, GAN loss = [2.3647401, 0.83578265, 0.811366]\n",
      "Batch 263/700: Discriminator loss = 1.2723150253295898, GAN loss = [2.4238613, 0.8437505, 0.8625454]\n",
      "Batch 264/700: Discriminator loss = 1.257670283317566, GAN loss = [2.4074793, 0.8524102, 0.837529]\n",
      "Batch 265/700: Discriminator loss = 1.2147400379180908, GAN loss = [2.4163363, 0.85796666, 0.8408663]\n",
      "Batch 266/700: Discriminator loss = 1.2183157205581665, GAN loss = [2.4066787, 0.8417658, 0.8474412]\n",
      "Batch 267/700: Discriminator loss = 1.2362406253814697, GAN loss = [2.4865558, 0.8636756, 0.90542716]\n",
      "Batch 268/700: Discriminator loss = 1.227372169494629, GAN loss = [2.3819606, 0.85882425, 0.8057046]\n",
      "Batch 269/700: Discriminator loss = 1.198368787765503, GAN loss = [2.4409351, 0.8719446, 0.8515732]\n",
      "Batch 270/700: Discriminator loss = 1.2251696586608887, GAN loss = [2.4391165, 0.8517449, 0.86996794]\n",
      "Batch 271/700: Discriminator loss = 1.2122101783752441, GAN loss = [2.4615521, 0.87670594, 0.86746264]\n",
      "Batch 272/700: Discriminator loss = 1.200536847114563, GAN loss = [2.4301507, 0.84404147, 0.86873853]\n",
      "Batch 273/700: Discriminator loss = 1.252928614616394, GAN loss = [2.396874, 0.82591677, 0.8535962]\n",
      "Batch 274/700: Discriminator loss = 1.2053242921829224, GAN loss = [2.4081266, 0.85634774, 0.83442503]\n",
      "Batch 275/700: Discriminator loss = 1.20845365524292, GAN loss = [2.4779983, 0.85165304, 0.90899855]\n",
      "Batch 276/700: Discriminator loss = 1.2283155918121338, GAN loss = [2.3995478, 0.8246711, 0.8575394]\n",
      "Batch 277/700: Discriminator loss = 1.2260702848434448, GAN loss = [2.3815632, 0.8238692, 0.84036857]\n",
      "Batch 278/700: Discriminator loss = 1.2123488187789917, GAN loss = [2.4548414, 0.8284065, 0.90913165]\n",
      "Batch 279/700: Discriminator loss = 1.2080883979797363, GAN loss = [2.4211705, 0.83708763, 0.86679816]\n",
      "Batch 280/700: Discriminator loss = 1.2143281698226929, GAN loss = [2.4813743, 0.8359332, 0.9281809]\n",
      "Batch 281/700: Discriminator loss = 1.2149001359939575, GAN loss = [2.492685, 0.8503856, 0.92505854]\n",
      "Batch 282/700: Discriminator loss = 1.2351469993591309, GAN loss = [2.3884022, 0.82866454, 0.84250814]\n",
      "Batch 283/700: Discriminator loss = 1.1963480710983276, GAN loss = [2.4593637, 0.8562783, 0.88587815]\n",
      "Batch 284/700: Discriminator loss = 1.2027158737182617, GAN loss = [2.4640965, 0.8576591, 0.8892503]\n",
      "Batch 285/700: Discriminator loss = 1.1951528787612915, GAN loss = [2.4198298, 0.8321814, 0.8704773]\n",
      "Batch 286/700: Discriminator loss = 1.201447606086731, GAN loss = [2.4580965, 0.84250695, 0.8984383]\n",
      "Batch 287/700: Discriminator loss = 1.2085992097854614, GAN loss = [2.4526682, 0.85415894, 0.8813717]\n",
      "Batch 288/700: Discriminator loss = 1.203196406364441, GAN loss = [2.4166505, 0.8484015, 0.8511306]\n",
      "Batch 289/700: Discriminator loss = 1.1686280965805054, GAN loss = [2.5395083, 0.875326, 0.9470823]\n",
      "Batch 290/700: Discriminator loss = 1.1718887090682983, GAN loss = [2.5302997, 0.8762171, 0.93700445]\n",
      "Batch 291/700: Discriminator loss = 1.1838421821594238, GAN loss = [2.5018766, 0.8608244, 0.9239916]\n",
      "Batch 292/700: Discriminator loss = 1.1829841136932373, GAN loss = [2.4826632, 0.86486757, 0.9007468]\n",
      "Batch 293/700: Discriminator loss = 1.2306822538375854, GAN loss = [2.4449441, 0.8270354, 0.90086293]\n",
      "Batch 294/700: Discriminator loss = 1.196243405342102, GAN loss = [2.4960964, 0.8804815, 0.8985712]\n",
      "Batch 295/700: Discriminator loss = 1.179815649986267, GAN loss = [2.5208411, 0.85361326, 0.95018995]\n",
      "Batch 296/700: Discriminator loss = 1.2048450708389282, GAN loss = [2.45408, 0.8267647, 0.9102851]\n",
      "Batch 297/700: Discriminator loss = 1.2388803958892822, GAN loss = [2.490252, 0.875188, 0.89803696]\n",
      "Batch 298/700: Discriminator loss = 1.2114890813827515, GAN loss = [2.4739118, 0.860806, 0.8960911]\n",
      "Batch 299/700: Discriminator loss = 1.1844879388809204, GAN loss = [2.5014482, 0.86216164, 0.92227155]\n",
      "Batch 300/700: Discriminator loss = 1.2215023040771484, GAN loss = [2.4613264, 0.83294016, 0.91135806]\n",
      "Batch 301/700: Discriminator loss = 1.2259191274642944, GAN loss = [2.4411771, 0.8385897, 0.8855504]\n",
      "Batch 302/700: Discriminator loss = 1.221490740776062, GAN loss = [2.4412506, 0.8197653, 0.90444064]\n",
      "Batch 303/700: Discriminator loss = 1.2345709800720215, GAN loss = [2.3978543, 0.82021403, 0.8605869]\n",
      "Batch 304/700: Discriminator loss = 1.2646137475967407, GAN loss = [2.385268, 0.8131581, 0.8550538]\n",
      "Batch 305/700: Discriminator loss = 1.2487798929214478, GAN loss = [2.4368188, 0.826783, 0.8929661]\n",
      "Batch 306/700: Discriminator loss = 1.241946816444397, GAN loss = [2.4476042, 0.826429, 0.90409666]\n",
      "Batch 307/700: Discriminator loss = 1.2753040790557861, GAN loss = [2.4025586, 0.82600784, 0.8594581]\n",
      "Batch 308/700: Discriminator loss = 1.2560012340545654, GAN loss = [2.3802073, 0.8148784, 0.8482328]\n",
      "Batch 309/700: Discriminator loss = 1.2413897514343262, GAN loss = [2.4083033, 0.835006, 0.8562]\n",
      "Batch 310/700: Discriminator loss = 1.2633159160614014, GAN loss = [2.3798351, 0.8181727, 0.84456736]\n",
      "Batch 311/700: Discriminator loss = 1.2512173652648926, GAN loss = [2.3496318, 0.82188207, 0.8106515]\n",
      "Batch 312/700: Discriminator loss = 1.254602074623108, GAN loss = [2.385899, 0.8371768, 0.8316307]\n",
      "Batch 313/700: Discriminator loss = 1.2291818857192993, GAN loss = [2.4145243, 0.83780324, 0.85963285]\n",
      "Batch 314/700: Discriminator loss = 1.1862753629684448, GAN loss = [2.4345188, 0.84537596, 0.87204885]\n",
      "Batch 315/700: Discriminator loss = 1.2493515014648438, GAN loss = [2.3987095, 0.8224932, 0.8591118]\n",
      "Batch 316/700: Discriminator loss = 1.1933636665344238, GAN loss = [2.433717, 0.8610677, 0.85555613]\n",
      "Batch 317/700: Discriminator loss = 1.2060396671295166, GAN loss = [2.4458787, 0.8706337, 0.85815763]\n",
      "Batch 318/700: Discriminator loss = 1.2272735834121704, GAN loss = [2.4363668, 0.8408957, 0.8783871]\n",
      "Batch 319/700: Discriminator loss = 1.2400089502334595, GAN loss = [2.3778162, 0.83134735, 0.829402]\n",
      "Batch 320/700: Discriminator loss = 1.2439792156219482, GAN loss = [2.3841345, 0.82231104, 0.8447764]\n",
      "Batch 321/700: Discriminator loss = 1.224800944328308, GAN loss = [2.4493968, 0.85361636, 0.8787434]\n",
      "Batch 322/700: Discriminator loss = 1.2272905111312866, GAN loss = [2.376404, 0.8437137, 0.8156633]\n",
      "Batch 323/700: Discriminator loss = 1.2317471504211426, GAN loss = [2.3945477, 0.82434964, 0.8531873]\n",
      "Batch 324/700: Discriminator loss = 1.2547416687011719, GAN loss = [2.3545926, 0.8074001, 0.83018523]\n",
      "Batch 325/700: Discriminator loss = 1.227881908416748, GAN loss = [2.419128, 0.85356253, 0.84857666]\n",
      "Batch 326/700: Discriminator loss = 1.228232502937317, GAN loss = [2.4166496, 0.835964, 0.8637071]\n",
      "Batch 327/700: Discriminator loss = 1.246213436126709, GAN loss = [2.3463523, 0.83302605, 0.79635257]\n",
      "Batch 328/700: Discriminator loss = 1.207871437072754, GAN loss = [2.401856, 0.8518815, 0.8329999]\n",
      "Batch 329/700: Discriminator loss = 1.2165262699127197, GAN loss = [2.4510672, 0.83450747, 0.89959615]\n",
      "Batch 330/700: Discriminator loss = 1.224075198173523, GAN loss = [2.4277992, 0.8553801, 0.8554663]\n",
      "Batch 331/700: Discriminator loss = 1.210326910018921, GAN loss = [2.3696463, 0.83642167, 0.8162733]\n",
      "Batch 332/700: Discriminator loss = 1.1979652643203735, GAN loss = [2.4131787, 0.84852636, 0.8477009]\n",
      "Batch 333/700: Discriminator loss = 1.2336170673370361, GAN loss = [2.388189, 0.8066445, 0.8645847]\n",
      "Batch 334/700: Discriminator loss = 1.1732057332992554, GAN loss = [2.404451, 0.8508961, 0.8365956]\n",
      "Batch 335/700: Discriminator loss = 1.2022291421890259, GAN loss = [2.399407, 0.8223066, 0.8601381]\n",
      "Batch 336/700: Discriminator loss = 1.230833649635315, GAN loss = [2.3844886, 0.81065595, 0.8568829]\n",
      "Batch 337/700: Discriminator loss = 1.2236212491989136, GAN loss = [2.4107828, 0.8327613, 0.86108726]\n",
      "Batch 338/700: Discriminator loss = 1.2160059213638306, GAN loss = [2.3747153, 0.83873314, 0.81907374]\n",
      "Batch 339/700: Discriminator loss = 1.1976615190505981, GAN loss = [2.4481041, 0.84631324, 0.8848983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 340/700: Discriminator loss = 1.234865665435791, GAN loss = [2.3219953, 0.8124749, 0.79264116]\n",
      "Batch 341/700: Discriminator loss = 1.2427986860275269, GAN loss = [2.4065053, 0.80170274, 0.8879343]\n",
      "Batch 342/700: Discriminator loss = 1.2163459062576294, GAN loss = [2.388485, 0.82861674, 0.84301084]\n",
      "Batch 343/700: Discriminator loss = 1.1934343576431274, GAN loss = [2.4491751, 0.84715545, 0.8851885]\n",
      "Batch 344/700: Discriminator loss = 1.2345930337905884, GAN loss = [2.348294, 0.81745994, 0.8140284]\n",
      "Batch 345/700: Discriminator loss = 1.2548316717147827, GAN loss = [2.3606339, 0.79244906, 0.8513963]\n",
      "Batch 346/700: Discriminator loss = 1.218277931213379, GAN loss = [2.3921382, 0.8462429, 0.8291266]\n",
      "Batch 347/700: Discriminator loss = 1.206632137298584, GAN loss = [2.4077122, 0.851654, 0.8393109]\n",
      "Batch 348/700: Discriminator loss = 1.1871545314788818, GAN loss = [2.3901563, 0.8631646, 0.81027085]\n",
      "Batch 349/700: Discriminator loss = 1.2141387462615967, GAN loss = [2.4497542, 0.8535151, 0.87954384]\n",
      "Batch 350/700: Discriminator loss = 1.2234877347946167, GAN loss = [2.3713677, 0.8237272, 0.8309669]\n",
      "Batch 351/700: Discriminator loss = 1.2049436569213867, GAN loss = [2.4036047, 0.85571635, 0.83123296]\n",
      "Batch 352/700: Discriminator loss = 1.2303045988082886, GAN loss = [2.4174414, 0.837607, 0.86319834]\n",
      "Batch 353/700: Discriminator loss = 1.262915015220642, GAN loss = [2.405686, 0.8124915, 0.87656707]\n",
      "Batch 354/700: Discriminator loss = 1.2177720069885254, GAN loss = [2.4243217, 0.8302816, 0.8774176]\n",
      "Batch 355/700: Discriminator loss = 1.2148107290267944, GAN loss = [2.3863904, 0.85527617, 0.81450456]\n",
      "Batch 356/700: Discriminator loss = 1.2098336219787598, GAN loss = [2.4105492, 0.8497993, 0.8441576]\n",
      "Batch 357/700: Discriminator loss = 1.2641527652740479, GAN loss = [2.3235297, 0.8268049, 0.78015685]\n",
      "Batch 358/700: Discriminator loss = 1.2007544040679932, GAN loss = [2.414268, 0.8510108, 0.84671533]\n",
      "Batch 359/700: Discriminator loss = 1.2269163131713867, GAN loss = [2.3345418, 0.81186754, 0.8061466]\n",
      "Batch 360/700: Discriminator loss = 1.228663682937622, GAN loss = [2.3475409, 0.8152801, 0.81574005]\n",
      "Batch 361/700: Discriminator loss = 1.2320787906646729, GAN loss = [2.3596334, 0.82696915, 0.81614846]\n",
      "Batch 362/700: Discriminator loss = 1.2315983772277832, GAN loss = [2.3857052, 0.8555638, 0.81364197]\n",
      "Batch 363/700: Discriminator loss = 1.2543970346450806, GAN loss = [2.381307, 0.8225577, 0.84225917]\n",
      "Batch 364/700: Discriminator loss = 1.2128491401672363, GAN loss = [2.4044204, 0.8427788, 0.84516335]\n",
      "Batch 365/700: Discriminator loss = 1.2126489877700806, GAN loss = [2.4189453, 0.84410703, 0.8583611]\n",
      "Batch 366/700: Discriminator loss = 1.1717829704284668, GAN loss = [2.4959347, 0.888355, 0.89109975]\n",
      "Batch 367/700: Discriminator loss = 1.211814284324646, GAN loss = [2.4234514, 0.8498747, 0.8570903]\n",
      "Batch 368/700: Discriminator loss = 1.2155818939208984, GAN loss = [2.4305644, 0.85801476, 0.85605603]\n",
      "Batch 369/700: Discriminator loss = 1.2354496717453003, GAN loss = [2.3385246, 0.8161234, 0.80591446]\n",
      "Batch 370/700: Discriminator loss = 1.1925827264785767, GAN loss = [2.4673278, 0.8683734, 0.8824758]\n",
      "Batch 371/700: Discriminator loss = 1.219312071800232, GAN loss = [2.327499, 0.81998956, 0.7910363]\n",
      "Batch 372/700: Discriminator loss = 1.219516396522522, GAN loss = [2.399874, 0.81581926, 0.8675758]\n",
      "Batch 373/700: Discriminator loss = 1.2205227613449097, GAN loss = [2.4452348, 0.8308552, 0.8979086]\n",
      "Batch 374/700: Discriminator loss = 1.1841973066329956, GAN loss = [2.4532363, 0.85033387, 0.88642687]\n",
      "Batch 375/700: Discriminator loss = 1.211076259613037, GAN loss = [2.4842217, 0.84173834, 0.926009]\n",
      "Batch 376/700: Discriminator loss = 1.2095509767532349, GAN loss = [2.4724329, 0.8221615, 0.93379134]\n",
      "Batch 377/700: Discriminator loss = 1.1815506219863892, GAN loss = [2.479306, 0.8625156, 0.9003155]\n",
      "Batch 378/700: Discriminator loss = 1.2104851007461548, GAN loss = [2.4626985, 0.8623545, 0.8838739]\n",
      "Batch 379/700: Discriminator loss = 1.1695865392684937, GAN loss = [2.4801493, 0.8742776, 0.8894029]\n",
      "Batch 380/700: Discriminator loss = 1.2135282754898071, GAN loss = [2.4473748, 0.8390628, 0.8918558]\n",
      "Batch 381/700: Discriminator loss = 1.2190698385238647, GAN loss = [2.3549519, 0.80603874, 0.83244413]\n",
      "Batch 382/700: Discriminator loss = 1.217430591583252, GAN loss = [2.4540765, 0.8294078, 0.9081949]\n",
      "Batch 383/700: Discriminator loss = 1.1916749477386475, GAN loss = [2.4733586, 0.84070426, 0.9161684]\n",
      "Batch 384/700: Discriminator loss = 1.1846541166305542, GAN loss = [2.4913745, 0.8501389, 0.9247511]\n",
      "Batch 385/700: Discriminator loss = 1.1903631687164307, GAN loss = [2.4476311, 0.83400154, 0.8971537]\n",
      "Batch 386/700: Discriminator loss = 1.1787145137786865, GAN loss = [2.4742675, 0.8502192, 0.9075852]\n",
      "Batch 387/700: Discriminator loss = 1.1759434938430786, GAN loss = [2.4410741, 0.8527755, 0.8718345]\n",
      "Batch 388/700: Discriminator loss = 1.1483432054519653, GAN loss = [2.5054402, 0.8518652, 0.93710893]\n",
      "Batch 389/700: Discriminator loss = 1.2175408601760864, GAN loss = [2.4225054, 0.8186291, 0.8874253]\n",
      "Batch 390/700: Discriminator loss = 1.2107141017913818, GAN loss = [2.4075022, 0.8364702, 0.85459656]\n",
      "Batch 391/700: Discriminator loss = 1.196573257446289, GAN loss = [2.4710572, 0.8139311, 0.9407008]\n",
      "Batch 392/700: Discriminator loss = 1.18670654296875, GAN loss = [2.4562547, 0.851725, 0.88811976]\n",
      "Batch 393/700: Discriminator loss = 1.176781415939331, GAN loss = [2.5483932, 0.86642104, 0.9655616]\n",
      "Batch 394/700: Discriminator loss = 1.1972885131835938, GAN loss = [2.4999256, 0.86589724, 0.9176167]\n",
      "Batch 395/700: Discriminator loss = 1.1947544813156128, GAN loss = [2.519514, 0.842668, 0.9604291]\n",
      "Batch 396/700: Discriminator loss = 1.1795564889907837, GAN loss = [2.508601, 0.84591055, 0.9462622]\n",
      "Batch 397/700: Discriminator loss = 1.1959394216537476, GAN loss = [2.5168626, 0.85269064, 0.94772613]\n",
      "Batch 398/700: Discriminator loss = 1.1677874326705933, GAN loss = [2.5694692, 0.8902916, 0.96271026]\n",
      "Batch 399/700: Discriminator loss = 1.2076910734176636, GAN loss = [2.5678165, 0.89084125, 0.9604966]\n",
      "Batch 400/700: Discriminator loss = 1.1375491619110107, GAN loss = [2.549382, 0.9007914, 0.9321222]\n",
      "Batch 401/700: Discriminator loss = 1.1978477239608765, GAN loss = [2.4386258, 0.8474041, 0.8747652]\n",
      "Batch 402/700: Discriminator loss = 1.2049028873443604, GAN loss = [2.4721057, 0.83659524, 0.9190592]\n",
      "Batch 403/700: Discriminator loss = 1.1994577646255493, GAN loss = [2.5229099, 0.8861989, 0.9202587]\n",
      "Batch 404/700: Discriminator loss = 1.1960691213607788, GAN loss = [2.4781384, 0.8526097, 0.9090735]\n",
      "Batch 405/700: Discriminator loss = 1.1979252099990845, GAN loss = [2.4975688, 0.87377465, 0.9073402]\n",
      "Batch 406/700: Discriminator loss = 1.2092068195343018, GAN loss = [2.4523392, 0.84806997, 0.8878011]\n",
      "Batch 407/700: Discriminator loss = 1.1805254220962524, GAN loss = [2.4800897, 0.8718035, 0.8918076]\n",
      "Batch 408/700: Discriminator loss = 1.1846858263015747, GAN loss = [2.4457374, 0.8516015, 0.8776458]\n",
      "Batch 409/700: Discriminator loss = 1.232999563217163, GAN loss = [2.4385388, 0.8302446, 0.8917947]\n",
      "Batch 410/700: Discriminator loss = 1.203842043876648, GAN loss = [2.4757042, 0.83656144, 0.9226414]\n",
      "Batch 411/700: Discriminator loss = 1.19444739818573, GAN loss = [2.5069382, 0.83645964, 0.9539738]\n",
      "Batch 412/700: Discriminator loss = 1.1938190460205078, GAN loss = [2.4450152, 0.84853154, 0.87997085]\n",
      "Batch 413/700: Discriminator loss = 1.1931782960891724, GAN loss = [2.50309, 0.8650312, 0.9215432]\n",
      "Batch 414/700: Discriminator loss = 1.195312261581421, GAN loss = [2.427878, 0.86916083, 0.84220284]\n",
      "Batch 415/700: Discriminator loss = 1.1972157955169678, GAN loss = [2.4869576, 0.8711379, 0.89930993]\n",
      "Batch 416/700: Discriminator loss = 1.2129435539245605, GAN loss = [2.4281092, 0.83289206, 0.87872094]\n",
      "Batch 417/700: Discriminator loss = 1.1913090944290161, GAN loss = [2.4845283, 0.849831, 0.9182194]\n",
      "Batch 418/700: Discriminator loss = 1.2013225555419922, GAN loss = [2.4635067, 0.85381854, 0.8932163]\n",
      "Batch 419/700: Discriminator loss = 1.2346166372299194, GAN loss = [2.4088638, 0.8472123, 0.8451854]\n",
      "Batch 420/700: Discriminator loss = 1.2186483144760132, GAN loss = [2.4608338, 0.8156352, 0.928746]\n",
      "Batch 421/700: Discriminator loss = 1.2370299100875854, GAN loss = [2.3809905, 0.81582177, 0.8487304]\n",
      "Batch 422/700: Discriminator loss = 1.2214250564575195, GAN loss = [2.4314854, 0.8474415, 0.86761504]\n",
      "Batch 423/700: Discriminator loss = 1.1845942735671997, GAN loss = [2.4573624, 0.84854627, 0.8923882]\n",
      "Batch 424/700: Discriminator loss = 1.2678622007369995, GAN loss = [2.4202292, 0.82996047, 0.8738449]\n",
      "Batch 425/700: Discriminator loss = 1.1898049116134644, GAN loss = [2.4747355, 0.86050254, 0.8978247]\n",
      "Batch 426/700: Discriminator loss = 1.1717709302902222, GAN loss = [2.493191, 0.87600815, 0.9007753]\n",
      "Batch 427/700: Discriminator loss = 1.2557587623596191, GAN loss = [2.44345, 0.80995077, 0.91709363]\n",
      "Batch 428/700: Discriminator loss = 1.2172952890396118, GAN loss = [2.4362063, 0.8520004, 0.8677916]\n",
      "Batch 429/700: Discriminator loss = 1.2143384218215942, GAN loss = [2.3706102, 0.82730156, 0.82688653]\n",
      "Batch 430/700: Discriminator loss = 1.2432576417922974, GAN loss = [2.347645, 0.81890106, 0.81230867]\n",
      "Batch 431/700: Discriminator loss = 1.2448432445526123, GAN loss = [2.3884852, 0.8323616, 0.8396751]\n",
      "Batch 432/700: Discriminator loss = 1.2393759489059448, GAN loss = [2.427099, 0.83094335, 0.87968946]\n",
      "Batch 433/700: Discriminator loss = 1.28499174118042, GAN loss = [2.415746, 0.79441255, 0.9048531]\n",
      "Batch 434/700: Discriminator loss = 1.2400156259536743, GAN loss = [2.4521248, 0.8257256, 0.909911]\n",
      "Batch 435/700: Discriminator loss = 1.229781985282898, GAN loss = [2.3895206, 0.8335455, 0.8394982]\n",
      "Batch 436/700: Discriminator loss = 1.233481526374817, GAN loss = [2.423951, 0.81736726, 0.89012307]\n",
      "Batch 437/700: Discriminator loss = 1.26622474193573, GAN loss = [2.3740916, 0.83274305, 0.82488704]\n",
      "Batch 438/700: Discriminator loss = 1.2498830556869507, GAN loss = [2.3463893, 0.7997371, 0.83020097]\n",
      "Batch 439/700: Discriminator loss = 1.2534819841384888, GAN loss = [2.3628676, 0.82018805, 0.8262332]\n",
      "Batch 440/700: Discriminator loss = 1.258913516998291, GAN loss = [2.3114622, 0.7932732, 0.8017524]\n",
      "Batch 441/700: Discriminator loss = 1.2451279163360596, GAN loss = [2.3236258, 0.8218964, 0.78529435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 442/700: Discriminator loss = 1.2545123100280762, GAN loss = [2.3497467, 0.80371356, 0.829597]\n",
      "Batch 443/700: Discriminator loss = 1.2345227003097534, GAN loss = [2.3694525, 0.8130968, 0.83992875]\n",
      "Batch 444/700: Discriminator loss = 1.2660895586013794, GAN loss = [2.382915, 0.8038855, 0.86260307]\n",
      "Batch 445/700: Discriminator loss = 1.2532907724380493, GAN loss = [2.3128192, 0.80267555, 0.7937063]\n",
      "Batch 446/700: Discriminator loss = 1.2328518629074097, GAN loss = [2.4191744, 0.81723267, 0.88551253]\n",
      "Batch 447/700: Discriminator loss = 1.2349637746810913, GAN loss = [2.3740458, 0.81867754, 0.83894897]\n",
      "Batch 448/700: Discriminator loss = 1.2182916402816772, GAN loss = [2.3923123, 0.8324781, 0.84343725]\n",
      "Batch 449/700: Discriminator loss = 1.2506009340286255, GAN loss = [2.410254, 0.8092228, 0.8846553]\n",
      "Batch 450/700: Discriminator loss = 1.2547156810760498, GAN loss = [2.402478, 0.82359695, 0.86252946]\n",
      "Batch 451/700: Discriminator loss = 1.2451661825180054, GAN loss = [2.375685, 0.80698097, 0.85237604]\n",
      "Batch 452/700: Discriminator loss = 1.2508080005645752, GAN loss = [2.4084494, 0.8415968, 0.850544]\n",
      "Batch 453/700: Discriminator loss = 1.2717618942260742, GAN loss = [2.3527699, 0.80197394, 0.83451825]\n",
      "Batch 454/700: Discriminator loss = 1.2049933671951294, GAN loss = [2.4444623, 0.8203204, 0.907883]\n",
      "Batch 455/700: Discriminator loss = 1.246444821357727, GAN loss = [2.4529078, 0.8123922, 0.92427045]\n",
      "Batch 456/700: Discriminator loss = 1.240723967552185, GAN loss = [2.3798494, 0.8375147, 0.82609046]\n",
      "Batch 457/700: Discriminator loss = 1.2110190391540527, GAN loss = [2.3799028, 0.8383655, 0.82528466]\n",
      "Batch 458/700: Discriminator loss = 1.2311877012252808, GAN loss = [2.3682246, 0.82204974, 0.82992667]\n",
      "Batch 459/700: Discriminator loss = 1.2363284826278687, GAN loss = [2.3590512, 0.8339959, 0.8088124]\n",
      "Batch 460/700: Discriminator loss = 1.2170870304107666, GAN loss = [2.4265049, 0.8479737, 0.86230123]\n",
      "Batch 461/700: Discriminator loss = 1.2400604486465454, GAN loss = [2.4092667, 0.8271081, 0.8659433]\n",
      "Batch 462/700: Discriminator loss = 1.2232227325439453, GAN loss = [2.4214816, 0.835029, 0.8702567]\n",
      "Batch 463/700: Discriminator loss = 1.246042251586914, GAN loss = [2.363167, 0.80556494, 0.84141976]\n",
      "Batch 464/700: Discriminator loss = 1.1946721076965332, GAN loss = [2.3771427, 0.8305899, 0.8303788]\n",
      "Batch 465/700: Discriminator loss = 1.288763403892517, GAN loss = [2.2927608, 0.77720505, 0.7993951]\n",
      "Batch 466/700: Discriminator loss = 1.2466312646865845, GAN loss = [2.4183495, 0.8222371, 0.87996966]\n",
      "Batch 467/700: Discriminator loss = 1.2344603538513184, GAN loss = [2.3859258, 0.8270443, 0.84274745]\n",
      "Batch 468/700: Discriminator loss = 1.2739907503128052, GAN loss = [2.3576376, 0.81157225, 0.82994086]\n",
      "Batch 469/700: Discriminator loss = 1.2409356832504272, GAN loss = [2.3892767, 0.80999106, 0.8631637]\n",
      "Batch 470/700: Discriminator loss = 1.2309902906417847, GAN loss = [2.345965, 0.8089636, 0.82089335]\n",
      "Batch 471/700: Discriminator loss = 1.2298836708068848, GAN loss = [2.3715367, 0.841281, 0.8141643]\n",
      "Batch 472/700: Discriminator loss = 1.2040026187896729, GAN loss = [2.4204755, 0.84317064, 0.8612357]\n",
      "Batch 473/700: Discriminator loss = 1.2114989757537842, GAN loss = [2.4095538, 0.8522582, 0.84125465]\n",
      "Batch 474/700: Discriminator loss = 1.1824071407318115, GAN loss = [2.4358416, 0.8666992, 0.8531168]\n",
      "Batch 475/700: Discriminator loss = 1.208788275718689, GAN loss = [2.4302948, 0.82032895, 0.89393693]\n",
      "Batch 476/700: Discriminator loss = 1.2205541133880615, GAN loss = [2.3600345, 0.81460625, 0.8294132]\n",
      "Batch 477/700: Discriminator loss = 1.2141542434692383, GAN loss = [2.3660407, 0.82321304, 0.8268321]\n",
      "Batch 478/700: Discriminator loss = 1.2265440225601196, GAN loss = [2.4213884, 0.83470553, 0.8707036]\n",
      "Batch 479/700: Discriminator loss = 1.2443573474884033, GAN loss = [2.3360415, 0.8087618, 0.8113227]\n",
      "Batch 480/700: Discriminator loss = 1.2093387842178345, GAN loss = [2.3731625, 0.8421855, 0.8150338]\n",
      "Batch 481/700: Discriminator loss = 1.236446499824524, GAN loss = [2.3553557, 0.8108526, 0.82857865]\n",
      "Batch 482/700: Discriminator loss = 1.2136424779891968, GAN loss = [2.4214957, 0.8674979, 0.83808875]\n",
      "Batch 483/700: Discriminator loss = 1.2264745235443115, GAN loss = [2.4018223, 0.816008, 0.869923]\n",
      "Batch 484/700: Discriminator loss = 1.2372443675994873, GAN loss = [2.3860223, 0.80230486, 0.86785096]\n",
      "Batch 485/700: Discriminator loss = 1.208326816558838, GAN loss = [2.4033835, 0.8441592, 0.84337807]\n",
      "Batch 486/700: Discriminator loss = 1.2239457368850708, GAN loss = [2.4257596, 0.82892555, 0.8810109]\n",
      "Batch 487/700: Discriminator loss = 1.2214860916137695, GAN loss = [2.3813043, 0.81911737, 0.84638107]\n",
      "Batch 488/700: Discriminator loss = 1.264564871788025, GAN loss = [2.4167488, 0.81465346, 0.8863019]\n",
      "Batch 489/700: Discriminator loss = 1.2324321269989014, GAN loss = [2.4311182, 0.8190204, 0.8963249]\n",
      "Batch 490/700: Discriminator loss = 1.2010936737060547, GAN loss = [2.4162006, 0.8307572, 0.86968315]\n",
      "Batch 491/700: Discriminator loss = 1.2204416990280151, GAN loss = [2.4818416, 0.8582935, 0.907819]\n",
      "Batch 492/700: Discriminator loss = 1.2155684232711792, GAN loss = [2.3415601, 0.8212421, 0.804614]\n",
      "Batch 493/700: Discriminator loss = 1.206615686416626, GAN loss = [2.495116, 0.8293114, 0.95012647]\n",
      "Batch 494/700: Discriminator loss = 1.25162672996521, GAN loss = [2.409577, 0.8213379, 0.8725772]\n",
      "Batch 495/700: Discriminator loss = 1.2404134273529053, GAN loss = [2.441625, 0.814704, 0.91128707]\n",
      "Batch 496/700: Discriminator loss = 1.218843936920166, GAN loss = [2.3606474, 0.8240067, 0.8210292]\n",
      "Batch 497/700: Discriminator loss = 1.2200137376785278, GAN loss = [2.4833412, 0.85610056, 0.91165185]\n",
      "Batch 498/700: Discriminator loss = 1.2732996940612793, GAN loss = [2.3612883, 0.8196502, 0.8260653]\n",
      "Batch 499/700: Discriminator loss = 1.1986814737319946, GAN loss = [2.4005663, 0.8476478, 0.83736664]\n",
      "Batch 500/700: Discriminator loss = 1.1792551279067993, GAN loss = [2.3663602, 0.8460292, 0.8048163]\n",
      "Batch 501/700: Discriminator loss = 1.2148030996322632, GAN loss = [2.3454654, 0.8288791, 0.8011063]\n",
      "Batch 502/700: Discriminator loss = 1.2481293678283691, GAN loss = [2.3726487, 0.80091524, 0.8562865]\n",
      "Batch 503/700: Discriminator loss = 1.2105430364608765, GAN loss = [2.3701494, 0.83130836, 0.8234298]\n",
      "Batch 504/700: Discriminator loss = 1.180503010749817, GAN loss = [2.437554, 0.86357933, 0.8585936]\n",
      "Batch 505/700: Discriminator loss = 1.2260148525238037, GAN loss = [2.3809638, 0.8124875, 0.85312617]\n",
      "Batch 506/700: Discriminator loss = 1.20619535446167, GAN loss = [2.414114, 0.82351226, 0.8752863]\n",
      "Batch 507/700: Discriminator loss = 1.2131397724151611, GAN loss = [2.3941474, 0.82541597, 0.8534519]\n",
      "Batch 508/700: Discriminator loss = 1.1929187774658203, GAN loss = [2.4300022, 0.8413967, 0.8733409]\n",
      "Batch 509/700: Discriminator loss = 1.201390027999878, GAN loss = [2.3687818, 0.8387925, 0.8147307]\n",
      "Batch 510/700: Discriminator loss = 1.226381540298462, GAN loss = [2.3763962, 0.83325434, 0.8278991]\n",
      "Batch 511/700: Discriminator loss = 1.1800696849822998, GAN loss = [2.412193, 0.8559359, 0.84103084]\n",
      "Batch 512/700: Discriminator loss = 1.2127888202667236, GAN loss = [2.4032843, 0.8492922, 0.8387817]\n",
      "Batch 513/700: Discriminator loss = 1.2080291509628296, GAN loss = [2.4342878, 0.87339455, 0.8457078]\n",
      "Batch 514/700: Discriminator loss = 1.202289342880249, GAN loss = [2.3643298, 0.8417102, 0.80745065]\n",
      "Batch 515/700: Discriminator loss = 1.2072107791900635, GAN loss = [2.3892787, 0.8677812, 0.8063483]\n",
      "Batch 516/700: Discriminator loss = 1.221583366394043, GAN loss = [2.361212, 0.82615817, 0.81992173]\n",
      "Batch 517/700: Discriminator loss = 1.1836204528808594, GAN loss = [2.4167697, 0.8658137, 0.8358411]\n",
      "Batch 518/700: Discriminator loss = 1.2202337980270386, GAN loss = [2.384816, 0.8253283, 0.8443888]\n",
      "Batch 519/700: Discriminator loss = 1.2138968706130981, GAN loss = [2.4232314, 0.8239964, 0.88414747]\n",
      "Batch 520/700: Discriminator loss = 1.2108317613601685, GAN loss = [2.36148, 0.8153796, 0.8310204]\n",
      "Batch 521/700: Discriminator loss = 1.2201547622680664, GAN loss = [2.4362562, 0.81835556, 0.9028363]\n",
      "Batch 522/700: Discriminator loss = 1.2535635232925415, GAN loss = [2.302647, 0.7778876, 0.80971354]\n",
      "Batch 523/700: Discriminator loss = 1.226582407951355, GAN loss = [2.430294, 0.8300613, 0.88520813]\n",
      "Batch 524/700: Discriminator loss = 1.1856316328048706, GAN loss = [2.4724448, 0.8410467, 0.9164022]\n",
      "Batch 525/700: Discriminator loss = 1.2379812002182007, GAN loss = [2.3563733, 0.7940862, 0.8473122]\n",
      "Batch 526/700: Discriminator loss = 1.21514892578125, GAN loss = [2.3993313, 0.82968706, 0.8546759]\n",
      "Batch 527/700: Discriminator loss = 1.2439932823181152, GAN loss = [2.3501623, 0.80007005, 0.83513945]\n",
      "Batch 528/700: Discriminator loss = 1.2516975402832031, GAN loss = [2.372054, 0.79705805, 0.8600504]\n",
      "Batch 529/700: Discriminator loss = 1.2378894090652466, GAN loss = [2.359829, 0.8120092, 0.83288795]\n",
      "Batch 530/700: Discriminator loss = 1.2129257917404175, GAN loss = [2.4328306, 0.81018347, 0.9077307]\n",
      "Batch 531/700: Discriminator loss = 1.2203502655029297, GAN loss = [2.3432572, 0.8091873, 0.81916916]\n",
      "Batch 532/700: Discriminator loss = 1.2186367511749268, GAN loss = [2.3930306, 0.82032096, 0.8578257]\n",
      "Batch 533/700: Discriminator loss = 1.183448076248169, GAN loss = [2.4267151, 0.8469552, 0.8648808]\n",
      "Batch 534/700: Discriminator loss = 1.2326539754867554, GAN loss = [2.3769503, 0.82485473, 0.83723116]\n",
      "Batch 535/700: Discriminator loss = 1.200990915298462, GAN loss = [2.4171839, 0.8404016, 0.8619349]\n",
      "Batch 536/700: Discriminator loss = 1.2213902473449707, GAN loss = [2.4200335, 0.8066193, 0.89858353]\n",
      "Batch 537/700: Discriminator loss = 1.1995601654052734, GAN loss = [2.4608278, 0.85405564, 0.8919585]\n",
      "Batch 538/700: Discriminator loss = 1.2087371349334717, GAN loss = [2.4239914, 0.8089668, 0.90021974]\n",
      "Batch 539/700: Discriminator loss = 1.247179388999939, GAN loss = [2.4129696, 0.7935585, 0.9046113]\n",
      "Batch 540/700: Discriminator loss = 1.195109486579895, GAN loss = [2.4557965, 0.8535025, 0.8874885]\n",
      "Batch 541/700: Discriminator loss = 1.2483835220336914, GAN loss = [2.4238899, 0.79233086, 0.91675735]\n",
      "Batch 542/700: Discriminator loss = 1.2173725366592407, GAN loss = [2.3854256, 0.80358505, 0.8670351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 543/700: Discriminator loss = 1.2616713047027588, GAN loss = [2.3936598, 0.7962045, 0.8826465]\n",
      "Batch 544/700: Discriminator loss = 1.2220877408981323, GAN loss = [2.3941543, 0.8051425, 0.87419647]\n",
      "Batch 545/700: Discriminator loss = 1.218635082244873, GAN loss = [2.4533489, 0.8295342, 0.90900743]\n",
      "Batch 546/700: Discriminator loss = 1.2306121587753296, GAN loss = [2.4077466, 0.8093457, 0.88361084]\n",
      "Batch 547/700: Discriminator loss = 1.2254985570907593, GAN loss = [2.3880527, 0.80511785, 0.8681532]\n",
      "Batch 548/700: Discriminator loss = 1.254431962966919, GAN loss = [2.3749745, 0.7992106, 0.86098117]\n",
      "Batch 549/700: Discriminator loss = 1.2339136600494385, GAN loss = [2.3863437, 0.80203176, 0.869512]\n",
      "Batch 550/700: Discriminator loss = 1.2121431827545166, GAN loss = [2.4359677, 0.8314267, 0.88974524]\n",
      "Batch 551/700: Discriminator loss = 1.2275830507278442, GAN loss = [2.414954, 0.8213191, 0.87884545]\n",
      "Batch 552/700: Discriminator loss = 1.1775692701339722, GAN loss = [2.5306346, 0.8528831, 0.9629643]\n",
      "Batch 553/700: Discriminator loss = 1.190684199333191, GAN loss = [2.4327765, 0.8507366, 0.8672538]\n",
      "Batch 554/700: Discriminator loss = 1.252712607383728, GAN loss = [2.4217937, 0.80870086, 0.8982991]\n",
      "Batch 555/700: Discriminator loss = 1.2198301553726196, GAN loss = [2.4451, 0.843737, 0.88656646]\n",
      "Batch 556/700: Discriminator loss = 1.2464336156845093, GAN loss = [2.417326, 0.8230997, 0.8794258]\n",
      "Batch 557/700: Discriminator loss = 1.1813850402832031, GAN loss = [2.4203532, 0.8530796, 0.8524749]\n",
      "Batch 558/700: Discriminator loss = 1.238479495048523, GAN loss = [2.3978565, 0.792288, 0.8907858]\n",
      "Batch 559/700: Discriminator loss = 1.2415847778320312, GAN loss = [2.3762274, 0.81589395, 0.8455631]\n",
      "Batch 560/700: Discriminator loss = 1.204060673713684, GAN loss = [2.4435909, 0.844527, 0.88430893]\n",
      "Batch 561/700: Discriminator loss = 1.2295423746109009, GAN loss = [2.3792553, 0.81319594, 0.851325]\n",
      "Batch 562/700: Discriminator loss = 1.2428638935089111, GAN loss = [2.3743377, 0.80917877, 0.85044724]\n",
      "Batch 563/700: Discriminator loss = 1.194037675857544, GAN loss = [2.4443424, 0.85301435, 0.8766318]\n",
      "Batch 564/700: Discriminator loss = 1.2536420822143555, GAN loss = [2.3413422, 0.7881145, 0.8385504]\n",
      "Batch 565/700: Discriminator loss = 1.2380096912384033, GAN loss = [2.3856626, 0.8001411, 0.87085813]\n",
      "Batch 566/700: Discriminator loss = 1.20697021484375, GAN loss = [2.35978, 0.8374643, 0.8076618]\n",
      "Batch 567/700: Discriminator loss = 1.2248456478118896, GAN loss = [2.3569655, 0.8412647, 0.80105036]\n",
      "Batch 568/700: Discriminator loss = 1.2514371871948242, GAN loss = [2.380379, 0.8102498, 0.85548836]\n",
      "Batch 569/700: Discriminator loss = 1.1965430974960327, GAN loss = [2.3932934, 0.8584539, 0.8202014]\n",
      "Batch 570/700: Discriminator loss = 1.2216018438339233, GAN loss = [2.4307604, 0.8342555, 0.8818841]\n",
      "Batch 571/700: Discriminator loss = 1.2320939302444458, GAN loss = [2.396941, 0.8397747, 0.8425606]\n",
      "Batch 572/700: Discriminator loss = 1.1975507736206055, GAN loss = [2.4804525, 0.847092, 0.9187635]\n",
      "Batch 573/700: Discriminator loss = 1.2391232252120972, GAN loss = [2.3528934, 0.82802635, 0.8102851]\n",
      "Batch 574/700: Discriminator loss = 1.1860789060592651, GAN loss = [2.4489436, 0.8643711, 0.8700014]\n",
      "Batch 575/700: Discriminator loss = 1.1793526411056519, GAN loss = [2.4615588, 0.8766021, 0.87039065]\n",
      "Batch 576/700: Discriminator loss = 1.2164521217346191, GAN loss = [2.3802266, 0.82189673, 0.8437781]\n",
      "Batch 577/700: Discriminator loss = 1.2280504703521729, GAN loss = [2.4095283, 0.8198226, 0.875172]\n",
      "Batch 578/700: Discriminator loss = 1.203446388244629, GAN loss = [2.438763, 0.84467256, 0.8795593]\n",
      "Batch 579/700: Discriminator loss = 1.225043535232544, GAN loss = [2.3832297, 0.81701195, 0.8516972]\n",
      "Batch 580/700: Discriminator loss = 1.2267283201217651, GAN loss = [2.375579, 0.8277297, 0.8333474]\n",
      "Batch 581/700: Discriminator loss = 1.2599573135375977, GAN loss = [2.375702, 0.8119986, 0.84922713]\n",
      "Batch 582/700: Discriminator loss = 1.1933714151382446, GAN loss = [2.3974533, 0.8425171, 0.8404888]\n",
      "Batch 583/700: Discriminator loss = 1.222012996673584, GAN loss = [2.398524, 0.82737184, 0.8567344]\n",
      "Batch 584/700: Discriminator loss = 1.1874257326126099, GAN loss = [2.4545336, 0.8889753, 0.85117686]\n",
      "Batch 585/700: Discriminator loss = 1.2126622200012207, GAN loss = [2.4077575, 0.84018576, 0.85321736]\n",
      "Batch 586/700: Discriminator loss = 1.1981836557388306, GAN loss = [2.4731858, 0.88334763, 0.8755146]\n",
      "Batch 587/700: Discriminator loss = 1.2024356126785278, GAN loss = [2.473114, 0.8583059, 0.9005061]\n",
      "Batch 588/700: Discriminator loss = 1.2296342849731445, GAN loss = [2.4462135, 0.8389639, 0.8929741]\n",
      "Batch 589/700: Discriminator loss = 1.2054919004440308, GAN loss = [2.4573386, 0.8618984, 0.88119906]\n",
      "Batch 590/700: Discriminator loss = 1.1907360553741455, GAN loss = [2.4346712, 0.8429764, 0.8774831]\n",
      "Batch 591/700: Discriminator loss = 1.1962661743164062, GAN loss = [2.364697, 0.8336539, 0.8168571]\n",
      "Batch 592/700: Discriminator loss = 1.2465097904205322, GAN loss = [2.3840594, 0.8163591, 0.8535293]\n",
      "Batch 593/700: Discriminator loss = 1.2011638879776, GAN loss = [2.3956742, 0.8415819, 0.83993345]\n",
      "Batch 594/700: Discriminator loss = 1.2152069807052612, GAN loss = [2.3721104, 0.8178932, 0.8400525]\n",
      "Batch 595/700: Discriminator loss = 1.2350951433181763, GAN loss = [2.3918664, 0.8131316, 0.8645704]\n",
      "Batch 596/700: Discriminator loss = 1.2478947639465332, GAN loss = [2.3508456, 0.8115308, 0.8251621]\n",
      "Batch 597/700: Discriminator loss = 1.2220723628997803, GAN loss = [2.4048362, 0.79786706, 0.892824]\n",
      "Batch 598/700: Discriminator loss = 1.2448065280914307, GAN loss = [2.2942755, 0.77695, 0.80318475]\n",
      "Batch 599/700: Discriminator loss = 1.185105800628662, GAN loss = [2.4557996, 0.8534873, 0.8881773]\n",
      "Batch 600/700: Discriminator loss = 1.244223952293396, GAN loss = [2.3720934, 0.8263511, 0.83161354]\n",
      "Batch 601/700: Discriminator loss = 1.216873288154602, GAN loss = [2.3609624, 0.8202864, 0.8265514]\n",
      "Batch 602/700: Discriminator loss = 1.1775238513946533, GAN loss = [2.4461107, 0.8443857, 0.8876053]\n",
      "Batch 603/700: Discriminator loss = 1.234533429145813, GAN loss = [2.4372995, 0.8081356, 0.9150549]\n",
      "Batch 604/700: Discriminator loss = 1.217694878578186, GAN loss = [2.426814, 0.83540255, 0.87730706]\n",
      "Batch 605/700: Discriminator loss = 1.2058342695236206, GAN loss = [2.407935, 0.82167137, 0.87216896]\n",
      "Batch 606/700: Discriminator loss = 1.2097896337509155, GAN loss = [2.406122, 0.81162375, 0.8804236]\n",
      "Batch 607/700: Discriminator loss = 1.2208672761917114, GAN loss = [2.4893684, 0.80609626, 0.96921104]\n",
      "Batch 608/700: Discriminator loss = 1.1841201782226562, GAN loss = [2.4600072, 0.83092237, 0.9150399]\n",
      "Batch 609/700: Discriminator loss = 1.1975589990615845, GAN loss = [2.425344, 0.81744504, 0.8938617]\n",
      "Batch 610/700: Discriminator loss = 1.2195936441421509, GAN loss = [2.461735, 0.8223585, 0.9253462]\n",
      "Batch 611/700: Discriminator loss = 1.1831644773483276, GAN loss = [2.4927201, 0.86973876, 0.9089664]\n",
      "Batch 612/700: Discriminator loss = 1.185600757598877, GAN loss = [2.470357, 0.8475661, 0.90878314]\n",
      "Batch 613/700: Discriminator loss = 1.2567884922027588, GAN loss = [2.4036548, 0.82089686, 0.86875784]\n",
      "Batch 614/700: Discriminator loss = 1.2143000364303589, GAN loss = [2.4069386, 0.83528763, 0.857677]\n",
      "Batch 615/700: Discriminator loss = 1.1749241352081299, GAN loss = [2.43929, 0.8450811, 0.88026446]\n",
      "Batch 616/700: Discriminator loss = 1.1816699504852295, GAN loss = [2.457728, 0.8559916, 0.8878132]\n",
      "Batch 617/700: Discriminator loss = 1.2145576477050781, GAN loss = [2.3829865, 0.8474565, 0.8216305]\n",
      "Batch 618/700: Discriminator loss = 1.2064839601516724, GAN loss = [2.507963, 0.82111394, 0.9729734]\n",
      "Batch 619/700: Discriminator loss = 1.2086254358291626, GAN loss = [2.4038084, 0.8337061, 0.8562458]\n",
      "Batch 620/700: Discriminator loss = 1.1848076581954956, GAN loss = [2.472423, 0.8584625, 0.9001304]\n",
      "Batch 621/700: Discriminator loss = 1.1974952220916748, GAN loss = [2.4652345, 0.85837936, 0.89304614]\n",
      "Batch 622/700: Discriminator loss = 1.1768323183059692, GAN loss = [2.5190032, 0.8790853, 0.9261327]\n",
      "Batch 623/700: Discriminator loss = 1.1492457389831543, GAN loss = [2.4965973, 0.89120084, 0.89162934]\n",
      "Batch 624/700: Discriminator loss = 1.1628085374832153, GAN loss = [2.4893215, 0.8707595, 0.9048078]\n",
      "Batch 625/700: Discriminator loss = 1.1864176988601685, GAN loss = [2.4419882, 0.84411097, 0.88414323]\n",
      "Batch 626/700: Discriminator loss = 1.1890348196029663, GAN loss = [2.4894671, 0.8533674, 0.92237794]\n",
      "Batch 627/700: Discriminator loss = 1.218156099319458, GAN loss = [2.4962924, 0.8464043, 0.93617445]\n",
      "Batch 628/700: Discriminator loss = 1.1954255104064941, GAN loss = [2.4498672, 0.8407475, 0.8954128]\n",
      "Batch 629/700: Discriminator loss = 1.2230304479599, GAN loss = [2.42636, 0.8393264, 0.8733278]\n",
      "Batch 630/700: Discriminator loss = 1.1862843036651611, GAN loss = [2.4811153, 0.8471287, 0.92028064]\n",
      "Batch 631/700: Discriminator loss = 1.2192100286483765, GAN loss = [2.4378912, 0.8250801, 0.8991169]\n",
      "Batch 632/700: Discriminator loss = 1.2153677940368652, GAN loss = [2.4322755, 0.8290715, 0.8895134]\n",
      "Batch 633/700: Discriminator loss = 1.171408772468567, GAN loss = [2.490357, 0.8719002, 0.9047673]\n",
      "Batch 634/700: Discriminator loss = 1.1750037670135498, GAN loss = [2.4749126, 0.866158, 0.89506376]\n",
      "Batch 635/700: Discriminator loss = 1.2360576391220093, GAN loss = [2.4461298, 0.81526536, 0.91717005]\n",
      "Batch 636/700: Discriminator loss = 1.2096024751663208, GAN loss = [2.4371405, 0.83604276, 0.88741183]\n",
      "Batch 637/700: Discriminator loss = 1.2394627332687378, GAN loss = [2.447678, 0.81106955, 0.92292905]\n",
      "Batch 638/700: Discriminator loss = 1.2076725959777832, GAN loss = [2.4120185, 0.84490967, 0.85343874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 639/700: Discriminator loss = 1.1912894248962402, GAN loss = [2.5142086, 0.8719777, 0.9285842]\n",
      "Batch 640/700: Discriminator loss = 1.1724988222122192, GAN loss = [2.4967475, 0.8856251, 0.89749163]\n",
      "Batch 641/700: Discriminator loss = 1.196622610092163, GAN loss = [2.491471, 0.84935415, 0.92849433]\n",
      "Batch 642/700: Discriminator loss = 1.1896350383758545, GAN loss = [2.4764733, 0.845335, 0.9175252]\n",
      "Batch 643/700: Discriminator loss = 1.1785708665847778, GAN loss = [2.507138, 0.86173666, 0.93178666]\n",
      "Batch 644/700: Discriminator loss = 1.1989831924438477, GAN loss = [2.4666345, 0.84963053, 0.9033944]\n",
      "Batch 645/700: Discriminator loss = 1.183175802230835, GAN loss = [2.4661446, 0.88194746, 0.8706014]\n",
      "Batch 646/700: Discriminator loss = 1.194471001625061, GAN loss = [2.4609425, 0.8417252, 0.905628]\n",
      "Batch 647/700: Discriminator loss = 1.1991932392120361, GAN loss = [2.4449365, 0.8429102, 0.88843817]\n",
      "Batch 648/700: Discriminator loss = 1.2007997035980225, GAN loss = [2.4281738, 0.837271, 0.8773195]\n",
      "Batch 649/700: Discriminator loss = 1.2310773134231567, GAN loss = [2.4565136, 0.8355117, 0.9074201]\n",
      "Batch 650/700: Discriminator loss = 1.2066725492477417, GAN loss = [2.478908, 0.8674813, 0.89784706]\n",
      "Batch 651/700: Discriminator loss = 1.2135065793991089, GAN loss = [2.4215596, 0.84162146, 0.86637014]\n",
      "Batch 652/700: Discriminator loss = 1.2146878242492676, GAN loss = [2.3997085, 0.83670175, 0.8494381]\n",
      "Batch 653/700: Discriminator loss = 1.1878312826156616, GAN loss = [2.4517555, 0.8578479, 0.8803457]\n",
      "Batch 654/700: Discriminator loss = 1.265642762184143, GAN loss = [2.3980975, 0.7993004, 0.885248]\n",
      "Batch 655/700: Discriminator loss = 1.1797512769699097, GAN loss = [2.4792984, 0.8579769, 0.9077922]\n",
      "Batch 656/700: Discriminator loss = 1.1965579986572266, GAN loss = [2.4149196, 0.8340552, 0.8673485]\n",
      "Batch 657/700: Discriminator loss = 1.236527442932129, GAN loss = [2.4015937, 0.8231971, 0.86489654]\n",
      "Batch 658/700: Discriminator loss = 1.243614912033081, GAN loss = [2.3302672, 0.80564207, 0.81113756]\n",
      "Batch 659/700: Discriminator loss = 1.1818991899490356, GAN loss = [2.39284, 0.8323899, 0.8469799]\n",
      "Batch 660/700: Discriminator loss = 1.2576322555541992, GAN loss = [2.3737175, 0.8073551, 0.85290754]\n",
      "Batch 661/700: Discriminator loss = 1.2391681671142578, GAN loss = [2.4102097, 0.79859537, 0.8981788]\n",
      "Batch 662/700: Discriminator loss = 1.2425473928451538, GAN loss = [2.3570387, 0.81248575, 0.831123]\n",
      "Batch 663/700: Discriminator loss = 1.1991575956344604, GAN loss = [2.3896499, 0.8236228, 0.8526086]\n",
      "Batch 664/700: Discriminator loss = 1.214083194732666, GAN loss = [2.3986232, 0.8180228, 0.8672023]\n",
      "Batch 665/700: Discriminator loss = 1.2401865720748901, GAN loss = [2.412443, 0.802502, 0.8965603]\n",
      "Batch 666/700: Discriminator loss = 1.226326823234558, GAN loss = [2.3635483, 0.8089472, 0.8412363]\n",
      "Batch 667/700: Discriminator loss = 1.232567548751831, GAN loss = [2.3658936, 0.8372999, 0.8152388]\n",
      "Batch 668/700: Discriminator loss = 1.212485909461975, GAN loss = [2.400441, 0.8488807, 0.8382211]\n",
      "Batch 669/700: Discriminator loss = 1.2236075401306152, GAN loss = [2.402432, 0.8326538, 0.85645413]\n",
      "Batch 670/700: Discriminator loss = 1.2174705266952515, GAN loss = [2.4231215, 0.83774585, 0.87207276]\n",
      "Batch 671/700: Discriminator loss = 1.2024537324905396, GAN loss = [2.3953648, 0.83263373, 0.8494424]\n",
      "Batch 672/700: Discriminator loss = 1.2572760581970215, GAN loss = [2.3263237, 0.8182011, 0.7948549]\n",
      "Batch 673/700: Discriminator loss = 1.200966715812683, GAN loss = [2.3972208, 0.8459845, 0.8379877]\n",
      "Batch 674/700: Discriminator loss = 1.1650824546813965, GAN loss = [2.482327, 0.8795762, 0.8895236]\n",
      "Batch 675/700: Discriminator loss = 1.1906791925430298, GAN loss = [2.4899147, 0.87775195, 0.89894485]\n",
      "Batch 676/700: Discriminator loss = 1.1745009422302246, GAN loss = [2.5163493, 0.87776536, 0.92537147]\n",
      "Batch 677/700: Discriminator loss = 1.1905566453933716, GAN loss = [2.4668553, 0.87404776, 0.8795986]\n",
      "Batch 678/700: Discriminator loss = 1.2230912446975708, GAN loss = [2.3744411, 0.8268127, 0.8344368]\n",
      "Batch 679/700: Discriminator loss = 1.2174159288406372, GAN loss = [2.3447144, 0.83569604, 0.7958448]\n",
      "Batch 680/700: Discriminator loss = 1.2122422456741333, GAN loss = [2.3963525, 0.8453257, 0.83786863]\n",
      "Batch 681/700: Discriminator loss = 1.2080152034759521, GAN loss = [2.4221017, 0.83958346, 0.8693755]\n",
      "Batch 682/700: Discriminator loss = 1.2083966732025146, GAN loss = [2.448724, 0.85237765, 0.88321966]\n",
      "Batch 683/700: Discriminator loss = 1.2557787895202637, GAN loss = [2.4433625, 0.8203739, 0.9098703]\n",
      "Batch 684/700: Discriminator loss = 1.2217605113983154, GAN loss = [2.444958, 0.84440523, 0.8874463]\n",
      "Batch 685/700: Discriminator loss = 1.1432808637619019, GAN loss = [2.4728243, 0.89152396, 0.86820495]\n",
      "Batch 686/700: Discriminator loss = 1.2201091051101685, GAN loss = [2.4185612, 0.86313003, 0.8423495]\n",
      "Batch 687/700: Discriminator loss = 1.1969201564788818, GAN loss = [2.3776226, 0.8458916, 0.8186486]\n",
      "Batch 688/700: Discriminator loss = 1.18061363697052, GAN loss = [2.4047973, 0.85981786, 0.8318923]\n",
      "Batch 689/700: Discriminator loss = 1.2043628692626953, GAN loss = [2.4438446, 0.847654, 0.8831146]\n",
      "Batch 690/700: Discriminator loss = 1.2223540544509888, GAN loss = [2.4008794, 0.81794953, 0.8698693]\n",
      "Batch 691/700: Discriminator loss = 1.1856130361557007, GAN loss = [2.4296975, 0.856326, 0.86032516]\n",
      "Batch 692/700: Discriminator loss = 1.2097479104995728, GAN loss = [2.4113998, 0.8083847, 0.88998985]\n",
      "Batch 693/700: Discriminator loss = 1.2029736042022705, GAN loss = [2.403992, 0.8299903, 0.8609837]\n",
      "Batch 694/700: Discriminator loss = 1.1826496124267578, GAN loss = [2.4657185, 0.84467775, 0.90804255]\n",
      "Batch 695/700: Discriminator loss = 1.2057404518127441, GAN loss = [2.4694657, 0.83588576, 0.92061377]\n",
      "Batch 696/700: Discriminator loss = 1.1821500062942505, GAN loss = [2.5073638, 0.8687212, 0.9257088]\n",
      "Batch 697/700: Discriminator loss = 1.1938689947128296, GAN loss = [2.3762603, 0.82841974, 0.83493996]\n",
      "Batch 698/700: Discriminator loss = 1.162095308303833, GAN loss = [2.542613, 0.9062609, 0.923479]\n",
      "Batch 699/700: Discriminator loss = 1.1619186401367188, GAN loss = [2.5631056, 0.8740258, 0.97623664]\n",
      "Batch 700/700: Discriminator loss = 1.159515142440796, GAN loss = [2.4975684, 0.86593467, 0.91881096]\n",
      "Epoch 16/30\n",
      "Batch 1/700: Discriminator loss = 1.2035515308380127, GAN loss = [2.4613166, 0.86026794, 0.8882329]\n",
      "Batch 2/700: Discriminator loss = 1.197873830795288, GAN loss = [2.4623048, 0.8665794, 0.8829134]\n",
      "Batch 3/700: Discriminator loss = 1.2035855054855347, GAN loss = [2.438425, 0.8765292, 0.84908575]\n",
      "Batch 4/700: Discriminator loss = 1.1983426809310913, GAN loss = [2.4391763, 0.8541815, 0.87219983]\n",
      "Batch 5/700: Discriminator loss = 1.1928359270095825, GAN loss = [2.484208, 0.8727407, 0.89867187]\n",
      "Batch 6/700: Discriminator loss = 1.1701505184173584, GAN loss = [2.4972284, 0.87633044, 0.90810204]\n",
      "Batch 7/700: Discriminator loss = 1.1788266897201538, GAN loss = [2.459546, 0.8616703, 0.8850679]\n",
      "Batch 8/700: Discriminator loss = 1.162635087966919, GAN loss = [2.4941785, 0.8809632, 0.9004124]\n",
      "Batch 9/700: Discriminator loss = 1.1800678968429565, GAN loss = [2.4840581, 0.851901, 0.9193573]\n",
      "Batch 10/700: Discriminator loss = 1.1832871437072754, GAN loss = [2.4920168, 0.86888564, 0.9103385]\n",
      "Batch 11/700: Discriminator loss = 1.2022358179092407, GAN loss = [2.460701, 0.84257543, 0.90533453]\n",
      "Batch 12/700: Discriminator loss = 1.1674340963363647, GAN loss = [2.448891, 0.851799, 0.8843087]\n",
      "Batch 13/700: Discriminator loss = 1.1605873107910156, GAN loss = [2.5119889, 0.87936157, 0.91985667]\n",
      "Batch 14/700: Discriminator loss = 1.1879550218582153, GAN loss = [2.4028292, 0.847848, 0.8422339]\n",
      "Batch 15/700: Discriminator loss = 1.1580232381820679, GAN loss = [2.5515215, 0.86871207, 0.9700827]\n",
      "Batch 16/700: Discriminator loss = 1.1759247779846191, GAN loss = [2.4492927, 0.8453295, 0.8912597]\n",
      "Batch 17/700: Discriminator loss = 1.2188102006912231, GAN loss = [2.4879625, 0.860136, 0.91515267]\n",
      "Batch 18/700: Discriminator loss = 1.1666773557662964, GAN loss = [2.517976, 0.8867147, 0.918621]\n",
      "Batch 19/700: Discriminator loss = 1.1482841968536377, GAN loss = [2.532422, 0.8761378, 0.94366646]\n",
      "Batch 20/700: Discriminator loss = 1.1901123523712158, GAN loss = [2.4527168, 0.8481843, 0.89194304]\n",
      "Batch 21/700: Discriminator loss = 1.1714192628860474, GAN loss = [2.5368862, 0.88253176, 0.9418002]\n",
      "Batch 22/700: Discriminator loss = 1.1573753356933594, GAN loss = [2.4974813, 0.8658235, 0.9191281]\n",
      "Batch 23/700: Discriminator loss = 1.1960132122039795, GAN loss = [2.4484155, 0.8349467, 0.9009552]\n",
      "Batch 24/700: Discriminator loss = 1.1700782775878906, GAN loss = [2.5142012, 0.8679919, 0.9337188]\n",
      "Batch 25/700: Discriminator loss = 1.158790111541748, GAN loss = [2.5802317, 0.87616324, 0.99161315]\n",
      "Batch 26/700: Discriminator loss = 1.1765204668045044, GAN loss = [2.5311246, 0.8590368, 0.9596689]\n",
      "Batch 27/700: Discriminator loss = 1.1849979162216187, GAN loss = [2.532829, 0.84219176, 0.97825426]\n",
      "Batch 28/700: Discriminator loss = 1.1820393800735474, GAN loss = [2.4769747, 0.85354304, 0.9110852]\n",
      "Batch 29/700: Discriminator loss = 1.2541371583938599, GAN loss = [2.3969705, 0.80846757, 0.87619454]\n",
      "Batch 30/700: Discriminator loss = 1.1787766218185425, GAN loss = [2.4938986, 0.87210983, 0.90952194]\n",
      "Batch 31/700: Discriminator loss = 1.1529029607772827, GAN loss = [2.5232286, 0.89168113, 0.91931593]\n",
      "Batch 32/700: Discriminator loss = 1.1984986066818237, GAN loss = [2.529492, 0.859762, 0.95752114]\n",
      "Batch 33/700: Discriminator loss = 1.215025544166565, GAN loss = [2.5369794, 0.8281266, 0.9966658]\n",
      "Batch 34/700: Discriminator loss = 1.2142213582992554, GAN loss = [2.4014733, 0.8265143, 0.8628058]\n",
      "Batch 35/700: Discriminator loss = 1.1863212585449219, GAN loss = [2.4645104, 0.8580251, 0.89436454]\n",
      "Batch 36/700: Discriminator loss = 1.2416608333587646, GAN loss = [2.4296057, 0.8238826, 0.89362663]\n",
      "Batch 37/700: Discriminator loss = 1.2256344556808472, GAN loss = [2.442783, 0.8437774, 0.8869321]\n",
      "Batch 38/700: Discriminator loss = 1.1868034601211548, GAN loss = [2.4678743, 0.8453396, 0.9104937]\n",
      "Batch 39/700: Discriminator loss = 1.220099925994873, GAN loss = [2.4153748, 0.8152272, 0.88812006]\n",
      "Batch 40/700: Discriminator loss = 1.2301558256149292, GAN loss = [2.4533756, 0.85429907, 0.8870609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 41/700: Discriminator loss = 1.1899101734161377, GAN loss = [2.4596493, 0.8764212, 0.87123036]\n",
      "Batch 42/700: Discriminator loss = 1.2188955545425415, GAN loss = [2.466675, 0.84561765, 0.9090796]\n",
      "Batch 43/700: Discriminator loss = 1.2057545185089111, GAN loss = [2.4501834, 0.82316697, 0.9150674]\n",
      "Batch 44/700: Discriminator loss = 1.2093614339828491, GAN loss = [2.4333715, 0.858793, 0.8626572]\n",
      "Batch 45/700: Discriminator loss = 1.2193231582641602, GAN loss = [2.4231071, 0.8358557, 0.8753483]\n",
      "Batch 46/700: Discriminator loss = 1.1981371641159058, GAN loss = [2.4843662, 0.8511208, 0.9213395]\n",
      "Batch 47/700: Discriminator loss = 1.2525405883789062, GAN loss = [2.4383023, 0.8306296, 0.89576614]\n",
      "Batch 48/700: Discriminator loss = 1.2389804124832153, GAN loss = [2.389394, 0.8201018, 0.8573936]\n",
      "Batch 49/700: Discriminator loss = 1.2404711246490479, GAN loss = [2.391489, 0.83542335, 0.8441757]\n",
      "Batch 50/700: Discriminator loss = 1.1952972412109375, GAN loss = [2.4252954, 0.8459755, 0.86743474]\n",
      "Batch 51/700: Discriminator loss = 1.2296462059020996, GAN loss = [2.40746, 0.8315234, 0.8640549]\n",
      "Batch 52/700: Discriminator loss = 1.2463011741638184, GAN loss = [2.3450694, 0.81610316, 0.81708664]\n",
      "Batch 53/700: Discriminator loss = 1.2120760679244995, GAN loss = [2.407301, 0.8482165, 0.8472099]\n",
      "Batch 54/700: Discriminator loss = 1.220237135887146, GAN loss = [2.3376389, 0.82288605, 0.80288047]\n",
      "Batch 55/700: Discriminator loss = 1.2321215867996216, GAN loss = [2.4119625, 0.83195513, 0.8681313]\n",
      "Batch 56/700: Discriminator loss = 1.2267823219299316, GAN loss = [2.4465225, 0.84209305, 0.8925531]\n",
      "Batch 57/700: Discriminator loss = 1.1860060691833496, GAN loss = [2.4319925, 0.86602193, 0.85409814]\n",
      "Batch 58/700: Discriminator loss = 1.1803462505340576, GAN loss = [2.5065975, 0.8847646, 0.90996516]\n",
      "Batch 59/700: Discriminator loss = 1.1772948503494263, GAN loss = [2.4627883, 0.89354134, 0.8573785]\n",
      "Batch 60/700: Discriminator loss = 1.1889342069625854, GAN loss = [2.4519916, 0.86885375, 0.87128156]\n",
      "Batch 61/700: Discriminator loss = 1.1763414144515991, GAN loss = [2.40052, 0.8612128, 0.82746077]\n",
      "Batch 62/700: Discriminator loss = 1.2284761667251587, GAN loss = [2.4632242, 0.85221595, 0.8991784]\n",
      "Batch 63/700: Discriminator loss = 1.1520236730575562, GAN loss = [2.493951, 0.9059209, 0.8762159]\n",
      "Batch 64/700: Discriminator loss = 1.213212251663208, GAN loss = [2.46608, 0.86028504, 0.8939895]\n",
      "Batch 65/700: Discriminator loss = 1.2391351461410522, GAN loss = [2.4853406, 0.8631533, 0.9103879]\n",
      "Batch 66/700: Discriminator loss = 1.2220619916915894, GAN loss = [2.4610612, 0.8674952, 0.8817761]\n",
      "Batch 67/700: Discriminator loss = 1.2002511024475098, GAN loss = [2.486993, 0.89611757, 0.8791056]\n",
      "Batch 68/700: Discriminator loss = 1.2016652822494507, GAN loss = [2.439444, 0.8755575, 0.85212713]\n",
      "Batch 69/700: Discriminator loss = 1.1976206302642822, GAN loss = [2.4794717, 0.8654227, 0.90229124]\n",
      "Batch 70/700: Discriminator loss = 1.2087289094924927, GAN loss = [2.4918125, 0.86964774, 0.9104013]\n",
      "Batch 71/700: Discriminator loss = 1.215745449066162, GAN loss = [2.4174755, 0.86438364, 0.8413464]\n",
      "Batch 72/700: Discriminator loss = 1.1913994550704956, GAN loss = [2.478284, 0.873821, 0.8927283]\n",
      "Batch 73/700: Discriminator loss = 1.2350637912750244, GAN loss = [2.4487154, 0.8360713, 0.9009217]\n",
      "Batch 74/700: Discriminator loss = 1.272027850151062, GAN loss = [2.376855, 0.8098652, 0.8552747]\n",
      "Batch 75/700: Discriminator loss = 1.2274032831192017, GAN loss = [2.4352467, 0.8486051, 0.87493]\n",
      "Batch 76/700: Discriminator loss = 1.2124269008636475, GAN loss = [2.440795, 0.8514026, 0.8776921]\n",
      "Batch 77/700: Discriminator loss = 1.2081419229507446, GAN loss = [2.4074326, 0.8328587, 0.8628581]\n",
      "Batch 78/700: Discriminator loss = 1.210493803024292, GAN loss = [2.5056317, 0.87858313, 0.91533357]\n",
      "Batch 79/700: Discriminator loss = 1.2121732234954834, GAN loss = [2.4040732, 0.8752373, 0.8171333]\n",
      "Batch 80/700: Discriminator loss = 1.1809303760528564, GAN loss = [2.495712, 0.87529445, 0.9087298]\n",
      "Batch 81/700: Discriminator loss = 1.207716703414917, GAN loss = [2.4533021, 0.8652642, 0.8763731]\n",
      "Batch 82/700: Discriminator loss = 1.212131381034851, GAN loss = [2.41129, 0.84521073, 0.85440993]\n",
      "Batch 83/700: Discriminator loss = 1.2020634412765503, GAN loss = [2.5135534, 0.86278105, 0.9391152]\n",
      "Batch 84/700: Discriminator loss = 1.2086701393127441, GAN loss = [2.5118482, 0.89110637, 0.9091111]\n",
      "Batch 85/700: Discriminator loss = 1.223343014717102, GAN loss = [2.499452, 0.83852386, 0.9493166]\n",
      "Batch 86/700: Discriminator loss = 1.209741234779358, GAN loss = [2.475748, 0.85709405, 0.90706694]\n",
      "Batch 87/700: Discriminator loss = 1.1871776580810547, GAN loss = [2.4832928, 0.84846985, 0.92324936]\n",
      "Batch 88/700: Discriminator loss = 1.1883490085601807, GAN loss = [2.4744766, 0.8606, 0.90230775]\n",
      "Batch 89/700: Discriminator loss = 1.1827718019485474, GAN loss = [2.5701947, 0.90087533, 0.95776033]\n",
      "Batch 90/700: Discriminator loss = 1.204219102859497, GAN loss = [2.4709678, 0.84532106, 0.914109]\n",
      "Batch 91/700: Discriminator loss = 1.2101677656173706, GAN loss = [2.4705133, 0.84046316, 0.91855085]\n",
      "Batch 92/700: Discriminator loss = 1.228190302848816, GAN loss = [2.4877858, 0.8398806, 0.9364338]\n",
      "Batch 93/700: Discriminator loss = 1.1982496976852417, GAN loss = [2.5497386, 0.8666112, 0.97167474]\n",
      "Batch 94/700: Discriminator loss = 1.2041293382644653, GAN loss = [2.4383948, 0.84375757, 0.8832087]\n",
      "Batch 95/700: Discriminator loss = 1.1779652833938599, GAN loss = [2.5574183, 0.90010375, 0.9459198]\n",
      "Batch 96/700: Discriminator loss = 1.2036857604980469, GAN loss = [2.4991407, 0.89430237, 0.8934677]\n",
      "Batch 97/700: Discriminator loss = 1.1909868717193604, GAN loss = [2.473941, 0.8773832, 0.8852127]\n",
      "Batch 98/700: Discriminator loss = 1.1883907318115234, GAN loss = [2.4748948, 0.87647223, 0.887097]\n",
      "Batch 99/700: Discriminator loss = 1.1948405504226685, GAN loss = [2.440418, 0.8762292, 0.85287553]\n",
      "Batch 100/700: Discriminator loss = 1.1883245706558228, GAN loss = [2.5043623, 0.88837683, 0.90468657]\n",
      "Batch 101/700: Discriminator loss = 1.1846468448638916, GAN loss = [2.5170734, 0.8969678, 0.9088223]\n",
      "Batch 102/700: Discriminator loss = 1.1911725997924805, GAN loss = [2.5164053, 0.8906002, 0.91454005]\n",
      "Batch 103/700: Discriminator loss = 1.1766701936721802, GAN loss = [2.5660515, 0.892052, 0.96274376]\n",
      "Batch 104/700: Discriminator loss = 1.1877877712249756, GAN loss = [2.4946089, 0.90518486, 0.87818545]\n",
      "Batch 105/700: Discriminator loss = 1.1885631084442139, GAN loss = [2.5125632, 0.89035517, 0.9109957]\n",
      "Batch 106/700: Discriminator loss = 1.167893409729004, GAN loss = [2.5454154, 0.9527252, 0.8815039]\n",
      "Batch 107/700: Discriminator loss = 1.1751424074172974, GAN loss = [2.5229347, 0.92103404, 0.8907225]\n",
      "Batch 108/700: Discriminator loss = 1.1532890796661377, GAN loss = [2.6645525, 0.94298816, 1.0104034]\n",
      "Batch 109/700: Discriminator loss = 1.1889173984527588, GAN loss = [2.5240204, 0.8993479, 0.91353095]\n",
      "Batch 110/700: Discriminator loss = 1.2003200054168701, GAN loss = [2.475567, 0.8617491, 0.9026955]\n",
      "Batch 111/700: Discriminator loss = 1.1967865228652954, GAN loss = [2.6085873, 0.9123296, 0.9851489]\n",
      "Batch 112/700: Discriminator loss = 1.2629085779190063, GAN loss = [2.4871762, 0.85800874, 0.91807675]\n",
      "Batch 113/700: Discriminator loss = 1.2082056999206543, GAN loss = [2.477434, 0.8708213, 0.8955365]\n",
      "Batch 114/700: Discriminator loss = 1.193870186805725, GAN loss = [2.539177, 0.9149754, 0.9131372]\n",
      "Batch 115/700: Discriminator loss = 1.2151024341583252, GAN loss = [2.4649417, 0.87028277, 0.88359255]\n",
      "Batch 116/700: Discriminator loss = 1.1818004846572876, GAN loss = [2.4592168, 0.906249, 0.84190476]\n",
      "Batch 117/700: Discriminator loss = 1.2063734531402588, GAN loss = [2.429396, 0.86700195, 0.85134315]\n",
      "Batch 118/700: Discriminator loss = 1.1801645755767822, GAN loss = [2.5041363, 0.9030032, 0.8900879]\n",
      "Batch 119/700: Discriminator loss = 1.2256659269332886, GAN loss = [2.4026756, 0.84902537, 0.84261894]\n",
      "Batch 120/700: Discriminator loss = 1.2194650173187256, GAN loss = [2.3859127, 0.8471533, 0.8277372]\n",
      "Batch 121/700: Discriminator loss = 1.26215398311615, GAN loss = [2.3311121, 0.82853645, 0.7915818]\n",
      "Batch 122/700: Discriminator loss = 1.202598214149475, GAN loss = [2.4341984, 0.8581831, 0.8650507]\n",
      "Batch 123/700: Discriminator loss = 1.2276291847229004, GAN loss = [2.349482, 0.84877646, 0.78976524]\n",
      "Batch 124/700: Discriminator loss = 1.179504156112671, GAN loss = [2.4404316, 0.87887514, 0.8506421]\n",
      "Batch 125/700: Discriminator loss = 1.2001135349273682, GAN loss = [2.473314, 0.8531676, 0.90926474]\n",
      "Batch 126/700: Discriminator loss = 1.1833428144454956, GAN loss = [2.4141202, 0.8759651, 0.82730603]\n",
      "Batch 127/700: Discriminator loss = 1.1745445728302002, GAN loss = [2.4628947, 0.88704634, 0.86504006]\n",
      "Batch 128/700: Discriminator loss = 1.1618520021438599, GAN loss = [2.506456, 0.88671213, 0.90897864]\n",
      "Batch 129/700: Discriminator loss = 1.1938363313674927, GAN loss = [2.427706, 0.8595376, 0.85744524]\n",
      "Batch 130/700: Discriminator loss = 1.1605286598205566, GAN loss = [2.454078, 0.8638976, 0.8794873]\n",
      "Batch 131/700: Discriminator loss = 1.1958997249603271, GAN loss = [2.4659653, 0.84849447, 0.90680313]\n",
      "Batch 132/700: Discriminator loss = 1.1772857904434204, GAN loss = [2.4820485, 0.8670015, 0.9044073]\n",
      "Batch 133/700: Discriminator loss = 1.187098503112793, GAN loss = [2.4627094, 0.86331004, 0.8887924]\n",
      "Batch 134/700: Discriminator loss = 1.1976003646850586, GAN loss = [2.4252703, 0.85205895, 0.8626331]\n",
      "Batch 135/700: Discriminator loss = 1.1838419437408447, GAN loss = [2.487523, 0.86756384, 0.909399]\n",
      "Batch 136/700: Discriminator loss = 1.1982027292251587, GAN loss = [2.492503, 0.87138414, 0.910574]\n",
      "Batch 137/700: Discriminator loss = 1.183833122253418, GAN loss = [2.4294055, 0.8678839, 0.8509973]\n",
      "Batch 138/700: Discriminator loss = 1.230333685874939, GAN loss = [2.4014366, 0.8194049, 0.87153375]\n",
      "Batch 139/700: Discriminator loss = 1.1863125562667847, GAN loss = [2.4935286, 0.8824691, 0.9005843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 140/700: Discriminator loss = 1.1916816234588623, GAN loss = [2.417846, 0.85795766, 0.84942514]\n",
      "Batch 141/700: Discriminator loss = 1.2046585083007812, GAN loss = [2.4310448, 0.82996774, 0.8906263]\n",
      "Batch 142/700: Discriminator loss = 1.2241300344467163, GAN loss = [2.437344, 0.8257965, 0.90110826]\n",
      "Batch 143/700: Discriminator loss = 1.2133220434188843, GAN loss = [2.3547485, 0.82782465, 0.81648695]\n",
      "Batch 144/700: Discriminator loss = 1.2369812726974487, GAN loss = [2.4042222, 0.812488, 0.8813019]\n",
      "Batch 145/700: Discriminator loss = 1.1886688470840454, GAN loss = [2.4395354, 0.84882057, 0.8802825]\n",
      "Batch 146/700: Discriminator loss = 1.193703532218933, GAN loss = [2.4613912, 0.8434864, 0.90747267]\n",
      "Batch 147/700: Discriminator loss = 1.1840687990188599, GAN loss = [2.431646, 0.8547981, 0.86641634]\n",
      "Batch 148/700: Discriminator loss = 1.196652889251709, GAN loss = [2.4154742, 0.8521666, 0.8528714]\n",
      "Batch 149/700: Discriminator loss = 1.2000300884246826, GAN loss = [2.425024, 0.85903656, 0.85556036]\n",
      "Batch 150/700: Discriminator loss = 1.2133824825286865, GAN loss = [2.4176733, 0.84758437, 0.85967714]\n",
      "Batch 151/700: Discriminator loss = 1.1809272766113281, GAN loss = [2.4790707, 0.85716087, 0.9115034]\n",
      "Batch 152/700: Discriminator loss = 1.1951088905334473, GAN loss = [2.4212108, 0.8750269, 0.8357804]\n",
      "Batch 153/700: Discriminator loss = 1.2088991403579712, GAN loss = [2.4402757, 0.8419669, 0.88790274]\n",
      "Batch 154/700: Discriminator loss = 1.1815749406814575, GAN loss = [2.4390166, 0.8603164, 0.86829877]\n",
      "Batch 155/700: Discriminator loss = 1.2460829019546509, GAN loss = [2.3638167, 0.80238205, 0.85105026]\n",
      "Batch 156/700: Discriminator loss = 1.1879264116287231, GAN loss = [2.499165, 0.84287, 0.94592613]\n",
      "Batch 157/700: Discriminator loss = 1.21781587600708, GAN loss = [2.4317358, 0.82248557, 0.8988893]\n",
      "Batch 158/700: Discriminator loss = 1.2041572332382202, GAN loss = [2.4278686, 0.837292, 0.8802374]\n",
      "Batch 159/700: Discriminator loss = 1.2283895015716553, GAN loss = [2.36175, 0.8141453, 0.8372889]\n",
      "Batch 160/700: Discriminator loss = 1.2475919723510742, GAN loss = [2.409765, 0.81242126, 0.88704956]\n",
      "Batch 161/700: Discriminator loss = 1.2325983047485352, GAN loss = [2.4357615, 0.8134674, 0.9120145]\n",
      "Batch 162/700: Discriminator loss = 1.2233692407608032, GAN loss = [2.4125319, 0.8232414, 0.8790323]\n",
      "Batch 163/700: Discriminator loss = 1.2539783716201782, GAN loss = [2.4045775, 0.8133415, 0.8810082]\n",
      "Batch 164/700: Discriminator loss = 1.2573729753494263, GAN loss = [2.4240828, 0.797284, 0.916609]\n",
      "Batch 165/700: Discriminator loss = 1.230584979057312, GAN loss = [2.3749034, 0.81739783, 0.8473509]\n",
      "Batch 166/700: Discriminator loss = 1.2873034477233887, GAN loss = [2.3262749, 0.804734, 0.81141096]\n",
      "Batch 167/700: Discriminator loss = 1.2504452466964722, GAN loss = [2.3719215, 0.7805182, 0.8812885]\n",
      "Batch 168/700: Discriminator loss = 1.2451756000518799, GAN loss = [2.3990545, 0.84349585, 0.8454525]\n",
      "Batch 169/700: Discriminator loss = 1.254154920578003, GAN loss = [2.3590498, 0.7779345, 0.8710264]\n",
      "Batch 170/700: Discriminator loss = 1.2944250106811523, GAN loss = [2.3280754, 0.7907696, 0.8272287]\n",
      "Batch 171/700: Discriminator loss = 1.2640529870986938, GAN loss = [2.3688002, 0.8057259, 0.8530224]\n",
      "Batch 172/700: Discriminator loss = 1.2828140258789062, GAN loss = [2.2971575, 0.786716, 0.8004186]\n",
      "Batch 173/700: Discriminator loss = 1.241925835609436, GAN loss = [2.2991443, 0.79622513, 0.79292524]\n",
      "Batch 174/700: Discriminator loss = 1.2510874271392822, GAN loss = [2.3077323, 0.7931214, 0.8046339]\n",
      "Batch 175/700: Discriminator loss = 1.2860782146453857, GAN loss = [2.3047261, 0.78319716, 0.81157476]\n",
      "Batch 176/700: Discriminator loss = 1.253443956375122, GAN loss = [2.3621337, 0.8195307, 0.8326783]\n",
      "Batch 177/700: Discriminator loss = 1.2084107398986816, GAN loss = [2.4140465, 0.8299526, 0.8741956]\n",
      "Batch 178/700: Discriminator loss = 1.1717543601989746, GAN loss = [2.389661, 0.8731959, 0.80659074]\n",
      "Batch 179/700: Discriminator loss = 1.231033444404602, GAN loss = [2.3601549, 0.80671036, 0.84360677]\n",
      "Batch 180/700: Discriminator loss = 1.2269891500473022, GAN loss = [2.3113651, 0.821636, 0.7799074]\n",
      "Batch 181/700: Discriminator loss = 1.208767056465149, GAN loss = [2.3431299, 0.8404591, 0.79287034]\n",
      "Batch 182/700: Discriminator loss = 1.2182397842407227, GAN loss = [2.3490593, 0.8278616, 0.81141883]\n",
      "Batch 183/700: Discriminator loss = 1.1898826360702515, GAN loss = [2.3962636, 0.8346482, 0.8518619]\n",
      "Batch 184/700: Discriminator loss = 1.2017264366149902, GAN loss = [2.3991456, 0.82849693, 0.8609286]\n",
      "Batch 185/700: Discriminator loss = 1.223392367362976, GAN loss = [2.3721592, 0.8173056, 0.8451642]\n",
      "Batch 186/700: Discriminator loss = 1.2058789730072021, GAN loss = [2.382566, 0.8300409, 0.84285194]\n",
      "Batch 187/700: Discriminator loss = 1.2028652429580688, GAN loss = [2.4491086, 0.8352526, 0.90419924]\n",
      "Batch 188/700: Discriminator loss = 1.2300134897232056, GAN loss = [2.38251, 0.8157418, 0.85713905]\n",
      "Batch 189/700: Discriminator loss = 1.2096238136291504, GAN loss = [2.4196417, 0.8217972, 0.8882441]\n",
      "Batch 190/700: Discriminator loss = 1.2350728511810303, GAN loss = [2.3781805, 0.80155253, 0.8670665]\n",
      "Batch 191/700: Discriminator loss = 1.2285312414169312, GAN loss = [2.3870316, 0.818599, 0.8589077]\n",
      "Batch 192/700: Discriminator loss = 1.2310594320297241, GAN loss = [2.4305687, 0.81019354, 0.91089666]\n",
      "Batch 193/700: Discriminator loss = 1.217227578163147, GAN loss = [2.42265, 0.82160217, 0.89162636]\n",
      "Batch 194/700: Discriminator loss = 1.2216999530792236, GAN loss = [2.368709, 0.824453, 0.83488303]\n",
      "Batch 195/700: Discriminator loss = 1.2019323110580444, GAN loss = [2.3512025, 0.82837975, 0.8134934]\n",
      "Batch 196/700: Discriminator loss = 1.226035714149475, GAN loss = [2.3836584, 0.7952475, 0.87912834]\n",
      "Batch 197/700: Discriminator loss = 1.2454785108566284, GAN loss = [2.3409452, 0.79514784, 0.8365536]\n",
      "Batch 198/700: Discriminator loss = 1.241637945175171, GAN loss = [2.3588955, 0.7919312, 0.8577606]\n",
      "Batch 199/700: Discriminator loss = 1.2534055709838867, GAN loss = [2.3302042, 0.7892203, 0.83182395]\n",
      "Batch 200/700: Discriminator loss = 1.2253124713897705, GAN loss = [2.342378, 0.8016974, 0.8315565]\n",
      "Batch 201/700: Discriminator loss = 1.2198816537857056, GAN loss = [2.3928366, 0.83154213, 0.8522154]\n",
      "Batch 202/700: Discriminator loss = 1.2253048419952393, GAN loss = [2.4048553, 0.8169188, 0.87890553]\n",
      "Batch 203/700: Discriminator loss = 1.1981004476547241, GAN loss = [2.3637793, 0.8368023, 0.8179872]\n",
      "Batch 204/700: Discriminator loss = 1.229894757270813, GAN loss = [2.354138, 0.8043271, 0.84085196]\n",
      "Batch 205/700: Discriminator loss = 1.2026119232177734, GAN loss = [2.3275094, 0.8325586, 0.7860312]\n",
      "Batch 206/700: Discriminator loss = 1.1941097974777222, GAN loss = [2.3929703, 0.8237372, 0.86035544]\n",
      "Batch 207/700: Discriminator loss = 1.2297066450119019, GAN loss = [2.3476653, 0.8059475, 0.8328903]\n",
      "Batch 208/700: Discriminator loss = 1.2054120302200317, GAN loss = [2.3359785, 0.79990685, 0.8272915]\n",
      "Batch 209/700: Discriminator loss = 1.2258509397506714, GAN loss = [2.3233852, 0.8093219, 0.8053308]\n",
      "Batch 210/700: Discriminator loss = 1.1912201642990112, GAN loss = [2.3690512, 0.8388791, 0.82148176]\n",
      "Batch 211/700: Discriminator loss = 1.2068537473678589, GAN loss = [2.390438, 0.81085795, 0.87093705]\n",
      "Batch 212/700: Discriminator loss = 1.2182950973510742, GAN loss = [2.3818963, 0.8129356, 0.86037475]\n",
      "Batch 213/700: Discriminator loss = 1.1994221210479736, GAN loss = [2.3027325, 0.8168692, 0.77732587]\n",
      "Batch 214/700: Discriminator loss = 1.2002005577087402, GAN loss = [2.3767965, 0.8224582, 0.8458524]\n",
      "Batch 215/700: Discriminator loss = 1.216383695602417, GAN loss = [2.3297753, 0.7959823, 0.82535475]\n",
      "Batch 216/700: Discriminator loss = 1.2154085636138916, GAN loss = [2.3477437, 0.79858744, 0.8407656]\n",
      "Batch 217/700: Discriminator loss = 1.196739673614502, GAN loss = [2.3718715, 0.8087027, 0.8548211]\n",
      "Batch 218/700: Discriminator loss = 1.2120386362075806, GAN loss = [2.3937793, 0.8118505, 0.8736204]\n",
      "Batch 219/700: Discriminator loss = 1.2070497274398804, GAN loss = [2.3613024, 0.8096076, 0.8434195]\n",
      "Batch 220/700: Discriminator loss = 1.2510267496109009, GAN loss = [2.3146086, 0.76535386, 0.84101605]\n",
      "Batch 221/700: Discriminator loss = 1.2603864669799805, GAN loss = [2.2890472, 0.7819171, 0.79891515]\n",
      "Batch 222/700: Discriminator loss = 1.2071290016174316, GAN loss = [2.3128076, 0.80659026, 0.7980115]\n",
      "Batch 223/700: Discriminator loss = 1.2214112281799316, GAN loss = [2.3117945, 0.8171788, 0.78642404]\n",
      "Batch 224/700: Discriminator loss = 1.2094504833221436, GAN loss = [2.372124, 0.8239956, 0.8399649]\n",
      "Batch 225/700: Discriminator loss = 1.2491461038589478, GAN loss = [2.2810073, 0.79728746, 0.77557397]\n",
      "Batch 226/700: Discriminator loss = 1.2332258224487305, GAN loss = [2.3018332, 0.7910499, 0.80265063]\n",
      "Batch 227/700: Discriminator loss = 1.2258601188659668, GAN loss = [2.2944803, 0.7921743, 0.7941782]\n",
      "Batch 228/700: Discriminator loss = 1.2196687459945679, GAN loss = [2.3280425, 0.78956217, 0.8303481]\n",
      "Batch 229/700: Discriminator loss = 1.2091456651687622, GAN loss = [2.3176653, 0.80627227, 0.8032719]\n",
      "Batch 230/700: Discriminator loss = 1.2289155721664429, GAN loss = [2.3483288, 0.8191507, 0.82106864]\n",
      "Batch 231/700: Discriminator loss = 1.2165333032608032, GAN loss = [2.3351216, 0.80232644, 0.8246983]\n",
      "Batch 232/700: Discriminator loss = 1.2254934310913086, GAN loss = [2.3090923, 0.798308, 0.8026899]\n",
      "Batch 233/700: Discriminator loss = 1.1988598108291626, GAN loss = [2.340433, 0.8122765, 0.8200588]\n",
      "Batch 234/700: Discriminator loss = 1.1992485523223877, GAN loss = [2.3403027, 0.8152249, 0.81698805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 235/700: Discriminator loss = 1.1832996606826782, GAN loss = [2.4241168, 0.84280396, 0.8732299]\n",
      "Batch 236/700: Discriminator loss = 1.199507713317871, GAN loss = [2.3437722, 0.8082455, 0.82746243]\n",
      "Batch 237/700: Discriminator loss = 1.1904064416885376, GAN loss = [2.432197, 0.8235503, 0.90060645]\n",
      "Batch 238/700: Discriminator loss = 1.2246626615524292, GAN loss = [2.2970886, 0.78495187, 0.80412316]\n",
      "Batch 239/700: Discriminator loss = 1.2357101440429688, GAN loss = [2.3829062, 0.79113907, 0.8837732]\n",
      "Batch 240/700: Discriminator loss = 1.2727330923080444, GAN loss = [2.3713136, 0.776134, 0.8871987]\n",
      "Batch 241/700: Discriminator loss = 1.1944047212600708, GAN loss = [2.3603973, 0.8138085, 0.83861727]\n",
      "Batch 242/700: Discriminator loss = 1.2363539934158325, GAN loss = [2.3480625, 0.7696316, 0.8704485]\n",
      "Batch 243/700: Discriminator loss = 1.223661184310913, GAN loss = [2.4022303, 0.8134417, 0.8807962]\n",
      "Batch 244/700: Discriminator loss = 1.1959171295166016, GAN loss = [2.3554769, 0.8149692, 0.832525]\n",
      "Batch 245/700: Discriminator loss = 1.2560887336730957, GAN loss = [2.3066947, 0.7722446, 0.8264824]\n",
      "Batch 246/700: Discriminator loss = 1.2178537845611572, GAN loss = [2.3389633, 0.80010927, 0.8308999]\n",
      "Batch 247/700: Discriminator loss = 1.2099785804748535, GAN loss = [2.3073454, 0.7854598, 0.81393677]\n",
      "Batch 248/700: Discriminator loss = 1.2289172410964966, GAN loss = [2.326272, 0.78622645, 0.832119]\n",
      "Batch 249/700: Discriminator loss = 1.2293635606765747, GAN loss = [2.3354177, 0.78933096, 0.8381817]\n",
      "Batch 250/700: Discriminator loss = 1.2225579023361206, GAN loss = [2.3689091, 0.79077536, 0.8702568]\n",
      "Batch 251/700: Discriminator loss = 1.1896300315856934, GAN loss = [2.3769176, 0.810579, 0.85847354]\n",
      "Batch 252/700: Discriminator loss = 1.2126671075820923, GAN loss = [2.352593, 0.79294825, 0.8517824]\n",
      "Batch 253/700: Discriminator loss = 1.2353622913360596, GAN loss = [2.3334768, 0.783716, 0.8419051]\n",
      "Batch 254/700: Discriminator loss = 1.208186149597168, GAN loss = [2.3847136, 0.8065696, 0.8702826]\n",
      "Batch 255/700: Discriminator loss = 1.1863038539886475, GAN loss = [2.388608, 0.8249259, 0.8558149]\n",
      "Batch 256/700: Discriminator loss = 1.2374553680419922, GAN loss = [2.3050253, 0.7841609, 0.8130014]\n",
      "Batch 257/700: Discriminator loss = 1.1933847665786743, GAN loss = [2.396806, 0.8184253, 0.87052816]\n",
      "Batch 258/700: Discriminator loss = 1.2035303115844727, GAN loss = [2.3466763, 0.7948658, 0.8439796]\n",
      "Batch 259/700: Discriminator loss = 1.223462700843811, GAN loss = [2.3282633, 0.7858155, 0.8346293]\n",
      "Batch 260/700: Discriminator loss = 1.235325574874878, GAN loss = [2.3295243, 0.78836745, 0.8333465]\n",
      "Batch 261/700: Discriminator loss = 1.2295598983764648, GAN loss = [2.406977, 0.7863517, 0.9128366]\n",
      "Batch 262/700: Discriminator loss = 1.2160260677337646, GAN loss = [2.300831, 0.79579675, 0.797262]\n",
      "Batch 263/700: Discriminator loss = 1.2238450050354004, GAN loss = [2.3966916, 0.80325335, 0.8856778]\n",
      "Batch 264/700: Discriminator loss = 1.1835966110229492, GAN loss = [2.4084506, 0.82949835, 0.87120736]\n",
      "Batch 265/700: Discriminator loss = 1.1957367658615112, GAN loss = [2.348656, 0.8131417, 0.8277883]\n",
      "Batch 266/700: Discriminator loss = 1.2127909660339355, GAN loss = [2.3309546, 0.8078333, 0.81540954]\n",
      "Batch 267/700: Discriminator loss = 1.2236288785934448, GAN loss = [2.346716, 0.78880167, 0.85021836]\n",
      "Batch 268/700: Discriminator loss = 1.2110565900802612, GAN loss = [2.311026, 0.8011548, 0.80219823]\n",
      "Batch 269/700: Discriminator loss = 1.1841022968292236, GAN loss = [2.4047632, 0.8213386, 0.87576836]\n",
      "Batch 270/700: Discriminator loss = 1.2100929021835327, GAN loss = [2.3679497, 0.8004633, 0.8598455]\n",
      "Batch 271/700: Discriminator loss = 1.2055416107177734, GAN loss = [2.416536, 0.79936045, 0.90956324]\n",
      "Batch 272/700: Discriminator loss = 1.2318840026855469, GAN loss = [2.348639, 0.81466407, 0.82639104]\n",
      "Batch 273/700: Discriminator loss = 1.2162355184555054, GAN loss = [2.4000132, 0.80626154, 0.88620776]\n",
      "Batch 274/700: Discriminator loss = 1.209975004196167, GAN loss = [2.3800032, 0.8113874, 0.8610933]\n",
      "Batch 275/700: Discriminator loss = 1.2083102464675903, GAN loss = [2.3642714, 0.8203891, 0.836383]\n",
      "Batch 276/700: Discriminator loss = 1.1978932619094849, GAN loss = [2.4164615, 0.8022445, 0.9067468]\n",
      "Batch 277/700: Discriminator loss = 1.2070101499557495, GAN loss = [2.3561947, 0.80632484, 0.8424361]\n",
      "Batch 278/700: Discriminator loss = 1.2106690406799316, GAN loss = [2.361179, 0.801563, 0.8522195]\n",
      "Batch 279/700: Discriminator loss = 1.209907054901123, GAN loss = [2.3316193, 0.7941462, 0.83010274]\n",
      "Batch 280/700: Discriminator loss = 1.2095973491668701, GAN loss = [2.3516998, 0.80513537, 0.83922887]\n",
      "Batch 281/700: Discriminator loss = 1.1940873861312866, GAN loss = [2.380878, 0.81353605, 0.86003065]\n",
      "Batch 282/700: Discriminator loss = 1.2031221389770508, GAN loss = [2.3991606, 0.8312132, 0.860659]\n",
      "Batch 283/700: Discriminator loss = 1.2334752082824707, GAN loss = [2.3593109, 0.8125095, 0.83953404]\n",
      "Batch 284/700: Discriminator loss = 1.2177547216415405, GAN loss = [2.3600295, 0.78649217, 0.8662938]\n",
      "Batch 285/700: Discriminator loss = 1.2220467329025269, GAN loss = [2.3921142, 0.7876513, 0.89723235]\n",
      "Batch 286/700: Discriminator loss = 1.233788013458252, GAN loss = [2.3619518, 0.776271, 0.8784768]\n",
      "Batch 287/700: Discriminator loss = 1.231740951538086, GAN loss = [2.3170633, 0.7839672, 0.82591474]\n",
      "Batch 288/700: Discriminator loss = 1.2192339897155762, GAN loss = [2.3681147, 0.8005523, 0.86039627]\n",
      "Batch 289/700: Discriminator loss = 1.2351211309432983, GAN loss = [2.3028777, 0.76849675, 0.827236]\n",
      "Batch 290/700: Discriminator loss = 1.2288578748703003, GAN loss = [2.3305473, 0.7757958, 0.84762275]\n",
      "Batch 291/700: Discriminator loss = 1.2272928953170776, GAN loss = [2.3808866, 0.80517304, 0.8685973]\n",
      "Batch 292/700: Discriminator loss = 1.2519140243530273, GAN loss = [2.2923589, 0.7688711, 0.816382]\n",
      "Batch 293/700: Discriminator loss = 1.2156933546066284, GAN loss = [2.3671012, 0.8086345, 0.8513789]\n",
      "Batch 294/700: Discriminator loss = 1.2394999265670776, GAN loss = [2.3543515, 0.77530104, 0.8719937]\n",
      "Batch 295/700: Discriminator loss = 1.2392563819885254, GAN loss = [2.4013355, 0.7983371, 0.895977]\n",
      "Batch 296/700: Discriminator loss = 1.2186223268508911, GAN loss = [2.3312666, 0.78062457, 0.8436505]\n",
      "Batch 297/700: Discriminator loss = 1.2114630937576294, GAN loss = [2.36234, 0.79622793, 0.859142]\n",
      "Batch 298/700: Discriminator loss = 1.2751519680023193, GAN loss = [2.2830572, 0.7534622, 0.8226447]\n",
      "Batch 299/700: Discriminator loss = 1.2180612087249756, GAN loss = [2.2974226, 0.78404945, 0.8064409]\n",
      "Batch 300/700: Discriminator loss = 1.2410941123962402, GAN loss = [2.3485594, 0.79174125, 0.84990805]\n",
      "Batch 301/700: Discriminator loss = 1.2333472967147827, GAN loss = [2.3000064, 0.7706053, 0.8225093]\n",
      "Batch 302/700: Discriminator loss = 1.2114250659942627, GAN loss = [2.3894353, 0.82234365, 0.860218]\n",
      "Batch 303/700: Discriminator loss = 1.2110923528671265, GAN loss = [2.362804, 0.79579955, 0.8601551]\n",
      "Batch 304/700: Discriminator loss = 1.2330595254898071, GAN loss = [2.3079383, 0.76681525, 0.83429664]\n",
      "Batch 305/700: Discriminator loss = 1.2416996955871582, GAN loss = [2.3232841, 0.7948567, 0.82161295]\n",
      "Batch 306/700: Discriminator loss = 1.2017076015472412, GAN loss = [2.3729808, 0.80165285, 0.86452585]\n",
      "Batch 307/700: Discriminator loss = 1.240380883216858, GAN loss = [2.3422256, 0.7877623, 0.84767264]\n",
      "Batch 308/700: Discriminator loss = 1.2196708917617798, GAN loss = [2.365397, 0.7942789, 0.86434907]\n",
      "Batch 309/700: Discriminator loss = 1.2368159294128418, GAN loss = [2.3284636, 0.777376, 0.84433746]\n",
      "Batch 310/700: Discriminator loss = 1.2148517370224, GAN loss = [2.3614743, 0.79439604, 0.8603559]\n",
      "Batch 311/700: Discriminator loss = 1.2312777042388916, GAN loss = [2.330929, 0.77139604, 0.85283166]\n",
      "Batch 312/700: Discriminator loss = 1.2256529331207275, GAN loss = [2.3272395, 0.7654604, 0.85510236]\n",
      "Batch 313/700: Discriminator loss = 1.2774817943572998, GAN loss = [2.3157392, 0.75822777, 0.8508664]\n",
      "Batch 314/700: Discriminator loss = 1.2198268175125122, GAN loss = [2.3833306, 0.79820067, 0.8785128]\n",
      "Batch 315/700: Discriminator loss = 1.2641079425811768, GAN loss = [2.3174987, 0.7726551, 0.83825636]\n",
      "Batch 316/700: Discriminator loss = 1.248606562614441, GAN loss = [2.3189373, 0.76542366, 0.8469544]\n",
      "Batch 317/700: Discriminator loss = 1.2260850667953491, GAN loss = [2.3657634, 0.78555924, 0.8736695]\n",
      "Batch 318/700: Discriminator loss = 1.2460956573486328, GAN loss = [2.3677828, 0.7836859, 0.877581]\n",
      "Batch 319/700: Discriminator loss = 1.2191963195800781, GAN loss = [2.3438122, 0.79267794, 0.84464353]\n",
      "Batch 320/700: Discriminator loss = 1.2505685091018677, GAN loss = [2.3338916, 0.78179544, 0.84563756]\n",
      "Batch 321/700: Discriminator loss = 1.2186405658721924, GAN loss = [2.3777885, 0.8010338, 0.87033165]\n",
      "Batch 322/700: Discriminator loss = 1.1858601570129395, GAN loss = [2.3808439, 0.83095956, 0.84350073]\n",
      "Batch 323/700: Discriminator loss = 1.2312562465667725, GAN loss = [2.3145525, 0.8099211, 0.7982894]\n",
      "Batch 324/700: Discriminator loss = 1.2431910037994385, GAN loss = [2.3906844, 0.8093785, 0.874995]\n",
      "Batch 325/700: Discriminator loss = 1.219027042388916, GAN loss = [2.3204823, 0.78793615, 0.8262658]\n",
      "Batch 326/700: Discriminator loss = 1.2015172243118286, GAN loss = [2.3468282, 0.81829816, 0.8222694]\n",
      "Batch 327/700: Discriminator loss = 1.190568447113037, GAN loss = [2.3841467, 0.83070636, 0.8471975]\n",
      "Batch 328/700: Discriminator loss = 1.2139966487884521, GAN loss = [2.3479247, 0.7914565, 0.8502442]\n",
      "Batch 329/700: Discriminator loss = 1.229604959487915, GAN loss = [2.3031297, 0.78188825, 0.8150371]\n",
      "Batch 330/700: Discriminator loss = 1.226180911064148, GAN loss = [2.3400419, 0.77750814, 0.856344]\n",
      "Batch 331/700: Discriminator loss = 1.2138357162475586, GAN loss = [2.352005, 0.78989846, 0.85593885]\n",
      "Batch 332/700: Discriminator loss = 1.2103869915008545, GAN loss = [2.4227622, 0.8148526, 0.9017588]\n",
      "Batch 333/700: Discriminator loss = 1.1931679248809814, GAN loss = [2.3756738, 0.841816, 0.8277286]\n",
      "Batch 334/700: Discriminator loss = 1.2071807384490967, GAN loss = [2.323688, 0.8102549, 0.8073341]\n",
      "Batch 335/700: Discriminator loss = 1.2007824182510376, GAN loss = [2.3927975, 0.81055474, 0.87616396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 336/700: Discriminator loss = 1.1888149976730347, GAN loss = [2.3869967, 0.8290345, 0.8519008]\n",
      "Batch 337/700: Discriminator loss = 1.227908968925476, GAN loss = [2.334049, 0.78647923, 0.8415108]\n",
      "Batch 338/700: Discriminator loss = 1.23348867893219, GAN loss = [2.341387, 0.7900488, 0.8452903]\n",
      "Batch 339/700: Discriminator loss = 1.2516405582427979, GAN loss = [2.3094943, 0.765265, 0.8381926]\n",
      "Batch 340/700: Discriminator loss = 1.2327210903167725, GAN loss = [2.3438535, 0.78070265, 0.8571265]\n",
      "Batch 341/700: Discriminator loss = 1.2361081838607788, GAN loss = [2.3625, 0.7906404, 0.8658508]\n",
      "Batch 342/700: Discriminator loss = 1.204994559288025, GAN loss = [2.3423102, 0.7995572, 0.83676094]\n",
      "Batch 343/700: Discriminator loss = 1.2023855447769165, GAN loss = [2.3297045, 0.8017285, 0.822003]\n",
      "Batch 344/700: Discriminator loss = 1.2002085447311401, GAN loss = [2.3622406, 0.82282335, 0.8334587]\n",
      "Batch 345/700: Discriminator loss = 1.2140393257141113, GAN loss = [2.4076164, 0.82737505, 0.8743026]\n",
      "Batch 346/700: Discriminator loss = 1.2226840257644653, GAN loss = [2.373403, 0.8050009, 0.86248595]\n",
      "Batch 347/700: Discriminator loss = 1.1992334127426147, GAN loss = [2.3959537, 0.8255496, 0.8645004]\n",
      "Batch 348/700: Discriminator loss = 1.2171368598937988, GAN loss = [2.3972144, 0.8228071, 0.86851573]\n",
      "Batch 349/700: Discriminator loss = 1.211060643196106, GAN loss = [2.3462458, 0.8088583, 0.83149666]\n",
      "Batch 350/700: Discriminator loss = 1.2090144157409668, GAN loss = [2.3801124, 0.817602, 0.8566253]\n",
      "Batch 351/700: Discriminator loss = 1.2552188634872437, GAN loss = [2.3249118, 0.7803193, 0.8387171]\n",
      "Batch 352/700: Discriminator loss = 1.1964201927185059, GAN loss = [2.3285837, 0.813273, 0.80945086]\n",
      "Batch 353/700: Discriminator loss = 1.2111303806304932, GAN loss = [2.3498776, 0.81143224, 0.83259284]\n",
      "Batch 354/700: Discriminator loss = 1.213836431503296, GAN loss = [2.3378918, 0.8316582, 0.80039084]\n",
      "Batch 355/700: Discriminator loss = 1.2078438997268677, GAN loss = [2.369486, 0.82428694, 0.83937037]\n",
      "Batch 356/700: Discriminator loss = 1.204013466835022, GAN loss = [2.3551831, 0.8275901, 0.8217784]\n",
      "Batch 357/700: Discriminator loss = 1.203702688217163, GAN loss = [2.3725085, 0.8224149, 0.8442813]\n",
      "Batch 358/700: Discriminator loss = 1.2031198740005493, GAN loss = [2.3476434, 0.8170596, 0.8247724]\n",
      "Batch 359/700: Discriminator loss = 1.2132645845413208, GAN loss = [2.351483, 0.81730324, 0.8283794]\n",
      "Batch 360/700: Discriminator loss = 1.218136191368103, GAN loss = [2.3370245, 0.7964257, 0.83479935]\n",
      "Batch 361/700: Discriminator loss = 1.1961218118667603, GAN loss = [2.3633492, 0.8149771, 0.84257674]\n",
      "Batch 362/700: Discriminator loss = 1.2051405906677246, GAN loss = [2.315061, 0.8145709, 0.7947045]\n",
      "Batch 363/700: Discriminator loss = 1.2486355304718018, GAN loss = [2.3047388, 0.78644043, 0.81252784]\n",
      "Batch 364/700: Discriminator loss = 1.2189960479736328, GAN loss = [2.3254442, 0.8035903, 0.8160942]\n",
      "Batch 365/700: Discriminator loss = 1.2246055603027344, GAN loss = [2.2828217, 0.79314554, 0.78392845]\n",
      "Batch 366/700: Discriminator loss = 1.2064918279647827, GAN loss = [2.345912, 0.7924009, 0.8477794]\n",
      "Batch 367/700: Discriminator loss = 1.2013988494873047, GAN loss = [2.402094, 0.8043864, 0.891982]\n",
      "Batch 368/700: Discriminator loss = 1.2203317880630493, GAN loss = [2.3121889, 0.7878295, 0.81864023]\n",
      "Batch 369/700: Discriminator loss = 1.2103453874588013, GAN loss = [2.3400934, 0.8251947, 0.8091922]\n",
      "Batch 370/700: Discriminator loss = 1.2318475246429443, GAN loss = [2.317075, 0.7793015, 0.83207893]\n",
      "Batch 371/700: Discriminator loss = 1.2231851816177368, GAN loss = [2.3517737, 0.78569967, 0.86038774]\n",
      "Batch 372/700: Discriminator loss = 1.2277933359146118, GAN loss = [2.3217556, 0.7822633, 0.833807]\n",
      "Batch 373/700: Discriminator loss = 1.2234840393066406, GAN loss = [2.325165, 0.7766852, 0.84280235]\n",
      "Batch 374/700: Discriminator loss = 1.2316081523895264, GAN loss = [2.3141851, 0.76537085, 0.84314734]\n",
      "Batch 375/700: Discriminator loss = 1.2351309061050415, GAN loss = [2.4184675, 0.77744, 0.9353722]\n",
      "Batch 376/700: Discriminator loss = 1.2308669090270996, GAN loss = [2.3200688, 0.7804499, 0.8339716]\n",
      "Batch 377/700: Discriminator loss = 1.2213817834854126, GAN loss = [2.3580792, 0.7845239, 0.86792153]\n",
      "Batch 378/700: Discriminator loss = 1.239243507385254, GAN loss = [2.288406, 0.76869607, 0.81409365]\n",
      "Batch 379/700: Discriminator loss = 1.216637134552002, GAN loss = [2.3664355, 0.7959001, 0.8649281]\n",
      "Batch 380/700: Discriminator loss = 1.236199140548706, GAN loss = [2.3183863, 0.7789817, 0.83380145]\n",
      "Batch 381/700: Discriminator loss = 1.2212990522384644, GAN loss = [2.3747919, 0.7902434, 0.87895477]\n",
      "Batch 382/700: Discriminator loss = 1.224409580230713, GAN loss = [2.387298, 0.78938556, 0.8923318]\n",
      "Batch 383/700: Discriminator loss = 1.235019564628601, GAN loss = [2.3651626, 0.79152954, 0.86806864]\n",
      "Batch 384/700: Discriminator loss = 1.2404206991195679, GAN loss = [2.34481, 0.7920551, 0.84720784]\n",
      "Batch 385/700: Discriminator loss = 1.212849497795105, GAN loss = [2.370014, 0.8154131, 0.84907514]\n",
      "Batch 386/700: Discriminator loss = 1.2356438636779785, GAN loss = [2.352127, 0.79633117, 0.8502927]\n",
      "Batch 387/700: Discriminator loss = 1.2363412380218506, GAN loss = [2.3565063, 0.793812, 0.8572184]\n",
      "Batch 388/700: Discriminator loss = 1.2373696565628052, GAN loss = [2.3037508, 0.788493, 0.80979973]\n",
      "Batch 389/700: Discriminator loss = 1.2345658540725708, GAN loss = [2.3520913, 0.8005779, 0.84607786]\n",
      "Batch 390/700: Discriminator loss = 1.2414331436157227, GAN loss = [2.3492672, 0.7932531, 0.8506081]\n",
      "Batch 391/700: Discriminator loss = 1.2025519609451294, GAN loss = [2.3528259, 0.82099104, 0.8264443]\n",
      "Batch 392/700: Discriminator loss = 1.213705062866211, GAN loss = [2.4127874, 0.8289663, 0.8784405]\n",
      "Batch 393/700: Discriminator loss = 1.1964420080184937, GAN loss = [2.3436413, 0.8309624, 0.8073053]\n",
      "Batch 394/700: Discriminator loss = 1.215295672416687, GAN loss = [2.3533642, 0.80823624, 0.8397708]\n",
      "Batch 395/700: Discriminator loss = 1.1926989555358887, GAN loss = [2.3395455, 0.8137981, 0.82038796]\n",
      "Batch 396/700: Discriminator loss = 1.2144347429275513, GAN loss = [2.3360274, 0.79329497, 0.837381]\n",
      "Batch 397/700: Discriminator loss = 1.2363916635513306, GAN loss = [2.3647034, 0.7763736, 0.88297784]\n",
      "Batch 398/700: Discriminator loss = 1.2449336051940918, GAN loss = [2.3151643, 0.76329935, 0.84652156]\n",
      "Batch 399/700: Discriminator loss = 1.2045131921768188, GAN loss = [2.355965, 0.79986036, 0.85077596]\n",
      "Batch 400/700: Discriminator loss = 1.2409402132034302, GAN loss = [2.3029275, 0.7627634, 0.83485967]\n",
      "Batch 401/700: Discriminator loss = 1.2116032838821411, GAN loss = [2.3612697, 0.79546523, 0.860513]\n",
      "Batch 402/700: Discriminator loss = 1.223815679550171, GAN loss = [2.33235, 0.79448026, 0.83259416]\n",
      "Batch 403/700: Discriminator loss = 1.2091946601867676, GAN loss = [2.3354154, 0.79380536, 0.8363561]\n",
      "Batch 404/700: Discriminator loss = 1.1993275880813599, GAN loss = [2.4259992, 0.81396455, 0.9067981]\n",
      "Batch 405/700: Discriminator loss = 1.2256346940994263, GAN loss = [2.3135023, 0.77662987, 0.8316576]\n",
      "Batch 406/700: Discriminator loss = 1.2194013595581055, GAN loss = [2.3302014, 0.7753456, 0.84965783]\n",
      "Batch 407/700: Discriminator loss = 1.2088121175765991, GAN loss = [2.3104002, 0.80000526, 0.80521005]\n",
      "Batch 408/700: Discriminator loss = 1.246669888496399, GAN loss = [2.360399, 0.77806973, 0.87715983]\n",
      "Batch 409/700: Discriminator loss = 1.2373602390289307, GAN loss = [2.3346581, 0.7802072, 0.8492973]\n",
      "Batch 410/700: Discriminator loss = 1.1931253671646118, GAN loss = [2.3864741, 0.8308067, 0.8505232]\n",
      "Batch 411/700: Discriminator loss = 1.213499903678894, GAN loss = [2.3873863, 0.8177176, 0.8645382]\n",
      "Batch 412/700: Discriminator loss = 1.2439258098602295, GAN loss = [2.3682268, 0.7731929, 0.88993233]\n",
      "Batch 413/700: Discriminator loss = 1.2153159379959106, GAN loss = [2.2932837, 0.7958968, 0.79230857]\n",
      "Batch 414/700: Discriminator loss = 1.223892331123352, GAN loss = [2.3453782, 0.7812191, 0.8591052]\n",
      "Batch 415/700: Discriminator loss = 1.245261788368225, GAN loss = [2.345702, 0.778342, 0.8623376]\n",
      "Batch 416/700: Discriminator loss = 1.213984727859497, GAN loss = [2.3750505, 0.8205474, 0.84949684]\n",
      "Batch 417/700: Discriminator loss = 1.1985344886779785, GAN loss = [2.3855553, 0.80796814, 0.8725953]\n",
      "Batch 418/700: Discriminator loss = 1.2043335437774658, GAN loss = [2.4283392, 0.82574934, 0.8976132]\n",
      "Batch 419/700: Discriminator loss = 1.1732714176177979, GAN loss = [2.413104, 0.83453894, 0.87360156]\n",
      "Batch 420/700: Discriminator loss = 1.2061833143234253, GAN loss = [2.3608527, 0.8114938, 0.84441984]\n",
      "Batch 421/700: Discriminator loss = 1.1824921369552612, GAN loss = [2.4538128, 0.83278483, 0.9161261]\n",
      "Batch 422/700: Discriminator loss = 1.1896573305130005, GAN loss = [2.420859, 0.8277331, 0.88824195]\n",
      "Batch 423/700: Discriminator loss = 1.1813311576843262, GAN loss = [2.4057689, 0.8252525, 0.8756452]\n",
      "Batch 424/700: Discriminator loss = 1.1979920864105225, GAN loss = [2.429202, 0.80304617, 0.9213056]\n",
      "Batch 425/700: Discriminator loss = 1.209718942642212, GAN loss = [2.3839335, 0.8114722, 0.8676251]\n",
      "Batch 426/700: Discriminator loss = 1.2043126821517944, GAN loss = [2.4342525, 0.80454683, 0.9248978]\n",
      "Batch 427/700: Discriminator loss = 1.1950429677963257, GAN loss = [2.4237037, 0.821121, 0.8978022]\n",
      "Batch 428/700: Discriminator loss = 1.2012468576431274, GAN loss = [2.3754845, 0.7918453, 0.87888604]\n",
      "Batch 429/700: Discriminator loss = 1.193655014038086, GAN loss = [2.3950665, 0.8207896, 0.86955506]\n",
      "Batch 430/700: Discriminator loss = 1.1968727111816406, GAN loss = [2.4092524, 0.8180566, 0.88649994]\n",
      "Batch 431/700: Discriminator loss = 1.2201958894729614, GAN loss = [2.3460667, 0.7964794, 0.84491456]\n",
      "Batch 432/700: Discriminator loss = 1.1975796222686768, GAN loss = [2.3770099, 0.8213811, 0.8509652]\n",
      "Batch 433/700: Discriminator loss = 1.2427982091903687, GAN loss = [2.364522, 0.7856781, 0.87419236]\n",
      "Batch 434/700: Discriminator loss = 1.2339388132095337, GAN loss = [2.3200855, 0.76712304, 0.8483221]\n",
      "Batch 435/700: Discriminator loss = 1.2179946899414062, GAN loss = [2.436982, 0.808487, 0.92386436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 436/700: Discriminator loss = 1.264581561088562, GAN loss = [2.2915046, 0.7581775, 0.82870483]\n",
      "Batch 437/700: Discriminator loss = 1.2239983081817627, GAN loss = [2.4003737, 0.8109175, 0.88484275]\n",
      "Batch 438/700: Discriminator loss = 1.261053204536438, GAN loss = [2.3592494, 0.75665605, 0.8979846]\n",
      "Batch 439/700: Discriminator loss = 1.213865876197815, GAN loss = [2.3618016, 0.78928447, 0.86790746]\n",
      "Batch 440/700: Discriminator loss = 1.2524714469909668, GAN loss = [2.3242106, 0.76802915, 0.85158044]\n",
      "Batch 441/700: Discriminator loss = 1.253021240234375, GAN loss = [2.3136127, 0.74939156, 0.8596365]\n",
      "Batch 442/700: Discriminator loss = 1.2373595237731934, GAN loss = [2.3550072, 0.78697234, 0.8634643]\n",
      "Batch 443/700: Discriminator loss = 1.2390297651290894, GAN loss = [2.3688786, 0.7916079, 0.8727216]\n",
      "Batch 444/700: Discriminator loss = 1.2362295389175415, GAN loss = [2.3242145, 0.7834867, 0.836194]\n",
      "Batch 445/700: Discriminator loss = 1.2373900413513184, GAN loss = [2.4017465, 0.779862, 0.91737527]\n",
      "Batch 446/700: Discriminator loss = 1.2543151378631592, GAN loss = [2.3481305, 0.7775666, 0.8660764]\n",
      "Batch 447/700: Discriminator loss = 1.2218073606491089, GAN loss = [2.3556306, 0.8170157, 0.83415353]\n",
      "Batch 448/700: Discriminator loss = 1.2405494451522827, GAN loss = [2.4138088, 0.77967376, 0.92969877]\n",
      "Batch 449/700: Discriminator loss = 1.2323083877563477, GAN loss = [2.325084, 0.7902879, 0.83037186]\n",
      "Batch 450/700: Discriminator loss = 1.194150447845459, GAN loss = [2.376744, 0.83460516, 0.8377298]\n",
      "Batch 451/700: Discriminator loss = 1.2002465724945068, GAN loss = [2.3614254, 0.81539184, 0.841631]\n",
      "Batch 452/700: Discriminator loss = 1.203016757965088, GAN loss = [2.3533325, 0.8195215, 0.82941467]\n",
      "Batch 453/700: Discriminator loss = 1.2250148057937622, GAN loss = [2.3268113, 0.78362185, 0.8388042]\n",
      "Batch 454/700: Discriminator loss = 1.2208499908447266, GAN loss = [2.3544316, 0.80083865, 0.84921783]\n",
      "Batch 455/700: Discriminator loss = 1.1708425283432007, GAN loss = [2.3937743, 0.8498835, 0.83952403]\n",
      "Batch 456/700: Discriminator loss = 1.2055490016937256, GAN loss = [2.4392264, 0.83226556, 0.90260607]\n",
      "Batch 457/700: Discriminator loss = 1.2187200784683228, GAN loss = [2.3685849, 0.8148146, 0.84941024]\n",
      "Batch 458/700: Discriminator loss = 1.233425259590149, GAN loss = [2.3623114, 0.78631616, 0.8716305]\n",
      "Batch 459/700: Discriminator loss = 1.251664161682129, GAN loss = [2.334779, 0.77506685, 0.8553608]\n",
      "Batch 460/700: Discriminator loss = 1.236849308013916, GAN loss = [2.3045168, 0.7878822, 0.81230664]\n",
      "Batch 461/700: Discriminator loss = 1.2091631889343262, GAN loss = [2.33986, 0.7940369, 0.8415241]\n",
      "Batch 462/700: Discriminator loss = 1.2379074096679688, GAN loss = [2.3394752, 0.7905213, 0.84467727]\n",
      "Batch 463/700: Discriminator loss = 1.219470739364624, GAN loss = [2.4074585, 0.8039355, 0.8992658]\n",
      "Batch 464/700: Discriminator loss = 1.2063244581222534, GAN loss = [2.3486588, 0.82030904, 0.8241033]\n",
      "Batch 465/700: Discriminator loss = 1.2016143798828125, GAN loss = [2.338834, 0.8182928, 0.8163081]\n",
      "Batch 466/700: Discriminator loss = 1.2127794027328491, GAN loss = [2.3438392, 0.8253132, 0.8143184]\n",
      "Batch 467/700: Discriminator loss = 1.2184076309204102, GAN loss = [2.3633742, 0.79799706, 0.86117876]\n",
      "Batch 468/700: Discriminator loss = 1.228289008140564, GAN loss = [2.301704, 0.7881401, 0.80936915]\n",
      "Batch 469/700: Discriminator loss = 1.2474093437194824, GAN loss = [2.3151078, 0.8081774, 0.80273545]\n",
      "Batch 470/700: Discriminator loss = 1.2396061420440674, GAN loss = [2.3065488, 0.79513776, 0.80721146]\n",
      "Batch 471/700: Discriminator loss = 1.2372982501983643, GAN loss = [2.3298805, 0.789671, 0.8360208]\n",
      "Batch 472/700: Discriminator loss = 1.2120790481567383, GAN loss = [2.3221805, 0.82342225, 0.7945898]\n",
      "Batch 473/700: Discriminator loss = 1.2097070217132568, GAN loss = [2.345036, 0.807627, 0.83325386]\n",
      "Batch 474/700: Discriminator loss = 1.229467749595642, GAN loss = [2.3086061, 0.79712135, 0.80733943]\n",
      "Batch 475/700: Discriminator loss = 1.2432866096496582, GAN loss = [2.3290267, 0.8060159, 0.8188723]\n",
      "Batch 476/700: Discriminator loss = 1.22084379196167, GAN loss = [2.3446698, 0.81552714, 0.8250095]\n",
      "Batch 477/700: Discriminator loss = 1.2370458841323853, GAN loss = [2.3649385, 0.8011325, 0.8596824]\n",
      "Batch 478/700: Discriminator loss = 1.1850402355194092, GAN loss = [2.3611703, 0.834565, 0.8224894]\n",
      "Batch 479/700: Discriminator loss = 1.2135952711105347, GAN loss = [2.3175232, 0.8103589, 0.8030518]\n",
      "Batch 480/700: Discriminator loss = 1.216467261314392, GAN loss = [2.378587, 0.80414015, 0.87032336]\n",
      "Batch 481/700: Discriminator loss = 1.2151600122451782, GAN loss = [2.3425348, 0.80795705, 0.8304436]\n",
      "Batch 482/700: Discriminator loss = 1.1832380294799805, GAN loss = [2.4118526, 0.8204026, 0.8873215]\n",
      "Batch 483/700: Discriminator loss = 1.2021892070770264, GAN loss = [2.374086, 0.8123479, 0.8576134]\n",
      "Batch 484/700: Discriminator loss = 1.2114475965499878, GAN loss = [2.3521316, 0.80346835, 0.844532]\n",
      "Batch 485/700: Discriminator loss = 1.2240701913833618, GAN loss = [2.384998, 0.79438514, 0.88647467]\n",
      "Batch 486/700: Discriminator loss = 1.2172123193740845, GAN loss = [2.3428717, 0.81024337, 0.8284779]\n",
      "Batch 487/700: Discriminator loss = 1.1772829294204712, GAN loss = [2.4243891, 0.8493184, 0.87091994]\n",
      "Batch 488/700: Discriminator loss = 1.2047581672668457, GAN loss = [2.4267325, 0.84096265, 0.88160956]\n",
      "Batch 489/700: Discriminator loss = 1.2189935445785522, GAN loss = [2.3711493, 0.8089523, 0.85803276]\n",
      "Batch 490/700: Discriminator loss = 1.2337241172790527, GAN loss = [2.3739645, 0.80245185, 0.8673342]\n",
      "Batch 491/700: Discriminator loss = 1.1857789754867554, GAN loss = [2.4178944, 0.8334297, 0.8802629]\n",
      "Batch 492/700: Discriminator loss = 1.2276246547698975, GAN loss = [2.373517, 0.8267063, 0.84260106]\n",
      "Batch 493/700: Discriminator loss = 1.1867748498916626, GAN loss = [2.4484437, 0.8362768, 0.9079323]\n",
      "Batch 494/700: Discriminator loss = 1.1886557340621948, GAN loss = [2.4401362, 0.8467737, 0.889109]\n",
      "Batch 495/700: Discriminator loss = 1.1942343711853027, GAN loss = [2.3593192, 0.8085853, 0.84648216]\n",
      "Batch 496/700: Discriminator loss = 1.2012101411819458, GAN loss = [2.3833017, 0.8172009, 0.8618425]\n",
      "Batch 497/700: Discriminator loss = 1.202749252319336, GAN loss = [2.405758, 0.81263626, 0.8888598]\n",
      "Batch 498/700: Discriminator loss = 1.2091814279556274, GAN loss = [2.3669682, 0.8125098, 0.8501922]\n",
      "Batch 499/700: Discriminator loss = 1.1973782777786255, GAN loss = [2.4032748, 0.84685904, 0.8521428]\n",
      "Batch 500/700: Discriminator loss = 1.1818206310272217, GAN loss = [2.3881662, 0.8397718, 0.8440922]\n",
      "Batch 501/700: Discriminator loss = 1.1952406167984009, GAN loss = [2.357496, 0.8208395, 0.83233213]\n",
      "Batch 502/700: Discriminator loss = 1.2168744802474976, GAN loss = [2.3614662, 0.7915892, 0.86553115]\n",
      "Batch 503/700: Discriminator loss = 1.2497302293777466, GAN loss = [2.335422, 0.80229324, 0.82876635]\n",
      "Batch 504/700: Discriminator loss = 1.1844948530197144, GAN loss = [2.3672817, 0.81026155, 0.8526364]\n",
      "Batch 505/700: Discriminator loss = 1.198790192604065, GAN loss = [2.4226046, 0.81198937, 0.9062178]\n",
      "Batch 506/700: Discriminator loss = 1.2271908521652222, GAN loss = [2.3760424, 0.8025835, 0.8690538]\n",
      "Batch 507/700: Discriminator loss = 1.2286738157272339, GAN loss = [2.3317106, 0.77802014, 0.84928054]\n",
      "Batch 508/700: Discriminator loss = 1.2182400226593018, GAN loss = [2.3686402, 0.78202957, 0.8822049]\n",
      "Batch 509/700: Discriminator loss = 1.2127937078475952, GAN loss = [2.3427386, 0.7928784, 0.845465]\n",
      "Batch 510/700: Discriminator loss = 1.2166361808776855, GAN loss = [2.3437538, 0.78822243, 0.851141]\n",
      "Batch 511/700: Discriminator loss = 1.186510443687439, GAN loss = [2.4236336, 0.83343625, 0.8858101]\n",
      "Batch 512/700: Discriminator loss = 1.1965175867080688, GAN loss = [2.3728588, 0.8282726, 0.8402138]\n",
      "Batch 513/700: Discriminator loss = 1.255800485610962, GAN loss = [2.3051875, 0.75144976, 0.8493758]\n",
      "Batch 514/700: Discriminator loss = 1.235422968864441, GAN loss = [2.3370738, 0.7858725, 0.84684324]\n",
      "Batch 515/700: Discriminator loss = 1.1950702667236328, GAN loss = [2.3578138, 0.80032915, 0.8531287]\n",
      "Batch 516/700: Discriminator loss = 1.2228707075119019, GAN loss = [2.3127136, 0.7642292, 0.8441332]\n",
      "Batch 517/700: Discriminator loss = 1.2007030248641968, GAN loss = [2.3518636, 0.78727555, 0.86024165]\n",
      "Batch 518/700: Discriminator loss = 1.2168067693710327, GAN loss = [2.3449838, 0.77314156, 0.8674963]\n",
      "Batch 519/700: Discriminator loss = 1.1837096214294434, GAN loss = [2.4132645, 0.80889326, 0.90002614]\n",
      "Batch 520/700: Discriminator loss = 1.230145812034607, GAN loss = [2.3092458, 0.7443756, 0.86053324]\n",
      "Batch 521/700: Discriminator loss = 1.2305940389633179, GAN loss = [2.3722832, 0.75296766, 0.91497225]\n",
      "Batch 522/700: Discriminator loss = 1.208349585533142, GAN loss = [2.3884594, 0.7805151, 0.9036124]\n",
      "Batch 523/700: Discriminator loss = 1.2142977714538574, GAN loss = [2.3512402, 0.7782773, 0.86864793]\n",
      "Batch 524/700: Discriminator loss = 1.2161202430725098, GAN loss = [2.3653927, 0.7741999, 0.88690656]\n",
      "Batch 525/700: Discriminator loss = 1.168075680732727, GAN loss = [2.3865108, 0.82904077, 0.8532078]\n",
      "Batch 526/700: Discriminator loss = 1.204584002494812, GAN loss = [2.342917, 0.7956958, 0.8429909]\n",
      "Batch 527/700: Discriminator loss = 1.2029361724853516, GAN loss = [2.409608, 0.8227637, 0.88263994]\n",
      "Batch 528/700: Discriminator loss = 1.2189977169036865, GAN loss = [2.356763, 0.77410406, 0.8784732]\n",
      "Batch 529/700: Discriminator loss = 1.230626106262207, GAN loss = [2.362342, 0.7813875, 0.87678236]\n",
      "Batch 530/700: Discriminator loss = 1.1928530931472778, GAN loss = [2.373483, 0.7916028, 0.87770814]\n",
      "Batch 531/700: Discriminator loss = 1.1996850967407227, GAN loss = [2.3546414, 0.7831426, 0.8673355]\n",
      "Batch 532/700: Discriminator loss = 1.2144529819488525, GAN loss = [2.3475332, 0.7785211, 0.86487037]\n",
      "Batch 533/700: Discriminator loss = 1.241948127746582, GAN loss = [2.2947466, 0.7397816, 0.85083985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 534/700: Discriminator loss = 1.2108782529830933, GAN loss = [2.3539412, 0.7697485, 0.88009745]\n",
      "Batch 535/700: Discriminator loss = 1.2256762981414795, GAN loss = [2.3637612, 0.768815, 0.89087915]\n",
      "Batch 536/700: Discriminator loss = 1.2368730306625366, GAN loss = [2.3548179, 0.75353914, 0.89722943]\n",
      "Batch 537/700: Discriminator loss = 1.2120935916900635, GAN loss = [2.4021485, 0.7980214, 0.90008813]\n",
      "Batch 538/700: Discriminator loss = 1.247482180595398, GAN loss = [2.270362, 0.76494265, 0.80139834]\n",
      "Batch 539/700: Discriminator loss = 1.224890112876892, GAN loss = [2.366223, 0.77673936, 0.8855024]\n",
      "Batch 540/700: Discriminator loss = 1.2456779479980469, GAN loss = [2.316921, 0.7649736, 0.84799933]\n",
      "Batch 541/700: Discriminator loss = 1.200889229774475, GAN loss = [2.4123707, 0.80479014, 0.9036686]\n",
      "Batch 542/700: Discriminator loss = 1.1996724605560303, GAN loss = [2.425345, 0.8055058, 0.9159462]\n",
      "Batch 543/700: Discriminator loss = 1.2205660343170166, GAN loss = [2.352367, 0.7878537, 0.86063975]\n",
      "Batch 544/700: Discriminator loss = 1.1961618661880493, GAN loss = [2.3829086, 0.82265604, 0.8564009]\n",
      "Batch 545/700: Discriminator loss = 1.1746463775634766, GAN loss = [2.4202564, 0.8434091, 0.87302244]\n",
      "Batch 546/700: Discriminator loss = 1.2271783351898193, GAN loss = [2.2863717, 0.7986102, 0.7839551]\n",
      "Batch 547/700: Discriminator loss = 1.243604063987732, GAN loss = [2.2826185, 0.77390176, 0.8049564]\n",
      "Batch 548/700: Discriminator loss = 1.2759084701538086, GAN loss = [2.3229191, 0.761239, 0.85796165]\n",
      "Batch 549/700: Discriminator loss = 1.2290263175964355, GAN loss = [2.4004421, 0.7922868, 0.9044658]\n",
      "Batch 550/700: Discriminator loss = 1.183961033821106, GAN loss = [2.374506, 0.8386415, 0.8322174]\n",
      "Batch 551/700: Discriminator loss = 1.215843677520752, GAN loss = [2.3142347, 0.78628874, 0.8243237]\n",
      "Batch 552/700: Discriminator loss = 1.2209092378616333, GAN loss = [2.4284503, 0.8039814, 0.9208783]\n",
      "Batch 553/700: Discriminator loss = 1.2320761680603027, GAN loss = [2.3642468, 0.78272706, 0.8779615]\n",
      "Batch 554/700: Discriminator loss = 1.2135000228881836, GAN loss = [2.3579254, 0.7934454, 0.86095244]\n",
      "Batch 555/700: Discriminator loss = 1.2290512323379517, GAN loss = [2.3646545, 0.78401595, 0.8771543]\n",
      "Batch 556/700: Discriminator loss = 1.196309208869934, GAN loss = [2.3654184, 0.81844884, 0.84353185]\n",
      "Batch 557/700: Discriminator loss = 1.2301257848739624, GAN loss = [2.3734045, 0.79820955, 0.8718002]\n",
      "Batch 558/700: Discriminator loss = 1.220216989517212, GAN loss = [2.3876112, 0.79511, 0.88914573]\n",
      "Batch 559/700: Discriminator loss = 1.2479941844940186, GAN loss = [2.3065314, 0.78700966, 0.8162178]\n",
      "Batch 560/700: Discriminator loss = 1.2446314096450806, GAN loss = [2.367129, 0.7977407, 0.86612755]\n",
      "Batch 561/700: Discriminator loss = 1.2303552627563477, GAN loss = [2.3505423, 0.79522645, 0.85209656]\n",
      "Batch 562/700: Discriminator loss = 1.2358492612838745, GAN loss = [2.3522449, 0.7908859, 0.85819834]\n",
      "Batch 563/700: Discriminator loss = 1.2016586065292358, GAN loss = [2.414881, 0.8280924, 0.88366866]\n",
      "Batch 564/700: Discriminator loss = 1.1843507289886475, GAN loss = [2.4333827, 0.8309435, 0.89935714]\n",
      "Batch 565/700: Discriminator loss = 1.1903859376907349, GAN loss = [2.3455033, 0.8250096, 0.81743765]\n",
      "Batch 566/700: Discriminator loss = 1.2201180458068848, GAN loss = [2.390175, 0.7991303, 0.888016]\n",
      "Batch 567/700: Discriminator loss = 1.2190959453582764, GAN loss = [2.3129907, 0.7910286, 0.81895137]\n",
      "Batch 568/700: Discriminator loss = 1.2220354080200195, GAN loss = [2.3748758, 0.8128602, 0.8590295]\n",
      "Batch 569/700: Discriminator loss = 1.2173863649368286, GAN loss = [2.346842, 0.80541056, 0.8384625]\n",
      "Batch 570/700: Discriminator loss = 1.217015027999878, GAN loss = [2.3568587, 0.79559904, 0.85830235]\n",
      "Batch 571/700: Discriminator loss = 1.21428382396698, GAN loss = [2.2982755, 0.8151506, 0.7801805]\n",
      "Batch 572/700: Discriminator loss = 1.2554426193237305, GAN loss = [2.3388572, 0.7833732, 0.8525548]\n",
      "Batch 573/700: Discriminator loss = 1.217063307762146, GAN loss = [2.295037, 0.79734564, 0.7947811]\n",
      "Batch 574/700: Discriminator loss = 1.250343680381775, GAN loss = [2.296248, 0.77113295, 0.8222296]\n",
      "Batch 575/700: Discriminator loss = 1.214849591255188, GAN loss = [2.3053837, 0.7980853, 0.804424]\n",
      "Batch 576/700: Discriminator loss = 1.2188750505447388, GAN loss = [2.3108783, 0.81765294, 0.7903617]\n",
      "Batch 577/700: Discriminator loss = 1.2216894626617432, GAN loss = [2.2992165, 0.7923319, 0.80403656]\n",
      "Batch 578/700: Discriminator loss = 1.219504714012146, GAN loss = [2.317587, 0.7988695, 0.81588143]\n",
      "Batch 579/700: Discriminator loss = 1.222213625907898, GAN loss = [2.2849882, 0.79826635, 0.7838972]\n",
      "Batch 580/700: Discriminator loss = 1.2287222146987915, GAN loss = [2.3052342, 0.7907102, 0.8117176]\n",
      "Batch 581/700: Discriminator loss = 1.2381203174591064, GAN loss = [2.3026545, 0.7802894, 0.8195679]\n",
      "Batch 582/700: Discriminator loss = 1.19441819190979, GAN loss = [2.3636518, 0.86023766, 0.80063516]\n",
      "Batch 583/700: Discriminator loss = 1.2218332290649414, GAN loss = [2.344504, 0.8082858, 0.8334553]\n",
      "Batch 584/700: Discriminator loss = 1.2406386137008667, GAN loss = [2.2953434, 0.78957385, 0.8030182]\n",
      "Batch 585/700: Discriminator loss = 1.2140034437179565, GAN loss = [2.348415, 0.8021566, 0.84352875]\n",
      "Batch 586/700: Discriminator loss = 1.1815241575241089, GAN loss = [2.335168, 0.8168416, 0.81562215]\n",
      "Batch 587/700: Discriminator loss = 1.24006986618042, GAN loss = [2.2660277, 0.7889015, 0.7744374]\n",
      "Batch 588/700: Discriminator loss = 1.2356343269348145, GAN loss = [2.3260741, 0.7818303, 0.84156966]\n",
      "Batch 589/700: Discriminator loss = 1.246640682220459, GAN loss = [2.2973518, 0.7783313, 0.8163759]\n",
      "Batch 590/700: Discriminator loss = 1.2298321723937988, GAN loss = [2.287127, 0.7748489, 0.80965173]\n",
      "Batch 591/700: Discriminator loss = 1.2163950204849243, GAN loss = [2.278629, 0.7822243, 0.7938039]\n",
      "Batch 592/700: Discriminator loss = 1.2282443046569824, GAN loss = [2.29632, 0.79052687, 0.8032153]\n",
      "Batch 593/700: Discriminator loss = 1.2285534143447876, GAN loss = [2.2766023, 0.7683853, 0.80565]\n",
      "Batch 594/700: Discriminator loss = 1.1903207302093506, GAN loss = [2.379801, 0.80973214, 0.86751676]\n",
      "Batch 595/700: Discriminator loss = 1.2288143634796143, GAN loss = [2.2974296, 0.7831163, 0.81176454]\n",
      "Batch 596/700: Discriminator loss = 1.2244514226913452, GAN loss = [2.3082242, 0.76732373, 0.83834136]\n",
      "Batch 597/700: Discriminator loss = 1.192943811416626, GAN loss = [2.3795714, 0.81531, 0.8617125]\n",
      "Batch 598/700: Discriminator loss = 1.2069108486175537, GAN loss = [2.3340583, 0.7922069, 0.8393125]\n",
      "Batch 599/700: Discriminator loss = 1.1906987428665161, GAN loss = [2.377902, 0.80561507, 0.8697706]\n",
      "Batch 600/700: Discriminator loss = 1.2121647596359253, GAN loss = [2.3120065, 0.7778588, 0.83165354]\n",
      "Batch 601/700: Discriminator loss = 1.196256399154663, GAN loss = [2.3593674, 0.7853867, 0.8715094]\n",
      "Batch 602/700: Discriminator loss = 1.2173346281051636, GAN loss = [2.2870512, 0.7703903, 0.81421286]\n",
      "Batch 603/700: Discriminator loss = 1.1920970678329468, GAN loss = [2.400089, 0.7940941, 0.903564]\n",
      "Batch 604/700: Discriminator loss = 1.2016346454620361, GAN loss = [2.3316054, 0.7960749, 0.8331215]\n",
      "Batch 605/700: Discriminator loss = 1.2120712995529175, GAN loss = [2.3446987, 0.78504694, 0.8572543]\n",
      "Batch 606/700: Discriminator loss = 1.196223497390747, GAN loss = [2.4277987, 0.8095017, 0.9159079]\n",
      "Batch 607/700: Discriminator loss = 1.1713166236877441, GAN loss = [2.3794093, 0.8211899, 0.8558464]\n",
      "Batch 608/700: Discriminator loss = 1.1802905797958374, GAN loss = [2.4076285, 0.8265109, 0.8787493]\n",
      "Batch 609/700: Discriminator loss = 1.1880402565002441, GAN loss = [2.3496058, 0.79935753, 0.84791106]\n",
      "Batch 610/700: Discriminator loss = 1.206616759300232, GAN loss = [2.3673768, 0.7855656, 0.8795088]\n",
      "Batch 611/700: Discriminator loss = 1.1911567449569702, GAN loss = [2.3592467, 0.79677916, 0.8601918]\n",
      "Batch 612/700: Discriminator loss = 1.1865228414535522, GAN loss = [2.333796, 0.7885922, 0.84294015]\n",
      "Batch 613/700: Discriminator loss = 1.2078795433044434, GAN loss = [2.3514898, 0.79003334, 0.8592057]\n",
      "Batch 614/700: Discriminator loss = 1.1898994445800781, GAN loss = [2.4097514, 0.7991739, 0.9083557]\n",
      "Batch 615/700: Discriminator loss = 1.19486665725708, GAN loss = [2.354943, 0.7942622, 0.85848993]\n",
      "Batch 616/700: Discriminator loss = 1.1870362758636475, GAN loss = [2.3591666, 0.8089224, 0.8480803]\n",
      "Batch 617/700: Discriminator loss = 1.1964755058288574, GAN loss = [2.386259, 0.7932988, 0.8908376]\n",
      "Batch 618/700: Discriminator loss = 1.1845531463623047, GAN loss = [2.382641, 0.82306623, 0.85747796]\n",
      "Batch 619/700: Discriminator loss = 1.214594841003418, GAN loss = [2.3011062, 0.78317803, 0.8158597]\n",
      "Batch 620/700: Discriminator loss = 1.2357189655303955, GAN loss = [2.2848516, 0.7728733, 0.8099223]\n",
      "Batch 621/700: Discriminator loss = 1.2004879713058472, GAN loss = [2.3834543, 0.80753165, 0.87388146]\n",
      "Batch 622/700: Discriminator loss = 1.2301862239837646, GAN loss = [2.3122377, 0.77956665, 0.8306525]\n",
      "Batch 623/700: Discriminator loss = 1.200234293937683, GAN loss = [2.3105328, 0.7899843, 0.8185389]\n",
      "Batch 624/700: Discriminator loss = 1.2148096561431885, GAN loss = [2.3246849, 0.7712433, 0.85144013]\n",
      "Batch 625/700: Discriminator loss = 1.251627802848816, GAN loss = [2.3200872, 0.7524646, 0.8656357]\n",
      "Batch 626/700: Discriminator loss = 1.1997134685516357, GAN loss = [2.3633158, 0.7842646, 0.87708277]\n",
      "Batch 627/700: Discriminator loss = 1.2156567573547363, GAN loss = [2.363036, 0.7743745, 0.8867262]\n",
      "Batch 628/700: Discriminator loss = 1.2037997245788574, GAN loss = [2.308642, 0.7873085, 0.8194183]\n",
      "Batch 629/700: Discriminator loss = 1.2419437170028687, GAN loss = [2.3217359, 0.75609446, 0.86375314]\n",
      "Batch 630/700: Discriminator loss = 1.2146856784820557, GAN loss = [2.2747188, 0.78134483, 0.7915251]\n",
      "Batch 631/700: Discriminator loss = 1.2082518339157104, GAN loss = [2.3078148, 0.7783162, 0.8276776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 632/700: Discriminator loss = 1.213752269744873, GAN loss = [2.3153439, 0.7704323, 0.84310144]\n",
      "Batch 633/700: Discriminator loss = 1.2078641653060913, GAN loss = [2.3445754, 0.7710942, 0.8716806]\n",
      "Batch 634/700: Discriminator loss = 1.206496238708496, GAN loss = [2.3081412, 0.77472985, 0.8316313]\n",
      "Batch 635/700: Discriminator loss = 1.2447926998138428, GAN loss = [2.295702, 0.76822656, 0.82570803]\n",
      "Batch 636/700: Discriminator loss = 1.1945689916610718, GAN loss = [2.3784547, 0.7967474, 0.8799533]\n",
      "Batch 637/700: Discriminator loss = 1.2147971391677856, GAN loss = [2.325503, 0.7677806, 0.85598546]\n",
      "Batch 638/700: Discriminator loss = 1.199581265449524, GAN loss = [2.30915, 0.7933235, 0.8141062]\n",
      "Batch 639/700: Discriminator loss = 1.194650650024414, GAN loss = [2.3573442, 0.78762865, 0.8680221]\n",
      "Batch 640/700: Discriminator loss = 1.217115879058838, GAN loss = [2.3206544, 0.7573835, 0.86159384]\n",
      "Batch 641/700: Discriminator loss = 1.217018723487854, GAN loss = [2.340884, 0.78594995, 0.85327363]\n",
      "Batch 642/700: Discriminator loss = 1.1787172555923462, GAN loss = [2.3686097, 0.81179804, 0.8551763]\n",
      "Batch 643/700: Discriminator loss = 1.201767086982727, GAN loss = [2.2985055, 0.773124, 0.8237636]\n",
      "Batch 644/700: Discriminator loss = 1.2132506370544434, GAN loss = [2.3359036, 0.7802544, 0.8540298]\n",
      "Batch 645/700: Discriminator loss = 1.2186787128448486, GAN loss = [2.3565083, 0.7846863, 0.8702174]\n",
      "Batch 646/700: Discriminator loss = 1.2221667766571045, GAN loss = [2.3115866, 0.76796776, 0.84204286]\n",
      "Batch 647/700: Discriminator loss = 1.1937626600265503, GAN loss = [2.3737729, 0.7987215, 0.87349284]\n",
      "Batch 648/700: Discriminator loss = 1.21848464012146, GAN loss = [2.3343406, 0.7840257, 0.84876424]\n",
      "Batch 649/700: Discriminator loss = 1.2183690071105957, GAN loss = [2.3222613, 0.7868734, 0.83384824]\n",
      "Batch 650/700: Discriminator loss = 1.2164835929870605, GAN loss = [2.377801, 0.7904829, 0.8857918]\n",
      "Batch 651/700: Discriminator loss = 1.2059082984924316, GAN loss = [2.403929, 0.8154477, 0.8869653]\n",
      "Batch 652/700: Discriminator loss = 1.1928856372833252, GAN loss = [2.3717225, 0.8041498, 0.86607397]\n",
      "Batch 653/700: Discriminator loss = 1.2143305540084839, GAN loss = [2.3753514, 0.79946053, 0.8744096]\n",
      "Batch 654/700: Discriminator loss = 1.2044485807418823, GAN loss = [2.3961875, 0.803623, 0.8911086]\n",
      "Batch 655/700: Discriminator loss = 1.231988549232483, GAN loss = [2.3488941, 0.79583895, 0.85161346]\n",
      "Batch 656/700: Discriminator loss = 1.2054028511047363, GAN loss = [2.3469946, 0.8096117, 0.83595145]\n",
      "Batch 657/700: Discriminator loss = 1.2037136554718018, GAN loss = [2.36935, 0.80272746, 0.8651964]\n",
      "Batch 658/700: Discriminator loss = 1.2163982391357422, GAN loss = [2.3917794, 0.79007673, 0.9002944]\n",
      "Batch 659/700: Discriminator loss = 1.2341043949127197, GAN loss = [2.2642624, 0.7739332, 0.7889462]\n",
      "Batch 660/700: Discriminator loss = 1.2511144876480103, GAN loss = [2.359312, 0.76996666, 0.88798475]\n",
      "Batch 661/700: Discriminator loss = 1.2209547758102417, GAN loss = [2.348, 0.78922766, 0.8574319]\n",
      "Batch 662/700: Discriminator loss = 1.2202600240707397, GAN loss = [2.3614626, 0.8053567, 0.8547864]\n",
      "Batch 663/700: Discriminator loss = 1.218440294265747, GAN loss = [2.35209, 0.78745127, 0.863344]\n",
      "Batch 664/700: Discriminator loss = 1.240372896194458, GAN loss = [2.3323472, 0.7756648, 0.8554155]\n",
      "Batch 665/700: Discriminator loss = 1.2272446155548096, GAN loss = [2.2916906, 0.7770205, 0.81341815]\n",
      "Batch 666/700: Discriminator loss = 1.2196942567825317, GAN loss = [2.3674033, 0.7997995, 0.8663621]\n",
      "Batch 667/700: Discriminator loss = 1.1934186220169067, GAN loss = [2.3289273, 0.80479944, 0.82290643]\n",
      "Batch 668/700: Discriminator loss = 1.211743712425232, GAN loss = [2.3351488, 0.8086208, 0.82532424]\n",
      "Batch 669/700: Discriminator loss = 1.2081917524337769, GAN loss = [2.3499358, 0.80402184, 0.8447332]\n",
      "Batch 670/700: Discriminator loss = 1.2036058902740479, GAN loss = [2.35668, 0.80544937, 0.8500666]\n",
      "Batch 671/700: Discriminator loss = 1.1820285320281982, GAN loss = [2.3782382, 0.8222882, 0.8548137]\n",
      "Batch 672/700: Discriminator loss = 1.2266619205474854, GAN loss = [2.3340583, 0.7834693, 0.8494826]\n",
      "Batch 673/700: Discriminator loss = 1.2088561058044434, GAN loss = [2.3478813, 0.7913858, 0.8554178]\n",
      "Batch 674/700: Discriminator loss = 1.2248809337615967, GAN loss = [2.347116, 0.7956769, 0.8503941]\n",
      "Batch 675/700: Discriminator loss = 1.191463828086853, GAN loss = [2.354204, 0.8094231, 0.84377146]\n",
      "Batch 676/700: Discriminator loss = 1.223078727722168, GAN loss = [2.3301466, 0.77723193, 0.85192984]\n",
      "Batch 677/700: Discriminator loss = 1.209105372428894, GAN loss = [2.4108777, 0.7918927, 0.9180232]\n",
      "Batch 678/700: Discriminator loss = 1.1966649293899536, GAN loss = [2.4352982, 0.80646026, 0.92788935]\n",
      "Batch 679/700: Discriminator loss = 1.2233119010925293, GAN loss = [2.3117108, 0.7963033, 0.8144673]\n",
      "Batch 680/700: Discriminator loss = 1.2251859903335571, GAN loss = [2.3494203, 0.79806, 0.8504426]\n",
      "Batch 681/700: Discriminator loss = 1.2041373252868652, GAN loss = [2.3650913, 0.81036407, 0.85382265]\n",
      "Batch 682/700: Discriminator loss = 1.2058357000350952, GAN loss = [2.390931, 0.8159008, 0.87413347]\n",
      "Batch 683/700: Discriminator loss = 1.2162894010543823, GAN loss = [2.4158688, 0.81252784, 0.9024557]\n",
      "Batch 684/700: Discriminator loss = 1.174615502357483, GAN loss = [2.4292762, 0.86195964, 0.8664295]\n",
      "Batch 685/700: Discriminator loss = 1.1879324913024902, GAN loss = [2.4158137, 0.8368283, 0.8781086]\n",
      "Batch 686/700: Discriminator loss = 1.2121490240097046, GAN loss = [2.364282, 0.79705596, 0.8663583]\n",
      "Batch 687/700: Discriminator loss = 1.208003044128418, GAN loss = [2.3957276, 0.81046605, 0.88439155]\n",
      "Batch 688/700: Discriminator loss = 1.2175488471984863, GAN loss = [2.395814, 0.83375955, 0.8611818]\n",
      "Batch 689/700: Discriminator loss = 1.204124093055725, GAN loss = [2.4029152, 0.8292083, 0.8728479]\n",
      "Batch 690/700: Discriminator loss = 1.178128957748413, GAN loss = [2.4040446, 0.83849996, 0.8646846]\n",
      "Batch 691/700: Discriminator loss = 1.1877866983413696, GAN loss = [2.3796422, 0.83388907, 0.84488326]\n",
      "Batch 692/700: Discriminator loss = 1.1936589479446411, GAN loss = [2.3657649, 0.83092576, 0.8339648]\n",
      "Batch 693/700: Discriminator loss = 1.1894177198410034, GAN loss = [2.345706, 0.80625373, 0.83857155]\n",
      "Batch 694/700: Discriminator loss = 1.2083711624145508, GAN loss = [2.3935113, 0.8076744, 0.8849639]\n",
      "Batch 695/700: Discriminator loss = 1.2126543521881104, GAN loss = [2.3722196, 0.79845583, 0.8729043]\n",
      "Batch 696/700: Discriminator loss = 1.2006503343582153, GAN loss = [2.3978703, 0.8092921, 0.88773626]\n",
      "Batch 697/700: Discriminator loss = 1.20944344997406, GAN loss = [2.3674214, 0.7889939, 0.87761253]\n",
      "Batch 698/700: Discriminator loss = 1.184216856956482, GAN loss = [2.4218113, 0.81639445, 0.9046287]\n",
      "Batch 699/700: Discriminator loss = 1.1838977336883545, GAN loss = [2.428664, 0.8212702, 0.9066195]\n",
      "Batch 700/700: Discriminator loss = 1.2200548648834229, GAN loss = [2.3473349, 0.78225595, 0.86431664]\n",
      "Epoch 17/30\n",
      "Batch 1/700: Discriminator loss = 1.2269654273986816, GAN loss = [2.3280215, 0.770119, 0.8571503]\n",
      "Batch 2/700: Discriminator loss = 1.2336468696594238, GAN loss = [2.307626, 0.7798423, 0.8270449]\n",
      "Batch 3/700: Discriminator loss = 1.202933430671692, GAN loss = [2.402749, 0.8027488, 0.89928114]\n",
      "Batch 4/700: Discriminator loss = 1.206555724143982, GAN loss = [2.3361635, 0.789463, 0.84601164]\n",
      "Batch 5/700: Discriminator loss = 1.2083827257156372, GAN loss = [2.3751729, 0.8022742, 0.8722371]\n",
      "Batch 6/700: Discriminator loss = 1.223628282546997, GAN loss = [2.3365598, 0.8106474, 0.8252833]\n",
      "Batch 7/700: Discriminator loss = 1.2302494049072266, GAN loss = [2.3264213, 0.76864153, 0.85718787]\n",
      "Batch 8/700: Discriminator loss = 1.220223307609558, GAN loss = [2.3604667, 0.7791349, 0.8807798]\n",
      "Batch 9/700: Discriminator loss = 1.2339061498641968, GAN loss = [2.2995074, 0.7807307, 0.8182664]\n",
      "Batch 10/700: Discriminator loss = 1.1987429857254028, GAN loss = [2.3180277, 0.7887266, 0.82883126]\n",
      "Batch 11/700: Discriminator loss = 1.2467671632766724, GAN loss = [2.2651138, 0.74837387, 0.816304]\n",
      "Batch 12/700: Discriminator loss = 1.233625054359436, GAN loss = [2.3135037, 0.7737072, 0.83940434]\n",
      "Batch 13/700: Discriminator loss = 1.2243629693984985, GAN loss = [2.3783376, 0.798382, 0.87959075]\n",
      "Batch 14/700: Discriminator loss = 1.2587733268737793, GAN loss = [2.315232, 0.7570172, 0.85788184]\n",
      "Batch 15/700: Discriminator loss = 1.253872275352478, GAN loss = [2.2480786, 0.7675268, 0.78024864]\n",
      "Batch 16/700: Discriminator loss = 1.2457737922668457, GAN loss = [2.317287, 0.766822, 0.8501928]\n",
      "Batch 17/700: Discriminator loss = 1.2449713945388794, GAN loss = [2.2909055, 0.7706816, 0.81996846]\n",
      "Batch 18/700: Discriminator loss = 1.256771445274353, GAN loss = [2.2692888, 0.75340354, 0.8156491]\n",
      "Batch 19/700: Discriminator loss = 1.2309112548828125, GAN loss = [2.2655292, 0.7708359, 0.7944858]\n",
      "Batch 20/700: Discriminator loss = 1.2627590894699097, GAN loss = [2.3007615, 0.76965845, 0.830919]\n",
      "Batch 21/700: Discriminator loss = 1.2152146100997925, GAN loss = [2.311193, 0.78675973, 0.8242807]\n",
      "Batch 22/700: Discriminator loss = 1.2172170877456665, GAN loss = [2.2475903, 0.79362655, 0.7538409]\n",
      "Batch 23/700: Discriminator loss = 1.213241457939148, GAN loss = [2.3064964, 0.79032004, 0.81608635]\n",
      "Batch 24/700: Discriminator loss = 1.2020946741104126, GAN loss = [2.2775288, 0.7926739, 0.7848012]\n",
      "Batch 25/700: Discriminator loss = 1.2394684553146362, GAN loss = [2.2307093, 0.7842552, 0.7464171]\n",
      "Batch 26/700: Discriminator loss = 1.2354793548583984, GAN loss = [2.278354, 0.7746656, 0.80367297]\n",
      "Batch 27/700: Discriminator loss = 1.2458229064941406, GAN loss = [2.2533245, 0.77116853, 0.782155]\n",
      "Batch 28/700: Discriminator loss = 1.2035677433013916, GAN loss = [2.3080661, 0.80281085, 0.8052692]\n",
      "Batch 29/700: Discriminator loss = 1.241697907447815, GAN loss = [2.2566285, 0.7501734, 0.8064788]\n",
      "Batch 30/700: Discriminator loss = 1.2435405254364014, GAN loss = [2.262867, 0.7664073, 0.79649705]\n",
      "Batch 31/700: Discriminator loss = 1.2035038471221924, GAN loss = [2.3495872, 0.8070924, 0.8425637]\n",
      "Batch 32/700: Discriminator loss = 1.2096233367919922, GAN loss = [2.2790349, 0.7795356, 0.7995967]\n",
      "Batch 33/700: Discriminator loss = 1.213746190071106, GAN loss = [2.3099058, 0.76800084, 0.84204024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 34/700: Discriminator loss = 1.2259474992752075, GAN loss = [2.2790906, 0.76711494, 0.81214786]\n",
      "Batch 35/700: Discriminator loss = 1.1847172975540161, GAN loss = [2.3714178, 0.8197649, 0.8518665]\n",
      "Batch 36/700: Discriminator loss = 1.224729061126709, GAN loss = [2.3138149, 0.7681887, 0.845868]\n",
      "Batch 37/700: Discriminator loss = 1.235116958618164, GAN loss = [2.2425508, 0.73398477, 0.80884004]\n",
      "Batch 38/700: Discriminator loss = 1.2283064126968384, GAN loss = [2.3155816, 0.7641594, 0.8517235]\n",
      "Batch 39/700: Discriminator loss = 1.2188326120376587, GAN loss = [2.292404, 0.75724584, 0.8354906]\n",
      "Batch 40/700: Discriminator loss = 1.23623788356781, GAN loss = [2.250131, 0.7538511, 0.796641]\n",
      "Batch 41/700: Discriminator loss = 1.2500056028366089, GAN loss = [2.2725399, 0.7383969, 0.83454263]\n",
      "Batch 42/700: Discriminator loss = 1.2340401411056519, GAN loss = [2.262855, 0.75858635, 0.8046954]\n",
      "Batch 43/700: Discriminator loss = 1.2114442586898804, GAN loss = [2.2825232, 0.77091515, 0.81207275]\n",
      "Batch 44/700: Discriminator loss = 1.227342963218689, GAN loss = [2.274848, 0.7576908, 0.81766176]\n",
      "Batch 45/700: Discriminator loss = 1.2299940586090088, GAN loss = [2.2542744, 0.7475409, 0.80727464]\n",
      "Batch 46/700: Discriminator loss = 1.22441565990448, GAN loss = [2.303768, 0.75610125, 0.84823155]\n",
      "Batch 47/700: Discriminator loss = 1.2221136093139648, GAN loss = [2.331899, 0.7590997, 0.87340045]\n",
      "Batch 48/700: Discriminator loss = 1.2164405584335327, GAN loss = [2.2905097, 0.7671038, 0.8240349]\n",
      "Batch 49/700: Discriminator loss = 1.2018566131591797, GAN loss = [2.325193, 0.7864394, 0.8394042]\n",
      "Batch 50/700: Discriminator loss = 1.2071952819824219, GAN loss = [2.2974057, 0.76900405, 0.82908803]\n",
      "Batch 51/700: Discriminator loss = 1.232082724571228, GAN loss = [2.2403984, 0.7418254, 0.79928946]\n",
      "Batch 52/700: Discriminator loss = 1.2027761936187744, GAN loss = [2.3482697, 0.79054016, 0.8584684]\n",
      "Batch 53/700: Discriminator loss = 1.227686882019043, GAN loss = [2.2435932, 0.74039, 0.80395865]\n",
      "Batch 54/700: Discriminator loss = 1.2690726518630981, GAN loss = [2.2025387, 0.71830124, 0.7850121]\n",
      "Batch 55/700: Discriminator loss = 1.247288703918457, GAN loss = [2.3277624, 0.7462812, 0.8822789]\n",
      "Batch 56/700: Discriminator loss = 1.2271727323532104, GAN loss = [2.274288, 0.7533637, 0.82174677]\n",
      "Batch 57/700: Discriminator loss = 1.208731770515442, GAN loss = [2.290607, 0.7925551, 0.7989039]\n",
      "Batch 58/700: Discriminator loss = 1.2452847957611084, GAN loss = [2.2763848, 0.7464618, 0.8308017]\n",
      "Batch 59/700: Discriminator loss = 1.2252299785614014, GAN loss = [2.2943077, 0.766906, 0.8283141]\n",
      "Batch 60/700: Discriminator loss = 1.2287013530731201, GAN loss = [2.320542, 0.7671226, 0.8543647]\n",
      "Batch 61/700: Discriminator loss = 1.2373723983764648, GAN loss = [2.2991517, 0.74946165, 0.8506688]\n",
      "Batch 62/700: Discriminator loss = 1.2134166955947876, GAN loss = [2.3089898, 0.794923, 0.8150776]\n",
      "Batch 63/700: Discriminator loss = 1.244004487991333, GAN loss = [2.2892168, 0.7758955, 0.81436294]\n",
      "Batch 64/700: Discriminator loss = 1.241375207901001, GAN loss = [2.2655451, 0.7536705, 0.81293905]\n",
      "Batch 65/700: Discriminator loss = 1.2202845811843872, GAN loss = [2.2996607, 0.7788421, 0.8219034]\n",
      "Batch 66/700: Discriminator loss = 1.2428098917007446, GAN loss = [2.2680655, 0.7527934, 0.8163796]\n",
      "Batch 67/700: Discriminator loss = 1.2317979335784912, GAN loss = [2.2828805, 0.7675743, 0.8164415]\n",
      "Batch 68/700: Discriminator loss = 1.2039211988449097, GAN loss = [2.3240871, 0.794223, 0.8310326]\n",
      "Batch 69/700: Discriminator loss = 1.240985631942749, GAN loss = [2.2900012, 0.7683071, 0.82288885]\n",
      "Batch 70/700: Discriminator loss = 1.2590545415878296, GAN loss = [2.271529, 0.7715121, 0.8012394]\n",
      "Batch 71/700: Discriminator loss = 1.2464991807937622, GAN loss = [2.2381506, 0.7623026, 0.77708834]\n",
      "Batch 72/700: Discriminator loss = 1.238387107849121, GAN loss = [2.2643783, 0.7595973, 0.80602896]\n",
      "Batch 73/700: Discriminator loss = 1.290307641029358, GAN loss = [2.2155912, 0.7353057, 0.7815509]\n",
      "Batch 74/700: Discriminator loss = 1.259151816368103, GAN loss = [2.2448428, 0.7534409, 0.7926799]\n",
      "Batch 75/700: Discriminator loss = 1.2709321975708008, GAN loss = [2.2349296, 0.7468931, 0.78933454]\n",
      "Batch 76/700: Discriminator loss = 1.269138216972351, GAN loss = [2.2599885, 0.7512836, 0.81002295]\n",
      "Batch 77/700: Discriminator loss = 1.2360541820526123, GAN loss = [2.2926774, 0.7679939, 0.8260182]\n",
      "Batch 78/700: Discriminator loss = 1.2089382410049438, GAN loss = [2.2889276, 0.7888892, 0.80138206]\n",
      "Batch 79/700: Discriminator loss = 1.2273099422454834, GAN loss = [2.2677038, 0.77150106, 0.79756874]\n",
      "Batch 80/700: Discriminator loss = 1.2442246675491333, GAN loss = [2.2262926, 0.7476652, 0.7799995]\n",
      "Batch 81/700: Discriminator loss = 1.2189273834228516, GAN loss = [2.251587, 0.77606744, 0.776908]\n",
      "Batch 82/700: Discriminator loss = 1.2474398612976074, GAN loss = [2.2680612, 0.7746414, 0.79482985]\n",
      "Batch 83/700: Discriminator loss = 1.1885895729064941, GAN loss = [2.3566015, 0.8129992, 0.8450266]\n",
      "Batch 84/700: Discriminator loss = 1.2203006744384766, GAN loss = [2.2873476, 0.75933504, 0.82946414]\n",
      "Batch 85/700: Discriminator loss = 1.2024885416030884, GAN loss = [2.2685547, 0.79064566, 0.77938825]\n",
      "Batch 86/700: Discriminator loss = 1.2195734977722168, GAN loss = [2.2428768, 0.76855445, 0.77583146]\n",
      "Batch 87/700: Discriminator loss = 1.2306162118911743, GAN loss = [2.2274287, 0.760477, 0.7684845]\n",
      "Batch 88/700: Discriminator loss = 1.2106691598892212, GAN loss = [2.3058867, 0.7783811, 0.8290725]\n",
      "Batch 89/700: Discriminator loss = 1.2263222932815552, GAN loss = [2.3052273, 0.7889625, 0.81785893]\n",
      "Batch 90/700: Discriminator loss = 1.238176703453064, GAN loss = [2.2543354, 0.75526965, 0.80067337]\n",
      "Batch 91/700: Discriminator loss = 1.2172998189926147, GAN loss = [2.2551053, 0.7834386, 0.7732876]\n",
      "Batch 92/700: Discriminator loss = 1.2141222953796387, GAN loss = [2.2856476, 0.77990633, 0.80738443]\n",
      "Batch 93/700: Discriminator loss = 1.2334545850753784, GAN loss = [2.2762024, 0.76943094, 0.80844545]\n",
      "Batch 94/700: Discriminator loss = 1.2263728380203247, GAN loss = [2.2929635, 0.7656982, 0.82896376]\n",
      "Batch 95/700: Discriminator loss = 1.2259224653244019, GAN loss = [2.294422, 0.762225, 0.8339154]\n",
      "Batch 96/700: Discriminator loss = 1.22822105884552, GAN loss = [2.323492, 0.77029073, 0.8549445]\n",
      "Batch 97/700: Discriminator loss = 1.19587242603302, GAN loss = [2.3189366, 0.7991426, 0.82157034]\n",
      "Batch 98/700: Discriminator loss = 1.209546685218811, GAN loss = [2.3206475, 0.7716936, 0.85075575]\n",
      "Batch 99/700: Discriminator loss = 1.1969833374023438, GAN loss = [2.279436, 0.779234, 0.80202484]\n",
      "Batch 100/700: Discriminator loss = 1.2296233177185059, GAN loss = [2.2697835, 0.77002317, 0.8015983]\n",
      "Batch 101/700: Discriminator loss = 1.2157238721847534, GAN loss = [2.2851753, 0.7769699, 0.810054]\n",
      "Batch 102/700: Discriminator loss = 1.2329670190811157, GAN loss = [2.321574, 0.762083, 0.86135614]\n",
      "Batch 103/700: Discriminator loss = 1.2061705589294434, GAN loss = [2.2736225, 0.7736553, 0.8018524]\n",
      "Batch 104/700: Discriminator loss = 1.2272855043411255, GAN loss = [2.293782, 0.7644146, 0.83128107]\n",
      "Batch 105/700: Discriminator loss = 1.1949301958084106, GAN loss = [2.3455896, 0.7898652, 0.857668]\n",
      "Batch 106/700: Discriminator loss = 1.2010077238082886, GAN loss = [2.2569723, 0.7676323, 0.7913232]\n",
      "Batch 107/700: Discriminator loss = 1.2143162488937378, GAN loss = [2.314782, 0.7672988, 0.84949297]\n",
      "Batch 108/700: Discriminator loss = 1.2301970720291138, GAN loss = [2.2920074, 0.746216, 0.8478276]\n",
      "Batch 109/700: Discriminator loss = 1.2166202068328857, GAN loss = [2.2757473, 0.759695, 0.8181028]\n",
      "Batch 110/700: Discriminator loss = 1.2243422269821167, GAN loss = [2.314524, 0.75709015, 0.8594911]\n",
      "Batch 111/700: Discriminator loss = 1.2418792247772217, GAN loss = [2.2977393, 0.74377114, 0.85603774]\n",
      "Batch 112/700: Discriminator loss = 1.2535663843154907, GAN loss = [2.2421618, 0.73970413, 0.8045356]\n",
      "Batch 113/700: Discriminator loss = 1.1968133449554443, GAN loss = [2.279221, 0.7654068, 0.8158998]\n",
      "Batch 114/700: Discriminator loss = 1.2273147106170654, GAN loss = [2.2617652, 0.7409302, 0.8229256]\n",
      "Batch 115/700: Discriminator loss = 1.2386540174484253, GAN loss = [2.2824183, 0.7385031, 0.84600586]\n",
      "Batch 116/700: Discriminator loss = 1.265494704246521, GAN loss = [2.1819417, 0.72715616, 0.7568787]\n",
      "Batch 117/700: Discriminator loss = 1.2529250383377075, GAN loss = [2.239016, 0.7295606, 0.8115681]\n",
      "Batch 118/700: Discriminator loss = 1.230233907699585, GAN loss = [2.2597754, 0.7562058, 0.8056976]\n",
      "Batch 119/700: Discriminator loss = 1.2348681688308716, GAN loss = [2.234328, 0.74981844, 0.78665113]\n",
      "Batch 120/700: Discriminator loss = 1.2413517236709595, GAN loss = [2.2350576, 0.74369234, 0.79352236]\n",
      "Batch 121/700: Discriminator loss = 1.2216190099716187, GAN loss = [2.2832694, 0.76784736, 0.81759936]\n",
      "Batch 122/700: Discriminator loss = 1.2291370630264282, GAN loss = [2.2400854, 0.76667947, 0.77560514]\n",
      "Batch 123/700: Discriminator loss = 1.2067961692810059, GAN loss = [2.301744, 0.7772231, 0.8267357]\n",
      "Batch 124/700: Discriminator loss = 1.2274160385131836, GAN loss = [2.2744985, 0.7598901, 0.8168446]\n",
      "Batch 125/700: Discriminator loss = 1.2286320924758911, GAN loss = [2.2583141, 0.7487552, 0.81180954]\n",
      "Batch 126/700: Discriminator loss = 1.2223554849624634, GAN loss = [2.2465606, 0.7534112, 0.7954145]\n",
      "Batch 127/700: Discriminator loss = 1.215482234954834, GAN loss = [2.3220248, 0.7728006, 0.85150045]\n",
      "Batch 128/700: Discriminator loss = 1.21321702003479, GAN loss = [2.2820215, 0.78365725, 0.8006479]\n",
      "Batch 129/700: Discriminator loss = 1.2220573425292969, GAN loss = [2.2727246, 0.76764125, 0.80737305]\n",
      "Batch 130/700: Discriminator loss = 1.2339681386947632, GAN loss = [2.2534363, 0.75007975, 0.8056476]\n",
      "Batch 131/700: Discriminator loss = 1.2296333312988281, GAN loss = [2.296545, 0.776343, 0.82249594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 132/700: Discriminator loss = 1.238539218902588, GAN loss = [2.2642176, 0.749408, 0.81711006]\n",
      "Batch 133/700: Discriminator loss = 1.240937352180481, GAN loss = [2.2450948, 0.7465577, 0.8008447]\n",
      "Batch 134/700: Discriminator loss = 1.2310892343521118, GAN loss = [2.273191, 0.7725613, 0.80295175]\n",
      "Batch 135/700: Discriminator loss = 1.2388169765472412, GAN loss = [2.2548673, 0.74921876, 0.8079926]\n",
      "Batch 136/700: Discriminator loss = 1.2573778629302979, GAN loss = [2.266402, 0.76251495, 0.806241]\n",
      "Batch 137/700: Discriminator loss = 1.2435057163238525, GAN loss = [2.256634, 0.74546564, 0.81354743]\n",
      "Batch 138/700: Discriminator loss = 1.2538292407989502, GAN loss = [2.2490451, 0.7421839, 0.80927676]\n",
      "Batch 139/700: Discriminator loss = 1.2647675275802612, GAN loss = [2.2439148, 0.7518793, 0.79447275]\n",
      "Batch 140/700: Discriminator loss = 1.239984154701233, GAN loss = [2.2230957, 0.74255556, 0.78298706]\n",
      "Batch 141/700: Discriminator loss = 1.2385209798812866, GAN loss = [2.2962258, 0.7532193, 0.8454649]\n",
      "Batch 142/700: Discriminator loss = 1.2420037984848022, GAN loss = [2.245224, 0.74621034, 0.80149347]\n",
      "Batch 143/700: Discriminator loss = 1.2458062171936035, GAN loss = [2.2479153, 0.74506384, 0.80534834]\n",
      "Batch 144/700: Discriminator loss = 1.2289613485336304, GAN loss = [2.2869427, 0.7400169, 0.8494208]\n",
      "Batch 145/700: Discriminator loss = 1.2453631162643433, GAN loss = [2.2289128, 0.7471544, 0.7842537]\n",
      "Batch 146/700: Discriminator loss = 1.2289741039276123, GAN loss = [2.2487195, 0.7704111, 0.78081465]\n",
      "Batch 147/700: Discriminator loss = 1.2691993713378906, GAN loss = [2.2419243, 0.73778373, 0.8066551]\n",
      "Batch 148/700: Discriminator loss = 1.2444273233413696, GAN loss = [2.2197068, 0.7337037, 0.78851026]\n",
      "Batch 149/700: Discriminator loss = 1.245680809020996, GAN loss = [2.3105202, 0.74867815, 0.86432976]\n",
      "Batch 150/700: Discriminator loss = 1.2175673246383667, GAN loss = [2.2543793, 0.75216675, 0.80467796]\n",
      "Batch 151/700: Discriminator loss = 1.2254828214645386, GAN loss = [2.2678459, 0.7484041, 0.8219103]\n",
      "Batch 152/700: Discriminator loss = 1.220036506652832, GAN loss = [2.2798293, 0.74819493, 0.8341193]\n",
      "Batch 153/700: Discriminator loss = 1.2529500722885132, GAN loss = [2.2475326, 0.73787445, 0.8121649]\n",
      "Batch 154/700: Discriminator loss = 1.2645474672317505, GAN loss = [2.2066429, 0.7199164, 0.78925085]\n",
      "Batch 155/700: Discriminator loss = 1.2039384841918945, GAN loss = [2.2791178, 0.7673529, 0.81429774]\n",
      "Batch 156/700: Discriminator loss = 1.2309725284576416, GAN loss = [2.2714858, 0.74617434, 0.82784456]\n",
      "Batch 157/700: Discriminator loss = 1.2177385091781616, GAN loss = [2.2529078, 0.766868, 0.78857946]\n",
      "Batch 158/700: Discriminator loss = 1.2370306253433228, GAN loss = [2.2161891, 0.73991007, 0.7788141]\n",
      "Batch 159/700: Discriminator loss = 1.25644052028656, GAN loss = [2.2686703, 0.73094773, 0.84024256]\n",
      "Batch 160/700: Discriminator loss = 1.2559013366699219, GAN loss = [2.2441182, 0.7246559, 0.8219868]\n",
      "Batch 161/700: Discriminator loss = 1.2385648488998413, GAN loss = [2.2816057, 0.73411477, 0.85002935]\n",
      "Batch 162/700: Discriminator loss = 1.2625596523284912, GAN loss = [2.2109997, 0.7038385, 0.80970854]\n",
      "Batch 163/700: Discriminator loss = 1.237122654914856, GAN loss = [2.2320576, 0.7376548, 0.7969576]\n",
      "Batch 164/700: Discriminator loss = 1.2334405183792114, GAN loss = [2.2278016, 0.753676, 0.7766835]\n",
      "Batch 165/700: Discriminator loss = 1.2543787956237793, GAN loss = [2.2664986, 0.7496807, 0.8193826]\n",
      "Batch 166/700: Discriminator loss = 1.2587240934371948, GAN loss = [2.3012836, 0.7505487, 0.853303]\n",
      "Batch 167/700: Discriminator loss = 1.2550145387649536, GAN loss = [2.2258828, 0.7299707, 0.79849]\n",
      "Batch 168/700: Discriminator loss = 1.2123054265975952, GAN loss = [2.2649953, 0.7841941, 0.7833802]\n",
      "Batch 169/700: Discriminator loss = 1.213248372077942, GAN loss = [2.2899868, 0.7520847, 0.8404836]\n",
      "Batch 170/700: Discriminator loss = 1.2561728954315186, GAN loss = [2.2374456, 0.7314218, 0.80861837]\n",
      "Batch 171/700: Discriminator loss = 1.2384247779846191, GAN loss = [2.3056586, 0.748979, 0.8592744]\n",
      "Batch 172/700: Discriminator loss = 1.2033113241195679, GAN loss = [2.272721, 0.763697, 0.8116313]\n",
      "Batch 173/700: Discriminator loss = 1.245330810546875, GAN loss = [2.2653518, 0.73242515, 0.835546]\n",
      "Batch 174/700: Discriminator loss = 1.2521758079528809, GAN loss = [2.2305355, 0.7328071, 0.80035734]\n",
      "Batch 175/700: Discriminator loss = 1.222187876701355, GAN loss = [2.273919, 0.7549613, 0.8216063]\n",
      "Batch 176/700: Discriminator loss = 1.2571834325790405, GAN loss = [2.2147477, 0.7069481, 0.81046504]\n",
      "Batch 177/700: Discriminator loss = 1.2317323684692383, GAN loss = [2.2657325, 0.7362558, 0.8321542]\n",
      "Batch 178/700: Discriminator loss = 1.239976167678833, GAN loss = [2.2224922, 0.7379711, 0.78720546]\n",
      "Batch 179/700: Discriminator loss = 1.2275766134262085, GAN loss = [2.2645004, 0.7602667, 0.80691874]\n",
      "Batch 180/700: Discriminator loss = 1.2334120273590088, GAN loss = [2.211478, 0.73622304, 0.77794397]\n",
      "Batch 181/700: Discriminator loss = 1.245762825012207, GAN loss = [2.2438257, 0.73002464, 0.81648225]\n",
      "Batch 182/700: Discriminator loss = 1.2444860935211182, GAN loss = [2.269984, 0.741567, 0.8310872]\n",
      "Batch 183/700: Discriminator loss = 1.2450950145721436, GAN loss = [2.2259915, 0.7263217, 0.8023369]\n",
      "Batch 184/700: Discriminator loss = 1.2375067472457886, GAN loss = [2.243408, 0.7445644, 0.8015207]\n",
      "Batch 185/700: Discriminator loss = 1.2328996658325195, GAN loss = [2.2770476, 0.7503504, 0.82937944]\n",
      "Batch 186/700: Discriminator loss = 1.213537335395813, GAN loss = [2.2216096, 0.7525163, 0.77178675]\n",
      "Batch 187/700: Discriminator loss = 1.182776689529419, GAN loss = [2.2913864, 0.7834418, 0.8106443]\n",
      "Batch 188/700: Discriminator loss = 1.2433629035949707, GAN loss = [2.2550228, 0.7459595, 0.8117711]\n",
      "Batch 189/700: Discriminator loss = 1.2492514848709106, GAN loss = [2.2473624, 0.74613744, 0.8039294]\n",
      "Batch 190/700: Discriminator loss = 1.2297550439834595, GAN loss = [2.2421803, 0.73761475, 0.80725753]\n",
      "Batch 191/700: Discriminator loss = 1.2162983417510986, GAN loss = [2.2615442, 0.7656963, 0.79853827]\n",
      "Batch 192/700: Discriminator loss = 1.2362935543060303, GAN loss = [2.2554772, 0.7365263, 0.82163]\n",
      "Batch 193/700: Discriminator loss = 1.2266980409622192, GAN loss = [2.2630365, 0.73202163, 0.8336988]\n",
      "Batch 194/700: Discriminator loss = 1.2281872034072876, GAN loss = [2.225076, 0.73800015, 0.78977394]\n",
      "Batch 195/700: Discriminator loss = 1.2409251928329468, GAN loss = [2.2507231, 0.7494679, 0.80396783]\n",
      "Batch 196/700: Discriminator loss = 1.2064502239227295, GAN loss = [2.3066204, 0.76255304, 0.84680426]\n",
      "Batch 197/700: Discriminator loss = 1.2426282167434692, GAN loss = [2.2730794, 0.74018687, 0.83563805]\n",
      "Batch 198/700: Discriminator loss = 1.2271674871444702, GAN loss = [2.2603288, 0.7361417, 0.8269316]\n",
      "Batch 199/700: Discriminator loss = 1.2247333526611328, GAN loss = [2.245559, 0.7368098, 0.8114896]\n",
      "Batch 200/700: Discriminator loss = 1.236101508140564, GAN loss = [2.2829092, 0.7352275, 0.8504088]\n",
      "Batch 201/700: Discriminator loss = 1.244511604309082, GAN loss = [2.2856863, 0.7324197, 0.8559881]\n",
      "Batch 202/700: Discriminator loss = 1.1926805973052979, GAN loss = [2.2737312, 0.7672688, 0.80920595]\n",
      "Batch 203/700: Discriminator loss = 1.212812900543213, GAN loss = [2.3058813, 0.7692768, 0.8393858]\n",
      "Batch 204/700: Discriminator loss = 1.2352690696716309, GAN loss = [2.2376328, 0.7327304, 0.80771685]\n",
      "Batch 205/700: Discriminator loss = 1.2086256742477417, GAN loss = [2.266164, 0.7522967, 0.8166953]\n",
      "Batch 206/700: Discriminator loss = 1.2118734121322632, GAN loss = [2.2891166, 0.7682296, 0.8237185]\n",
      "Batch 207/700: Discriminator loss = 1.2353591918945312, GAN loss = [2.2391863, 0.7388748, 0.80315226]\n",
      "Batch 208/700: Discriminator loss = 1.250016689300537, GAN loss = [2.2381942, 0.72208154, 0.8189743]\n",
      "Batch 209/700: Discriminator loss = 1.2221063375473022, GAN loss = [2.2235134, 0.74390143, 0.7824837]\n",
      "Batch 210/700: Discriminator loss = 1.2268755435943604, GAN loss = [2.2557662, 0.74453956, 0.8141101]\n",
      "Batch 211/700: Discriminator loss = 1.2330650091171265, GAN loss = [2.2331555, 0.72203124, 0.81402075]\n",
      "Batch 212/700: Discriminator loss = 1.2401410341262817, GAN loss = [2.3337557, 0.7495977, 0.8870558]\n",
      "Batch 213/700: Discriminator loss = 1.2339324951171875, GAN loss = [2.2148902, 0.7291662, 0.7886259]\n",
      "Batch 214/700: Discriminator loss = 1.2151432037353516, GAN loss = [2.2567973, 0.746702, 0.81300414]\n",
      "Batch 215/700: Discriminator loss = 1.224603295326233, GAN loss = [2.2993927, 0.75599724, 0.84630346]\n",
      "Batch 216/700: Discriminator loss = 1.244219422340393, GAN loss = [2.2618062, 0.7472651, 0.8174634]\n",
      "Batch 217/700: Discriminator loss = 1.2234512567520142, GAN loss = [2.26522, 0.7511548, 0.81700206]\n",
      "Batch 218/700: Discriminator loss = 1.2472697496414185, GAN loss = [2.2337246, 0.71409196, 0.8225667]\n",
      "Batch 219/700: Discriminator loss = 1.20967698097229, GAN loss = [2.2754648, 0.7421208, 0.83628184]\n",
      "Batch 220/700: Discriminator loss = 1.2243314981460571, GAN loss = [2.2626164, 0.75709134, 0.808479]\n",
      "Batch 221/700: Discriminator loss = 1.2313613891601562, GAN loss = [2.2548935, 0.7469448, 0.81092817]\n",
      "Batch 222/700: Discriminator loss = 1.212233543395996, GAN loss = [2.2490897, 0.7437324, 0.8083664]\n",
      "Batch 223/700: Discriminator loss = 1.232030987739563, GAN loss = [2.2491019, 0.73975974, 0.8123619]\n",
      "Batch 224/700: Discriminator loss = 1.2054957151412964, GAN loss = [2.2744849, 0.7544351, 0.82307905]\n",
      "Batch 225/700: Discriminator loss = 1.2286653518676758, GAN loss = [2.2383559, 0.73451704, 0.8068785]\n",
      "Batch 226/700: Discriminator loss = 1.2379529476165771, GAN loss = [2.2412307, 0.7237942, 0.82049894]\n",
      "Batch 227/700: Discriminator loss = 1.2084146738052368, GAN loss = [2.2332168, 0.74897593, 0.78731406]\n",
      "Batch 228/700: Discriminator loss = 1.2312718629837036, GAN loss = [2.262075, 0.7292619, 0.8359083]\n",
      "Batch 229/700: Discriminator loss = 1.2225898504257202, GAN loss = [2.2241979, 0.7468768, 0.7804171]\n",
      "Batch 230/700: Discriminator loss = 1.2156962156295776, GAN loss = [2.2678454, 0.7416553, 0.8292994]\n",
      "Batch 231/700: Discriminator loss = 1.2310296297073364, GAN loss = [2.2293594, 0.74029624, 0.79219663]\n",
      "Batch 232/700: Discriminator loss = 1.2449105978012085, GAN loss = [2.2723875, 0.7359394, 0.8396122]\n",
      "Batch 233/700: Discriminator loss = 1.2334245443344116, GAN loss = [2.256266, 0.74435705, 0.8150983]\n",
      "Batch 234/700: Discriminator loss = 1.2342814207077026, GAN loss = [2.2643774, 0.7531194, 0.814478]\n",
      "Batch 235/700: Discriminator loss = 1.2397292852401733, GAN loss = [2.257554, 0.74421906, 0.81658256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 236/700: Discriminator loss = 1.241010069847107, GAN loss = [2.232663, 0.7313661, 0.8045739]\n",
      "Batch 237/700: Discriminator loss = 1.2234865427017212, GAN loss = [2.2519696, 0.7492929, 0.8059824]\n",
      "Batch 238/700: Discriminator loss = 1.2710490226745605, GAN loss = [2.2181873, 0.71567225, 0.80585754]\n",
      "Batch 239/700: Discriminator loss = 1.2470542192459106, GAN loss = [2.2218258, 0.7308079, 0.7943875]\n",
      "Batch 240/700: Discriminator loss = 1.2297272682189941, GAN loss = [2.241889, 0.7553096, 0.78997916]\n",
      "Batch 241/700: Discriminator loss = 1.2539401054382324, GAN loss = [2.2661822, 0.7381122, 0.8315002]\n",
      "Batch 242/700: Discriminator loss = 1.2662248611450195, GAN loss = [2.1923807, 0.73259, 0.76324487]\n",
      "Batch 243/700: Discriminator loss = 1.2287195920944214, GAN loss = [2.2262053, 0.7403476, 0.7893297]\n",
      "Batch 244/700: Discriminator loss = 1.2220063209533691, GAN loss = [2.2184486, 0.7610174, 0.7609297]\n",
      "Batch 245/700: Discriminator loss = 1.2337726354599, GAN loss = [2.2304134, 0.73829156, 0.79565084]\n",
      "Batch 246/700: Discriminator loss = 1.2246592044830322, GAN loss = [2.2415538, 0.7492784, 0.7958294]\n",
      "Batch 247/700: Discriminator loss = 1.2670165300369263, GAN loss = [2.1795127, 0.7189805, 0.7641151]\n",
      "Batch 248/700: Discriminator loss = 1.2309671640396118, GAN loss = [2.2481632, 0.7478554, 0.8039235]\n",
      "Batch 249/700: Discriminator loss = 1.2151721715927124, GAN loss = [2.2413526, 0.7664111, 0.77858716]\n",
      "Batch 250/700: Discriminator loss = 1.2453054189682007, GAN loss = [2.219085, 0.7291446, 0.79361856]\n",
      "Batch 251/700: Discriminator loss = 1.2210185527801514, GAN loss = [2.2875228, 0.7613801, 0.8298533]\n",
      "Batch 252/700: Discriminator loss = 1.2271627187728882, GAN loss = [2.2267962, 0.7343121, 0.79621977]\n",
      "Batch 253/700: Discriminator loss = 1.2481390237808228, GAN loss = [2.2315378, 0.7397079, 0.79559326]\n",
      "Batch 254/700: Discriminator loss = 1.2493518590927124, GAN loss = [2.2459502, 0.7366571, 0.81308717]\n",
      "Batch 255/700: Discriminator loss = 1.2231335639953613, GAN loss = [2.2704167, 0.75173587, 0.8224932]\n",
      "Batch 256/700: Discriminator loss = 1.231004238128662, GAN loss = [2.2207189, 0.73208994, 0.7924782]\n",
      "Batch 257/700: Discriminator loss = 1.2287553548812866, GAN loss = [2.2810507, 0.7469529, 0.83796984]\n",
      "Batch 258/700: Discriminator loss = 1.2641050815582275, GAN loss = [2.194087, 0.7202164, 0.77777976]\n",
      "Batch 259/700: Discriminator loss = 1.230765700340271, GAN loss = [2.2732985, 0.7317531, 0.8454778]\n",
      "Batch 260/700: Discriminator loss = 1.2399976253509521, GAN loss = [2.2856123, 0.728181, 0.86139226]\n",
      "Batch 261/700: Discriminator loss = 1.2439439296722412, GAN loss = [2.2039149, 0.7214743, 0.7864276]\n",
      "Batch 262/700: Discriminator loss = 1.228391408920288, GAN loss = [2.2705884, 0.74808633, 0.8265059]\n",
      "Batch 263/700: Discriminator loss = 1.2547520399093628, GAN loss = [2.1993003, 0.71677375, 0.7865486]\n",
      "Batch 264/700: Discriminator loss = 1.2067972421646118, GAN loss = [2.2458658, 0.75065523, 0.79924333]\n",
      "Batch 265/700: Discriminator loss = 1.2284212112426758, GAN loss = [2.2757092, 0.74451995, 0.8352524]\n",
      "Batch 266/700: Discriminator loss = 1.2628707885742188, GAN loss = [2.223741, 0.6996523, 0.8281794]\n",
      "Batch 267/700: Discriminator loss = 1.2239912748336792, GAN loss = [2.257758, 0.7296049, 0.8322648]\n",
      "Batch 268/700: Discriminator loss = 1.264460802078247, GAN loss = [2.251022, 0.7141115, 0.8410423]\n",
      "Batch 269/700: Discriminator loss = 1.2150453329086304, GAN loss = [2.2642972, 0.7534604, 0.81498533]\n",
      "Batch 270/700: Discriminator loss = 1.217922329902649, GAN loss = [2.2899022, 0.7589917, 0.8350727]\n",
      "Batch 271/700: Discriminator loss = 1.2091583013534546, GAN loss = [2.2883134, 0.76001054, 0.83250153]\n",
      "Batch 272/700: Discriminator loss = 1.2080764770507812, GAN loss = [2.3062866, 0.75910133, 0.85140806]\n",
      "Batch 273/700: Discriminator loss = 1.235721230506897, GAN loss = [2.2568786, 0.7252328, 0.8359077]\n",
      "Batch 274/700: Discriminator loss = 1.2339578866958618, GAN loss = [2.2787347, 0.73065424, 0.8523724]\n",
      "Batch 275/700: Discriminator loss = 1.2069038152694702, GAN loss = [2.3008745, 0.7448308, 0.8603659]\n",
      "Batch 276/700: Discriminator loss = 1.2233312129974365, GAN loss = [2.2577946, 0.742737, 0.8193997]\n",
      "Batch 277/700: Discriminator loss = 1.2298043966293335, GAN loss = [2.252307, 0.74149245, 0.8151791]\n",
      "Batch 278/700: Discriminator loss = 1.2046737670898438, GAN loss = [2.2886233, 0.7609134, 0.83209884]\n",
      "Batch 279/700: Discriminator loss = 1.210647702217102, GAN loss = [2.3214064, 0.75889283, 0.8669191]\n",
      "Batch 280/700: Discriminator loss = 1.2050080299377441, GAN loss = [2.2783074, 0.76458025, 0.81814474]\n",
      "Batch 281/700: Discriminator loss = 1.2323912382125854, GAN loss = [2.2674878, 0.74924517, 0.8226719]\n",
      "Batch 282/700: Discriminator loss = 1.2058708667755127, GAN loss = [2.2979982, 0.7692359, 0.83320206]\n",
      "Batch 283/700: Discriminator loss = 1.2223163843154907, GAN loss = [2.3149657, 0.76164293, 0.8577881]\n",
      "Batch 284/700: Discriminator loss = 1.2188094854354858, GAN loss = [2.2598944, 0.7538135, 0.81056565]\n",
      "Batch 285/700: Discriminator loss = 1.2013871669769287, GAN loss = [2.306528, 0.7765735, 0.834467]\n",
      "Batch 286/700: Discriminator loss = 1.21137273311615, GAN loss = [2.2772577, 0.7691414, 0.81265837]\n",
      "Batch 287/700: Discriminator loss = 1.1982336044311523, GAN loss = [2.2809699, 0.77328295, 0.812264]\n",
      "Batch 288/700: Discriminator loss = 1.2285536527633667, GAN loss = [2.268435, 0.7618927, 0.81115127]\n",
      "Batch 289/700: Discriminator loss = 1.2030678987503052, GAN loss = [2.296734, 0.772841, 0.82851607]\n",
      "Batch 290/700: Discriminator loss = 1.2209064960479736, GAN loss = [2.2691886, 0.7710438, 0.8027964]\n",
      "Batch 291/700: Discriminator loss = 1.2317761182785034, GAN loss = [2.2876701, 0.7602877, 0.8320533]\n",
      "Batch 292/700: Discriminator loss = 1.207010269165039, GAN loss = [2.3343582, 0.78140825, 0.85764426]\n",
      "Batch 293/700: Discriminator loss = 1.2078038454055786, GAN loss = [2.3207624, 0.78830767, 0.83715767]\n",
      "Batch 294/700: Discriminator loss = 1.1942863464355469, GAN loss = [2.2882152, 0.77279943, 0.8201321]\n",
      "Batch 295/700: Discriminator loss = 1.2413865327835083, GAN loss = [2.2901433, 0.7477807, 0.8470969]\n",
      "Batch 296/700: Discriminator loss = 1.2124686241149902, GAN loss = [2.2914615, 0.77522904, 0.8209761]\n",
      "Batch 297/700: Discriminator loss = 1.2170413732528687, GAN loss = [2.262918, 0.7721298, 0.7955345]\n",
      "Batch 298/700: Discriminator loss = 1.2359561920166016, GAN loss = [2.263468, 0.7522316, 0.81597465]\n",
      "Batch 299/700: Discriminator loss = 1.195336103439331, GAN loss = [2.4189622, 0.81406206, 0.90964526]\n",
      "Batch 300/700: Discriminator loss = 1.2503291368484497, GAN loss = [2.3108835, 0.74620295, 0.8694437]\n",
      "Batch 301/700: Discriminator loss = 1.2378733158111572, GAN loss = [2.31608, 0.76699644, 0.8538601]\n",
      "Batch 302/700: Discriminator loss = 1.2381367683410645, GAN loss = [2.367626, 0.78610986, 0.88630587]\n",
      "Batch 303/700: Discriminator loss = 1.2049890756607056, GAN loss = [2.3274372, 0.78435105, 0.8478873]\n",
      "Batch 304/700: Discriminator loss = 1.236072301864624, GAN loss = [2.2871716, 0.7604883, 0.8314824]\n",
      "Batch 305/700: Discriminator loss = 1.2277055978775024, GAN loss = [2.2929463, 0.75864005, 0.8391129]\n",
      "Batch 306/700: Discriminator loss = 1.2278071641921997, GAN loss = [2.3766556, 0.7800331, 0.9014376]\n",
      "Batch 307/700: Discriminator loss = 1.2325514554977417, GAN loss = [2.2904153, 0.7551871, 0.84006345]\n",
      "Batch 308/700: Discriminator loss = 1.218021035194397, GAN loss = [2.3091853, 0.77526075, 0.83878386]\n",
      "Batch 309/700: Discriminator loss = 1.2689354419708252, GAN loss = [2.3037438, 0.75048727, 0.85813886]\n",
      "Batch 310/700: Discriminator loss = 1.2067666053771973, GAN loss = [2.3456032, 0.7990978, 0.8514132]\n",
      "Batch 311/700: Discriminator loss = 1.221318006515503, GAN loss = [2.3160894, 0.77436197, 0.8466665]\n",
      "Batch 312/700: Discriminator loss = 1.2245182991027832, GAN loss = [2.3387022, 0.7815332, 0.86213]\n",
      "Batch 313/700: Discriminator loss = 1.2055693864822388, GAN loss = [2.3047128, 0.78403986, 0.8256466]\n",
      "Batch 314/700: Discriminator loss = 1.227426290512085, GAN loss = [2.293097, 0.7722678, 0.8258194]\n",
      "Batch 315/700: Discriminator loss = 1.2186425924301147, GAN loss = [2.3079126, 0.77600497, 0.83691186]\n",
      "Batch 316/700: Discriminator loss = 1.1918684244155884, GAN loss = [2.3200939, 0.79616565, 0.8289454]\n",
      "Batch 317/700: Discriminator loss = 1.2205549478530884, GAN loss = [2.3342266, 0.788715, 0.8505434]\n",
      "Batch 318/700: Discriminator loss = 1.1628344058990479, GAN loss = [2.3793988, 0.8185217, 0.8659251]\n",
      "Batch 319/700: Discriminator loss = 1.173000693321228, GAN loss = [2.3864112, 0.8055862, 0.88589424]\n",
      "Batch 320/700: Discriminator loss = 1.175199031829834, GAN loss = [2.3999612, 0.80755776, 0.8974988]\n",
      "Batch 321/700: Discriminator loss = 1.1932523250579834, GAN loss = [2.3526103, 0.79842407, 0.85930806]\n",
      "Batch 322/700: Discriminator loss = 1.1535954475402832, GAN loss = [2.4400039, 0.8626965, 0.8824594]\n",
      "Batch 323/700: Discriminator loss = 1.2244840860366821, GAN loss = [2.303026, 0.7582221, 0.849975]\n",
      "Batch 324/700: Discriminator loss = 1.2085514068603516, GAN loss = [2.3929057, 0.78887045, 0.9092396]\n",
      "Batch 325/700: Discriminator loss = 1.197190523147583, GAN loss = [2.3406932, 0.78268903, 0.8632379]\n",
      "Batch 326/700: Discriminator loss = 1.1805453300476074, GAN loss = [2.40248, 0.80190164, 0.90584666]\n",
      "Batch 327/700: Discriminator loss = 1.1785160303115845, GAN loss = [2.3790562, 0.8120201, 0.8723316]\n",
      "Batch 328/700: Discriminator loss = 1.181220293045044, GAN loss = [2.4274383, 0.81726885, 0.915488]\n",
      "Batch 329/700: Discriminator loss = 1.156015157699585, GAN loss = [2.383668, 0.82825017, 0.8607563]\n",
      "Batch 330/700: Discriminator loss = 1.2292110919952393, GAN loss = [2.2859418, 0.75623405, 0.8350746]\n",
      "Batch 331/700: Discriminator loss = 1.2196975946426392, GAN loss = [2.3994613, 0.7685566, 0.93631655]\n",
      "Batch 332/700: Discriminator loss = 1.1982203722000122, GAN loss = [2.3741233, 0.79368967, 0.8858743]\n",
      "Batch 333/700: Discriminator loss = 1.209734320640564, GAN loss = [2.3617926, 0.7919499, 0.87530553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 334/700: Discriminator loss = 1.2177859544754028, GAN loss = [2.3041, 0.76782197, 0.8417669]\n",
      "Batch 335/700: Discriminator loss = 1.1867649555206299, GAN loss = [2.3294692, 0.8128843, 0.82210046]\n",
      "Batch 336/700: Discriminator loss = 1.211580514907837, GAN loss = [2.3095224, 0.78144425, 0.8336122]\n",
      "Batch 337/700: Discriminator loss = 1.196245789527893, GAN loss = [2.313848, 0.78588563, 0.8335136]\n",
      "Batch 338/700: Discriminator loss = 1.2086650133132935, GAN loss = [2.3458416, 0.78911537, 0.8623012]\n",
      "Batch 339/700: Discriminator loss = 1.2033785581588745, GAN loss = [2.345222, 0.7892269, 0.8615894]\n",
      "Batch 340/700: Discriminator loss = 1.226815104484558, GAN loss = [2.2873652, 0.76244986, 0.830529]\n",
      "Batch 341/700: Discriminator loss = 1.1812267303466797, GAN loss = [2.3381362, 0.7976571, 0.84612274]\n",
      "Batch 342/700: Discriminator loss = 1.171676516532898, GAN loss = [2.3242974, 0.8119033, 0.8180716]\n",
      "Batch 343/700: Discriminator loss = 1.2215121984481812, GAN loss = [2.3021786, 0.7712704, 0.83662575]\n",
      "Batch 344/700: Discriminator loss = 1.1907196044921875, GAN loss = [2.3295655, 0.7909546, 0.84436715]\n",
      "Batch 345/700: Discriminator loss = 1.2065377235412598, GAN loss = [2.2997258, 0.7642626, 0.8412637]\n",
      "Batch 346/700: Discriminator loss = 1.2038341760635376, GAN loss = [2.3201306, 0.77672875, 0.84924483]\n",
      "Batch 347/700: Discriminator loss = 1.2153522968292236, GAN loss = [2.3428717, 0.79095113, 0.85779035]\n",
      "Batch 348/700: Discriminator loss = 1.220027208328247, GAN loss = [2.3006177, 0.774435, 0.8320817]\n",
      "Batch 349/700: Discriminator loss = 1.2170538902282715, GAN loss = [2.358481, 0.7730181, 0.8913871]\n",
      "Batch 350/700: Discriminator loss = 1.2295397520065308, GAN loss = [2.2781363, 0.7694201, 0.81467414]\n",
      "Batch 351/700: Discriminator loss = 1.2503560781478882, GAN loss = [2.241057, 0.7427234, 0.8043161]\n",
      "Batch 352/700: Discriminator loss = 1.2363723516464233, GAN loss = [2.2916713, 0.762561, 0.8351157]\n",
      "Batch 353/700: Discriminator loss = 1.2034425735473633, GAN loss = [2.3321254, 0.7966319, 0.8415242]\n",
      "Batch 354/700: Discriminator loss = 1.2110960483551025, GAN loss = [2.2746856, 0.77887285, 0.8018684]\n",
      "Batch 355/700: Discriminator loss = 1.2233179807662964, GAN loss = [2.2731977, 0.7607653, 0.81851095]\n",
      "Batch 356/700: Discriminator loss = 1.2233240604400635, GAN loss = [2.3062568, 0.76333106, 0.84902376]\n",
      "Batch 357/700: Discriminator loss = 1.2124799489974976, GAN loss = [2.2893147, 0.77169806, 0.82375413]\n",
      "Batch 358/700: Discriminator loss = 1.20767343044281, GAN loss = [2.2682104, 0.7693727, 0.80500144]\n",
      "Batch 359/700: Discriminator loss = 1.194676399230957, GAN loss = [2.3013344, 0.77667785, 0.8308473]\n",
      "Batch 360/700: Discriminator loss = 1.2054136991500854, GAN loss = [2.3222375, 0.7894544, 0.8390019]\n",
      "Batch 361/700: Discriminator loss = 1.2030311822891235, GAN loss = [2.2964687, 0.78536135, 0.8173468]\n",
      "Batch 362/700: Discriminator loss = 1.1971238851547241, GAN loss = [2.3229809, 0.7810825, 0.8481578]\n",
      "Batch 363/700: Discriminator loss = 1.1934082508087158, GAN loss = [2.2871938, 0.7747026, 0.8187751]\n",
      "Batch 364/700: Discriminator loss = 1.2311794757843018, GAN loss = [2.2682893, 0.73437726, 0.8402287]\n",
      "Batch 365/700: Discriminator loss = 1.2079403400421143, GAN loss = [2.3103204, 0.764379, 0.85229224]\n",
      "Batch 366/700: Discriminator loss = 1.237661361694336, GAN loss = [2.298011, 0.7445262, 0.8598702]\n",
      "Batch 367/700: Discriminator loss = 1.2361890077590942, GAN loss = [2.2689168, 0.73834366, 0.83699054]\n",
      "Batch 368/700: Discriminator loss = 1.2849280834197998, GAN loss = [2.2162526, 0.70562744, 0.8170817]\n",
      "Batch 369/700: Discriminator loss = 1.230012059211731, GAN loss = [2.2701476, 0.74486375, 0.8317841]\n",
      "Batch 370/700: Discriminator loss = 1.2126445770263672, GAN loss = [2.2468772, 0.7498662, 0.8035453]\n",
      "Batch 371/700: Discriminator loss = 1.2442501783370972, GAN loss = [2.2863545, 0.73368126, 0.8592504]\n",
      "Batch 372/700: Discriminator loss = 1.1979645490646362, GAN loss = [2.2998483, 0.7843827, 0.82207376]\n",
      "Batch 373/700: Discriminator loss = 1.2110975980758667, GAN loss = [2.2708087, 0.77348185, 0.8039601]\n",
      "Batch 374/700: Discriminator loss = 1.254370093345642, GAN loss = [2.2732096, 0.7332717, 0.84659034]\n",
      "Batch 375/700: Discriminator loss = 1.2425763607025146, GAN loss = [2.2333012, 0.7386783, 0.80129725]\n",
      "Batch 376/700: Discriminator loss = 1.247658371925354, GAN loss = [2.2478561, 0.7342947, 0.82024974]\n",
      "Batch 377/700: Discriminator loss = 1.24052894115448, GAN loss = [2.2771564, 0.7375835, 0.8462757]\n",
      "Batch 378/700: Discriminator loss = 1.2164764404296875, GAN loss = [2.2587578, 0.7587559, 0.8067348]\n",
      "Batch 379/700: Discriminator loss = 1.2508119344711304, GAN loss = [2.245236, 0.72572744, 0.8262748]\n",
      "Batch 380/700: Discriminator loss = 1.228411078453064, GAN loss = [2.2796912, 0.75019956, 0.8362904]\n",
      "Batch 381/700: Discriminator loss = 1.230207920074463, GAN loss = [2.2881465, 0.75653005, 0.8384329]\n",
      "Batch 382/700: Discriminator loss = 1.2485624551773071, GAN loss = [2.241161, 0.7330396, 0.8149611]\n",
      "Batch 383/700: Discriminator loss = 1.208105444908142, GAN loss = [2.303099, 0.77081823, 0.8391468]\n",
      "Batch 384/700: Discriminator loss = 1.2119628190994263, GAN loss = [2.2476735, 0.7626811, 0.7918796]\n",
      "Batch 385/700: Discriminator loss = 1.2306137084960938, GAN loss = [2.2700858, 0.7557113, 0.8212885]\n",
      "Batch 386/700: Discriminator loss = 1.2000888586044312, GAN loss = [2.2692482, 0.77832705, 0.7978392]\n",
      "Batch 387/700: Discriminator loss = 1.211885690689087, GAN loss = [2.2658303, 0.78497535, 0.78778166]\n",
      "Batch 388/700: Discriminator loss = 1.1996062994003296, GAN loss = [2.2366307, 0.7665629, 0.7770078]\n",
      "Batch 389/700: Discriminator loss = 1.2063437700271606, GAN loss = [2.2882588, 0.7672476, 0.8279781]\n",
      "Batch 390/700: Discriminator loss = 1.2389984130859375, GAN loss = [2.2447, 0.739276, 0.81241804]\n",
      "Batch 391/700: Discriminator loss = 1.2154088020324707, GAN loss = [2.2953973, 0.76762664, 0.8348018]\n",
      "Batch 392/700: Discriminator loss = 1.2068445682525635, GAN loss = [2.308015, 0.77177435, 0.8433026]\n",
      "Batch 393/700: Discriminator loss = 1.237731695175171, GAN loss = [2.2621071, 0.74161917, 0.82756853]\n",
      "Batch 394/700: Discriminator loss = 1.25043785572052, GAN loss = [2.2408493, 0.73967624, 0.8082741]\n",
      "Batch 395/700: Discriminator loss = 1.229320764541626, GAN loss = [2.2892034, 0.750818, 0.84550834]\n",
      "Batch 396/700: Discriminator loss = 1.2037557363510132, GAN loss = [2.2905478, 0.77151, 0.8261741]\n",
      "Batch 397/700: Discriminator loss = 1.2332179546356201, GAN loss = [2.2835987, 0.75188506, 0.8388791]\n",
      "Batch 398/700: Discriminator loss = 1.218299388885498, GAN loss = [2.297054, 0.75985426, 0.84440213]\n",
      "Batch 399/700: Discriminator loss = 1.2392305135726929, GAN loss = [2.2440577, 0.7476844, 0.80360526]\n",
      "Batch 400/700: Discriminator loss = 1.2173552513122559, GAN loss = [2.2793756, 0.7736957, 0.81293434]\n",
      "Batch 401/700: Discriminator loss = 1.2460007667541504, GAN loss = [2.2063763, 0.739258, 0.7743945]\n",
      "Batch 402/700: Discriminator loss = 1.2427771091461182, GAN loss = [2.2264063, 0.7368401, 0.79687196]\n",
      "Batch 403/700: Discriminator loss = 1.2453030347824097, GAN loss = [2.2324135, 0.7340275, 0.80572397]\n",
      "Batch 404/700: Discriminator loss = 1.2158739566802979, GAN loss = [2.2711434, 0.7471542, 0.8313578]\n",
      "Batch 405/700: Discriminator loss = 1.249567985534668, GAN loss = [2.1853962, 0.73110795, 0.7616678]\n",
      "Batch 406/700: Discriminator loss = 1.2095348834991455, GAN loss = [2.258798, 0.75936395, 0.8068349]\n",
      "Batch 407/700: Discriminator loss = 1.2373934984207153, GAN loss = [2.23753, 0.7471209, 0.7978336]\n",
      "Batch 408/700: Discriminator loss = 1.219477891921997, GAN loss = [2.2870839, 0.75293463, 0.8415888]\n",
      "Batch 409/700: Discriminator loss = 1.2451636791229248, GAN loss = [2.217192, 0.71710855, 0.80753356]\n",
      "Batch 410/700: Discriminator loss = 1.187475562095642, GAN loss = [2.3524003, 0.7796648, 0.8801924]\n",
      "Batch 411/700: Discriminator loss = 1.1969650983810425, GAN loss = [2.2775757, 0.7762808, 0.80876267]\n",
      "Batch 412/700: Discriminator loss = 1.1908351182937622, GAN loss = [2.3005526, 0.7612574, 0.8467709]\n",
      "Batch 413/700: Discriminator loss = 1.2087889909744263, GAN loss = [2.3366458, 0.7563539, 0.88777304]\n",
      "Batch 414/700: Discriminator loss = 1.1818923950195312, GAN loss = [2.294496, 0.76319337, 0.83880144]\n",
      "Batch 415/700: Discriminator loss = 1.2031311988830566, GAN loss = [2.2621706, 0.7411741, 0.82852316]\n",
      "Batch 416/700: Discriminator loss = 1.215727686882019, GAN loss = [2.3052745, 0.75612485, 0.856696]\n",
      "Batch 417/700: Discriminator loss = 1.214114785194397, GAN loss = [2.310867, 0.7432109, 0.87521845]\n",
      "Batch 418/700: Discriminator loss = 1.204692006111145, GAN loss = [2.3353548, 0.76958704, 0.87334496]\n",
      "Batch 419/700: Discriminator loss = 1.2384809255599976, GAN loss = [2.2880812, 0.7322868, 0.8633949]\n",
      "Batch 420/700: Discriminator loss = 1.2119511365890503, GAN loss = [2.3229566, 0.75747573, 0.8730991]\n",
      "Batch 421/700: Discriminator loss = 1.219773530960083, GAN loss = [2.2846177, 0.7479501, 0.8442986]\n",
      "Batch 422/700: Discriminator loss = 1.230478048324585, GAN loss = [2.2593386, 0.7436914, 0.8232942]\n",
      "Batch 423/700: Discriminator loss = 1.2226852178573608, GAN loss = [2.2724204, 0.746835, 0.83325577]\n",
      "Batch 424/700: Discriminator loss = 1.2471158504486084, GAN loss = [2.261419, 0.71389425, 0.855218]\n",
      "Batch 425/700: Discriminator loss = 1.2269026041030884, GAN loss = [2.2644923, 0.7468848, 0.82532495]\n",
      "Batch 426/700: Discriminator loss = 1.258058786392212, GAN loss = [2.2724679, 0.7336025, 0.84659576]\n",
      "Batch 427/700: Discriminator loss = 1.2378637790679932, GAN loss = [2.181218, 0.7247415, 0.764225]\n",
      "Batch 428/700: Discriminator loss = 1.2305606603622437, GAN loss = [2.2841413, 0.7463111, 0.845586]\n",
      "Batch 429/700: Discriminator loss = 1.225197196006775, GAN loss = [2.279727, 0.7530438, 0.83445364]\n",
      "Batch 430/700: Discriminator loss = 1.245721459388733, GAN loss = [2.259505, 0.7216192, 0.8456701]\n",
      "Batch 431/700: Discriminator loss = 1.2396056652069092, GAN loss = [2.269404, 0.75621986, 0.8209975]\n",
      "Batch 432/700: Discriminator loss = 1.2620900869369507, GAN loss = [2.1770506, 0.7249257, 0.75997317]\n",
      "Batch 433/700: Discriminator loss = 1.2312235832214355, GAN loss = [2.247454, 0.7438614, 0.81148446]\n",
      "Batch 434/700: Discriminator loss = 1.2572479248046875, GAN loss = [2.2076793, 0.726172, 0.78943616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 435/700: Discriminator loss = 1.272939920425415, GAN loss = [2.201509, 0.72239405, 0.78708315]\n",
      "Batch 436/700: Discriminator loss = 1.2231491804122925, GAN loss = [2.2594953, 0.75094336, 0.8165585]\n",
      "Batch 437/700: Discriminator loss = 1.2328301668167114, GAN loss = [2.24869, 0.73646927, 0.82027036]\n",
      "Batch 438/700: Discriminator loss = 1.2091538906097412, GAN loss = [2.3117704, 0.7682196, 0.8516355]\n",
      "Batch 439/700: Discriminator loss = 1.1894642114639282, GAN loss = [2.3297565, 0.78148687, 0.8563917]\n",
      "Batch 440/700: Discriminator loss = 1.2263236045837402, GAN loss = [2.267745, 0.7513815, 0.8245349]\n",
      "Batch 441/700: Discriminator loss = 1.1984286308288574, GAN loss = [2.2853055, 0.77902925, 0.8144923]\n",
      "Batch 442/700: Discriminator loss = 1.2278246879577637, GAN loss = [2.2933478, 0.7683481, 0.8332628]\n",
      "Batch 443/700: Discriminator loss = 1.1945812702178955, GAN loss = [2.2713041, 0.76458466, 0.8150196]\n",
      "Batch 444/700: Discriminator loss = 1.1792196035385132, GAN loss = [2.3421183, 0.80819166, 0.8422688]\n",
      "Batch 445/700: Discriminator loss = 1.1943883895874023, GAN loss = [2.325396, 0.79548055, 0.8382947]\n",
      "Batch 446/700: Discriminator loss = 1.186342477798462, GAN loss = [2.3288426, 0.8096565, 0.8275963]\n",
      "Batch 447/700: Discriminator loss = 1.1757352352142334, GAN loss = [2.3475058, 0.80974084, 0.8462151]\n",
      "Batch 448/700: Discriminator loss = 1.1988458633422852, GAN loss = [2.282431, 0.7794401, 0.8114697]\n",
      "Batch 449/700: Discriminator loss = 1.2220871448516846, GAN loss = [2.2722852, 0.77806467, 0.80273277]\n",
      "Batch 450/700: Discriminator loss = 1.2124197483062744, GAN loss = [2.3270905, 0.7553077, 0.88033736]\n",
      "Batch 451/700: Discriminator loss = 1.2059688568115234, GAN loss = [2.2878253, 0.7792273, 0.81718636]\n",
      "Batch 452/700: Discriminator loss = 1.1975947618484497, GAN loss = [2.325741, 0.7848327, 0.8495075]\n",
      "Batch 453/700: Discriminator loss = 1.2055621147155762, GAN loss = [2.3660452, 0.7922048, 0.88246423]\n",
      "Batch 454/700: Discriminator loss = 1.189690113067627, GAN loss = [2.3046849, 0.78107315, 0.8322645]\n",
      "Batch 455/700: Discriminator loss = 1.1972142457962036, GAN loss = [2.3367832, 0.7856925, 0.85977966]\n",
      "Batch 456/700: Discriminator loss = 1.1987210512161255, GAN loss = [2.2889216, 0.7764783, 0.8211718]\n",
      "Batch 457/700: Discriminator loss = 1.1951042413711548, GAN loss = [2.2672753, 0.7788432, 0.79720134]\n",
      "Batch 458/700: Discriminator loss = 1.2336549758911133, GAN loss = [2.2996387, 0.7466606, 0.8617766]\n",
      "Batch 459/700: Discriminator loss = 1.2001702785491943, GAN loss = [2.3030033, 0.77773345, 0.8341028]\n",
      "Batch 460/700: Discriminator loss = 1.2347240447998047, GAN loss = [2.241782, 0.7483572, 0.8022966]\n",
      "Batch 461/700: Discriminator loss = 1.2385673522949219, GAN loss = [2.2728033, 0.7399281, 0.8417822]\n",
      "Batch 462/700: Discriminator loss = 1.2323287725448608, GAN loss = [2.2392647, 0.7554138, 0.7927861]\n",
      "Batch 463/700: Discriminator loss = 1.2294816970825195, GAN loss = [2.256784, 0.74846077, 0.8172829]\n",
      "Batch 464/700: Discriminator loss = 1.2118862867355347, GAN loss = [2.260553, 0.75606453, 0.8134627]\n",
      "Batch 465/700: Discriminator loss = 1.2472177743911743, GAN loss = [2.241558, 0.731476, 0.8190651]\n",
      "Batch 466/700: Discriminator loss = 1.2526296377182007, GAN loss = [2.2413836, 0.725506, 0.8248624]\n",
      "Batch 467/700: Discriminator loss = 1.2529228925704956, GAN loss = [2.2908738, 0.7376638, 0.86220175]\n",
      "Batch 468/700: Discriminator loss = 1.260504961013794, GAN loss = [2.2190237, 0.7345758, 0.79345477]\n",
      "Batch 469/700: Discriminator loss = 1.2513233423233032, GAN loss = [2.2175877, 0.74139017, 0.7852366]\n",
      "Batch 470/700: Discriminator loss = 1.2231298685073853, GAN loss = [2.2500937, 0.75987166, 0.79928553]\n",
      "Batch 471/700: Discriminator loss = 1.2508950233459473, GAN loss = [2.1922996, 0.73289675, 0.7684866]\n",
      "Batch 472/700: Discriminator loss = 1.2682400941848755, GAN loss = [2.2247217, 0.71923465, 0.8145832]\n",
      "Batch 473/700: Discriminator loss = 1.249342441558838, GAN loss = [2.2034962, 0.7356157, 0.7769855]\n",
      "Batch 474/700: Discriminator loss = 1.2627973556518555, GAN loss = [2.2304256, 0.7431494, 0.7963933]\n",
      "Batch 475/700: Discriminator loss = 1.2580543756484985, GAN loss = [2.2311444, 0.7590305, 0.7812527]\n",
      "Batch 476/700: Discriminator loss = 1.231030821800232, GAN loss = [2.1648083, 0.7521832, 0.7217826]\n",
      "Batch 477/700: Discriminator loss = 1.264188289642334, GAN loss = [2.221099, 0.7276394, 0.80264425]\n",
      "Batch 478/700: Discriminator loss = 1.2212885618209839, GAN loss = [2.25637, 0.75728065, 0.8082897]\n",
      "Batch 479/700: Discriminator loss = 1.2338244915008545, GAN loss = [2.2578692, 0.75563085, 0.81146544]\n",
      "Batch 480/700: Discriminator loss = 1.24076509475708, GAN loss = [2.2600682, 0.7562819, 0.8130442]\n",
      "Batch 481/700: Discriminator loss = 1.1872868537902832, GAN loss = [2.2342212, 0.77170426, 0.77180886]\n",
      "Batch 482/700: Discriminator loss = 1.2190979719161987, GAN loss = [2.242386, 0.74644554, 0.80526817]\n",
      "Batch 483/700: Discriminator loss = 1.2163281440734863, GAN loss = [2.252711, 0.7646116, 0.7974725]\n",
      "Batch 484/700: Discriminator loss = 1.2187517881393433, GAN loss = [2.235309, 0.75225115, 0.79247534]\n",
      "Batch 485/700: Discriminator loss = 1.1958324909210205, GAN loss = [2.330551, 0.7929628, 0.8470394]\n",
      "Batch 486/700: Discriminator loss = 1.2255995273590088, GAN loss = [2.2314746, 0.756381, 0.78457916]\n",
      "Batch 487/700: Discriminator loss = 1.2455426454544067, GAN loss = [2.1649256, 0.7293398, 0.74509645]\n",
      "Batch 488/700: Discriminator loss = 1.2118425369262695, GAN loss = [2.2421935, 0.7535546, 0.79817873]\n",
      "Batch 489/700: Discriminator loss = 1.2489358186721802, GAN loss = [2.1960514, 0.7314982, 0.77410895]\n",
      "Batch 490/700: Discriminator loss = 1.2088567018508911, GAN loss = [2.2224016, 0.7616756, 0.77029943]\n",
      "Batch 491/700: Discriminator loss = 1.2265989780426025, GAN loss = [2.230562, 0.743482, 0.7966799]\n",
      "Batch 492/700: Discriminator loss = 1.2212990522384644, GAN loss = [2.2380204, 0.74247277, 0.8051881]\n",
      "Batch 493/700: Discriminator loss = 1.2140228748321533, GAN loss = [2.307449, 0.7565021, 0.86062425]\n",
      "Batch 494/700: Discriminator loss = 1.2042511701583862, GAN loss = [2.282131, 0.7715671, 0.82028013]\n",
      "Batch 495/700: Discriminator loss = 1.2145709991455078, GAN loss = [2.2610579, 0.76657575, 0.8042343]\n",
      "Batch 496/700: Discriminator loss = 1.2040929794311523, GAN loss = [2.271732, 0.7783413, 0.80317134]\n",
      "Batch 497/700: Discriminator loss = 1.1966811418533325, GAN loss = [2.299421, 0.7842032, 0.8250056]\n",
      "Batch 498/700: Discriminator loss = 1.2046267986297607, GAN loss = [2.273529, 0.7672298, 0.81610644]\n",
      "Batch 499/700: Discriminator loss = 1.2156139612197876, GAN loss = [2.2274213, 0.7583839, 0.77886117]\n",
      "Batch 500/700: Discriminator loss = 1.2158962488174438, GAN loss = [2.2515132, 0.74772537, 0.8136234]\n",
      "Batch 501/700: Discriminator loss = 1.2104225158691406, GAN loss = [2.284411, 0.77720916, 0.81705505]\n",
      "Batch 502/700: Discriminator loss = 1.2156087160110474, GAN loss = [2.245698, 0.76556313, 0.79000497]\n",
      "Batch 503/700: Discriminator loss = 1.202245831489563, GAN loss = [2.2439475, 0.765423, 0.7884148]\n",
      "Batch 504/700: Discriminator loss = 1.2146016359329224, GAN loss = [2.271006, 0.76060385, 0.82030606]\n",
      "Batch 505/700: Discriminator loss = 1.2141937017440796, GAN loss = [2.2436004, 0.76312286, 0.7903829]\n",
      "Batch 506/700: Discriminator loss = 1.199886441230774, GAN loss = [2.2597702, 0.76299745, 0.80669665]\n",
      "Batch 507/700: Discriminator loss = 1.2505881786346436, GAN loss = [2.2314425, 0.7273706, 0.8140103]\n",
      "Batch 508/700: Discriminator loss = 1.2442501783370972, GAN loss = [2.178648, 0.7187704, 0.76983756]\n",
      "Batch 509/700: Discriminator loss = 1.201212763786316, GAN loss = [2.285051, 0.7722523, 0.8227768]\n",
      "Batch 510/700: Discriminator loss = 1.2024438381195068, GAN loss = [2.2344368, 0.7506482, 0.7937898]\n",
      "Batch 511/700: Discriminator loss = 1.2479636669158936, GAN loss = [2.2048268, 0.7302082, 0.78463227]\n",
      "Batch 512/700: Discriminator loss = 1.236564040184021, GAN loss = [2.2118225, 0.72919166, 0.79266185]\n",
      "Batch 513/700: Discriminator loss = 1.2118263244628906, GAN loss = [2.2508168, 0.74106324, 0.8198022]\n",
      "Batch 514/700: Discriminator loss = 1.2214274406433105, GAN loss = [2.2968328, 0.76337, 0.8435325]\n",
      "Batch 515/700: Discriminator loss = 1.2387597560882568, GAN loss = [2.2092254, 0.72292596, 0.7963924]\n",
      "Batch 516/700: Discriminator loss = 1.2438204288482666, GAN loss = [2.2006447, 0.71886146, 0.7918968]\n",
      "Batch 517/700: Discriminator loss = 1.2339791059494019, GAN loss = [2.215483, 0.7160072, 0.809608]\n",
      "Batch 518/700: Discriminator loss = 1.2690976858139038, GAN loss = [2.1993716, 0.70646197, 0.8030638]\n",
      "Batch 519/700: Discriminator loss = 1.2158982753753662, GAN loss = [2.2574341, 0.7290243, 0.83857733]\n",
      "Batch 520/700: Discriminator loss = 1.2621607780456543, GAN loss = [2.204126, 0.7089275, 0.8053845]\n",
      "Batch 521/700: Discriminator loss = 1.2549233436584473, GAN loss = [2.186309, 0.70555055, 0.79096586]\n",
      "Batch 522/700: Discriminator loss = 1.253734827041626, GAN loss = [2.224619, 0.7123784, 0.8224661]\n",
      "Batch 523/700: Discriminator loss = 1.2625709772109985, GAN loss = [2.1711113, 0.69699836, 0.7843547]\n",
      "Batch 524/700: Discriminator loss = 1.237113356590271, GAN loss = [2.1983044, 0.7206985, 0.7878785]\n",
      "Batch 525/700: Discriminator loss = 1.2457870244979858, GAN loss = [2.230406, 0.7190129, 0.82170016]\n",
      "Batch 526/700: Discriminator loss = 1.240668535232544, GAN loss = [2.1981544, 0.73084176, 0.77764845]\n",
      "Batch 527/700: Discriminator loss = 1.2420976161956787, GAN loss = [2.2436054, 0.71509254, 0.8388816]\n",
      "Batch 528/700: Discriminator loss = 1.237949013710022, GAN loss = [2.195713, 0.7131907, 0.79292375]\n",
      "Batch 529/700: Discriminator loss = 1.266146183013916, GAN loss = [2.1525462, 0.68303293, 0.7799411]\n",
      "Batch 530/700: Discriminator loss = 1.247802972793579, GAN loss = [2.2166889, 0.7120982, 0.81506777]\n",
      "Batch 531/700: Discriminator loss = 1.2420302629470825, GAN loss = [2.2011235, 0.7122462, 0.7994007]\n",
      "Batch 532/700: Discriminator loss = 1.2399169206619263, GAN loss = [2.1943185, 0.7186977, 0.78618515]\n",
      "Batch 533/700: Discriminator loss = 1.2728272676467896, GAN loss = [2.1472023, 0.6873073, 0.7705187]\n",
      "Batch 534/700: Discriminator loss = 1.2365775108337402, GAN loss = [2.1972456, 0.725446, 0.782481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 535/700: Discriminator loss = 1.2318679094314575, GAN loss = [2.2649376, 0.73377085, 0.84190524]\n",
      "Batch 536/700: Discriminator loss = 1.2547727823257446, GAN loss = [2.2092602, 0.69952506, 0.8205263]\n",
      "Batch 537/700: Discriminator loss = 1.2535744905471802, GAN loss = [2.1635, 0.7137315, 0.7605996]\n",
      "Batch 538/700: Discriminator loss = 1.234511375427246, GAN loss = [2.2376044, 0.70816857, 0.84030616]\n",
      "Batch 539/700: Discriminator loss = 1.2534217834472656, GAN loss = [2.2170193, 0.70997506, 0.8179597]\n",
      "Batch 540/700: Discriminator loss = 1.2155961990356445, GAN loss = [2.204101, 0.7359862, 0.77906966]\n",
      "Batch 541/700: Discriminator loss = 1.2137333154678345, GAN loss = [2.2304807, 0.73685074, 0.80461496]\n",
      "Batch 542/700: Discriminator loss = 1.2288390398025513, GAN loss = [2.217676, 0.7440326, 0.7846541]\n",
      "Batch 543/700: Discriminator loss = 1.231245517730713, GAN loss = [2.2130845, 0.71820587, 0.8059075]\n",
      "Batch 544/700: Discriminator loss = 1.239683747291565, GAN loss = [2.1746492, 0.72223425, 0.76346517]\n",
      "Batch 545/700: Discriminator loss = 1.2089561223983765, GAN loss = [2.2360964, 0.7447092, 0.80244756]\n",
      "Batch 546/700: Discriminator loss = 1.2339731454849243, GAN loss = [2.2133899, 0.7301894, 0.7942798]\n",
      "Batch 547/700: Discriminator loss = 1.2289118766784668, GAN loss = [2.2291696, 0.72686505, 0.8134043]\n",
      "Batch 548/700: Discriminator loss = 1.2114752531051636, GAN loss = [2.234026, 0.75003237, 0.79512286]\n",
      "Batch 549/700: Discriminator loss = 1.2001233100891113, GAN loss = [2.2580519, 0.7665007, 0.8027129]\n",
      "Batch 550/700: Discriminator loss = 1.1947649717330933, GAN loss = [2.2629592, 0.76466155, 0.809494]\n",
      "Batch 551/700: Discriminator loss = 1.2001014947891235, GAN loss = [2.274252, 0.7578904, 0.82759184]\n",
      "Batch 552/700: Discriminator loss = 1.2334085702896118, GAN loss = [2.2302039, 0.7173228, 0.82412577]\n",
      "Batch 553/700: Discriminator loss = 1.2058802843093872, GAN loss = [2.2184486, 0.74152136, 0.7881838]\n",
      "Batch 554/700: Discriminator loss = 1.2208061218261719, GAN loss = [2.2560697, 0.7315807, 0.83575714]\n",
      "Batch 555/700: Discriminator loss = 1.2059005498886108, GAN loss = [2.2361348, 0.747305, 0.800115]\n",
      "Batch 556/700: Discriminator loss = 1.2340766191482544, GAN loss = [2.2269218, 0.73191744, 0.80630964]\n",
      "Batch 557/700: Discriminator loss = 1.201920747756958, GAN loss = [2.2882369, 0.75495476, 0.8446093]\n",
      "Batch 558/700: Discriminator loss = 1.2117480039596558, GAN loss = [2.232998, 0.75077295, 0.79356456]\n",
      "Batch 559/700: Discriminator loss = 1.235018253326416, GAN loss = [2.225256, 0.72886956, 0.8077299]\n",
      "Batch 560/700: Discriminator loss = 1.2146166563034058, GAN loss = [2.2221086, 0.75294614, 0.7805273]\n",
      "Batch 561/700: Discriminator loss = 1.2129793167114258, GAN loss = [2.263357, 0.7519091, 0.822827]\n",
      "Batch 562/700: Discriminator loss = 1.2014087438583374, GAN loss = [2.2469373, 0.76296306, 0.79537094]\n",
      "Batch 563/700: Discriminator loss = 1.2290194034576416, GAN loss = [2.2377768, 0.7588327, 0.79034686]\n",
      "Batch 564/700: Discriminator loss = 1.2452855110168457, GAN loss = [2.2368326, 0.7189832, 0.8292533]\n",
      "Batch 565/700: Discriminator loss = 1.2413166761398315, GAN loss = [2.1862283, 0.73139876, 0.76624006]\n",
      "Batch 566/700: Discriminator loss = 1.1922091245651245, GAN loss = [2.2867692, 0.7742562, 0.82393956]\n",
      "Batch 567/700: Discriminator loss = 1.187804102897644, GAN loss = [2.2735698, 0.769194, 0.81581587]\n",
      "Batch 568/700: Discriminator loss = 1.2028454542160034, GAN loss = [2.2184105, 0.7544145, 0.77544737]\n",
      "Batch 569/700: Discriminator loss = 1.2187466621398926, GAN loss = [2.2514005, 0.7389932, 0.82386696]\n",
      "Batch 570/700: Discriminator loss = 1.232802152633667, GAN loss = [2.2078407, 0.723271, 0.7960372]\n",
      "Batch 571/700: Discriminator loss = 1.2018378973007202, GAN loss = [2.260326, 0.7515768, 0.82022357]\n",
      "Batch 572/700: Discriminator loss = 1.222075343132019, GAN loss = [2.1928453, 0.7412998, 0.763037]\n",
      "Batch 573/700: Discriminator loss = 1.221860647201538, GAN loss = [2.226431, 0.7419927, 0.7959452]\n",
      "Batch 574/700: Discriminator loss = 1.2290925979614258, GAN loss = [2.1989167, 0.7313165, 0.77911437]\n",
      "Batch 575/700: Discriminator loss = 1.2318427562713623, GAN loss = [2.1855485, 0.7296248, 0.7674514]\n",
      "Batch 576/700: Discriminator loss = 1.2213767766952515, GAN loss = [2.2378666, 0.73526525, 0.8141264]\n",
      "Batch 577/700: Discriminator loss = 1.22243070602417, GAN loss = [2.1853092, 0.7278401, 0.76899284]\n",
      "Batch 578/700: Discriminator loss = 1.2369160652160645, GAN loss = [2.215122, 0.73429656, 0.7923529]\n",
      "Batch 579/700: Discriminator loss = 1.2193844318389893, GAN loss = [2.2172675, 0.7355224, 0.79327655]\n",
      "Batch 580/700: Discriminator loss = 1.2460215091705322, GAN loss = [2.2069142, 0.73741865, 0.7810378]\n",
      "Batch 581/700: Discriminator loss = 1.2385941743850708, GAN loss = [2.2401996, 0.7211468, 0.83060026]\n",
      "Batch 582/700: Discriminator loss = 1.2256295680999756, GAN loss = [2.205869, 0.73062927, 0.78679144]\n",
      "Batch 583/700: Discriminator loss = 1.211711049079895, GAN loss = [2.256182, 0.74321604, 0.8245196]\n",
      "Batch 584/700: Discriminator loss = 1.2092351913452148, GAN loss = [2.2479417, 0.749939, 0.8095637]\n",
      "Batch 585/700: Discriminator loss = 1.228606939315796, GAN loss = [2.2252367, 0.7206183, 0.81619126]\n",
      "Batch 586/700: Discriminator loss = 1.2185628414154053, GAN loss = [2.212459, 0.72784895, 0.796201]\n",
      "Batch 587/700: Discriminator loss = 1.25791597366333, GAN loss = [2.216191, 0.7182193, 0.80958253]\n",
      "Batch 588/700: Discriminator loss = 1.2275617122650146, GAN loss = [2.2502048, 0.73001534, 0.8318144]\n",
      "Batch 589/700: Discriminator loss = 1.2312184572219849, GAN loss = [2.174844, 0.717007, 0.76947427]\n",
      "Batch 590/700: Discriminator loss = 1.2093288898468018, GAN loss = [2.2552354, 0.75151515, 0.8153724]\n",
      "Batch 591/700: Discriminator loss = 1.2178945541381836, GAN loss = [2.2679746, 0.7459703, 0.833662]\n",
      "Batch 592/700: Discriminator loss = 1.2208502292633057, GAN loss = [2.219826, 0.7348816, 0.79661775]\n",
      "Batch 593/700: Discriminator loss = 1.2305155992507935, GAN loss = [2.24244, 0.72563344, 0.8284954]\n",
      "Batch 594/700: Discriminator loss = 1.225260615348816, GAN loss = [2.212746, 0.72071624, 0.80372596]\n",
      "Batch 595/700: Discriminator loss = 1.2165309190750122, GAN loss = [2.231016, 0.7416428, 0.8010781]\n",
      "Batch 596/700: Discriminator loss = 1.2221906185150146, GAN loss = [2.2206419, 0.74777514, 0.78458]\n",
      "Batch 597/700: Discriminator loss = 1.2172876596450806, GAN loss = [2.2275589, 0.7425589, 0.79671854]\n",
      "Batch 598/700: Discriminator loss = 1.2392176389694214, GAN loss = [2.2688875, 0.72607404, 0.85454804]\n",
      "Batch 599/700: Discriminator loss = 1.235893964767456, GAN loss = [2.2152436, 0.72099984, 0.80599684]\n",
      "Batch 600/700: Discriminator loss = 1.2086900472640991, GAN loss = [2.261265, 0.76335406, 0.80968523]\n",
      "Batch 601/700: Discriminator loss = 1.230056643486023, GAN loss = [2.2354074, 0.72637755, 0.82082415]\n",
      "Batch 602/700: Discriminator loss = 1.2409354448318481, GAN loss = [2.2067332, 0.7193656, 0.799175]\n",
      "Batch 603/700: Discriminator loss = 1.2091695070266724, GAN loss = [2.276674, 0.7501281, 0.8383751]\n",
      "Batch 604/700: Discriminator loss = 1.242498755455017, GAN loss = [2.2359316, 0.7086421, 0.83913803]\n",
      "Batch 605/700: Discriminator loss = 1.2391693592071533, GAN loss = [2.2107925, 0.7225458, 0.8001118]\n",
      "Batch 606/700: Discriminator loss = 1.2416965961456299, GAN loss = [2.2189324, 0.71471757, 0.81609744]\n",
      "Batch 607/700: Discriminator loss = 1.2103917598724365, GAN loss = [2.2517498, 0.7423952, 0.82126343]\n",
      "Batch 608/700: Discriminator loss = 1.2213486433029175, GAN loss = [2.1689548, 0.72291654, 0.75796723]\n",
      "Batch 609/700: Discriminator loss = 1.2430870532989502, GAN loss = [2.2263513, 0.71719813, 0.82110465]\n",
      "Batch 610/700: Discriminator loss = 1.2364368438720703, GAN loss = [2.2253623, 0.73220134, 0.8051319]\n",
      "Batch 611/700: Discriminator loss = 1.2406402826309204, GAN loss = [2.2497156, 0.7114027, 0.85029846]\n",
      "Batch 612/700: Discriminator loss = 1.2457897663116455, GAN loss = [2.1893435, 0.7163465, 0.78500104]\n",
      "Batch 613/700: Discriminator loss = 1.2627297639846802, GAN loss = [2.1891117, 0.69868284, 0.80245215]\n",
      "Batch 614/700: Discriminator loss = 1.2302896976470947, GAN loss = [2.2207294, 0.72101676, 0.81175375]\n",
      "Batch 615/700: Discriminator loss = 1.2680343389511108, GAN loss = [2.1594057, 0.6913962, 0.7800824]\n",
      "Batch 616/700: Discriminator loss = 1.2402344942092896, GAN loss = [2.2270331, 0.7243164, 0.8148214]\n",
      "Batch 617/700: Discriminator loss = 1.2471686601638794, GAN loss = [2.1888735, 0.71280855, 0.7881964]\n",
      "Batch 618/700: Discriminator loss = 1.259665846824646, GAN loss = [2.1595118, 0.71138906, 0.7602913]\n",
      "Batch 619/700: Discriminator loss = 1.2515723705291748, GAN loss = [2.215127, 0.7244358, 0.8028962]\n",
      "Batch 620/700: Discriminator loss = 1.2305148839950562, GAN loss = [2.2054796, 0.74213135, 0.7755838]\n",
      "Batch 621/700: Discriminator loss = 1.2445759773254395, GAN loss = [2.2179422, 0.73807526, 0.7921398]\n",
      "Batch 622/700: Discriminator loss = 1.225184679031372, GAN loss = [2.2188566, 0.7394654, 0.79167986]\n",
      "Batch 623/700: Discriminator loss = 1.2380412817001343, GAN loss = [2.2041674, 0.7225347, 0.7939372]\n",
      "Batch 624/700: Discriminator loss = 1.2298728227615356, GAN loss = [2.2043834, 0.7262348, 0.7904712]\n",
      "Batch 625/700: Discriminator loss = 1.205615758895874, GAN loss = [2.2144978, 0.7581092, 0.76873076]\n",
      "Batch 626/700: Discriminator loss = 1.230112075805664, GAN loss = [2.2513323, 0.7362794, 0.82743186]\n",
      "Batch 627/700: Discriminator loss = 1.2677476406097412, GAN loss = [2.208361, 0.7239907, 0.79678255]\n",
      "Batch 628/700: Discriminator loss = 1.2280333042144775, GAN loss = [2.1984463, 0.7369652, 0.773932]\n",
      "Batch 629/700: Discriminator loss = 1.2198065519332886, GAN loss = [2.238715, 0.74105215, 0.8101464]\n",
      "Batch 630/700: Discriminator loss = 1.2121580839157104, GAN loss = [2.223754, 0.7483352, 0.78793174]\n",
      "Batch 631/700: Discriminator loss = 1.2397310733795166, GAN loss = [2.2293952, 0.73198587, 0.80993974]\n",
      "Batch 632/700: Discriminator loss = 1.2002817392349243, GAN loss = [2.187327, 0.7627917, 0.73709816]\n",
      "Batch 633/700: Discriminator loss = 1.21239173412323, GAN loss = [2.2351215, 0.7533882, 0.7943271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 634/700: Discriminator loss = 1.1947928667068481, GAN loss = [2.292178, 0.7772203, 0.8275937]\n",
      "Batch 635/700: Discriminator loss = 1.2021907567977905, GAN loss = [2.2638156, 0.7767553, 0.79974085]\n",
      "Batch 636/700: Discriminator loss = 1.207766056060791, GAN loss = [2.2396433, 0.7704181, 0.7819394]\n",
      "Batch 637/700: Discriminator loss = 1.193543791770935, GAN loss = [2.241394, 0.77593994, 0.7781908]\n",
      "Batch 638/700: Discriminator loss = 1.2034623622894287, GAN loss = [2.2398348, 0.7631501, 0.78945786]\n",
      "Batch 639/700: Discriminator loss = 1.207474946975708, GAN loss = [2.2287595, 0.75228035, 0.78928316]\n",
      "Batch 640/700: Discriminator loss = 1.2304166555404663, GAN loss = [2.2622452, 0.7474491, 0.82762367]\n",
      "Batch 641/700: Discriminator loss = 1.188268780708313, GAN loss = [2.2989078, 0.77637845, 0.8353948]\n",
      "Batch 642/700: Discriminator loss = 1.1991719007492065, GAN loss = [2.2270668, 0.75274736, 0.78721344]\n",
      "Batch 643/700: Discriminator loss = 1.205267071723938, GAN loss = [2.2892194, 0.7753797, 0.82675546]\n",
      "Batch 644/700: Discriminator loss = 1.1892045736312866, GAN loss = [2.2758405, 0.77988374, 0.8089003]\n",
      "Batch 645/700: Discriminator loss = 1.1820992231369019, GAN loss = [2.2577357, 0.7855844, 0.78512686]\n",
      "Batch 646/700: Discriminator loss = 1.1730873584747314, GAN loss = [2.2980728, 0.77937233, 0.8317147]\n",
      "Batch 647/700: Discriminator loss = 1.1701350212097168, GAN loss = [2.28488, 0.7919989, 0.8059324]\n",
      "Batch 648/700: Discriminator loss = 1.1897423267364502, GAN loss = [2.2912796, 0.77766055, 0.82670885]\n",
      "Batch 649/700: Discriminator loss = 1.1935834884643555, GAN loss = [2.2833688, 0.7666941, 0.8297988]\n",
      "Batch 650/700: Discriminator loss = 1.1964471340179443, GAN loss = [2.2831013, 0.7812975, 0.81496376]\n",
      "Batch 651/700: Discriminator loss = 1.1748976707458496, GAN loss = [2.336834, 0.7901397, 0.8598813]\n",
      "Batch 652/700: Discriminator loss = 1.1881296634674072, GAN loss = [2.2690558, 0.7714787, 0.8107825]\n",
      "Batch 653/700: Discriminator loss = 1.1954609155654907, GAN loss = [2.3124344, 0.7653092, 0.86034346]\n",
      "Batch 654/700: Discriminator loss = 1.2127227783203125, GAN loss = [2.259028, 0.7481708, 0.824086]\n",
      "Batch 655/700: Discriminator loss = 1.2064518928527832, GAN loss = [2.2610495, 0.7619194, 0.8123677]\n",
      "Batch 656/700: Discriminator loss = 1.2057727575302124, GAN loss = [2.275959, 0.7577703, 0.83144116]\n",
      "Batch 657/700: Discriminator loss = 1.2038754224777222, GAN loss = [2.3240604, 0.7674838, 0.86985224]\n",
      "Batch 658/700: Discriminator loss = 1.2205023765563965, GAN loss = [2.228994, 0.7514133, 0.7908722]\n",
      "Batch 659/700: Discriminator loss = 1.181841254234314, GAN loss = [2.3291342, 0.77530426, 0.8671325]\n",
      "Batch 660/700: Discriminator loss = 1.1977425813674927, GAN loss = [2.3119493, 0.7692541, 0.85600805]\n",
      "Batch 661/700: Discriminator loss = 1.180398941040039, GAN loss = [2.3263426, 0.77712005, 0.86254984]\n",
      "Batch 662/700: Discriminator loss = 1.1727008819580078, GAN loss = [2.3055062, 0.7812031, 0.8376406]\n",
      "Batch 663/700: Discriminator loss = 1.1815745830535889, GAN loss = [2.3717015, 0.7910145, 0.8940304]\n",
      "Batch 664/700: Discriminator loss = 1.196632981300354, GAN loss = [2.2592654, 0.76341325, 0.809194]\n",
      "Batch 665/700: Discriminator loss = 1.1766490936279297, GAN loss = [2.3061821, 0.7911117, 0.8284071]\n",
      "Batch 666/700: Discriminator loss = 1.1968882083892822, GAN loss = [2.31702, 0.7616916, 0.86866003]\n",
      "Batch 667/700: Discriminator loss = 1.205756425857544, GAN loss = [2.2938347, 0.74643517, 0.860736]\n",
      "Batch 668/700: Discriminator loss = 1.2032601833343506, GAN loss = [2.3366547, 0.7609528, 0.88904047]\n",
      "Batch 669/700: Discriminator loss = 1.207183837890625, GAN loss = [2.3148057, 0.7617361, 0.8664216]\n",
      "Batch 670/700: Discriminator loss = 1.2142335176467896, GAN loss = [2.3381472, 0.74961096, 0.9018978]\n",
      "Batch 671/700: Discriminator loss = 1.2002531290054321, GAN loss = [2.321219, 0.75575536, 0.8788276]\n",
      "Batch 672/700: Discriminator loss = 1.19309663772583, GAN loss = [2.3165298, 0.77288765, 0.85699546]\n",
      "Batch 673/700: Discriminator loss = 1.2078410387039185, GAN loss = [2.3133237, 0.7500104, 0.8766537]\n",
      "Batch 674/700: Discriminator loss = 1.1999326944351196, GAN loss = [2.3243709, 0.7672102, 0.87048393]\n",
      "Batch 675/700: Discriminator loss = 1.2184200286865234, GAN loss = [2.2683017, 0.7354102, 0.84619784]\n",
      "Batch 676/700: Discriminator loss = 1.211289644241333, GAN loss = [2.2952232, 0.7541011, 0.85440683]\n",
      "Batch 677/700: Discriminator loss = 1.2095541954040527, GAN loss = [2.332565, 0.7560463, 0.8898007]\n",
      "Batch 678/700: Discriminator loss = 1.2336418628692627, GAN loss = [2.3000517, 0.73877966, 0.8745568]\n",
      "Batch 679/700: Discriminator loss = 1.226381778717041, GAN loss = [2.3464808, 0.7497518, 0.9100186]\n",
      "Batch 680/700: Discriminator loss = 1.2242952585220337, GAN loss = [2.2709298, 0.7401019, 0.8441152]\n",
      "Batch 681/700: Discriminator loss = 1.2168151140213013, GAN loss = [2.2530546, 0.7431267, 0.8232135]\n",
      "Batch 682/700: Discriminator loss = 1.2091398239135742, GAN loss = [2.2969697, 0.76195097, 0.84831125]\n",
      "Batch 683/700: Discriminator loss = 1.2303080558776855, GAN loss = [2.2700384, 0.73533463, 0.8480017]\n",
      "Batch 684/700: Discriminator loss = 1.2300142049789429, GAN loss = [2.2827036, 0.7352932, 0.86070466]\n",
      "Batch 685/700: Discriminator loss = 1.199937343597412, GAN loss = [2.337289, 0.76255524, 0.8880255]\n",
      "Batch 686/700: Discriminator loss = 1.210096001625061, GAN loss = [2.2776325, 0.7473394, 0.8435953]\n",
      "Batch 687/700: Discriminator loss = 1.1935272216796875, GAN loss = [2.316441, 0.7689561, 0.86080366]\n",
      "Batch 688/700: Discriminator loss = 1.2256531715393066, GAN loss = [2.2944448, 0.7438965, 0.863879]\n",
      "Batch 689/700: Discriminator loss = 1.2175666093826294, GAN loss = [2.2752683, 0.7386074, 0.8500078]\n",
      "Batch 690/700: Discriminator loss = 1.214274287223816, GAN loss = [2.3082998, 0.7516088, 0.87005156]\n",
      "Batch 691/700: Discriminator loss = 1.2267448902130127, GAN loss = [2.3005998, 0.7404392, 0.87352645]\n",
      "Batch 692/700: Discriminator loss = 1.1983658075332642, GAN loss = [2.3171291, 0.77018684, 0.86030143]\n",
      "Batch 693/700: Discriminator loss = 1.1990985870361328, GAN loss = [2.3375018, 0.7731887, 0.87767136]\n",
      "Batch 694/700: Discriminator loss = 1.2071880102157593, GAN loss = [2.3235078, 0.7537052, 0.8831578]\n",
      "Batch 695/700: Discriminator loss = 1.196839690208435, GAN loss = [2.3473768, 0.7668778, 0.893846]\n",
      "Batch 696/700: Discriminator loss = 1.2109168767929077, GAN loss = [2.2774014, 0.75017405, 0.84056646]\n",
      "Batch 697/700: Discriminator loss = 1.2077597379684448, GAN loss = [2.364764, 0.7846323, 0.89346755]\n",
      "Batch 698/700: Discriminator loss = 1.2104696035385132, GAN loss = [2.316502, 0.78210604, 0.8477263]\n",
      "Batch 699/700: Discriminator loss = 1.2028743028640747, GAN loss = [2.2751396, 0.75718, 0.8312877]\n",
      "Batch 700/700: Discriminator loss = 1.172534465789795, GAN loss = [2.313265, 0.80189157, 0.82468224]\n",
      "Epoch 18/30\n",
      "Batch 1/700: Discriminator loss = 1.223875641822815, GAN loss = [2.3330193, 0.7488859, 0.8974306]\n",
      "Batch 2/700: Discriminator loss = 1.1991945505142212, GAN loss = [2.3573663, 0.8056946, 0.8649511]\n",
      "Batch 3/700: Discriminator loss = 1.220620036125183, GAN loss = [2.325979, 0.7756953, 0.863539]\n",
      "Batch 4/700: Discriminator loss = 1.1826993227005005, GAN loss = [2.3500438, 0.80138403, 0.8618687]\n",
      "Batch 5/700: Discriminator loss = 1.2177238464355469, GAN loss = [2.3226113, 0.77099097, 0.8648066]\n",
      "Batch 6/700: Discriminator loss = 1.2113221883773804, GAN loss = [2.3261511, 0.77905685, 0.8602747]\n",
      "Batch 7/700: Discriminator loss = 1.189736008644104, GAN loss = [2.3813899, 0.79354596, 0.90104383]\n",
      "Batch 8/700: Discriminator loss = 1.2523231506347656, GAN loss = [2.3011634, 0.73573065, 0.87865484]\n",
      "Batch 9/700: Discriminator loss = 1.2001447677612305, GAN loss = [2.3162842, 0.7796286, 0.849877]\n",
      "Batch 10/700: Discriminator loss = 1.2596052885055542, GAN loss = [2.2656925, 0.7399445, 0.8389851]\n",
      "Batch 11/700: Discriminator loss = 1.2101705074310303, GAN loss = [2.3030708, 0.7765506, 0.83977896]\n",
      "Batch 12/700: Discriminator loss = 1.2171307802200317, GAN loss = [2.312918, 0.7727883, 0.853402]\n",
      "Batch 13/700: Discriminator loss = 1.2135632038116455, GAN loss = [2.2917778, 0.7621084, 0.8429541]\n",
      "Batch 14/700: Discriminator loss = 1.203276515007019, GAN loss = [2.3009326, 0.77454025, 0.83968675]\n",
      "Batch 15/700: Discriminator loss = 1.2162747383117676, GAN loss = [2.291013, 0.754324, 0.84999037]\n",
      "Batch 16/700: Discriminator loss = 1.2430647611618042, GAN loss = [2.2253132, 0.7392834, 0.79934716]\n",
      "Batch 17/700: Discriminator loss = 1.2561354637145996, GAN loss = [2.2710361, 0.72402364, 0.8603451]\n",
      "Batch 18/700: Discriminator loss = 1.244917392730713, GAN loss = [2.2583218, 0.7204284, 0.85122734]\n",
      "Batch 19/700: Discriminator loss = 1.2494279146194458, GAN loss = [2.2960804, 0.7371025, 0.87231046]\n",
      "Batch 20/700: Discriminator loss = 1.2406057119369507, GAN loss = [2.261796, 0.74480224, 0.83034706]\n",
      "Batch 21/700: Discriminator loss = 1.244521975517273, GAN loss = [2.254119, 0.7317865, 0.8356896]\n",
      "Batch 22/700: Discriminator loss = 1.2729119062423706, GAN loss = [2.2661436, 0.73598814, 0.843519]\n",
      "Batch 23/700: Discriminator loss = 1.2489278316497803, GAN loss = [2.2155123, 0.74787873, 0.7809972]\n",
      "Batch 24/700: Discriminator loss = 1.2779127359390259, GAN loss = [2.2306023, 0.7196295, 0.82431906]\n",
      "Batch 25/700: Discriminator loss = 1.2646827697753906, GAN loss = [2.248193, 0.7480902, 0.8134484]\n",
      "Batch 26/700: Discriminator loss = 1.2772520780563354, GAN loss = [2.206486, 0.73336685, 0.7864588]\n",
      "Batch 27/700: Discriminator loss = 1.2430623769760132, GAN loss = [2.255572, 0.74986154, 0.81902426]\n",
      "Batch 28/700: Discriminator loss = 1.217734694480896, GAN loss = [2.3118577, 0.7739608, 0.8512094]\n",
      "Batch 29/700: Discriminator loss = 1.197579026222229, GAN loss = [2.3246045, 0.78492063, 0.85298586]\n",
      "Batch 30/700: Discriminator loss = 1.2074525356292725, GAN loss = [2.2689385, 0.76126826, 0.82096887]\n",
      "Batch 31/700: Discriminator loss = 1.2078697681427002, GAN loss = [2.3140435, 0.7731561, 0.8541773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32/700: Discriminator loss = 1.16741144657135, GAN loss = [2.3639994, 0.82027745, 0.85702205]\n",
      "Batch 33/700: Discriminator loss = 1.2513129711151123, GAN loss = [2.2946317, 0.7287387, 0.879213]\n",
      "Batch 34/700: Discriminator loss = 1.227552056312561, GAN loss = [2.2728133, 0.7386477, 0.84749436]\n",
      "Batch 35/700: Discriminator loss = 1.2257652282714844, GAN loss = [2.2809572, 0.72627443, 0.8680223]\n",
      "Batch 36/700: Discriminator loss = 1.1956865787506104, GAN loss = [2.3145394, 0.75983566, 0.8680588]\n",
      "Batch 37/700: Discriminator loss = 1.189788579940796, GAN loss = [2.3567133, 0.7762155, 0.89385825]\n",
      "Batch 38/700: Discriminator loss = 1.2156533002853394, GAN loss = [2.3167973, 0.74785674, 0.8823303]\n",
      "Batch 39/700: Discriminator loss = 1.22037935256958, GAN loss = [2.3287368, 0.743187, 0.8989716]\n",
      "Batch 40/700: Discriminator loss = 1.21039879322052, GAN loss = [2.2380557, 0.74046415, 0.81103444]\n",
      "Batch 41/700: Discriminator loss = 1.1996357440948486, GAN loss = [2.3316085, 0.7597353, 0.88534796]\n",
      "Batch 42/700: Discriminator loss = 1.1935006380081177, GAN loss = [2.4054053, 0.7819953, 0.9369259]\n",
      "Batch 43/700: Discriminator loss = 1.2064870595932007, GAN loss = [2.336382, 0.77586335, 0.8740752]\n",
      "Batch 44/700: Discriminator loss = 1.2023826837539673, GAN loss = [2.325767, 0.76844954, 0.8709253]\n",
      "Batch 45/700: Discriminator loss = 1.2291467189788818, GAN loss = [2.290991, 0.7386091, 0.8660311]\n",
      "Batch 46/700: Discriminator loss = 1.2062358856201172, GAN loss = [2.295228, 0.7726149, 0.8363057]\n",
      "Batch 47/700: Discriminator loss = 1.1890859603881836, GAN loss = [2.3305647, 0.77854013, 0.86575836]\n",
      "Batch 48/700: Discriminator loss = 1.2203116416931152, GAN loss = [2.3238184, 0.76147276, 0.87612504]\n",
      "Batch 49/700: Discriminator loss = 1.2067186832427979, GAN loss = [2.2905488, 0.7692171, 0.8351623]\n",
      "Batch 50/700: Discriminator loss = 1.1641268730163574, GAN loss = [2.3827786, 0.8078373, 0.88881636]\n",
      "Batch 51/700: Discriminator loss = 1.1979962587356567, GAN loss = [2.3528485, 0.78564787, 0.88111466]\n",
      "Batch 52/700: Discriminator loss = 1.1920044422149658, GAN loss = [2.326676, 0.7799598, 0.86066747]\n",
      "Batch 53/700: Discriminator loss = 1.2143921852111816, GAN loss = [2.3837385, 0.7687222, 0.9290112]\n",
      "Batch 54/700: Discriminator loss = 1.2313498258590698, GAN loss = [2.2627552, 0.74304914, 0.83374494]\n",
      "Batch 55/700: Discriminator loss = 1.206505537033081, GAN loss = [2.3494468, 0.77780724, 0.8857185]\n",
      "Batch 56/700: Discriminator loss = 1.235954999923706, GAN loss = [2.3136897, 0.7488179, 0.8789789]\n",
      "Batch 57/700: Discriminator loss = 1.2323849201202393, GAN loss = [2.2473304, 0.7530073, 0.80847883]\n",
      "Batch 58/700: Discriminator loss = 1.2376177310943604, GAN loss = [2.3410125, 0.75318164, 0.9020403]\n",
      "Batch 59/700: Discriminator loss = 1.191633701324463, GAN loss = [2.3561323, 0.7813786, 0.8890239]\n",
      "Batch 60/700: Discriminator loss = 1.2157694101333618, GAN loss = [2.2864025, 0.76371324, 0.83702666]\n",
      "Batch 61/700: Discriminator loss = 1.2010959386825562, GAN loss = [2.3160257, 0.77637553, 0.8540447]\n",
      "Batch 62/700: Discriminator loss = 1.2065097093582153, GAN loss = [2.3201149, 0.78311867, 0.8514502]\n",
      "Batch 63/700: Discriminator loss = 1.2030912637710571, GAN loss = [2.3370287, 0.7980432, 0.8535073]\n",
      "Batch 64/700: Discriminator loss = 1.1999567747116089, GAN loss = [2.2978737, 0.7863554, 0.82610995]\n",
      "Batch 65/700: Discriminator loss = 1.2106527090072632, GAN loss = [2.313211, 0.792289, 0.83557916]\n",
      "Batch 66/700: Discriminator loss = 1.1854411363601685, GAN loss = [2.3561761, 0.8084802, 0.8624037]\n",
      "Batch 67/700: Discriminator loss = 1.1872409582138062, GAN loss = [2.3022628, 0.78677636, 0.83024263]\n",
      "Batch 68/700: Discriminator loss = 1.227983832359314, GAN loss = [2.3247392, 0.7738917, 0.86565375]\n",
      "Batch 69/700: Discriminator loss = 1.2106044292449951, GAN loss = [2.2996104, 0.80160475, 0.81288236]\n",
      "Batch 70/700: Discriminator loss = 1.1924386024475098, GAN loss = [2.3402722, 0.8062117, 0.8490104]\n",
      "Batch 71/700: Discriminator loss = 1.1796164512634277, GAN loss = [2.334322, 0.81329, 0.83603674]\n",
      "Batch 72/700: Discriminator loss = 1.195284366607666, GAN loss = [2.3311028, 0.7975313, 0.8486367]\n",
      "Batch 73/700: Discriminator loss = 1.1772716045379639, GAN loss = [2.309094, 0.812849, 0.8113698]\n",
      "Batch 74/700: Discriminator loss = 1.192158818244934, GAN loss = [2.3108282, 0.79079276, 0.83522105]\n",
      "Batch 75/700: Discriminator loss = 1.1825900077819824, GAN loss = [2.3081782, 0.7960324, 0.8273813]\n",
      "Batch 76/700: Discriminator loss = 1.2136919498443604, GAN loss = [2.2819092, 0.77458924, 0.8225947]\n",
      "Batch 77/700: Discriminator loss = 1.21267569065094, GAN loss = [2.260038, 0.7614856, 0.81386924]\n",
      "Batch 78/700: Discriminator loss = 1.228122591972351, GAN loss = [2.2632005, 0.75421464, 0.82435805]\n",
      "Batch 79/700: Discriminator loss = 1.2014961242675781, GAN loss = [2.266157, 0.7687959, 0.81279325]\n",
      "Batch 80/700: Discriminator loss = 1.1970174312591553, GAN loss = [2.303523, 0.7737781, 0.84523225]\n",
      "Batch 81/700: Discriminator loss = 1.212205171585083, GAN loss = [2.2844858, 0.7740681, 0.8259501]\n",
      "Batch 82/700: Discriminator loss = 1.2320237159729004, GAN loss = [2.2624002, 0.76364654, 0.814342]\n",
      "Batch 83/700: Discriminator loss = 1.2042763233184814, GAN loss = [2.304513, 0.7706996, 0.84945434]\n",
      "Batch 84/700: Discriminator loss = 1.207170844078064, GAN loss = [2.2748444, 0.7558574, 0.83467597]\n",
      "Batch 85/700: Discriminator loss = 1.2336230278015137, GAN loss = [2.2680092, 0.7416968, 0.84204626]\n",
      "Batch 86/700: Discriminator loss = 1.2524960041046143, GAN loss = [2.2681363, 0.7433703, 0.84054947]\n",
      "Batch 87/700: Discriminator loss = 1.1902049779891968, GAN loss = [2.3138618, 0.7831628, 0.8465359]\n",
      "Batch 88/700: Discriminator loss = 1.1978996992111206, GAN loss = [2.2678823, 0.7631929, 0.8205826]\n",
      "Batch 89/700: Discriminator loss = 1.2260398864746094, GAN loss = [2.246214, 0.7504499, 0.8117017]\n",
      "Batch 90/700: Discriminator loss = 1.2410365343093872, GAN loss = [2.1752522, 0.72251374, 0.76872987]\n",
      "Batch 91/700: Discriminator loss = 1.2462658882141113, GAN loss = [2.2160661, 0.72996527, 0.8021549]\n",
      "Batch 92/700: Discriminator loss = 1.2647035121917725, GAN loss = [2.2130527, 0.7111648, 0.8179998]\n",
      "Batch 93/700: Discriminator loss = 1.2215555906295776, GAN loss = [2.2308354, 0.74855113, 0.79844016]\n",
      "Batch 94/700: Discriminator loss = 1.253822922706604, GAN loss = [2.246225, 0.735591, 0.8268327]\n",
      "Batch 95/700: Discriminator loss = 1.2581268548965454, GAN loss = [2.1872084, 0.72382104, 0.77963114]\n",
      "Batch 96/700: Discriminator loss = 1.1953905820846558, GAN loss = [2.2297552, 0.7570932, 0.7889499]\n",
      "Batch 97/700: Discriminator loss = 1.2284456491470337, GAN loss = [2.2008052, 0.7410017, 0.7761321]\n",
      "Batch 98/700: Discriminator loss = 1.2309365272521973, GAN loss = [2.2144244, 0.7566254, 0.7741701]\n",
      "Batch 99/700: Discriminator loss = 1.2287825345993042, GAN loss = [2.2035184, 0.748366, 0.7715633]\n",
      "Batch 100/700: Discriminator loss = 1.2327375411987305, GAN loss = [2.198998, 0.7330894, 0.7823703]\n",
      "Batch 101/700: Discriminator loss = 1.1931041479110718, GAN loss = [2.2379646, 0.7790069, 0.7754633]\n",
      "Batch 102/700: Discriminator loss = 1.1989275217056274, GAN loss = [2.2672162, 0.7645723, 0.81919634]\n",
      "Batch 103/700: Discriminator loss = 1.1903403997421265, GAN loss = [2.2641983, 0.7905691, 0.790221]\n",
      "Batch 104/700: Discriminator loss = 1.2043150663375854, GAN loss = [2.1961899, 0.76534224, 0.74747556]\n",
      "Batch 105/700: Discriminator loss = 1.2439773082733154, GAN loss = [2.2266881, 0.7288425, 0.81450534]\n",
      "Batch 106/700: Discriminator loss = 1.2291234731674194, GAN loss = [2.2719154, 0.73260546, 0.856006]\n",
      "Batch 107/700: Discriminator loss = 1.2505134344100952, GAN loss = [2.2115602, 0.72615325, 0.80213135]\n",
      "Batch 108/700: Discriminator loss = 1.2365845441818237, GAN loss = [2.2088168, 0.743153, 0.78242135]\n",
      "Batch 109/700: Discriminator loss = 1.2342257499694824, GAN loss = [2.1799042, 0.72719073, 0.7694963]\n",
      "Batch 110/700: Discriminator loss = 1.2167080640792847, GAN loss = [2.2701366, 0.7632011, 0.8237443]\n",
      "Batch 111/700: Discriminator loss = 1.2201340198516846, GAN loss = [2.2487483, 0.7438507, 0.8217366]\n",
      "Batch 112/700: Discriminator loss = 1.2311264276504517, GAN loss = [2.2505958, 0.7423943, 0.8250719]\n",
      "Batch 113/700: Discriminator loss = 1.241805076599121, GAN loss = [2.1933105, 0.7343492, 0.7758719]\n",
      "Batch 114/700: Discriminator loss = 1.2064032554626465, GAN loss = [2.23622, 0.7674787, 0.78569365]\n",
      "Batch 115/700: Discriminator loss = 1.2449921369552612, GAN loss = [2.182921, 0.7132064, 0.78669554]\n",
      "Batch 116/700: Discriminator loss = 1.244309902191162, GAN loss = [2.17008, 0.72453153, 0.76255316]\n",
      "Batch 117/700: Discriminator loss = 1.2395820617675781, GAN loss = [2.2043018, 0.7197336, 0.8016121]\n",
      "Batch 118/700: Discriminator loss = 1.244123935699463, GAN loss = [2.1904545, 0.71355414, 0.7939789]\n",
      "Batch 119/700: Discriminator loss = 1.2460168600082397, GAN loss = [2.2068164, 0.72143584, 0.8025008]\n",
      "Batch 120/700: Discriminator loss = 1.2120479345321655, GAN loss = [2.2024853, 0.743202, 0.77643174]\n",
      "Batch 121/700: Discriminator loss = 1.243656039237976, GAN loss = [2.1978524, 0.7129313, 0.8021079]\n",
      "Batch 122/700: Discriminator loss = 1.2398862838745117, GAN loss = [2.1814835, 0.70993346, 0.7887633]\n",
      "Batch 123/700: Discriminator loss = 1.2687979936599731, GAN loss = [2.1650846, 0.6990883, 0.7832359]\n",
      "Batch 124/700: Discriminator loss = 1.2404080629348755, GAN loss = [2.2061946, 0.7214619, 0.80200547]\n",
      "Batch 125/700: Discriminator loss = 1.2208083868026733, GAN loss = [2.211611, 0.72912115, 0.7997979]\n",
      "Batch 126/700: Discriminator loss = 1.2518304586410522, GAN loss = [2.2199376, 0.7186416, 0.81864095]\n",
      "Batch 127/700: Discriminator loss = 1.2404530048370361, GAN loss = [2.2193623, 0.72321945, 0.81351936]\n",
      "Batch 128/700: Discriminator loss = 1.2212705612182617, GAN loss = [2.1986496, 0.7456099, 0.7704388]\n",
      "Batch 129/700: Discriminator loss = 1.2136361598968506, GAN loss = [2.2171104, 0.7412448, 0.7932959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 130/700: Discriminator loss = 1.2232115268707275, GAN loss = [2.221779, 0.7352791, 0.80395347]\n",
      "Batch 131/700: Discriminator loss = 1.2267142534255981, GAN loss = [2.1895154, 0.7261439, 0.7808525]\n",
      "Batch 132/700: Discriminator loss = 1.22854745388031, GAN loss = [2.2576087, 0.74621826, 0.82890403]\n",
      "Batch 133/700: Discriminator loss = 1.2059624195098877, GAN loss = [2.2158625, 0.74009466, 0.7933156]\n",
      "Batch 134/700: Discriminator loss = 1.2064898014068604, GAN loss = [2.228305, 0.74423486, 0.80164605]\n",
      "Batch 135/700: Discriminator loss = 1.240073800086975, GAN loss = [2.195941, 0.70995504, 0.80359]\n",
      "Batch 136/700: Discriminator loss = 1.215238094329834, GAN loss = [2.2287014, 0.7470024, 0.79933095]\n",
      "Batch 137/700: Discriminator loss = 1.2072569131851196, GAN loss = [2.2165632, 0.7477305, 0.78650665]\n",
      "Batch 138/700: Discriminator loss = 1.2195056676864624, GAN loss = [2.24018, 0.74673325, 0.81116915]\n",
      "Batch 139/700: Discriminator loss = 1.217834711074829, GAN loss = [2.1921892, 0.7253243, 0.7846357]\n",
      "Batch 140/700: Discriminator loss = 1.2185012102127075, GAN loss = [2.21126, 0.7343264, 0.7947416]\n",
      "Batch 141/700: Discriminator loss = 1.2298328876495361, GAN loss = [2.2015753, 0.723878, 0.7955439]\n",
      "Batch 142/700: Discriminator loss = 1.2026233673095703, GAN loss = [2.222162, 0.7613751, 0.77867067]\n",
      "Batch 143/700: Discriminator loss = 1.2039896249771118, GAN loss = [2.238607, 0.7494246, 0.8071011]\n",
      "Batch 144/700: Discriminator loss = 1.1877068281173706, GAN loss = [2.2481449, 0.7593725, 0.8067259]\n",
      "Batch 145/700: Discriminator loss = 1.1947318315505981, GAN loss = [2.2584343, 0.75170755, 0.82470846]\n",
      "Batch 146/700: Discriminator loss = 1.1912426948547363, GAN loss = [2.2324672, 0.74343294, 0.80705184]\n",
      "Batch 147/700: Discriminator loss = 1.2056820392608643, GAN loss = [2.2775712, 0.7453365, 0.8502966]\n",
      "Batch 148/700: Discriminator loss = 1.212240219116211, GAN loss = [2.2219002, 0.73114604, 0.80885386]\n",
      "Batch 149/700: Discriminator loss = 1.2064865827560425, GAN loss = [2.2619689, 0.7482984, 0.8318064]\n",
      "Batch 150/700: Discriminator loss = 1.217844009399414, GAN loss = [2.2500093, 0.75171876, 0.81645566]\n",
      "Batch 151/700: Discriminator loss = 1.2058300971984863, GAN loss = [2.239052, 0.7495708, 0.8076735]\n",
      "Batch 152/700: Discriminator loss = 1.228844165802002, GAN loss = [2.2375553, 0.72284216, 0.83292925]\n",
      "Batch 153/700: Discriminator loss = 1.1856735944747925, GAN loss = [2.245289, 0.7556308, 0.8079019]\n",
      "Batch 154/700: Discriminator loss = 1.210638403892517, GAN loss = [2.246736, 0.75879836, 0.80620676]\n",
      "Batch 155/700: Discriminator loss = 1.2152436971664429, GAN loss = [2.2395608, 0.75405765, 0.80380064]\n",
      "Batch 156/700: Discriminator loss = 1.207323431968689, GAN loss = [2.26455, 0.74336565, 0.8395287]\n",
      "Batch 157/700: Discriminator loss = 1.1800585985183716, GAN loss = [2.251542, 0.7673274, 0.80259764]\n",
      "Batch 158/700: Discriminator loss = 1.1860909461975098, GAN loss = [2.277335, 0.7692133, 0.8265364]\n",
      "Batch 159/700: Discriminator loss = 1.2174824476242065, GAN loss = [2.2647452, 0.7525206, 0.8306793]\n",
      "Batch 160/700: Discriminator loss = 1.1835639476776123, GAN loss = [2.3359618, 0.77959776, 0.8748605]\n",
      "Batch 161/700: Discriminator loss = 1.1829211711883545, GAN loss = [2.3387074, 0.7872737, 0.86996615]\n",
      "Batch 162/700: Discriminator loss = 1.1626394987106323, GAN loss = [2.3275084, 0.793821, 0.8522385]\n",
      "Batch 163/700: Discriminator loss = 1.1819894313812256, GAN loss = [2.3043263, 0.7710195, 0.8518875]\n",
      "Batch 164/700: Discriminator loss = 1.189207911491394, GAN loss = [2.2995481, 0.76657355, 0.85159075]\n",
      "Batch 165/700: Discriminator loss = 1.1756067276000977, GAN loss = [2.3444767, 0.77603257, 0.88709724]\n",
      "Batch 166/700: Discriminator loss = 1.212705135345459, GAN loss = [2.2358673, 0.74764085, 0.8069223]\n",
      "Batch 167/700: Discriminator loss = 1.2234715223312378, GAN loss = [2.313857, 0.7448378, 0.88775957]\n",
      "Batch 168/700: Discriminator loss = 1.217812418937683, GAN loss = [2.2841797, 0.73867875, 0.86427766]\n",
      "Batch 169/700: Discriminator loss = 1.205377221107483, GAN loss = [2.3013134, 0.7590409, 0.8610797]\n",
      "Batch 170/700: Discriminator loss = 1.2380238771438599, GAN loss = [2.2295775, 0.7188923, 0.8295203]\n",
      "Batch 171/700: Discriminator loss = 1.199668526649475, GAN loss = [2.2671666, 0.7531454, 0.83290327]\n",
      "Batch 172/700: Discriminator loss = 1.1853548288345337, GAN loss = [2.304962, 0.7595292, 0.8643586]\n",
      "Batch 173/700: Discriminator loss = 1.2025517225265503, GAN loss = [2.2764368, 0.74840856, 0.8469913]\n",
      "Batch 174/700: Discriminator loss = 1.2279983758926392, GAN loss = [2.2412674, 0.7243522, 0.83592135]\n",
      "Batch 175/700: Discriminator loss = 1.2063052654266357, GAN loss = [2.2748587, 0.74908876, 0.84481454]\n",
      "Batch 176/700: Discriminator loss = 1.1935595273971558, GAN loss = [2.3019989, 0.7599671, 0.8611195]\n",
      "Batch 177/700: Discriminator loss = 1.2191332578659058, GAN loss = [2.2893214, 0.7423222, 0.86614084]\n",
      "Batch 178/700: Discriminator loss = 1.2276533842086792, GAN loss = [2.2489479, 0.7290955, 0.8390389]\n",
      "Batch 179/700: Discriminator loss = 1.2060860395431519, GAN loss = [2.2731807, 0.75066304, 0.84173703]\n",
      "Batch 180/700: Discriminator loss = 1.2011741399765015, GAN loss = [2.3126752, 0.76496285, 0.8669641]\n",
      "Batch 181/700: Discriminator loss = 1.2223531007766724, GAN loss = [2.236417, 0.7336807, 0.8220177]\n",
      "Batch 182/700: Discriminator loss = 1.2078875303268433, GAN loss = [2.2630196, 0.73682094, 0.8455122]\n",
      "Batch 183/700: Discriminator loss = 1.2348058223724365, GAN loss = [2.256785, 0.72811097, 0.8480194]\n",
      "Batch 184/700: Discriminator loss = 1.2163820266723633, GAN loss = [2.249015, 0.73864555, 0.82975316]\n",
      "Batch 185/700: Discriminator loss = 1.2514301538467407, GAN loss = [2.2081623, 0.7129905, 0.8145926]\n",
      "Batch 186/700: Discriminator loss = 1.2229264974594116, GAN loss = [2.2937503, 0.7411643, 0.8720491]\n",
      "Batch 187/700: Discriminator loss = 1.2152012586593628, GAN loss = [2.2512877, 0.7429043, 0.8278948]\n",
      "Batch 188/700: Discriminator loss = 1.2073652744293213, GAN loss = [2.2354136, 0.7510649, 0.8038918]\n",
      "Batch 189/700: Discriminator loss = 1.2083793878555298, GAN loss = [2.237117, 0.7474681, 0.8092295]\n",
      "Batch 190/700: Discriminator loss = 1.2156968116760254, GAN loss = [2.235815, 0.72555053, 0.82987595]\n",
      "Batch 191/700: Discriminator loss = 1.240660309791565, GAN loss = [2.2284226, 0.7225066, 0.8255531]\n",
      "Batch 192/700: Discriminator loss = 1.2194364070892334, GAN loss = [2.227865, 0.74121046, 0.80632216]\n",
      "Batch 193/700: Discriminator loss = 1.2162597179412842, GAN loss = [2.2539287, 0.7343859, 0.8392536]\n",
      "Batch 194/700: Discriminator loss = 1.2172245979309082, GAN loss = [2.280588, 0.7617951, 0.83853936]\n",
      "Batch 195/700: Discriminator loss = 1.203783392906189, GAN loss = [2.243081, 0.74545914, 0.8173807]\n",
      "Batch 196/700: Discriminator loss = 1.2180696725845337, GAN loss = [2.2267163, 0.7293053, 0.81717896]\n",
      "Batch 197/700: Discriminator loss = 1.2250982522964478, GAN loss = [2.2131488, 0.73532355, 0.79760164]\n",
      "Batch 198/700: Discriminator loss = 1.210291862487793, GAN loss = [2.2535126, 0.7445712, 0.8287362]\n",
      "Batch 199/700: Discriminator loss = 1.2323477268218994, GAN loss = [2.2312822, 0.72738546, 0.8237043]\n",
      "Batch 200/700: Discriminator loss = 1.2073018550872803, GAN loss = [2.255487, 0.7549048, 0.82040995]\n",
      "Batch 201/700: Discriminator loss = 1.2189565896987915, GAN loss = [2.2709723, 0.76918775, 0.82162786]\n",
      "Batch 202/700: Discriminator loss = 1.236020565032959, GAN loss = [2.2129717, 0.73137695, 0.8014317]\n",
      "Batch 203/700: Discriminator loss = 1.223516583442688, GAN loss = [2.1930459, 0.7387643, 0.77412933]\n",
      "Batch 204/700: Discriminator loss = 1.2261805534362793, GAN loss = [2.2455776, 0.7300202, 0.83541787]\n",
      "Batch 205/700: Discriminator loss = 1.2120546102523804, GAN loss = [2.2591403, 0.7664054, 0.8126001]\n",
      "Batch 206/700: Discriminator loss = 1.2386261224746704, GAN loss = [2.2415597, 0.73184097, 0.8295842]\n",
      "Batch 207/700: Discriminator loss = 1.2458312511444092, GAN loss = [2.2866552, 0.7697008, 0.8368217]\n",
      "Batch 208/700: Discriminator loss = 1.2154396772384644, GAN loss = [2.262178, 0.7410003, 0.8410373]\n",
      "Batch 209/700: Discriminator loss = 1.1930615901947021, GAN loss = [2.34886, 0.77353513, 0.8951907]\n",
      "Batch 210/700: Discriminator loss = 1.2214945554733276, GAN loss = [2.2500908, 0.74015164, 0.8298123]\n",
      "Batch 211/700: Discriminator loss = 1.2119969129562378, GAN loss = [2.289405, 0.7575485, 0.85173416]\n",
      "Batch 212/700: Discriminator loss = 1.2491852045059204, GAN loss = [2.2601447, 0.719077, 0.86096185]\n",
      "Batch 213/700: Discriminator loss = 1.2049754858016968, GAN loss = [2.30698, 0.75063413, 0.87625283]\n",
      "Batch 214/700: Discriminator loss = 1.220489501953125, GAN loss = [2.2566452, 0.74646074, 0.8300967]\n",
      "Batch 215/700: Discriminator loss = 1.2198797464370728, GAN loss = [2.3016794, 0.7514418, 0.87016904]\n",
      "Batch 216/700: Discriminator loss = 1.221947431564331, GAN loss = [2.252198, 0.7452883, 0.82686776]\n",
      "Batch 217/700: Discriminator loss = 1.1895614862442017, GAN loss = [2.286355, 0.7582653, 0.8480667]\n",
      "Batch 218/700: Discriminator loss = 1.2036088705062866, GAN loss = [2.244885, 0.74714476, 0.81774825]\n",
      "Batch 219/700: Discriminator loss = 1.1842677593231201, GAN loss = [2.3677118, 0.75979686, 0.9279532]\n",
      "Batch 220/700: Discriminator loss = 1.1815587282180786, GAN loss = [2.3351636, 0.7728463, 0.8823818]\n",
      "Batch 221/700: Discriminator loss = 1.2039363384246826, GAN loss = [2.233736, 0.74267334, 0.81114775]\n",
      "Batch 222/700: Discriminator loss = 1.200539231300354, GAN loss = [2.2368248, 0.7475584, 0.80937076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 223/700: Discriminator loss = 1.180401086807251, GAN loss = [2.3293207, 0.7743976, 0.8750439]\n",
      "Batch 224/700: Discriminator loss = 1.2085691690444946, GAN loss = [2.2833014, 0.755915, 0.847522]\n",
      "Batch 225/700: Discriminator loss = 1.204694390296936, GAN loss = [2.2767577, 0.7459944, 0.8509088]\n",
      "Batch 226/700: Discriminator loss = 1.201061725616455, GAN loss = [2.2723596, 0.74967974, 0.8428249]\n",
      "Batch 227/700: Discriminator loss = 1.2133299112319946, GAN loss = [2.3571196, 0.7396479, 0.9376381]\n",
      "Batch 228/700: Discriminator loss = 1.2320500612258911, GAN loss = [2.3035536, 0.738663, 0.88507617]\n",
      "Batch 229/700: Discriminator loss = 1.2085272073745728, GAN loss = [2.3215768, 0.74539423, 0.89639]\n",
      "Batch 230/700: Discriminator loss = 1.2108904123306274, GAN loss = [2.2994256, 0.7464979, 0.87314767]\n",
      "Batch 231/700: Discriminator loss = 1.2184830904006958, GAN loss = [2.2641273, 0.7497935, 0.8345545]\n",
      "Batch 232/700: Discriminator loss = 1.2391862869262695, GAN loss = [2.2253034, 0.7253845, 0.82012343]\n",
      "Batch 233/700: Discriminator loss = 1.2370448112487793, GAN loss = [2.2877924, 0.7350448, 0.87294745]\n",
      "Batch 234/700: Discriminator loss = 1.232196569442749, GAN loss = [2.2266078, 0.7416886, 0.80511224]\n",
      "Batch 235/700: Discriminator loss = 1.2482043504714966, GAN loss = [2.2606661, 0.7367693, 0.84410006]\n",
      "Batch 236/700: Discriminator loss = 1.2609224319458008, GAN loss = [2.223994, 0.73551446, 0.8086949]\n",
      "Batch 237/700: Discriminator loss = 1.2843101024627686, GAN loss = [2.188765, 0.70869905, 0.80029404]\n",
      "Batch 238/700: Discriminator loss = 1.2521344423294067, GAN loss = [2.2039113, 0.7177249, 0.80642617]\n",
      "Batch 239/700: Discriminator loss = 1.2391552925109863, GAN loss = [2.2307353, 0.73717093, 0.8138229]\n",
      "Batch 240/700: Discriminator loss = 1.250004529953003, GAN loss = [2.2203166, 0.72790086, 0.8126885]\n",
      "Batch 241/700: Discriminator loss = 1.2711973190307617, GAN loss = [2.215398, 0.7180284, 0.8176834]\n",
      "Batch 242/700: Discriminator loss = 1.2646410465240479, GAN loss = [2.2008784, 0.7184632, 0.8027693]\n",
      "Batch 243/700: Discriminator loss = 1.2323834896087646, GAN loss = [2.2122986, 0.7396315, 0.79305464]\n",
      "Batch 244/700: Discriminator loss = 1.2593883275985718, GAN loss = [2.215994, 0.7214516, 0.81496084]\n",
      "Batch 245/700: Discriminator loss = 1.243863582611084, GAN loss = [2.2023456, 0.7311262, 0.79167557]\n",
      "Batch 246/700: Discriminator loss = 1.2304372787475586, GAN loss = [2.2008872, 0.74393946, 0.7774239]\n",
      "Batch 247/700: Discriminator loss = 1.2313114404678345, GAN loss = [2.213942, 0.739105, 0.7953399]\n",
      "Batch 248/700: Discriminator loss = 1.2275885343551636, GAN loss = [2.1690726, 0.74583924, 0.74377]\n",
      "Batch 249/700: Discriminator loss = 1.220102071762085, GAN loss = [2.2166975, 0.7422921, 0.79495984]\n",
      "Batch 250/700: Discriminator loss = 1.2111256122589111, GAN loss = [2.2125416, 0.74100035, 0.7921142]\n",
      "Batch 251/700: Discriminator loss = 1.2119077444076538, GAN loss = [2.2387772, 0.74500203, 0.81436867]\n",
      "Batch 252/700: Discriminator loss = 1.2061302661895752, GAN loss = [2.2650554, 0.750273, 0.8353892]\n",
      "Batch 253/700: Discriminator loss = 1.2114189863204956, GAN loss = [2.254138, 0.75321436, 0.82155275]\n",
      "Batch 254/700: Discriminator loss = 1.2090121507644653, GAN loss = [2.243718, 0.7618514, 0.802519]\n",
      "Batch 255/700: Discriminator loss = 1.1918983459472656, GAN loss = [2.2299263, 0.76651454, 0.7840808]\n",
      "Batch 256/700: Discriminator loss = 1.1794508695602417, GAN loss = [2.2645788, 0.77772444, 0.80754775]\n",
      "Batch 257/700: Discriminator loss = 1.1745144128799438, GAN loss = [2.2768388, 0.7787127, 0.8188343]\n",
      "Batch 258/700: Discriminator loss = 1.1823691129684448, GAN loss = [2.2415218, 0.7663353, 0.79590243]\n",
      "Batch 259/700: Discriminator loss = 1.2021708488464355, GAN loss = [2.234511, 0.75420487, 0.80102944]\n",
      "Batch 260/700: Discriminator loss = 1.1885217428207397, GAN loss = [2.2871616, 0.78444827, 0.82343394]\n",
      "Batch 261/700: Discriminator loss = 1.2211072444915771, GAN loss = [2.2671373, 0.75344175, 0.8344102]\n",
      "Batch 262/700: Discriminator loss = 1.197473168373108, GAN loss = [2.283115, 0.76109624, 0.84274316]\n",
      "Batch 263/700: Discriminator loss = 1.2165946960449219, GAN loss = [2.2198827, 0.7358988, 0.8047202]\n",
      "Batch 264/700: Discriminator loss = 1.202510118484497, GAN loss = [2.2575688, 0.7484322, 0.8298923]\n",
      "Batch 265/700: Discriminator loss = 1.2370409965515137, GAN loss = [2.2259054, 0.73159754, 0.815092]\n",
      "Batch 266/700: Discriminator loss = 1.2319391965866089, GAN loss = [2.19368, 0.73404914, 0.7804388]\n",
      "Batch 267/700: Discriminator loss = 1.1982247829437256, GAN loss = [2.249195, 0.7591414, 0.8108728]\n",
      "Batch 268/700: Discriminator loss = 1.2138391733169556, GAN loss = [2.240345, 0.7404043, 0.82076895]\n",
      "Batch 269/700: Discriminator loss = 1.2130565643310547, GAN loss = [2.2890294, 0.7478817, 0.86199236]\n",
      "Batch 270/700: Discriminator loss = 1.2019609212875366, GAN loss = [2.2648246, 0.7352345, 0.8504457]\n",
      "Batch 271/700: Discriminator loss = 1.2185777425765991, GAN loss = [2.254698, 0.7468098, 0.82874656]\n",
      "Batch 272/700: Discriminator loss = 1.2178866863250732, GAN loss = [2.2395997, 0.7363504, 0.8241079]\n",
      "Batch 273/700: Discriminator loss = 1.21108877658844, GAN loss = [2.2691708, 0.744609, 0.8454251]\n",
      "Batch 274/700: Discriminator loss = 1.2129265069961548, GAN loss = [2.2434337, 0.7388798, 0.8254311]\n",
      "Batch 275/700: Discriminator loss = 1.2185218334197998, GAN loss = [2.29259, 0.73227143, 0.8812169]\n",
      "Batch 276/700: Discriminator loss = 1.2188338041305542, GAN loss = [2.2761173, 0.742594, 0.85443145]\n",
      "Batch 277/700: Discriminator loss = 1.2448604106903076, GAN loss = [2.252226, 0.737514, 0.8356235]\n",
      "Batch 278/700: Discriminator loss = 1.202642798423767, GAN loss = [2.3220458, 0.75394523, 0.8890218]\n",
      "Batch 279/700: Discriminator loss = 1.195641040802002, GAN loss = [2.280172, 0.76189744, 0.83920336]\n",
      "Batch 280/700: Discriminator loss = 1.2245514392852783, GAN loss = [2.249251, 0.73634386, 0.83386755]\n",
      "Batch 281/700: Discriminator loss = 1.2018243074417114, GAN loss = [2.267202, 0.7573359, 0.8308408]\n",
      "Batch 282/700: Discriminator loss = 1.2145938873291016, GAN loss = [2.354376, 0.7632963, 0.9120698]\n",
      "Batch 283/700: Discriminator loss = 1.1882917881011963, GAN loss = [2.2846992, 0.75851387, 0.847175]\n",
      "Batch 284/700: Discriminator loss = 1.21011221408844, GAN loss = [2.2619686, 0.7459618, 0.83700395]\n",
      "Batch 285/700: Discriminator loss = 1.2169158458709717, GAN loss = [2.2239726, 0.742311, 0.8026632]\n",
      "Batch 286/700: Discriminator loss = 1.2264502048492432, GAN loss = [2.2432187, 0.7304213, 0.83382106]\n",
      "Batch 287/700: Discriminator loss = 1.1988754272460938, GAN loss = [2.3149354, 0.75160056, 0.88436663]\n",
      "Batch 288/700: Discriminator loss = 1.2234890460968018, GAN loss = [2.2670617, 0.73674464, 0.85136276]\n",
      "Batch 289/700: Discriminator loss = 1.2538081407546997, GAN loss = [2.2394307, 0.7169809, 0.84352136]\n",
      "Batch 290/700: Discriminator loss = 1.2249659299850464, GAN loss = [2.2257044, 0.7301256, 0.8166729]\n",
      "Batch 291/700: Discriminator loss = 1.2215865850448608, GAN loss = [2.215387, 0.7400346, 0.7964575]\n",
      "Batch 292/700: Discriminator loss = 1.2543928623199463, GAN loss = [2.2242515, 0.70955354, 0.8357991]\n",
      "Batch 293/700: Discriminator loss = 1.241873025894165, GAN loss = [2.223161, 0.7163502, 0.8279051]\n",
      "Batch 294/700: Discriminator loss = 1.2238185405731201, GAN loss = [2.2035449, 0.7411516, 0.78348696]\n",
      "Batch 295/700: Discriminator loss = 1.2530039548873901, GAN loss = [2.2610314, 0.7198001, 0.8623279]\n",
      "Batch 296/700: Discriminator loss = 1.2155150175094604, GAN loss = [2.2160888, 0.73512787, 0.8020488]\n",
      "Batch 297/700: Discriminator loss = 1.2303909063339233, GAN loss = [2.176326, 0.7327195, 0.7646951]\n",
      "Batch 298/700: Discriminator loss = 1.2117161750793457, GAN loss = [2.2397733, 0.75001144, 0.8108558]\n",
      "Batch 299/700: Discriminator loss = 1.2362840175628662, GAN loss = [2.2243307, 0.74611264, 0.7993373]\n",
      "Batch 300/700: Discriminator loss = 1.228365182876587, GAN loss = [2.188183, 0.7291742, 0.78015554]\n",
      "Batch 301/700: Discriminator loss = 1.2398828268051147, GAN loss = [2.1797884, 0.71560335, 0.7853501]\n",
      "Batch 302/700: Discriminator loss = 1.2405569553375244, GAN loss = [2.1710494, 0.716843, 0.7753817]\n",
      "Batch 303/700: Discriminator loss = 1.2309160232543945, GAN loss = [2.231327, 0.74510854, 0.80740595]\n",
      "Batch 304/700: Discriminator loss = 1.2955193519592285, GAN loss = [2.148947, 0.69634247, 0.77380854]\n",
      "Batch 305/700: Discriminator loss = 1.244831919670105, GAN loss = [2.1747303, 0.7197451, 0.77620775]\n",
      "Batch 306/700: Discriminator loss = 1.2352797985076904, GAN loss = [2.1925337, 0.7307694, 0.7830051]\n",
      "Batch 307/700: Discriminator loss = 1.2416026592254639, GAN loss = [2.198434, 0.75076294, 0.7689347]\n",
      "Batch 308/700: Discriminator loss = 1.2230937480926514, GAN loss = [2.1782858, 0.7218205, 0.7777419]\n",
      "Batch 309/700: Discriminator loss = 1.2388718128204346, GAN loss = [2.1896212, 0.7106661, 0.80024683]\n",
      "Batch 310/700: Discriminator loss = 1.2373297214508057, GAN loss = [2.1824665, 0.71740836, 0.78637487]\n",
      "Batch 311/700: Discriminator loss = 1.2263139486312866, GAN loss = [2.1775992, 0.72084814, 0.7781089]\n",
      "Batch 312/700: Discriminator loss = 1.2137788534164429, GAN loss = [2.2177804, 0.73047084, 0.80869424]\n",
      "Batch 313/700: Discriminator loss = 1.2264662981033325, GAN loss = [2.1881258, 0.7219309, 0.78760755]\n",
      "Batch 314/700: Discriminator loss = 1.2286648750305176, GAN loss = [2.1750126, 0.7172691, 0.77917093]\n",
      "Batch 315/700: Discriminator loss = 1.2516460418701172, GAN loss = [2.184941, 0.71499085, 0.79139894]\n",
      "Batch 316/700: Discriminator loss = 1.2369694709777832, GAN loss = [2.202711, 0.7027326, 0.82146716]\n",
      "Batch 317/700: Discriminator loss = 1.2325555086135864, GAN loss = [2.1790574, 0.71804476, 0.7825386]\n",
      "Batch 318/700: Discriminator loss = 1.2207731008529663, GAN loss = [2.195546, 0.7248694, 0.7922418]\n",
      "Batch 319/700: Discriminator loss = 1.2255438566207886, GAN loss = [2.1603394, 0.72696185, 0.7549733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 320/700: Discriminator loss = 1.2133554220199585, GAN loss = [2.1927836, 0.73690337, 0.77752084]\n",
      "Batch 321/700: Discriminator loss = 1.2107746601104736, GAN loss = [2.189546, 0.7278266, 0.7833949]\n",
      "Batch 322/700: Discriminator loss = 1.217392921447754, GAN loss = [2.2153254, 0.730032, 0.80700773]\n",
      "Batch 323/700: Discriminator loss = 1.190316915512085, GAN loss = [2.1974382, 0.750288, 0.76889914]\n",
      "Batch 324/700: Discriminator loss = 1.2193562984466553, GAN loss = [2.192607, 0.7187368, 0.7956461]\n",
      "Batch 325/700: Discriminator loss = 1.2145421504974365, GAN loss = [2.2088845, 0.7247453, 0.80593264]\n",
      "Batch 326/700: Discriminator loss = 1.221448302268982, GAN loss = [2.2236633, 0.7305887, 0.81489426]\n",
      "Batch 327/700: Discriminator loss = 1.2032921314239502, GAN loss = [2.245837, 0.7551567, 0.812521]\n",
      "Batch 328/700: Discriminator loss = 1.2120497226715088, GAN loss = [2.220768, 0.7319902, 0.81064004]\n",
      "Batch 329/700: Discriminator loss = 1.1900562047958374, GAN loss = [2.2150095, 0.7430068, 0.7939006]\n",
      "Batch 330/700: Discriminator loss = 1.2040613889694214, GAN loss = [2.24268, 0.7461491, 0.81847936]\n",
      "Batch 331/700: Discriminator loss = 1.225672960281372, GAN loss = [2.2058592, 0.72137034, 0.80649114]\n",
      "Batch 332/700: Discriminator loss = 1.2137099504470825, GAN loss = [2.1858478, 0.7248028, 0.78309196]\n",
      "Batch 333/700: Discriminator loss = 1.1926411390304565, GAN loss = [2.2500424, 0.7483933, 0.8237416]\n",
      "Batch 334/700: Discriminator loss = 1.219248652458191, GAN loss = [2.2161453, 0.72518533, 0.8131018]\n",
      "Batch 335/700: Discriminator loss = 1.2332996129989624, GAN loss = [2.1990178, 0.7161673, 0.8050338]\n",
      "Batch 336/700: Discriminator loss = 1.2005988359451294, GAN loss = [2.2775185, 0.7458665, 0.85388124]\n",
      "Batch 337/700: Discriminator loss = 1.2135928869247437, GAN loss = [2.2083502, 0.722213, 0.8084034]\n",
      "Batch 338/700: Discriminator loss = 1.1931064128875732, GAN loss = [2.2288916, 0.7439885, 0.80720794]\n",
      "Batch 339/700: Discriminator loss = 1.1991302967071533, GAN loss = [2.2706857, 0.75249565, 0.8405315]\n",
      "Batch 340/700: Discriminator loss = 1.2049317359924316, GAN loss = [2.2155042, 0.73833007, 0.7995545]\n",
      "Batch 341/700: Discriminator loss = 1.2221007347106934, GAN loss = [2.2170274, 0.7182538, 0.8211967]\n",
      "Batch 342/700: Discriminator loss = 1.204199194908142, GAN loss = [2.1860359, 0.7438937, 0.7646043]\n",
      "Batch 343/700: Discriminator loss = 1.195618748664856, GAN loss = [2.2257316, 0.7452654, 0.8029714]\n",
      "Batch 344/700: Discriminator loss = 1.2202539443969727, GAN loss = [2.1932561, 0.72933364, 0.7864702]\n",
      "Batch 345/700: Discriminator loss = 1.1647889614105225, GAN loss = [2.316099, 0.77524984, 0.86343324]\n",
      "Batch 346/700: Discriminator loss = 1.2142165899276733, GAN loss = [2.2527122, 0.72214717, 0.8531862]\n",
      "Batch 347/700: Discriminator loss = 1.2037643194198608, GAN loss = [2.1944284, 0.73347837, 0.7836121]\n",
      "Batch 348/700: Discriminator loss = 1.2236934900283813, GAN loss = [2.1880238, 0.71771765, 0.793009]\n",
      "Batch 349/700: Discriminator loss = 1.1887218952178955, GAN loss = [2.2330985, 0.75343835, 0.802416]\n",
      "Batch 350/700: Discriminator loss = 1.217785120010376, GAN loss = [2.2046187, 0.72722274, 0.8001995]\n",
      "Batch 351/700: Discriminator loss = 1.1990166902542114, GAN loss = [2.2094908, 0.7490019, 0.78333837]\n",
      "Batch 352/700: Discriminator loss = 1.222945213317871, GAN loss = [2.2103267, 0.7221267, 0.81109166]\n",
      "Batch 353/700: Discriminator loss = 1.2050249576568604, GAN loss = [2.1641135, 0.73895806, 0.7480803]\n",
      "Batch 354/700: Discriminator loss = 1.1907237768173218, GAN loss = [2.2458987, 0.76098996, 0.8078856]\n",
      "Batch 355/700: Discriminator loss = 1.1960415840148926, GAN loss = [2.2589054, 0.75526166, 0.8266718]\n",
      "Batch 356/700: Discriminator loss = 1.2151318788528442, GAN loss = [2.2082367, 0.7341287, 0.79717684]\n",
      "Batch 357/700: Discriminator loss = 1.223634123802185, GAN loss = [2.2189925, 0.72414935, 0.8179468]\n",
      "Batch 358/700: Discriminator loss = 1.2054935693740845, GAN loss = [2.208199, 0.74269426, 0.78865725]\n",
      "Batch 359/700: Discriminator loss = 1.2246416807174683, GAN loss = [2.2165427, 0.71904474, 0.82070524]\n",
      "Batch 360/700: Discriminator loss = 1.2137683629989624, GAN loss = [2.203898, 0.7215937, 0.80555284]\n",
      "Batch 361/700: Discriminator loss = 1.2269450426101685, GAN loss = [2.2083845, 0.7084993, 0.82316774]\n",
      "Batch 362/700: Discriminator loss = 1.2222254276275635, GAN loss = [2.2017164, 0.7140015, 0.8110163]\n",
      "Batch 363/700: Discriminator loss = 1.2139363288879395, GAN loss = [2.174066, 0.7232472, 0.7741478]\n",
      "Batch 364/700: Discriminator loss = 1.225490689277649, GAN loss = [2.1975856, 0.71925324, 0.80168843]\n",
      "Batch 365/700: Discriminator loss = 1.213079571723938, GAN loss = [2.2246797, 0.7181637, 0.8299016]\n",
      "Batch 366/700: Discriminator loss = 1.2357407808303833, GAN loss = [2.1932223, 0.7302006, 0.7864352]\n",
      "Batch 367/700: Discriminator loss = 1.2484991550445557, GAN loss = [2.1727712, 0.7109039, 0.78531426]\n",
      "Batch 368/700: Discriminator loss = 1.2202197313308716, GAN loss = [2.2143128, 0.73569757, 0.802084]\n",
      "Batch 369/700: Discriminator loss = 1.2468302249908447, GAN loss = [2.195126, 0.7060217, 0.81258035]\n",
      "Batch 370/700: Discriminator loss = 1.2173482179641724, GAN loss = [2.2025278, 0.7312119, 0.7947856]\n",
      "Batch 371/700: Discriminator loss = 1.212781310081482, GAN loss = [2.2278621, 0.73696, 0.8143842]\n",
      "Batch 372/700: Discriminator loss = 1.2511812448501587, GAN loss = [2.204863, 0.70774794, 0.820625]\n",
      "Batch 373/700: Discriminator loss = 1.1982073783874512, GAN loss = [2.236679, 0.7448764, 0.8153327]\n",
      "Batch 374/700: Discriminator loss = 1.2606723308563232, GAN loss = [2.18239, 0.6914328, 0.81450164]\n",
      "Batch 375/700: Discriminator loss = 1.2209479808807373, GAN loss = [2.2303967, 0.72460914, 0.8293377]\n",
      "Batch 376/700: Discriminator loss = 1.2460745573043823, GAN loss = [2.1811457, 0.7141156, 0.7905841]\n",
      "Batch 377/700: Discriminator loss = 1.2039623260498047, GAN loss = [2.216097, 0.74774826, 0.7919184]\n",
      "Batch 378/700: Discriminator loss = 1.262819766998291, GAN loss = [2.1799922, 0.7137917, 0.7897866]\n",
      "Batch 379/700: Discriminator loss = 1.2355928421020508, GAN loss = [2.1836233, 0.71260345, 0.79462606]\n",
      "Batch 380/700: Discriminator loss = 1.2104125022888184, GAN loss = [2.1920116, 0.74325234, 0.7723885]\n",
      "Batch 381/700: Discriminator loss = 1.2432564496994019, GAN loss = [2.249298, 0.7284211, 0.84454376]\n",
      "Batch 382/700: Discriminator loss = 1.207607388496399, GAN loss = [2.2404583, 0.73630494, 0.82784307]\n",
      "Batch 383/700: Discriminator loss = 1.203018069267273, GAN loss = [2.2273755, 0.7579214, 0.7931616]\n",
      "Batch 384/700: Discriminator loss = 1.2030971050262451, GAN loss = [2.259708, 0.753828, 0.82960165]\n",
      "Batch 385/700: Discriminator loss = 1.220198392868042, GAN loss = [2.2053366, 0.7420008, 0.78708184]\n",
      "Batch 386/700: Discriminator loss = 1.214409351348877, GAN loss = [2.2539124, 0.7380297, 0.83964723]\n",
      "Batch 387/700: Discriminator loss = 1.1906338930130005, GAN loss = [2.2378097, 0.7603585, 0.8012338]\n",
      "Batch 388/700: Discriminator loss = 1.195108413696289, GAN loss = [2.2403543, 0.7564416, 0.8077257]\n",
      "Batch 389/700: Discriminator loss = 1.2472178936004639, GAN loss = [2.2261608, 0.7135506, 0.83643585]\n",
      "Batch 390/700: Discriminator loss = 1.2254999876022339, GAN loss = [2.2007718, 0.72711456, 0.7974992]\n",
      "Batch 391/700: Discriminator loss = 1.2106499671936035, GAN loss = [2.272388, 0.7553294, 0.8409302]\n",
      "Batch 392/700: Discriminator loss = 1.2368062734603882, GAN loss = [2.19569, 0.7200546, 0.7995285]\n",
      "Batch 393/700: Discriminator loss = 1.1979364156723022, GAN loss = [2.199958, 0.7369693, 0.78690094]\n",
      "Batch 394/700: Discriminator loss = 1.2409636974334717, GAN loss = [2.233237, 0.7091335, 0.848042]\n",
      "Batch 395/700: Discriminator loss = 1.250758409500122, GAN loss = [2.1910214, 0.7092808, 0.805705]\n",
      "Batch 396/700: Discriminator loss = 1.2319438457489014, GAN loss = [2.1584578, 0.71889025, 0.7635613]\n",
      "Batch 397/700: Discriminator loss = 1.2373157739639282, GAN loss = [2.1586404, 0.7116902, 0.770974]\n",
      "Batch 398/700: Discriminator loss = 1.2421889305114746, GAN loss = [2.1489422, 0.699658, 0.7733394]\n",
      "Batch 399/700: Discriminator loss = 1.2415695190429688, GAN loss = [2.2535899, 0.70997775, 0.86768675]\n",
      "Batch 400/700: Discriminator loss = 1.2362600564956665, GAN loss = [2.1869507, 0.71075875, 0.8002875]\n",
      "Batch 401/700: Discriminator loss = 1.217647671699524, GAN loss = [2.211084, 0.74630934, 0.78888917]\n",
      "Batch 402/700: Discriminator loss = 1.2443920373916626, GAN loss = [2.2014737, 0.7046268, 0.82099116]\n",
      "Batch 403/700: Discriminator loss = 1.250591516494751, GAN loss = [2.178223, 0.7177333, 0.784673]\n",
      "Batch 404/700: Discriminator loss = 1.2112493515014648, GAN loss = [2.2043805, 0.73035544, 0.79823995]\n",
      "Batch 405/700: Discriminator loss = 1.2246493101119995, GAN loss = [2.2142115, 0.74372596, 0.79472816]\n",
      "Batch 406/700: Discriminator loss = 1.2119206190109253, GAN loss = [2.2232168, 0.7309491, 0.81653756]\n",
      "Batch 407/700: Discriminator loss = 1.2130322456359863, GAN loss = [2.2351794, 0.7385314, 0.8209433]\n",
      "Batch 408/700: Discriminator loss = 1.2278213500976562, GAN loss = [2.2139816, 0.72031385, 0.8179805]\n",
      "Batch 409/700: Discriminator loss = 1.1931945085525513, GAN loss = [2.2661755, 0.76999617, 0.8205142]\n",
      "Batch 410/700: Discriminator loss = 1.1849220991134644, GAN loss = [2.2239134, 0.7637402, 0.7845161]\n",
      "Batch 411/700: Discriminator loss = 1.1900514364242554, GAN loss = [2.2267492, 0.76077616, 0.7903199]\n",
      "Batch 412/700: Discriminator loss = 1.2002902030944824, GAN loss = [2.199955, 0.7518986, 0.77241755]\n",
      "Batch 413/700: Discriminator loss = 1.1900440454483032, GAN loss = [2.2527814, 0.75985074, 0.8173207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 414/700: Discriminator loss = 1.1847732067108154, GAN loss = [2.2446668, 0.7519709, 0.8171149]\n",
      "Batch 415/700: Discriminator loss = 1.1884671449661255, GAN loss = [2.2571783, 0.7508573, 0.83077055]\n",
      "Batch 416/700: Discriminator loss = 1.2270115613937378, GAN loss = [2.2189772, 0.72786933, 0.8155673]\n",
      "Batch 417/700: Discriminator loss = 1.1970349550247192, GAN loss = [2.25469, 0.7574575, 0.8216937]\n",
      "Batch 418/700: Discriminator loss = 1.1976734399795532, GAN loss = [2.251128, 0.7479156, 0.8276888]\n",
      "Batch 419/700: Discriminator loss = 1.1993136405944824, GAN loss = [2.2454262, 0.7419903, 0.8279198]\n",
      "Batch 420/700: Discriminator loss = 1.2156047821044922, GAN loss = [2.1630917, 0.72470313, 0.7628865]\n",
      "Batch 421/700: Discriminator loss = 1.2231738567352295, GAN loss = [2.2427483, 0.7246813, 0.84257835]\n",
      "Batch 422/700: Discriminator loss = 1.2491458654403687, GAN loss = [2.1529245, 0.715808, 0.76163274]\n",
      "Batch 423/700: Discriminator loss = 1.2263020277023315, GAN loss = [2.1994414, 0.7178118, 0.8061407]\n",
      "Batch 424/700: Discriminator loss = 1.230711579322815, GAN loss = [2.2323022, 0.71811426, 0.83869714]\n",
      "Batch 425/700: Discriminator loss = 1.2553542852401733, GAN loss = [2.1537814, 0.68649733, 0.7918067]\n",
      "Batch 426/700: Discriminator loss = 1.2364293336868286, GAN loss = [2.2038124, 0.72100556, 0.80733794]\n",
      "Batch 427/700: Discriminator loss = 1.2172324657440186, GAN loss = [2.199954, 0.7286976, 0.7958268]\n",
      "Batch 428/700: Discriminator loss = 1.247327446937561, GAN loss = [2.149502, 0.712967, 0.7611338]\n",
      "Batch 429/700: Discriminator loss = 1.2311660051345825, GAN loss = [2.19713, 0.72359157, 0.7981552]\n",
      "Batch 430/700: Discriminator loss = 1.2491933107376099, GAN loss = [2.2101715, 0.70111513, 0.83369875]\n",
      "Batch 431/700: Discriminator loss = 1.2285757064819336, GAN loss = [2.131629, 0.7105975, 0.7456832]\n",
      "Batch 432/700: Discriminator loss = 1.2096656560897827, GAN loss = [2.220643, 0.74648094, 0.79882354]\n",
      "Batch 433/700: Discriminator loss = 1.2139729261398315, GAN loss = [2.2285256, 0.73435557, 0.8188405]\n",
      "Batch 434/700: Discriminator loss = 1.1975818872451782, GAN loss = [2.2300518, 0.7502537, 0.804473]\n",
      "Batch 435/700: Discriminator loss = 1.2130082845687866, GAN loss = [2.229425, 0.7528332, 0.80128497]\n",
      "Batch 436/700: Discriminator loss = 1.1849637031555176, GAN loss = [2.232805, 0.7605547, 0.79697764]\n",
      "Batch 437/700: Discriminator loss = 1.1750539541244507, GAN loss = [2.2355638, 0.7708985, 0.7894279]\n",
      "Batch 438/700: Discriminator loss = 1.1908857822418213, GAN loss = [2.250406, 0.767005, 0.8081955]\n",
      "Batch 439/700: Discriminator loss = 1.1996649503707886, GAN loss = [2.2268202, 0.76246226, 0.7891924]\n",
      "Batch 440/700: Discriminator loss = 1.2091087102890015, GAN loss = [2.2289221, 0.73170996, 0.82209104]\n",
      "Batch 441/700: Discriminator loss = 1.180764079093933, GAN loss = [2.2989974, 0.769586, 0.85433847]\n",
      "Batch 442/700: Discriminator loss = 1.1994682550430298, GAN loss = [2.274738, 0.74924135, 0.8504655]\n",
      "Batch 443/700: Discriminator loss = 1.1872773170471191, GAN loss = [2.2687013, 0.7585545, 0.8351574]\n",
      "Batch 444/700: Discriminator loss = 1.2019479274749756, GAN loss = [2.2449665, 0.7649147, 0.80510545]\n",
      "Batch 445/700: Discriminator loss = 1.1866731643676758, GAN loss = [2.3060687, 0.7648346, 0.86633486]\n",
      "Batch 446/700: Discriminator loss = 1.17518150806427, GAN loss = [2.267322, 0.7669163, 0.8255504]\n",
      "Batch 447/700: Discriminator loss = 1.1983648538589478, GAN loss = [2.2257264, 0.7421054, 0.8088093]\n",
      "Batch 448/700: Discriminator loss = 1.2084393501281738, GAN loss = [2.2667441, 0.7446001, 0.8473787]\n",
      "Batch 449/700: Discriminator loss = 1.2038944959640503, GAN loss = [2.2676597, 0.7568728, 0.8360724]\n",
      "Batch 450/700: Discriminator loss = 1.209505558013916, GAN loss = [2.259624, 0.7354761, 0.84949225]\n",
      "Batch 451/700: Discriminator loss = 1.187829852104187, GAN loss = [2.3097808, 0.7587648, 0.87639976]\n",
      "Batch 452/700: Discriminator loss = 1.198556661605835, GAN loss = [2.2690248, 0.74603117, 0.848404]\n",
      "Batch 453/700: Discriminator loss = 1.2018702030181885, GAN loss = [2.2461655, 0.7377449, 0.8338535]\n",
      "Batch 454/700: Discriminator loss = 1.2163338661193848, GAN loss = [2.262487, 0.7373447, 0.850606]\n",
      "Batch 455/700: Discriminator loss = 1.2387975454330444, GAN loss = [2.2356784, 0.7178925, 0.8432748]\n",
      "Batch 456/700: Discriminator loss = 1.2087812423706055, GAN loss = [2.2267897, 0.7269822, 0.82531947]\n",
      "Batch 457/700: Discriminator loss = 1.229134202003479, GAN loss = [2.2192163, 0.7207464, 0.82399386]\n",
      "Batch 458/700: Discriminator loss = 1.216965913772583, GAN loss = [2.2293804, 0.7306363, 0.8242673]\n",
      "Batch 459/700: Discriminator loss = 1.2333425283432007, GAN loss = [2.2454734, 0.7152505, 0.855762]\n",
      "Batch 460/700: Discriminator loss = 1.20855712890625, GAN loss = [2.274944, 0.73277617, 0.8677193]\n",
      "Batch 461/700: Discriminator loss = 1.1974596977233887, GAN loss = [2.298011, 0.74382913, 0.8797517]\n",
      "Batch 462/700: Discriminator loss = 1.203701376914978, GAN loss = [2.2803376, 0.74432445, 0.8616045]\n",
      "Batch 463/700: Discriminator loss = 1.219985842704773, GAN loss = [2.2036204, 0.72494864, 0.80428207]\n",
      "Batch 464/700: Discriminator loss = 1.188856601715088, GAN loss = [2.2522628, 0.74580973, 0.83207923]\n",
      "Batch 465/700: Discriminator loss = 1.2253541946411133, GAN loss = [2.2631576, 0.72845954, 0.86034334]\n",
      "Batch 466/700: Discriminator loss = 1.1955070495605469, GAN loss = [2.2880666, 0.74509627, 0.868639]\n",
      "Batch 467/700: Discriminator loss = 1.227634310722351, GAN loss = [2.2707312, 0.72299653, 0.87341917]\n",
      "Batch 468/700: Discriminator loss = 1.236016035079956, GAN loss = [2.2686195, 0.7230333, 0.8712814]\n",
      "Batch 469/700: Discriminator loss = 1.204171061515808, GAN loss = [2.2576444, 0.7429795, 0.8403482]\n",
      "Batch 470/700: Discriminator loss = 1.223264455795288, GAN loss = [2.2381084, 0.73329735, 0.830485]\n",
      "Batch 471/700: Discriminator loss = 1.2462888956069946, GAN loss = [2.1864262, 0.7003438, 0.81176764]\n",
      "Batch 472/700: Discriminator loss = 1.2369235754013062, GAN loss = [2.2541926, 0.72995514, 0.84991455]\n",
      "Batch 473/700: Discriminator loss = 1.2160308361053467, GAN loss = [2.2471602, 0.74614036, 0.82668793]\n",
      "Batch 474/700: Discriminator loss = 1.2755221128463745, GAN loss = [2.1805604, 0.7022052, 0.8040011]\n",
      "Batch 475/700: Discriminator loss = 1.2229771614074707, GAN loss = [2.2623553, 0.74272364, 0.845268]\n",
      "Batch 476/700: Discriminator loss = 1.2058985233306885, GAN loss = [2.3050036, 0.77558297, 0.8550436]\n",
      "Batch 477/700: Discriminator loss = 1.2083486318588257, GAN loss = [2.3277564, 0.76844645, 0.88491976]\n",
      "Batch 478/700: Discriminator loss = 1.249735951423645, GAN loss = [2.282536, 0.7349611, 0.87318474]\n",
      "Batch 479/700: Discriminator loss = 1.2449216842651367, GAN loss = [2.2645772, 0.7324385, 0.8577559]\n",
      "Batch 480/700: Discriminator loss = 1.2228609323501587, GAN loss = [2.2693005, 0.7452703, 0.8496576]\n",
      "Batch 481/700: Discriminator loss = 1.2241867780685425, GAN loss = [2.291502, 0.7472442, 0.86989003]\n",
      "Batch 482/700: Discriminator loss = 1.2748992443084717, GAN loss = [2.2161186, 0.7007163, 0.8410416]\n",
      "Batch 483/700: Discriminator loss = 1.2703509330749512, GAN loss = [2.2099469, 0.70683074, 0.82875896]\n",
      "Batch 484/700: Discriminator loss = 1.2721587419509888, GAN loss = [2.2079093, 0.709491, 0.8240768]\n",
      "Batch 485/700: Discriminator loss = 1.2365847826004028, GAN loss = [2.2593749, 0.7374997, 0.84753984]\n",
      "Batch 486/700: Discriminator loss = 1.2345550060272217, GAN loss = [2.25898, 0.72696525, 0.85768044]\n",
      "Batch 487/700: Discriminator loss = 1.218802809715271, GAN loss = [2.2841108, 0.7374981, 0.8722765]\n",
      "Batch 488/700: Discriminator loss = 1.2576414346694946, GAN loss = [2.2284925, 0.7126061, 0.84155893]\n",
      "Batch 489/700: Discriminator loss = 1.2502151727676392, GAN loss = [2.2232356, 0.7163434, 0.832579]\n",
      "Batch 490/700: Discriminator loss = 1.2689411640167236, GAN loss = [2.1872575, 0.72575396, 0.78720075]\n",
      "Batch 491/700: Discriminator loss = 1.2318943738937378, GAN loss = [2.2535613, 0.76600134, 0.8132687]\n",
      "Batch 492/700: Discriminator loss = 1.235681176185608, GAN loss = [2.1993794, 0.7280968, 0.79701203]\n",
      "Batch 493/700: Discriminator loss = 1.2288753986358643, GAN loss = [2.2116463, 0.74774504, 0.7896543]\n",
      "Batch 494/700: Discriminator loss = 1.2195460796356201, GAN loss = [2.2506857, 0.76675135, 0.80972016]\n",
      "Batch 495/700: Discriminator loss = 1.215484857559204, GAN loss = [2.1721532, 0.736605, 0.76136]\n",
      "Batch 496/700: Discriminator loss = 1.233078122138977, GAN loss = [2.2145765, 0.7381374, 0.80227554]\n",
      "Batch 497/700: Discriminator loss = 1.2005023956298828, GAN loss = [2.2388809, 0.7749427, 0.78980505]\n",
      "Batch 498/700: Discriminator loss = 1.2019795179367065, GAN loss = [2.2267761, 0.74981874, 0.80285233]\n",
      "Batch 499/700: Discriminator loss = 1.2040942907333374, GAN loss = [2.2468321, 0.7553545, 0.8174099]\n",
      "Batch 500/700: Discriminator loss = 1.1738461256027222, GAN loss = [2.2648053, 0.7850116, 0.8057578]\n",
      "Batch 501/700: Discriminator loss = 1.1786459684371948, GAN loss = [2.2518773, 0.7677817, 0.8101002]\n",
      "Batch 502/700: Discriminator loss = 1.182860255241394, GAN loss = [2.2489142, 0.7517207, 0.8232409]\n",
      "Batch 503/700: Discriminator loss = 1.2009450197219849, GAN loss = [2.2319717, 0.74449265, 0.8135656]\n",
      "Batch 504/700: Discriminator loss = 1.20170259475708, GAN loss = [2.2400413, 0.7446229, 0.8215321]\n",
      "Batch 505/700: Discriminator loss = 1.2075860500335693, GAN loss = [2.226917, 0.7523992, 0.8006557]\n",
      "Batch 506/700: Discriminator loss = 1.2102121114730835, GAN loss = [2.2325208, 0.75017256, 0.8085177]\n",
      "Batch 507/700: Discriminator loss = 1.2076926231384277, GAN loss = [2.2290103, 0.7483741, 0.80683374]\n",
      "Batch 508/700: Discriminator loss = 1.2222304344177246, GAN loss = [2.260343, 0.74014336, 0.84641427]\n",
      "Batch 509/700: Discriminator loss = 1.2054197788238525, GAN loss = [2.232316, 0.74829966, 0.8102459]\n",
      "Batch 510/700: Discriminator loss = 1.2317218780517578, GAN loss = [2.2401164, 0.7282222, 0.83814275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 511/700: Discriminator loss = 1.202072262763977, GAN loss = [2.2378902, 0.7415131, 0.82263947]\n",
      "Batch 512/700: Discriminator loss = 1.2240601778030396, GAN loss = [2.2671509, 0.76534784, 0.8280952]\n",
      "Batch 513/700: Discriminator loss = 1.221958041191101, GAN loss = [2.2140908, 0.7376413, 0.8027605]\n",
      "Batch 514/700: Discriminator loss = 1.1960116624832153, GAN loss = [2.2765298, 0.75577235, 0.84708464]\n",
      "Batch 515/700: Discriminator loss = 1.213841438293457, GAN loss = [2.2410214, 0.7629748, 0.8043859]\n",
      "Batch 516/700: Discriminator loss = 1.2552217245101929, GAN loss = [2.233716, 0.7331571, 0.8269319]\n",
      "Batch 517/700: Discriminator loss = 1.2254211902618408, GAN loss = [2.2524903, 0.7573972, 0.8215039]\n",
      "Batch 518/700: Discriminator loss = 1.2019309997558594, GAN loss = [2.2327178, 0.75008833, 0.8090741]\n",
      "Batch 519/700: Discriminator loss = 1.2014105319976807, GAN loss = [2.2606509, 0.78223443, 0.8048935]\n",
      "Batch 520/700: Discriminator loss = 1.2266744375228882, GAN loss = [2.2226758, 0.7474546, 0.8017265]\n",
      "Batch 521/700: Discriminator loss = 1.2228271961212158, GAN loss = [2.2164583, 0.75154006, 0.7914617]\n",
      "Batch 522/700: Discriminator loss = 1.1813716888427734, GAN loss = [2.2487206, 0.78511804, 0.79018366]\n",
      "Batch 523/700: Discriminator loss = 1.180578589439392, GAN loss = [2.260266, 0.7899643, 0.796915]\n",
      "Batch 524/700: Discriminator loss = 1.1795008182525635, GAN loss = [2.2042694, 0.77349585, 0.757424]\n",
      "Batch 525/700: Discriminator loss = 1.1853910684585571, GAN loss = [2.2256672, 0.7628688, 0.78948206]\n",
      "Batch 526/700: Discriminator loss = 1.1748167276382446, GAN loss = [2.2828195, 0.7902627, 0.81927645]\n",
      "Batch 527/700: Discriminator loss = 1.1900038719177246, GAN loss = [2.265096, 0.7777295, 0.81412834]\n",
      "Batch 528/700: Discriminator loss = 1.1806086301803589, GAN loss = [2.2388844, 0.76680255, 0.7988887]\n",
      "Batch 529/700: Discriminator loss = 1.2212096452713013, GAN loss = [2.2171154, 0.7443679, 0.7995951]\n",
      "Batch 530/700: Discriminator loss = 1.2100480794906616, GAN loss = [2.2341092, 0.7421795, 0.8188295]\n",
      "Batch 531/700: Discriminator loss = 1.202623724937439, GAN loss = [2.2155712, 0.75167215, 0.79084915]\n",
      "Batch 532/700: Discriminator loss = 1.1934218406677246, GAN loss = [2.2164025, 0.7512913, 0.79209304]\n",
      "Batch 533/700: Discriminator loss = 1.2078344821929932, GAN loss = [2.20716, 0.74956626, 0.78461576]\n",
      "Batch 534/700: Discriminator loss = 1.2311315536499023, GAN loss = [2.2116327, 0.73455566, 0.8041407]\n",
      "Batch 535/700: Discriminator loss = 1.1890125274658203, GAN loss = [2.2320545, 0.7585007, 0.80064934]\n",
      "Batch 536/700: Discriminator loss = 1.1988390684127808, GAN loss = [2.2262058, 0.7503275, 0.80300355]\n",
      "Batch 537/700: Discriminator loss = 1.2043007612228394, GAN loss = [2.1969576, 0.7390478, 0.78507894]\n",
      "Batch 538/700: Discriminator loss = 1.225473403930664, GAN loss = [2.1993952, 0.72706336, 0.7995374]\n",
      "Batch 539/700: Discriminator loss = 1.2328523397445679, GAN loss = [2.210499, 0.72395015, 0.8137972]\n",
      "Batch 540/700: Discriminator loss = 1.20103919506073, GAN loss = [2.2095032, 0.7420156, 0.79477644]\n",
      "Batch 541/700: Discriminator loss = 1.202209711074829, GAN loss = [2.2167926, 0.7289023, 0.81522125]\n",
      "Batch 542/700: Discriminator loss = 1.1987509727478027, GAN loss = [2.2122629, 0.7447783, 0.7948534]\n",
      "Batch 543/700: Discriminator loss = 1.216417670249939, GAN loss = [2.189353, 0.72590536, 0.79084796]\n",
      "Batch 544/700: Discriminator loss = 1.2138384580612183, GAN loss = [2.2290938, 0.7254747, 0.83105314]\n",
      "Batch 545/700: Discriminator loss = 1.2004600763320923, GAN loss = [2.203812, 0.7510247, 0.78025866]\n",
      "Batch 546/700: Discriminator loss = 1.1996183395385742, GAN loss = [2.2364264, 0.7340589, 0.82988626]\n",
      "Batch 547/700: Discriminator loss = 1.1993783712387085, GAN loss = [2.2422976, 0.740167, 0.8296997]\n",
      "Batch 548/700: Discriminator loss = 1.222178339958191, GAN loss = [2.2430422, 0.73018175, 0.84047323]\n",
      "Batch 549/700: Discriminator loss = 1.2143018245697021, GAN loss = [2.2466767, 0.73686785, 0.8374577]\n",
      "Batch 550/700: Discriminator loss = 1.2178826332092285, GAN loss = [2.179786, 0.7298421, 0.7776176]\n",
      "Batch 551/700: Discriminator loss = 1.2130967378616333, GAN loss = [2.1913702, 0.7429388, 0.7761337]\n",
      "Batch 552/700: Discriminator loss = 1.2066807746887207, GAN loss = [2.223606, 0.7560524, 0.7952921]\n",
      "Batch 553/700: Discriminator loss = 1.178826093673706, GAN loss = [2.2494538, 0.7673475, 0.8098885]\n",
      "Batch 554/700: Discriminator loss = 1.1868698596954346, GAN loss = [2.261576, 0.75463396, 0.83475953]\n",
      "Batch 555/700: Discriminator loss = 1.2210078239440918, GAN loss = [2.2011921, 0.72619635, 0.80284166]\n",
      "Batch 556/700: Discriminator loss = 1.2154966592788696, GAN loss = [2.2645402, 0.7417778, 0.8506398]\n",
      "Batch 557/700: Discriminator loss = 1.182250738143921, GAN loss = [2.2452908, 0.77035886, 0.8028424]\n",
      "Batch 558/700: Discriminator loss = 1.2053803205490112, GAN loss = [2.2526386, 0.7386185, 0.84196717]\n",
      "Batch 559/700: Discriminator loss = 1.200150728225708, GAN loss = [2.2607415, 0.73942393, 0.8492879]\n",
      "Batch 560/700: Discriminator loss = 1.1997679471969604, GAN loss = [2.2159328, 0.7339096, 0.8100182]\n",
      "Batch 561/700: Discriminator loss = 1.2175904512405396, GAN loss = [2.2279956, 0.73355967, 0.8224482]\n",
      "Batch 562/700: Discriminator loss = 1.2349305152893066, GAN loss = [2.2189195, 0.7260236, 0.8209317]\n",
      "Batch 563/700: Discriminator loss = 1.197356939315796, GAN loss = [2.2192178, 0.74517953, 0.8021003]\n",
      "Batch 564/700: Discriminator loss = 1.1992765665054321, GAN loss = [2.2212338, 0.74916595, 0.8001649]\n",
      "Batch 565/700: Discriminator loss = 1.1928867101669312, GAN loss = [2.232575, 0.7463626, 0.81435263]\n",
      "Batch 566/700: Discriminator loss = 1.1981472969055176, GAN loss = [2.2693105, 0.7567134, 0.8407818]\n",
      "Batch 567/700: Discriminator loss = 1.1977428197860718, GAN loss = [2.2316391, 0.7488453, 0.8110133]\n",
      "Batch 568/700: Discriminator loss = 1.1900287866592407, GAN loss = [2.2475877, 0.7471087, 0.8287271]\n",
      "Batch 569/700: Discriminator loss = 1.204314947128296, GAN loss = [2.225654, 0.7438047, 0.8101381]\n",
      "Batch 570/700: Discriminator loss = 1.1933866739273071, GAN loss = [2.2539074, 0.756764, 0.8254741]\n",
      "Batch 571/700: Discriminator loss = 1.1996320486068726, GAN loss = [2.2287424, 0.7362952, 0.82081413]\n",
      "Batch 572/700: Discriminator loss = 1.1986970901489258, GAN loss = [2.2404203, 0.7532923, 0.81553155]\n",
      "Batch 573/700: Discriminator loss = 1.2086068391799927, GAN loss = [2.2068152, 0.7286259, 0.8066318]\n",
      "Batch 574/700: Discriminator loss = 1.205479383468628, GAN loss = [2.218478, 0.7424551, 0.8045035]\n",
      "Batch 575/700: Discriminator loss = 1.19863760471344, GAN loss = [2.2580535, 0.74923164, 0.83732444]\n",
      "Batch 576/700: Discriminator loss = 1.1925848722457886, GAN loss = [2.2245035, 0.7580183, 0.79500544]\n",
      "Batch 577/700: Discriminator loss = 1.1968387365341187, GAN loss = [2.2503088, 0.75618994, 0.82265335]\n",
      "Batch 578/700: Discriminator loss = 1.2209287881851196, GAN loss = [2.1871285, 0.7204598, 0.7952047]\n",
      "Batch 579/700: Discriminator loss = 1.2103924751281738, GAN loss = [2.1957526, 0.72387016, 0.80040187]\n",
      "Batch 580/700: Discriminator loss = 1.2397319078445435, GAN loss = [2.1703098, 0.70165384, 0.7971729]\n",
      "Batch 581/700: Discriminator loss = 1.2116600275039673, GAN loss = [2.2420459, 0.7341088, 0.8364692]\n",
      "Batch 582/700: Discriminator loss = 1.20111083984375, GAN loss = [2.242195, 0.7415456, 0.8291975]\n",
      "Batch 583/700: Discriminator loss = 1.2464112043380737, GAN loss = [2.1740596, 0.6987223, 0.8038987]\n",
      "Batch 584/700: Discriminator loss = 1.200909972190857, GAN loss = [2.1852314, 0.7280668, 0.78573227]\n",
      "Batch 585/700: Discriminator loss = 1.2096456289291382, GAN loss = [2.2389162, 0.730604, 0.8368836]\n",
      "Batch 586/700: Discriminator loss = 1.2121042013168335, GAN loss = [2.219769, 0.728935, 0.8194193]\n",
      "Batch 587/700: Discriminator loss = 1.2329981327056885, GAN loss = [2.200344, 0.71743876, 0.8114965]\n",
      "Batch 588/700: Discriminator loss = 1.1998709440231323, GAN loss = [2.2292147, 0.7511742, 0.8066268]\n",
      "Batch 589/700: Discriminator loss = 1.2357397079467773, GAN loss = [2.178548, 0.69892716, 0.80819374]\n",
      "Batch 590/700: Discriminator loss = 1.207843542098999, GAN loss = [2.1809387, 0.73026896, 0.77925164]\n",
      "Batch 591/700: Discriminator loss = 1.194899320602417, GAN loss = [2.244018, 0.7457842, 0.82681906]\n",
      "Batch 592/700: Discriminator loss = 1.205169677734375, GAN loss = [2.233264, 0.7453532, 0.81650084]\n",
      "Batch 593/700: Discriminator loss = 1.2285276651382446, GAN loss = [2.1981585, 0.71837103, 0.808379]\n",
      "Batch 594/700: Discriminator loss = 1.1824493408203125, GAN loss = [2.2515352, 0.7621515, 0.8179842]\n",
      "Batch 595/700: Discriminator loss = 1.204397439956665, GAN loss = [2.2299864, 0.73464555, 0.82396513]\n",
      "Batch 596/700: Discriminator loss = 1.2176531553268433, GAN loss = [2.2278843, 0.7226004, 0.8339291]\n",
      "Batch 597/700: Discriminator loss = 1.2027863264083862, GAN loss = [2.2608519, 0.7371936, 0.8523166]\n",
      "Batch 598/700: Discriminator loss = 1.1916301250457764, GAN loss = [2.2497766, 0.7567403, 0.82170975]\n",
      "Batch 599/700: Discriminator loss = 1.179644227027893, GAN loss = [2.2843585, 0.7569318, 0.856118]\n",
      "Batch 600/700: Discriminator loss = 1.224977731704712, GAN loss = [2.256249, 0.7265615, 0.8584015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 601/700: Discriminator loss = 1.1915913820266724, GAN loss = [2.2496464, 0.74656695, 0.8318279]\n",
      "Batch 602/700: Discriminator loss = 1.1903492212295532, GAN loss = [2.2174506, 0.74682325, 0.7993918]\n",
      "Batch 603/700: Discriminator loss = 1.1905581951141357, GAN loss = [2.2618778, 0.74977577, 0.84087664]\n",
      "Batch 604/700: Discriminator loss = 1.1875543594360352, GAN loss = [2.2563798, 0.7463131, 0.8388558]\n",
      "Batch 605/700: Discriminator loss = 1.1970186233520508, GAN loss = [2.256667, 0.75073624, 0.83472335]\n",
      "Batch 606/700: Discriminator loss = 1.1852343082427979, GAN loss = [2.3332734, 0.76914436, 0.8929381]\n",
      "Batch 607/700: Discriminator loss = 1.1929621696472168, GAN loss = [2.2729487, 0.7487265, 0.8530601]\n",
      "Batch 608/700: Discriminator loss = 1.2043440341949463, GAN loss = [2.2502143, 0.7447706, 0.83430123]\n",
      "Batch 609/700: Discriminator loss = 1.1972229480743408, GAN loss = [2.2535055, 0.7449389, 0.83744764]\n",
      "Batch 610/700: Discriminator loss = 1.2331480979919434, GAN loss = [2.2554045, 0.72353846, 0.8607725]\n",
      "Batch 611/700: Discriminator loss = 1.1974682807922363, GAN loss = [2.2662857, 0.7364583, 0.85875136]\n",
      "Batch 612/700: Discriminator loss = 1.2094720602035522, GAN loss = [2.2522798, 0.73059064, 0.8506374]\n",
      "Batch 613/700: Discriminator loss = 1.2233220338821411, GAN loss = [2.2492723, 0.7253418, 0.8528992]\n",
      "Batch 614/700: Discriminator loss = 1.207947015762329, GAN loss = [2.256733, 0.729776, 0.8559407]\n",
      "Batch 615/700: Discriminator loss = 1.2043321132659912, GAN loss = [2.2540298, 0.7339606, 0.84908104]\n",
      "Batch 616/700: Discriminator loss = 1.2600926160812378, GAN loss = [2.218452, 0.6992552, 0.8482347]\n",
      "Batch 617/700: Discriminator loss = 1.2381494045257568, GAN loss = [2.2465806, 0.71820974, 0.85743034]\n",
      "Batch 618/700: Discriminator loss = 1.2743916511535645, GAN loss = [2.185554, 0.68469775, 0.82993186]\n",
      "Batch 619/700: Discriminator loss = 1.2084978818893433, GAN loss = [2.2516978, 0.7369335, 0.84385115]\n",
      "Batch 620/700: Discriminator loss = 1.2178813219070435, GAN loss = [2.2197988, 0.72885954, 0.8200593]\n",
      "Batch 621/700: Discriminator loss = 1.2362843751907349, GAN loss = [2.174988, 0.7099604, 0.7941731]\n",
      "Batch 622/700: Discriminator loss = 1.232557773590088, GAN loss = [2.1932697, 0.7085157, 0.8139245]\n",
      "Batch 623/700: Discriminator loss = 1.218097448348999, GAN loss = [2.2496753, 0.7310052, 0.84786385]\n",
      "Batch 624/700: Discriminator loss = 1.2171624898910522, GAN loss = [2.2402456, 0.7307473, 0.83869714]\n",
      "Batch 625/700: Discriminator loss = 1.2171804904937744, GAN loss = [2.244846, 0.7337767, 0.8402881]\n",
      "Batch 626/700: Discriminator loss = 1.2262005805969238, GAN loss = [2.2213423, 0.72070485, 0.8298925]\n",
      "Batch 627/700: Discriminator loss = 1.2368419170379639, GAN loss = [2.206403, 0.7218014, 0.8138938]\n",
      "Batch 628/700: Discriminator loss = 1.2335700988769531, GAN loss = [2.1382968, 0.70986694, 0.75775766]\n",
      "Batch 629/700: Discriminator loss = 1.2046927213668823, GAN loss = [2.236144, 0.7448267, 0.82067156]\n",
      "Batch 630/700: Discriminator loss = 1.219144582748413, GAN loss = [2.198457, 0.72587293, 0.80195636]\n",
      "Batch 631/700: Discriminator loss = 1.2227343320846558, GAN loss = [2.2008488, 0.72013307, 0.81011117]\n",
      "Batch 632/700: Discriminator loss = 1.1980295181274414, GAN loss = [2.190623, 0.738361, 0.78166276]\n",
      "Batch 633/700: Discriminator loss = 1.2185360193252563, GAN loss = [2.191143, 0.7178305, 0.8027199]\n",
      "Batch 634/700: Discriminator loss = 1.2159029245376587, GAN loss = [2.1847796, 0.7451319, 0.76906204]\n",
      "Batch 635/700: Discriminator loss = 1.193034052848816, GAN loss = [2.2273383, 0.748464, 0.8082924]\n",
      "Batch 636/700: Discriminator loss = 1.2264559268951416, GAN loss = [2.1794286, 0.7178219, 0.7910209]\n",
      "Batch 637/700: Discriminator loss = 1.2158315181732178, GAN loss = [2.1914306, 0.72272545, 0.7981202]\n",
      "Batch 638/700: Discriminator loss = 1.2329328060150146, GAN loss = [2.1646936, 0.7049705, 0.7891483]\n",
      "Batch 639/700: Discriminator loss = 1.219993233680725, GAN loss = [2.208077, 0.7188826, 0.81863534]\n",
      "Batch 640/700: Discriminator loss = 1.2236930131912231, GAN loss = [2.17881, 0.70762205, 0.8006511]\n",
      "Batch 641/700: Discriminator loss = 1.2209159135818481, GAN loss = [2.186202, 0.7232904, 0.7923893]\n",
      "Batch 642/700: Discriminator loss = 1.2202473878860474, GAN loss = [2.2208514, 0.71438086, 0.83596826]\n",
      "Batch 643/700: Discriminator loss = 1.224073052406311, GAN loss = [2.1804492, 0.71510035, 0.7948609]\n",
      "Batch 644/700: Discriminator loss = 1.231895089149475, GAN loss = [2.1605027, 0.6988442, 0.79117835]\n",
      "Batch 645/700: Discriminator loss = 1.2249131202697754, GAN loss = [2.1714628, 0.71550447, 0.785492]\n",
      "Batch 646/700: Discriminator loss = 1.232315182685852, GAN loss = [2.16154, 0.70563626, 0.78546405]\n",
      "Batch 647/700: Discriminator loss = 1.2218384742736816, GAN loss = [2.1525302, 0.70438874, 0.77773535]\n",
      "Batch 648/700: Discriminator loss = 1.222697377204895, GAN loss = [2.1637857, 0.70434046, 0.7890773]\n",
      "Batch 649/700: Discriminator loss = 1.2420588731765747, GAN loss = [2.1618152, 0.6914978, 0.79997665]\n",
      "Batch 650/700: Discriminator loss = 1.2124797105789185, GAN loss = [2.1775773, 0.71842635, 0.78883165]\n",
      "Batch 651/700: Discriminator loss = 1.2351007461547852, GAN loss = [2.144713, 0.68510085, 0.78931564]\n",
      "Batch 652/700: Discriminator loss = 1.23567533493042, GAN loss = [2.1266012, 0.69462496, 0.76169515]\n",
      "Batch 653/700: Discriminator loss = 1.2290953397750854, GAN loss = [2.1736884, 0.71421725, 0.78920156]\n",
      "Batch 654/700: Discriminator loss = 1.2481203079223633, GAN loss = [2.1163518, 0.69379616, 0.7523081]\n",
      "Batch 655/700: Discriminator loss = 1.2196851968765259, GAN loss = [2.1523156, 0.7128027, 0.7692933]\n",
      "Batch 656/700: Discriminator loss = 1.2522661685943604, GAN loss = [2.1329362, 0.6867289, 0.77601486]\n",
      "Batch 657/700: Discriminator loss = 1.2410297393798828, GAN loss = [2.1880567, 0.69929767, 0.8185867]\n",
      "Batch 658/700: Discriminator loss = 1.2340887784957886, GAN loss = [2.1463673, 0.69347906, 0.78274095]\n",
      "Batch 659/700: Discriminator loss = 1.2370350360870361, GAN loss = [2.1626527, 0.6946136, 0.79792386]\n",
      "Batch 660/700: Discriminator loss = 1.2342708110809326, GAN loss = [2.1836998, 0.701398, 0.8122132]\n",
      "Batch 661/700: Discriminator loss = 1.226987600326538, GAN loss = [2.1821694, 0.7025432, 0.80956477]\n",
      "Batch 662/700: Discriminator loss = 1.2138043642044067, GAN loss = [2.1964095, 0.7213928, 0.8049728]\n",
      "Batch 663/700: Discriminator loss = 1.212432861328125, GAN loss = [2.1554284, 0.7197387, 0.76566905]\n",
      "Batch 664/700: Discriminator loss = 1.2061738967895508, GAN loss = [2.1930518, 0.7190292, 0.80401593]\n",
      "Batch 665/700: Discriminator loss = 1.2062417268753052, GAN loss = [2.2368112, 0.730142, 0.83668685]\n",
      "Batch 666/700: Discriminator loss = 1.2195066213607788, GAN loss = [2.152919, 0.7058424, 0.77711535]\n",
      "Batch 667/700: Discriminator loss = 1.2077168226242065, GAN loss = [2.2223144, 0.71909356, 0.83326864]\n",
      "Batch 668/700: Discriminator loss = 1.1786729097366333, GAN loss = [2.232923, 0.74480736, 0.8181789]\n",
      "Batch 669/700: Discriminator loss = 1.2278696298599243, GAN loss = [2.2008939, 0.7082874, 0.82269156]\n",
      "Batch 670/700: Discriminator loss = 1.221801519393921, GAN loss = [2.2091568, 0.7090404, 0.8302245]\n",
      "Batch 671/700: Discriminator loss = 1.224716305732727, GAN loss = [2.2215526, 0.70603156, 0.84564865]\n",
      "Batch 672/700: Discriminator loss = 1.2116104364395142, GAN loss = [2.20299, 0.7262237, 0.80690324]\n",
      "Batch 673/700: Discriminator loss = 1.2108187675476074, GAN loss = [2.2513201, 0.72690356, 0.8545715]\n",
      "Batch 674/700: Discriminator loss = 1.208435297012329, GAN loss = [2.2418609, 0.72517234, 0.8468645]\n",
      "Batch 675/700: Discriminator loss = 1.2102088928222656, GAN loss = [2.2595043, 0.74089545, 0.84879583]\n",
      "Batch 676/700: Discriminator loss = 1.169008731842041, GAN loss = [2.248986, 0.75891715, 0.8202623]\n",
      "Batch 677/700: Discriminator loss = 1.2102357149124146, GAN loss = [2.2457056, 0.7233788, 0.8525335]\n",
      "Batch 678/700: Discriminator loss = 1.188401699066162, GAN loss = [2.2684455, 0.74292624, 0.8557369]\n",
      "Batch 679/700: Discriminator loss = 1.197238564491272, GAN loss = [2.2747977, 0.74339277, 0.8616402]\n",
      "Batch 680/700: Discriminator loss = 1.1747031211853027, GAN loss = [2.2669616, 0.75287575, 0.8443389]\n",
      "Batch 681/700: Discriminator loss = 1.191426396369934, GAN loss = [2.2502081, 0.7437161, 0.8367729]\n",
      "Batch 682/700: Discriminator loss = 1.223030686378479, GAN loss = [2.2181027, 0.7040102, 0.8443963]\n",
      "Batch 683/700: Discriminator loss = 1.212472677230835, GAN loss = [2.1770606, 0.7237715, 0.7836126]\n",
      "Batch 684/700: Discriminator loss = 1.2018053531646729, GAN loss = [2.224786, 0.72624743, 0.828885]\n",
      "Batch 685/700: Discriminator loss = 1.219166874885559, GAN loss = [2.1984117, 0.72215164, 0.8066317]\n",
      "Batch 686/700: Discriminator loss = 1.2145583629608154, GAN loss = [2.2144735, 0.7233535, 0.82151246]\n",
      "Batch 687/700: Discriminator loss = 1.2173322439193726, GAN loss = [2.253112, 0.72643834, 0.8570849]\n",
      "Batch 688/700: Discriminator loss = 1.208876371383667, GAN loss = [2.2413116, 0.7276564, 0.84408075]\n",
      "Batch 689/700: Discriminator loss = 1.195282220840454, GAN loss = [2.2385402, 0.7422912, 0.8266948]\n",
      "Batch 690/700: Discriminator loss = 1.2275922298431396, GAN loss = [2.1993215, 0.7083301, 0.8214592]\n",
      "Batch 691/700: Discriminator loss = 1.2221882343292236, GAN loss = [2.2338006, 0.7182026, 0.84607446]\n",
      "Batch 692/700: Discriminator loss = 1.2450038194656372, GAN loss = [2.178762, 0.69981414, 0.80944276]\n",
      "Batch 693/700: Discriminator loss = 1.241721510887146, GAN loss = [2.201823, 0.6995304, 0.8327898]\n",
      "Batch 694/700: Discriminator loss = 1.233465313911438, GAN loss = [2.2101107, 0.7059155, 0.83469766]\n",
      "Batch 695/700: Discriminator loss = 1.231520175933838, GAN loss = [2.197229, 0.6988248, 0.828913]\n",
      "Batch 696/700: Discriminator loss = 1.2209668159484863, GAN loss = [2.1894162, 0.7087781, 0.81114143]\n",
      "Batch 697/700: Discriminator loss = 1.23263418674469, GAN loss = [2.1673443, 0.70159554, 0.7962444]\n",
      "Batch 698/700: Discriminator loss = 1.23890221118927, GAN loss = [2.1756418, 0.70071435, 0.8054395]\n",
      "Batch 699/700: Discriminator loss = 1.2426798343658447, GAN loss = [2.2206988, 0.6925392, 0.85868263]\n",
      "Batch 700/700: Discriminator loss = 1.2558825016021729, GAN loss = [2.1430569, 0.68955946, 0.784032]\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/700: Discriminator loss = 1.2382032871246338, GAN loss = [2.1758323, 0.70592254, 0.800456]\n",
      "Batch 2/700: Discriminator loss = 1.243839979171753, GAN loss = [2.1493478, 0.6824033, 0.7974933]\n",
      "Batch 3/700: Discriminator loss = 1.2435795068740845, GAN loss = [2.168524, 0.7119515, 0.787135]\n",
      "Batch 4/700: Discriminator loss = 1.23014497756958, GAN loss = [2.1776497, 0.6981958, 0.8100226]\n",
      "Batch 5/700: Discriminator loss = 1.2401888370513916, GAN loss = [2.1750035, 0.69852966, 0.8070516]\n",
      "Batch 6/700: Discriminator loss = 1.2114819288253784, GAN loss = [2.214252, 0.7191307, 0.82571983]\n",
      "Batch 7/700: Discriminator loss = 1.2258323431015015, GAN loss = [2.156292, 0.71036935, 0.7765392]\n",
      "Batch 8/700: Discriminator loss = 1.2217106819152832, GAN loss = [2.2080114, 0.7073262, 0.8313167]\n",
      "Batch 9/700: Discriminator loss = 1.2130109071731567, GAN loss = [2.1860077, 0.71741647, 0.7992492]\n",
      "Batch 10/700: Discriminator loss = 1.2232683897018433, GAN loss = [2.2120337, 0.71395963, 0.8287485]\n",
      "Batch 11/700: Discriminator loss = 1.1848649978637695, GAN loss = [2.2541146, 0.76121163, 0.8235894]\n",
      "Batch 12/700: Discriminator loss = 1.2069560289382935, GAN loss = [2.281322, 0.7249454, 0.88707596]\n",
      "Batch 13/700: Discriminator loss = 1.211888074874878, GAN loss = [2.2184095, 0.7244394, 0.82467985]\n",
      "Batch 14/700: Discriminator loss = 1.200150728225708, GAN loss = [2.225464, 0.7361835, 0.82001466]\n",
      "Batch 15/700: Discriminator loss = 1.2140722274780273, GAN loss = [2.28487, 0.7374056, 0.8782079]\n",
      "Batch 16/700: Discriminator loss = 1.208292841911316, GAN loss = [2.221991, 0.7207841, 0.8319697]\n",
      "Batch 17/700: Discriminator loss = 1.2222328186035156, GAN loss = [2.1791883, 0.7141598, 0.79581803]\n",
      "Batch 18/700: Discriminator loss = 1.2272018194198608, GAN loss = [2.164477, 0.696053, 0.7992526]\n",
      "Batch 19/700: Discriminator loss = 1.2192445993423462, GAN loss = [2.19695, 0.71214753, 0.81566507]\n",
      "Batch 20/700: Discriminator loss = 1.222516417503357, GAN loss = [2.2096326, 0.70914, 0.8313795]\n",
      "Batch 21/700: Discriminator loss = 1.2224088907241821, GAN loss = [2.2018714, 0.7004204, 0.83235604]\n",
      "Batch 22/700: Discriminator loss = 1.2069815397262573, GAN loss = [2.2776837, 0.72614336, 0.88246846]\n",
      "Batch 23/700: Discriminator loss = 1.2248036861419678, GAN loss = [2.1907976, 0.70872396, 0.8130147]\n",
      "Batch 24/700: Discriminator loss = 1.1992520093917847, GAN loss = [2.2498846, 0.7420807, 0.8387775]\n",
      "Batch 25/700: Discriminator loss = 1.2264788150787354, GAN loss = [2.1811776, 0.70554054, 0.80663544]\n",
      "Batch 26/700: Discriminator loss = 1.2318544387817383, GAN loss = [2.2563283, 0.7101446, 0.8772058]\n",
      "Batch 27/700: Discriminator loss = 1.2272469997406006, GAN loss = [2.2098079, 0.70859826, 0.8322487]\n",
      "Batch 28/700: Discriminator loss = 1.2426546812057495, GAN loss = [2.185945, 0.6929891, 0.8240249]\n",
      "Batch 29/700: Discriminator loss = 1.252642035484314, GAN loss = [2.190936, 0.686408, 0.83562624]\n",
      "Batch 30/700: Discriminator loss = 1.2036687135696411, GAN loss = [2.2578435, 0.7301793, 0.85878897]\n",
      "Batch 31/700: Discriminator loss = 1.21635103225708, GAN loss = [2.2185256, 0.727433, 0.82221913]\n",
      "Batch 32/700: Discriminator loss = 1.222434639930725, GAN loss = [2.1957047, 0.7121686, 0.81465447]\n",
      "Batch 33/700: Discriminator loss = 1.208810567855835, GAN loss = [2.2334776, 0.73194915, 0.8326515]\n",
      "Batch 34/700: Discriminator loss = 1.2406154870986938, GAN loss = [2.1715715, 0.7113735, 0.79133356]\n",
      "Batch 35/700: Discriminator loss = 1.2326688766479492, GAN loss = [2.136368, 0.7063023, 0.7612097]\n",
      "Batch 36/700: Discriminator loss = 1.2079174518585205, GAN loss = [2.2505808, 0.7360771, 0.8456513]\n",
      "Batch 37/700: Discriminator loss = 1.2300647497177124, GAN loss = [2.2157943, 0.7141791, 0.83277]\n",
      "Batch 38/700: Discriminator loss = 1.2281692028045654, GAN loss = [2.2161229, 0.70858717, 0.8386939]\n",
      "Batch 39/700: Discriminator loss = 1.2535386085510254, GAN loss = [2.200217, 0.6927237, 0.8386554]\n",
      "Batch 40/700: Discriminator loss = 1.2178187370300293, GAN loss = [2.1786225, 0.71024215, 0.79954916]\n",
      "Batch 41/700: Discriminator loss = 1.261894941329956, GAN loss = [2.1659415, 0.70077485, 0.7963466]\n",
      "Batch 42/700: Discriminator loss = 1.2153512239456177, GAN loss = [2.1956801, 0.71760994, 0.80926824]\n",
      "Batch 43/700: Discriminator loss = 1.2123702764511108, GAN loss = [2.2264884, 0.74508524, 0.8126371]\n",
      "Batch 44/700: Discriminator loss = 1.2168408632278442, GAN loss = [2.2198029, 0.7358349, 0.8152375]\n",
      "Batch 45/700: Discriminator loss = 1.2070631980895996, GAN loss = [2.1682699, 0.7253536, 0.7741923]\n",
      "Batch 46/700: Discriminator loss = 1.2257838249206543, GAN loss = [2.1847374, 0.7260182, 0.79000974]\n",
      "Batch 47/700: Discriminator loss = 1.2194453477859497, GAN loss = [2.1771646, 0.72966504, 0.7787855]\n",
      "Batch 48/700: Discriminator loss = 1.2050915956497192, GAN loss = [2.2228732, 0.73375046, 0.8204062]\n",
      "Batch 49/700: Discriminator loss = 1.2433284521102905, GAN loss = [2.1637845, 0.706921, 0.7881607]\n",
      "Batch 50/700: Discriminator loss = 1.2041393518447876, GAN loss = [2.204821, 0.7294492, 0.8066949]\n",
      "Batch 51/700: Discriminator loss = 1.2068408727645874, GAN loss = [2.2141705, 0.7333459, 0.8121744]\n",
      "Batch 52/700: Discriminator loss = 1.2104357481002808, GAN loss = [2.1831145, 0.7203887, 0.7940906]\n",
      "Batch 53/700: Discriminator loss = 1.2152082920074463, GAN loss = [2.2147326, 0.7276034, 0.8185057]\n",
      "Batch 54/700: Discriminator loss = 1.2077280282974243, GAN loss = [2.2040608, 0.72379684, 0.8116464]\n",
      "Batch 55/700: Discriminator loss = 1.2317352294921875, GAN loss = [2.1806276, 0.71104765, 0.8009857]\n",
      "Batch 56/700: Discriminator loss = 1.227006435394287, GAN loss = [2.1672318, 0.70407426, 0.79458755]\n",
      "Batch 57/700: Discriminator loss = 1.2316696643829346, GAN loss = [2.1884365, 0.7153572, 0.8045272]\n",
      "Batch 58/700: Discriminator loss = 1.2262178659439087, GAN loss = [2.191483, 0.7089891, 0.81395173]\n",
      "Batch 59/700: Discriminator loss = 1.2049301862716675, GAN loss = [2.181656, 0.7261003, 0.7870213]\n",
      "Batch 60/700: Discriminator loss = 1.2170532941818237, GAN loss = [2.174897, 0.7116576, 0.79472685]\n",
      "Batch 61/700: Discriminator loss = 1.2155460119247437, GAN loss = [2.1686668, 0.7285173, 0.7716621]\n",
      "Batch 62/700: Discriminator loss = 1.2094616889953613, GAN loss = [2.2014952, 0.72287154, 0.8101597]\n",
      "Batch 63/700: Discriminator loss = 1.2237616777420044, GAN loss = [2.1681921, 0.7055337, 0.7942118]\n",
      "Batch 64/700: Discriminator loss = 1.2300390005111694, GAN loss = [2.1635666, 0.6968738, 0.79826707]\n",
      "Batch 65/700: Discriminator loss = 1.2164150476455688, GAN loss = [2.209784, 0.7080282, 0.833346]\n",
      "Batch 66/700: Discriminator loss = 1.1967167854309082, GAN loss = [2.2401798, 0.73973006, 0.8320629]\n",
      "Batch 67/700: Discriminator loss = 1.214137315750122, GAN loss = [2.1673906, 0.70978826, 0.7892319]\n",
      "Batch 68/700: Discriminator loss = 1.2097054719924927, GAN loss = [2.1902032, 0.72012275, 0.801736]\n",
      "Batch 69/700: Discriminator loss = 1.2202072143554688, GAN loss = [2.2185218, 0.73167086, 0.81853294]\n",
      "Batch 70/700: Discriminator loss = 1.2089742422103882, GAN loss = [2.160507, 0.72815627, 0.7640535]\n",
      "Batch 71/700: Discriminator loss = 1.2335455417633057, GAN loss = [2.1549199, 0.6961299, 0.7905148]\n",
      "Batch 72/700: Discriminator loss = 1.2023520469665527, GAN loss = [2.2276196, 0.7249759, 0.834385]\n",
      "Batch 73/700: Discriminator loss = 1.2273881435394287, GAN loss = [2.176789, 0.71721303, 0.7913259]\n",
      "Batch 74/700: Discriminator loss = 1.2321757078170776, GAN loss = [2.1767023, 0.70724237, 0.80120987]\n",
      "Batch 75/700: Discriminator loss = 1.1933653354644775, GAN loss = [2.224844, 0.7283034, 0.82829714]\n",
      "Batch 76/700: Discriminator loss = 1.2170636653900146, GAN loss = [2.220974, 0.718526, 0.8342135]\n",
      "Batch 77/700: Discriminator loss = 1.1984575986862183, GAN loss = [2.1863859, 0.7261776, 0.79198426]\n",
      "Batch 78/700: Discriminator loss = 1.2193951606750488, GAN loss = [2.2130804, 0.7159881, 0.82889676]\n",
      "Batch 79/700: Discriminator loss = 1.20973801612854, GAN loss = [2.1838152, 0.7215912, 0.79405123]\n",
      "Batch 80/700: Discriminator loss = 1.1972908973693848, GAN loss = [2.2397058, 0.7437092, 0.8278396]\n",
      "Batch 81/700: Discriminator loss = 1.2150332927703857, GAN loss = [2.211992, 0.7360538, 0.80781305]\n",
      "Batch 82/700: Discriminator loss = 1.2149187326431274, GAN loss = [2.1913729, 0.710194, 0.8130836]\n",
      "Batch 83/700: Discriminator loss = 1.2178407907485962, GAN loss = [2.1918442, 0.71428406, 0.8094772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 84/700: Discriminator loss = 1.2279373407363892, GAN loss = [2.227403, 0.724957, 0.8343846]\n",
      "Batch 85/700: Discriminator loss = 1.2177671194076538, GAN loss = [2.173764, 0.7235553, 0.7821618]\n",
      "Batch 86/700: Discriminator loss = 1.2059608697891235, GAN loss = [2.2063887, 0.72722954, 0.8111168]\n",
      "Batch 87/700: Discriminator loss = 1.2040581703186035, GAN loss = [2.1931672, 0.72336555, 0.80177695]\n",
      "Batch 88/700: Discriminator loss = 1.1853773593902588, GAN loss = [2.3250601, 0.7586733, 0.8983791]\n",
      "Batch 89/700: Discriminator loss = 1.2000051736831665, GAN loss = [2.2318797, 0.7483662, 0.8155145]\n",
      "Batch 90/700: Discriminator loss = 1.198598027229309, GAN loss = [2.2244773, 0.7383915, 0.81808734]\n",
      "Batch 91/700: Discriminator loss = 1.2092852592468262, GAN loss = [2.1744943, 0.72967565, 0.77682245]\n",
      "Batch 92/700: Discriminator loss = 1.2251280546188354, GAN loss = [2.2169828, 0.7208996, 0.8280975]\n",
      "Batch 93/700: Discriminator loss = 1.2173664569854736, GAN loss = [2.2216127, 0.7312756, 0.8223511]\n",
      "Batch 94/700: Discriminator loss = 1.233597993850708, GAN loss = [2.2028632, 0.7139145, 0.8209393]\n",
      "Batch 95/700: Discriminator loss = 1.2295931577682495, GAN loss = [2.1972446, 0.7200003, 0.80922264]\n",
      "Batch 96/700: Discriminator loss = 1.219329833984375, GAN loss = [2.2016633, 0.73410815, 0.79953593]\n",
      "Batch 97/700: Discriminator loss = 1.216038703918457, GAN loss = [2.202149, 0.72550386, 0.8086455]\n",
      "Batch 98/700: Discriminator loss = 1.227719783782959, GAN loss = [2.1936555, 0.7190127, 0.8066587]\n",
      "Batch 99/700: Discriminator loss = 1.225577712059021, GAN loss = [2.1961334, 0.71983093, 0.80833215]\n",
      "Batch 100/700: Discriminator loss = 1.2097657918930054, GAN loss = [2.274755, 0.73442435, 0.8723654]\n",
      "Batch 101/700: Discriminator loss = 1.2033742666244507, GAN loss = [2.2283034, 0.7313859, 0.8289564]\n",
      "Batch 102/700: Discriminator loss = 1.2103391885757446, GAN loss = [2.2181387, 0.72340155, 0.826795]\n",
      "Batch 103/700: Discriminator loss = 1.209152102470398, GAN loss = [2.2536478, 0.7258676, 0.85985106]\n",
      "Batch 104/700: Discriminator loss = 1.2078694105148315, GAN loss = [2.244131, 0.7392592, 0.83696204]\n",
      "Batch 105/700: Discriminator loss = 1.1941049098968506, GAN loss = [2.2508855, 0.74256355, 0.84042937]\n",
      "Batch 106/700: Discriminator loss = 1.2026216983795166, GAN loss = [2.2267857, 0.72989607, 0.82902265]\n",
      "Batch 107/700: Discriminator loss = 1.1955068111419678, GAN loss = [2.2742803, 0.745133, 0.86129415]\n",
      "Batch 108/700: Discriminator loss = 1.2004820108413696, GAN loss = [2.260628, 0.7337543, 0.8590461]\n",
      "Batch 109/700: Discriminator loss = 1.2182492017745972, GAN loss = [2.232115, 0.73060316, 0.8337155]\n",
      "Batch 110/700: Discriminator loss = 1.2436658143997192, GAN loss = [2.2047458, 0.7067593, 0.8302152]\n",
      "Batch 111/700: Discriminator loss = 1.2304130792617798, GAN loss = [2.1968513, 0.7266309, 0.8024742]\n",
      "Batch 112/700: Discriminator loss = 1.2040483951568604, GAN loss = [2.2590268, 0.7408657, 0.850436]\n",
      "Batch 113/700: Discriminator loss = 1.2388592958450317, GAN loss = [2.2255514, 0.7216601, 0.83617884]\n",
      "Batch 114/700: Discriminator loss = 1.22415292263031, GAN loss = [2.2291865, 0.7251844, 0.8363125]\n",
      "Batch 115/700: Discriminator loss = 1.25337553024292, GAN loss = [2.1741023, 0.70920897, 0.79719716]\n",
      "Batch 116/700: Discriminator loss = 1.220098614692688, GAN loss = [2.2198658, 0.72748697, 0.82468826]\n",
      "Batch 117/700: Discriminator loss = 1.250915288925171, GAN loss = [2.1980314, 0.69654936, 0.83379537]\n",
      "Batch 118/700: Discriminator loss = 1.214816927909851, GAN loss = [2.2135725, 0.74189574, 0.80400676]\n",
      "Batch 119/700: Discriminator loss = 1.2273422479629517, GAN loss = [2.21823, 0.72584015, 0.824723]\n",
      "Batch 120/700: Discriminator loss = 1.2106305360794067, GAN loss = [2.234313, 0.7465471, 0.8201166]\n",
      "Batch 121/700: Discriminator loss = 1.1912310123443604, GAN loss = [2.2272778, 0.74619055, 0.81345475]\n",
      "Batch 122/700: Discriminator loss = 1.2044063806533813, GAN loss = [2.23527, 0.7424421, 0.8252102]\n",
      "Batch 123/700: Discriminator loss = 1.193864107131958, GAN loss = [2.2358067, 0.7621013, 0.80610514]\n",
      "Batch 124/700: Discriminator loss = 1.2177852392196655, GAN loss = [2.2090814, 0.72246146, 0.8190501]\n",
      "Batch 125/700: Discriminator loss = 1.2235090732574463, GAN loss = [2.2436073, 0.72326124, 0.8528101]\n",
      "Batch 126/700: Discriminator loss = 1.2077680826187134, GAN loss = [2.1841664, 0.7295262, 0.78712493]\n",
      "Batch 127/700: Discriminator loss = 1.2228071689605713, GAN loss = [2.2407312, 0.7290207, 0.8442171]\n",
      "Batch 128/700: Discriminator loss = 1.2419437170028687, GAN loss = [2.2050273, 0.7104572, 0.82709855]\n",
      "Batch 129/700: Discriminator loss = 1.2151455879211426, GAN loss = [2.2204044, 0.72614664, 0.8268147]\n",
      "Batch 130/700: Discriminator loss = 1.217721939086914, GAN loss = [2.2216315, 0.74084985, 0.8133633]\n",
      "Batch 131/700: Discriminator loss = 1.2174317836761475, GAN loss = [2.2015352, 0.72995067, 0.80417323]\n",
      "Batch 132/700: Discriminator loss = 1.2040256261825562, GAN loss = [2.2200933, 0.74642336, 0.8062607]\n",
      "Batch 133/700: Discriminator loss = 1.21700918674469, GAN loss = [2.2195528, 0.74608773, 0.80604506]\n",
      "Batch 134/700: Discriminator loss = 1.2109975814819336, GAN loss = [2.2525094, 0.7629726, 0.82210547]\n",
      "Batch 135/700: Discriminator loss = 1.2157899141311646, GAN loss = [2.24838, 0.745311, 0.83563894]\n",
      "Batch 136/700: Discriminator loss = 1.1960134506225586, GAN loss = [2.2613287, 0.7667278, 0.82717466]\n",
      "Batch 137/700: Discriminator loss = 1.2163810729980469, GAN loss = [2.2050045, 0.73516923, 0.8024267]\n",
      "Batch 138/700: Discriminator loss = 1.1937835216522217, GAN loss = [2.2511692, 0.7551819, 0.8286098]\n",
      "Batch 139/700: Discriminator loss = 1.215147852897644, GAN loss = [2.2182705, 0.74809045, 0.8028344]\n",
      "Batch 140/700: Discriminator loss = 1.226183295249939, GAN loss = [2.2362585, 0.7289334, 0.8400002]\n",
      "Batch 141/700: Discriminator loss = 1.194473147392273, GAN loss = [2.2159944, 0.75036967, 0.7983341]\n",
      "Batch 142/700: Discriminator loss = 1.1970975399017334, GAN loss = [2.2859123, 0.7506443, 0.868016]\n",
      "Batch 143/700: Discriminator loss = 1.1944149732589722, GAN loss = [2.2621522, 0.74750847, 0.8474221]\n",
      "Batch 144/700: Discriminator loss = 1.205449104309082, GAN loss = [2.2494102, 0.74459404, 0.83763194]\n",
      "Batch 145/700: Discriminator loss = 1.1909562349319458, GAN loss = [2.2907932, 0.75824964, 0.8654022]\n",
      "Batch 146/700: Discriminator loss = 1.2003343105316162, GAN loss = [2.256618, 0.76306665, 0.8264496]\n",
      "Batch 147/700: Discriminator loss = 1.1914383172988892, GAN loss = [2.2425923, 0.7501829, 0.8253541]\n",
      "Batch 148/700: Discriminator loss = 1.1965283155441284, GAN loss = [2.2234232, 0.7578413, 0.79858214]\n",
      "Batch 149/700: Discriminator loss = 1.1621713638305664, GAN loss = [2.312876, 0.7876738, 0.85824674]\n",
      "Batch 150/700: Discriminator loss = 1.200941801071167, GAN loss = [2.3166175, 0.7517144, 0.8979778]\n",
      "Batch 151/700: Discriminator loss = 1.1900174617767334, GAN loss = [2.2795444, 0.76639074, 0.8462487]\n",
      "Batch 152/700: Discriminator loss = 1.2072420120239258, GAN loss = [2.2627149, 0.7480024, 0.8478241]\n",
      "Batch 153/700: Discriminator loss = 1.168172001838684, GAN loss = [2.297241, 0.78199506, 0.84838694]\n",
      "Batch 154/700: Discriminator loss = 1.183037519454956, GAN loss = [2.282448, 0.75755155, 0.85808295]\n",
      "Batch 155/700: Discriminator loss = 1.1897876262664795, GAN loss = [2.2321434, 0.74262327, 0.82276136]\n",
      "Batch 156/700: Discriminator loss = 1.1731467247009277, GAN loss = [2.3085675, 0.7661783, 0.875666]\n",
      "Batch 157/700: Discriminator loss = 1.1997312307357788, GAN loss = [2.2005064, 0.73193437, 0.80187476]\n",
      "Batch 158/700: Discriminator loss = 1.183810830116272, GAN loss = [2.291688, 0.75648916, 0.8685318]\n",
      "Batch 159/700: Discriminator loss = 1.1734614372253418, GAN loss = [2.3028204, 0.7733993, 0.8627692]\n",
      "Batch 160/700: Discriminator loss = 1.18333101272583, GAN loss = [2.3039782, 0.7541755, 0.88315934]\n",
      "Batch 161/700: Discriminator loss = 1.174726963043213, GAN loss = [2.3053799, 0.76647013, 0.872288]\n",
      "Batch 162/700: Discriminator loss = 1.1817958354949951, GAN loss = [2.332724, 0.76055616, 0.90557826]\n",
      "Batch 163/700: Discriminator loss = 1.1671665906906128, GAN loss = [2.2994432, 0.7664965, 0.86638933]\n",
      "Batch 164/700: Discriminator loss = 1.2010754346847534, GAN loss = [2.2437453, 0.7415712, 0.8356544]\n",
      "Batch 165/700: Discriminator loss = 1.2158489227294922, GAN loss = [2.2314308, 0.724982, 0.83997506]\n",
      "Batch 166/700: Discriminator loss = 1.1685433387756348, GAN loss = [2.2908905, 0.7610936, 0.8633662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 167/700: Discriminator loss = 1.1871641874313354, GAN loss = [2.3142495, 0.7572901, 0.89056045]\n",
      "Batch 168/700: Discriminator loss = 1.1793376207351685, GAN loss = [2.3108768, 0.76415724, 0.8803638]\n",
      "Batch 169/700: Discriminator loss = 1.180806279182434, GAN loss = [2.3283193, 0.7649054, 0.8971012]\n",
      "Batch 170/700: Discriminator loss = 1.1784173250198364, GAN loss = [2.2939148, 0.75244355, 0.8751923]\n",
      "Batch 171/700: Discriminator loss = 1.1856772899627686, GAN loss = [2.363721, 0.76191175, 0.9355667]\n",
      "Batch 172/700: Discriminator loss = 1.1677809953689575, GAN loss = [2.3112285, 0.76690996, 0.8781108]\n",
      "Batch 173/700: Discriminator loss = 1.1962077617645264, GAN loss = [2.3002002, 0.7354006, 0.8986204]\n",
      "Batch 174/700: Discriminator loss = 1.1773874759674072, GAN loss = [2.3467865, 0.7645966, 0.91602117]\n",
      "Batch 175/700: Discriminator loss = 1.1759438514709473, GAN loss = [2.2830124, 0.76519716, 0.8516721]\n",
      "Batch 176/700: Discriminator loss = 1.1991171836853027, GAN loss = [2.3082, 0.74551445, 0.8965645]\n",
      "Batch 177/700: Discriminator loss = 1.1942533254623413, GAN loss = [2.219524, 0.73136276, 0.82207924]\n",
      "Batch 178/700: Discriminator loss = 1.2078191041946411, GAN loss = [2.284512, 0.74002284, 0.8784473]\n",
      "Batch 179/700: Discriminator loss = 1.220628023147583, GAN loss = [2.2560177, 0.7282371, 0.86177146]\n",
      "Batch 180/700: Discriminator loss = 1.21733558177948, GAN loss = [2.2047253, 0.740448, 0.7982957]\n",
      "Batch 181/700: Discriminator loss = 1.2309191226959229, GAN loss = [2.2498262, 0.73133665, 0.8525424]\n",
      "Batch 182/700: Discriminator loss = 1.2506141662597656, GAN loss = [2.2105036, 0.7127228, 0.8318697]\n",
      "Batch 183/700: Discriminator loss = 1.2275513410568237, GAN loss = [2.2208705, 0.7381772, 0.81681997]\n",
      "Batch 184/700: Discriminator loss = 1.2306265830993652, GAN loss = [2.2219114, 0.7321699, 0.8238961]\n",
      "Batch 185/700: Discriminator loss = 1.2432740926742554, GAN loss = [2.2089553, 0.72221327, 0.8209259]\n",
      "Batch 186/700: Discriminator loss = 1.2543069124221802, GAN loss = [2.1645317, 0.7152328, 0.78351784]\n",
      "Batch 187/700: Discriminator loss = 1.270342469215393, GAN loss = [2.145494, 0.68639123, 0.7933478]\n",
      "Batch 188/700: Discriminator loss = 1.246399998664856, GAN loss = [2.1806254, 0.7133304, 0.8015707]\n",
      "Batch 189/700: Discriminator loss = 1.2313647270202637, GAN loss = [2.162893, 0.7284469, 0.7687427]\n",
      "Batch 190/700: Discriminator loss = 1.2638018131256104, GAN loss = [2.115859, 0.6915567, 0.7586163]\n",
      "Batch 191/700: Discriminator loss = 1.2779128551483154, GAN loss = [2.1387966, 0.6947522, 0.77839106]\n",
      "Batch 192/700: Discriminator loss = 1.2174972295761108, GAN loss = [2.1787248, 0.7375444, 0.77555335]\n",
      "Batch 193/700: Discriminator loss = 1.2395507097244263, GAN loss = [2.17583, 0.7144205, 0.79581076]\n",
      "Batch 194/700: Discriminator loss = 1.2684282064437866, GAN loss = [2.1592872, 0.7052656, 0.78846407]\n",
      "Batch 195/700: Discriminator loss = 1.23905348777771, GAN loss = [2.1680417, 0.7278856, 0.77463335]\n",
      "Batch 196/700: Discriminator loss = 1.2357029914855957, GAN loss = [2.1549156, 0.72357506, 0.7658721]\n",
      "Batch 197/700: Discriminator loss = 1.21820867061615, GAN loss = [2.1410687, 0.7340492, 0.74160105]\n",
      "Batch 198/700: Discriminator loss = 1.2078877687454224, GAN loss = [2.1563983, 0.7385619, 0.7524703]\n",
      "Batch 199/700: Discriminator loss = 1.2219452857971191, GAN loss = [2.165479, 0.7148558, 0.78530174]\n",
      "Batch 200/700: Discriminator loss = 1.2044920921325684, GAN loss = [2.2084758, 0.73332673, 0.80985093]\n",
      "Batch 201/700: Discriminator loss = 1.2297639846801758, GAN loss = [2.141952, 0.7051079, 0.7715847]\n",
      "Batch 202/700: Discriminator loss = 1.2197037935256958, GAN loss = [2.1854017, 0.7075455, 0.8126363]\n",
      "Batch 203/700: Discriminator loss = 1.2336808443069458, GAN loss = [2.1673377, 0.70874274, 0.7934023]\n",
      "Batch 204/700: Discriminator loss = 1.2068617343902588, GAN loss = [2.181767, 0.7298096, 0.7867944]\n",
      "Batch 205/700: Discriminator loss = 1.2217057943344116, GAN loss = [2.1810915, 0.71727616, 0.7986882]\n",
      "Batch 206/700: Discriminator loss = 1.218010425567627, GAN loss = [2.1966102, 0.7177007, 0.81382525]\n",
      "Batch 207/700: Discriminator loss = 1.245245337486267, GAN loss = [2.2021635, 0.71100974, 0.8260972]\n",
      "Batch 208/700: Discriminator loss = 1.2272440195083618, GAN loss = [2.1802545, 0.71910775, 0.79611933]\n",
      "Batch 209/700: Discriminator loss = 1.229953646659851, GAN loss = [2.1658227, 0.72047234, 0.7803708]\n",
      "Batch 210/700: Discriminator loss = 1.2015674114227295, GAN loss = [2.2199104, 0.7395941, 0.8153923]\n",
      "Batch 211/700: Discriminator loss = 1.2100194692611694, GAN loss = [2.2022407, 0.7301023, 0.80725634]\n",
      "Batch 212/700: Discriminator loss = 1.1974586248397827, GAN loss = [2.2073193, 0.7400429, 0.80243325]\n",
      "Batch 213/700: Discriminator loss = 1.204153060913086, GAN loss = [2.2068098, 0.7366418, 0.80536056]\n",
      "Batch 214/700: Discriminator loss = 1.2095404863357544, GAN loss = [2.202552, 0.7276922, 0.81008613]\n",
      "Batch 215/700: Discriminator loss = 1.2008605003356934, GAN loss = [2.2492912, 0.74839646, 0.83615065]\n",
      "Batch 216/700: Discriminator loss = 1.203120231628418, GAN loss = [2.2309756, 0.74748284, 0.8187774]\n",
      "Batch 217/700: Discriminator loss = 1.205309510231018, GAN loss = [2.1987736, 0.7225754, 0.8115142]\n",
      "Batch 218/700: Discriminator loss = 1.227183222770691, GAN loss = [2.252317, 0.7149206, 0.87274384]\n",
      "Batch 219/700: Discriminator loss = 1.2211726903915405, GAN loss = [2.2207048, 0.73944986, 0.81662154]\n",
      "Batch 220/700: Discriminator loss = 1.2111866474151611, GAN loss = [2.2456515, 0.74456644, 0.83645004]\n",
      "Batch 221/700: Discriminator loss = 1.2232110500335693, GAN loss = [2.2107675, 0.7236302, 0.8225043]\n",
      "Batch 222/700: Discriminator loss = 1.2328054904937744, GAN loss = [2.2217815, 0.72489715, 0.83224714]\n",
      "Batch 223/700: Discriminator loss = 1.2356189489364624, GAN loss = [2.2335806, 0.7130056, 0.85594183]\n",
      "Batch 224/700: Discriminator loss = 1.2093061208724976, GAN loss = [2.249498, 0.75677687, 0.8280861]\n",
      "Batch 225/700: Discriminator loss = 1.218126654624939, GAN loss = [2.249336, 0.729225, 0.8554661]\n",
      "Batch 226/700: Discriminator loss = 1.2135696411132812, GAN loss = [2.2773395, 0.7424384, 0.8702534]\n",
      "Batch 227/700: Discriminator loss = 1.2448488473892212, GAN loss = [2.1864312, 0.7081689, 0.81360817]\n",
      "Batch 228/700: Discriminator loss = 1.246143102645874, GAN loss = [2.1685097, 0.7140429, 0.7898149]\n",
      "Batch 229/700: Discriminator loss = 1.2247288227081299, GAN loss = [2.18945, 0.7334052, 0.7913999]\n",
      "Batch 230/700: Discriminator loss = 1.2210911512374878, GAN loss = [2.2039695, 0.7448373, 0.7944834]\n",
      "Batch 231/700: Discriminator loss = 1.243665099143982, GAN loss = [2.1912625, 0.7171953, 0.8094253]\n",
      "Batch 232/700: Discriminator loss = 1.2214317321777344, GAN loss = [2.209896, 0.7401004, 0.80514693]\n",
      "Batch 233/700: Discriminator loss = 1.2459293603897095, GAN loss = [2.165561, 0.700094, 0.80082273]\n",
      "Batch 234/700: Discriminator loss = 1.2283380031585693, GAN loss = [2.179322, 0.72162455, 0.7930642]\n",
      "Batch 235/700: Discriminator loss = 1.2341160774230957, GAN loss = [2.1886995, 0.7093735, 0.81470454]\n",
      "Batch 236/700: Discriminator loss = 1.212116003036499, GAN loss = [2.1667442, 0.73696893, 0.76517004]\n",
      "Batch 237/700: Discriminator loss = 1.2263283729553223, GAN loss = [2.1708903, 0.7173696, 0.7889386]\n",
      "Batch 238/700: Discriminator loss = 1.235172986984253, GAN loss = [2.1823106, 0.7244213, 0.79332787]\n",
      "Batch 239/700: Discriminator loss = 1.203678011894226, GAN loss = [2.1918566, 0.74331355, 0.7840015]\n",
      "Batch 240/700: Discriminator loss = 1.2404146194458008, GAN loss = [2.1675444, 0.7020828, 0.8009478]\n",
      "Batch 241/700: Discriminator loss = 1.2148360013961792, GAN loss = [2.1682568, 0.73155814, 0.7722034]\n",
      "Batch 242/700: Discriminator loss = 1.2227288484573364, GAN loss = [2.1589649, 0.7164873, 0.77800834]\n",
      "Batch 243/700: Discriminator loss = 1.2288153171539307, GAN loss = [2.201176, 0.7137453, 0.8229972]\n",
      "Batch 244/700: Discriminator loss = 1.2339177131652832, GAN loss = [2.1677551, 0.71725166, 0.786101]\n",
      "Batch 245/700: Discriminator loss = 1.2201690673828125, GAN loss = [2.1897614, 0.7228615, 0.80253327]\n",
      "Batch 246/700: Discriminator loss = 1.2299078702926636, GAN loss = [2.1648567, 0.7176162, 0.78292274]\n",
      "Batch 247/700: Discriminator loss = 1.2097772359848022, GAN loss = [2.1839612, 0.7384444, 0.78123504]\n",
      "Batch 248/700: Discriminator loss = 1.2321466207504272, GAN loss = [2.1796591, 0.7139307, 0.8014677]\n",
      "Batch 249/700: Discriminator loss = 1.2133055925369263, GAN loss = [2.2355185, 0.72585076, 0.8454506]\n",
      "Batch 250/700: Discriminator loss = 1.1896995306015015, GAN loss = [2.2180395, 0.74043113, 0.81341803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 251/700: Discriminator loss = 1.2003768682479858, GAN loss = [2.1693342, 0.73419535, 0.7709811]\n",
      "Batch 252/700: Discriminator loss = 1.2088431119918823, GAN loss = [2.1892614, 0.71529406, 0.8098552]\n",
      "Batch 253/700: Discriminator loss = 1.2195281982421875, GAN loss = [2.1506815, 0.71826243, 0.7683471]\n",
      "Batch 254/700: Discriminator loss = 1.1996244192123413, GAN loss = [2.2011433, 0.7279384, 0.8091745]\n",
      "Batch 255/700: Discriminator loss = 1.2203985452651978, GAN loss = [2.164812, 0.7092399, 0.7915764]\n",
      "Batch 256/700: Discriminator loss = 1.210533857345581, GAN loss = [2.1898267, 0.72544205, 0.8004272]\n",
      "Batch 257/700: Discriminator loss = 1.226979374885559, GAN loss = [2.1716795, 0.7237034, 0.78405005]\n",
      "Batch 258/700: Discriminator loss = 1.221295714378357, GAN loss = [2.1953056, 0.71697944, 0.8144338]\n",
      "Batch 259/700: Discriminator loss = 1.208447813987732, GAN loss = [2.1867712, 0.7249805, 0.7979246]\n",
      "Batch 260/700: Discriminator loss = 1.2141661643981934, GAN loss = [2.2201462, 0.7347843, 0.8215263]\n",
      "Batch 261/700: Discriminator loss = 1.2219358682632446, GAN loss = [2.2192357, 0.7143247, 0.84112096]\n",
      "Batch 262/700: Discriminator loss = 1.223513126373291, GAN loss = [2.1759934, 0.7100256, 0.80220985]\n",
      "Batch 263/700: Discriminator loss = 1.2187929153442383, GAN loss = [2.1790242, 0.7119584, 0.8033401]\n",
      "Batch 264/700: Discriminator loss = 1.2280315160751343, GAN loss = [2.174477, 0.7049649, 0.80580515]\n",
      "Batch 265/700: Discriminator loss = 1.2148966789245605, GAN loss = [2.2231593, 0.7219096, 0.8375775]\n",
      "Batch 266/700: Discriminator loss = 1.2105677127838135, GAN loss = [2.1795306, 0.71799386, 0.7979064]\n",
      "Batch 267/700: Discriminator loss = 1.211429476737976, GAN loss = [2.257141, 0.72930205, 0.86426526]\n",
      "Batch 268/700: Discriminator loss = 1.2025634050369263, GAN loss = [2.200803, 0.7260349, 0.8112398]\n",
      "Batch 269/700: Discriminator loss = 1.2418452501296997, GAN loss = [2.1907096, 0.6966293, 0.8305904]\n",
      "Batch 270/700: Discriminator loss = 1.202394723892212, GAN loss = [2.170458, 0.72604644, 0.780954]\n",
      "Batch 271/700: Discriminator loss = 1.2172386646270752, GAN loss = [2.208422, 0.7209533, 0.824033]\n",
      "Batch 272/700: Discriminator loss = 1.2079132795333862, GAN loss = [2.1919136, 0.711446, 0.8170518]\n",
      "Batch 273/700: Discriminator loss = 1.2109590768814087, GAN loss = [2.1745594, 0.71178156, 0.7993886]\n",
      "Batch 274/700: Discriminator loss = 1.1920067071914673, GAN loss = [2.2542958, 0.72965056, 0.86128163]\n",
      "Batch 275/700: Discriminator loss = 1.2205556631088257, GAN loss = [2.155124, 0.71035063, 0.78144693]\n",
      "Batch 276/700: Discriminator loss = 1.1858632564544678, GAN loss = [2.2165418, 0.73295474, 0.8202992]\n",
      "Batch 277/700: Discriminator loss = 1.223385214805603, GAN loss = [2.1351125, 0.69784003, 0.77402014]\n",
      "Batch 278/700: Discriminator loss = 1.2069967985153198, GAN loss = [2.1960907, 0.713659, 0.81921786]\n",
      "Batch 279/700: Discriminator loss = 1.2177270650863647, GAN loss = [2.2597034, 0.7267849, 0.86972517]\n",
      "Batch 280/700: Discriminator loss = 1.2080554962158203, GAN loss = [2.1854534, 0.7227642, 0.799509]\n",
      "Batch 281/700: Discriminator loss = 1.1999379396438599, GAN loss = [2.1648324, 0.7186391, 0.78302974]\n",
      "Batch 282/700: Discriminator loss = 1.2134723663330078, GAN loss = [2.1825445, 0.7068151, 0.8125714]\n",
      "Batch 283/700: Discriminator loss = 1.2281333208084106, GAN loss = [2.1812153, 0.70075685, 0.817307]\n",
      "Batch 284/700: Discriminator loss = 1.2227282524108887, GAN loss = [2.1580455, 0.70331603, 0.7915897]\n",
      "Batch 285/700: Discriminator loss = 1.2213701009750366, GAN loss = [2.1795812, 0.70474887, 0.81170523]\n",
      "Batch 286/700: Discriminator loss = 1.2072252035140991, GAN loss = [2.2151542, 0.72504205, 0.82698226]\n",
      "Batch 287/700: Discriminator loss = 1.215834379196167, GAN loss = [2.2124627, 0.711775, 0.8375501]\n",
      "Batch 288/700: Discriminator loss = 1.2218654155731201, GAN loss = [2.208437, 0.7110483, 0.8342405]\n",
      "Batch 289/700: Discriminator loss = 1.223802089691162, GAN loss = [2.1792867, 0.7045527, 0.8115784]\n",
      "Batch 290/700: Discriminator loss = 1.2260148525238037, GAN loss = [2.1547866, 0.703213, 0.7884175]\n",
      "Batch 291/700: Discriminator loss = 1.2231138944625854, GAN loss = [2.1711895, 0.6882069, 0.819825]\n",
      "Batch 292/700: Discriminator loss = 1.2236592769622803, GAN loss = [2.1473525, 0.6931955, 0.79099184]\n",
      "Batch 293/700: Discriminator loss = 1.2331339120864868, GAN loss = [2.214178, 0.70377684, 0.84724015]\n",
      "Batch 294/700: Discriminator loss = 1.2103700637817383, GAN loss = [2.1806488, 0.72087425, 0.79661375]\n",
      "Batch 295/700: Discriminator loss = 1.2030847072601318, GAN loss = [2.209925, 0.73169684, 0.81507516]\n",
      "Batch 296/700: Discriminator loss = 1.1922838687896729, GAN loss = [2.2345216, 0.7408387, 0.8305339]\n",
      "Batch 297/700: Discriminator loss = 1.2128753662109375, GAN loss = [2.1987453, 0.7174159, 0.8181866]\n",
      "Batch 298/700: Discriminator loss = 1.2202659845352173, GAN loss = [2.199864, 0.6929787, 0.8437408]\n",
      "Batch 299/700: Discriminator loss = 1.2022747993469238, GAN loss = [2.2085001, 0.7234773, 0.82187414]\n",
      "Batch 300/700: Discriminator loss = 1.223461389541626, GAN loss = [2.168399, 0.70274335, 0.8025142]\n",
      "Batch 301/700: Discriminator loss = 1.2044224739074707, GAN loss = [2.1992328, 0.7246827, 0.81142545]\n",
      "Batch 302/700: Discriminator loss = 1.2241591215133667, GAN loss = [2.1841722, 0.70322627, 0.81782115]\n",
      "Batch 303/700: Discriminator loss = 1.2165298461914062, GAN loss = [2.1948075, 0.7159503, 0.8157356]\n",
      "Batch 304/700: Discriminator loss = 1.219466209411621, GAN loss = [2.1592557, 0.6990067, 0.79712546]\n",
      "Batch 305/700: Discriminator loss = 1.2115429639816284, GAN loss = [2.1851773, 0.7144498, 0.80761224]\n",
      "Batch 306/700: Discriminator loss = 1.2146563529968262, GAN loss = [2.1864097, 0.7052244, 0.8180698]\n",
      "Batch 307/700: Discriminator loss = 1.219112515449524, GAN loss = [2.1827462, 0.71013486, 0.8095107]\n",
      "Batch 308/700: Discriminator loss = 1.2323193550109863, GAN loss = [2.1594915, 0.6918529, 0.80455595]\n",
      "Batch 309/700: Discriminator loss = 1.2135487794876099, GAN loss = [2.2100055, 0.7226954, 0.8242489]\n",
      "Batch 310/700: Discriminator loss = 1.2163000106811523, GAN loss = [2.213016, 0.7108802, 0.83907354]\n",
      "Batch 311/700: Discriminator loss = 1.2201441526412964, GAN loss = [2.2208598, 0.711967, 0.8458137]\n",
      "Batch 312/700: Discriminator loss = 1.2090396881103516, GAN loss = [2.1950004, 0.7146465, 0.81726044]\n",
      "Batch 313/700: Discriminator loss = 1.227903962135315, GAN loss = [2.1948378, 0.7129266, 0.8188153]\n",
      "Batch 314/700: Discriminator loss = 1.2131166458129883, GAN loss = [2.2524962, 0.7236569, 0.8657467]\n",
      "Batch 315/700: Discriminator loss = 1.2253365516662598, GAN loss = [2.1864061, 0.70540243, 0.8179134]\n",
      "Batch 316/700: Discriminator loss = 1.216959834098816, GAN loss = [2.2243538, 0.72158104, 0.83968604]\n",
      "Batch 317/700: Discriminator loss = 1.19832444190979, GAN loss = [2.2364824, 0.72511816, 0.84828675]\n",
      "Batch 318/700: Discriminator loss = 1.2130446434020996, GAN loss = [2.218837, 0.7120204, 0.84375]\n",
      "Batch 319/700: Discriminator loss = 1.2018049955368042, GAN loss = [2.2324028, 0.7370346, 0.83231807]\n",
      "Batch 320/700: Discriminator loss = 1.2104963064193726, GAN loss = [2.2507236, 0.71760124, 0.87009954]\n",
      "Batch 321/700: Discriminator loss = 1.203582763671875, GAN loss = [2.2242181, 0.7285311, 0.83268774]\n",
      "Batch 322/700: Discriminator loss = 1.2335208654403687, GAN loss = [2.2023926, 0.7094019, 0.8300037]\n",
      "Batch 323/700: Discriminator loss = 1.198430061340332, GAN loss = [2.2460916, 0.72432023, 0.8587927]\n",
      "Batch 324/700: Discriminator loss = 1.2031601667404175, GAN loss = [2.2138221, 0.72912323, 0.8217267]\n",
      "Batch 325/700: Discriminator loss = 1.2015538215637207, GAN loss = [2.2950473, 0.73684764, 0.8952222]\n",
      "Batch 326/700: Discriminator loss = 1.1793138980865479, GAN loss = [2.2464743, 0.74578875, 0.8377063]\n",
      "Batch 327/700: Discriminator loss = 1.2186495065689087, GAN loss = [2.2143767, 0.7086915, 0.8427061]\n",
      "Batch 328/700: Discriminator loss = 1.1888407468795776, GAN loss = [2.2777667, 0.73714197, 0.87766665]\n",
      "Batch 329/700: Discriminator loss = 1.1726480722427368, GAN loss = [2.287881, 0.75753075, 0.86743075]\n",
      "Batch 330/700: Discriminator loss = 1.2012702226638794, GAN loss = [2.277838, 0.7321184, 0.8828204]\n",
      "Batch 331/700: Discriminator loss = 1.178895354270935, GAN loss = [2.2378023, 0.74217224, 0.83274996]\n",
      "Batch 332/700: Discriminator loss = 1.191375494003296, GAN loss = [2.2377563, 0.74220246, 0.8326877]\n",
      "Batch 333/700: Discriminator loss = 1.1805016994476318, GAN loss = [2.3318067, 0.74624765, 0.9227159]\n",
      "Batch 334/700: Discriminator loss = 1.1827425956726074, GAN loss = [2.281047, 0.75260663, 0.86563903]\n",
      "Batch 335/700: Discriminator loss = 1.197080135345459, GAN loss = [2.2394204, 0.73611414, 0.84053606]\n",
      "Batch 336/700: Discriminator loss = 1.220342993736267, GAN loss = [2.2405465, 0.7182776, 0.85953975]\n",
      "Batch 337/700: Discriminator loss = 1.1938645839691162, GAN loss = [2.254497, 0.7466486, 0.845165]\n",
      "Batch 338/700: Discriminator loss = 1.2042651176452637, GAN loss = [2.2184083, 0.7340156, 0.8217487]\n",
      "Batch 339/700: Discriminator loss = 1.1822189092636108, GAN loss = [2.3073013, 0.75888336, 0.88579917]\n",
      "Batch 340/700: Discriminator loss = 1.2014923095703125, GAN loss = [2.279939, 0.7386567, 0.87866455]\n",
      "Batch 341/700: Discriminator loss = 1.193437099456787, GAN loss = [2.2626274, 0.74477327, 0.85524577]\n",
      "Batch 342/700: Discriminator loss = 1.1838408708572388, GAN loss = [2.2849565, 0.75778013, 0.86460036]\n",
      "Batch 343/700: Discriminator loss = 1.1936436891555786, GAN loss = [2.274985, 0.7524171, 0.8600332]\n",
      "Batch 344/700: Discriminator loss = 1.2184257507324219, GAN loss = [2.2447093, 0.72531533, 0.8568792]\n",
      "Batch 345/700: Discriminator loss = 1.1945691108703613, GAN loss = [2.2847545, 0.7649733, 0.8572928]\n",
      "Batch 346/700: Discriminator loss = 1.2192375659942627, GAN loss = [2.2423944, 0.73980606, 0.84012693]\n",
      "Batch 347/700: Discriminator loss = 1.174355387687683, GAN loss = [2.245028, 0.7676227, 0.81496567]\n",
      "Batch 348/700: Discriminator loss = 1.2079499959945679, GAN loss = [2.2322903, 0.7333431, 0.8365276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 349/700: Discriminator loss = 1.2167917490005493, GAN loss = [2.241573, 0.7410349, 0.8381374]\n",
      "Batch 350/700: Discriminator loss = 1.1974064111709595, GAN loss = [2.2687533, 0.74504876, 0.8613132]\n",
      "Batch 351/700: Discriminator loss = 1.2059277296066284, GAN loss = [2.2670639, 0.74994016, 0.8547506]\n",
      "Batch 352/700: Discriminator loss = 1.21183180809021, GAN loss = [2.2176573, 0.7389214, 0.81638265]\n",
      "Batch 353/700: Discriminator loss = 1.2085496187210083, GAN loss = [2.2783313, 0.7402396, 0.8757476]\n",
      "Batch 354/700: Discriminator loss = 1.1953353881835938, GAN loss = [2.2526934, 0.76707953, 0.82327515]\n",
      "Batch 355/700: Discriminator loss = 1.2247610092163086, GAN loss = [2.2463753, 0.73730546, 0.8467268]\n",
      "Batch 356/700: Discriminator loss = 1.2123228311538696, GAN loss = [2.267077, 0.7404681, 0.86424845]\n",
      "Batch 357/700: Discriminator loss = 1.2232344150543213, GAN loss = [2.2246459, 0.7269322, 0.8353531]\n",
      "Batch 358/700: Discriminator loss = 1.2149360179901123, GAN loss = [2.2052968, 0.73657465, 0.80636454]\n",
      "Batch 359/700: Discriminator loss = 1.2341209650039673, GAN loss = [2.1863327, 0.7233897, 0.8006088]\n",
      "Batch 360/700: Discriminator loss = 1.2091237306594849, GAN loss = [2.2159944, 0.73677605, 0.8168946]\n",
      "Batch 361/700: Discriminator loss = 1.24147367477417, GAN loss = [2.1551692, 0.70823044, 0.78463393]\n",
      "Batch 362/700: Discriminator loss = 1.2116773128509521, GAN loss = [2.1815076, 0.73416716, 0.7850644]\n",
      "Batch 363/700: Discriminator loss = 1.2076442241668701, GAN loss = [2.1900125, 0.733462, 0.7943115]\n",
      "Batch 364/700: Discriminator loss = 1.2107983827590942, GAN loss = [2.2289262, 0.74655014, 0.8201696]\n",
      "Batch 365/700: Discriminator loss = 1.2113527059555054, GAN loss = [2.2108476, 0.73394203, 0.8147363]\n",
      "Batch 366/700: Discriminator loss = 1.1981135606765747, GAN loss = [2.2347074, 0.74305826, 0.8295217]\n",
      "Batch 367/700: Discriminator loss = 1.1900218725204468, GAN loss = [2.2491908, 0.75914305, 0.82796973]\n",
      "Batch 368/700: Discriminator loss = 1.1756716966629028, GAN loss = [2.2305803, 0.7694904, 0.7990532]\n",
      "Batch 369/700: Discriminator loss = 1.2088619470596313, GAN loss = [2.2086504, 0.7258671, 0.8207915]\n",
      "Batch 370/700: Discriminator loss = 1.202104091644287, GAN loss = [2.223323, 0.7370894, 0.82427454]\n",
      "Batch 371/700: Discriminator loss = 1.186208963394165, GAN loss = [2.2535849, 0.7616953, 0.8299646]\n",
      "Batch 372/700: Discriminator loss = 1.2184618711471558, GAN loss = [2.2280405, 0.72647494, 0.83967924]\n",
      "Batch 373/700: Discriminator loss = 1.2088403701782227, GAN loss = [2.2640615, 0.7492119, 0.8529952]\n",
      "Batch 374/700: Discriminator loss = 1.2226850986480713, GAN loss = [2.234388, 0.73191255, 0.84064776]\n",
      "Batch 375/700: Discriminator loss = 1.21107017993927, GAN loss = [2.249099, 0.75227135, 0.8350235]\n",
      "Batch 376/700: Discriminator loss = 1.2148237228393555, GAN loss = [2.2444453, 0.7558146, 0.8268408]\n",
      "Batch 377/700: Discriminator loss = 1.262589693069458, GAN loss = [2.1623635, 0.7045929, 0.7959919]\n",
      "Batch 378/700: Discriminator loss = 1.2087149620056152, GAN loss = [2.2307532, 0.7502652, 0.8187206]\n",
      "Batch 379/700: Discriminator loss = 1.197077751159668, GAN loss = [2.2585938, 0.7632267, 0.83362883]\n",
      "Batch 380/700: Discriminator loss = 1.2052289247512817, GAN loss = [2.2365043, 0.7547769, 0.8200028]\n",
      "Batch 381/700: Discriminator loss = 1.2131319046020508, GAN loss = [2.2374518, 0.74089956, 0.8348297]\n",
      "Batch 382/700: Discriminator loss = 1.2004917860031128, GAN loss = [2.2914126, 0.7584191, 0.87128264]\n",
      "Batch 383/700: Discriminator loss = 1.1817961931228638, GAN loss = [2.3045177, 0.7831497, 0.85967284]\n",
      "Batch 384/700: Discriminator loss = 1.1870381832122803, GAN loss = [2.345189, 0.77281684, 0.9106877]\n",
      "Batch 385/700: Discriminator loss = 1.2103238105773926, GAN loss = [2.2674263, 0.74974495, 0.85601515]\n",
      "Batch 386/700: Discriminator loss = 1.172599196434021, GAN loss = [2.3157468, 0.7788478, 0.87526137]\n",
      "Batch 387/700: Discriminator loss = 1.2079484462738037, GAN loss = [2.2995355, 0.7537445, 0.8841871]\n",
      "Batch 388/700: Discriminator loss = 1.1996876001358032, GAN loss = [2.2959301, 0.76578546, 0.86857307]\n",
      "Batch 389/700: Discriminator loss = 1.233430027961731, GAN loss = [2.2442834, 0.733832, 0.8489156]\n",
      "Batch 390/700: Discriminator loss = 1.2565045356750488, GAN loss = [2.1539762, 0.7083196, 0.7841487]\n",
      "Batch 391/700: Discriminator loss = 1.219740867614746, GAN loss = [2.275938, 0.74356234, 0.8708873]\n",
      "Batch 392/700: Discriminator loss = 1.244010329246521, GAN loss = [2.2102804, 0.7402704, 0.8085403]\n",
      "Batch 393/700: Discriminator loss = 1.200126051902771, GAN loss = [2.2598662, 0.7621987, 0.83620024]\n",
      "Batch 394/700: Discriminator loss = 1.228076457977295, GAN loss = [2.2090225, 0.7421885, 0.80537444]\n",
      "Batch 395/700: Discriminator loss = 1.1906657218933105, GAN loss = [2.2592402, 0.7773178, 0.82047814]\n",
      "Batch 396/700: Discriminator loss = 1.2045868635177612, GAN loss = [2.2271569, 0.7533869, 0.81235695]\n",
      "Batch 397/700: Discriminator loss = 1.1704151630401611, GAN loss = [2.2464862, 0.78003114, 0.80506533]\n",
      "Batch 398/700: Discriminator loss = 1.1885926723480225, GAN loss = [2.2803557, 0.7714446, 0.8475349]\n",
      "Batch 399/700: Discriminator loss = 1.1400704383850098, GAN loss = [2.3163865, 0.81403166, 0.84100235]\n",
      "Batch 400/700: Discriminator loss = 1.1592475175857544, GAN loss = [2.2773468, 0.795598, 0.8204307]\n",
      "Batch 401/700: Discriminator loss = 1.1399927139282227, GAN loss = [2.2980864, 0.79794574, 0.8388672]\n",
      "Batch 402/700: Discriminator loss = 1.164817214012146, GAN loss = [2.3434434, 0.78877485, 0.89344156]\n",
      "Batch 403/700: Discriminator loss = 1.1560946702957153, GAN loss = [2.34894, 0.786619, 0.90114343]\n",
      "Batch 404/700: Discriminator loss = 1.1333882808685303, GAN loss = [2.292643, 0.80094457, 0.8305601]\n",
      "Batch 405/700: Discriminator loss = 1.134598731994629, GAN loss = [2.3334913, 0.8069959, 0.8653958]\n",
      "Batch 406/700: Discriminator loss = 1.1426358222961426, GAN loss = [2.3175442, 0.79492545, 0.86155695]\n",
      "Batch 407/700: Discriminator loss = 1.1794812679290771, GAN loss = [2.2549813, 0.75118476, 0.8427781]\n",
      "Batch 408/700: Discriminator loss = 1.1731942892074585, GAN loss = [2.3463578, 0.76358664, 0.9217919]\n",
      "Batch 409/700: Discriminator loss = 1.1772047281265259, GAN loss = [2.2777371, 0.7602482, 0.8565248]\n",
      "Batch 410/700: Discriminator loss = 1.1850569248199463, GAN loss = [2.345137, 0.7744176, 0.909769]\n",
      "Batch 411/700: Discriminator loss = 1.1957334280014038, GAN loss = [2.3040125, 0.7728566, 0.8702073]\n",
      "Batch 412/700: Discriminator loss = 1.1981654167175293, GAN loss = [2.2912638, 0.7737269, 0.85657746]\n",
      "Batch 413/700: Discriminator loss = 1.2046791315078735, GAN loss = [2.3579926, 0.7759656, 0.9210595]\n",
      "Batch 414/700: Discriminator loss = 1.180673599243164, GAN loss = [2.2967792, 0.7815134, 0.854293]\n",
      "Batch 415/700: Discriminator loss = 1.184183955192566, GAN loss = [2.317979, 0.79077256, 0.8662507]\n",
      "Batch 416/700: Discriminator loss = 1.1886649131774902, GAN loss = [2.3259249, 0.812094, 0.8528966]\n",
      "Batch 417/700: Discriminator loss = 1.156498908996582, GAN loss = [2.3226764, 0.8216085, 0.84015274]\n",
      "Batch 418/700: Discriminator loss = 1.1529570817947388, GAN loss = [2.3683093, 0.81647086, 0.8909259]\n",
      "Batch 419/700: Discriminator loss = 1.1429195404052734, GAN loss = [2.4288495, 0.83689535, 0.931042]\n",
      "Batch 420/700: Discriminator loss = 1.149176836013794, GAN loss = [2.3494935, 0.81410813, 0.8744744]\n",
      "Batch 421/700: Discriminator loss = 1.1739099025726318, GAN loss = [2.3370576, 0.784012, 0.8921203]\n",
      "Batch 422/700: Discriminator loss = 1.171427845954895, GAN loss = [2.3357482, 0.77516913, 0.8996501]\n",
      "Batch 423/700: Discriminator loss = 1.168116807937622, GAN loss = [2.3305776, 0.79097146, 0.87869704]\n",
      "Batch 424/700: Discriminator loss = 1.1950223445892334, GAN loss = [2.3144848, 0.7571174, 0.89648384]\n",
      "Batch 425/700: Discriminator loss = 1.1804569959640503, GAN loss = [2.3102138, 0.7705088, 0.8788479]\n",
      "Batch 426/700: Discriminator loss = 1.2404040098190308, GAN loss = [2.2266366, 0.7126656, 0.85313934]\n",
      "Batch 427/700: Discriminator loss = 1.1922577619552612, GAN loss = [2.3026893, 0.76477605, 0.8771024]\n",
      "Batch 428/700: Discriminator loss = 1.1999231576919556, GAN loss = [2.3388069, 0.7614887, 0.91653496]\n",
      "Batch 429/700: Discriminator loss = 1.2063180208206177, GAN loss = [2.3043294, 0.74192286, 0.90164834]\n",
      "Batch 430/700: Discriminator loss = 1.2256321907043457, GAN loss = [2.285202, 0.7469878, 0.87748015]\n",
      "Batch 431/700: Discriminator loss = 1.1916162967681885, GAN loss = [2.2979467, 0.7610929, 0.8761418]\n",
      "Batch 432/700: Discriminator loss = 1.1839431524276733, GAN loss = [2.2847981, 0.76597977, 0.85813934]\n",
      "Batch 433/700: Discriminator loss = 1.187132477760315, GAN loss = [2.2677827, 0.76325434, 0.8438827]\n",
      "Batch 434/700: Discriminator loss = 1.1810410022735596, GAN loss = [2.360674, 0.764612, 0.9354417]\n",
      "Batch 435/700: Discriminator loss = 1.1887601613998413, GAN loss = [2.25861, 0.7671124, 0.8309209]\n",
      "Batch 436/700: Discriminator loss = 1.175600528717041, GAN loss = [2.2941387, 0.7809301, 0.852659]\n",
      "Batch 437/700: Discriminator loss = 1.1731269359588623, GAN loss = [2.2954416, 0.76805925, 0.86684984]\n",
      "Batch 438/700: Discriminator loss = 1.1672085523605347, GAN loss = [2.3011906, 0.7766113, 0.86407]\n",
      "Batch 439/700: Discriminator loss = 1.2169322967529297, GAN loss = [2.262798, 0.7406273, 0.8617037]\n",
      "Batch 440/700: Discriminator loss = 1.1496015787124634, GAN loss = [2.2931054, 0.7879857, 0.844684]\n",
      "Batch 441/700: Discriminator loss = 1.1998108625411987, GAN loss = [2.2892962, 0.7554409, 0.8734577]\n",
      "Batch 442/700: Discriminator loss = 1.2198092937469482, GAN loss = [2.2596207, 0.7631972, 0.8360429]\n",
      "Batch 443/700: Discriminator loss = 1.1612215042114258, GAN loss = [2.29828, 0.78855, 0.84936494]\n",
      "Batch 444/700: Discriminator loss = 1.1836886405944824, GAN loss = [2.2499897, 0.7607888, 0.82884]\n",
      "Batch 445/700: Discriminator loss = 1.20094633102417, GAN loss = [2.2829764, 0.7520594, 0.8705847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 446/700: Discriminator loss = 1.1850212812423706, GAN loss = [2.2737315, 0.78541374, 0.82801026]\n",
      "Batch 447/700: Discriminator loss = 1.1769073009490967, GAN loss = [2.2771902, 0.77374244, 0.8431584]\n",
      "Batch 448/700: Discriminator loss = 1.1782582998275757, GAN loss = [2.2855415, 0.7759149, 0.8493488]\n",
      "Batch 449/700: Discriminator loss = 1.1935133934020996, GAN loss = [2.296751, 0.7606597, 0.8758111]\n",
      "Batch 450/700: Discriminator loss = 1.170680046081543, GAN loss = [2.3421636, 0.7783516, 0.90353423]\n",
      "Batch 451/700: Discriminator loss = 1.180229663848877, GAN loss = [2.329023, 0.7782759, 0.8904787]\n",
      "Batch 452/700: Discriminator loss = 1.1807587146759033, GAN loss = [2.2837827, 0.7774023, 0.8461473]\n",
      "Batch 453/700: Discriminator loss = 1.1717890501022339, GAN loss = [2.2756279, 0.77872205, 0.83671]\n",
      "Batch 454/700: Discriminator loss = 1.1891485452651978, GAN loss = [2.329271, 0.7797678, 0.8893446]\n",
      "Batch 455/700: Discriminator loss = 1.1768851280212402, GAN loss = [2.3067667, 0.76936567, 0.87728286]\n",
      "Batch 456/700: Discriminator loss = 1.1745285987854004, GAN loss = [2.298929, 0.78024024, 0.8585895]\n",
      "Batch 457/700: Discriminator loss = 1.1640743017196655, GAN loss = [2.3533666, 0.79550225, 0.8978037]\n",
      "Batch 458/700: Discriminator loss = 1.1672804355621338, GAN loss = [2.328738, 0.7805205, 0.888194]\n",
      "Batch 459/700: Discriminator loss = 1.1736609935760498, GAN loss = [2.3719583, 0.80217344, 0.9098089]\n",
      "Batch 460/700: Discriminator loss = 1.1792941093444824, GAN loss = [2.2862601, 0.7824915, 0.84383863]\n",
      "Batch 461/700: Discriminator loss = 1.2196778059005737, GAN loss = [2.2524614, 0.7240622, 0.86851233]\n",
      "Batch 462/700: Discriminator loss = 1.2109700441360474, GAN loss = [2.2402725, 0.7338519, 0.84659845]\n",
      "Batch 463/700: Discriminator loss = 1.2085647583007812, GAN loss = [2.2741451, 0.73896027, 0.8754074]\n",
      "Batch 464/700: Discriminator loss = 1.2227766513824463, GAN loss = [2.2370715, 0.73114294, 0.8461976]\n",
      "Batch 465/700: Discriminator loss = 1.2190269231796265, GAN loss = [2.2655194, 0.7263222, 0.87950814]\n",
      "Batch 466/700: Discriminator loss = 1.1945606470108032, GAN loss = [2.2385173, 0.7418627, 0.8369912]\n",
      "Batch 467/700: Discriminator loss = 1.2300773859024048, GAN loss = [2.252206, 0.7359311, 0.8566526]\n",
      "Batch 468/700: Discriminator loss = 1.22246515750885, GAN loss = [2.2333517, 0.72414595, 0.8496406]\n",
      "Batch 469/700: Discriminator loss = 1.2328288555145264, GAN loss = [2.1857529, 0.72178656, 0.8044516]\n",
      "Batch 470/700: Discriminator loss = 1.2293046712875366, GAN loss = [2.2062023, 0.7064291, 0.8403166]\n",
      "Batch 471/700: Discriminator loss = 1.235019564628601, GAN loss = [2.2363844, 0.714584, 0.8623981]\n",
      "Batch 472/700: Discriminator loss = 1.223136067390442, GAN loss = [2.2178595, 0.72581255, 0.83270544]\n",
      "Batch 473/700: Discriminator loss = 1.208624005317688, GAN loss = [2.2165444, 0.7380298, 0.81922066]\n",
      "Batch 474/700: Discriminator loss = 1.2402607202529907, GAN loss = [2.157169, 0.710027, 0.7878958]\n",
      "Batch 475/700: Discriminator loss = 1.2232537269592285, GAN loss = [2.233873, 0.71001935, 0.8646425]\n",
      "Batch 476/700: Discriminator loss = 1.19936203956604, GAN loss = [2.2311764, 0.7369028, 0.83509886]\n",
      "Batch 477/700: Discriminator loss = 1.2226225137710571, GAN loss = [2.1753578, 0.7179749, 0.7982598]\n",
      "Batch 478/700: Discriminator loss = 1.220347285270691, GAN loss = [2.2264595, 0.7227999, 0.8445634]\n",
      "Batch 479/700: Discriminator loss = 1.205275297164917, GAN loss = [2.2352486, 0.72576296, 0.85040253]\n",
      "Batch 480/700: Discriminator loss = 1.2255175113677979, GAN loss = [2.1891234, 0.72263235, 0.8074369]\n",
      "Batch 481/700: Discriminator loss = 1.2172945737838745, GAN loss = [2.2271674, 0.73011214, 0.83803195]\n",
      "Batch 482/700: Discriminator loss = 1.2342731952667236, GAN loss = [2.1773975, 0.7100713, 0.8083194]\n",
      "Batch 483/700: Discriminator loss = 1.202499508857727, GAN loss = [2.2132847, 0.7375753, 0.8167131]\n",
      "Batch 484/700: Discriminator loss = 1.2275452613830566, GAN loss = [2.2058997, 0.72253007, 0.82438797]\n",
      "Batch 485/700: Discriminator loss = 1.2368017435073853, GAN loss = [2.194412, 0.7172432, 0.8182]\n",
      "Batch 486/700: Discriminator loss = 1.2385168075561523, GAN loss = [2.2040648, 0.71068144, 0.8344427]\n",
      "Batch 487/700: Discriminator loss = 1.2317322492599487, GAN loss = [2.1968265, 0.7122426, 0.825672]\n",
      "Batch 488/700: Discriminator loss = 1.2229716777801514, GAN loss = [2.2162862, 0.72526896, 0.83211684]\n",
      "Batch 489/700: Discriminator loss = 1.1969066858291626, GAN loss = [2.172099, 0.7401534, 0.77305686]\n",
      "Batch 490/700: Discriminator loss = 1.199393630027771, GAN loss = [2.1762657, 0.7381311, 0.77927923]\n",
      "Batch 491/700: Discriminator loss = 1.2177413702011108, GAN loss = [2.214959, 0.72801775, 0.8281163]\n",
      "Batch 492/700: Discriminator loss = 1.217192530632019, GAN loss = [2.1837382, 0.7272195, 0.79772496]\n",
      "Batch 493/700: Discriminator loss = 1.202883243560791, GAN loss = [2.1993594, 0.73699975, 0.80360246]\n",
      "Batch 494/700: Discriminator loss = 1.2184600830078125, GAN loss = [2.1972399, 0.7123349, 0.82616585]\n",
      "Batch 495/700: Discriminator loss = 1.2311195135116577, GAN loss = [2.2396967, 0.71977377, 0.86120534]\n",
      "Batch 496/700: Discriminator loss = 1.1950069665908813, GAN loss = [2.2593467, 0.7488637, 0.85178083]\n",
      "Batch 497/700: Discriminator loss = 1.208741307258606, GAN loss = [2.2476604, 0.75673366, 0.83223134]\n",
      "Batch 498/700: Discriminator loss = 1.2020108699798584, GAN loss = [2.2245703, 0.7424906, 0.8233994]\n",
      "Batch 499/700: Discriminator loss = 1.2341278791427612, GAN loss = [2.216948, 0.7315257, 0.82676256]\n",
      "Batch 500/700: Discriminator loss = 1.1754329204559326, GAN loss = [2.2526479, 0.75181067, 0.84222406]\n",
      "Batch 501/700: Discriminator loss = 1.1944608688354492, GAN loss = [2.2045014, 0.7388227, 0.80710924]\n",
      "Batch 502/700: Discriminator loss = 1.215114712715149, GAN loss = [2.2084246, 0.7334922, 0.816407]\n",
      "Batch 503/700: Discriminator loss = 1.2280460596084595, GAN loss = [2.201846, 0.71688294, 0.82647306]\n",
      "Batch 504/700: Discriminator loss = 1.2051886320114136, GAN loss = [2.2021894, 0.74044037, 0.803285]\n",
      "Batch 505/700: Discriminator loss = 1.1922715902328491, GAN loss = [2.2252908, 0.74984586, 0.8170341]\n",
      "Batch 506/700: Discriminator loss = 1.2156281471252441, GAN loss = [2.2174168, 0.73524857, 0.82380927]\n",
      "Batch 507/700: Discriminator loss = 1.2073863744735718, GAN loss = [2.1672535, 0.7292308, 0.7797043]\n",
      "Batch 508/700: Discriminator loss = 1.2159568071365356, GAN loss = [2.2063565, 0.7210376, 0.8270388]\n",
      "Batch 509/700: Discriminator loss = 1.2225658893585205, GAN loss = [2.1759918, 0.71915644, 0.7985891]\n",
      "Batch 510/700: Discriminator loss = 1.2078078985214233, GAN loss = [2.1894505, 0.73302925, 0.7982119]\n",
      "Batch 511/700: Discriminator loss = 1.2119388580322266, GAN loss = [2.2273958, 0.73310137, 0.8361109]\n",
      "Batch 512/700: Discriminator loss = 1.20310378074646, GAN loss = [2.2192943, 0.7284271, 0.8327233]\n",
      "Batch 513/700: Discriminator loss = 1.2264560461044312, GAN loss = [2.1697571, 0.71647596, 0.7951865]\n",
      "Batch 514/700: Discriminator loss = 1.2470548152923584, GAN loss = [2.2029874, 0.7163054, 0.8286392]\n",
      "Batch 515/700: Discriminator loss = 1.2088274955749512, GAN loss = [2.2246513, 0.7442407, 0.82240725]\n",
      "Batch 516/700: Discriminator loss = 1.2127940654754639, GAN loss = [2.166112, 0.7208023, 0.78734016]\n",
      "Batch 517/700: Discriminator loss = 1.2134902477264404, GAN loss = [2.2576191, 0.7291563, 0.87051743]\n",
      "Batch 518/700: Discriminator loss = 1.2125005722045898, GAN loss = [2.2054553, 0.72083, 0.8266977]\n",
      "Batch 519/700: Discriminator loss = 1.2093720436096191, GAN loss = [2.1893823, 0.73929685, 0.792196]\n",
      "Batch 520/700: Discriminator loss = 1.1863608360290527, GAN loss = [2.2093246, 0.7539223, 0.7975545]\n",
      "Batch 521/700: Discriminator loss = 1.1959296464920044, GAN loss = [2.265681, 0.7468782, 0.86099684]\n",
      "Batch 522/700: Discriminator loss = 1.2332834005355835, GAN loss = [2.2115602, 0.72083604, 0.832957]\n",
      "Batch 523/700: Discriminator loss = 1.208977222442627, GAN loss = [2.215806, 0.7290552, 0.8290053]\n",
      "Batch 524/700: Discriminator loss = 1.2189159393310547, GAN loss = [2.1835833, 0.74247956, 0.7833721]\n",
      "Batch 525/700: Discriminator loss = 1.209791660308838, GAN loss = [2.1852582, 0.7287342, 0.79879344]\n",
      "Batch 526/700: Discriminator loss = 1.204407811164856, GAN loss = [2.1790597, 0.7330928, 0.78824866]\n",
      "Batch 527/700: Discriminator loss = 1.1972612142562866, GAN loss = [2.2355242, 0.7392957, 0.83854604]\n",
      "Batch 528/700: Discriminator loss = 1.2381699085235596, GAN loss = [2.1588292, 0.7108435, 0.79032546]\n",
      "Batch 529/700: Discriminator loss = 1.2052927017211914, GAN loss = [2.1907465, 0.7324353, 0.80066943]\n",
      "Batch 530/700: Discriminator loss = 1.1818149089813232, GAN loss = [2.2280338, 0.7527594, 0.81764716]\n",
      "Batch 531/700: Discriminator loss = 1.1834304332733154, GAN loss = [2.2448204, 0.73743844, 0.84976596]\n",
      "Batch 532/700: Discriminator loss = 1.1775180101394653, GAN loss = [2.2656252, 0.7605187, 0.84750587]\n",
      "Batch 533/700: Discriminator loss = 1.18302321434021, GAN loss = [2.216854, 0.7532177, 0.80606097]\n",
      "Batch 534/700: Discriminator loss = 1.1950806379318237, GAN loss = [2.2359662, 0.7414914, 0.83693373]\n",
      "Batch 535/700: Discriminator loss = 1.2180519104003906, GAN loss = [2.160803, 0.712083, 0.79121786]\n",
      "Batch 536/700: Discriminator loss = 1.202518105506897, GAN loss = [2.2406752, 0.73653305, 0.84667236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 537/700: Discriminator loss = 1.2212128639221191, GAN loss = [2.243506, 0.73486334, 0.8511916]\n",
      "Batch 538/700: Discriminator loss = 1.212927222251892, GAN loss = [2.2336395, 0.7298706, 0.846344]\n",
      "Batch 539/700: Discriminator loss = 1.210145354270935, GAN loss = [2.2349553, 0.7424228, 0.8351233]\n",
      "Batch 540/700: Discriminator loss = 1.202651023864746, GAN loss = [2.2590518, 0.7463197, 0.85532403]\n",
      "Batch 541/700: Discriminator loss = 1.2196153402328491, GAN loss = [2.2268765, 0.74339694, 0.82606363]\n",
      "Batch 542/700: Discriminator loss = 1.2068473100662231, GAN loss = [2.2151263, 0.7473393, 0.8103589]\n",
      "Batch 543/700: Discriminator loss = 1.2148792743682861, GAN loss = [2.2361848, 0.74943686, 0.82929695]\n",
      "Batch 544/700: Discriminator loss = 1.2075412273406982, GAN loss = [2.1824584, 0.74500895, 0.77997255]\n",
      "Batch 545/700: Discriminator loss = 1.2335269451141357, GAN loss = [2.2173643, 0.73581225, 0.8240548]\n",
      "Batch 546/700: Discriminator loss = 1.2104724645614624, GAN loss = [2.2577922, 0.7680334, 0.83223045]\n",
      "Batch 547/700: Discriminator loss = 1.1902096271514893, GAN loss = [2.260575, 0.77422965, 0.8287561]\n",
      "Batch 548/700: Discriminator loss = 1.1998014450073242, GAN loss = [2.2167041, 0.75988007, 0.7991827]\n",
      "Batch 549/700: Discriminator loss = 1.1922860145568848, GAN loss = [2.1983638, 0.7490168, 0.79168373]\n",
      "Batch 550/700: Discriminator loss = 1.2145847082138062, GAN loss = [2.2380354, 0.7370741, 0.84328073]\n",
      "Batch 551/700: Discriminator loss = 1.1945319175720215, GAN loss = [2.2119422, 0.75424075, 0.8000169]\n",
      "Batch 552/700: Discriminator loss = 1.1938995122909546, GAN loss = [2.2368896, 0.7503593, 0.82882094]\n",
      "Batch 553/700: Discriminator loss = 1.2011092901229858, GAN loss = [2.2533138, 0.7555068, 0.8400843]\n",
      "Batch 554/700: Discriminator loss = 1.2007155418395996, GAN loss = [2.281793, 0.7464757, 0.8776009]\n",
      "Batch 555/700: Discriminator loss = 1.218440294265747, GAN loss = [2.2519746, 0.7260407, 0.8682223]\n",
      "Batch 556/700: Discriminator loss = 1.2041599750518799, GAN loss = [2.2629619, 0.7375938, 0.8676666]\n",
      "Batch 557/700: Discriminator loss = 1.2197240591049194, GAN loss = [2.2150888, 0.7359085, 0.82149553]\n",
      "Batch 558/700: Discriminator loss = 1.2178188562393188, GAN loss = [2.2190475, 0.72353804, 0.8378599]\n",
      "Batch 559/700: Discriminator loss = 1.1868551969528198, GAN loss = [2.2028744, 0.75794, 0.78732294]\n",
      "Batch 560/700: Discriminator loss = 1.1999826431274414, GAN loss = [2.2313786, 0.7340763, 0.8397189]\n",
      "Batch 561/700: Discriminator loss = 1.205026388168335, GAN loss = [2.2103968, 0.7320059, 0.8208547]\n",
      "Batch 562/700: Discriminator loss = 1.2062277793884277, GAN loss = [2.1962364, 0.7304368, 0.80829537]\n",
      "Batch 563/700: Discriminator loss = 1.2064465284347534, GAN loss = [2.220819, 0.7213221, 0.8420317]\n",
      "Batch 564/700: Discriminator loss = 1.2165039777755737, GAN loss = [2.2343216, 0.71771044, 0.85919654]\n",
      "Batch 565/700: Discriminator loss = 1.189562201499939, GAN loss = [2.2578704, 0.7408808, 0.85962224]\n",
      "Batch 566/700: Discriminator loss = 1.210126519203186, GAN loss = [2.2216823, 0.7218625, 0.8424925]\n",
      "Batch 567/700: Discriminator loss = 1.196045994758606, GAN loss = [2.23033, 0.7412663, 0.8317812]\n",
      "Batch 568/700: Discriminator loss = 1.171842336654663, GAN loss = [2.244044, 0.75900954, 0.8278026]\n",
      "Batch 569/700: Discriminator loss = 1.2109607458114624, GAN loss = [2.2206895, 0.72810227, 0.8354145]\n",
      "Batch 570/700: Discriminator loss = 1.199039101600647, GAN loss = [2.219339, 0.73828703, 0.8239474]\n",
      "Batch 571/700: Discriminator loss = 1.2050586938858032, GAN loss = [2.249131, 0.729047, 0.863038]\n",
      "Batch 572/700: Discriminator loss = 1.2176649570465088, GAN loss = [2.1736646, 0.706519, 0.8101577]\n",
      "Batch 573/700: Discriminator loss = 1.2149404287338257, GAN loss = [2.2408125, 0.7331827, 0.8507059]\n",
      "Batch 574/700: Discriminator loss = 1.2150325775146484, GAN loss = [2.199746, 0.7127134, 0.8301475]\n",
      "Batch 575/700: Discriminator loss = 1.2147101163864136, GAN loss = [2.2279885, 0.7339106, 0.83723426]\n",
      "Batch 576/700: Discriminator loss = 1.2315763235092163, GAN loss = [2.1729028, 0.7251274, 0.7909916]\n",
      "Batch 577/700: Discriminator loss = 1.2030143737792969, GAN loss = [2.220709, 0.7282281, 0.83575606]\n",
      "Batch 578/700: Discriminator loss = 1.2018202543258667, GAN loss = [2.216082, 0.73393774, 0.82547605]\n",
      "Batch 579/700: Discriminator loss = 1.210153341293335, GAN loss = [2.2280676, 0.7419498, 0.82949966]\n",
      "Batch 580/700: Discriminator loss = 1.2140647172927856, GAN loss = [2.2087777, 0.7272514, 0.82497126]\n",
      "Batch 581/700: Discriminator loss = 1.1921770572662354, GAN loss = [2.2283335, 0.73911357, 0.832723]\n",
      "Batch 582/700: Discriminator loss = 1.2292976379394531, GAN loss = [2.1925912, 0.71404916, 0.82206815]\n",
      "Batch 583/700: Discriminator loss = 1.229958176612854, GAN loss = [2.1808975, 0.71930784, 0.8051445]\n",
      "Batch 584/700: Discriminator loss = 1.2120774984359741, GAN loss = [2.203122, 0.72623515, 0.820489]\n",
      "Batch 585/700: Discriminator loss = 1.2271314859390259, GAN loss = [2.188911, 0.70877177, 0.82378846]\n",
      "Batch 586/700: Discriminator loss = 1.2205678224563599, GAN loss = [2.1766858, 0.7158325, 0.80454654]\n",
      "Batch 587/700: Discriminator loss = 1.2117056846618652, GAN loss = [2.179454, 0.727338, 0.7958542]\n",
      "Batch 588/700: Discriminator loss = 1.212652325630188, GAN loss = [2.1654656, 0.7335533, 0.7756829]\n",
      "Batch 589/700: Discriminator loss = 1.186297059059143, GAN loss = [2.1990654, 0.7573305, 0.7855438]\n",
      "Batch 590/700: Discriminator loss = 1.2114101648330688, GAN loss = [2.168844, 0.7257547, 0.78691673]\n",
      "Batch 591/700: Discriminator loss = 1.1983802318572998, GAN loss = [2.182779, 0.74832094, 0.7783004]\n",
      "Batch 592/700: Discriminator loss = 1.2049345970153809, GAN loss = [2.2012098, 0.73179084, 0.813298]\n",
      "Batch 593/700: Discriminator loss = 1.2109140157699585, GAN loss = [2.2143316, 0.737708, 0.82054657]\n",
      "Batch 594/700: Discriminator loss = 1.227209448814392, GAN loss = [2.1469066, 0.7103722, 0.7805133]\n",
      "Batch 595/700: Discriminator loss = 1.2213214635849, GAN loss = [2.1517937, 0.70148677, 0.7943322]\n",
      "Batch 596/700: Discriminator loss = 1.2048382759094238, GAN loss = [2.1351728, 0.72125465, 0.75797933]\n",
      "Batch 597/700: Discriminator loss = 1.2211520671844482, GAN loss = [2.1941617, 0.7140324, 0.82422674]\n",
      "Batch 598/700: Discriminator loss = 1.2115552425384521, GAN loss = [2.1434112, 0.71184075, 0.7756784]\n",
      "Batch 599/700: Discriminator loss = 1.2315348386764526, GAN loss = [2.1515222, 0.70132965, 0.79430234]\n",
      "Batch 600/700: Discriminator loss = 1.2125111818313599, GAN loss = [2.1691835, 0.7198137, 0.79349244]\n",
      "Batch 601/700: Discriminator loss = 1.2086879014968872, GAN loss = [2.1495142, 0.7147527, 0.7788972]\n",
      "Batch 602/700: Discriminator loss = 1.2129777669906616, GAN loss = [2.1421423, 0.7150407, 0.7712529]\n",
      "Batch 603/700: Discriminator loss = 1.1918203830718994, GAN loss = [2.1803284, 0.72514844, 0.79934853]\n",
      "Batch 604/700: Discriminator loss = 1.2036052942276, GAN loss = [2.1929371, 0.7226653, 0.8144586]\n",
      "Batch 605/700: Discriminator loss = 1.1971931457519531, GAN loss = [2.1822255, 0.7204056, 0.8060101]\n",
      "Batch 606/700: Discriminator loss = 1.21468186378479, GAN loss = [2.1567545, 0.7089457, 0.792008]\n",
      "Batch 607/700: Discriminator loss = 1.2037397623062134, GAN loss = [2.2096307, 0.7222811, 0.83156365]\n",
      "Batch 608/700: Discriminator loss = 1.212438941001892, GAN loss = [2.1864314, 0.7096418, 0.821017]\n",
      "Batch 609/700: Discriminator loss = 1.2120575904846191, GAN loss = [2.157979, 0.7107106, 0.79150724]\n",
      "Batch 610/700: Discriminator loss = 1.2243300676345825, GAN loss = [2.1968129, 0.7111198, 0.82993484]\n",
      "Batch 611/700: Discriminator loss = 1.209704041481018, GAN loss = [2.2114623, 0.7295854, 0.82612795]\n",
      "Batch 612/700: Discriminator loss = 1.211598515510559, GAN loss = [2.2136288, 0.7291468, 0.8287351]\n",
      "Batch 613/700: Discriminator loss = 1.190022587776184, GAN loss = [2.185098, 0.73622185, 0.793116]\n",
      "Batch 614/700: Discriminator loss = 1.188119649887085, GAN loss = [2.175151, 0.7321407, 0.7872598]\n",
      "Batch 615/700: Discriminator loss = 1.1993075609207153, GAN loss = [2.2157354, 0.72434914, 0.8356572]\n",
      "Batch 616/700: Discriminator loss = 1.1876084804534912, GAN loss = [2.2129757, 0.74075294, 0.8165062]\n",
      "Batch 617/700: Discriminator loss = 1.2006937265396118, GAN loss = [2.2177339, 0.73152715, 0.8304942]\n",
      "Batch 618/700: Discriminator loss = 1.1952999830245972, GAN loss = [2.1945047, 0.7263665, 0.8124412]\n",
      "Batch 619/700: Discriminator loss = 1.1998929977416992, GAN loss = [2.2020257, 0.72729075, 0.8190498]\n",
      "Batch 620/700: Discriminator loss = 1.2065619230270386, GAN loss = [2.16335, 0.7344331, 0.7732521]\n",
      "Batch 621/700: Discriminator loss = 1.2090953588485718, GAN loss = [2.1664202, 0.72525024, 0.78552926]\n",
      "Batch 622/700: Discriminator loss = 1.2058827877044678, GAN loss = [2.18342, 0.72125024, 0.8065578]\n",
      "Batch 623/700: Discriminator loss = 1.2152488231658936, GAN loss = [2.1662786, 0.705238, 0.80546266]\n",
      "Batch 624/700: Discriminator loss = 1.2049977779388428, GAN loss = [2.2247908, 0.7279635, 0.84127206]\n",
      "Batch 625/700: Discriminator loss = 1.207680583000183, GAN loss = [2.1882155, 0.70284134, 0.82983345]\n",
      "Batch 626/700: Discriminator loss = 1.1814301013946533, GAN loss = [2.2293015, 0.75087357, 0.82290655]\n",
      "Batch 627/700: Discriminator loss = 1.1906083822250366, GAN loss = [2.1876729, 0.7296461, 0.8025279]\n",
      "Batch 628/700: Discriminator loss = 1.1897433996200562, GAN loss = [2.2019281, 0.7436754, 0.80277985]\n",
      "Batch 629/700: Discriminator loss = 1.216647744178772, GAN loss = [2.140416, 0.7077377, 0.7772215]\n",
      "Batch 630/700: Discriminator loss = 1.2101106643676758, GAN loss = [2.2224083, 0.7176667, 0.8492777]\n",
      "Batch 631/700: Discriminator loss = 1.2077208757400513, GAN loss = [2.2069726, 0.72827804, 0.82321876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 632/700: Discriminator loss = 1.1924813985824585, GAN loss = [2.1909497, 0.732832, 0.80263937]\n",
      "Batch 633/700: Discriminator loss = 1.2283604145050049, GAN loss = [2.1647105, 0.7068917, 0.8023444]\n",
      "Batch 634/700: Discriminator loss = 1.2113010883331299, GAN loss = [2.1931396, 0.72384036, 0.81382614]\n",
      "Batch 635/700: Discriminator loss = 1.2174832820892334, GAN loss = [2.187574, 0.7129231, 0.8191744]\n",
      "Batch 636/700: Discriminator loss = 1.2224770784378052, GAN loss = [2.2147963, 0.71992815, 0.8393837]\n",
      "Batch 637/700: Discriminator loss = 1.2090827226638794, GAN loss = [2.2053142, 0.7239853, 0.8258263]\n",
      "Batch 638/700: Discriminator loss = 1.19986891746521, GAN loss = [2.222249, 0.73725516, 0.8294977]\n",
      "Batch 639/700: Discriminator loss = 1.2054017782211304, GAN loss = [2.2172787, 0.73181534, 0.82996833]\n",
      "Batch 640/700: Discriminator loss = 1.1729366779327393, GAN loss = [2.2641344, 0.77097845, 0.8376599]\n",
      "Batch 641/700: Discriminator loss = 1.2225885391235352, GAN loss = [2.1840513, 0.71314394, 0.81541014]\n",
      "Batch 642/700: Discriminator loss = 1.2128098011016846, GAN loss = [2.2508962, 0.7298962, 0.8655191]\n",
      "Batch 643/700: Discriminator loss = 1.2054156064987183, GAN loss = [2.2402592, 0.73506755, 0.8497322]\n",
      "Batch 644/700: Discriminator loss = 1.1976276636123657, GAN loss = [2.21164, 0.7370855, 0.8191159]\n",
      "Batch 645/700: Discriminator loss = 1.2098461389541626, GAN loss = [2.2185218, 0.7299127, 0.83318716]\n",
      "Batch 646/700: Discriminator loss = 1.2069225311279297, GAN loss = [2.2062495, 0.72212964, 0.828707]\n",
      "Batch 647/700: Discriminator loss = 1.1989790201187134, GAN loss = [2.2031956, 0.7376589, 0.81014246]\n",
      "Batch 648/700: Discriminator loss = 1.2169080972671509, GAN loss = [2.2052476, 0.723232, 0.8266357]\n",
      "Batch 649/700: Discriminator loss = 1.2226098775863647, GAN loss = [2.223886, 0.72870773, 0.83981186]\n",
      "Batch 650/700: Discriminator loss = 1.2146477699279785, GAN loss = [2.2311008, 0.7188618, 0.85687685]\n",
      "Batch 651/700: Discriminator loss = 1.2082140445709229, GAN loss = [2.2044294, 0.73384523, 0.8152318]\n",
      "Batch 652/700: Discriminator loss = 1.224733829498291, GAN loss = [2.2029788, 0.7171333, 0.83049464]\n",
      "Batch 653/700: Discriminator loss = 1.2269471883773804, GAN loss = [2.1570058, 0.7154582, 0.78620154]\n",
      "Batch 654/700: Discriminator loss = 1.241245150566101, GAN loss = [2.1754034, 0.70982087, 0.8102493]\n",
      "Batch 655/700: Discriminator loss = 1.2226008176803589, GAN loss = [2.1304271, 0.7082615, 0.7668489]\n",
      "Batch 656/700: Discriminator loss = 1.2486339807510376, GAN loss = [2.1870914, 0.6943285, 0.83746725]\n",
      "Batch 657/700: Discriminator loss = 1.2183138132095337, GAN loss = [2.1910565, 0.7212459, 0.81454605]\n",
      "Batch 658/700: Discriminator loss = 1.2180465459823608, GAN loss = [2.191496, 0.7283737, 0.807892]\n",
      "Batch 659/700: Discriminator loss = 1.2161450386047363, GAN loss = [2.202787, 0.73357826, 0.81403106]\n",
      "Batch 660/700: Discriminator loss = 1.2102748155593872, GAN loss = [2.1878638, 0.72549856, 0.8072326]\n",
      "Batch 661/700: Discriminator loss = 1.2095719575881958, GAN loss = [2.1859403, 0.7313958, 0.7994474]\n",
      "Batch 662/700: Discriminator loss = 1.1890455484390259, GAN loss = [2.2035403, 0.74145526, 0.80702287]\n",
      "Batch 663/700: Discriminator loss = 1.205169439315796, GAN loss = [2.194789, 0.7312777, 0.8084734]\n",
      "Batch 664/700: Discriminator loss = 1.209540843963623, GAN loss = [2.2357733, 0.74140626, 0.839362]\n",
      "Batch 665/700: Discriminator loss = 1.2042670249938965, GAN loss = [2.2403693, 0.74775124, 0.8376419]\n",
      "Batch 666/700: Discriminator loss = 1.1934162378311157, GAN loss = [2.2360537, 0.7529602, 0.82814926]\n",
      "Batch 667/700: Discriminator loss = 1.190040111541748, GAN loss = [2.2680342, 0.75498205, 0.85811806]\n",
      "Batch 668/700: Discriminator loss = 1.2048540115356445, GAN loss = [2.2428348, 0.7466156, 0.84128344]\n",
      "Batch 669/700: Discriminator loss = 1.201545238494873, GAN loss = [2.2222035, 0.7461844, 0.82109594]\n",
      "Batch 670/700: Discriminator loss = 1.1973704099655151, GAN loss = [2.22784, 0.7633506, 0.8095836]\n",
      "Batch 671/700: Discriminator loss = 1.2107127904891968, GAN loss = [2.2514021, 0.7451286, 0.8513856]\n",
      "Batch 672/700: Discriminator loss = 1.2066658735275269, GAN loss = [2.2458975, 0.75053567, 0.8404815]\n",
      "Batch 673/700: Discriminator loss = 1.1996374130249023, GAN loss = [2.2372053, 0.7539024, 0.8284378]\n",
      "Batch 674/700: Discriminator loss = 1.195275902748108, GAN loss = [2.2670503, 0.7631942, 0.8490026]\n",
      "Batch 675/700: Discriminator loss = 1.1997908353805542, GAN loss = [2.2865448, 0.7495526, 0.8821735]\n",
      "Batch 676/700: Discriminator loss = 1.1872358322143555, GAN loss = [2.2726963, 0.7775004, 0.84039134]\n",
      "Batch 677/700: Discriminator loss = 1.1837952136993408, GAN loss = [2.2759268, 0.77644587, 0.8446897]\n",
      "Batch 678/700: Discriminator loss = 1.218664526939392, GAN loss = [2.2889702, 0.7619071, 0.8722888]\n",
      "Batch 679/700: Discriminator loss = 1.2000495195388794, GAN loss = [2.3217, 0.7770503, 0.8898863]\n",
      "Batch 680/700: Discriminator loss = 1.2300041913986206, GAN loss = [2.3241296, 0.7698969, 0.89946747]\n",
      "Batch 681/700: Discriminator loss = 1.2467079162597656, GAN loss = [2.2408302, 0.74840593, 0.8376603]\n",
      "Batch 682/700: Discriminator loss = 1.207223892211914, GAN loss = [2.2525146, 0.7723673, 0.8253992]\n",
      "Batch 683/700: Discriminator loss = 1.2465941905975342, GAN loss = [2.238229, 0.7497657, 0.83370996]\n",
      "Batch 684/700: Discriminator loss = 1.2190592288970947, GAN loss = [2.2423854, 0.7690768, 0.81855536]\n",
      "Batch 685/700: Discriminator loss = 1.2178021669387817, GAN loss = [2.2456403, 0.76978844, 0.8210945]\n",
      "Batch 686/700: Discriminator loss = 1.2401249408721924, GAN loss = [2.2360578, 0.7474145, 0.8338768]\n",
      "Batch 687/700: Discriminator loss = 1.2112507820129395, GAN loss = [2.2462494, 0.77011, 0.8213744]\n",
      "Batch 688/700: Discriminator loss = 1.224830985069275, GAN loss = [2.1970644, 0.7446761, 0.79763776]\n",
      "Batch 689/700: Discriminator loss = 1.2314373254776, GAN loss = [2.1993818, 0.7528657, 0.7917553]\n",
      "Batch 690/700: Discriminator loss = 1.2220288515090942, GAN loss = [2.1955287, 0.7453787, 0.7953949]\n",
      "Batch 691/700: Discriminator loss = 1.2352113723754883, GAN loss = [2.2049747, 0.73878145, 0.81145144]\n",
      "Batch 692/700: Discriminator loss = 1.2107311487197876, GAN loss = [2.2075942, 0.74799573, 0.80487275]\n",
      "Batch 693/700: Discriminator loss = 1.2192347049713135, GAN loss = [2.1653419, 0.7368899, 0.7737323]\n",
      "Batch 694/700: Discriminator loss = 1.1789307594299316, GAN loss = [2.2007546, 0.7531435, 0.792919]\n",
      "Batch 695/700: Discriminator loss = 1.2085124254226685, GAN loss = [2.1751025, 0.7254679, 0.7949691]\n",
      "Batch 696/700: Discriminator loss = 1.218960165977478, GAN loss = [2.203955, 0.72304755, 0.8262725]\n",
      "Batch 697/700: Discriminator loss = 1.2099639177322388, GAN loss = [2.2532687, 0.7308681, 0.8677859]\n",
      "Batch 698/700: Discriminator loss = 1.2118420600891113, GAN loss = [2.2283964, 0.7312884, 0.84252244]\n",
      "Batch 699/700: Discriminator loss = 1.1974494457244873, GAN loss = [2.254036, 0.74585146, 0.85363275]\n",
      "Batch 700/700: Discriminator loss = 1.2101857662200928, GAN loss = [2.1846912, 0.72436, 0.8058134]\n",
      "Epoch 20/30\n",
      "Batch 1/700: Discriminator loss = 1.210150122642517, GAN loss = [2.2189026, 0.7244167, 0.8399969]\n",
      "Batch 2/700: Discriminator loss = 1.203053593635559, GAN loss = [2.1998823, 0.7327507, 0.81267077]\n",
      "Batch 3/700: Discriminator loss = 1.212926983833313, GAN loss = [2.2022746, 0.727242, 0.8206041]\n",
      "Batch 4/700: Discriminator loss = 1.1946486234664917, GAN loss = [2.2086673, 0.7341613, 0.820106]\n",
      "Batch 5/700: Discriminator loss = 1.2034207582473755, GAN loss = [2.2208405, 0.72464865, 0.84181094]\n",
      "Batch 6/700: Discriminator loss = 1.2032722234725952, GAN loss = [2.2165132, 0.7323976, 0.8297462]\n",
      "Batch 7/700: Discriminator loss = 1.2087377309799194, GAN loss = [2.2615647, 0.7367582, 0.87045944]\n",
      "Batch 8/700: Discriminator loss = 1.2163604497909546, GAN loss = [2.2759151, 0.7316625, 0.8899012]\n",
      "Batch 9/700: Discriminator loss = 1.2210960388183594, GAN loss = [2.2404034, 0.7188882, 0.8671589]\n",
      "Batch 10/700: Discriminator loss = 1.2142813205718994, GAN loss = [2.212653, 0.7323592, 0.8259225]\n",
      "Batch 11/700: Discriminator loss = 1.181471824645996, GAN loss = [2.2231576, 0.7586078, 0.81016]\n",
      "Batch 12/700: Discriminator loss = 1.2101353406906128, GAN loss = [2.2728548, 0.7433163, 0.8751379]\n",
      "Batch 13/700: Discriminator loss = 1.2103015184402466, GAN loss = [2.2407322, 0.7421899, 0.8441224]\n",
      "Batch 14/700: Discriminator loss = 1.2092009782791138, GAN loss = [2.2094486, 0.73893934, 0.81608826]\n",
      "Batch 15/700: Discriminator loss = 1.197800636291504, GAN loss = [2.2936194, 0.7485476, 0.89065576]\n",
      "Batch 16/700: Discriminator loss = 1.1941955089569092, GAN loss = [2.2486858, 0.7600076, 0.83427435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17/700: Discriminator loss = 1.203334927558899, GAN loss = [2.2532425, 0.75268775, 0.84617364]\n",
      "Batch 18/700: Discriminator loss = 1.1969492435455322, GAN loss = [2.2366228, 0.7446377, 0.83761847]\n",
      "Batch 19/700: Discriminator loss = 1.1877144575119019, GAN loss = [2.2485878, 0.7707876, 0.823468]\n",
      "Batch 20/700: Discriminator loss = 1.171735167503357, GAN loss = [2.2535, 0.7744595, 0.82474494]\n",
      "Batch 21/700: Discriminator loss = 1.1651862859725952, GAN loss = [2.2715151, 0.7827592, 0.83449984]\n",
      "Batch 22/700: Discriminator loss = 1.179411768913269, GAN loss = [2.228025, 0.75551194, 0.8182987]\n",
      "Batch 23/700: Discriminator loss = 1.1575419902801514, GAN loss = [2.3101368, 0.7829361, 0.87301886]\n",
      "Batch 24/700: Discriminator loss = 1.1712915897369385, GAN loss = [2.296252, 0.7579122, 0.8842015]\n",
      "Batch 25/700: Discriminator loss = 1.1685535907745361, GAN loss = [2.286574, 0.7678963, 0.8645709]\n",
      "Batch 26/700: Discriminator loss = 1.2051440477371216, GAN loss = [2.2815557, 0.7371777, 0.89030313]\n",
      "Batch 27/700: Discriminator loss = 1.185694932937622, GAN loss = [2.3013477, 0.7595222, 0.88777983]\n",
      "Batch 28/700: Discriminator loss = 1.236646294593811, GAN loss = [2.2492428, 0.7167723, 0.87845033]\n",
      "Batch 29/700: Discriminator loss = 1.2187459468841553, GAN loss = [2.2711205, 0.7082952, 0.90882945]\n",
      "Batch 30/700: Discriminator loss = 1.2259262800216675, GAN loss = [2.2858748, 0.71172506, 0.92017525]\n",
      "Batch 31/700: Discriminator loss = 1.2402143478393555, GAN loss = [2.2558334, 0.7132824, 0.8886046]\n",
      "Batch 32/700: Discriminator loss = 1.2284916639328003, GAN loss = [2.217051, 0.71095747, 0.8521718]\n",
      "Batch 33/700: Discriminator loss = 1.2378908395767212, GAN loss = [2.2151093, 0.70811754, 0.85310453]\n",
      "Batch 34/700: Discriminator loss = 1.230634093284607, GAN loss = [2.212413, 0.71829, 0.84027505]\n",
      "Batch 35/700: Discriminator loss = 1.2240931987762451, GAN loss = [2.247001, 0.7338772, 0.85930943]\n",
      "Batch 36/700: Discriminator loss = 1.215802550315857, GAN loss = [2.2309847, 0.732668, 0.84452266]\n",
      "Batch 37/700: Discriminator loss = 1.2126619815826416, GAN loss = [2.2262545, 0.7522747, 0.82019925]\n",
      "Batch 38/700: Discriminator loss = 1.1983681917190552, GAN loss = [2.2616475, 0.76883525, 0.8390441]\n",
      "Batch 39/700: Discriminator loss = 1.1982625722885132, GAN loss = [2.2781696, 0.7687891, 0.85562414]\n",
      "Batch 40/700: Discriminator loss = 1.201123833656311, GAN loss = [2.263677, 0.7470156, 0.86293083]\n",
      "Batch 41/700: Discriminator loss = 1.2193297147750854, GAN loss = [2.2470791, 0.72702265, 0.8663374]\n",
      "Batch 42/700: Discriminator loss = 1.2437621355056763, GAN loss = [2.2225518, 0.71000236, 0.85884833]\n",
      "Batch 43/700: Discriminator loss = 1.1930994987487793, GAN loss = [2.263421, 0.7546936, 0.85504633]\n",
      "Batch 44/700: Discriminator loss = 1.2232002019882202, GAN loss = [2.2732377, 0.7378833, 0.8817036]\n",
      "Batch 45/700: Discriminator loss = 1.210895299911499, GAN loss = [2.2548091, 0.7469001, 0.8542871]\n",
      "Batch 46/700: Discriminator loss = 1.197004795074463, GAN loss = [2.2903078, 0.7597776, 0.87694395]\n",
      "Batch 47/700: Discriminator loss = 1.2506076097488403, GAN loss = [2.219686, 0.7150276, 0.85109365]\n",
      "Batch 48/700: Discriminator loss = 1.2297741174697876, GAN loss = [2.1937716, 0.7179645, 0.8222695]\n",
      "Batch 49/700: Discriminator loss = 1.2344295978546143, GAN loss = [2.1990597, 0.7188205, 0.82674414]\n",
      "Batch 50/700: Discriminator loss = 1.1780294179916382, GAN loss = [2.2636068, 0.7648459, 0.8452851]\n",
      "Batch 51/700: Discriminator loss = 1.212254524230957, GAN loss = [2.2537541, 0.7404379, 0.8598606]\n",
      "Batch 52/700: Discriminator loss = 1.2489197254180908, GAN loss = [2.1547036, 0.71229833, 0.7889557]\n",
      "Batch 53/700: Discriminator loss = 1.231690764427185, GAN loss = [2.2119002, 0.7368034, 0.8216801]\n",
      "Batch 54/700: Discriminator loss = 1.2282915115356445, GAN loss = [2.206496, 0.7378905, 0.8152303]\n",
      "Batch 55/700: Discriminator loss = 1.2445019483566284, GAN loss = [2.1368308, 0.7158162, 0.76767564]\n",
      "Batch 56/700: Discriminator loss = 1.2266405820846558, GAN loss = [2.1971698, 0.73427755, 0.8095918]\n",
      "Batch 57/700: Discriminator loss = 1.229233741760254, GAN loss = [2.1856265, 0.7318259, 0.80053854]\n",
      "Batch 58/700: Discriminator loss = 1.2159318923950195, GAN loss = [2.1885593, 0.740117, 0.79522026]\n",
      "Batch 59/700: Discriminator loss = 1.2371445894241333, GAN loss = [2.2000024, 0.7214423, 0.82536817]\n",
      "Batch 60/700: Discriminator loss = 1.227433204650879, GAN loss = [2.1911697, 0.7283503, 0.8096559]\n",
      "Batch 61/700: Discriminator loss = 1.1788326501846313, GAN loss = [2.2142777, 0.7616602, 0.79947716]\n",
      "Batch 62/700: Discriminator loss = 1.24785578250885, GAN loss = [2.197913, 0.73390913, 0.810873]\n",
      "Batch 63/700: Discriminator loss = 1.209796667098999, GAN loss = [2.199008, 0.7502392, 0.7956799]\n",
      "Batch 64/700: Discriminator loss = 1.1951144933700562, GAN loss = [2.1602516, 0.74572814, 0.7614575]\n",
      "Batch 65/700: Discriminator loss = 1.177096962928772, GAN loss = [2.221347, 0.77854764, 0.789747]\n",
      "Batch 66/700: Discriminator loss = 1.2277768850326538, GAN loss = [2.162908, 0.7267993, 0.7830603]\n",
      "Batch 67/700: Discriminator loss = 1.188581943511963, GAN loss = [2.2256503, 0.7482635, 0.82434744]\n",
      "Batch 68/700: Discriminator loss = 1.1965553760528564, GAN loss = [2.2009497, 0.73887193, 0.8090354]\n",
      "Batch 69/700: Discriminator loss = 1.2003241777420044, GAN loss = [2.1933835, 0.7456781, 0.79468]\n",
      "Batch 70/700: Discriminator loss = 1.168662428855896, GAN loss = [2.2544632, 0.77410185, 0.827358]\n",
      "Batch 71/700: Discriminator loss = 1.1539949178695679, GAN loss = [2.24343, 0.7931537, 0.7973031]\n",
      "Batch 72/700: Discriminator loss = 1.1653931140899658, GAN loss = [2.2662642, 0.7674414, 0.8458655]\n",
      "Batch 73/700: Discriminator loss = 1.1920702457427979, GAN loss = [2.213486, 0.7454971, 0.8150521]\n",
      "Batch 74/700: Discriminator loss = 1.1885367631912231, GAN loss = [2.240524, 0.745391, 0.8422258]\n",
      "Batch 75/700: Discriminator loss = 1.1814336776733398, GAN loss = [2.25119, 0.7520517, 0.84627616]\n",
      "Batch 76/700: Discriminator loss = 1.1739600896835327, GAN loss = [2.270594, 0.74719673, 0.87057245]\n",
      "Batch 77/700: Discriminator loss = 1.1892138719558716, GAN loss = [2.1910348, 0.7280345, 0.8101973]\n",
      "Batch 78/700: Discriminator loss = 1.1962612867355347, GAN loss = [2.212783, 0.7281101, 0.8319019]\n",
      "Batch 79/700: Discriminator loss = 1.1956866979599, GAN loss = [2.2087226, 0.73043793, 0.8255661]\n",
      "Batch 80/700: Discriminator loss = 1.218893051147461, GAN loss = [2.2731268, 0.7217442, 0.8986958]\n",
      "Batch 81/700: Discriminator loss = 1.1993542909622192, GAN loss = [2.2415907, 0.7349984, 0.8539344]\n",
      "Batch 82/700: Discriminator loss = 1.2081055641174316, GAN loss = [2.2213125, 0.7261595, 0.8425364]\n",
      "Batch 83/700: Discriminator loss = 1.2112903594970703, GAN loss = [2.1985793, 0.71633226, 0.82967347]\n",
      "Batch 84/700: Discriminator loss = 1.197683334350586, GAN loss = [2.1816378, 0.7173775, 0.81172234]\n",
      "Batch 85/700: Discriminator loss = 1.2017319202423096, GAN loss = [2.2352664, 0.7420963, 0.8406542]\n",
      "Batch 86/700: Discriminator loss = 1.1856554746627808, GAN loss = [2.2059948, 0.746206, 0.8073066]\n",
      "Batch 87/700: Discriminator loss = 1.204026222229004, GAN loss = [2.1925554, 0.7303328, 0.809769]\n",
      "Batch 88/700: Discriminator loss = 1.2025030851364136, GAN loss = [2.2243235, 0.7423766, 0.8295101]\n",
      "Batch 89/700: Discriminator loss = 1.1921929121017456, GAN loss = [2.2701316, 0.73943937, 0.8782772]\n",
      "Batch 90/700: Discriminator loss = 1.1683504581451416, GAN loss = [2.234251, 0.7611708, 0.8206939]\n",
      "Batch 91/700: Discriminator loss = 1.2081283330917358, GAN loss = [2.1974022, 0.71618134, 0.8288474]\n",
      "Batch 92/700: Discriminator loss = 1.2163530588150024, GAN loss = [2.21276, 0.72106326, 0.83933794]\n",
      "Batch 93/700: Discriminator loss = 1.2004079818725586, GAN loss = [2.2106466, 0.7234676, 0.83483374]\n",
      "Batch 94/700: Discriminator loss = 1.195701003074646, GAN loss = [2.2015889, 0.7271944, 0.8220726]\n",
      "Batch 95/700: Discriminator loss = 1.205857276916504, GAN loss = [2.2068462, 0.7254297, 0.82912916]\n",
      "Batch 96/700: Discriminator loss = 1.1947110891342163, GAN loss = [2.2112982, 0.73759896, 0.8214472]\n",
      "Batch 97/700: Discriminator loss = 1.209938645362854, GAN loss = [2.1918259, 0.71386003, 0.82575154]\n",
      "Batch 98/700: Discriminator loss = 1.1951676607131958, GAN loss = [2.1941483, 0.73029715, 0.8116684]\n",
      "Batch 99/700: Discriminator loss = 1.217068076133728, GAN loss = [2.190314, 0.70450246, 0.83365923]\n",
      "Batch 100/700: Discriminator loss = 1.191450595855713, GAN loss = [2.2410598, 0.7357266, 0.8532029]\n",
      "Batch 101/700: Discriminator loss = 1.1918727159500122, GAN loss = [2.2310047, 0.73129624, 0.847594]\n",
      "Batch 102/700: Discriminator loss = 1.1816492080688477, GAN loss = [2.2010033, 0.73800117, 0.81091523]\n",
      "Batch 103/700: Discriminator loss = 1.1975065469741821, GAN loss = [2.2462587, 0.7269036, 0.8673027]\n",
      "Batch 104/700: Discriminator loss = 1.1704639196395874, GAN loss = [2.2590337, 0.7601261, 0.8468843]\n",
      "Batch 105/700: Discriminator loss = 1.1721570491790771, GAN loss = [2.236897, 0.7630803, 0.8218332]\n",
      "Batch 106/700: Discriminator loss = 1.1925305128097534, GAN loss = [2.2253234, 0.73591787, 0.83744913]\n",
      "Batch 107/700: Discriminator loss = 1.1998357772827148, GAN loss = [2.2101398, 0.73056746, 0.82765806]\n",
      "Batch 108/700: Discriminator loss = 1.1620597839355469, GAN loss = [2.277382, 0.7647599, 0.86072904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 109/700: Discriminator loss = 1.2052838802337646, GAN loss = [2.2045708, 0.7284281, 0.8242659]\n",
      "Batch 110/700: Discriminator loss = 1.2136728763580322, GAN loss = [2.1957088, 0.73218757, 0.81166655]\n",
      "Batch 111/700: Discriminator loss = 1.217984676361084, GAN loss = [2.1997547, 0.72626054, 0.8216736]\n",
      "Batch 112/700: Discriminator loss = 1.2103233337402344, GAN loss = [2.1844249, 0.7252863, 0.80734986]\n",
      "Batch 113/700: Discriminator loss = 1.2106826305389404, GAN loss = [2.2614245, 0.7386362, 0.87102973]\n",
      "Batch 114/700: Discriminator loss = 1.1970586776733398, GAN loss = [2.216499, 0.7359692, 0.8287939]\n",
      "Batch 115/700: Discriminator loss = 1.2070626020431519, GAN loss = [2.244498, 0.7379341, 0.8548314]\n",
      "Batch 116/700: Discriminator loss = 1.2015043497085571, GAN loss = [2.2061238, 0.74973136, 0.80466485]\n",
      "Batch 117/700: Discriminator loss = 1.191149115562439, GAN loss = [2.2535937, 0.77275115, 0.8290997]\n",
      "Batch 118/700: Discriminator loss = 1.231672763824463, GAN loss = [2.1670299, 0.71400183, 0.80127794]\n",
      "Batch 119/700: Discriminator loss = 1.1999073028564453, GAN loss = [2.189901, 0.75142115, 0.78672653]\n",
      "Batch 120/700: Discriminator loss = 1.218732237815857, GAN loss = [2.2215974, 0.73178744, 0.83805054]\n",
      "Batch 121/700: Discriminator loss = 1.237257957458496, GAN loss = [2.1591916, 0.7082843, 0.79914314]\n",
      "Batch 122/700: Discriminator loss = 1.2181310653686523, GAN loss = [2.2252028, 0.73369485, 0.8397569]\n",
      "Batch 123/700: Discriminator loss = 1.2269381284713745, GAN loss = [2.1996238, 0.7165073, 0.8313784]\n",
      "Batch 124/700: Discriminator loss = 1.2284537553787231, GAN loss = [2.1990504, 0.7317132, 0.81560117]\n",
      "Batch 125/700: Discriminator loss = 1.2064208984375, GAN loss = [2.1846018, 0.741169, 0.79170036]\n",
      "Batch 126/700: Discriminator loss = 1.1861170530319214, GAN loss = [2.2090642, 0.7573289, 0.80000615]\n",
      "Batch 127/700: Discriminator loss = 1.217818021774292, GAN loss = [2.1901634, 0.7228181, 0.81561697]\n",
      "Batch 128/700: Discriminator loss = 1.199830174446106, GAN loss = [2.206383, 0.759976, 0.79469055]\n",
      "Batch 129/700: Discriminator loss = 1.2127684354782104, GAN loss = [2.2286308, 0.7444111, 0.8325129]\n",
      "Batch 130/700: Discriminator loss = 1.1887720823287964, GAN loss = [2.2466445, 0.7547722, 0.8401743]\n",
      "Batch 131/700: Discriminator loss = 1.21896493434906, GAN loss = [2.1931155, 0.72731745, 0.81411284]\n",
      "Batch 132/700: Discriminator loss = 1.2130323648452759, GAN loss = [2.2025018, 0.73254067, 0.8182718]\n",
      "Batch 133/700: Discriminator loss = 1.2231379747390747, GAN loss = [2.2341156, 0.7324413, 0.84999794]\n",
      "Batch 134/700: Discriminator loss = 1.1917240619659424, GAN loss = [2.2270818, 0.74817765, 0.827238]\n",
      "Batch 135/700: Discriminator loss = 1.2199050188064575, GAN loss = [2.1897256, 0.72287923, 0.8152039]\n",
      "Batch 136/700: Discriminator loss = 1.2094905376434326, GAN loss = [2.2228754, 0.7385726, 0.8326607]\n",
      "Batch 137/700: Discriminator loss = 1.1734740734100342, GAN loss = [2.264677, 0.7724097, 0.8406364]\n",
      "Batch 138/700: Discriminator loss = 1.1967248916625977, GAN loss = [2.2161417, 0.7517431, 0.81277525]\n",
      "Batch 139/700: Discriminator loss = 1.2064743041992188, GAN loss = [2.1814249, 0.7323064, 0.79748964]\n",
      "Batch 140/700: Discriminator loss = 1.2027873992919922, GAN loss = [2.220756, 0.7331638, 0.8359525]\n",
      "Batch 141/700: Discriminator loss = 1.2037566900253296, GAN loss = [2.22387, 0.74355817, 0.82864225]\n",
      "Batch 142/700: Discriminator loss = 1.2113569974899292, GAN loss = [2.1854722, 0.72375715, 0.8100349]\n",
      "Batch 143/700: Discriminator loss = 1.2066328525543213, GAN loss = [2.2496562, 0.7311568, 0.86681306]\n",
      "Batch 144/700: Discriminator loss = 1.204835057258606, GAN loss = [2.2331278, 0.74726737, 0.83417726]\n",
      "Batch 145/700: Discriminator loss = 1.2023212909698486, GAN loss = [2.230772, 0.7328386, 0.8462454]\n",
      "Batch 146/700: Discriminator loss = 1.2302978038787842, GAN loss = [2.2442985, 0.7290159, 0.8635997]\n",
      "Batch 147/700: Discriminator loss = 1.192125916481018, GAN loss = [2.2514522, 0.760177, 0.83959997]\n",
      "Batch 148/700: Discriminator loss = 1.1649004220962524, GAN loss = [2.275236, 0.77503717, 0.8485296]\n",
      "Batch 149/700: Discriminator loss = 1.184082269668579, GAN loss = [2.2797186, 0.75834954, 0.8697073]\n",
      "Batch 150/700: Discriminator loss = 1.2043004035949707, GAN loss = [2.251457, 0.7440934, 0.855709]\n",
      "Batch 151/700: Discriminator loss = 1.2096774578094482, GAN loss = [2.2228963, 0.73816, 0.83307946]\n",
      "Batch 152/700: Discriminator loss = 1.188844084739685, GAN loss = [2.2793934, 0.75439775, 0.87333435]\n",
      "Batch 153/700: Discriminator loss = 1.1994332075119019, GAN loss = [2.2771542, 0.74005693, 0.88542724]\n",
      "Batch 154/700: Discriminator loss = 1.1857187747955322, GAN loss = [2.2818847, 0.75856256, 0.8716572]\n",
      "Batch 155/700: Discriminator loss = 1.180845022201538, GAN loss = [2.2750049, 0.7525371, 0.87082726]\n",
      "Batch 156/700: Discriminator loss = 1.2174389362335205, GAN loss = [2.226576, 0.7392518, 0.835702]\n",
      "Batch 157/700: Discriminator loss = 1.1910890340805054, GAN loss = [2.2752547, 0.74700785, 0.87662834]\n",
      "Batch 158/700: Discriminator loss = 1.2221870422363281, GAN loss = [2.222112, 0.7386124, 0.83189553]\n",
      "Batch 159/700: Discriminator loss = 1.2257004976272583, GAN loss = [2.210643, 0.73828584, 0.8207687]\n",
      "Batch 160/700: Discriminator loss = 1.1999843120574951, GAN loss = [2.2741702, 0.76003534, 0.8625478]\n",
      "Batch 161/700: Discriminator loss = 1.1979507207870483, GAN loss = [2.318021, 0.7489861, 0.9174435]\n",
      "Batch 162/700: Discriminator loss = 1.1881928443908691, GAN loss = [2.29434, 0.77592546, 0.8668242]\n",
      "Batch 163/700: Discriminator loss = 1.212404727935791, GAN loss = [2.2412035, 0.7407216, 0.84887236]\n",
      "Batch 164/700: Discriminator loss = 1.2160717248916626, GAN loss = [2.2492616, 0.7452423, 0.8524225]\n",
      "Batch 165/700: Discriminator loss = 1.2005079984664917, GAN loss = [2.3170254, 0.78684103, 0.8786055]\n",
      "Batch 166/700: Discriminator loss = 1.225967288017273, GAN loss = [2.207534, 0.7396204, 0.816328]\n",
      "Batch 167/700: Discriminator loss = 1.2348415851593018, GAN loss = [2.1655457, 0.7266981, 0.7872691]\n",
      "Batch 168/700: Discriminator loss = 1.2428703308105469, GAN loss = [2.2383244, 0.7373527, 0.84940773]\n",
      "Batch 169/700: Discriminator loss = 1.2068572044372559, GAN loss = [2.2723122, 0.76829773, 0.852478]\n",
      "Batch 170/700: Discriminator loss = 1.2089276313781738, GAN loss = [2.2092865, 0.75589037, 0.80188733]\n",
      "Batch 171/700: Discriminator loss = 1.200905442237854, GAN loss = [2.2756548, 0.76424676, 0.85993266]\n",
      "Batch 172/700: Discriminator loss = 1.2009079456329346, GAN loss = [2.2611105, 0.77918035, 0.83049476]\n",
      "Batch 173/700: Discriminator loss = 1.186907410621643, GAN loss = [2.2695434, 0.78486824, 0.8332484]\n",
      "Batch 174/700: Discriminator loss = 1.151616096496582, GAN loss = [2.3580194, 0.8227267, 0.88388324]\n",
      "Batch 175/700: Discriminator loss = 1.1962858438491821, GAN loss = [2.242115, 0.7816151, 0.80910575]\n",
      "Batch 176/700: Discriminator loss = 1.20071280002594, GAN loss = [2.2892168, 0.7738662, 0.86396766]\n",
      "Batch 177/700: Discriminator loss = 1.1911046504974365, GAN loss = [2.3263443, 0.80163735, 0.8733381]\n",
      "Batch 178/700: Discriminator loss = 1.1640011072158813, GAN loss = [2.3507445, 0.8048451, 0.89452666]\n",
      "Batch 179/700: Discriminator loss = 1.180511236190796, GAN loss = [2.2795997, 0.7928366, 0.83536375]\n",
      "Batch 180/700: Discriminator loss = 1.1981528997421265, GAN loss = [2.3238087, 0.7893139, 0.8830765]\n",
      "Batch 181/700: Discriminator loss = 1.1564934253692627, GAN loss = [2.340757, 0.8141856, 0.875155]\n",
      "Batch 182/700: Discriminator loss = 1.1699358224868774, GAN loss = [2.3194394, 0.8098308, 0.858172]\n",
      "Batch 183/700: Discriminator loss = 1.1960387229919434, GAN loss = [2.3037856, 0.7846287, 0.867712]\n",
      "Batch 184/700: Discriminator loss = 1.2024099826812744, GAN loss = [2.266144, 0.7790641, 0.835628]\n",
      "Batch 185/700: Discriminator loss = 1.1835373640060425, GAN loss = [2.3158162, 0.79487807, 0.869481]\n",
      "Batch 186/700: Discriminator loss = 1.1778227090835571, GAN loss = [2.351922, 0.81010646, 0.8903405]\n",
      "Batch 187/700: Discriminator loss = 1.205973505973816, GAN loss = [2.278372, 0.78198606, 0.8449064]\n",
      "Batch 188/700: Discriminator loss = 1.224469780921936, GAN loss = [2.2754552, 0.7769516, 0.8470315]\n",
      "Batch 189/700: Discriminator loss = 1.2210149765014648, GAN loss = [2.2856252, 0.7923394, 0.8417903]\n",
      "Batch 190/700: Discriminator loss = 1.212348461151123, GAN loss = [2.295122, 0.80354196, 0.8400775]\n",
      "Batch 191/700: Discriminator loss = 1.187774419784546, GAN loss = [2.2788696, 0.8183637, 0.80898595]\n",
      "Batch 192/700: Discriminator loss = 1.1693551540374756, GAN loss = [2.2859564, 0.8164238, 0.8179803]\n",
      "Batch 193/700: Discriminator loss = 1.1638054847717285, GAN loss = [2.3592653, 0.8415059, 0.8661873]\n",
      "Batch 194/700: Discriminator loss = 1.1566517353057861, GAN loss = [2.3372226, 0.84591484, 0.83973783]\n",
      "Batch 195/700: Discriminator loss = 1.1601165533065796, GAN loss = [2.3196666, 0.8268466, 0.84128904]\n",
      "Batch 196/700: Discriminator loss = 1.1721996068954468, GAN loss = [2.3538601, 0.8143787, 0.8879853]\n",
      "Batch 197/700: Discriminator loss = 1.1645503044128418, GAN loss = [2.2931268, 0.80540377, 0.83625257]\n",
      "Batch 198/700: Discriminator loss = 1.1785485744476318, GAN loss = [2.330023, 0.80584043, 0.8727343]\n",
      "Batch 199/700: Discriminator loss = 1.1935033798217773, GAN loss = [2.2876105, 0.7742746, 0.8619099]\n",
      "Batch 200/700: Discriminator loss = 1.1565827131271362, GAN loss = [2.3145235, 0.81435376, 0.8487563]\n",
      "Batch 201/700: Discriminator loss = 1.1599317789077759, GAN loss = [2.2930017, 0.8092419, 0.83236015]\n",
      "Batch 202/700: Discriminator loss = 1.205828309059143, GAN loss = [2.303812, 0.7755108, 0.87691283]\n",
      "Batch 203/700: Discriminator loss = 1.1637635231018066, GAN loss = [2.319555, 0.8109547, 0.8572298]\n",
      "Batch 204/700: Discriminator loss = 1.174153447151184, GAN loss = [2.3059955, 0.79298246, 0.86165774]\n",
      "Batch 205/700: Discriminator loss = 1.186029076576233, GAN loss = [2.2847276, 0.7783156, 0.85508573]\n",
      "Batch 206/700: Discriminator loss = 1.177790880203247, GAN loss = [2.3170664, 0.7794637, 0.8863147]\n",
      "Batch 207/700: Discriminator loss = 1.1657112836837769, GAN loss = [2.302968, 0.792889, 0.85884917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 208/700: Discriminator loss = 1.1761174201965332, GAN loss = [2.3124576, 0.783766, 0.87751615]\n",
      "Batch 209/700: Discriminator loss = 1.1682647466659546, GAN loss = [2.2841978, 0.7879638, 0.84512484]\n",
      "Batch 210/700: Discriminator loss = 1.1836140155792236, GAN loss = [2.2822053, 0.76812804, 0.8630331]\n",
      "Batch 211/700: Discriminator loss = 1.1977399587631226, GAN loss = [2.2972097, 0.7579907, 0.8882346]\n",
      "Batch 212/700: Discriminator loss = 1.2077068090438843, GAN loss = [2.2160168, 0.7476763, 0.8173946]\n",
      "Batch 213/700: Discriminator loss = 1.1936720609664917, GAN loss = [2.3403711, 0.76777005, 0.9217056]\n",
      "Batch 214/700: Discriminator loss = 1.2046889066696167, GAN loss = [2.3177257, 0.75981176, 0.90706986]\n",
      "Batch 215/700: Discriminator loss = 1.1788650751113892, GAN loss = [2.3447661, 0.7721866, 0.9217646]\n",
      "Batch 216/700: Discriminator loss = 1.2092654705047607, GAN loss = [2.3113692, 0.7483238, 0.91226584]\n",
      "Batch 217/700: Discriminator loss = 1.200892448425293, GAN loss = [2.3002124, 0.75616616, 0.89327765]\n",
      "Batch 218/700: Discriminator loss = 1.2019619941711426, GAN loss = [2.275167, 0.75915456, 0.86526215]\n",
      "Batch 219/700: Discriminator loss = 1.1843454837799072, GAN loss = [2.3216286, 0.7804441, 0.89047295]\n",
      "Batch 220/700: Discriminator loss = 1.182408332824707, GAN loss = [2.300038, 0.77916044, 0.87019396]\n",
      "Batch 221/700: Discriminator loss = 1.1806113719940186, GAN loss = [2.2699184, 0.78937584, 0.829886]\n",
      "Batch 222/700: Discriminator loss = 1.174296259880066, GAN loss = [2.2824497, 0.78787774, 0.84394616]\n",
      "Batch 223/700: Discriminator loss = 1.1601864099502563, GAN loss = [2.30647, 0.8082921, 0.8475815]\n",
      "Batch 224/700: Discriminator loss = 1.1599793434143066, GAN loss = [2.3057988, 0.8066087, 0.8486249]\n",
      "Batch 225/700: Discriminator loss = 1.1753838062286377, GAN loss = [2.280725, 0.80256945, 0.8276236]\n",
      "Batch 226/700: Discriminator loss = 1.1640264987945557, GAN loss = [2.3419144, 0.8055558, 0.88585806]\n",
      "Batch 227/700: Discriminator loss = 1.1764719486236572, GAN loss = [2.3114202, 0.81048113, 0.85046476]\n",
      "Batch 228/700: Discriminator loss = 1.151429295539856, GAN loss = [2.2724376, 0.81558627, 0.8064093]\n",
      "Batch 229/700: Discriminator loss = 1.1627029180526733, GAN loss = [2.3042386, 0.81085664, 0.84297323]\n",
      "Batch 230/700: Discriminator loss = 1.1577550172805786, GAN loss = [2.3228292, 0.82173765, 0.8507159]\n",
      "Batch 231/700: Discriminator loss = 1.148330807685852, GAN loss = [2.3668807, 0.8219281, 0.8946179]\n",
      "Batch 232/700: Discriminator loss = 1.1599724292755127, GAN loss = [2.338734, 0.81115794, 0.87729406]\n",
      "Batch 233/700: Discriminator loss = 1.1512142419815063, GAN loss = [2.3511086, 0.8348868, 0.8659791]\n",
      "Batch 234/700: Discriminator loss = 1.1540114879608154, GAN loss = [2.325503, 0.8203183, 0.85495967]\n",
      "Batch 235/700: Discriminator loss = 1.152557611465454, GAN loss = [2.3214176, 0.8110455, 0.8601755]\n",
      "Batch 236/700: Discriminator loss = 1.1444798707962036, GAN loss = [2.359099, 0.8275624, 0.8813851]\n",
      "Batch 237/700: Discriminator loss = 1.184112787246704, GAN loss = [2.325955, 0.781693, 0.89414334]\n",
      "Batch 238/700: Discriminator loss = 1.1380159854888916, GAN loss = [2.3576427, 0.8240431, 0.8835204]\n",
      "Batch 239/700: Discriminator loss = 1.1384105682373047, GAN loss = [2.3694603, 0.84066653, 0.878759]\n",
      "Batch 240/700: Discriminator loss = 1.1553733348846436, GAN loss = [2.361477, 0.82362366, 0.8878473]\n",
      "Batch 241/700: Discriminator loss = 1.159758448600769, GAN loss = [2.3322232, 0.8044385, 0.8777806]\n",
      "Batch 242/700: Discriminator loss = 1.1682722568511963, GAN loss = [2.3504424, 0.8088613, 0.891601]\n",
      "Batch 243/700: Discriminator loss = 1.1750818490982056, GAN loss = [2.3471742, 0.7994253, 0.8977977]\n",
      "Batch 244/700: Discriminator loss = 1.1756227016448975, GAN loss = [2.3228195, 0.79605937, 0.8768329]\n",
      "Batch 245/700: Discriminator loss = 1.1793222427368164, GAN loss = [2.3170514, 0.784135, 0.8830136]\n",
      "Batch 246/700: Discriminator loss = 1.155699372291565, GAN loss = [2.3990593, 0.82079315, 0.9283768]\n",
      "Batch 247/700: Discriminator loss = 1.1651216745376587, GAN loss = [2.3692381, 0.814303, 0.9050683]\n",
      "Batch 248/700: Discriminator loss = 1.1774636507034302, GAN loss = [2.3182235, 0.78087425, 0.88751787]\n",
      "Batch 249/700: Discriminator loss = 1.1610888242721558, GAN loss = [2.3544202, 0.7900987, 0.9145269]\n",
      "Batch 250/700: Discriminator loss = 1.171510934829712, GAN loss = [2.3867157, 0.7804337, 0.9565129]\n",
      "Batch 251/700: Discriminator loss = 1.1736189126968384, GAN loss = [2.3217988, 0.78590775, 0.88614964]\n",
      "Batch 252/700: Discriminator loss = 1.1528685092926025, GAN loss = [2.3215697, 0.8156651, 0.8561827]\n",
      "Batch 253/700: Discriminator loss = 1.1593623161315918, GAN loss = [2.3344073, 0.78751725, 0.8971986]\n",
      "Batch 254/700: Discriminator loss = 1.1819337606430054, GAN loss = [2.353691, 0.7735823, 0.9304583]\n",
      "Batch 255/700: Discriminator loss = 1.1802992820739746, GAN loss = [2.3301947, 0.7872704, 0.8933143]\n",
      "Batch 256/700: Discriminator loss = 1.1820893287658691, GAN loss = [2.3401258, 0.7685342, 0.9220199]\n",
      "Batch 257/700: Discriminator loss = 1.1915478706359863, GAN loss = [2.3031833, 0.7603596, 0.89329225]\n",
      "Batch 258/700: Discriminator loss = 1.186941146850586, GAN loss = [2.2972894, 0.75896645, 0.88882416]\n",
      "Batch 259/700: Discriminator loss = 1.2153061628341675, GAN loss = [2.286762, 0.73732024, 0.8999596]\n",
      "Batch 260/700: Discriminator loss = 1.1863306760787964, GAN loss = [2.3430219, 0.7786257, 0.9149461]\n",
      "Batch 261/700: Discriminator loss = 1.185486078262329, GAN loss = [2.3647375, 0.7819528, 0.9333764]\n",
      "Batch 262/700: Discriminator loss = 1.1950668096542358, GAN loss = [2.296486, 0.75343627, 0.8936626]\n",
      "Batch 263/700: Discriminator loss = 1.1917282342910767, GAN loss = [2.3321302, 0.7574209, 0.9253542]\n",
      "Batch 264/700: Discriminator loss = 1.1967114210128784, GAN loss = [2.2689457, 0.75705856, 0.8625441]\n",
      "Batch 265/700: Discriminator loss = 1.2009881734848022, GAN loss = [2.2758684, 0.75207883, 0.87445855]\n",
      "Batch 266/700: Discriminator loss = 1.2226581573486328, GAN loss = [2.2773442, 0.73346055, 0.89456314]\n",
      "Batch 267/700: Discriminator loss = 1.2019633054733276, GAN loss = [2.2989898, 0.7502525, 0.89942175]\n",
      "Batch 268/700: Discriminator loss = 1.2335081100463867, GAN loss = [2.2150571, 0.730344, 0.83539236]\n",
      "Batch 269/700: Discriminator loss = 1.2061516046524048, GAN loss = [2.2589524, 0.752213, 0.8574049]\n",
      "Batch 270/700: Discriminator loss = 1.1974890232086182, GAN loss = [2.2795522, 0.75410897, 0.8761112]\n",
      "Batch 271/700: Discriminator loss = 1.182709813117981, GAN loss = [2.2700543, 0.7546679, 0.86605316]\n",
      "Batch 272/700: Discriminator loss = 1.1858808994293213, GAN loss = [2.3033297, 0.76176035, 0.89224327]\n",
      "Batch 273/700: Discriminator loss = 1.2484502792358398, GAN loss = [2.247959, 0.72325253, 0.8753918]\n",
      "Batch 274/700: Discriminator loss = 1.195750117301941, GAN loss = [2.2433102, 0.7507019, 0.84329927]\n",
      "Batch 275/700: Discriminator loss = 1.1990888118743896, GAN loss = [2.2525706, 0.748673, 0.85459673]\n",
      "Batch 276/700: Discriminator loss = 1.1800247430801392, GAN loss = [2.292042, 0.78186387, 0.86089635]\n",
      "Batch 277/700: Discriminator loss = 1.1777230501174927, GAN loss = [2.2641897, 0.7716046, 0.8433254]\n",
      "Batch 278/700: Discriminator loss = 1.2068439722061157, GAN loss = [2.253974, 0.74659675, 0.85812247]\n",
      "Batch 279/700: Discriminator loss = 1.1838266849517822, GAN loss = [2.3071675, 0.78200716, 0.8759093]\n",
      "Batch 280/700: Discriminator loss = 1.1639924049377441, GAN loss = [2.3174894, 0.7900169, 0.87823045]\n",
      "Batch 281/700: Discriminator loss = 1.1712279319763184, GAN loss = [2.266739, 0.7821067, 0.83537346]\n",
      "Batch 282/700: Discriminator loss = 1.1953142881393433, GAN loss = [2.2563825, 0.7621305, 0.8449868]\n",
      "Batch 283/700: Discriminator loss = 1.1725016832351685, GAN loss = [2.2684531, 0.77776825, 0.84142226]\n",
      "Batch 284/700: Discriminator loss = 1.1813117265701294, GAN loss = [2.3197389, 0.76232266, 0.90817994]\n",
      "Batch 285/700: Discriminator loss = 1.1670761108398438, GAN loss = [2.2958324, 0.7782315, 0.86839086]\n",
      "Batch 286/700: Discriminator loss = 1.1674131155014038, GAN loss = [2.2937582, 0.7747114, 0.86986905]\n",
      "Batch 287/700: Discriminator loss = 1.1732690334320068, GAN loss = [2.3413777, 0.7789043, 0.9133289]\n",
      "Batch 288/700: Discriminator loss = 1.1746175289154053, GAN loss = [2.2770295, 0.7711795, 0.8567463]\n",
      "Batch 289/700: Discriminator loss = 1.178605556488037, GAN loss = [2.2890384, 0.7858115, 0.85416394]\n",
      "Batch 290/700: Discriminator loss = 1.1737359762191772, GAN loss = [2.2972305, 0.7768912, 0.8713196]\n",
      "Batch 291/700: Discriminator loss = 1.1678310632705688, GAN loss = [2.351415, 0.7965412, 0.9058914]\n",
      "Batch 292/700: Discriminator loss = 1.2023656368255615, GAN loss = [2.259824, 0.73916405, 0.87173706]\n",
      "Batch 293/700: Discriminator loss = 1.1727330684661865, GAN loss = [2.3150768, 0.79246986, 0.8737445]\n",
      "Batch 294/700: Discriminator loss = 1.1974509954452515, GAN loss = [2.2526195, 0.7612571, 0.8425396]\n",
      "Batch 295/700: Discriminator loss = 1.1761975288391113, GAN loss = [2.2907598, 0.76556516, 0.87639165]\n",
      "Batch 296/700: Discriminator loss = 1.1789517402648926, GAN loss = [2.2437437, 0.7764393, 0.81853193]\n",
      "Batch 297/700: Discriminator loss = 1.191685438156128, GAN loss = [2.2343, 0.7696012, 0.81595683]\n",
      "Batch 298/700: Discriminator loss = 1.1853713989257812, GAN loss = [2.2370002, 0.7749048, 0.8134033]\n",
      "Batch 299/700: Discriminator loss = 1.1804519891738892, GAN loss = [2.284813, 0.7776983, 0.8584838]\n",
      "Batch 300/700: Discriminator loss = 1.1881366968154907, GAN loss = [2.249972, 0.7729846, 0.8284051]\n",
      "Batch 301/700: Discriminator loss = 1.1780983209609985, GAN loss = [2.2982004, 0.7718043, 0.87786275]\n",
      "Batch 302/700: Discriminator loss = 1.1942594051361084, GAN loss = [2.239879, 0.7508212, 0.84058076]\n",
      "Batch 303/700: Discriminator loss = 1.195143222808838, GAN loss = [2.2510695, 0.75407034, 0.84857035]\n",
      "Batch 304/700: Discriminator loss = 1.2002071142196655, GAN loss = [2.2574477, 0.7530449, 0.8560341]\n",
      "Batch 305/700: Discriminator loss = 1.2153245210647583, GAN loss = [2.223178, 0.752302, 0.82255715]\n",
      "Batch 306/700: Discriminator loss = 1.2225700616836548, GAN loss = [2.2043607, 0.7427746, 0.8133139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 307/700: Discriminator loss = 1.203491449356079, GAN loss = [2.2417467, 0.7488693, 0.84465635]\n",
      "Batch 308/700: Discriminator loss = 1.2293251752853394, GAN loss = [2.2028587, 0.7217032, 0.8329785]\n",
      "Batch 309/700: Discriminator loss = 1.2449208498001099, GAN loss = [2.194633, 0.7172212, 0.82925546]\n",
      "Batch 310/700: Discriminator loss = 1.212277889251709, GAN loss = [2.17988, 0.74543947, 0.78630775]\n",
      "Batch 311/700: Discriminator loss = 1.2426270246505737, GAN loss = [2.1709747, 0.72142327, 0.8014173]\n",
      "Batch 312/700: Discriminator loss = 1.254152536392212, GAN loss = [2.17496, 0.72517604, 0.8016491]\n",
      "Batch 313/700: Discriminator loss = 1.2094701528549194, GAN loss = [2.1746974, 0.7490971, 0.77748024]\n",
      "Batch 314/700: Discriminator loss = 1.2412831783294678, GAN loss = [2.1501217, 0.73347974, 0.7685484]\n",
      "Batch 315/700: Discriminator loss = 1.215771198272705, GAN loss = [2.1584203, 0.73814476, 0.77220935]\n",
      "Batch 316/700: Discriminator loss = 1.2054204940795898, GAN loss = [2.2191148, 0.76010317, 0.81095314]\n",
      "Batch 317/700: Discriminator loss = 1.1856344938278198, GAN loss = [2.2157254, 0.77151126, 0.796167]\n",
      "Batch 318/700: Discriminator loss = 1.203431248664856, GAN loss = [2.1705408, 0.7417163, 0.7808092]\n",
      "Batch 319/700: Discriminator loss = 1.182031512260437, GAN loss = [2.1941197, 0.76321465, 0.78291625]\n",
      "Batch 320/700: Discriminator loss = 1.1932950019836426, GAN loss = [2.2088382, 0.7573406, 0.8035403]\n",
      "Batch 321/700: Discriminator loss = 1.201192855834961, GAN loss = [2.1675627, 0.7365194, 0.78312093]\n",
      "Batch 322/700: Discriminator loss = 1.2198632955551147, GAN loss = [2.1436052, 0.72667813, 0.769043]\n",
      "Batch 323/700: Discriminator loss = 1.2009443044662476, GAN loss = [2.1662712, 0.7549406, 0.7634745]\n",
      "Batch 324/700: Discriminator loss = 1.2131909132003784, GAN loss = [2.1767364, 0.72966075, 0.79924536]\n",
      "Batch 325/700: Discriminator loss = 1.2085844278335571, GAN loss = [2.2063286, 0.730659, 0.8278558]\n",
      "Batch 326/700: Discriminator loss = 1.2071117162704468, GAN loss = [2.1831424, 0.7369539, 0.7983883]\n",
      "Batch 327/700: Discriminator loss = 1.222074270248413, GAN loss = [2.1779132, 0.7270086, 0.80311203]\n",
      "Batch 328/700: Discriminator loss = 1.2227689027786255, GAN loss = [2.1503415, 0.7294597, 0.77309954]\n",
      "Batch 329/700: Discriminator loss = 1.2056214809417725, GAN loss = [2.191812, 0.7397493, 0.804299]\n",
      "Batch 330/700: Discriminator loss = 1.1997013092041016, GAN loss = [2.2539952, 0.7469074, 0.8593346]\n",
      "Batch 331/700: Discriminator loss = 1.2192072868347168, GAN loss = [2.193506, 0.72603446, 0.8197337]\n",
      "Batch 332/700: Discriminator loss = 1.2124065160751343, GAN loss = [2.1939316, 0.735754, 0.8104621]\n",
      "Batch 333/700: Discriminator loss = 1.2009845972061157, GAN loss = [2.2020917, 0.74019265, 0.81421083]\n",
      "Batch 334/700: Discriminator loss = 1.2358838319778442, GAN loss = [2.206072, 0.7182716, 0.8401528]\n",
      "Batch 335/700: Discriminator loss = 1.2197433710098267, GAN loss = [2.224428, 0.7399763, 0.8368279]\n",
      "Batch 336/700: Discriminator loss = 1.2078351974487305, GAN loss = [2.221503, 0.74692696, 0.82697505]\n",
      "Batch 337/700: Discriminator loss = 1.2120281457901, GAN loss = [2.2315462, 0.73485994, 0.8491086]\n",
      "Batch 338/700: Discriminator loss = 1.1980082988739014, GAN loss = [2.2586262, 0.7431137, 0.86795235]\n",
      "Batch 339/700: Discriminator loss = 1.2033426761627197, GAN loss = [2.2405465, 0.74546057, 0.84755003]\n",
      "Batch 340/700: Discriminator loss = 1.202096700668335, GAN loss = [2.1915417, 0.7342214, 0.8098115]\n",
      "Batch 341/700: Discriminator loss = 1.2200584411621094, GAN loss = [2.23053, 0.7306873, 0.85235727]\n",
      "Batch 342/700: Discriminator loss = 1.2044962644577026, GAN loss = [2.2083387, 0.738623, 0.822266]\n",
      "Batch 343/700: Discriminator loss = 1.1880136728286743, GAN loss = [2.2344072, 0.7508686, 0.83612335]\n",
      "Batch 344/700: Discriminator loss = 1.211529016494751, GAN loss = [2.2416773, 0.7387284, 0.85557646]\n",
      "Batch 345/700: Discriminator loss = 1.2186589241027832, GAN loss = [2.1950877, 0.7222793, 0.82548165]\n",
      "Batch 346/700: Discriminator loss = 1.2387269735336304, GAN loss = [2.2137992, 0.73220307, 0.83431023]\n",
      "Batch 347/700: Discriminator loss = 1.2291544675827026, GAN loss = [2.1854892, 0.7185947, 0.81966054]\n",
      "Batch 348/700: Discriminator loss = 1.1916041374206543, GAN loss = [2.2279465, 0.76306593, 0.8176899]\n",
      "Batch 349/700: Discriminator loss = 1.2145358324050903, GAN loss = [2.2208462, 0.7466812, 0.8270095]\n",
      "Batch 350/700: Discriminator loss = 1.2228487730026245, GAN loss = [2.1746233, 0.71509767, 0.81239176]\n",
      "Batch 351/700: Discriminator loss = 1.219712734222412, GAN loss = [2.236942, 0.7359484, 0.8538714]\n",
      "Batch 352/700: Discriminator loss = 1.1894850730895996, GAN loss = [2.2207437, 0.7588795, 0.8147548]\n",
      "Batch 353/700: Discriminator loss = 1.2321711778640747, GAN loss = [2.2342548, 0.73553544, 0.85162246]\n",
      "Batch 354/700: Discriminator loss = 1.2064454555511475, GAN loss = [2.224315, 0.76167536, 0.8155506]\n",
      "Batch 355/700: Discriminator loss = 1.190367579460144, GAN loss = [2.2501664, 0.76525843, 0.83783144]\n",
      "Batch 356/700: Discriminator loss = 1.1960681676864624, GAN loss = [2.2029188, 0.7540155, 0.80183524]\n",
      "Batch 357/700: Discriminator loss = 1.22898268699646, GAN loss = [2.2074163, 0.746805, 0.8135461]\n",
      "Batch 358/700: Discriminator loss = 1.2073947191238403, GAN loss = [2.206571, 0.745102, 0.81441605]\n",
      "Batch 359/700: Discriminator loss = 1.2059718370437622, GAN loss = [2.2290344, 0.7444777, 0.83752203]\n",
      "Batch 360/700: Discriminator loss = 1.1942870616912842, GAN loss = [2.2017903, 0.74540186, 0.80936676]\n",
      "Batch 361/700: Discriminator loss = 1.174280047416687, GAN loss = [2.259987, 0.77222914, 0.8407695]\n",
      "Batch 362/700: Discriminator loss = 1.1964771747589111, GAN loss = [2.2176716, 0.7532218, 0.8174897]\n",
      "Batch 363/700: Discriminator loss = 1.1975114345550537, GAN loss = [2.253753, 0.7491306, 0.85769653]\n",
      "Batch 364/700: Discriminator loss = 1.178017258644104, GAN loss = [2.243363, 0.7563327, 0.84015894]\n",
      "Batch 365/700: Discriminator loss = 1.2012393474578857, GAN loss = [2.209186, 0.73513395, 0.8272289]\n",
      "Batch 366/700: Discriminator loss = 1.1767042875289917, GAN loss = [2.2992015, 0.76246506, 0.88995904]\n",
      "Batch 367/700: Discriminator loss = 1.1856797933578491, GAN loss = [2.2360222, 0.7434559, 0.84581965]\n",
      "Batch 368/700: Discriminator loss = 1.2013511657714844, GAN loss = [2.2669737, 0.74086726, 0.8793864]\n",
      "Batch 369/700: Discriminator loss = 1.200866460800171, GAN loss = [2.2056472, 0.7311606, 0.82779676]\n",
      "Batch 370/700: Discriminator loss = 1.237444281578064, GAN loss = [2.2042224, 0.69510865, 0.8624511]\n",
      "Batch 371/700: Discriminator loss = 1.2189701795578003, GAN loss = [2.227082, 0.7108155, 0.8696284]\n",
      "Batch 372/700: Discriminator loss = 1.2114289999008179, GAN loss = [2.219901, 0.7168161, 0.85646474]\n",
      "Batch 373/700: Discriminator loss = 1.2282813787460327, GAN loss = [2.1611097, 0.7112334, 0.8032897]\n",
      "Batch 374/700: Discriminator loss = 1.201603889465332, GAN loss = [2.2347982, 0.73129183, 0.8569552]\n",
      "Batch 375/700: Discriminator loss = 1.211459994316101, GAN loss = [2.2151291, 0.71886134, 0.8497416]\n",
      "Batch 376/700: Discriminator loss = 1.2003250122070312, GAN loss = [2.2456245, 0.73599434, 0.8631251]\n",
      "Batch 377/700: Discriminator loss = 1.2431174516677856, GAN loss = [2.210665, 0.6864354, 0.8777403]\n",
      "Batch 378/700: Discriminator loss = 1.2218213081359863, GAN loss = [2.1937463, 0.7205894, 0.82669884]\n",
      "Batch 379/700: Discriminator loss = 1.23227858543396, GAN loss = [2.2166784, 0.6994898, 0.87075937]\n",
      "Batch 380/700: Discriminator loss = 1.2166051864624023, GAN loss = [2.19683, 0.7178303, 0.832591]\n",
      "Batch 381/700: Discriminator loss = 1.2026031017303467, GAN loss = [2.2309606, 0.7442847, 0.8403006]\n",
      "Batch 382/700: Discriminator loss = 1.2209757566452026, GAN loss = [2.181925, 0.7131718, 0.8224146]\n",
      "Batch 383/700: Discriminator loss = 1.214997410774231, GAN loss = [2.1983805, 0.7228182, 0.8292396]\n",
      "Batch 384/700: Discriminator loss = 1.2092839479446411, GAN loss = [2.2045033, 0.7278266, 0.83038026]\n",
      "Batch 385/700: Discriminator loss = 1.2026276588439941, GAN loss = [2.1719496, 0.72980773, 0.7958744]\n",
      "Batch 386/700: Discriminator loss = 1.2225688695907593, GAN loss = [2.1710339, 0.71959853, 0.8051951]\n",
      "Batch 387/700: Discriminator loss = 1.2218748331069946, GAN loss = [2.1743038, 0.7134666, 0.8146088]\n",
      "Batch 388/700: Discriminator loss = 1.248490571975708, GAN loss = [2.158225, 0.69663024, 0.81537664]\n",
      "Batch 389/700: Discriminator loss = 1.2153522968292236, GAN loss = [2.1775975, 0.72048753, 0.8108961]\n",
      "Batch 390/700: Discriminator loss = 1.2156000137329102, GAN loss = [2.1820543, 0.7139946, 0.8218485]\n",
      "Batch 391/700: Discriminator loss = 1.2145123481750488, GAN loss = [2.2218268, 0.72268414, 0.85293204]\n",
      "Batch 392/700: Discriminator loss = 1.1981397867202759, GAN loss = [2.227635, 0.74966, 0.83176076]\n",
      "Batch 393/700: Discriminator loss = 1.2207542657852173, GAN loss = [2.1881332, 0.71775675, 0.8241746]\n",
      "Batch 394/700: Discriminator loss = 1.2095532417297363, GAN loss = [2.1963313, 0.74143714, 0.80870366]\n",
      "Batch 395/700: Discriminator loss = 1.2328402996063232, GAN loss = [2.1482706, 0.715359, 0.78673965]\n",
      "Batch 396/700: Discriminator loss = 1.202712059020996, GAN loss = [2.1907642, 0.7300354, 0.8145747]\n",
      "Batch 397/700: Discriminator loss = 1.2102047204971313, GAN loss = [2.1738975, 0.7337544, 0.7939954]\n",
      "Batch 398/700: Discriminator loss = 1.1998380422592163, GAN loss = [2.1937249, 0.73849654, 0.80910516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 399/700: Discriminator loss = 1.1972121000289917, GAN loss = [2.180805, 0.7430253, 0.7916839]\n",
      "Batch 400/700: Discriminator loss = 1.1931936740875244, GAN loss = [2.1863735, 0.7315586, 0.8087373]\n",
      "Batch 401/700: Discriminator loss = 1.200564980506897, GAN loss = [2.1954696, 0.7357283, 0.8136809]\n",
      "Batch 402/700: Discriminator loss = 1.2175649404525757, GAN loss = [2.1692684, 0.70867974, 0.8145455]\n",
      "Batch 403/700: Discriminator loss = 1.2233057022094727, GAN loss = [2.1465762, 0.7106046, 0.789954]\n",
      "Batch 404/700: Discriminator loss = 1.190356731414795, GAN loss = [2.2202146, 0.7455876, 0.8286362]\n",
      "Batch 405/700: Discriminator loss = 1.2017369270324707, GAN loss = [2.2045534, 0.7382936, 0.8202988]\n",
      "Batch 406/700: Discriminator loss = 1.2266714572906494, GAN loss = [2.165956, 0.7124395, 0.80759263]\n",
      "Batch 407/700: Discriminator loss = 1.2106292247772217, GAN loss = [2.200188, 0.7247667, 0.8295204]\n",
      "Batch 408/700: Discriminator loss = 1.2006722688674927, GAN loss = [2.167358, 0.7289041, 0.79257005]\n",
      "Batch 409/700: Discriminator loss = 1.1975326538085938, GAN loss = [2.182572, 0.73376447, 0.802948]\n",
      "Batch 410/700: Discriminator loss = 1.2002676725387573, GAN loss = [2.1906633, 0.733178, 0.8116471]\n",
      "Batch 411/700: Discriminator loss = 1.210773229598999, GAN loss = [2.1867778, 0.7346791, 0.8062663]\n",
      "Batch 412/700: Discriminator loss = 1.2258310317993164, GAN loss = [2.1487663, 0.716173, 0.7867775]\n",
      "Batch 413/700: Discriminator loss = 1.2014555931091309, GAN loss = [2.1837983, 0.73198897, 0.8059907]\n",
      "Batch 414/700: Discriminator loss = 1.1975470781326294, GAN loss = [2.1710079, 0.7306423, 0.7945472]\n",
      "Batch 415/700: Discriminator loss = 1.1950321197509766, GAN loss = [2.140949, 0.7310521, 0.76410025]\n",
      "Batch 416/700: Discriminator loss = 1.2165268659591675, GAN loss = [2.1825635, 0.71197313, 0.8248237]\n",
      "Batch 417/700: Discriminator loss = 1.2181838750839233, GAN loss = [2.1494539, 0.70931745, 0.7943861]\n",
      "Batch 418/700: Discriminator loss = 1.20340895652771, GAN loss = [2.165246, 0.72185564, 0.79765165]\n",
      "Batch 419/700: Discriminator loss = 1.217166781425476, GAN loss = [2.199606, 0.7166315, 0.8372425]\n",
      "Batch 420/700: Discriminator loss = 1.2130881547927856, GAN loss = [2.1630008, 0.71873945, 0.79854757]\n",
      "Batch 421/700: Discriminator loss = 1.191701889038086, GAN loss = [2.2040136, 0.75204897, 0.80626506]\n",
      "Batch 422/700: Discriminator loss = 1.1930785179138184, GAN loss = [2.2288742, 0.7505734, 0.8326089]\n",
      "Batch 423/700: Discriminator loss = 1.2144798040390015, GAN loss = [2.1825, 0.71627015, 0.82053983]\n",
      "Batch 424/700: Discriminator loss = 1.2121587991714478, GAN loss = [2.1379073, 0.7250491, 0.76717186]\n",
      "Batch 425/700: Discriminator loss = 1.1968027353286743, GAN loss = [2.2021995, 0.7376712, 0.8188383]\n",
      "Batch 426/700: Discriminator loss = 1.2065554857254028, GAN loss = [2.1669161, 0.72530264, 0.79590905]\n",
      "Batch 427/700: Discriminator loss = 1.2039560079574585, GAN loss = [2.1973357, 0.7303154, 0.8213102]\n",
      "Batch 428/700: Discriminator loss = 1.217814326286316, GAN loss = [2.1902957, 0.7297761, 0.8148022]\n",
      "Batch 429/700: Discriminator loss = 1.2109527587890625, GAN loss = [2.202582, 0.7385656, 0.81828845]\n",
      "Batch 430/700: Discriminator loss = 1.1929782629013062, GAN loss = [2.1887932, 0.73775613, 0.8052948]\n",
      "Batch 431/700: Discriminator loss = 1.2186768054962158, GAN loss = [2.1717155, 0.7159667, 0.81000656]\n",
      "Batch 432/700: Discriminator loss = 1.2064509391784668, GAN loss = [2.216881, 0.7334451, 0.83770007]\n",
      "Batch 433/700: Discriminator loss = 1.1900687217712402, GAN loss = [2.188322, 0.7464684, 0.7961417]\n",
      "Batch 434/700: Discriminator loss = 1.2152605056762695, GAN loss = [2.1906517, 0.72099113, 0.8239476]\n",
      "Batch 435/700: Discriminator loss = 1.2017908096313477, GAN loss = [2.2286265, 0.72684675, 0.85606134]\n",
      "Batch 436/700: Discriminator loss = 1.1950571537017822, GAN loss = [2.210524, 0.72514623, 0.8396273]\n",
      "Batch 437/700: Discriminator loss = 1.2195450067520142, GAN loss = [2.1763828, 0.72032416, 0.81029695]\n",
      "Batch 438/700: Discriminator loss = 1.2138952016830444, GAN loss = [2.1811068, 0.73437333, 0.8009889]\n",
      "Batch 439/700: Discriminator loss = 1.2084776163101196, GAN loss = [2.1831744, 0.73390853, 0.80352545]\n",
      "Batch 440/700: Discriminator loss = 1.2193832397460938, GAN loss = [2.178258, 0.7116978, 0.8207977]\n",
      "Batch 441/700: Discriminator loss = 1.2241692543029785, GAN loss = [2.1415458, 0.7079111, 0.78787404]\n",
      "Batch 442/700: Discriminator loss = 1.1881946325302124, GAN loss = [2.211675, 0.74081224, 0.8250975]\n",
      "Batch 443/700: Discriminator loss = 1.2056183815002441, GAN loss = [2.172781, 0.72542727, 0.80158186]\n",
      "Batch 444/700: Discriminator loss = 1.2057167291641235, GAN loss = [2.1986225, 0.7240434, 0.8287853]\n",
      "Batch 445/700: Discriminator loss = 1.2093002796173096, GAN loss = [2.2007048, 0.7185766, 0.83630204]\n",
      "Batch 446/700: Discriminator loss = 1.2044483423233032, GAN loss = [2.1845508, 0.7267485, 0.811963]\n",
      "Batch 447/700: Discriminator loss = 1.2219141721725464, GAN loss = [2.2588146, 0.71639204, 0.896561]\n",
      "Batch 448/700: Discriminator loss = 1.2228769063949585, GAN loss = [2.195956, 0.7158595, 0.83420724]\n",
      "Batch 449/700: Discriminator loss = 1.2184183597564697, GAN loss = [2.1895514, 0.71686643, 0.8267695]\n",
      "Batch 450/700: Discriminator loss = 1.209116816520691, GAN loss = [2.2058203, 0.72556883, 0.83432317]\n",
      "Batch 451/700: Discriminator loss = 1.2112902402877808, GAN loss = [2.22074, 0.7295344, 0.8452518]\n",
      "Batch 452/700: Discriminator loss = 1.2020134925842285, GAN loss = [2.1597738, 0.7182982, 0.7954831]\n",
      "Batch 453/700: Discriminator loss = 1.2454140186309814, GAN loss = [2.1648457, 0.7010753, 0.8177338]\n",
      "Batch 454/700: Discriminator loss = 1.2057793140411377, GAN loss = [2.2171774, 0.73185766, 0.83925164]\n",
      "Batch 455/700: Discriminator loss = 1.2174978256225586, GAN loss = [2.1612566, 0.71196294, 0.8031785]\n",
      "Batch 456/700: Discriminator loss = 1.2256863117218018, GAN loss = [2.1902325, 0.7168734, 0.8272057]\n",
      "Batch 457/700: Discriminator loss = 1.223478078842163, GAN loss = [2.1863172, 0.7144173, 0.82572347]\n",
      "Batch 458/700: Discriminator loss = 1.2059050798416138, GAN loss = [2.197125, 0.7176762, 0.8332746]\n",
      "Batch 459/700: Discriminator loss = 1.214067816734314, GAN loss = [2.2054572, 0.71204644, 0.84725016]\n",
      "Batch 460/700: Discriminator loss = 1.2236270904541016, GAN loss = [2.176618, 0.7193097, 0.81115043]\n",
      "Batch 461/700: Discriminator loss = 1.2106962203979492, GAN loss = [2.1680753, 0.7225339, 0.79936737]\n",
      "Batch 462/700: Discriminator loss = 1.2229564189910889, GAN loss = [2.248592, 0.7186546, 0.8837795]\n",
      "Batch 463/700: Discriminator loss = 1.2069168090820312, GAN loss = [2.243603, 0.74392426, 0.8535464]\n",
      "Batch 464/700: Discriminator loss = 1.2178541421890259, GAN loss = [2.1863127, 0.72517306, 0.81499666]\n",
      "Batch 465/700: Discriminator loss = 1.1985440254211426, GAN loss = [2.2762468, 0.7523613, 0.87775445]\n",
      "Batch 466/700: Discriminator loss = 1.186964511871338, GAN loss = [2.266114, 0.74992067, 0.8700688]\n",
      "Batch 467/700: Discriminator loss = 1.2005711793899536, GAN loss = [2.2427914, 0.7343605, 0.86229676]\n",
      "Batch 468/700: Discriminator loss = 1.2279216051101685, GAN loss = [2.1992948, 0.7160154, 0.8371291]\n",
      "Batch 469/700: Discriminator loss = 1.2085058689117432, GAN loss = [2.2631466, 0.7354083, 0.8815892]\n",
      "Batch 470/700: Discriminator loss = 1.1956658363342285, GAN loss = [2.1983314, 0.73200774, 0.820186]\n",
      "Batch 471/700: Discriminator loss = 1.2130227088928223, GAN loss = [2.2478695, 0.7201521, 0.8815839]\n",
      "Batch 472/700: Discriminator loss = 1.226814866065979, GAN loss = [2.2118874, 0.7151143, 0.85065097]\n",
      "Batch 473/700: Discriminator loss = 1.2111982107162476, GAN loss = [2.2345233, 0.73789597, 0.8504947]\n",
      "Batch 474/700: Discriminator loss = 1.2336244583129883, GAN loss = [2.1949518, 0.70635134, 0.84246475]\n",
      "Batch 475/700: Discriminator loss = 1.2286465167999268, GAN loss = [2.1897256, 0.7159016, 0.82767946]\n",
      "Batch 476/700: Discriminator loss = 1.1988834142684937, GAN loss = [2.2283692, 0.7428807, 0.83933276]\n",
      "Batch 477/700: Discriminator loss = 1.212798833847046, GAN loss = [2.19912, 0.7246641, 0.8283031]\n",
      "Batch 478/700: Discriminator loss = 1.1924842596054077, GAN loss = [2.2049851, 0.7346034, 0.8242307]\n",
      "Batch 479/700: Discriminator loss = 1.1900047063827515, GAN loss = [2.255246, 0.7445174, 0.86458373]\n",
      "Batch 480/700: Discriminator loss = 1.1781100034713745, GAN loss = [2.2462175, 0.761519, 0.8385413]\n",
      "Batch 481/700: Discriminator loss = 1.1880426406860352, GAN loss = [2.233843, 0.742648, 0.8450257]\n",
      "Batch 482/700: Discriminator loss = 1.1994520425796509, GAN loss = [2.2788637, 0.74951667, 0.88317025]\n",
      "Batch 483/700: Discriminator loss = 1.1826404333114624, GAN loss = [2.2619243, 0.761843, 0.85390395]\n",
      "Batch 484/700: Discriminator loss = 1.213096261024475, GAN loss = [2.2209058, 0.7349327, 0.8398068]\n",
      "Batch 485/700: Discriminator loss = 1.1968427896499634, GAN loss = [2.2473602, 0.7387407, 0.8624581]\n",
      "Batch 486/700: Discriminator loss = 1.199103832244873, GAN loss = [2.2543871, 0.7384613, 0.8697655]\n",
      "Batch 487/700: Discriminator loss = 1.1904089450836182, GAN loss = [2.2123961, 0.7357351, 0.8304779]\n",
      "Batch 488/700: Discriminator loss = 1.185605764389038, GAN loss = [2.263312, 0.75271964, 0.86440665]\n",
      "Batch 489/700: Discriminator loss = 1.191518783569336, GAN loss = [2.258541, 0.7533088, 0.85905874]\n",
      "Batch 490/700: Discriminator loss = 1.2012943029403687, GAN loss = [2.19497, 0.73475105, 0.814066]\n",
      "Batch 491/700: Discriminator loss = 1.196244716644287, GAN loss = [2.2587757, 0.74920243, 0.86343217]\n",
      "Batch 492/700: Discriminator loss = 1.1697636842727661, GAN loss = [2.2512028, 0.77154005, 0.8335316]\n",
      "Batch 493/700: Discriminator loss = 1.2097610235214233, GAN loss = [2.2396111, 0.74348557, 0.84999967]\n",
      "Batch 494/700: Discriminator loss = 1.203902006149292, GAN loss = [2.2500215, 0.7627758, 0.8411301]\n",
      "Batch 495/700: Discriminator loss = 1.1854703426361084, GAN loss = [2.2435791, 0.75954765, 0.83792275]\n",
      "Batch 496/700: Discriminator loss = 1.180457592010498, GAN loss = [2.25769, 0.7675759, 0.8440377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 497/700: Discriminator loss = 1.1523579359054565, GAN loss = [2.3172734, 0.78480065, 0.88640875]\n",
      "Batch 498/700: Discriminator loss = 1.164940357208252, GAN loss = [2.3117142, 0.7749474, 0.89072305]\n",
      "Batch 499/700: Discriminator loss = 1.1875965595245361, GAN loss = [2.2322698, 0.75716263, 0.829061]\n",
      "Batch 500/700: Discriminator loss = 1.1893569231033325, GAN loss = [2.277141, 0.7626007, 0.86849004]\n",
      "Batch 501/700: Discriminator loss = 1.1812307834625244, GAN loss = [2.286278, 0.7611479, 0.87907845]\n",
      "Batch 502/700: Discriminator loss = 1.1768295764923096, GAN loss = [2.2816448, 0.7644315, 0.87114924]\n",
      "Batch 503/700: Discriminator loss = 1.1617242097854614, GAN loss = [2.2634425, 0.7824501, 0.8349076]\n",
      "Batch 504/700: Discriminator loss = 1.18231999874115, GAN loss = [2.2362387, 0.77610815, 0.81405556]\n",
      "Batch 505/700: Discriminator loss = 1.1666675806045532, GAN loss = [2.2913303, 0.7778726, 0.86737597]\n",
      "Batch 506/700: Discriminator loss = 1.1701866388320923, GAN loss = [2.2693613, 0.7700264, 0.8532507]\n",
      "Batch 507/700: Discriminator loss = 1.1800835132598877, GAN loss = [2.2654185, 0.7709365, 0.8483906]\n",
      "Batch 508/700: Discriminator loss = 1.2006973028182983, GAN loss = [2.268252, 0.743588, 0.8785578]\n",
      "Batch 509/700: Discriminator loss = 1.1668049097061157, GAN loss = [2.2639182, 0.7797908, 0.83799917]\n",
      "Batch 510/700: Discriminator loss = 1.1585458517074585, GAN loss = [2.2991753, 0.77217835, 0.88087755]\n",
      "Batch 511/700: Discriminator loss = 1.1950595378875732, GAN loss = [2.2690027, 0.7453062, 0.8776065]\n",
      "Batch 512/700: Discriminator loss = 1.2135123014450073, GAN loss = [2.2378285, 0.7339868, 0.8577782]\n",
      "Batch 513/700: Discriminator loss = 1.1940603256225586, GAN loss = [2.2534983, 0.7531672, 0.8542867]\n",
      "Batch 514/700: Discriminator loss = 1.2017439603805542, GAN loss = [2.2450306, 0.7339327, 0.8650722]\n",
      "Batch 515/700: Discriminator loss = 1.1959426403045654, GAN loss = [2.2128844, 0.7425295, 0.8243447]\n",
      "Batch 516/700: Discriminator loss = 1.201231598854065, GAN loss = [2.2618377, 0.75526357, 0.8605872]\n",
      "Batch 517/700: Discriminator loss = 1.1981040239334106, GAN loss = [2.237121, 0.74998355, 0.84117025]\n",
      "Batch 518/700: Discriminator loss = 1.1889195442199707, GAN loss = [2.2554839, 0.75274205, 0.85679543]\n",
      "Batch 519/700: Discriminator loss = 1.1994993686676025, GAN loss = [2.3107092, 0.758206, 0.9065966]\n",
      "Batch 520/700: Discriminator loss = 1.1919362545013428, GAN loss = [2.3093643, 0.7608335, 0.9026528]\n",
      "Batch 521/700: Discriminator loss = 1.1802407503128052, GAN loss = [2.3311357, 0.75751203, 0.92775476]\n",
      "Batch 522/700: Discriminator loss = 1.2040619850158691, GAN loss = [2.280653, 0.7384986, 0.89627945]\n",
      "Batch 523/700: Discriminator loss = 1.1997557878494263, GAN loss = [2.3116417, 0.7446008, 0.92116946]\n",
      "Batch 524/700: Discriminator loss = 1.2022348642349243, GAN loss = [2.343941, 0.75664186, 0.941422]\n",
      "Batch 525/700: Discriminator loss = 1.2038289308547974, GAN loss = [2.204389, 0.73539704, 0.8231387]\n",
      "Batch 526/700: Discriminator loss = 1.2211225032806396, GAN loss = [2.2492945, 0.7212833, 0.88217616]\n",
      "Batch 527/700: Discriminator loss = 1.2181696891784668, GAN loss = [2.2866163, 0.739311, 0.90149534]\n",
      "Batch 528/700: Discriminator loss = 1.2530949115753174, GAN loss = [2.2436817, 0.71335816, 0.88453066]\n",
      "Batch 529/700: Discriminator loss = 1.2417676448822021, GAN loss = [2.2111394, 0.7272589, 0.8380806]\n",
      "Batch 530/700: Discriminator loss = 1.2187514305114746, GAN loss = [2.2890875, 0.74595857, 0.89731646]\n",
      "Batch 531/700: Discriminator loss = 1.238244652748108, GAN loss = [2.269118, 0.7282367, 0.895062]\n",
      "Batch 532/700: Discriminator loss = 1.2214311361312866, GAN loss = [2.2764513, 0.7530593, 0.8775734]\n",
      "Batch 533/700: Discriminator loss = 1.2007167339324951, GAN loss = [2.2537518, 0.76449084, 0.84344083]\n",
      "Batch 534/700: Discriminator loss = 1.2147479057312012, GAN loss = [2.303065, 0.74631095, 0.9109507]\n",
      "Batch 535/700: Discriminator loss = 1.2155866622924805, GAN loss = [2.2361395, 0.7368775, 0.8534549]\n",
      "Batch 536/700: Discriminator loss = 1.225408911705017, GAN loss = [2.262416, 0.7441926, 0.8724209]\n",
      "Batch 537/700: Discriminator loss = 1.1949549913406372, GAN loss = [2.3263588, 0.7716563, 0.90890783]\n",
      "Batch 538/700: Discriminator loss = 1.2292122840881348, GAN loss = [2.2209406, 0.7257427, 0.8494055]\n",
      "Batch 539/700: Discriminator loss = 1.202299952507019, GAN loss = [2.2925007, 0.75947195, 0.8872432]\n",
      "Batch 540/700: Discriminator loss = 1.2326371669769287, GAN loss = [2.2142494, 0.73596954, 0.8325133]\n",
      "Batch 541/700: Discriminator loss = 1.1936465501785278, GAN loss = [2.2787945, 0.7678359, 0.8652109]\n",
      "Batch 542/700: Discriminator loss = 1.1728906631469727, GAN loss = [2.3000512, 0.7900339, 0.8642955]\n",
      "Batch 543/700: Discriminator loss = 1.1783461570739746, GAN loss = [2.2919767, 0.7768995, 0.8693646]\n",
      "Batch 544/700: Discriminator loss = 1.1946218013763428, GAN loss = [2.2488844, 0.7821031, 0.82107866]\n",
      "Batch 545/700: Discriminator loss = 1.192618727684021, GAN loss = [2.2378395, 0.75420713, 0.8379456]\n",
      "Batch 546/700: Discriminator loss = 1.2063167095184326, GAN loss = [2.2342842, 0.7490079, 0.8396174]\n",
      "Batch 547/700: Discriminator loss = 1.2179255485534668, GAN loss = [2.2546847, 0.7463887, 0.8626683]\n",
      "Batch 548/700: Discriminator loss = 1.2197685241699219, GAN loss = [2.2522542, 0.74861455, 0.85802054]\n",
      "Batch 549/700: Discriminator loss = 1.1689085960388184, GAN loss = [2.3355222, 0.79405266, 0.8958376]\n",
      "Batch 550/700: Discriminator loss = 1.2062313556671143, GAN loss = [2.2638927, 0.74531966, 0.87293345]\n",
      "Batch 551/700: Discriminator loss = 1.2117629051208496, GAN loss = [2.2454457, 0.7364516, 0.8633616]\n",
      "Batch 552/700: Discriminator loss = 1.1919068098068237, GAN loss = [2.2829468, 0.7590126, 0.87832475]\n",
      "Batch 553/700: Discriminator loss = 1.1749308109283447, GAN loss = [2.2407856, 0.7737735, 0.82142603]\n",
      "Batch 554/700: Discriminator loss = 1.2229818105697632, GAN loss = [2.2639916, 0.7405377, 0.8778584]\n",
      "Batch 555/700: Discriminator loss = 1.1856063604354858, GAN loss = [2.2963972, 0.75752234, 0.8932646]\n",
      "Batch 556/700: Discriminator loss = 1.2196745872497559, GAN loss = [2.2453804, 0.74326736, 0.8565081]\n",
      "Batch 557/700: Discriminator loss = 1.1899869441986084, GAN loss = [2.2809553, 0.75269836, 0.8826585]\n",
      "Batch 558/700: Discriminator loss = 1.1930131912231445, GAN loss = [2.3112633, 0.75331736, 0.9123468]\n",
      "Batch 559/700: Discriminator loss = 1.234460473060608, GAN loss = [2.2355564, 0.7352655, 0.8546924]\n",
      "Batch 560/700: Discriminator loss = 1.2180696725845337, GAN loss = [2.2992573, 0.7421714, 0.9114805]\n",
      "Batch 561/700: Discriminator loss = 1.1936227083206177, GAN loss = [2.2741632, 0.766749, 0.86179465]\n",
      "Batch 562/700: Discriminator loss = 1.2356024980545044, GAN loss = [2.1981184, 0.73169017, 0.82081705]\n",
      "Batch 563/700: Discriminator loss = 1.1994694471359253, GAN loss = [2.2740335, 0.75145185, 0.87697905]\n",
      "Batch 564/700: Discriminator loss = 1.1980987787246704, GAN loss = [2.230401, 0.7564368, 0.8283681]\n",
      "Batch 565/700: Discriminator loss = 1.1955146789550781, GAN loss = [2.2694833, 0.7542875, 0.8695987]\n",
      "Batch 566/700: Discriminator loss = 1.2094955444335938, GAN loss = [2.2088032, 0.7557965, 0.80739903]\n",
      "Batch 567/700: Discriminator loss = 1.2182667255401611, GAN loss = [2.2025335, 0.74199176, 0.8149401]\n",
      "Batch 568/700: Discriminator loss = 1.2159734964370728, GAN loss = [2.2398455, 0.749403, 0.84485185]\n",
      "Batch 569/700: Discriminator loss = 1.2187105417251587, GAN loss = [2.2097814, 0.7459068, 0.8183004]\n",
      "Batch 570/700: Discriminator loss = 1.2096123695373535, GAN loss = [2.2269633, 0.75804925, 0.82334906]\n",
      "Batch 571/700: Discriminator loss = 1.1965453624725342, GAN loss = [2.2691655, 0.7643653, 0.8592501]\n",
      "Batch 572/700: Discriminator loss = 1.1822794675827026, GAN loss = [2.258687, 0.77679944, 0.83636737]\n",
      "Batch 573/700: Discriminator loss = 1.1888362169265747, GAN loss = [2.2356808, 0.7678025, 0.82237846]\n",
      "Batch 574/700: Discriminator loss = 1.1914253234863281, GAN loss = [2.2276113, 0.75922906, 0.8228687]\n",
      "Batch 575/700: Discriminator loss = 1.2186267375946045, GAN loss = [2.2434394, 0.74058014, 0.8573525]\n",
      "Batch 576/700: Discriminator loss = 1.1941279172897339, GAN loss = [2.2187011, 0.7573386, 0.81584305]\n",
      "Batch 577/700: Discriminator loss = 1.1731371879577637, GAN loss = [2.3009918, 0.7789062, 0.8765714]\n",
      "Batch 578/700: Discriminator loss = 1.2088758945465088, GAN loss = [2.2573228, 0.7378459, 0.873976]\n",
      "Batch 579/700: Discriminator loss = 1.1761375665664673, GAN loss = [2.292833, 0.78797835, 0.85935706]\n",
      "Batch 580/700: Discriminator loss = 1.1814824342727661, GAN loss = [2.3474185, 0.78344584, 0.9184898]\n",
      "Batch 581/700: Discriminator loss = 1.180235743522644, GAN loss = [2.2936363, 0.7841743, 0.86397284]\n",
      "Batch 582/700: Discriminator loss = 1.1698877811431885, GAN loss = [2.3136368, 0.78408045, 0.88405454]\n",
      "Batch 583/700: Discriminator loss = 1.1777629852294922, GAN loss = [2.2761574, 0.7786267, 0.8520025]\n",
      "Batch 584/700: Discriminator loss = 1.2033430337905884, GAN loss = [2.2710023, 0.76247954, 0.86297345]\n",
      "Batch 585/700: Discriminator loss = 1.1876550912857056, GAN loss = [2.2498813, 0.7675413, 0.83675694]\n",
      "Batch 586/700: Discriminator loss = 1.2052191495895386, GAN loss = [2.289687, 0.7653476, 0.8787299]\n",
      "Batch 587/700: Discriminator loss = 1.1821324825286865, GAN loss = [2.2611377, 0.77543527, 0.8400704]\n",
      "Batch 588/700: Discriminator loss = 1.2031632661819458, GAN loss = [2.2855988, 0.77111787, 0.86880445]\n",
      "Batch 589/700: Discriminator loss = 1.1852548122406006, GAN loss = [2.2644129, 0.775331, 0.84334785]\n",
      "Batch 590/700: Discriminator loss = 1.1815860271453857, GAN loss = [2.2825375, 0.7862819, 0.85046905]\n",
      "Batch 591/700: Discriminator loss = 1.2223893404006958, GAN loss = [2.2319953, 0.746063, 0.8400986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 592/700: Discriminator loss = 1.2494276762008667, GAN loss = [2.240929, 0.7314318, 0.86361116]\n",
      "Batch 593/700: Discriminator loss = 1.2211581468582153, GAN loss = [2.2359073, 0.76168174, 0.82831514]\n",
      "Batch 594/700: Discriminator loss = 1.2218782901763916, GAN loss = [2.259039, 0.759364, 0.85375464]\n",
      "Batch 595/700: Discriminator loss = 1.2306996583938599, GAN loss = [2.2168353, 0.75531983, 0.81557155]\n",
      "Batch 596/700: Discriminator loss = 1.2066586017608643, GAN loss = [2.2311785, 0.7642328, 0.82096785]\n",
      "Batch 597/700: Discriminator loss = 1.2055203914642334, GAN loss = [2.2520938, 0.7576894, 0.848383]\n",
      "Batch 598/700: Discriminator loss = 1.223202109336853, GAN loss = [2.2791946, 0.73652375, 0.89660394]\n",
      "Batch 599/700: Discriminator loss = 1.2129411697387695, GAN loss = [2.236337, 0.7418493, 0.8483935]\n",
      "Batch 600/700: Discriminator loss = 1.2006505727767944, GAN loss = [2.2240956, 0.7515422, 0.82647127]\n",
      "Batch 601/700: Discriminator loss = 1.1871142387390137, GAN loss = [2.226636, 0.76651007, 0.8140578]\n",
      "Batch 602/700: Discriminator loss = 1.190361738204956, GAN loss = [2.2312934, 0.75888395, 0.826349]\n",
      "Batch 603/700: Discriminator loss = 1.2280994653701782, GAN loss = [2.2246432, 0.72472906, 0.8538552]\n",
      "Batch 604/700: Discriminator loss = 1.2204946279525757, GAN loss = [2.216087, 0.73348314, 0.8365539]\n",
      "Batch 605/700: Discriminator loss = 1.2053219079971313, GAN loss = [2.2742937, 0.750976, 0.8772901]\n",
      "Batch 606/700: Discriminator loss = 1.184475302696228, GAN loss = [2.2848954, 0.76147, 0.87743586]\n",
      "Batch 607/700: Discriminator loss = 1.1963157653808594, GAN loss = [2.2904599, 0.7629964, 0.8815022]\n",
      "Batch 608/700: Discriminator loss = 1.1914558410644531, GAN loss = [2.257574, 0.7546828, 0.8569683]\n",
      "Batch 609/700: Discriminator loss = 1.1982072591781616, GAN loss = [2.31189, 0.757351, 0.90863234]\n",
      "Batch 610/700: Discriminator loss = 1.2057560682296753, GAN loss = [2.2615275, 0.75043356, 0.86518264]\n",
      "Batch 611/700: Discriminator loss = 1.1997970342636108, GAN loss = [2.2734566, 0.74939156, 0.8781798]\n",
      "Batch 612/700: Discriminator loss = 1.1878186464309692, GAN loss = [2.2684631, 0.75840974, 0.8642065]\n",
      "Batch 613/700: Discriminator loss = 1.1902446746826172, GAN loss = [2.30779, 0.7615002, 0.90047675]\n",
      "Batch 614/700: Discriminator loss = 1.207667589187622, GAN loss = [2.2403545, 0.7415698, 0.8530083]\n",
      "Batch 615/700: Discriminator loss = 1.2113828659057617, GAN loss = [2.2979019, 0.7464802, 0.90568656]\n",
      "Batch 616/700: Discriminator loss = 1.2104885578155518, GAN loss = [2.3048751, 0.7609204, 0.89824843]\n",
      "Batch 617/700: Discriminator loss = 1.178435206413269, GAN loss = [2.3085003, 0.77605647, 0.88676554]\n",
      "Batch 618/700: Discriminator loss = 1.2349646091461182, GAN loss = [2.2501502, 0.72623396, 0.8782934]\n",
      "Batch 619/700: Discriminator loss = 1.2243986129760742, GAN loss = [2.2352607, 0.72114664, 0.86854434]\n",
      "Batch 620/700: Discriminator loss = 1.2180434465408325, GAN loss = [2.268221, 0.7531953, 0.8694984]\n",
      "Batch 621/700: Discriminator loss = 1.2372373342514038, GAN loss = [2.221679, 0.7349798, 0.84118766]\n",
      "Batch 622/700: Discriminator loss = 1.2117520570755005, GAN loss = [2.2336423, 0.74910635, 0.8390461]\n",
      "Batch 623/700: Discriminator loss = 1.2259047031402588, GAN loss = [2.2607288, 0.7319578, 0.88330495]\n",
      "Batch 624/700: Discriminator loss = 1.222456932067871, GAN loss = [2.2359552, 0.73944557, 0.8510821]\n",
      "Batch 625/700: Discriminator loss = 1.1997921466827393, GAN loss = [2.2166998, 0.7691497, 0.8021695]\n",
      "Batch 626/700: Discriminator loss = 1.2336088418960571, GAN loss = [2.221796, 0.74531347, 0.8311425]\n",
      "Batch 627/700: Discriminator loss = 1.2217570543289185, GAN loss = [2.2112074, 0.7246412, 0.8412729]\n",
      "Batch 628/700: Discriminator loss = 1.216100811958313, GAN loss = [2.2292588, 0.74359727, 0.8403995]\n",
      "Batch 629/700: Discriminator loss = 1.2325913906097412, GAN loss = [2.1941047, 0.7190543, 0.8298414]\n",
      "Batch 630/700: Discriminator loss = 1.2046782970428467, GAN loss = [2.2384632, 0.74958724, 0.8437175]\n",
      "Batch 631/700: Discriminator loss = 1.1908854246139526, GAN loss = [2.2228918, 0.7594733, 0.8183007]\n",
      "Batch 632/700: Discriminator loss = 1.2391656637191772, GAN loss = [2.219018, 0.727077, 0.8468903]\n",
      "Batch 633/700: Discriminator loss = 1.2311474084854126, GAN loss = [2.1708205, 0.72502816, 0.80080605]\n",
      "Batch 634/700: Discriminator loss = 1.2090191841125488, GAN loss = [2.243818, 0.7531115, 0.84576917]\n",
      "Batch 635/700: Discriminator loss = 1.2243415117263794, GAN loss = [2.2118766, 0.7289606, 0.838002]\n",
      "Batch 636/700: Discriminator loss = 1.2044286727905273, GAN loss = [2.232918, 0.73763746, 0.8503936]\n",
      "Batch 637/700: Discriminator loss = 1.2250776290893555, GAN loss = [2.2036977, 0.73026526, 0.8285775]\n",
      "Batch 638/700: Discriminator loss = 1.213314175605774, GAN loss = [2.2285035, 0.7411194, 0.84256655]\n",
      "Batch 639/700: Discriminator loss = 1.2122151851654053, GAN loss = [2.2314065, 0.7481543, 0.83846664]\n",
      "Batch 640/700: Discriminator loss = 1.2186639308929443, GAN loss = [2.1925626, 0.73208505, 0.8157394]\n",
      "Batch 641/700: Discriminator loss = 1.2292615175247192, GAN loss = [2.143967, 0.72250587, 0.77679324]\n",
      "Batch 642/700: Discriminator loss = 1.2304718494415283, GAN loss = [2.1777456, 0.7282476, 0.8048905]\n",
      "Batch 643/700: Discriminator loss = 1.2044917345046997, GAN loss = [2.1799483, 0.74703133, 0.7883701]\n",
      "Batch 644/700: Discriminator loss = 1.2471799850463867, GAN loss = [2.185376, 0.70380557, 0.83707]\n",
      "Batch 645/700: Discriminator loss = 1.2556953430175781, GAN loss = [2.1909516, 0.7024468, 0.84404784]\n",
      "Batch 646/700: Discriminator loss = 1.2050763368606567, GAN loss = [2.2212882, 0.7526111, 0.824258]\n",
      "Batch 647/700: Discriminator loss = 1.2401983737945557, GAN loss = [2.1720417, 0.72061586, 0.80703783]\n",
      "Batch 648/700: Discriminator loss = 1.2365915775299072, GAN loss = [2.2113907, 0.7306646, 0.8363523]\n",
      "Batch 649/700: Discriminator loss = 1.2373336553573608, GAN loss = [2.1864083, 0.73792624, 0.8041137]\n",
      "Batch 650/700: Discriminator loss = 1.2330734729766846, GAN loss = [2.1719632, 0.7352169, 0.7923993]\n",
      "Batch 651/700: Discriminator loss = 1.2088292837142944, GAN loss = [2.1819904, 0.75426286, 0.7834129]\n",
      "Batch 652/700: Discriminator loss = 1.1872798204421997, GAN loss = [2.1963632, 0.78386724, 0.76821244]\n",
      "Batch 653/700: Discriminator loss = 1.1966650485992432, GAN loss = [2.205554, 0.7578968, 0.8034134]\n",
      "Batch 654/700: Discriminator loss = 1.2013367414474487, GAN loss = [2.1564398, 0.7592981, 0.75293833]\n",
      "Batch 655/700: Discriminator loss = 1.2014269828796387, GAN loss = [2.1599998, 0.7454583, 0.77037466]\n",
      "Batch 656/700: Discriminator loss = 1.2115367650985718, GAN loss = [2.185318, 0.7382799, 0.8028984]\n",
      "Batch 657/700: Discriminator loss = 1.2170623540878296, GAN loss = [2.164713, 0.74012756, 0.78047395]\n",
      "Batch 658/700: Discriminator loss = 1.2018710374832153, GAN loss = [2.1718204, 0.7416785, 0.7860397]\n",
      "Batch 659/700: Discriminator loss = 1.2082279920578003, GAN loss = [2.2047246, 0.75099844, 0.80963826]\n",
      "Batch 660/700: Discriminator loss = 1.197100043296814, GAN loss = [2.2192297, 0.7620003, 0.8131619]\n",
      "Batch 661/700: Discriminator loss = 1.1609734296798706, GAN loss = [2.2537653, 0.8025903, 0.8071232]\n",
      "Batch 662/700: Discriminator loss = 1.1672894954681396, GAN loss = [2.2019942, 0.78614914, 0.77182204]\n",
      "Batch 663/700: Discriminator loss = 1.2011208534240723, GAN loss = [2.21624, 0.7578875, 0.8143502]\n",
      "Batch 664/700: Discriminator loss = 1.195090889930725, GAN loss = [2.1855712, 0.7555237, 0.78605807]\n",
      "Batch 665/700: Discriminator loss = 1.184321403503418, GAN loss = [2.2251985, 0.7675486, 0.8136749]\n",
      "Batch 666/700: Discriminator loss = 1.1816825866699219, GAN loss = [2.2196314, 0.76556915, 0.8101197]\n",
      "Batch 667/700: Discriminator loss = 1.1993812322616577, GAN loss = [2.1688948, 0.7514653, 0.7735296]\n",
      "Batch 668/700: Discriminator loss = 1.1850498914718628, GAN loss = [2.2063987, 0.76307696, 0.7994434]\n",
      "Batch 669/700: Discriminator loss = 1.1928695440292358, GAN loss = [2.202965, 0.7798578, 0.77925545]\n",
      "Batch 670/700: Discriminator loss = 1.1904560327529907, GAN loss = [2.2237864, 0.7607288, 0.81922376]\n",
      "Batch 671/700: Discriminator loss = 1.1879020929336548, GAN loss = [2.1855462, 0.75787246, 0.7838412]\n",
      "Batch 672/700: Discriminator loss = 1.2049825191497803, GAN loss = [2.1769702, 0.7552353, 0.77789307]\n",
      "Batch 673/700: Discriminator loss = 1.1948140859603882, GAN loss = [2.206274, 0.77827454, 0.7841552]\n",
      "Batch 674/700: Discriminator loss = 1.224973440170288, GAN loss = [2.1999207, 0.73452234, 0.821571]\n",
      "Batch 675/700: Discriminator loss = 1.1967251300811768, GAN loss = [2.2241488, 0.7648635, 0.81546956]\n",
      "Batch 676/700: Discriminator loss = 1.202142357826233, GAN loss = [2.2654204, 0.7580797, 0.8635232]\n",
      "Batch 677/700: Discriminator loss = 1.1914421319961548, GAN loss = [2.2151177, 0.7543224, 0.8169799]\n",
      "Batch 678/700: Discriminator loss = 1.18736732006073, GAN loss = [2.250027, 0.76141924, 0.84480524]\n",
      "Batch 679/700: Discriminator loss = 1.1917569637298584, GAN loss = [2.2602782, 0.77705747, 0.8394167]\n",
      "Batch 680/700: Discriminator loss = 1.1850717067718506, GAN loss = [2.2903059, 0.7739961, 0.87249696]\n",
      "Batch 681/700: Discriminator loss = 1.1848782300949097, GAN loss = [2.2864828, 0.7702473, 0.8724367]\n",
      "Batch 682/700: Discriminator loss = 1.1869231462478638, GAN loss = [2.306119, 0.7708337, 0.891492]\n",
      "Batch 683/700: Discriminator loss = 1.1827343702316284, GAN loss = [2.2671983, 0.7731212, 0.8502948]\n",
      "Batch 684/700: Discriminator loss = 1.1873513460159302, GAN loss = [2.2981002, 0.76761764, 0.8867152]\n",
      "Batch 685/700: Discriminator loss = 1.2003474235534668, GAN loss = [2.2823935, 0.7730247, 0.8656373]\n",
      "Batch 686/700: Discriminator loss = 1.2198892831802368, GAN loss = [2.2528758, 0.7683119, 0.8408748]\n",
      "Batch 687/700: Discriminator loss = 1.2140312194824219, GAN loss = [2.213788, 0.7499115, 0.8202192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 688/700: Discriminator loss = 1.223779320716858, GAN loss = [2.1593447, 0.73527753, 0.7804306]\n",
      "Batch 689/700: Discriminator loss = 1.2190163135528564, GAN loss = [2.2061615, 0.75824267, 0.8043221]\n",
      "Batch 690/700: Discriminator loss = 1.1721779108047485, GAN loss = [2.249819, 0.7780301, 0.8282446]\n",
      "Batch 691/700: Discriminator loss = 1.1827752590179443, GAN loss = [2.2297938, 0.77274626, 0.81355643]\n",
      "Batch 692/700: Discriminator loss = 1.182910442352295, GAN loss = [2.2192543, 0.77743983, 0.7983931]\n",
      "Batch 693/700: Discriminator loss = 1.1765762567520142, GAN loss = [2.2243104, 0.7678438, 0.8130853]\n",
      "Batch 694/700: Discriminator loss = 1.1886272430419922, GAN loss = [2.2436492, 0.76856095, 0.8317493]\n",
      "Batch 695/700: Discriminator loss = 1.1921043395996094, GAN loss = [2.194955, 0.7621685, 0.7894856]\n",
      "Batch 696/700: Discriminator loss = 1.20749831199646, GAN loss = [2.2126696, 0.75442696, 0.81498116]\n",
      "Batch 697/700: Discriminator loss = 1.2180371284484863, GAN loss = [2.1853378, 0.730526, 0.8115807]\n",
      "Batch 698/700: Discriminator loss = 1.2213135957717896, GAN loss = [2.2323105, 0.7318962, 0.8572012]\n",
      "Batch 699/700: Discriminator loss = 1.2090001106262207, GAN loss = [2.2186077, 0.7499179, 0.8254955]\n",
      "Batch 700/700: Discriminator loss = 1.2074308395385742, GAN loss = [2.2286682, 0.74508554, 0.84039706]\n",
      "Epoch 21/30\n",
      "Batch 1/700: Discriminator loss = 1.2097259759902954, GAN loss = [2.217004, 0.7411486, 0.83269614]\n",
      "Batch 2/700: Discriminator loss = 1.186460256576538, GAN loss = [2.2729943, 0.7766422, 0.85323995]\n",
      "Batch 3/700: Discriminator loss = 1.1796891689300537, GAN loss = [2.2948043, 0.78829855, 0.86342806]\n",
      "Batch 4/700: Discriminator loss = 1.1727485656738281, GAN loss = [2.2761714, 0.781904, 0.851202]\n",
      "Batch 5/700: Discriminator loss = 1.1919571161270142, GAN loss = [2.2493324, 0.7701824, 0.8361107]\n",
      "Batch 6/700: Discriminator loss = 1.1855499744415283, GAN loss = [2.3220885, 0.7618507, 0.9172326]\n",
      "Batch 7/700: Discriminator loss = 1.194167971611023, GAN loss = [2.2784503, 0.7814378, 0.8540313]\n",
      "Batch 8/700: Discriminator loss = 1.1940240859985352, GAN loss = [2.2824073, 0.7671466, 0.87229913]\n",
      "Batch 9/700: Discriminator loss = 1.1771007776260376, GAN loss = [2.2424674, 0.7782074, 0.82132983]\n",
      "Batch 10/700: Discriminator loss = 1.1904937028884888, GAN loss = [2.2958257, 0.7742343, 0.87866974]\n",
      "Batch 11/700: Discriminator loss = 1.1988686323165894, GAN loss = [2.2449234, 0.7581773, 0.8438587]\n",
      "Batch 12/700: Discriminator loss = 1.2020999193191528, GAN loss = [2.2618167, 0.7615248, 0.8574198]\n",
      "Batch 13/700: Discriminator loss = 1.184062123298645, GAN loss = [2.3010216, 0.7835163, 0.8746374]\n",
      "Batch 14/700: Discriminator loss = 1.2152605056762695, GAN loss = [2.1979983, 0.7314134, 0.82373124]\n",
      "Batch 15/700: Discriminator loss = 1.2278022766113281, GAN loss = [2.2286553, 0.73698866, 0.84884673]\n",
      "Batch 16/700: Discriminator loss = 1.1987664699554443, GAN loss = [2.2664957, 0.769645, 0.854058]\n",
      "Batch 17/700: Discriminator loss = 1.2227524518966675, GAN loss = [2.2114484, 0.74139655, 0.8272728]\n",
      "Batch 18/700: Discriminator loss = 1.2565885782241821, GAN loss = [2.2186792, 0.71265703, 0.8632603]\n",
      "Batch 19/700: Discriminator loss = 1.2586504220962524, GAN loss = [2.179059, 0.7226439, 0.8136401]\n",
      "Batch 20/700: Discriminator loss = 1.2120122909545898, GAN loss = [2.2809756, 0.7539991, 0.8841988]\n",
      "Batch 21/700: Discriminator loss = 1.2918877601623535, GAN loss = [2.1715364, 0.6868039, 0.8419438]\n",
      "Batch 22/700: Discriminator loss = 1.2251585721969604, GAN loss = [2.2112448, 0.7463769, 0.8220796]\n",
      "Batch 23/700: Discriminator loss = 1.2376148700714111, GAN loss = [2.163034, 0.73645294, 0.78379357]\n",
      "Batch 24/700: Discriminator loss = 1.223462700843811, GAN loss = [2.1942055, 0.7432878, 0.80813193]\n",
      "Batch 25/700: Discriminator loss = 1.2106736898422241, GAN loss = [2.215436, 0.74149096, 0.83117425]\n",
      "Batch 26/700: Discriminator loss = 1.2095746994018555, GAN loss = [2.2421706, 0.7653583, 0.83405393]\n",
      "Batch 27/700: Discriminator loss = 1.208099126815796, GAN loss = [2.197417, 0.74832314, 0.80634254]\n",
      "Batch 28/700: Discriminator loss = 1.2041469812393188, GAN loss = [2.254801, 0.7547394, 0.8573307]\n",
      "Batch 29/700: Discriminator loss = 1.1799378395080566, GAN loss = [2.2356308, 0.7691446, 0.82378733]\n",
      "Batch 30/700: Discriminator loss = 1.1723183393478394, GAN loss = [2.3163154, 0.7920881, 0.8815605]\n",
      "Batch 31/700: Discriminator loss = 1.1899287700653076, GAN loss = [2.2598283, 0.77027303, 0.8469203]\n",
      "Batch 32/700: Discriminator loss = 1.188353419303894, GAN loss = [2.2217114, 0.766459, 0.8126683]\n",
      "Batch 33/700: Discriminator loss = 1.192481279373169, GAN loss = [2.2938766, 0.7702348, 0.88109964]\n",
      "Batch 34/700: Discriminator loss = 1.1760748624801636, GAN loss = [2.3209965, 0.7883241, 0.8901729]\n",
      "Batch 35/700: Discriminator loss = 1.193752408027649, GAN loss = [2.241314, 0.7703721, 0.82848775]\n",
      "Batch 36/700: Discriminator loss = 1.193937063217163, GAN loss = [2.2483828, 0.7585579, 0.84741455]\n",
      "Batch 37/700: Discriminator loss = 1.2081916332244873, GAN loss = [2.2505991, 0.7497044, 0.85852814]\n",
      "Batch 38/700: Discriminator loss = 1.1889495849609375, GAN loss = [2.2820942, 0.76262933, 0.8771456]\n",
      "Batch 39/700: Discriminator loss = 1.204647421836853, GAN loss = [2.268432, 0.74982697, 0.8763296]\n",
      "Batch 40/700: Discriminator loss = 1.218839168548584, GAN loss = [2.2357483, 0.7479025, 0.8456143]\n",
      "Batch 41/700: Discriminator loss = 1.2165913581848145, GAN loss = [2.1919746, 0.7440305, 0.80574113]\n",
      "Batch 42/700: Discriminator loss = 1.2021158933639526, GAN loss = [2.2517858, 0.7624595, 0.84717554]\n",
      "Batch 43/700: Discriminator loss = 1.1991769075393677, GAN loss = [2.2686977, 0.7623725, 0.8642322]\n",
      "Batch 44/700: Discriminator loss = 1.2249099016189575, GAN loss = [2.2139802, 0.73777765, 0.83416903]\n",
      "Batch 45/700: Discriminator loss = 1.2146475315093994, GAN loss = [2.1941311, 0.7376537, 0.81447524]\n",
      "Batch 46/700: Discriminator loss = 1.198416829109192, GAN loss = [2.2510717, 0.76063013, 0.8484818]\n",
      "Batch 47/700: Discriminator loss = 1.2157533168792725, GAN loss = [2.1981554, 0.7531376, 0.8030994]\n",
      "Batch 48/700: Discriminator loss = 1.1931698322296143, GAN loss = [2.1991029, 0.75744075, 0.79979235]\n",
      "Batch 49/700: Discriminator loss = 1.2004035711288452, GAN loss = [2.196228, 0.7563736, 0.7980235]\n",
      "Batch 50/700: Discriminator loss = 1.1936222314834595, GAN loss = [2.1940937, 0.75528735, 0.7970094]\n",
      "Batch 51/700: Discriminator loss = 1.2147302627563477, GAN loss = [2.1933722, 0.73809654, 0.81350243]\n",
      "Batch 52/700: Discriminator loss = 1.2020286321640015, GAN loss = [2.1876009, 0.7513473, 0.7945121]\n",
      "Batch 53/700: Discriminator loss = 1.1991733312606812, GAN loss = [2.1757038, 0.7473946, 0.786602]\n",
      "Batch 54/700: Discriminator loss = 1.216126561164856, GAN loss = [2.1825075, 0.74621934, 0.7946205]\n",
      "Batch 55/700: Discriminator loss = 1.2125310897827148, GAN loss = [2.1691058, 0.7476538, 0.7798172]\n",
      "Batch 56/700: Discriminator loss = 1.1770747900009155, GAN loss = [2.2414129, 0.76735324, 0.8324662]\n",
      "Batch 57/700: Discriminator loss = 1.1856393814086914, GAN loss = [2.2625377, 0.78522474, 0.835758]\n",
      "Batch 58/700: Discriminator loss = 1.1792147159576416, GAN loss = [2.233115, 0.786846, 0.80475205]\n",
      "Batch 59/700: Discriminator loss = 1.1740689277648926, GAN loss = [2.1964424, 0.791978, 0.76299775]\n",
      "Batch 60/700: Discriminator loss = 1.1540305614471436, GAN loss = [2.2464607, 0.78919715, 0.8158424]\n",
      "Batch 61/700: Discriminator loss = 1.1833386421203613, GAN loss = [2.1959121, 0.77500033, 0.7795401]\n",
      "Batch 62/700: Discriminator loss = 1.1513241529464722, GAN loss = [2.2453232, 0.79859805, 0.805399]\n",
      "Batch 63/700: Discriminator loss = 1.1538827419281006, GAN loss = [2.2669702, 0.79058135, 0.83511]\n",
      "Batch 64/700: Discriminator loss = 1.1626167297363281, GAN loss = [2.222282, 0.77797186, 0.8030654]\n",
      "Batch 65/700: Discriminator loss = 1.1545345783233643, GAN loss = [2.2448077, 0.7935405, 0.8100765]\n",
      "Batch 66/700: Discriminator loss = 1.1515628099441528, GAN loss = [2.3125196, 0.8081629, 0.86320716]\n",
      "Batch 67/700: Discriminator loss = 1.1665583848953247, GAN loss = [2.2772732, 0.79672074, 0.83944017]\n",
      "Batch 68/700: Discriminator loss = 1.1634680032730103, GAN loss = [2.3330538, 0.76937395, 0.922618]\n",
      "Batch 69/700: Discriminator loss = 1.1723161935806274, GAN loss = [2.2995272, 0.7834317, 0.875061]\n",
      "Batch 70/700: Discriminator loss = 1.1705666780471802, GAN loss = [2.2668235, 0.79060066, 0.8352207]\n",
      "Batch 71/700: Discriminator loss = 1.1503466367721558, GAN loss = [2.3389523, 0.7987253, 0.899272]\n",
      "Batch 72/700: Discriminator loss = 1.158840537071228, GAN loss = [2.3065171, 0.7875401, 0.87805074]\n",
      "Batch 73/700: Discriminator loss = 1.1941791772842407, GAN loss = [2.26192, 0.7737997, 0.8472141]\n",
      "Batch 74/700: Discriminator loss = 1.173060655593872, GAN loss = [2.2941067, 0.78622925, 0.86698323]\n",
      "Batch 75/700: Discriminator loss = 1.1963474750518799, GAN loss = [2.197358, 0.7577534, 0.79868317]\n",
      "Batch 76/700: Discriminator loss = 1.2175517082214355, GAN loss = [2.2970388, 0.75195813, 0.90411687]\n",
      "Batch 77/700: Discriminator loss = 1.2245439291000366, GAN loss = [2.2233508, 0.74695647, 0.8354083]\n",
      "Batch 78/700: Discriminator loss = 1.2159940004348755, GAN loss = [2.2007194, 0.750493, 0.8092099]\n",
      "Batch 79/700: Discriminator loss = 1.238178014755249, GAN loss = [2.201606, 0.7429437, 0.8176088]\n",
      "Batch 80/700: Discriminator loss = 1.2323836088180542, GAN loss = [2.147168, 0.73997843, 0.76609856]\n",
      "Batch 81/700: Discriminator loss = 1.2139060497283936, GAN loss = [2.1911888, 0.7460137, 0.8040667]\n",
      "Batch 82/700: Discriminator loss = 1.199788212776184, GAN loss = [2.172675, 0.7663798, 0.76517624]\n",
      "Batch 83/700: Discriminator loss = 1.2009797096252441, GAN loss = [2.2258115, 0.7818468, 0.8028404]\n",
      "Batch 84/700: Discriminator loss = 1.2030919790267944, GAN loss = [2.1936822, 0.7576783, 0.79486275]\n",
      "Batch 85/700: Discriminator loss = 1.2173904180526733, GAN loss = [2.1997104, 0.7438384, 0.81468964]\n",
      "Batch 86/700: Discriminator loss = 1.1944310665130615, GAN loss = [2.2287192, 0.78712445, 0.8003851]\n",
      "Batch 87/700: Discriminator loss = 1.1967637538909912, GAN loss = [2.2223113, 0.7890939, 0.79200345]\n",
      "Batch 88/700: Discriminator loss = 1.1810410022735596, GAN loss = [2.2120245, 0.78609544, 0.7847287]\n",
      "Batch 89/700: Discriminator loss = 1.2065534591674805, GAN loss = [2.2411885, 0.7464058, 0.8535846]\n",
      "Batch 90/700: Discriminator loss = 1.20237398147583, GAN loss = [2.2209446, 0.7558059, 0.8239623]\n",
      "Batch 91/700: Discriminator loss = 1.186661720275879, GAN loss = [2.2223284, 0.76840895, 0.81277496]\n",
      "Batch 92/700: Discriminator loss = 1.1809555292129517, GAN loss = [2.2571766, 0.78570276, 0.8303611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 93/700: Discriminator loss = 1.1878544092178345, GAN loss = [2.2649167, 0.77524066, 0.8485881]\n",
      "Batch 94/700: Discriminator loss = 1.1831955909729004, GAN loss = [2.242643, 0.77512735, 0.82645166]\n",
      "Batch 95/700: Discriminator loss = 1.2009470462799072, GAN loss = [2.1983936, 0.7549727, 0.8024153]\n",
      "Batch 96/700: Discriminator loss = 1.1911219358444214, GAN loss = [2.2557654, 0.76600367, 0.8488034]\n",
      "Batch 97/700: Discriminator loss = 1.192522644996643, GAN loss = [2.2429457, 0.75858283, 0.8434533]\n",
      "Batch 98/700: Discriminator loss = 1.2096238136291504, GAN loss = [2.2032104, 0.7504283, 0.81190324]\n",
      "Batch 99/700: Discriminator loss = 1.2534914016723633, GAN loss = [2.1822915, 0.70856947, 0.83288383]\n",
      "Batch 100/700: Discriminator loss = 1.22298002243042, GAN loss = [2.1807852, 0.7210352, 0.81895524]\n",
      "Batch 101/700: Discriminator loss = 1.196449637413025, GAN loss = [2.215189, 0.7543142, 0.8201342]\n",
      "Batch 102/700: Discriminator loss = 1.1929435729980469, GAN loss = [2.1993294, 0.7592054, 0.79944116]\n",
      "Batch 103/700: Discriminator loss = 1.2185897827148438, GAN loss = [2.1809008, 0.7383047, 0.80197406]\n",
      "Batch 104/700: Discriminator loss = 1.1726614236831665, GAN loss = [2.2429798, 0.77680665, 0.82560456]\n",
      "Batch 105/700: Discriminator loss = 1.2012873888015747, GAN loss = [2.199546, 0.74439013, 0.81464005]\n",
      "Batch 106/700: Discriminator loss = 1.18763267993927, GAN loss = [2.2151253, 0.75230485, 0.82236046]\n",
      "Batch 107/700: Discriminator loss = 1.1885308027267456, GAN loss = [2.1716273, 0.7433137, 0.78790545]\n",
      "Batch 108/700: Discriminator loss = 1.1769347190856934, GAN loss = [2.2334526, 0.7698378, 0.8232465]\n",
      "Batch 109/700: Discriminator loss = 1.2112542390823364, GAN loss = [2.173248, 0.7209032, 0.8119991]\n",
      "Batch 110/700: Discriminator loss = 1.1956125497817993, GAN loss = [2.2505963, 0.7450153, 0.86528045]\n",
      "Batch 111/700: Discriminator loss = 1.1858819723129272, GAN loss = [2.1922834, 0.7502278, 0.80180407]\n",
      "Batch 112/700: Discriminator loss = 1.184246301651001, GAN loss = [2.2157567, 0.7538526, 0.82169485]\n",
      "Batch 113/700: Discriminator loss = 1.188085675239563, GAN loss = [2.215599, 0.74709094, 0.8283331]\n",
      "Batch 114/700: Discriminator loss = 1.2052310705184937, GAN loss = [2.1859763, 0.7251347, 0.82070434]\n",
      "Batch 115/700: Discriminator loss = 1.2099894285202026, GAN loss = [2.2095304, 0.7237721, 0.8456693]\n",
      "Batch 116/700: Discriminator loss = 1.1988651752471924, GAN loss = [2.191189, 0.73156846, 0.8195672]\n",
      "Batch 117/700: Discriminator loss = 1.189022421836853, GAN loss = [2.2097483, 0.74678427, 0.82294047]\n",
      "Batch 118/700: Discriminator loss = 1.218306303024292, GAN loss = [2.203406, 0.74293894, 0.8204481]\n",
      "Batch 119/700: Discriminator loss = 1.2060760259628296, GAN loss = [2.1798499, 0.71883017, 0.8210021]\n",
      "Batch 120/700: Discriminator loss = 1.209038257598877, GAN loss = [2.2198842, 0.73728025, 0.8426127]\n",
      "Batch 121/700: Discriminator loss = 1.189711570739746, GAN loss = [2.2214115, 0.75357974, 0.8278695]\n",
      "Batch 122/700: Discriminator loss = 1.1975401639938354, GAN loss = [2.230061, 0.7341697, 0.8559541]\n",
      "Batch 123/700: Discriminator loss = 1.1733129024505615, GAN loss = [2.2268012, 0.76439905, 0.8224878]\n",
      "Batch 124/700: Discriminator loss = 1.1877210140228271, GAN loss = [2.2376997, 0.7551959, 0.8426173]\n",
      "Batch 125/700: Discriminator loss = 1.1887096166610718, GAN loss = [2.2272627, 0.75372446, 0.8336702]\n",
      "Batch 126/700: Discriminator loss = 1.1752885580062866, GAN loss = [2.2538652, 0.7677018, 0.84631896]\n",
      "Batch 127/700: Discriminator loss = 1.2134044170379639, GAN loss = [2.19436, 0.7290718, 0.82547295]\n",
      "Batch 128/700: Discriminator loss = 1.1873117685317993, GAN loss = [2.2227776, 0.74891144, 0.8340909]\n",
      "Batch 129/700: Discriminator loss = 1.1761784553527832, GAN loss = [2.2656834, 0.7737911, 0.8521607]\n",
      "Batch 130/700: Discriminator loss = 1.2022508382797241, GAN loss = [2.1978245, 0.73635834, 0.821759]\n",
      "Batch 131/700: Discriminator loss = 1.21674644947052, GAN loss = [2.2029474, 0.7188677, 0.84440416]\n",
      "Batch 132/700: Discriminator loss = 1.1869690418243408, GAN loss = [2.240208, 0.7415695, 0.8590026]\n",
      "Batch 133/700: Discriminator loss = 1.1981362104415894, GAN loss = [2.234406, 0.74117875, 0.85363406]\n",
      "Batch 134/700: Discriminator loss = 1.2170796394348145, GAN loss = [2.1983442, 0.719918, 0.83886904]\n",
      "Batch 135/700: Discriminator loss = 1.2139291763305664, GAN loss = [2.1591935, 0.7134568, 0.8062098]\n",
      "Batch 136/700: Discriminator loss = 1.1978802680969238, GAN loss = [2.2471523, 0.73765916, 0.8699836]\n",
      "Batch 137/700: Discriminator loss = 1.1992381811141968, GAN loss = [2.1876197, 0.7304275, 0.8176871]\n",
      "Batch 138/700: Discriminator loss = 1.2005535364151, GAN loss = [2.220578, 0.7384621, 0.8426247]\n",
      "Batch 139/700: Discriminator loss = 1.2006441354751587, GAN loss = [2.260013, 0.7454376, 0.8750828]\n",
      "Batch 140/700: Discriminator loss = 1.1928982734680176, GAN loss = [2.2753167, 0.746251, 0.88958067]\n",
      "Batch 141/700: Discriminator loss = 1.2110737562179565, GAN loss = [2.2238114, 0.7260109, 0.85831624]\n",
      "Batch 142/700: Discriminator loss = 1.1864306926727295, GAN loss = [2.2844918, 0.75320137, 0.8918201]\n",
      "Batch 143/700: Discriminator loss = 1.1929259300231934, GAN loss = [2.2486205, 0.7342564, 0.8749155]\n",
      "Batch 144/700: Discriminator loss = 1.191367268562317, GAN loss = [2.2491727, 0.7530182, 0.85673624]\n",
      "Batch 145/700: Discriminator loss = 1.1893969774246216, GAN loss = [2.2480173, 0.74246, 0.86616135]\n",
      "Batch 146/700: Discriminator loss = 1.1682031154632568, GAN loss = [2.2539787, 0.7698948, 0.84469]\n",
      "Batch 147/700: Discriminator loss = 1.1645466089248657, GAN loss = [2.2861652, 0.77387315, 0.8728897]\n",
      "Batch 148/700: Discriminator loss = 1.1821444034576416, GAN loss = [2.2528903, 0.7570562, 0.8564225]\n",
      "Batch 149/700: Discriminator loss = 1.1897480487823486, GAN loss = [2.264184, 0.76237607, 0.8623818]\n",
      "Batch 150/700: Discriminator loss = 1.2023040056228638, GAN loss = [2.2099745, 0.74376017, 0.82678527]\n",
      "Batch 151/700: Discriminator loss = 1.1922415494918823, GAN loss = [2.2189662, 0.7528208, 0.8267331]\n",
      "Batch 152/700: Discriminator loss = 1.1906646490097046, GAN loss = [2.2202063, 0.7521479, 0.8286645]\n",
      "Batch 153/700: Discriminator loss = 1.2113301753997803, GAN loss = [2.2442288, 0.7338235, 0.8710251]\n",
      "Batch 154/700: Discriminator loss = 1.1920452117919922, GAN loss = [2.2450032, 0.74736786, 0.85825753]\n",
      "Batch 155/700: Discriminator loss = 1.2048686742782593, GAN loss = [2.2481399, 0.7348472, 0.8739148]\n",
      "Batch 156/700: Discriminator loss = 1.2012568712234497, GAN loss = [2.2959375, 0.75387347, 0.90268487]\n",
      "Batch 157/700: Discriminator loss = 1.2156513929367065, GAN loss = [2.2588327, 0.7378267, 0.8816198]\n",
      "Batch 158/700: Discriminator loss = 1.2306959629058838, GAN loss = [2.2014205, 0.7091541, 0.85285485]\n",
      "Batch 159/700: Discriminator loss = 1.2376800775527954, GAN loss = [2.2203689, 0.71183443, 0.8690954]\n",
      "Batch 160/700: Discriminator loss = 1.2399176359176636, GAN loss = [2.2163377, 0.7164021, 0.860469]\n",
      "Batch 161/700: Discriminator loss = 1.232239842414856, GAN loss = [2.2105503, 0.71224076, 0.85878485]\n",
      "Batch 162/700: Discriminator loss = 1.2486790418624878, GAN loss = [2.2234516, 0.721263, 0.8626109]\n",
      "Batch 163/700: Discriminator loss = 1.2101819515228271, GAN loss = [2.2342515, 0.74147034, 0.8531678]\n",
      "Batch 164/700: Discriminator loss = 1.221976399421692, GAN loss = [2.2135277, 0.7512181, 0.8226852]\n",
      "Batch 165/700: Discriminator loss = 1.208884835243225, GAN loss = [2.2350357, 0.73844045, 0.85694814]\n",
      "Batch 166/700: Discriminator loss = 1.188645362854004, GAN loss = [2.2907941, 0.7623764, 0.88876176]\n",
      "Batch 167/700: Discriminator loss = 1.209019422531128, GAN loss = [2.2383106, 0.7283544, 0.8703085]\n",
      "Batch 168/700: Discriminator loss = 1.1978839635849, GAN loss = [2.2255328, 0.73790634, 0.84797347]\n",
      "Batch 169/700: Discriminator loss = 1.2281850576400757, GAN loss = [2.1985202, 0.725577, 0.8332969]\n",
      "Batch 170/700: Discriminator loss = 1.2406781911849976, GAN loss = [2.1702266, 0.71352404, 0.81706244]\n",
      "Batch 171/700: Discriminator loss = 1.2338711023330688, GAN loss = [2.2139752, 0.7143302, 0.8600047]\n",
      "Batch 172/700: Discriminator loss = 1.2199944257736206, GAN loss = [2.1847641, 0.73008806, 0.81503594]\n",
      "Batch 173/700: Discriminator loss = 1.2035471200942993, GAN loss = [2.2532732, 0.7531198, 0.8605255]\n",
      "Batch 174/700: Discriminator loss = 1.2088489532470703, GAN loss = [2.224127, 0.7410668, 0.8434471]\n",
      "Batch 175/700: Discriminator loss = 1.188952922821045, GAN loss = [2.253148, 0.75174, 0.8618063]\n",
      "Batch 176/700: Discriminator loss = 1.2138108015060425, GAN loss = [2.2601752, 0.7381463, 0.8824338]\n",
      "Batch 177/700: Discriminator loss = 1.162593960762024, GAN loss = [2.2879345, 0.7906516, 0.8576933]\n",
      "Batch 178/700: Discriminator loss = 1.1912485361099243, GAN loss = [2.248477, 0.7693956, 0.8394764]\n",
      "Batch 179/700: Discriminator loss = 1.1807032823562622, GAN loss = [2.2219534, 0.7588174, 0.8235356]\n",
      "Batch 180/700: Discriminator loss = 1.1872718334197998, GAN loss = [2.2642467, 0.75464547, 0.87001085]\n",
      "Batch 181/700: Discriminator loss = 1.181748628616333, GAN loss = [2.1922593, 0.7630604, 0.78962016]\n",
      "Batch 182/700: Discriminator loss = 1.1656819581985474, GAN loss = [2.2444324, 0.766177, 0.8387018]\n",
      "Batch 183/700: Discriminator loss = 1.191937804222107, GAN loss = [2.2000518, 0.75213844, 0.8083565]\n",
      "Batch 184/700: Discriminator loss = 1.1733883619308472, GAN loss = [2.2726328, 0.7597632, 0.8733253]\n",
      "Batch 185/700: Discriminator loss = 1.1686880588531494, GAN loss = [2.2674263, 0.77914447, 0.84874594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 186/700: Discriminator loss = 1.1724931001663208, GAN loss = [2.2596123, 0.7553084, 0.864764]\n",
      "Batch 187/700: Discriminator loss = 1.1888903379440308, GAN loss = [2.2672036, 0.7551912, 0.87246156]\n",
      "Batch 188/700: Discriminator loss = 1.1889549493789673, GAN loss = [2.2561905, 0.76802564, 0.84858865]\n",
      "Batch 189/700: Discriminator loss = 1.1841561794281006, GAN loss = [2.2611847, 0.7635897, 0.8580175]\n",
      "Batch 190/700: Discriminator loss = 1.1804314851760864, GAN loss = [2.2461188, 0.7719176, 0.834623]\n",
      "Batch 191/700: Discriminator loss = 1.162777304649353, GAN loss = [2.2905636, 0.78110045, 0.8698878]\n",
      "Batch 192/700: Discriminator loss = 1.18122136592865, GAN loss = [2.2957368, 0.76627517, 0.8898952]\n",
      "Batch 193/700: Discriminator loss = 1.1921536922454834, GAN loss = [2.2118275, 0.74267256, 0.8295824]\n",
      "Batch 194/700: Discriminator loss = 1.194666862487793, GAN loss = [2.274693, 0.7481723, 0.886936]\n",
      "Batch 195/700: Discriminator loss = 1.2216280698776245, GAN loss = [2.2468283, 0.7349916, 0.87223846]\n",
      "Batch 196/700: Discriminator loss = 1.18626070022583, GAN loss = [2.2348444, 0.7658674, 0.82937944]\n",
      "Batch 197/700: Discriminator loss = 1.232521414756775, GAN loss = [2.2026727, 0.7190375, 0.84403527]\n",
      "Batch 198/700: Discriminator loss = 1.1817848682403564, GAN loss = [2.2230515, 0.75561106, 0.8278285]\n",
      "Batch 199/700: Discriminator loss = 1.1837717294692993, GAN loss = [2.2259061, 0.7570833, 0.82921064]\n",
      "Batch 200/700: Discriminator loss = 1.20802640914917, GAN loss = [2.2446694, 0.73641634, 0.8686305]\n",
      "Batch 201/700: Discriminator loss = 1.1939849853515625, GAN loss = [2.2556553, 0.7407019, 0.8753262]\n",
      "Batch 202/700: Discriminator loss = 1.1802423000335693, GAN loss = [2.2879868, 0.7604498, 0.887909]\n",
      "Batch 203/700: Discriminator loss = 1.183432936668396, GAN loss = [2.231061, 0.76110405, 0.8303302]\n",
      "Batch 204/700: Discriminator loss = 1.1789089441299438, GAN loss = [2.237082, 0.75965685, 0.8378038]\n",
      "Batch 205/700: Discriminator loss = 1.1919113397598267, GAN loss = [2.2560062, 0.7626506, 0.85373926]\n",
      "Batch 206/700: Discriminator loss = 1.1814136505126953, GAN loss = [2.3016822, 0.7497445, 0.9123162]\n",
      "Batch 207/700: Discriminator loss = 1.178571343421936, GAN loss = [2.2278173, 0.76968443, 0.8185006]\n",
      "Batch 208/700: Discriminator loss = 1.1723415851593018, GAN loss = [2.2723644, 0.7685325, 0.86419547]\n",
      "Batch 209/700: Discriminator loss = 1.186533808708191, GAN loss = [2.286413, 0.7612173, 0.8855572]\n",
      "Batch 210/700: Discriminator loss = 1.2110934257507324, GAN loss = [2.2097375, 0.7395829, 0.83052707]\n",
      "Batch 211/700: Discriminator loss = 1.2072150707244873, GAN loss = [2.2970777, 0.7591331, 0.89832604]\n",
      "Batch 212/700: Discriminator loss = 1.2046040296554565, GAN loss = [2.2479274, 0.7437848, 0.8645559]\n",
      "Batch 213/700: Discriminator loss = 1.1703147888183594, GAN loss = [2.2743716, 0.7828674, 0.85194933]\n",
      "Batch 214/700: Discriminator loss = 1.1707777976989746, GAN loss = [2.2719753, 0.78019416, 0.8522348]\n",
      "Batch 215/700: Discriminator loss = 1.1870390176773071, GAN loss = [2.2864969, 0.76142484, 0.8855291]\n",
      "Batch 216/700: Discriminator loss = 1.1968786716461182, GAN loss = [2.2646778, 0.7604134, 0.8647327]\n",
      "Batch 217/700: Discriminator loss = 1.1819783449172974, GAN loss = [2.2495778, 0.7590684, 0.8509759]\n",
      "Batch 218/700: Discriminator loss = 1.1971267461776733, GAN loss = [2.278033, 0.73588514, 0.90263563]\n",
      "Batch 219/700: Discriminator loss = 1.1978607177734375, GAN loss = [2.3020844, 0.7516209, 0.9109751]\n",
      "Batch 220/700: Discriminator loss = 1.2031562328338623, GAN loss = [2.240516, 0.75262827, 0.8484005]\n",
      "Batch 221/700: Discriminator loss = 1.1973562240600586, GAN loss = [2.2540805, 0.7520212, 0.8625752]\n",
      "Batch 222/700: Discriminator loss = 1.2072334289550781, GAN loss = [2.1797, 0.73190194, 0.8083417]\n",
      "Batch 223/700: Discriminator loss = 1.1951491832733154, GAN loss = [2.2200487, 0.74486864, 0.83576155]\n",
      "Batch 224/700: Discriminator loss = 1.2147825956344604, GAN loss = [2.300859, 0.7346808, 0.9267965]\n",
      "Batch 225/700: Discriminator loss = 1.2335478067398071, GAN loss = [2.1862972, 0.7202636, 0.8266806]\n",
      "Batch 226/700: Discriminator loss = 1.2341631650924683, GAN loss = [2.2343462, 0.7260931, 0.8689539]\n",
      "Batch 227/700: Discriminator loss = 1.1975334882736206, GAN loss = [2.3082213, 0.7627793, 0.906184]\n",
      "Batch 228/700: Discriminator loss = 1.1863538026809692, GAN loss = [2.2393172, 0.76494265, 0.83514434]\n",
      "Batch 229/700: Discriminator loss = 1.2363574504852295, GAN loss = [2.2002687, 0.7253567, 0.83570695]\n",
      "Batch 230/700: Discriminator loss = 1.2064307928085327, GAN loss = [2.2013762, 0.73252016, 0.82968676]\n",
      "Batch 231/700: Discriminator loss = 1.1685043573379517, GAN loss = [2.2916622, 0.78251696, 0.8700208]\n",
      "Batch 232/700: Discriminator loss = 1.215161681175232, GAN loss = [2.2257051, 0.74616295, 0.84046006]\n",
      "Batch 233/700: Discriminator loss = 1.222143530845642, GAN loss = [2.2142923, 0.72935885, 0.8458708]\n",
      "Batch 234/700: Discriminator loss = 1.2241981029510498, GAN loss = [2.2038715, 0.74409485, 0.8207294]\n",
      "Batch 235/700: Discriminator loss = 1.1986064910888672, GAN loss = [2.222736, 0.7531286, 0.8305681]\n",
      "Batch 236/700: Discriminator loss = 1.2162888050079346, GAN loss = [2.2293065, 0.7420237, 0.8482574]\n",
      "Batch 237/700: Discriminator loss = 1.2164404392242432, GAN loss = [2.258149, 0.73509, 0.8840299]\n",
      "Batch 238/700: Discriminator loss = 1.2065863609313965, GAN loss = [2.186878, 0.7430771, 0.80477244]\n",
      "Batch 239/700: Discriminator loss = 1.2323191165924072, GAN loss = [2.1719787, 0.7267761, 0.806157]\n",
      "Batch 240/700: Discriminator loss = 1.2279938459396362, GAN loss = [2.206426, 0.7332175, 0.83419776]\n",
      "Batch 241/700: Discriminator loss = 1.2183371782302856, GAN loss = [2.2005491, 0.75042504, 0.8111465]\n",
      "Batch 242/700: Discriminator loss = 1.2013752460479736, GAN loss = [2.222008, 0.75950533, 0.823555]\n",
      "Batch 243/700: Discriminator loss = 1.2030290365219116, GAN loss = [2.1966007, 0.7489885, 0.8086843]\n",
      "Batch 244/700: Discriminator loss = 1.184027910232544, GAN loss = [2.2201383, 0.75328726, 0.827944]\n",
      "Batch 245/700: Discriminator loss = 1.2307281494140625, GAN loss = [2.1924982, 0.7221888, 0.83142966]\n",
      "Batch 246/700: Discriminator loss = 1.179979920387268, GAN loss = [2.234742, 0.76004034, 0.8358568]\n",
      "Batch 247/700: Discriminator loss = 1.1863645315170288, GAN loss = [2.2769086, 0.7650063, 0.8731033]\n",
      "Batch 248/700: Discriminator loss = 1.211440920829773, GAN loss = [2.2153099, 0.74652207, 0.83003396]\n",
      "Batch 249/700: Discriminator loss = 1.1978778839111328, GAN loss = [2.1968539, 0.7477787, 0.81034815]\n",
      "Batch 250/700: Discriminator loss = 1.1929326057434082, GAN loss = [2.1954074, 0.7582525, 0.79845166]\n",
      "Batch 251/700: Discriminator loss = 1.2050082683563232, GAN loss = [2.2405014, 0.7346297, 0.86718506]\n",
      "Batch 252/700: Discriminator loss = 1.1976536512374878, GAN loss = [2.1896281, 0.75406235, 0.7968919]\n",
      "Batch 253/700: Discriminator loss = 1.2200987339019775, GAN loss = [2.219909, 0.7210109, 0.86023957]\n",
      "Batch 254/700: Discriminator loss = 1.1968472003936768, GAN loss = [2.25502, 0.7565205, 0.85985166]\n",
      "Batch 255/700: Discriminator loss = 1.174341082572937, GAN loss = [2.2515442, 0.7573936, 0.85553396]\n",
      "Batch 256/700: Discriminator loss = 1.2055480480194092, GAN loss = [2.2669528, 0.73217994, 0.8961923]\n",
      "Batch 257/700: Discriminator loss = 1.2325363159179688, GAN loss = [2.1822412, 0.716587, 0.82710046]\n",
      "Batch 258/700: Discriminator loss = 1.2023353576660156, GAN loss = [2.214751, 0.7441633, 0.83203393]\n",
      "Batch 259/700: Discriminator loss = 1.2059942483901978, GAN loss = [2.2329164, 0.73550063, 0.85886306]\n",
      "Batch 260/700: Discriminator loss = 1.2035568952560425, GAN loss = [2.216524, 0.7334851, 0.84449774]\n",
      "Batch 261/700: Discriminator loss = 1.2034467458724976, GAN loss = [2.2658284, 0.7416431, 0.88567865]\n",
      "Batch 262/700: Discriminator loss = 1.207383632659912, GAN loss = [2.288003, 0.7504498, 0.8990783]\n",
      "Batch 263/700: Discriminator loss = 1.1947321891784668, GAN loss = [2.288394, 0.75766176, 0.892262]\n",
      "Batch 264/700: Discriminator loss = 1.2158129215240479, GAN loss = [2.191572, 0.7350958, 0.8180267]\n",
      "Batch 265/700: Discriminator loss = 1.2047345638275146, GAN loss = [2.26696, 0.732789, 0.89574003]\n",
      "Batch 266/700: Discriminator loss = 1.2054953575134277, GAN loss = [2.2285001, 0.74352235, 0.8465401]\n",
      "Batch 267/700: Discriminator loss = 1.2011325359344482, GAN loss = [2.160518, 0.7372711, 0.78481585]\n",
      "Batch 268/700: Discriminator loss = 1.2390977144241333, GAN loss = [2.1732087, 0.7141792, 0.8205942]\n",
      "Batch 269/700: Discriminator loss = 1.1941808462142944, GAN loss = [2.2174804, 0.75292397, 0.82615006]\n",
      "Batch 270/700: Discriminator loss = 1.2030247449874878, GAN loss = [2.189976, 0.7357952, 0.81578666]\n",
      "Batch 271/700: Discriminator loss = 1.2183119058609009, GAN loss = [2.1957877, 0.72574687, 0.8316474]\n",
      "Batch 272/700: Discriminator loss = 1.1925667524337769, GAN loss = [2.2133477, 0.7269116, 0.8480456]\n",
      "Batch 273/700: Discriminator loss = 1.195236325263977, GAN loss = [2.262984, 0.76023775, 0.8643853]\n",
      "Batch 274/700: Discriminator loss = 1.1627492904663086, GAN loss = [2.2255108, 0.7689277, 0.8182332]\n",
      "Batch 275/700: Discriminator loss = 1.1729471683502197, GAN loss = [2.2538593, 0.75076157, 0.86475533]\n",
      "Batch 276/700: Discriminator loss = 1.191925048828125, GAN loss = [2.2769682, 0.7466378, 0.89202446]\n",
      "Batch 277/700: Discriminator loss = 1.1891096830368042, GAN loss = [2.2469132, 0.75108635, 0.85752225]\n",
      "Batch 278/700: Discriminator loss = 1.1917306184768677, GAN loss = [2.2471006, 0.7443031, 0.86447173]\n",
      "Batch 279/700: Discriminator loss = 1.1865589618682861, GAN loss = [2.258696, 0.7531692, 0.86719614]\n",
      "Batch 280/700: Discriminator loss = 1.1819299459457397, GAN loss = [2.2632403, 0.7435976, 0.8813218]\n",
      "Batch 281/700: Discriminator loss = 1.1978464126586914, GAN loss = [2.1987934, 0.72838193, 0.832102]\n",
      "Batch 282/700: Discriminator loss = 1.2036726474761963, GAN loss = [2.2338827, 0.72868764, 0.8669069]\n",
      "Batch 283/700: Discriminator loss = 1.191645622253418, GAN loss = [2.2342749, 0.7362387, 0.8597693]\n",
      "Batch 284/700: Discriminator loss = 1.1896530389785767, GAN loss = [2.2662015, 0.7315363, 0.89641386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 285/700: Discriminator loss = 1.1955006122589111, GAN loss = [2.238626, 0.7318559, 0.8685308]\n",
      "Batch 286/700: Discriminator loss = 1.192958950996399, GAN loss = [2.2667897, 0.7463693, 0.8821759]\n",
      "Batch 287/700: Discriminator loss = 1.1891456842422485, GAN loss = [2.230767, 0.7375826, 0.8549287]\n",
      "Batch 288/700: Discriminator loss = 1.1931730508804321, GAN loss = [2.250935, 0.73937297, 0.87330925]\n",
      "Batch 289/700: Discriminator loss = 1.1774789094924927, GAN loss = [2.3087695, 0.7765661, 0.8939474]\n",
      "Batch 290/700: Discriminator loss = 1.1800287961959839, GAN loss = [2.306126, 0.76693094, 0.90093744]\n",
      "Batch 291/700: Discriminator loss = 1.1757665872573853, GAN loss = [2.2788844, 0.767926, 0.8727119]\n",
      "Batch 292/700: Discriminator loss = 1.1636972427368164, GAN loss = [2.3080652, 0.7713382, 0.8984929]\n",
      "Batch 293/700: Discriminator loss = 1.1885453462600708, GAN loss = [2.2667365, 0.7532025, 0.8753267]\n",
      "Batch 294/700: Discriminator loss = 1.1598156690597534, GAN loss = [2.2925832, 0.7875354, 0.8668562]\n",
      "Batch 295/700: Discriminator loss = 1.171217679977417, GAN loss = [2.3163314, 0.77525675, 0.90290284]\n",
      "Batch 296/700: Discriminator loss = 1.1651802062988281, GAN loss = [2.2890553, 0.77820987, 0.87271684]\n",
      "Batch 297/700: Discriminator loss = 1.1794039011001587, GAN loss = [2.2480245, 0.76490355, 0.8450054]\n",
      "Batch 298/700: Discriminator loss = 1.1753785610198975, GAN loss = [2.3205423, 0.77524984, 0.9071659]\n",
      "Batch 299/700: Discriminator loss = 1.1601133346557617, GAN loss = [2.2925045, 0.79911417, 0.8552734]\n",
      "Batch 300/700: Discriminator loss = 1.1671398878097534, GAN loss = [2.2829351, 0.79111475, 0.85369253]\n",
      "Batch 301/700: Discriminator loss = 1.1917191743850708, GAN loss = [2.2749407, 0.77318114, 0.8636224]\n",
      "Batch 302/700: Discriminator loss = 1.1566660404205322, GAN loss = [2.3040023, 0.8110368, 0.8548249]\n",
      "Batch 303/700: Discriminator loss = 1.1460808515548706, GAN loss = [2.2928073, 0.812049, 0.8426035]\n",
      "Batch 304/700: Discriminator loss = 1.1793047189712524, GAN loss = [2.2823863, 0.78426343, 0.859953]\n",
      "Batch 305/700: Discriminator loss = 1.1647727489471436, GAN loss = [2.3414319, 0.7810986, 0.9221568]\n",
      "Batch 306/700: Discriminator loss = 1.151713490486145, GAN loss = [2.2913327, 0.7900361, 0.8631156]\n",
      "Batch 307/700: Discriminator loss = 1.1863118410110474, GAN loss = [2.240693, 0.75839853, 0.84411466]\n",
      "Batch 308/700: Discriminator loss = 1.1668107509613037, GAN loss = [2.2818341, 0.78495497, 0.85872495]\n",
      "Batch 309/700: Discriminator loss = 1.1837646961212158, GAN loss = [2.2795415, 0.7662429, 0.8751863]\n",
      "Batch 310/700: Discriminator loss = 1.1497762203216553, GAN loss = [2.3846474, 0.8002178, 0.94634575]\n",
      "Batch 311/700: Discriminator loss = 1.1962199211120605, GAN loss = [2.2266052, 0.7439065, 0.84464675]\n",
      "Batch 312/700: Discriminator loss = 1.1749584674835205, GAN loss = [2.2692695, 0.75882494, 0.87242514]\n",
      "Batch 313/700: Discriminator loss = 1.1895127296447754, GAN loss = [2.290859, 0.7778002, 0.8750832]\n",
      "Batch 314/700: Discriminator loss = 1.1650487184524536, GAN loss = [2.3534863, 0.7727259, 0.94280845]\n",
      "Batch 315/700: Discriminator loss = 1.198473334312439, GAN loss = [2.2546878, 0.74168414, 0.87508655]\n",
      "Batch 316/700: Discriminator loss = 1.1880680322647095, GAN loss = [2.2620513, 0.7561126, 0.86808586]\n",
      "Batch 317/700: Discriminator loss = 1.1876083612442017, GAN loss = [2.260636, 0.7528016, 0.87003136]\n",
      "Batch 318/700: Discriminator loss = 1.1865556240081787, GAN loss = [2.2806473, 0.75332564, 0.8895574]\n",
      "Batch 319/700: Discriminator loss = 1.198392391204834, GAN loss = [2.2419786, 0.7401864, 0.8640711]\n",
      "Batch 320/700: Discriminator loss = 1.1807836294174194, GAN loss = [2.2481012, 0.750178, 0.86024255]\n",
      "Batch 321/700: Discriminator loss = 1.1807878017425537, GAN loss = [2.2757726, 0.77178514, 0.86634356]\n",
      "Batch 322/700: Discriminator loss = 1.2012355327606201, GAN loss = [2.2796369, 0.74709094, 0.8949302]\n",
      "Batch 323/700: Discriminator loss = 1.198053240776062, GAN loss = [2.2199595, 0.7417197, 0.84066844]\n",
      "Batch 324/700: Discriminator loss = 1.1849148273468018, GAN loss = [2.2775066, 0.75770867, 0.8822596]\n",
      "Batch 325/700: Discriminator loss = 1.1741071939468384, GAN loss = [2.307964, 0.7676316, 0.90283114]\n",
      "Batch 326/700: Discriminator loss = 1.176203966140747, GAN loss = [2.2728083, 0.7616705, 0.8736531]\n",
      "Batch 327/700: Discriminator loss = 1.1970027685165405, GAN loss = [2.2498422, 0.7501812, 0.8621774]\n",
      "Batch 328/700: Discriminator loss = 1.1769604682922363, GAN loss = [2.334098, 0.7698795, 0.9267611]\n",
      "Batch 329/700: Discriminator loss = 1.1743144989013672, GAN loss = [2.3103442, 0.77713585, 0.89576894]\n",
      "Batch 330/700: Discriminator loss = 1.163459300994873, GAN loss = [2.2879076, 0.78128046, 0.86921823]\n",
      "Batch 331/700: Discriminator loss = 1.179453730583191, GAN loss = [2.3036675, 0.78067786, 0.8856154]\n",
      "Batch 332/700: Discriminator loss = 1.199756145477295, GAN loss = [2.291346, 0.76134634, 0.89265245]\n",
      "Batch 333/700: Discriminator loss = 1.1658157110214233, GAN loss = [2.3264952, 0.7792919, 0.9098954]\n",
      "Batch 334/700: Discriminator loss = 1.1719344854354858, GAN loss = [2.3341875, 0.78512007, 0.91178757]\n",
      "Batch 335/700: Discriminator loss = 1.1723415851593018, GAN loss = [2.3201976, 0.78183824, 0.90110415]\n",
      "Batch 336/700: Discriminator loss = 1.175429344177246, GAN loss = [2.3609107, 0.79036665, 0.93333036]\n",
      "Batch 337/700: Discriminator loss = 1.1872810125350952, GAN loss = [2.3008456, 0.77157, 0.89207596]\n",
      "Batch 338/700: Discriminator loss = 1.220759630203247, GAN loss = [2.2119005, 0.7423737, 0.83234507]\n",
      "Batch 339/700: Discriminator loss = 1.1720267534255981, GAN loss = [2.310844, 0.77712935, 0.89654714]\n",
      "Batch 340/700: Discriminator loss = 1.183933138847351, GAN loss = [2.244073, 0.7801244, 0.8268001]\n",
      "Batch 341/700: Discriminator loss = 1.192339539527893, GAN loss = [2.2905447, 0.768155, 0.885257]\n",
      "Batch 342/700: Discriminator loss = 1.17686927318573, GAN loss = [2.292499, 0.7835672, 0.8718098]\n",
      "Batch 343/700: Discriminator loss = 1.2076058387756348, GAN loss = [2.2346842, 0.7582634, 0.83930516]\n",
      "Batch 344/700: Discriminator loss = 1.2209293842315674, GAN loss = [2.203411, 0.7466101, 0.8196766]\n",
      "Batch 345/700: Discriminator loss = 1.200257420539856, GAN loss = [2.2197618, 0.76592636, 0.8166872]\n",
      "Batch 346/700: Discriminator loss = 1.198958158493042, GAN loss = [2.246493, 0.7676588, 0.84168345]\n",
      "Batch 347/700: Discriminator loss = 1.21001398563385, GAN loss = [2.2158666, 0.7742427, 0.80446786]\n",
      "Batch 348/700: Discriminator loss = 1.19307541847229, GAN loss = [2.2215734, 0.78428483, 0.8001489]\n",
      "Batch 349/700: Discriminator loss = 1.204275131225586, GAN loss = [2.245498, 0.76063186, 0.84772307]\n",
      "Batch 350/700: Discriminator loss = 1.1973588466644287, GAN loss = [2.206306, 0.7784412, 0.79072714]\n",
      "Batch 351/700: Discriminator loss = 1.1830039024353027, GAN loss = [2.2017128, 0.7852581, 0.77932274]\n",
      "Batch 352/700: Discriminator loss = 1.2095271348953247, GAN loss = [2.2031937, 0.7571404, 0.808936]\n",
      "Batch 353/700: Discriminator loss = 1.221544861793518, GAN loss = [2.2029448, 0.7564071, 0.80943894]\n",
      "Batch 354/700: Discriminator loss = 1.207689642906189, GAN loss = [2.206601, 0.7491869, 0.82032394]\n",
      "Batch 355/700: Discriminator loss = 1.2049741744995117, GAN loss = [2.1795566, 0.74173295, 0.8007286]\n",
      "Batch 356/700: Discriminator loss = 1.2179487943649292, GAN loss = [2.1909509, 0.7461354, 0.807737]\n",
      "Batch 357/700: Discriminator loss = 1.2035613059997559, GAN loss = [2.1881742, 0.75654876, 0.79457057]\n",
      "Batch 358/700: Discriminator loss = 1.1762475967407227, GAN loss = [2.2422116, 0.77260786, 0.83257544]\n",
      "Batch 359/700: Discriminator loss = 1.1638368368148804, GAN loss = [2.2364237, 0.78020525, 0.8192174]\n",
      "Batch 360/700: Discriminator loss = 1.1945785284042358, GAN loss = [2.1893759, 0.75366014, 0.79873216]\n",
      "Batch 361/700: Discriminator loss = 1.162841558456421, GAN loss = [2.2397578, 0.7951226, 0.8076749]\n",
      "Batch 362/700: Discriminator loss = 1.1892250776290894, GAN loss = [2.2240193, 0.7666514, 0.8204531]\n",
      "Batch 363/700: Discriminator loss = 1.1937532424926758, GAN loss = [2.202186, 0.75383157, 0.8114655]\n",
      "Batch 364/700: Discriminator loss = 1.1794836521148682, GAN loss = [2.2602074, 0.77817744, 0.8451622]\n",
      "Batch 365/700: Discriminator loss = 1.1916106939315796, GAN loss = [2.2383394, 0.7624793, 0.8390209]\n",
      "Batch 366/700: Discriminator loss = 1.1460540294647217, GAN loss = [2.2903187, 0.81362987, 0.8398933]\n",
      "Batch 367/700: Discriminator loss = 1.186758041381836, GAN loss = [2.2151482, 0.74931204, 0.82908493]\n",
      "Batch 368/700: Discriminator loss = 1.1975507736206055, GAN loss = [2.2194066, 0.7413787, 0.8413146]\n",
      "Batch 369/700: Discriminator loss = 1.1803635358810425, GAN loss = [2.2353003, 0.7609435, 0.8376762]\n",
      "Batch 370/700: Discriminator loss = 1.1801114082336426, GAN loss = [2.216578, 0.75157756, 0.82836604]\n",
      "Batch 371/700: Discriminator loss = 1.180280327796936, GAN loss = [2.2505178, 0.74859995, 0.86532706]\n",
      "Batch 372/700: Discriminator loss = 1.21745765209198, GAN loss = [2.2040756, 0.7120297, 0.85550034]\n",
      "Batch 373/700: Discriminator loss = 1.1972243785858154, GAN loss = [2.205799, 0.74114126, 0.8281609]\n",
      "Batch 374/700: Discriminator loss = 1.1763026714324951, GAN loss = [2.213699, 0.7561093, 0.82113665]\n",
      "Batch 375/700: Discriminator loss = 1.205104112625122, GAN loss = [2.1940002, 0.73207974, 0.8255089]\n",
      "Batch 376/700: Discriminator loss = 1.2156490087509155, GAN loss = [2.2346992, 0.7214916, 0.87684304]\n",
      "Batch 377/700: Discriminator loss = 1.1990859508514404, GAN loss = [2.2366877, 0.7400777, 0.8602888]\n",
      "Batch 378/700: Discriminator loss = 1.201852560043335, GAN loss = [2.1916635, 0.7191343, 0.83623236]\n",
      "Batch 379/700: Discriminator loss = 1.1928927898406982, GAN loss = [2.2713768, 0.72664934, 0.9084576]\n",
      "Batch 380/700: Discriminator loss = 1.1999528408050537, GAN loss = [2.2193098, 0.72436905, 0.8587046]\n",
      "Batch 381/700: Discriminator loss = 1.1894304752349854, GAN loss = [2.3143277, 0.7403035, 0.93783075]\n",
      "Batch 382/700: Discriminator loss = 1.1898378133773804, GAN loss = [2.2241426, 0.73447984, 0.85350305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 383/700: Discriminator loss = 1.194987416267395, GAN loss = [2.228348, 0.7391252, 0.853077]\n",
      "Batch 384/700: Discriminator loss = 1.2005717754364014, GAN loss = [2.2177489, 0.72776383, 0.85385835]\n",
      "Batch 385/700: Discriminator loss = 1.1867029666900635, GAN loss = [2.2267292, 0.7484269, 0.8422052]\n",
      "Batch 386/700: Discriminator loss = 1.1907826662063599, GAN loss = [2.2175684, 0.7434465, 0.8380526]\n",
      "Batch 387/700: Discriminator loss = 1.2010688781738281, GAN loss = [2.217611, 0.7358204, 0.84575933]\n",
      "Batch 388/700: Discriminator loss = 1.204236388206482, GAN loss = [2.2051284, 0.72674507, 0.842384]\n",
      "Batch 389/700: Discriminator loss = 1.2027658224105835, GAN loss = [2.191957, 0.7341075, 0.8218785]\n",
      "Batch 390/700: Discriminator loss = 1.2035001516342163, GAN loss = [2.228223, 0.7386105, 0.85366]\n",
      "Batch 391/700: Discriminator loss = 1.1743602752685547, GAN loss = [2.2465038, 0.7663994, 0.8441734]\n",
      "Batch 392/700: Discriminator loss = 1.2051926851272583, GAN loss = [2.200572, 0.74030036, 0.8243668]\n",
      "Batch 393/700: Discriminator loss = 1.1865954399108887, GAN loss = [2.266464, 0.7642556, 0.8663162]\n",
      "Batch 394/700: Discriminator loss = 1.1856135129928589, GAN loss = [2.2302325, 0.77992487, 0.8144294]\n",
      "Batch 395/700: Discriminator loss = 1.1971147060394287, GAN loss = [2.2174451, 0.74937856, 0.83220404]\n",
      "Batch 396/700: Discriminator loss = 1.209542155265808, GAN loss = [2.200849, 0.7408774, 0.8241364]\n",
      "Batch 397/700: Discriminator loss = 1.2052068710327148, GAN loss = [2.2088313, 0.73134875, 0.84165883]\n",
      "Batch 398/700: Discriminator loss = 1.215328574180603, GAN loss = [2.2117531, 0.7382638, 0.83769]\n",
      "Batch 399/700: Discriminator loss = 1.181045651435852, GAN loss = [2.2281911, 0.7584196, 0.8340165]\n",
      "Batch 400/700: Discriminator loss = 1.2033108472824097, GAN loss = [2.2156239, 0.73899466, 0.8408939]\n",
      "Batch 401/700: Discriminator loss = 1.2167617082595825, GAN loss = [2.2306466, 0.7521057, 0.8428295]\n",
      "Batch 402/700: Discriminator loss = 1.222887396812439, GAN loss = [2.2654164, 0.7411551, 0.88854843]\n",
      "Batch 403/700: Discriminator loss = 1.2021732330322266, GAN loss = [2.2420497, 0.7418832, 0.8644597]\n",
      "Batch 404/700: Discriminator loss = 1.2003427743911743, GAN loss = [2.2426453, 0.74240756, 0.8645518]\n",
      "Batch 405/700: Discriminator loss = 1.2043856382369995, GAN loss = [2.193067, 0.7422798, 0.81512433]\n",
      "Batch 406/700: Discriminator loss = 1.1917039155960083, GAN loss = [2.2330127, 0.7485292, 0.84881544]\n",
      "Batch 407/700: Discriminator loss = 1.2045272588729858, GAN loss = [2.236142, 0.7498746, 0.8505939]\n",
      "Batch 408/700: Discriminator loss = 1.206618309020996, GAN loss = [2.2300568, 0.75677973, 0.8376224]\n",
      "Batch 409/700: Discriminator loss = 1.2133046388626099, GAN loss = [2.2024896, 0.7416854, 0.8251371]\n",
      "Batch 410/700: Discriminator loss = 1.221552848815918, GAN loss = [2.1995077, 0.72343284, 0.84040976]\n",
      "Batch 411/700: Discriminator loss = 1.2159916162490845, GAN loss = [2.2209556, 0.7417028, 0.8435986]\n",
      "Batch 412/700: Discriminator loss = 1.2111899852752686, GAN loss = [2.1991823, 0.7405512, 0.82300425]\n",
      "Batch 413/700: Discriminator loss = 1.20377516746521, GAN loss = [2.175415, 0.7412336, 0.79856515]\n",
      "Batch 414/700: Discriminator loss = 1.2147420644760132, GAN loss = [2.1793118, 0.74510884, 0.79858536]\n",
      "Batch 415/700: Discriminator loss = 1.2024887800216675, GAN loss = [2.1905315, 0.7518491, 0.8030861]\n",
      "Batch 416/700: Discriminator loss = 1.2138651609420776, GAN loss = [2.2226205, 0.7435003, 0.8435577]\n",
      "Batch 417/700: Discriminator loss = 1.2202849388122559, GAN loss = [2.1614368, 0.7374075, 0.7885026]\n",
      "Batch 418/700: Discriminator loss = 1.1906216144561768, GAN loss = [2.20693, 0.7530316, 0.8183924]\n",
      "Batch 419/700: Discriminator loss = 1.2204314470291138, GAN loss = [2.1504169, 0.72731066, 0.78763354]\n",
      "Batch 420/700: Discriminator loss = 1.2038259506225586, GAN loss = [2.185987, 0.738836, 0.81170905]\n",
      "Batch 421/700: Discriminator loss = 1.1794278621673584, GAN loss = [2.2543201, 0.7663909, 0.85250974]\n",
      "Batch 422/700: Discriminator loss = 1.2169075012207031, GAN loss = [2.1858783, 0.74352527, 0.80695885]\n",
      "Batch 423/700: Discriminator loss = 1.215072751045227, GAN loss = [2.1939633, 0.7369188, 0.82167655]\n",
      "Batch 424/700: Discriminator loss = 1.1805928945541382, GAN loss = [2.2267487, 0.7812671, 0.8101392]\n",
      "Batch 425/700: Discriminator loss = 1.207255482673645, GAN loss = [2.1808476, 0.75423074, 0.7912825]\n",
      "Batch 426/700: Discriminator loss = 1.1850415468215942, GAN loss = [2.211191, 0.78005946, 0.7957925]\n",
      "Batch 427/700: Discriminator loss = 1.175421953201294, GAN loss = [2.209936, 0.7711103, 0.8035066]\n",
      "Batch 428/700: Discriminator loss = 1.1802172660827637, GAN loss = [2.229413, 0.77049804, 0.8236095]\n",
      "Batch 429/700: Discriminator loss = 1.157217264175415, GAN loss = [2.2857687, 0.8058439, 0.84463805]\n",
      "Batch 430/700: Discriminator loss = 1.1639196872711182, GAN loss = [2.2220752, 0.7808432, 0.80594325]\n",
      "Batch 431/700: Discriminator loss = 1.195059061050415, GAN loss = [2.2686653, 0.75695145, 0.87641954]\n",
      "Batch 432/700: Discriminator loss = 1.175398588180542, GAN loss = [2.274411, 0.7632876, 0.87583625]\n",
      "Batch 433/700: Discriminator loss = 1.1520782709121704, GAN loss = [2.3041835, 0.7898672, 0.87902796]\n",
      "Batch 434/700: Discriminator loss = 1.180212378501892, GAN loss = [2.2388012, 0.7652455, 0.83827233]\n",
      "Batch 435/700: Discriminator loss = 1.1647359132766724, GAN loss = [2.2789252, 0.7841715, 0.8595035]\n",
      "Batch 436/700: Discriminator loss = 1.1384549140930176, GAN loss = [2.288348, 0.8023619, 0.8507571]\n",
      "Batch 437/700: Discriminator loss = 1.1796882152557373, GAN loss = [2.2085986, 0.7562728, 0.8171133]\n",
      "Batch 438/700: Discriminator loss = 1.1790337562561035, GAN loss = [2.308045, 0.76513404, 0.907717]\n",
      "Batch 439/700: Discriminator loss = 1.1734631061553955, GAN loss = [2.2777257, 0.78395385, 0.8586017]\n",
      "Batch 440/700: Discriminator loss = 1.154294490814209, GAN loss = [2.283205, 0.7779745, 0.87010634]\n",
      "Batch 441/700: Discriminator loss = 1.1676301956176758, GAN loss = [2.3022594, 0.7767254, 0.89043075]\n",
      "Batch 442/700: Discriminator loss = 1.176883339881897, GAN loss = [2.298299, 0.7664883, 0.8967206]\n",
      "Batch 443/700: Discriminator loss = 1.1529253721237183, GAN loss = [2.265216, 0.78739387, 0.8427483]\n",
      "Batch 444/700: Discriminator loss = 1.1668474674224854, GAN loss = [2.279805, 0.7672203, 0.8775145]\n",
      "Batch 445/700: Discriminator loss = 1.1483886241912842, GAN loss = [2.2877553, 0.79490644, 0.857791]\n",
      "Batch 446/700: Discriminator loss = 1.155437707901001, GAN loss = [2.3103302, 0.7821018, 0.8931741]\n",
      "Batch 447/700: Discriminator loss = 1.16351318359375, GAN loss = [2.2905433, 0.7705225, 0.884998]\n",
      "Batch 448/700: Discriminator loss = 1.158142328262329, GAN loss = [2.2863386, 0.776166, 0.8751689]\n",
      "Batch 449/700: Discriminator loss = 1.163756251335144, GAN loss = [2.341279, 0.77120185, 0.9351019]\n",
      "Batch 450/700: Discriminator loss = 1.1740728616714478, GAN loss = [2.343469, 0.77180177, 0.93673027]\n",
      "Batch 451/700: Discriminator loss = 1.172971487045288, GAN loss = [2.2886796, 0.76649415, 0.8872684]\n",
      "Batch 452/700: Discriminator loss = 1.1808934211730957, GAN loss = [2.348516, 0.75955445, 0.9540537]\n",
      "Batch 453/700: Discriminator loss = 1.1872450113296509, GAN loss = [2.281749, 0.75155103, 0.8952991]\n",
      "Batch 454/700: Discriminator loss = 1.177669644355774, GAN loss = [2.2686055, 0.76444936, 0.8692715]\n",
      "Batch 455/700: Discriminator loss = 1.1903226375579834, GAN loss = [2.2497733, 0.75536484, 0.85953486]\n",
      "Batch 456/700: Discriminator loss = 1.205161213874817, GAN loss = [2.2494833, 0.748721, 0.86590517]\n",
      "Batch 457/700: Discriminator loss = 1.1877217292785645, GAN loss = [2.282553, 0.7593466, 0.8883715]\n",
      "Batch 458/700: Discriminator loss = 1.1938573122024536, GAN loss = [2.2734675, 0.75051683, 0.8881365]\n",
      "Batch 459/700: Discriminator loss = 1.2039299011230469, GAN loss = [2.282873, 0.7322615, 0.91583514]\n",
      "Batch 460/700: Discriminator loss = 1.2014501094818115, GAN loss = [2.2657847, 0.74217206, 0.888864]\n",
      "Batch 461/700: Discriminator loss = 1.216741681098938, GAN loss = [2.2183928, 0.7293758, 0.8542761]\n",
      "Batch 462/700: Discriminator loss = 1.2226349115371704, GAN loss = [2.248914, 0.7284938, 0.8856906]\n",
      "Batch 463/700: Discriminator loss = 1.2036398649215698, GAN loss = [2.3270762, 0.7301634, 0.96219414]\n",
      "Batch 464/700: Discriminator loss = 1.219151258468628, GAN loss = [2.225789, 0.72704977, 0.86402726]\n",
      "Batch 465/700: Discriminator loss = 1.2305079698562622, GAN loss = [2.186616, 0.731123, 0.8208075]\n",
      "Batch 466/700: Discriminator loss = 1.205222249031067, GAN loss = [2.1957674, 0.7378919, 0.82321954]\n",
      "Batch 467/700: Discriminator loss = 1.2225435972213745, GAN loss = [2.2001343, 0.7180053, 0.8475309]\n",
      "Batch 468/700: Discriminator loss = 1.208190679550171, GAN loss = [2.2134182, 0.74363184, 0.83522844]\n",
      "Batch 469/700: Discriminator loss = 1.2252569198608398, GAN loss = [2.2665277, 0.73508584, 0.8969395]\n",
      "Batch 470/700: Discriminator loss = 1.2225176095962524, GAN loss = [2.2006643, 0.7217051, 0.84450537]\n",
      "Batch 471/700: Discriminator loss = 1.2161675691604614, GAN loss = [2.1938305, 0.7133315, 0.8460746]\n",
      "Batch 472/700: Discriminator loss = 1.2369016408920288, GAN loss = [2.1825314, 0.7145134, 0.8336075]\n",
      "Batch 473/700: Discriminator loss = 1.2535336017608643, GAN loss = [2.200745, 0.70495105, 0.86140096]\n",
      "Batch 474/700: Discriminator loss = 1.2574489116668701, GAN loss = [2.1825292, 0.69444185, 0.8536961]\n",
      "Batch 475/700: Discriminator loss = 1.2374036312103271, GAN loss = [2.153804, 0.70337385, 0.81606776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 476/700: Discriminator loss = 1.259649395942688, GAN loss = [2.1385992, 0.6842417, 0.82002366]\n",
      "Batch 477/700: Discriminator loss = 1.2465109825134277, GAN loss = [2.1351256, 0.6963291, 0.8044793]\n",
      "Batch 478/700: Discriminator loss = 1.2659412622451782, GAN loss = [2.0910983, 0.676242, 0.7805435]\n",
      "Batch 479/700: Discriminator loss = 1.2593042850494385, GAN loss = [2.0976455, 0.6851328, 0.7782251]\n",
      "Batch 480/700: Discriminator loss = 1.2428100109100342, GAN loss = [2.1602647, 0.70709604, 0.8188872]\n",
      "Batch 481/700: Discriminator loss = 1.2540770769119263, GAN loss = [2.1334608, 0.70802987, 0.79115903]\n",
      "Batch 482/700: Discriminator loss = 1.2858835458755493, GAN loss = [2.0759115, 0.6813463, 0.7603144]\n",
      "Batch 483/700: Discriminator loss = 1.2583180665969849, GAN loss = [2.1051028, 0.69553953, 0.775328]\n",
      "Batch 484/700: Discriminator loss = 1.2435561418533325, GAN loss = [2.0723069, 0.6947796, 0.7432972]\n",
      "Batch 485/700: Discriminator loss = 1.2373287677764893, GAN loss = [2.11919, 0.7010666, 0.78390914]\n",
      "Batch 486/700: Discriminator loss = 1.2433042526245117, GAN loss = [2.1425107, 0.6957238, 0.81258684]\n",
      "Batch 487/700: Discriminator loss = 1.243866205215454, GAN loss = [2.1182382, 0.69769096, 0.7863597]\n",
      "Batch 488/700: Discriminator loss = 1.2418849468231201, GAN loss = [2.16865, 0.7159181, 0.8185428]\n",
      "Batch 489/700: Discriminator loss = 1.2311075925827026, GAN loss = [2.14355, 0.7118019, 0.797554]\n",
      "Batch 490/700: Discriminator loss = 1.2251847982406616, GAN loss = [2.138246, 0.7114655, 0.7925916]\n",
      "Batch 491/700: Discriminator loss = 1.2336928844451904, GAN loss = [2.1417577, 0.7057734, 0.8018045]\n",
      "Batch 492/700: Discriminator loss = 1.2021276950836182, GAN loss = [2.135884, 0.73109, 0.7706207]\n",
      "Batch 493/700: Discriminator loss = 1.2081139087677002, GAN loss = [2.1653457, 0.71517736, 0.81601363]\n",
      "Batch 494/700: Discriminator loss = 1.228319525718689, GAN loss = [2.124841, 0.71226114, 0.7784408]\n",
      "Batch 495/700: Discriminator loss = 1.217743992805481, GAN loss = [2.134724, 0.7219734, 0.7786241]\n",
      "Batch 496/700: Discriminator loss = 1.2030583620071411, GAN loss = [2.1470225, 0.726983, 0.7859154]\n",
      "Batch 497/700: Discriminator loss = 1.2198518514633179, GAN loss = [2.128636, 0.7062958, 0.78822726]\n",
      "Batch 498/700: Discriminator loss = 1.2020559310913086, GAN loss = [2.17167, 0.7179655, 0.81959176]\n",
      "Batch 499/700: Discriminator loss = 1.230326533317566, GAN loss = [2.1313977, 0.69337493, 0.8039294]\n",
      "Batch 500/700: Discriminator loss = 1.2300106287002563, GAN loss = [2.1766284, 0.6982885, 0.84427804]\n",
      "Batch 501/700: Discriminator loss = 1.2322368621826172, GAN loss = [2.130403, 0.6938894, 0.8024902]\n",
      "Batch 502/700: Discriminator loss = 1.2199907302856445, GAN loss = [2.1642478, 0.71197295, 0.8182759]\n",
      "Batch 503/700: Discriminator loss = 1.2058794498443604, GAN loss = [2.1900783, 0.71508676, 0.84102064]\n",
      "Batch 504/700: Discriminator loss = 1.2283402681350708, GAN loss = [2.1256063, 0.7030092, 0.7886661]\n",
      "Batch 505/700: Discriminator loss = 1.210231900215149, GAN loss = [2.1763504, 0.7145153, 0.82794046]\n",
      "Batch 506/700: Discriminator loss = 1.2148330211639404, GAN loss = [2.1671612, 0.70649165, 0.82679534]\n",
      "Batch 507/700: Discriminator loss = 1.2018320560455322, GAN loss = [2.1484127, 0.7322417, 0.7823235]\n",
      "Batch 508/700: Discriminator loss = 1.2084192037582397, GAN loss = [2.1960378, 0.7162539, 0.8459694]\n",
      "Batch 509/700: Discriminator loss = 1.194739818572998, GAN loss = [2.160682, 0.7292017, 0.79768366]\n",
      "Batch 510/700: Discriminator loss = 1.2082748413085938, GAN loss = [2.1667426, 0.7192723, 0.81370324]\n",
      "Batch 511/700: Discriminator loss = 1.2127240896224976, GAN loss = [2.1596773, 0.7286151, 0.79731673]\n",
      "Batch 512/700: Discriminator loss = 1.184715986251831, GAN loss = [2.2211602, 0.7536731, 0.8337585]\n",
      "Batch 513/700: Discriminator loss = 1.2105854749679565, GAN loss = [2.211681, 0.7431554, 0.8348144]\n",
      "Batch 514/700: Discriminator loss = 1.216179609298706, GAN loss = [2.1256227, 0.7237974, 0.76815665]\n",
      "Batch 515/700: Discriminator loss = 1.1943175792694092, GAN loss = [2.1689758, 0.7383687, 0.79698515]\n",
      "Batch 516/700: Discriminator loss = 1.194589614868164, GAN loss = [2.1913874, 0.7439506, 0.81386673]\n",
      "Batch 517/700: Discriminator loss = 1.180023193359375, GAN loss = [2.2058291, 0.7579821, 0.81431586]\n",
      "Batch 518/700: Discriminator loss = 1.1668275594711304, GAN loss = [2.2330666, 0.7662771, 0.833292]\n",
      "Batch 519/700: Discriminator loss = 1.198403000831604, GAN loss = [2.1982262, 0.74322104, 0.8215281]\n",
      "Batch 520/700: Discriminator loss = 1.1769014596939087, GAN loss = [2.2202275, 0.7629947, 0.823785]\n",
      "Batch 521/700: Discriminator loss = 1.185420274734497, GAN loss = [2.1984, 0.7631266, 0.80185074]\n",
      "Batch 522/700: Discriminator loss = 1.1737418174743652, GAN loss = [2.2675574, 0.7696005, 0.86455464]\n",
      "Batch 523/700: Discriminator loss = 1.177863359451294, GAN loss = [2.1776552, 0.76251584, 0.78178716]\n",
      "Batch 524/700: Discriminator loss = 1.173718810081482, GAN loss = [2.245913, 0.76764303, 0.84495956]\n",
      "Batch 525/700: Discriminator loss = 1.180691123008728, GAN loss = [2.1898966, 0.75360006, 0.80303377]\n",
      "Batch 526/700: Discriminator loss = 1.1871013641357422, GAN loss = [2.198617, 0.7523047, 0.8130937]\n",
      "Batch 527/700: Discriminator loss = 1.1809477806091309, GAN loss = [2.1828291, 0.74407387, 0.8055558]\n",
      "Batch 528/700: Discriminator loss = 1.170607566833496, GAN loss = [2.216681, 0.7538954, 0.82960963]\n",
      "Batch 529/700: Discriminator loss = 1.1845709085464478, GAN loss = [2.1984653, 0.7507513, 0.8145558]\n",
      "Batch 530/700: Discriminator loss = 1.175085425376892, GAN loss = [2.2145789, 0.7561273, 0.8253187]\n",
      "Batch 531/700: Discriminator loss = 1.1961731910705566, GAN loss = [2.1999953, 0.73175424, 0.8351229]\n",
      "Batch 532/700: Discriminator loss = 1.192088007926941, GAN loss = [2.284054, 0.7466677, 0.90428835]\n",
      "Batch 533/700: Discriminator loss = 1.2004027366638184, GAN loss = [2.1852276, 0.7326796, 0.8194757]\n",
      "Batch 534/700: Discriminator loss = 1.2006499767303467, GAN loss = [2.201629, 0.73817575, 0.8304195]\n",
      "Batch 535/700: Discriminator loss = 1.2188022136688232, GAN loss = [2.2356594, 0.7393041, 0.86336]\n",
      "Batch 536/700: Discriminator loss = 1.1980448961257935, GAN loss = [2.1629, 0.73359764, 0.7963321]\n",
      "Batch 537/700: Discriminator loss = 1.1749260425567627, GAN loss = [2.2274938, 0.75876206, 0.8357639]\n",
      "Batch 538/700: Discriminator loss = 1.190466284751892, GAN loss = [2.1988082, 0.7562134, 0.8096414]\n",
      "Batch 539/700: Discriminator loss = 1.196298599243164, GAN loss = [2.2065525, 0.74460685, 0.8289977]\n",
      "Batch 540/700: Discriminator loss = 1.2139283418655396, GAN loss = [2.1784992, 0.74031967, 0.80526805]\n",
      "Batch 541/700: Discriminator loss = 1.1850063800811768, GAN loss = [2.2235332, 0.74625075, 0.84439987]\n",
      "Batch 542/700: Discriminator loss = 1.1927030086517334, GAN loss = [2.182993, 0.74943155, 0.8007014]\n",
      "Batch 543/700: Discriminator loss = 1.206910252571106, GAN loss = [2.1823258, 0.73879486, 0.81067336]\n",
      "Batch 544/700: Discriminator loss = 1.2062842845916748, GAN loss = [2.199828, 0.75056785, 0.8164092]\n",
      "Batch 545/700: Discriminator loss = 1.172395944595337, GAN loss = [2.2281733, 0.77150023, 0.82383513]\n",
      "Batch 546/700: Discriminator loss = 1.1947726011276245, GAN loss = [2.1922903, 0.7462346, 0.8132079]\n",
      "Batch 547/700: Discriminator loss = 1.2140194177627563, GAN loss = [2.143074, 0.71495676, 0.7952636]\n",
      "Batch 548/700: Discriminator loss = 1.2238736152648926, GAN loss = [2.1785214, 0.72771645, 0.81796545]\n",
      "Batch 549/700: Discriminator loss = 1.1846683025360107, GAN loss = [2.2357388, 0.75477326, 0.84810936]\n",
      "Batch 550/700: Discriminator loss = 1.203477144241333, GAN loss = [2.2244163, 0.74721634, 0.8443028]\n",
      "Batch 551/700: Discriminator loss = 1.2042335271835327, GAN loss = [2.1690207, 0.74224997, 0.793845]\n",
      "Batch 552/700: Discriminator loss = 1.2116304636001587, GAN loss = [2.2075837, 0.737262, 0.83737504]\n",
      "Batch 553/700: Discriminator loss = 1.2126833200454712, GAN loss = [2.1836102, 0.7439367, 0.80672073]\n",
      "Batch 554/700: Discriminator loss = 1.1783947944641113, GAN loss = [2.1947799, 0.76084185, 0.80097336]\n",
      "Batch 555/700: Discriminator loss = 1.2106099128723145, GAN loss = [2.1733725, 0.7301932, 0.8102106]\n",
      "Batch 556/700: Discriminator loss = 1.2283852100372314, GAN loss = [2.1203883, 0.7190408, 0.76835465]\n",
      "Batch 557/700: Discriminator loss = 1.241302728652954, GAN loss = [2.1451206, 0.7030534, 0.8090398]\n",
      "Batch 558/700: Discriminator loss = 1.2289044857025146, GAN loss = [2.1640205, 0.7126092, 0.81835914]\n",
      "Batch 559/700: Discriminator loss = 1.2076680660247803, GAN loss = [2.2295275, 0.75803787, 0.8384049]\n",
      "Batch 560/700: Discriminator loss = 1.2232353687286377, GAN loss = [2.1638906, 0.73060006, 0.8001673]\n",
      "Batch 561/700: Discriminator loss = 1.2084360122680664, GAN loss = [2.1786253, 0.7373, 0.80817634]\n",
      "Batch 562/700: Discriminator loss = 1.2000548839569092, GAN loss = [2.2261956, 0.74894875, 0.8441095]\n",
      "Batch 563/700: Discriminator loss = 1.2288979291915894, GAN loss = [2.1592715, 0.7216916, 0.8044512]\n",
      "Batch 564/700: Discriminator loss = 1.2400246858596802, GAN loss = [2.1084912, 0.70885575, 0.76651293]\n",
      "Batch 565/700: Discriminator loss = 1.1851203441619873, GAN loss = [2.1984894, 0.75801134, 0.8073787]\n",
      "Batch 566/700: Discriminator loss = 1.211694598197937, GAN loss = [2.1799147, 0.73905075, 0.80777]\n",
      "Batch 567/700: Discriminator loss = 1.2031203508377075, GAN loss = [2.1657763, 0.73237175, 0.8003327]\n",
      "Batch 568/700: Discriminator loss = 1.2148584127426147, GAN loss = [2.1955044, 0.72708464, 0.8353511]\n",
      "Batch 569/700: Discriminator loss = 1.2222723960876465, GAN loss = [2.1569834, 0.7217777, 0.8021493]\n",
      "Batch 570/700: Discriminator loss = 1.215155005455017, GAN loss = [2.1921306, 0.7367895, 0.8222976]\n",
      "Batch 571/700: Discriminator loss = 1.200864315032959, GAN loss = [2.1824634, 0.73355216, 0.81588256]\n",
      "Batch 572/700: Discriminator loss = 1.19472336769104, GAN loss = [2.2018626, 0.7343892, 0.8344778]\n",
      "Batch 573/700: Discriminator loss = 1.1966010332107544, GAN loss = [2.1827948, 0.732144, 0.8176879]\n",
      "Batch 574/700: Discriminator loss = 1.1894110441207886, GAN loss = [2.2127576, 0.76306367, 0.8167443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 575/700: Discriminator loss = 1.1672780513763428, GAN loss = [2.2873914, 0.7650473, 0.88940287]\n",
      "Batch 576/700: Discriminator loss = 1.1928027868270874, GAN loss = [2.1932774, 0.7604694, 0.79988146]\n",
      "Batch 577/700: Discriminator loss = 1.1906849145889282, GAN loss = [2.189542, 0.74664056, 0.81000733]\n",
      "Batch 578/700: Discriminator loss = 1.1708223819732666, GAN loss = [2.2420228, 0.77720284, 0.83195657]\n",
      "Batch 579/700: Discriminator loss = 1.1707807779312134, GAN loss = [2.2404118, 0.76533663, 0.842244]\n",
      "Batch 580/700: Discriminator loss = 1.1868500709533691, GAN loss = [2.1601083, 0.7326113, 0.79467225]\n",
      "Batch 581/700: Discriminator loss = 1.1706207990646362, GAN loss = [2.2687924, 0.774655, 0.861338]\n",
      "Batch 582/700: Discriminator loss = 1.1717185974121094, GAN loss = [2.2201498, 0.76036775, 0.82700646]\n",
      "Batch 583/700: Discriminator loss = 1.1569257974624634, GAN loss = [2.2578351, 0.7863161, 0.8387672]\n",
      "Batch 584/700: Discriminator loss = 1.201675534248352, GAN loss = [2.1979551, 0.72613126, 0.83909655]\n",
      "Batch 585/700: Discriminator loss = 1.2139860391616821, GAN loss = [2.197823, 0.72251624, 0.84259504]\n",
      "Batch 586/700: Discriminator loss = 1.1990952491760254, GAN loss = [2.2388644, 0.73588747, 0.8702864]\n",
      "Batch 587/700: Discriminator loss = 1.175093173980713, GAN loss = [2.2504513, 0.7729381, 0.844838]\n",
      "Batch 588/700: Discriminator loss = 1.1986284255981445, GAN loss = [2.2176082, 0.7298099, 0.8551435]\n",
      "Batch 589/700: Discriminator loss = 1.2115367650985718, GAN loss = [2.239107, 0.72675467, 0.87971616]\n",
      "Batch 590/700: Discriminator loss = 1.195404291152954, GAN loss = [2.2594373, 0.7451151, 0.88172454]\n",
      "Batch 591/700: Discriminator loss = 1.1749030351638794, GAN loss = [2.2330642, 0.7619643, 0.83853316]\n",
      "Batch 592/700: Discriminator loss = 1.2020882368087769, GAN loss = [2.2226472, 0.7358918, 0.85421103]\n",
      "Batch 593/700: Discriminator loss = 1.2208243608474731, GAN loss = [2.218475, 0.72010475, 0.86586654]\n",
      "Batch 594/700: Discriminator loss = 1.1917575597763062, GAN loss = [2.190616, 0.73703694, 0.821095]\n",
      "Batch 595/700: Discriminator loss = 1.2151591777801514, GAN loss = [2.2560172, 0.7241029, 0.89946115]\n",
      "Batch 596/700: Discriminator loss = 1.20868980884552, GAN loss = [2.2365015, 0.7322124, 0.8718377]\n",
      "Batch 597/700: Discriminator loss = 1.2238876819610596, GAN loss = [2.233661, 0.7179465, 0.8832804]\n",
      "Batch 598/700: Discriminator loss = 1.2074075937271118, GAN loss = [2.196464, 0.7425974, 0.8214324]\n",
      "Batch 599/700: Discriminator loss = 1.2359286546707153, GAN loss = [2.1585708, 0.71909297, 0.8070337]\n",
      "Batch 600/700: Discriminator loss = 1.2559229135513306, GAN loss = [2.1965082, 0.6993489, 0.8647174]\n",
      "Batch 601/700: Discriminator loss = 1.2150664329528809, GAN loss = [2.1674922, 0.72478503, 0.81028444]\n",
      "Batch 602/700: Discriminator loss = 1.2213623523712158, GAN loss = [2.1387074, 0.7178909, 0.78840256]\n",
      "Batch 603/700: Discriminator loss = 1.231701135635376, GAN loss = [2.161048, 0.7425222, 0.7861206]\n",
      "Batch 604/700: Discriminator loss = 1.2309035062789917, GAN loss = [2.1482491, 0.738302, 0.7775566]\n",
      "Batch 605/700: Discriminator loss = 1.2023353576660156, GAN loss = [2.2404022, 0.74857974, 0.8594494]\n",
      "Batch 606/700: Discriminator loss = 1.2147843837738037, GAN loss = [2.2147574, 0.73446244, 0.84791946]\n",
      "Batch 607/700: Discriminator loss = 1.2183489799499512, GAN loss = [2.195757, 0.7258263, 0.837555]\n",
      "Batch 608/700: Discriminator loss = 1.214963674545288, GAN loss = [2.1525502, 0.7396164, 0.780563]\n",
      "Batch 609/700: Discriminator loss = 1.2132171392440796, GAN loss = [2.1624703, 0.73853165, 0.7915863]\n",
      "Batch 610/700: Discriminator loss = 1.2176631689071655, GAN loss = [2.196807, 0.7434959, 0.8209641]\n",
      "Batch 611/700: Discriminator loss = 1.240661382675171, GAN loss = [2.1942847, 0.7321791, 0.82975113]\n",
      "Batch 612/700: Discriminator loss = 1.2235509157180786, GAN loss = [2.2243125, 0.7343848, 0.85758287]\n",
      "Batch 613/700: Discriminator loss = 1.237952470779419, GAN loss = [2.171099, 0.71282685, 0.82593215]\n",
      "Batch 614/700: Discriminator loss = 1.2436634302139282, GAN loss = [2.1556375, 0.71335566, 0.8099507]\n",
      "Batch 615/700: Discriminator loss = 1.2053847312927246, GAN loss = [2.2310266, 0.7535861, 0.84512734]\n",
      "Batch 616/700: Discriminator loss = 1.224704384803772, GAN loss = [2.2136672, 0.73633176, 0.84502965]\n",
      "Batch 617/700: Discriminator loss = 1.2037765979766846, GAN loss = [2.2080595, 0.74014086, 0.8356129]\n",
      "Batch 618/700: Discriminator loss = 1.2428816556930542, GAN loss = [2.1635563, 0.7155133, 0.8157362]\n",
      "Batch 619/700: Discriminator loss = 1.2347112894058228, GAN loss = [2.159719, 0.7283222, 0.79909724]\n",
      "Batch 620/700: Discriminator loss = 1.2461340427398682, GAN loss = [2.1780057, 0.7267266, 0.8189749]\n",
      "Batch 621/700: Discriminator loss = 1.2406383752822876, GAN loss = [2.1410117, 0.7119458, 0.7967689]\n",
      "Batch 622/700: Discriminator loss = 1.219505786895752, GAN loss = [2.1782897, 0.72195035, 0.8240433]\n",
      "Batch 623/700: Discriminator loss = 1.2120181322097778, GAN loss = [2.2094872, 0.7574155, 0.8197665]\n",
      "Batch 624/700: Discriminator loss = 1.2137999534606934, GAN loss = [2.232467, 0.74312043, 0.85702676]\n",
      "Batch 625/700: Discriminator loss = 1.2276531457901, GAN loss = [2.184582, 0.72305834, 0.8291863]\n",
      "Batch 626/700: Discriminator loss = 1.2235900163650513, GAN loss = [2.1734004, 0.72492963, 0.8161651]\n",
      "Batch 627/700: Discriminator loss = 1.183130145072937, GAN loss = [2.2132332, 0.7629998, 0.8179552]\n",
      "Batch 628/700: Discriminator loss = 1.1921367645263672, GAN loss = [2.2226892, 0.75509214, 0.83534324]\n",
      "Batch 629/700: Discriminator loss = 1.193056344985962, GAN loss = [2.2499528, 0.75575906, 0.86193895]\n",
      "Batch 630/700: Discriminator loss = 1.2349753379821777, GAN loss = [2.1717238, 0.71956044, 0.8199291]\n",
      "Batch 631/700: Discriminator loss = 1.1785776615142822, GAN loss = [2.2466958, 0.7638214, 0.8506558]\n",
      "Batch 632/700: Discriminator loss = 1.207703948020935, GAN loss = [2.1865366, 0.7459415, 0.80839926]\n",
      "Batch 633/700: Discriminator loss = 1.184279441833496, GAN loss = [2.1971745, 0.75380576, 0.8111969]\n",
      "Batch 634/700: Discriminator loss = 1.1790379285812378, GAN loss = [2.2545428, 0.7751768, 0.84722465]\n",
      "Batch 635/700: Discriminator loss = 1.1946412324905396, GAN loss = [2.1982808, 0.74811816, 0.8180537]\n",
      "Batch 636/700: Discriminator loss = 1.1801594495773315, GAN loss = [2.2513173, 0.7599318, 0.8593023]\n",
      "Batch 637/700: Discriminator loss = 1.1715242862701416, GAN loss = [2.2403808, 0.7854017, 0.8229063]\n",
      "Batch 638/700: Discriminator loss = 1.1602272987365723, GAN loss = [2.2558854, 0.78172284, 0.8421141]\n",
      "Batch 639/700: Discriminator loss = 1.1614024639129639, GAN loss = [2.2095037, 0.77535146, 0.80212045]\n",
      "Batch 640/700: Discriminator loss = 1.181020975112915, GAN loss = [2.2725265, 0.7865122, 0.8540074]\n",
      "Batch 641/700: Discriminator loss = 1.1640686988830566, GAN loss = [2.292747, 0.7851545, 0.8756133]\n",
      "Batch 642/700: Discriminator loss = 1.1411347389221191, GAN loss = [2.2764826, 0.80240524, 0.8421323]\n",
      "Batch 643/700: Discriminator loss = 1.1757433414459229, GAN loss = [2.278141, 0.7693068, 0.87693536]\n",
      "Batch 644/700: Discriminator loss = 1.1852381229400635, GAN loss = [2.2738643, 0.77011526, 0.8719054]\n",
      "Batch 645/700: Discriminator loss = 1.1495813131332397, GAN loss = [2.322763, 0.800538, 0.8904469]\n",
      "Batch 646/700: Discriminator loss = 1.1709240674972534, GAN loss = [2.248274, 0.7736535, 0.8428856]\n",
      "Batch 647/700: Discriminator loss = 1.1859396696090698, GAN loss = [2.2422214, 0.7526066, 0.8579297]\n",
      "Batch 648/700: Discriminator loss = 1.1970746517181396, GAN loss = [2.2290115, 0.74452174, 0.8528559]\n",
      "Batch 649/700: Discriminator loss = 1.201799750328064, GAN loss = [2.2288837, 0.75053567, 0.84675294]\n",
      "Batch 650/700: Discriminator loss = 1.2185404300689697, GAN loss = [2.1954622, 0.73008126, 0.8337997]\n",
      "Batch 651/700: Discriminator loss = 1.2335090637207031, GAN loss = [2.209636, 0.7266759, 0.8513879]\n",
      "Batch 652/700: Discriminator loss = 1.260888934135437, GAN loss = [2.1361504, 0.6956385, 0.80893534]\n",
      "Batch 653/700: Discriminator loss = 1.268729567527771, GAN loss = [2.1490965, 0.69099265, 0.82651156]\n",
      "Batch 654/700: Discriminator loss = 1.2932865619659424, GAN loss = [2.1544254, 0.69487, 0.82793885]\n",
      "Batch 655/700: Discriminator loss = 1.25502610206604, GAN loss = [2.1704545, 0.7239199, 0.8148714]\n",
      "Batch 656/700: Discriminator loss = 1.2623718976974487, GAN loss = [2.1565018, 0.7156759, 0.8091194]\n",
      "Batch 657/700: Discriminator loss = 1.2070298194885254, GAN loss = [2.2263927, 0.771992, 0.82269406]\n",
      "Batch 658/700: Discriminator loss = 1.2666064500808716, GAN loss = [2.133251, 0.70725524, 0.7942922]\n",
      "Batch 659/700: Discriminator loss = 1.2339839935302734, GAN loss = [2.154638, 0.7329552, 0.78999716]\n",
      "Batch 660/700: Discriminator loss = 1.2169935703277588, GAN loss = [2.148309, 0.7406549, 0.7759971]\n",
      "Batch 661/700: Discriminator loss = 1.221790075302124, GAN loss = [2.2025244, 0.7454619, 0.82542807]\n",
      "Batch 662/700: Discriminator loss = 1.1887558698654175, GAN loss = [2.2305293, 0.7769009, 0.82200974]\n",
      "Batch 663/700: Discriminator loss = 1.1888891458511353, GAN loss = [2.2015545, 0.7647201, 0.80523974]\n",
      "Batch 664/700: Discriminator loss = 1.1800647974014282, GAN loss = [2.2306058, 0.7806841, 0.81836146]\n",
      "Batch 665/700: Discriminator loss = 1.2041208744049072, GAN loss = [2.2061024, 0.75095534, 0.8236482]\n",
      "Batch 666/700: Discriminator loss = 1.1658589839935303, GAN loss = [2.290564, 0.78920776, 0.86991835]\n",
      "Batch 667/700: Discriminator loss = 1.175157904624939, GAN loss = [2.2077708, 0.7699565, 0.8064336]\n",
      "Batch 668/700: Discriminator loss = 1.1871873140335083, GAN loss = [2.25605, 0.7614741, 0.8632444]\n",
      "Batch 669/700: Discriminator loss = 1.176009178161621, GAN loss = [2.2407038, 0.7684063, 0.8410374]\n",
      "Batch 670/700: Discriminator loss = 1.1659125089645386, GAN loss = [2.2382708, 0.7796173, 0.82746434]\n",
      "Batch 671/700: Discriminator loss = 1.168415904045105, GAN loss = [2.2491426, 0.7943793, 0.82362765]\n",
      "Batch 672/700: Discriminator loss = 1.1903698444366455, GAN loss = [2.2299738, 0.7536609, 0.84525144]\n",
      "Batch 673/700: Discriminator loss = 1.1858773231506348, GAN loss = [2.2669868, 0.7726831, 0.8633058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 674/700: Discriminator loss = 1.1778051853179932, GAN loss = [2.2860734, 0.791075, 0.86404127]\n",
      "Batch 675/700: Discriminator loss = 1.1827352046966553, GAN loss = [2.2485693, 0.7767084, 0.84096074]\n",
      "Batch 676/700: Discriminator loss = 1.2007925510406494, GAN loss = [2.2063134, 0.7440259, 0.83144224]\n",
      "Batch 677/700: Discriminator loss = 1.1845861673355103, GAN loss = [2.1911323, 0.7689005, 0.7914479]\n",
      "Batch 678/700: Discriminator loss = 1.1902216672897339, GAN loss = [2.199888, 0.74198586, 0.82716703]\n",
      "Batch 679/700: Discriminator loss = 1.2008534669876099, GAN loss = [2.2009254, 0.7480777, 0.8221506]\n",
      "Batch 680/700: Discriminator loss = 1.2046483755111694, GAN loss = [2.1929548, 0.74007916, 0.8222006]\n",
      "Batch 681/700: Discriminator loss = 1.2309505939483643, GAN loss = [2.205383, 0.7337345, 0.8410037]\n",
      "Batch 682/700: Discriminator loss = 1.1891093254089355, GAN loss = [2.1602974, 0.74861723, 0.78105795]\n",
      "Batch 683/700: Discriminator loss = 1.193545937538147, GAN loss = [2.211814, 0.7613411, 0.81989515]\n",
      "Batch 684/700: Discriminator loss = 1.1733261346817017, GAN loss = [2.2191777, 0.76195055, 0.82668686]\n",
      "Batch 685/700: Discriminator loss = 1.192137360572815, GAN loss = [2.2084358, 0.76572806, 0.8122019]\n",
      "Batch 686/700: Discriminator loss = 1.1643784046173096, GAN loss = [2.1872149, 0.7736925, 0.7830417]\n",
      "Batch 687/700: Discriminator loss = 1.208418846130371, GAN loss = [2.1927004, 0.7369204, 0.8253327]\n",
      "Batch 688/700: Discriminator loss = 1.1812087297439575, GAN loss = [2.1752203, 0.751042, 0.79376024]\n",
      "Batch 689/700: Discriminator loss = 1.185477375984192, GAN loss = [2.1872547, 0.750157, 0.80671996]\n",
      "Batch 690/700: Discriminator loss = 1.1829673051834106, GAN loss = [2.193243, 0.7477905, 0.8151197]\n",
      "Batch 691/700: Discriminator loss = 1.1713601350784302, GAN loss = [2.2247531, 0.7504071, 0.84405893]\n",
      "Batch 692/700: Discriminator loss = 1.2010412216186523, GAN loss = [2.171955, 0.7330919, 0.8086277]\n",
      "Batch 693/700: Discriminator loss = 1.1730588674545288, GAN loss = [2.199727, 0.76513666, 0.80440253]\n",
      "Batch 694/700: Discriminator loss = 1.1755287647247314, GAN loss = [2.2091238, 0.75740737, 0.82159925]\n",
      "Batch 695/700: Discriminator loss = 1.1743545532226562, GAN loss = [2.211881, 0.753793, 0.8280359]\n",
      "Batch 696/700: Discriminator loss = 1.159320592880249, GAN loss = [2.2113695, 0.76774514, 0.8136291]\n",
      "Batch 697/700: Discriminator loss = 1.1677422523498535, GAN loss = [2.1761472, 0.74632215, 0.7998768]\n",
      "Batch 698/700: Discriminator loss = 1.1903828382492065, GAN loss = [2.1914442, 0.74521726, 0.81633085]\n",
      "Batch 699/700: Discriminator loss = 1.196807622909546, GAN loss = [2.1952744, 0.7312189, 0.83421403]\n",
      "Batch 700/700: Discriminator loss = 1.161826491355896, GAN loss = [2.2308476, 0.76440775, 0.8366385]\n",
      "Epoch 22/30\n",
      "Batch 1/700: Discriminator loss = 1.1844755411148071, GAN loss = [2.191809, 0.74121076, 0.82083136]\n",
      "Batch 2/700: Discriminator loss = 1.1876587867736816, GAN loss = [2.2101154, 0.7406726, 0.83971626]\n",
      "Batch 3/700: Discriminator loss = 1.162255883216858, GAN loss = [2.237942, 0.75938106, 0.8488811]\n",
      "Batch 4/700: Discriminator loss = 1.1954246759414673, GAN loss = [2.2222264, 0.74023193, 0.8523555]\n",
      "Batch 5/700: Discriminator loss = 1.1808478832244873, GAN loss = [2.2470367, 0.7416513, 0.8757894]\n",
      "Batch 6/700: Discriminator loss = 1.1718286275863647, GAN loss = [2.233014, 0.76296234, 0.84049636]\n",
      "Batch 7/700: Discriminator loss = 1.1903672218322754, GAN loss = [2.1786225, 0.7338905, 0.81519884]\n",
      "Batch 8/700: Discriminator loss = 1.1931864023208618, GAN loss = [2.1999145, 0.7357563, 0.83464575]\n",
      "Batch 9/700: Discriminator loss = 1.208917498588562, GAN loss = [2.1676092, 0.732153, 0.8059562]\n",
      "Batch 10/700: Discriminator loss = 1.196778416633606, GAN loss = [2.2195551, 0.7403336, 0.84974694]\n",
      "Batch 11/700: Discriminator loss = 1.1952567100524902, GAN loss = [2.1598036, 0.7351883, 0.79516447]\n",
      "Batch 12/700: Discriminator loss = 1.190281867980957, GAN loss = [2.162923, 0.73017824, 0.80330664]\n",
      "Batch 13/700: Discriminator loss = 1.189436435699463, GAN loss = [2.1615872, 0.7326006, 0.79957205]\n",
      "Batch 14/700: Discriminator loss = 1.2015479803085327, GAN loss = [2.1786497, 0.7320007, 0.8172631]\n",
      "Batch 15/700: Discriminator loss = 1.2008073329925537, GAN loss = [2.196567, 0.73117715, 0.83603144]\n",
      "Batch 16/700: Discriminator loss = 1.181797742843628, GAN loss = [2.2233565, 0.75615126, 0.83787125]\n",
      "Batch 17/700: Discriminator loss = 1.1899542808532715, GAN loss = [2.201053, 0.7353335, 0.8363895]\n",
      "Batch 18/700: Discriminator loss = 1.2103931903839111, GAN loss = [2.158536, 0.7246039, 0.80462545]\n",
      "Batch 19/700: Discriminator loss = 1.2086255550384521, GAN loss = [2.1816256, 0.72903615, 0.823298]\n",
      "Batch 20/700: Discriminator loss = 1.2103835344314575, GAN loss = [2.168407, 0.71727896, 0.82184446]\n",
      "Batch 21/700: Discriminator loss = 1.2189536094665527, GAN loss = [2.1585283, 0.7063004, 0.82295793]\n",
      "Batch 22/700: Discriminator loss = 1.211595892906189, GAN loss = [2.1194232, 0.7297699, 0.76040053]\n",
      "Batch 23/700: Discriminator loss = 1.2022960186004639, GAN loss = [2.2080946, 0.7350769, 0.8437955]\n",
      "Batch 24/700: Discriminator loss = 1.1895906925201416, GAN loss = [2.1966, 0.7327537, 0.83464754]\n",
      "Batch 25/700: Discriminator loss = 1.1873409748077393, GAN loss = [2.2290316, 0.75461733, 0.84523284]\n",
      "Batch 26/700: Discriminator loss = 1.1977505683898926, GAN loss = [2.1940076, 0.7294473, 0.83539224]\n",
      "Batch 27/700: Discriminator loss = 1.1908105611801147, GAN loss = [2.1748312, 0.75136614, 0.7943028]\n",
      "Batch 28/700: Discriminator loss = 1.1895415782928467, GAN loss = [2.168782, 0.74552274, 0.79410136]\n",
      "Batch 29/700: Discriminator loss = 1.19096040725708, GAN loss = [2.2136233, 0.74698776, 0.83748245]\n",
      "Batch 30/700: Discriminator loss = 1.196352481842041, GAN loss = [2.1794715, 0.73635894, 0.8139562]\n",
      "Batch 31/700: Discriminator loss = 1.2079068422317505, GAN loss = [2.1851683, 0.731078, 0.82492906]\n",
      "Batch 32/700: Discriminator loss = 1.2093244791030884, GAN loss = [2.1660287, 0.7236701, 0.81320524]\n",
      "Batch 33/700: Discriminator loss = 1.1930967569351196, GAN loss = [2.2081904, 0.7409295, 0.83808917]\n",
      "Batch 34/700: Discriminator loss = 1.2069529294967651, GAN loss = [2.1732626, 0.7330397, 0.8110514]\n",
      "Batch 35/700: Discriminator loss = 1.189599633216858, GAN loss = [2.2194297, 0.7483442, 0.8419335]\n",
      "Batch 36/700: Discriminator loss = 1.2119086980819702, GAN loss = [2.1734912, 0.735208, 0.80912995]\n",
      "Batch 37/700: Discriminator loss = 1.1939641237258911, GAN loss = [2.244286, 0.7627624, 0.8523658]\n",
      "Batch 38/700: Discriminator loss = 1.191213607788086, GAN loss = [2.2433455, 0.7703836, 0.84379554]\n",
      "Batch 39/700: Discriminator loss = 1.1692984104156494, GAN loss = [2.2254095, 0.77598846, 0.82025576]\n",
      "Batch 40/700: Discriminator loss = 1.1822839975357056, GAN loss = [2.2206552, 0.7598604, 0.83166313]\n",
      "Batch 41/700: Discriminator loss = 1.1723181009292603, GAN loss = [2.2239554, 0.7706626, 0.8241779]\n",
      "Batch 42/700: Discriminator loss = 1.179344654083252, GAN loss = [2.2246692, 0.7650743, 0.8304639]\n",
      "Batch 43/700: Discriminator loss = 1.1941859722137451, GAN loss = [2.2343318, 0.7575405, 0.8476792]\n",
      "Batch 44/700: Discriminator loss = 1.1748311519622803, GAN loss = [2.2548442, 0.77764994, 0.8481116]\n",
      "Batch 45/700: Discriminator loss = 1.174007534980774, GAN loss = [2.2164357, 0.7682424, 0.81913126]\n",
      "Batch 46/700: Discriminator loss = 1.164857029914856, GAN loss = [2.2551713, 0.77731264, 0.8488274]\n",
      "Batch 47/700: Discriminator loss = 1.1883959770202637, GAN loss = [2.1941204, 0.75366956, 0.81144404]\n",
      "Batch 48/700: Discriminator loss = 1.174214243888855, GAN loss = [2.2189455, 0.76297927, 0.82699347]\n",
      "Batch 49/700: Discriminator loss = 1.1684261560440063, GAN loss = [2.2328324, 0.7548278, 0.84905136]\n",
      "Batch 50/700: Discriminator loss = 1.166488528251648, GAN loss = [2.2455904, 0.7678623, 0.8487823]\n",
      "Batch 51/700: Discriminator loss = 1.1902343034744263, GAN loss = [2.204436, 0.740834, 0.8346684]\n",
      "Batch 52/700: Discriminator loss = 1.18573796749115, GAN loss = [2.2183118, 0.7392003, 0.8501917]\n",
      "Batch 53/700: Discriminator loss = 1.188335657119751, GAN loss = [2.2236125, 0.7467687, 0.84795004]\n",
      "Batch 54/700: Discriminator loss = 1.1984264850616455, GAN loss = [2.2187223, 0.7328376, 0.857021]\n",
      "Batch 55/700: Discriminator loss = 1.2007756233215332, GAN loss = [2.2306755, 0.7375061, 0.864321]\n",
      "Batch 56/700: Discriminator loss = 1.2035274505615234, GAN loss = [2.1615489, 0.73024607, 0.8024794]\n",
      "Batch 57/700: Discriminator loss = 1.1839821338653564, GAN loss = [2.2107036, 0.74524003, 0.8366806]\n",
      "Batch 58/700: Discriminator loss = 1.1811000108718872, GAN loss = [2.2199233, 0.7426378, 0.84854543]\n",
      "Batch 59/700: Discriminator loss = 1.1917346715927124, GAN loss = [2.1598308, 0.7312709, 0.79985285]\n",
      "Batch 60/700: Discriminator loss = 1.1658326387405396, GAN loss = [2.2149615, 0.7575961, 0.82869256]\n",
      "Batch 61/700: Discriminator loss = 1.1842479705810547, GAN loss = [2.2311556, 0.74781877, 0.85469127]\n",
      "Batch 62/700: Discriminator loss = 1.189258337020874, GAN loss = [2.204148, 0.7390646, 0.836474]\n",
      "Batch 63/700: Discriminator loss = 1.1594542264938354, GAN loss = [2.2198193, 0.7540615, 0.8371832]\n",
      "Batch 64/700: Discriminator loss = 1.1920300722122192, GAN loss = [2.2307038, 0.741678, 0.8604849]\n",
      "Batch 65/700: Discriminator loss = 1.159232497215271, GAN loss = [2.2119071, 0.7526021, 0.8308178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 66/700: Discriminator loss = 1.1821433305740356, GAN loss = [2.208713, 0.7360248, 0.8442301]\n",
      "Batch 67/700: Discriminator loss = 1.1524230241775513, GAN loss = [2.2474914, 0.7643235, 0.8547278]\n",
      "Batch 68/700: Discriminator loss = 1.1668341159820557, GAN loss = [2.225483, 0.7548043, 0.8422633]\n",
      "Batch 69/700: Discriminator loss = 1.189480185508728, GAN loss = [2.1790705, 0.73570365, 0.8149871]\n",
      "Batch 70/700: Discriminator loss = 1.1926926374435425, GAN loss = [2.2070053, 0.730517, 0.848151]\n",
      "Batch 71/700: Discriminator loss = 1.1645139455795288, GAN loss = [2.2272282, 0.7524908, 0.84642404]\n",
      "Batch 72/700: Discriminator loss = 1.2017362117767334, GAN loss = [2.1504605, 0.72758085, 0.7945905]\n",
      "Batch 73/700: Discriminator loss = 1.2058312892913818, GAN loss = [2.2105076, 0.7260678, 0.856177]\n",
      "Batch 74/700: Discriminator loss = 1.1974393129348755, GAN loss = [2.193087, 0.72983956, 0.83501345]\n",
      "Batch 75/700: Discriminator loss = 1.1591871976852417, GAN loss = [2.2047956, 0.7527703, 0.82381624]\n",
      "Batch 76/700: Discriminator loss = 1.1821860074996948, GAN loss = [2.2133794, 0.7419445, 0.84324974]\n",
      "Batch 77/700: Discriminator loss = 1.1707850694656372, GAN loss = [2.2305431, 0.7490747, 0.85328466]\n",
      "Batch 78/700: Discriminator loss = 1.1812007427215576, GAN loss = [2.2269466, 0.755056, 0.8437167]\n",
      "Batch 79/700: Discriminator loss = 1.1789114475250244, GAN loss = [2.181837, 0.73946816, 0.8142145]\n",
      "Batch 80/700: Discriminator loss = 1.175618290901184, GAN loss = [2.202846, 0.7417684, 0.83295476]\n",
      "Batch 81/700: Discriminator loss = 1.1756186485290527, GAN loss = [2.1789148, 0.7355734, 0.8152419]\n",
      "Batch 82/700: Discriminator loss = 1.1794205904006958, GAN loss = [2.2456055, 0.73732394, 0.88021225]\n",
      "Batch 83/700: Discriminator loss = 1.1808160543441772, GAN loss = [2.1656435, 0.7301185, 0.80747277]\n",
      "Batch 84/700: Discriminator loss = 1.189041018486023, GAN loss = [2.1956587, 0.73558974, 0.8320286]\n",
      "Batch 85/700: Discriminator loss = 1.173646330833435, GAN loss = [2.1884472, 0.74216413, 0.8182495]\n",
      "Batch 86/700: Discriminator loss = 1.1860935688018799, GAN loss = [2.19543, 0.7345747, 0.8328196]\n",
      "Batch 87/700: Discriminator loss = 1.1848881244659424, GAN loss = [2.205561, 0.7307339, 0.8467919]\n",
      "Batch 88/700: Discriminator loss = 1.178786039352417, GAN loss = [2.1814158, 0.7329956, 0.8203855]\n",
      "Batch 89/700: Discriminator loss = 1.1980534791946411, GAN loss = [2.214452, 0.7313477, 0.85507417]\n",
      "Batch 90/700: Discriminator loss = 1.2112445831298828, GAN loss = [2.1429844, 0.69835925, 0.816598]\n",
      "Batch 91/700: Discriminator loss = 1.1880244016647339, GAN loss = [2.2277827, 0.7291676, 0.87060845]\n",
      "Batch 92/700: Discriminator loss = 1.1914331912994385, GAN loss = [2.2340527, 0.7343399, 0.8717017]\n",
      "Batch 93/700: Discriminator loss = 1.1886143684387207, GAN loss = [2.2017915, 0.72845054, 0.84529656]\n",
      "Batch 94/700: Discriminator loss = 1.215123176574707, GAN loss = [2.2260373, 0.70516944, 0.89279985]\n",
      "Batch 95/700: Discriminator loss = 1.1942760944366455, GAN loss = [2.1999786, 0.7253208, 0.84658486]\n",
      "Batch 96/700: Discriminator loss = 1.2101161479949951, GAN loss = [2.202585, 0.72802794, 0.8464914]\n",
      "Batch 97/700: Discriminator loss = 1.1963270902633667, GAN loss = [2.1669407, 0.7220719, 0.81681216]\n",
      "Batch 98/700: Discriminator loss = 1.2189034223556519, GAN loss = [2.1331575, 0.7030697, 0.8020387]\n",
      "Batch 99/700: Discriminator loss = 1.1915507316589355, GAN loss = [2.1988869, 0.7234018, 0.8474345]\n",
      "Batch 100/700: Discriminator loss = 1.206485629081726, GAN loss = [2.1934316, 0.7280159, 0.83733857]\n",
      "Batch 101/700: Discriminator loss = 1.2096112966537476, GAN loss = [2.190385, 0.7182667, 0.84401774]\n",
      "Batch 102/700: Discriminator loss = 1.2064536809921265, GAN loss = [2.1528666, 0.7287867, 0.7959739]\n",
      "Batch 103/700: Discriminator loss = 1.2000097036361694, GAN loss = [2.1765943, 0.7222545, 0.82624006]\n",
      "Batch 104/700: Discriminator loss = 1.19195556640625, GAN loss = [2.2154305, 0.7460386, 0.84129936]\n",
      "Batch 105/700: Discriminator loss = 1.241697907447815, GAN loss = [2.153136, 0.69027627, 0.83475757]\n",
      "Batch 106/700: Discriminator loss = 1.230952501296997, GAN loss = [2.1391094, 0.69840086, 0.81261116]\n",
      "Batch 107/700: Discriminator loss = 1.178585171699524, GAN loss = [2.223759, 0.7506676, 0.8450032]\n",
      "Batch 108/700: Discriminator loss = 1.203953742980957, GAN loss = [2.1806514, 0.72700167, 0.82556933]\n",
      "Batch 109/700: Discriminator loss = 1.2260433435440063, GAN loss = [2.1386545, 0.7050645, 0.805505]\n",
      "Batch 110/700: Discriminator loss = 1.1983689069747925, GAN loss = [2.1792212, 0.71951187, 0.83163625]\n",
      "Batch 111/700: Discriminator loss = 1.2204111814498901, GAN loss = [2.1734478, 0.70874274, 0.8366492]\n",
      "Batch 112/700: Discriminator loss = 1.1954964399337769, GAN loss = [2.1838515, 0.7400426, 0.8157596]\n",
      "Batch 113/700: Discriminator loss = 1.206533670425415, GAN loss = [2.1725729, 0.7303225, 0.8142215]\n",
      "Batch 114/700: Discriminator loss = 1.2038817405700684, GAN loss = [2.183184, 0.73082113, 0.82434535]\n",
      "Batch 115/700: Discriminator loss = 1.2054834365844727, GAN loss = [2.1967978, 0.72885567, 0.83992976]\n",
      "Batch 116/700: Discriminator loss = 1.213194489479065, GAN loss = [2.1812057, 0.7272274, 0.8259637]\n",
      "Batch 117/700: Discriminator loss = 1.1885008811950684, GAN loss = [2.234669, 0.75243574, 0.85421485]\n",
      "Batch 118/700: Discriminator loss = 1.1817748546600342, GAN loss = [2.2056332, 0.74922884, 0.82839507]\n",
      "Batch 119/700: Discriminator loss = 1.2060866355895996, GAN loss = [2.165174, 0.71447706, 0.82269317]\n",
      "Batch 120/700: Discriminator loss = 1.2174893617630005, GAN loss = [2.1872575, 0.7121566, 0.8471025]\n",
      "Batch 121/700: Discriminator loss = 1.179917573928833, GAN loss = [2.1889021, 0.7414545, 0.81944203]\n",
      "Batch 122/700: Discriminator loss = 1.196083426475525, GAN loss = [2.2114325, 0.7313178, 0.8520891]\n",
      "Batch 123/700: Discriminator loss = 1.2181297540664673, GAN loss = [2.2113163, 0.71511304, 0.86816055]\n",
      "Batch 124/700: Discriminator loss = 1.2301393747329712, GAN loss = [2.119248, 0.6972683, 0.7939455]\n",
      "Batch 125/700: Discriminator loss = 1.224347472190857, GAN loss = [2.1348112, 0.7098634, 0.79690987]\n",
      "Batch 126/700: Discriminator loss = 1.2169002294540405, GAN loss = [2.1751032, 0.71268255, 0.8343993]\n",
      "Batch 127/700: Discriminator loss = 1.2258341312408447, GAN loss = [2.136441, 0.699927, 0.80851007]\n",
      "Batch 128/700: Discriminator loss = 1.225685954093933, GAN loss = [2.1307437, 0.7075117, 0.7952276]\n",
      "Batch 129/700: Discriminator loss = 1.1952319145202637, GAN loss = [2.1615593, 0.72613966, 0.80740386]\n",
      "Batch 130/700: Discriminator loss = 1.2021218538284302, GAN loss = [2.1557496, 0.7271495, 0.8005562]\n",
      "Batch 131/700: Discriminator loss = 1.208114743232727, GAN loss = [2.231943, 0.7260724, 0.8778092]\n",
      "Batch 132/700: Discriminator loss = 1.222190499305725, GAN loss = [2.1364129, 0.7056552, 0.8026874]\n",
      "Batch 133/700: Discriminator loss = 1.2117637395858765, GAN loss = [2.1653218, 0.7227562, 0.8144973]\n",
      "Batch 134/700: Discriminator loss = 1.1904771327972412, GAN loss = [2.1812913, 0.7312226, 0.8220157]\n",
      "Batch 135/700: Discriminator loss = 1.1980966329574585, GAN loss = [2.1856856, 0.7421055, 0.8155299]\n",
      "Batch 136/700: Discriminator loss = 1.1856409311294556, GAN loss = [2.203246, 0.75817764, 0.8170137]\n",
      "Batch 137/700: Discriminator loss = 1.1976567506790161, GAN loss = [2.191788, 0.7392174, 0.82450986]\n",
      "Batch 138/700: Discriminator loss = 1.1827362775802612, GAN loss = [2.2009594, 0.75169283, 0.8212036]\n",
      "Batch 139/700: Discriminator loss = 1.152593970298767, GAN loss = [2.2727041, 0.76965606, 0.8749995]\n",
      "Batch 140/700: Discriminator loss = 1.1778533458709717, GAN loss = [2.207852, 0.7570758, 0.8227472]\n",
      "Batch 141/700: Discriminator loss = 1.1882363557815552, GAN loss = [2.1986406, 0.74198556, 0.82863396]\n",
      "Batch 142/700: Discriminator loss = 1.196522831916809, GAN loss = [2.2065835, 0.74088395, 0.83768964]\n",
      "Batch 143/700: Discriminator loss = 1.1926733255386353, GAN loss = [2.1799603, 0.72331375, 0.82864076]\n",
      "Batch 144/700: Discriminator loss = 1.1946486234664917, GAN loss = [2.2213678, 0.71920204, 0.8741513]\n",
      "Batch 145/700: Discriminator loss = 1.214039921760559, GAN loss = [2.2239873, 0.7150246, 0.880951]\n",
      "Batch 146/700: Discriminator loss = 1.182292103767395, GAN loss = [2.2265012, 0.7491417, 0.8493611]\n",
      "Batch 147/700: Discriminator loss = 1.2128781080245972, GAN loss = [2.1602437, 0.72643846, 0.8058264]\n",
      "Batch 148/700: Discriminator loss = 1.2013946771621704, GAN loss = [2.1797423, 0.7290545, 0.822722]\n",
      "Batch 149/700: Discriminator loss = 1.199831485748291, GAN loss = [2.1669517, 0.7382573, 0.8007279]\n",
      "Batch 150/700: Discriminator loss = 1.2127140760421753, GAN loss = [2.1541076, 0.7270262, 0.7991151]\n",
      "Batch 151/700: Discriminator loss = 1.2011566162109375, GAN loss = [2.1834018, 0.72031784, 0.8351192]\n",
      "Batch 152/700: Discriminator loss = 1.2082173824310303, GAN loss = [2.1602757, 0.7125938, 0.81972456]\n",
      "Batch 153/700: Discriminator loss = 1.2225847244262695, GAN loss = [2.1821842, 0.7100585, 0.8441862]\n",
      "Batch 154/700: Discriminator loss = 1.2110791206359863, GAN loss = [2.235827, 0.7148025, 0.893121]\n",
      "Batch 155/700: Discriminator loss = 1.2232834100723267, GAN loss = [2.1759903, 0.7032365, 0.84488237]\n",
      "Batch 156/700: Discriminator loss = 1.2312005758285522, GAN loss = [2.158776, 0.70299304, 0.8279225]\n",
      "Batch 157/700: Discriminator loss = 1.217865228652954, GAN loss = [2.2243004, 0.70944166, 0.8870256]\n",
      "Batch 158/700: Discriminator loss = 1.2172951698303223, GAN loss = [2.2288332, 0.7207354, 0.8803161]\n",
      "Batch 159/700: Discriminator loss = 1.2076836824417114, GAN loss = [2.1734157, 0.7339451, 0.81172264]\n",
      "Batch 160/700: Discriminator loss = 1.2436515092849731, GAN loss = [2.1322389, 0.7080549, 0.7964674]\n",
      "Batch 161/700: Discriminator loss = 1.20074462890625, GAN loss = [2.1234214, 0.7232723, 0.77244914]\n",
      "Batch 162/700: Discriminator loss = 1.1955922842025757, GAN loss = [2.1687012, 0.7355404, 0.8054526]\n",
      "Batch 163/700: Discriminator loss = 1.1969627141952515, GAN loss = [2.217469, 0.73517203, 0.8545884]\n",
      "Batch 164/700: Discriminator loss = 1.206027626991272, GAN loss = [2.1595037, 0.7270063, 0.804795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 165/700: Discriminator loss = 1.251212477684021, GAN loss = [2.1495745, 0.70687425, 0.81501085]\n",
      "Batch 166/700: Discriminator loss = 1.2166430950164795, GAN loss = [2.125065, 0.7197973, 0.77755296]\n",
      "Batch 167/700: Discriminator loss = 1.2241768836975098, GAN loss = [2.114417, 0.7149908, 0.7717144]\n",
      "Batch 168/700: Discriminator loss = 1.2257152795791626, GAN loss = [2.15645, 0.7061308, 0.8226006]\n",
      "Batch 169/700: Discriminator loss = 1.2403526306152344, GAN loss = [2.1068635, 0.6987125, 0.78041995]\n",
      "Batch 170/700: Discriminator loss = 1.2259552478790283, GAN loss = [2.1872554, 0.71679026, 0.84272325]\n",
      "Batch 171/700: Discriminator loss = 1.2431378364562988, GAN loss = [2.1395347, 0.7066419, 0.8051185]\n",
      "Batch 172/700: Discriminator loss = 1.208261251449585, GAN loss = [2.1552958, 0.72950083, 0.7979951]\n",
      "Batch 173/700: Discriminator loss = 1.2197057008743286, GAN loss = [2.1919246, 0.72761965, 0.83647764]\n",
      "Batch 174/700: Discriminator loss = 1.2253684997558594, GAN loss = [2.1428828, 0.74684507, 0.76821727]\n",
      "Batch 175/700: Discriminator loss = 1.2067123651504517, GAN loss = [2.1376042, 0.7303274, 0.77942574]\n",
      "Batch 176/700: Discriminator loss = 1.2001962661743164, GAN loss = [2.1975782, 0.7529196, 0.8167849]\n",
      "Batch 177/700: Discriminator loss = 1.192853331565857, GAN loss = [2.1799643, 0.7600243, 0.79203]\n",
      "Batch 178/700: Discriminator loss = 1.1863069534301758, GAN loss = [2.2110076, 0.74853724, 0.8345111]\n",
      "Batch 179/700: Discriminator loss = 1.176260232925415, GAN loss = [2.2301757, 0.7564116, 0.84577227]\n",
      "Batch 180/700: Discriminator loss = 1.1866142749786377, GAN loss = [2.2258468, 0.7595639, 0.8382571]\n",
      "Batch 181/700: Discriminator loss = 1.185768723487854, GAN loss = [2.2321677, 0.7445926, 0.85952616]\n",
      "Batch 182/700: Discriminator loss = 1.1941397190093994, GAN loss = [2.1977434, 0.74187505, 0.8277919]\n",
      "Batch 183/700: Discriminator loss = 1.180703043937683, GAN loss = [2.2580936, 0.76601756, 0.86397225]\n",
      "Batch 184/700: Discriminator loss = 1.2064015865325928, GAN loss = [2.22571, 0.73308784, 0.86452407]\n",
      "Batch 185/700: Discriminator loss = 1.1776108741760254, GAN loss = [2.2440503, 0.7611766, 0.85476756]\n",
      "Batch 186/700: Discriminator loss = 1.1661571264266968, GAN loss = [2.2750244, 0.7701841, 0.8767216]\n",
      "Batch 187/700: Discriminator loss = 1.1739681959152222, GAN loss = [2.1961684, 0.767646, 0.80040324]\n",
      "Batch 188/700: Discriminator loss = 1.2133530378341675, GAN loss = [2.2250628, 0.74410784, 0.8528236]\n",
      "Batch 189/700: Discriminator loss = 1.1859678030014038, GAN loss = [2.261286, 0.7684843, 0.86467475]\n",
      "Batch 190/700: Discriminator loss = 1.184239387512207, GAN loss = [2.2298698, 0.7503648, 0.8514115]\n",
      "Batch 191/700: Discriminator loss = 1.189775824546814, GAN loss = [2.215623, 0.7421914, 0.8453775]\n",
      "Batch 192/700: Discriminator loss = 1.174249291419983, GAN loss = [2.2860854, 0.76210177, 0.89595115]\n",
      "Batch 193/700: Discriminator loss = 1.1574040651321411, GAN loss = [2.2755883, 0.77337617, 0.87420106]\n",
      "Batch 194/700: Discriminator loss = 1.1825025081634521, GAN loss = [2.2537148, 0.75675374, 0.868964]\n",
      "Batch 195/700: Discriminator loss = 1.1363710165023804, GAN loss = [2.3271697, 0.7940753, 0.90512884]\n",
      "Batch 196/700: Discriminator loss = 1.1630783081054688, GAN loss = [2.2482529, 0.7792949, 0.84101313]\n",
      "Batch 197/700: Discriminator loss = 1.1644763946533203, GAN loss = [2.3294468, 0.782595, 0.9189263]\n",
      "Batch 198/700: Discriminator loss = 1.152176022529602, GAN loss = [2.2820196, 0.78023756, 0.87388724]\n",
      "Batch 199/700: Discriminator loss = 1.1460403203964233, GAN loss = [2.3639379, 0.8037881, 0.9322919]\n",
      "Batch 200/700: Discriminator loss = 1.1534518003463745, GAN loss = [2.3764, 0.7817905, 0.96679044]\n",
      "Batch 201/700: Discriminator loss = 1.1527713537216187, GAN loss = [2.3448663, 0.79537505, 0.92170984]\n",
      "Batch 202/700: Discriminator loss = 1.1692830324172974, GAN loss = [2.2873783, 0.77212936, 0.88748413]\n",
      "Batch 203/700: Discriminator loss = 1.1649901866912842, GAN loss = [2.3672826, 0.7829663, 0.9565554]\n",
      "Batch 204/700: Discriminator loss = 1.1528280973434448, GAN loss = [2.3042555, 0.7832392, 0.8932698]\n",
      "Batch 205/700: Discriminator loss = 1.1647217273712158, GAN loss = [2.282445, 0.78092575, 0.873776]\n",
      "Batch 206/700: Discriminator loss = 1.1640303134918213, GAN loss = [2.3357499, 0.79646057, 0.9115517]\n",
      "Batch 207/700: Discriminator loss = 1.173583745956421, GAN loss = [2.3105605, 0.7813491, 0.90150034]\n",
      "Batch 208/700: Discriminator loss = 1.1846705675125122, GAN loss = [2.2851815, 0.7636044, 0.8938786]\n",
      "Batch 209/700: Discriminator loss = 1.1574958562850952, GAN loss = [2.3202665, 0.79657984, 0.89600044]\n",
      "Batch 210/700: Discriminator loss = 1.1728324890136719, GAN loss = [2.2920656, 0.7830707, 0.8813102]\n",
      "Batch 211/700: Discriminator loss = 1.1628203392028809, GAN loss = [2.3300989, 0.7999943, 0.9024219]\n",
      "Batch 212/700: Discriminator loss = 1.1415163278579712, GAN loss = [2.4055793, 0.8275879, 0.9503132]\n",
      "Batch 213/700: Discriminator loss = 1.1606661081314087, GAN loss = [2.3138652, 0.78211576, 0.9040725]\n",
      "Batch 214/700: Discriminator loss = 1.1405136585235596, GAN loss = [2.3747013, 0.81567085, 0.93137497]\n",
      "Batch 215/700: Discriminator loss = 1.1611500978469849, GAN loss = [2.3326879, 0.78555703, 0.91948366]\n",
      "Batch 216/700: Discriminator loss = 1.1407467126846313, GAN loss = [2.2998374, 0.78933406, 0.88284904]\n",
      "Batch 217/700: Discriminator loss = 1.1898908615112305, GAN loss = [2.2902527, 0.7660271, 0.8965749]\n",
      "Batch 218/700: Discriminator loss = 1.2006009817123413, GAN loss = [2.2779763, 0.7591085, 0.8912068]\n",
      "Batch 219/700: Discriminator loss = 1.199088454246521, GAN loss = [2.2918146, 0.74771315, 0.91640955]\n",
      "Batch 220/700: Discriminator loss = 1.202389121055603, GAN loss = [2.3342605, 0.7498629, 0.9566735]\n",
      "Batch 221/700: Discriminator loss = 1.2124792337417603, GAN loss = [2.306732, 0.7480411, 0.930932]\n",
      "Batch 222/700: Discriminator loss = 1.2153974771499634, GAN loss = [2.2604358, 0.7636113, 0.8690322]\n",
      "Batch 223/700: Discriminator loss = 1.222260594367981, GAN loss = [2.266964, 0.7843966, 0.8547706]\n",
      "Batch 224/700: Discriminator loss = 1.1908529996871948, GAN loss = [2.2803073, 0.77371544, 0.8787746]\n",
      "Batch 225/700: Discriminator loss = 1.1653331518173218, GAN loss = [2.3664556, 0.8071709, 0.93145174]\n",
      "Batch 226/700: Discriminator loss = 1.1795294284820557, GAN loss = [2.336975, 0.79969084, 0.9094295]\n",
      "Batch 227/700: Discriminator loss = 1.1723861694335938, GAN loss = [2.2869751, 0.7893082, 0.8698004]\n",
      "Batch 228/700: Discriminator loss = 1.1529936790466309, GAN loss = [2.291589, 0.835286, 0.82843]\n",
      "Batch 229/700: Discriminator loss = 1.176557183265686, GAN loss = [2.3187058, 0.8042707, 0.8865578]\n",
      "Batch 230/700: Discriminator loss = 1.185144066810608, GAN loss = [2.263638, 0.77476, 0.8609864]\n",
      "Batch 231/700: Discriminator loss = 1.1893357038497925, GAN loss = [2.2080574, 0.76442015, 0.8157363]\n",
      "Batch 232/700: Discriminator loss = 1.175068974494934, GAN loss = [2.275972, 0.78596, 0.8621145]\n",
      "Batch 233/700: Discriminator loss = 1.1543183326721191, GAN loss = [2.3145473, 0.8039071, 0.88275373]\n",
      "Batch 234/700: Discriminator loss = 1.1831858158111572, GAN loss = [2.2692716, 0.76776785, 0.8736012]\n",
      "Batch 235/700: Discriminator loss = 1.1942256689071655, GAN loss = [2.2510033, 0.7640154, 0.85908294]\n",
      "Batch 236/700: Discriminator loss = 1.2116987705230713, GAN loss = [2.3001664, 0.7563224, 0.9159453]\n",
      "Batch 237/700: Discriminator loss = 1.1940644979476929, GAN loss = [2.2485619, 0.7836659, 0.837003]\n",
      "Batch 238/700: Discriminator loss = 1.197402000427246, GAN loss = [2.2377236, 0.75174713, 0.85806704]\n",
      "Batch 239/700: Discriminator loss = 1.2002938985824585, GAN loss = [2.2633595, 0.76819533, 0.8672366]\n",
      "Batch 240/700: Discriminator loss = 1.179627537727356, GAN loss = [2.2550619, 0.7625944, 0.86453974]\n",
      "Batch 241/700: Discriminator loss = 1.1940391063690186, GAN loss = [2.234919, 0.76373625, 0.8432657]\n",
      "Batch 242/700: Discriminator loss = 1.1857473850250244, GAN loss = [2.2369308, 0.76976985, 0.83925605]\n",
      "Batch 243/700: Discriminator loss = 1.2303718328475952, GAN loss = [2.2156553, 0.7314186, 0.8563096]\n",
      "Batch 244/700: Discriminator loss = 1.1960009336471558, GAN loss = [2.274661, 0.7583142, 0.8884251]\n",
      "Batch 245/700: Discriminator loss = 1.171160101890564, GAN loss = [2.2372975, 0.7692772, 0.8401111]\n",
      "Batch 246/700: Discriminator loss = 1.200124740600586, GAN loss = [2.218404, 0.74745715, 0.84304434]\n",
      "Batch 247/700: Discriminator loss = 1.1774158477783203, GAN loss = [2.2139368, 0.7606735, 0.8253686]\n",
      "Batch 248/700: Discriminator loss = 1.2021605968475342, GAN loss = [2.1554666, 0.7414347, 0.7861423]\n",
      "Batch 249/700: Discriminator loss = 1.1781407594680786, GAN loss = [2.2106063, 0.7538446, 0.82889205]\n",
      "Batch 250/700: Discriminator loss = 1.1754511594772339, GAN loss = [2.235836, 0.7656795, 0.8423043]\n",
      "Batch 251/700: Discriminator loss = 1.2025631666183472, GAN loss = [2.1997461, 0.74572563, 0.8261839]\n",
      "Batch 252/700: Discriminator loss = 1.173613429069519, GAN loss = [2.252949, 0.76404154, 0.86107683]\n",
      "Batch 253/700: Discriminator loss = 1.1676034927368164, GAN loss = [2.267014, 0.7728211, 0.8663876]\n",
      "Batch 254/700: Discriminator loss = 1.157790184020996, GAN loss = [2.240458, 0.7758569, 0.8368372]\n",
      "Batch 255/700: Discriminator loss = 1.1761313676834106, GAN loss = [2.2245317, 0.76490045, 0.8318887]\n",
      "Batch 256/700: Discriminator loss = 1.17823326587677, GAN loss = [2.2548113, 0.75503737, 0.872067]\n",
      "Batch 257/700: Discriminator loss = 1.1847282648086548, GAN loss = [2.1970515, 0.7612534, 0.80812705]\n",
      "Batch 258/700: Discriminator loss = 1.1448034048080444, GAN loss = [2.2409284, 0.7939195, 0.8194034]\n",
      "Batch 259/700: Discriminator loss = 1.1774420738220215, GAN loss = [2.2380292, 0.755482, 0.85500026]\n",
      "Batch 260/700: Discriminator loss = 1.1896312236785889, GAN loss = [2.2599452, 0.74076986, 0.8916662]\n",
      "Batch 261/700: Discriminator loss = 1.1676944494247437, GAN loss = [2.2408867, 0.7518951, 0.8615172]\n",
      "Batch 262/700: Discriminator loss = 1.170654535293579, GAN loss = [2.1849804, 0.7613634, 0.7961979]\n",
      "Batch 263/700: Discriminator loss = 1.1671701669692993, GAN loss = [2.253181, 0.7565327, 0.8692839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 264/700: Discriminator loss = 1.1526999473571777, GAN loss = [2.2338006, 0.7802993, 0.8261909]\n",
      "Batch 265/700: Discriminator loss = 1.1873421669006348, GAN loss = [2.237794, 0.74572927, 0.8648092]\n",
      "Batch 266/700: Discriminator loss = 1.1884174346923828, GAN loss = [2.1831748, 0.74639595, 0.8095777]\n",
      "Batch 267/700: Discriminator loss = 1.1994578838348389, GAN loss = [2.2781253, 0.7602742, 0.89070344]\n",
      "Batch 268/700: Discriminator loss = 1.2004927396774292, GAN loss = [2.2322147, 0.7339491, 0.8711619]\n",
      "Batch 269/700: Discriminator loss = 1.1871219873428345, GAN loss = [2.286739, 0.75155866, 0.9081369]\n",
      "Batch 270/700: Discriminator loss = 1.1912939548492432, GAN loss = [2.229977, 0.7442565, 0.85872674]\n",
      "Batch 271/700: Discriminator loss = 1.1839288473129272, GAN loss = [2.2312472, 0.7397017, 0.8646188]\n",
      "Batch 272/700: Discriminator loss = 1.1882091760635376, GAN loss = [2.2395103, 0.7397381, 0.87289923]\n",
      "Batch 273/700: Discriminator loss = 1.1806715726852417, GAN loss = [2.1990764, 0.7486445, 0.8235987]\n",
      "Batch 274/700: Discriminator loss = 1.1802551746368408, GAN loss = [2.203176, 0.75926256, 0.8171247]\n",
      "Batch 275/700: Discriminator loss = 1.1932600736618042, GAN loss = [2.2234719, 0.7492956, 0.84741706]\n",
      "Batch 276/700: Discriminator loss = 1.199828863143921, GAN loss = [2.2427418, 0.755949, 0.86007094]\n",
      "Batch 277/700: Discriminator loss = 1.2196238040924072, GAN loss = [2.1977124, 0.71332324, 0.85769445]\n",
      "Batch 278/700: Discriminator loss = 1.1917911767959595, GAN loss = [2.2019427, 0.747204, 0.8280596]\n",
      "Batch 279/700: Discriminator loss = 1.225084900856018, GAN loss = [2.2547617, 0.7393232, 0.8887918]\n",
      "Batch 280/700: Discriminator loss = 1.1856989860534668, GAN loss = [2.1987107, 0.7674214, 0.8046745]\n",
      "Batch 281/700: Discriminator loss = 1.1761530637741089, GAN loss = [2.2974162, 0.76123774, 0.9095875]\n",
      "Batch 282/700: Discriminator loss = 1.1855947971343994, GAN loss = [2.267636, 0.757937, 0.88310975]\n",
      "Batch 283/700: Discriminator loss = 1.2098045349121094, GAN loss = [2.2039094, 0.7306257, 0.84667456]\n",
      "Batch 284/700: Discriminator loss = 1.2143006324768066, GAN loss = [2.2190998, 0.73533624, 0.8571461]\n",
      "Batch 285/700: Discriminator loss = 1.21537446975708, GAN loss = [2.2353938, 0.7263534, 0.8823975]\n",
      "Batch 286/700: Discriminator loss = 1.2146575450897217, GAN loss = [2.21173, 0.7232203, 0.8618523]\n",
      "Batch 287/700: Discriminator loss = 1.2328143119812012, GAN loss = [2.1417017, 0.718347, 0.7966668]\n",
      "Batch 288/700: Discriminator loss = 1.2213102579116821, GAN loss = [2.1884258, 0.7180698, 0.8436541]\n",
      "Batch 289/700: Discriminator loss = 1.1960265636444092, GAN loss = [2.1847136, 0.76429194, 0.79369265]\n",
      "Batch 290/700: Discriminator loss = 1.2122877836227417, GAN loss = [2.150081, 0.743951, 0.77937734]\n",
      "Batch 291/700: Discriminator loss = 1.2547204494476318, GAN loss = [2.1759064, 0.695373, 0.8537609]\n",
      "Batch 292/700: Discriminator loss = 1.1971131563186646, GAN loss = [2.2333164, 0.74915254, 0.85739326]\n",
      "Batch 293/700: Discriminator loss = 1.2228891849517822, GAN loss = [2.164283, 0.72448653, 0.8130344]\n",
      "Batch 294/700: Discriminator loss = 1.2348366975784302, GAN loss = [2.1913183, 0.7231821, 0.84138125]\n",
      "Batch 295/700: Discriminator loss = 1.224570870399475, GAN loss = [2.15912, 0.73255736, 0.7998264]\n",
      "Batch 296/700: Discriminator loss = 1.200340747833252, GAN loss = [2.165134, 0.7468115, 0.7916185]\n",
      "Batch 297/700: Discriminator loss = 1.2197704315185547, GAN loss = [2.1371841, 0.72149086, 0.78902847]\n",
      "Batch 298/700: Discriminator loss = 1.2308591604232788, GAN loss = [2.2065742, 0.7254028, 0.85451806]\n",
      "Batch 299/700: Discriminator loss = 1.2046908140182495, GAN loss = [2.2084754, 0.73835504, 0.84346336]\n",
      "Batch 300/700: Discriminator loss = 1.2167047262191772, GAN loss = [2.171534, 0.7276491, 0.8172376]\n",
      "Batch 301/700: Discriminator loss = 1.232451319694519, GAN loss = [2.1615908, 0.73769873, 0.79725283]\n",
      "Batch 302/700: Discriminator loss = 1.2314119338989258, GAN loss = [2.1229057, 0.71280646, 0.7834748]\n",
      "Batch 303/700: Discriminator loss = 1.201265811920166, GAN loss = [2.1665215, 0.74318933, 0.79671615]\n",
      "Batch 304/700: Discriminator loss = 1.21775484085083, GAN loss = [2.198543, 0.72761536, 0.8443053]\n",
      "Batch 305/700: Discriminator loss = 1.215667724609375, GAN loss = [2.1603057, 0.720449, 0.8132541]\n",
      "Batch 306/700: Discriminator loss = 1.1955070495605469, GAN loss = [2.141768, 0.7312643, 0.7839179]\n",
      "Batch 307/700: Discriminator loss = 1.2080078125, GAN loss = [2.1244333, 0.72012377, 0.7777366]\n",
      "Batch 308/700: Discriminator loss = 1.2062907218933105, GAN loss = [2.1818805, 0.72957236, 0.82574767]\n",
      "Batch 309/700: Discriminator loss = 1.2053231000900269, GAN loss = [2.1602519, 0.7118728, 0.8218318]\n",
      "Batch 310/700: Discriminator loss = 1.187942385673523, GAN loss = [2.178748, 0.73215544, 0.8200825]\n",
      "Batch 311/700: Discriminator loss = 1.1773929595947266, GAN loss = [2.1801105, 0.75601065, 0.7976049]\n",
      "Batch 312/700: Discriminator loss = 1.198186993598938, GAN loss = [2.1828513, 0.7286937, 0.8276783]\n",
      "Batch 313/700: Discriminator loss = 1.1830854415893555, GAN loss = [2.1997116, 0.7403856, 0.8328479]\n",
      "Batch 314/700: Discriminator loss = 1.1985416412353516, GAN loss = [2.1819143, 0.73125803, 0.82419336]\n",
      "Batch 315/700: Discriminator loss = 1.200296401977539, GAN loss = [2.2069585, 0.7271492, 0.85335916]\n",
      "Batch 316/700: Discriminator loss = 1.1996911764144897, GAN loss = [2.197346, 0.72781885, 0.84309256]\n",
      "Batch 317/700: Discriminator loss = 1.183577299118042, GAN loss = [2.1538234, 0.7373503, 0.7900439]\n",
      "Batch 318/700: Discriminator loss = 1.1914039850234985, GAN loss = [2.175427, 0.7324475, 0.81657195]\n",
      "Batch 319/700: Discriminator loss = 1.2006489038467407, GAN loss = [2.182108, 0.7216386, 0.8341023]\n",
      "Batch 320/700: Discriminator loss = 1.203736662864685, GAN loss = [2.1726172, 0.7273098, 0.8189649]\n",
      "Batch 321/700: Discriminator loss = 1.150334119796753, GAN loss = [2.2679436, 0.780164, 0.8614601]\n",
      "Batch 322/700: Discriminator loss = 1.1580793857574463, GAN loss = [2.2580347, 0.772614, 0.85910666]\n",
      "Batch 323/700: Discriminator loss = 1.1794569492340088, GAN loss = [2.2304168, 0.75035745, 0.853759]\n",
      "Batch 324/700: Discriminator loss = 1.1909630298614502, GAN loss = [2.2373276, 0.74963874, 0.8614014]\n",
      "Batch 325/700: Discriminator loss = 1.1797354221343994, GAN loss = [2.2326732, 0.7534363, 0.85296106]\n",
      "Batch 326/700: Discriminator loss = 1.1848821640014648, GAN loss = [2.2253797, 0.74774927, 0.8513609]\n",
      "Batch 327/700: Discriminator loss = 1.185267448425293, GAN loss = [2.2873166, 0.7570499, 0.9039957]\n",
      "Batch 328/700: Discriminator loss = 1.1895182132720947, GAN loss = [2.2370527, 0.7476265, 0.863152]\n",
      "Batch 329/700: Discriminator loss = 1.1740769147872925, GAN loss = [2.2423637, 0.76308554, 0.8529884]\n",
      "Batch 330/700: Discriminator loss = 1.1945390701293945, GAN loss = [2.225859, 0.7401344, 0.8594365]\n",
      "Batch 331/700: Discriminator loss = 1.175150990486145, GAN loss = [2.252722, 0.74878526, 0.8776414]\n",
      "Batch 332/700: Discriminator loss = 1.175567865371704, GAN loss = [2.2662776, 0.7522323, 0.8877545]\n",
      "Batch 333/700: Discriminator loss = 1.176886796951294, GAN loss = [2.275666, 0.7570246, 0.892335]\n",
      "Batch 334/700: Discriminator loss = 1.2173919677734375, GAN loss = [2.2598135, 0.7494332, 0.88407576]\n",
      "Batch 335/700: Discriminator loss = 1.1828192472457886, GAN loss = [2.2244067, 0.754798, 0.84328735]\n",
      "Batch 336/700: Discriminator loss = 1.179341197013855, GAN loss = [2.2241237, 0.75582826, 0.84196144]\n",
      "Batch 337/700: Discriminator loss = 1.1742591857910156, GAN loss = [2.233634, 0.75495774, 0.85232645]\n",
      "Batch 338/700: Discriminator loss = 1.1812385320663452, GAN loss = [2.26208, 0.7572607, 0.87847906]\n",
      "Batch 339/700: Discriminator loss = 1.1823854446411133, GAN loss = [2.2561224, 0.748647, 0.88113]\n",
      "Batch 340/700: Discriminator loss = 1.1856329441070557, GAN loss = [2.2582421, 0.75864416, 0.8732466]\n",
      "Batch 341/700: Discriminator loss = 1.1771371364593506, GAN loss = [2.2056866, 0.74383265, 0.8355009]\n",
      "Batch 342/700: Discriminator loss = 1.1934843063354492, GAN loss = [2.2448447, 0.7529815, 0.8654998]\n",
      "Batch 343/700: Discriminator loss = 1.1885710954666138, GAN loss = [2.2432098, 0.74238986, 0.8744665]\n",
      "Batch 344/700: Discriminator loss = 1.1767107248306274, GAN loss = [2.2582254, 0.7508795, 0.88099235]\n",
      "Batch 345/700: Discriminator loss = 1.1673059463500977, GAN loss = [2.2694585, 0.75908625, 0.88401824]\n",
      "Batch 346/700: Discriminator loss = 1.181168794631958, GAN loss = [2.2122383, 0.75494736, 0.830938]\n",
      "Batch 347/700: Discriminator loss = 1.1802641153335571, GAN loss = [2.2208908, 0.74414176, 0.85040724]\n",
      "Batch 348/700: Discriminator loss = 1.1759827136993408, GAN loss = [2.2518733, 0.7525217, 0.8730248]\n",
      "Batch 349/700: Discriminator loss = 1.1919430494308472, GAN loss = [2.2112572, 0.73750794, 0.8474279]\n",
      "Batch 350/700: Discriminator loss = 1.1717184782028198, GAN loss = [2.286108, 0.76428276, 0.8955168]\n",
      "Batch 351/700: Discriminator loss = 1.1908150911331177, GAN loss = [2.2330472, 0.7411501, 0.86559385]\n",
      "Batch 352/700: Discriminator loss = 1.1720349788665771, GAN loss = [2.3082998, 0.7581092, 0.923902]\n",
      "Batch 353/700: Discriminator loss = 1.175561785697937, GAN loss = [2.2414517, 0.7541733, 0.8609941]\n",
      "Batch 354/700: Discriminator loss = 1.1582965850830078, GAN loss = [2.257166, 0.7712281, 0.85964227]\n",
      "Batch 355/700: Discriminator loss = 1.18324875831604, GAN loss = [2.2363102, 0.74247634, 0.8675382]\n",
      "Batch 356/700: Discriminator loss = 1.1620028018951416, GAN loss = [2.2724354, 0.7690865, 0.87707406]\n",
      "Batch 357/700: Discriminator loss = 1.1708626747131348, GAN loss = [2.2439375, 0.76416785, 0.85353124]\n",
      "Batch 358/700: Discriminator loss = 1.2002437114715576, GAN loss = [2.2559166, 0.72736275, 0.90235174]\n",
      "Batch 359/700: Discriminator loss = 1.1843305826187134, GAN loss = [2.231411, 0.7597537, 0.84548044]\n",
      "Batch 360/700: Discriminator loss = 1.1800892353057861, GAN loss = [2.261288, 0.7592032, 0.87591827]\n",
      "Batch 361/700: Discriminator loss = 1.2013472318649292, GAN loss = [2.2022424, 0.74306184, 0.83301324]\n",
      "Batch 362/700: Discriminator loss = 1.1930829286575317, GAN loss = [2.219456, 0.7399396, 0.8533552]\n",
      "Batch 363/700: Discriminator loss = 1.1714688539505005, GAN loss = [2.2450423, 0.7690724, 0.84981126]\n",
      "Batch 364/700: Discriminator loss = 1.1841944456100464, GAN loss = [2.2710652, 0.76032585, 0.884594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 365/700: Discriminator loss = 1.1928716897964478, GAN loss = [2.259454, 0.74304926, 0.8902831]\n",
      "Batch 366/700: Discriminator loss = 1.1725720167160034, GAN loss = [2.2372832, 0.754152, 0.8570235]\n",
      "Batch 367/700: Discriminator loss = 1.203341007232666, GAN loss = [2.2834082, 0.74842954, 0.90888274]\n",
      "Batch 368/700: Discriminator loss = 1.20786714553833, GAN loss = [2.2404063, 0.74085885, 0.8734578]\n",
      "Batch 369/700: Discriminator loss = 1.1875048875808716, GAN loss = [2.2596035, 0.74437934, 0.8891383]\n",
      "Batch 370/700: Discriminator loss = 1.185510277748108, GAN loss = [2.2449708, 0.7558683, 0.8630297]\n",
      "Batch 371/700: Discriminator loss = 1.2009241580963135, GAN loss = [2.1948009, 0.74330246, 0.82546073]\n",
      "Batch 372/700: Discriminator loss = 1.1823995113372803, GAN loss = [2.3172114, 0.76187116, 0.92933136]\n",
      "Batch 373/700: Discriminator loss = 1.1962859630584717, GAN loss = [2.201148, 0.744045, 0.83109903]\n",
      "Batch 374/700: Discriminator loss = 1.1704329252243042, GAN loss = [2.268167, 0.7684648, 0.873712]\n",
      "Batch 375/700: Discriminator loss = 1.1537261009216309, GAN loss = [2.2541547, 0.7834914, 0.84467185]\n",
      "Batch 376/700: Discriminator loss = 1.1831657886505127, GAN loss = [2.243725, 0.7534349, 0.864263]\n",
      "Batch 377/700: Discriminator loss = 1.1707689762115479, GAN loss = [2.279999, 0.770922, 0.8829966]\n",
      "Batch 378/700: Discriminator loss = 1.1981059312820435, GAN loss = [2.2327428, 0.7513134, 0.8553175]\n",
      "Batch 379/700: Discriminator loss = 1.2059295177459717, GAN loss = [2.2579627, 0.75697845, 0.87484145]\n",
      "Batch 380/700: Discriminator loss = 1.1914448738098145, GAN loss = [2.254807, 0.7674663, 0.86116457]\n",
      "Batch 381/700: Discriminator loss = 1.1765997409820557, GAN loss = [2.2454312, 0.77504975, 0.84418607]\n",
      "Batch 382/700: Discriminator loss = 1.147143840789795, GAN loss = [2.2783902, 0.7982946, 0.8538945]\n",
      "Batch 383/700: Discriminator loss = 1.1747552156448364, GAN loss = [2.2322638, 0.7768546, 0.82919174]\n",
      "Batch 384/700: Discriminator loss = 1.1611500978469849, GAN loss = [2.2783587, 0.77328837, 0.8788596]\n",
      "Batch 385/700: Discriminator loss = 1.18918776512146, GAN loss = [2.2776296, 0.7725339, 0.8788712]\n",
      "Batch 386/700: Discriminator loss = 1.15188729763031, GAN loss = [2.2774186, 0.78829473, 0.8628903]\n",
      "Batch 387/700: Discriminator loss = 1.169797658920288, GAN loss = [2.3370855, 0.77618706, 0.93464136]\n",
      "Batch 388/700: Discriminator loss = 1.149091362953186, GAN loss = [2.2770374, 0.78953356, 0.86122185]\n",
      "Batch 389/700: Discriminator loss = 1.1672419309616089, GAN loss = [2.28022, 0.7832238, 0.8706886]\n",
      "Batch 390/700: Discriminator loss = 1.155653715133667, GAN loss = [2.3085427, 0.79665464, 0.885523]\n",
      "Batch 391/700: Discriminator loss = 1.167819619178772, GAN loss = [2.290236, 0.7822102, 0.88162225]\n",
      "Batch 392/700: Discriminator loss = 1.1713100671768188, GAN loss = [2.2839184, 0.7742132, 0.8832665]\n",
      "Batch 393/700: Discriminator loss = 1.1747177839279175, GAN loss = [2.3269997, 0.78074867, 0.91976523]\n",
      "Batch 394/700: Discriminator loss = 1.1649339199066162, GAN loss = [2.2929313, 0.78853446, 0.87784904]\n",
      "Batch 395/700: Discriminator loss = 1.1646225452423096, GAN loss = [2.3148408, 0.80380595, 0.88441026]\n",
      "Batch 396/700: Discriminator loss = 1.1725072860717773, GAN loss = [2.2811036, 0.7798532, 0.8745479]\n",
      "Batch 397/700: Discriminator loss = 1.1974133253097534, GAN loss = [2.2668352, 0.7673839, 0.87266177]\n",
      "Batch 398/700: Discriminator loss = 1.1818954944610596, GAN loss = [2.286388, 0.7686747, 0.8908966]\n",
      "Batch 399/700: Discriminator loss = 1.1748110055923462, GAN loss = [2.315835, 0.77760005, 0.91139746]\n",
      "Batch 400/700: Discriminator loss = 1.1779694557189941, GAN loss = [2.3098507, 0.7869738, 0.8960203]\n",
      "Batch 401/700: Discriminator loss = 1.1629269123077393, GAN loss = [2.3207583, 0.7989297, 0.8949486]\n",
      "Batch 402/700: Discriminator loss = 1.1814846992492676, GAN loss = [2.3580167, 0.7891995, 0.9418973]\n",
      "Batch 403/700: Discriminator loss = 1.1425604820251465, GAN loss = [2.303815, 0.81845033, 0.8584185]\n",
      "Batch 404/700: Discriminator loss = 1.1688809394836426, GAN loss = [2.2886527, 0.792812, 0.8688716]\n",
      "Batch 405/700: Discriminator loss = 1.168776512145996, GAN loss = [2.2786894, 0.7831751, 0.8684951]\n",
      "Batch 406/700: Discriminator loss = 1.1806849241256714, GAN loss = [2.2798028, 0.7667884, 0.8859601]\n",
      "Batch 407/700: Discriminator loss = 1.1999480724334717, GAN loss = [2.300131, 0.753088, 0.91997004]\n",
      "Batch 408/700: Discriminator loss = 1.147037148475647, GAN loss = [2.3026156, 0.801114, 0.8744021]\n",
      "Batch 409/700: Discriminator loss = 1.1762840747833252, GAN loss = [2.2669024, 0.7663034, 0.87348944]\n",
      "Batch 410/700: Discriminator loss = 1.1686080694198608, GAN loss = [2.2914517, 0.77438843, 0.8899191]\n",
      "Batch 411/700: Discriminator loss = 1.1765096187591553, GAN loss = [2.2976205, 0.78090143, 0.8895409]\n",
      "Batch 412/700: Discriminator loss = 1.1724965572357178, GAN loss = [2.3072205, 0.7804354, 0.8995839]\n",
      "Batch 413/700: Discriminator loss = 1.1873986721038818, GAN loss = [2.271163, 0.7554689, 0.88844836]\n",
      "Batch 414/700: Discriminator loss = 1.174295425415039, GAN loss = [2.2986593, 0.76942563, 0.9019824]\n",
      "Batch 415/700: Discriminator loss = 1.2310895919799805, GAN loss = [2.2244964, 0.71555895, 0.88168985]\n",
      "Batch 416/700: Discriminator loss = 1.1784175634384155, GAN loss = [2.2516067, 0.7755678, 0.8487953]\n",
      "Batch 417/700: Discriminator loss = 1.187106728553772, GAN loss = [2.2393248, 0.75714165, 0.8549448]\n",
      "Batch 418/700: Discriminator loss = 1.1836938858032227, GAN loss = [2.314559, 0.7741789, 0.9131353]\n",
      "Batch 419/700: Discriminator loss = 1.1515171527862549, GAN loss = [2.272966, 0.7833214, 0.86239344]\n",
      "Batch 420/700: Discriminator loss = 1.1940840482711792, GAN loss = [2.2775211, 0.7628575, 0.8873842]\n",
      "Batch 421/700: Discriminator loss = 1.1717827320098877, GAN loss = [2.3060675, 0.7767117, 0.90207666]\n",
      "Batch 422/700: Discriminator loss = 1.2203068733215332, GAN loss = [2.204168, 0.7414074, 0.83547974]\n",
      "Batch 423/700: Discriminator loss = 1.1978638172149658, GAN loss = [2.2715316, 0.74973506, 0.894523]\n",
      "Batch 424/700: Discriminator loss = 1.1731829643249512, GAN loss = [2.2978141, 0.781204, 0.88935333]\n",
      "Batch 425/700: Discriminator loss = 1.2011140584945679, GAN loss = [2.2116964, 0.75376654, 0.8306688]\n",
      "Batch 426/700: Discriminator loss = 1.1890215873718262, GAN loss = [2.2670763, 0.7905601, 0.8492519]\n",
      "Batch 427/700: Discriminator loss = 1.1949267387390137, GAN loss = [2.2081754, 0.74189925, 0.8390205]\n",
      "Batch 428/700: Discriminator loss = 1.2026550769805908, GAN loss = [2.2008832, 0.7505832, 0.82306695]\n",
      "Batch 429/700: Discriminator loss = 1.1744017601013184, GAN loss = [2.2898726, 0.7775179, 0.88514745]\n",
      "Batch 430/700: Discriminator loss = 1.1662594079971313, GAN loss = [2.3200774, 0.77842414, 0.9144542]\n",
      "Batch 431/700: Discriminator loss = 1.1749340295791626, GAN loss = [2.2807653, 0.7861679, 0.86739993]\n",
      "Batch 432/700: Discriminator loss = 1.1925188302993774, GAN loss = [2.2246487, 0.7696436, 0.8277999]\n",
      "Batch 433/700: Discriminator loss = 1.1949721574783325, GAN loss = [2.2227483, 0.75943303, 0.8361119]\n",
      "Batch 434/700: Discriminator loss = 1.2034059762954712, GAN loss = [2.2385175, 0.7514423, 0.8598665]\n",
      "Batch 435/700: Discriminator loss = 1.1982388496398926, GAN loss = [2.168477, 0.7520991, 0.78915787]\n",
      "Batch 436/700: Discriminator loss = 1.1725941896438599, GAN loss = [2.2690072, 0.7854013, 0.8563753]\n",
      "Batch 437/700: Discriminator loss = 1.1976549625396729, GAN loss = [2.2690601, 0.7615315, 0.88030356]\n",
      "Batch 438/700: Discriminator loss = 1.1963551044464111, GAN loss = [2.1845534, 0.7498344, 0.8074994]\n",
      "Batch 439/700: Discriminator loss = 1.1664597988128662, GAN loss = [2.2364323, 0.7808375, 0.82836795]\n",
      "Batch 440/700: Discriminator loss = 1.172921061515808, GAN loss = [2.2450962, 0.778554, 0.83929366]\n",
      "Batch 441/700: Discriminator loss = 1.1928105354309082, GAN loss = [2.2451272, 0.7502501, 0.8676243]\n",
      "Batch 442/700: Discriminator loss = 1.178681492805481, GAN loss = [2.2519274, 0.76435196, 0.86032975]\n",
      "Batch 443/700: Discriminator loss = 1.1880996227264404, GAN loss = [2.237408, 0.76643044, 0.8437246]\n",
      "Batch 444/700: Discriminator loss = 1.19944167137146, GAN loss = [2.2242165, 0.7572631, 0.8396802]\n",
      "Batch 445/700: Discriminator loss = 1.2130060195922852, GAN loss = [2.2381563, 0.7412628, 0.8696248]\n",
      "Batch 446/700: Discriminator loss = 1.1943879127502441, GAN loss = [2.204934, 0.76557726, 0.812104]\n",
      "Batch 447/700: Discriminator loss = 1.197167992591858, GAN loss = [2.238271, 0.7558762, 0.8551561]\n",
      "Batch 448/700: Discriminator loss = 1.2035218477249146, GAN loss = [2.2017481, 0.7596523, 0.8148708]\n",
      "Batch 449/700: Discriminator loss = 1.193644642829895, GAN loss = [2.191016, 0.7477684, 0.8160332]\n",
      "Batch 450/700: Discriminator loss = 1.2048569917678833, GAN loss = [2.195617, 0.73442125, 0.8340051]\n",
      "Batch 451/700: Discriminator loss = 1.204107403755188, GAN loss = [2.21534, 0.76032346, 0.82786566]\n",
      "Batch 452/700: Discriminator loss = 1.1815658807754517, GAN loss = [2.230097, 0.7683734, 0.83459306]\n",
      "Batch 453/700: Discriminator loss = 1.1923986673355103, GAN loss = [2.285315, 0.77047724, 0.88772583]\n",
      "Batch 454/700: Discriminator loss = 1.1769287586212158, GAN loss = [2.2170153, 0.76700324, 0.8229206]\n",
      "Batch 455/700: Discriminator loss = 1.1866896152496338, GAN loss = [2.2473025, 0.7676766, 0.85254806]\n",
      "Batch 456/700: Discriminator loss = 1.1675935983657837, GAN loss = [2.2620595, 0.81547546, 0.81952804]\n",
      "Batch 457/700: Discriminator loss = 1.160441517829895, GAN loss = [2.2740905, 0.79504013, 0.85200715]\n",
      "Batch 458/700: Discriminator loss = 1.199569582939148, GAN loss = [2.2403686, 0.7584795, 0.85487854]\n",
      "Batch 459/700: Discriminator loss = 1.1703461408615112, GAN loss = [2.2689602, 0.7779345, 0.864045]\n",
      "Batch 460/700: Discriminator loss = 1.1659735441207886, GAN loss = [2.2559772, 0.7747185, 0.85430443]\n",
      "Batch 461/700: Discriminator loss = 1.172256588935852, GAN loss = [2.2275412, 0.77126455, 0.82935977]\n",
      "Batch 462/700: Discriminator loss = 1.1831011772155762, GAN loss = [2.2761467, 0.7685516, 0.8807132]\n",
      "Batch 463/700: Discriminator loss = 1.153347373008728, GAN loss = [2.275089, 0.7925698, 0.85567755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 464/700: Discriminator loss = 1.1551190614700317, GAN loss = [2.2614696, 0.78940475, 0.84525985]\n",
      "Batch 465/700: Discriminator loss = 1.162398338317871, GAN loss = [2.2752807, 0.77872163, 0.86977994]\n",
      "Batch 466/700: Discriminator loss = 1.1662049293518066, GAN loss = [2.2504506, 0.7578479, 0.86585826]\n",
      "Batch 467/700: Discriminator loss = 1.1979385614395142, GAN loss = [2.2554832, 0.7466099, 0.882159]\n",
      "Batch 468/700: Discriminator loss = 1.1886152029037476, GAN loss = [2.2127674, 0.7480219, 0.83805937]\n",
      "Batch 469/700: Discriminator loss = 1.2006853818893433, GAN loss = [2.2151482, 0.73561096, 0.85288346]\n",
      "Batch 470/700: Discriminator loss = 1.1773953437805176, GAN loss = [2.238684, 0.76809484, 0.8439566]\n",
      "Batch 471/700: Discriminator loss = 1.2048304080963135, GAN loss = [2.2503068, 0.7427193, 0.8809642]\n",
      "Batch 472/700: Discriminator loss = 1.2333096265792847, GAN loss = [2.2160337, 0.7218819, 0.8675362]\n",
      "Batch 473/700: Discriminator loss = 1.1829979419708252, GAN loss = [2.2492745, 0.7551254, 0.86756027]\n",
      "Batch 474/700: Discriminator loss = 1.2144888639450073, GAN loss = [2.1966717, 0.740166, 0.8299614]\n",
      "Batch 475/700: Discriminator loss = 1.1986010074615479, GAN loss = [2.264319, 0.7462506, 0.8915585]\n",
      "Batch 476/700: Discriminator loss = 1.2127933502197266, GAN loss = [2.214998, 0.7512961, 0.8372208]\n",
      "Batch 477/700: Discriminator loss = 1.2038627862930298, GAN loss = [2.2526474, 0.7521965, 0.873972]\n",
      "Batch 478/700: Discriminator loss = 1.2006099224090576, GAN loss = [2.2236655, 0.7602376, 0.83696854]\n",
      "Batch 479/700: Discriminator loss = 1.2111002206802368, GAN loss = [2.1884296, 0.74751425, 0.8144644]\n",
      "Batch 480/700: Discriminator loss = 1.194412112236023, GAN loss = [2.203321, 0.76749945, 0.8093811]\n",
      "Batch 481/700: Discriminator loss = 1.2257225513458252, GAN loss = [2.193744, 0.7314756, 0.8358408]\n",
      "Batch 482/700: Discriminator loss = 1.1857316493988037, GAN loss = [2.2276382, 0.7728184, 0.82841486]\n",
      "Batch 483/700: Discriminator loss = 1.1939666271209717, GAN loss = [2.1862202, 0.764627, 0.7952187]\n",
      "Batch 484/700: Discriminator loss = 1.2065092325210571, GAN loss = [2.2298396, 0.7530231, 0.8504469]\n",
      "Batch 485/700: Discriminator loss = 1.193320631980896, GAN loss = [2.2440517, 0.753512, 0.864164]\n",
      "Batch 486/700: Discriminator loss = 1.1863878965377808, GAN loss = [2.2560246, 0.76593995, 0.86371064]\n",
      "Batch 487/700: Discriminator loss = 1.1935875415802002, GAN loss = [2.2364173, 0.7670262, 0.84301585]\n",
      "Batch 488/700: Discriminator loss = 1.171287178993225, GAN loss = [2.2531447, 0.79052955, 0.83626014]\n",
      "Batch 489/700: Discriminator loss = 1.1855270862579346, GAN loss = [2.2365735, 0.75677115, 0.85346085]\n",
      "Batch 490/700: Discriminator loss = 1.1824524402618408, GAN loss = [2.2332344, 0.76986676, 0.8370504]\n",
      "Batch 491/700: Discriminator loss = 1.1932826042175293, GAN loss = [2.231297, 0.75862855, 0.8463668]\n",
      "Batch 492/700: Discriminator loss = 1.198677659034729, GAN loss = [2.2183175, 0.74428236, 0.84773093]\n",
      "Batch 493/700: Discriminator loss = 1.1870856285095215, GAN loss = [2.2424488, 0.76419985, 0.8519524]\n",
      "Batch 494/700: Discriminator loss = 1.2111573219299316, GAN loss = [2.2085865, 0.7408772, 0.8413928]\n",
      "Batch 495/700: Discriminator loss = 1.2189619541168213, GAN loss = [2.2539518, 0.7407034, 0.88691694]\n",
      "Batch 496/700: Discriminator loss = 1.1942789554595947, GAN loss = [2.2201784, 0.7621427, 0.8317127]\n",
      "Batch 497/700: Discriminator loss = 1.241223692893982, GAN loss = [2.178735, 0.71364015, 0.83878726]\n",
      "Batch 498/700: Discriminator loss = 1.2086272239685059, GAN loss = [2.1969128, 0.7429884, 0.8276064]\n",
      "Batch 499/700: Discriminator loss = 1.2253838777542114, GAN loss = [2.2098758, 0.7352226, 0.8483439]\n",
      "Batch 500/700: Discriminator loss = 1.2280917167663574, GAN loss = [2.2137663, 0.7416713, 0.8457481]\n",
      "Batch 501/700: Discriminator loss = 1.2404289245605469, GAN loss = [2.2067664, 0.74138457, 0.83901185]\n",
      "Batch 502/700: Discriminator loss = 1.2046161890029907, GAN loss = [2.2266116, 0.7567706, 0.84344393]\n",
      "Batch 503/700: Discriminator loss = 1.2258449792861938, GAN loss = [2.2232642, 0.7373146, 0.8595324]\n",
      "Batch 504/700: Discriminator loss = 1.2067207098007202, GAN loss = [2.22706, 0.75462884, 0.8459857]\n",
      "Batch 505/700: Discriminator loss = 1.214499592781067, GAN loss = [2.2313228, 0.759107, 0.8457675]\n",
      "Batch 506/700: Discriminator loss = 1.216517686843872, GAN loss = [2.2293155, 0.738258, 0.8646115]\n",
      "Batch 507/700: Discriminator loss = 1.2153252363204956, GAN loss = [2.2720532, 0.7528479, 0.89275885]\n",
      "Batch 508/700: Discriminator loss = 1.2283878326416016, GAN loss = [2.2190535, 0.7298646, 0.86273813]\n",
      "Batch 509/700: Discriminator loss = 1.2377876043319702, GAN loss = [2.1718102, 0.7373945, 0.8079697]\n",
      "Batch 510/700: Discriminator loss = 1.2092183828353882, GAN loss = [2.2394826, 0.7465091, 0.86653113]\n",
      "Batch 511/700: Discriminator loss = 1.2311326265335083, GAN loss = [2.2392852, 0.73331726, 0.87952775]\n",
      "Batch 512/700: Discriminator loss = 1.1973927021026611, GAN loss = [2.2237887, 0.7656095, 0.83174837]\n",
      "Batch 513/700: Discriminator loss = 1.201011300086975, GAN loss = [2.2433052, 0.75441444, 0.862467]\n",
      "Batch 514/700: Discriminator loss = 1.227790355682373, GAN loss = [2.2126505, 0.73274225, 0.85349447]\n",
      "Batch 515/700: Discriminator loss = 1.198038935661316, GAN loss = [2.231295, 0.7682135, 0.8366708]\n",
      "Batch 516/700: Discriminator loss = 1.2156314849853516, GAN loss = [2.2054098, 0.7367221, 0.84226]\n",
      "Batch 517/700: Discriminator loss = 1.2002593278884888, GAN loss = [2.2339716, 0.7531193, 0.8544133]\n",
      "Batch 518/700: Discriminator loss = 1.2149560451507568, GAN loss = [2.198265, 0.7451184, 0.8267278]\n",
      "Batch 519/700: Discriminator loss = 1.2025516033172607, GAN loss = [2.2405043, 0.75748545, 0.8566058]\n",
      "Batch 520/700: Discriminator loss = 1.2198712825775146, GAN loss = [2.1987844, 0.7437096, 0.8286637]\n",
      "Batch 521/700: Discriminator loss = 1.2078227996826172, GAN loss = [2.2220454, 0.7422916, 0.8533356]\n",
      "Batch 522/700: Discriminator loss = 1.1974918842315674, GAN loss = [2.2021575, 0.7441318, 0.8316117]\n",
      "Batch 523/700: Discriminator loss = 1.195085883140564, GAN loss = [2.2234583, 0.7558625, 0.84118783]\n",
      "Batch 524/700: Discriminator loss = 1.207053542137146, GAN loss = [2.241185, 0.7334799, 0.8813095]\n",
      "Batch 525/700: Discriminator loss = 1.2281033992767334, GAN loss = [2.2239308, 0.7275692, 0.8699618]\n",
      "Batch 526/700: Discriminator loss = 1.2120033502578735, GAN loss = [2.2441986, 0.7327652, 0.88501513]\n",
      "Batch 527/700: Discriminator loss = 1.2119905948638916, GAN loss = [2.2493393, 0.75099397, 0.8719346]\n",
      "Batch 528/700: Discriminator loss = 1.1760350465774536, GAN loss = [2.2378445, 0.766155, 0.8452778]\n",
      "Batch 529/700: Discriminator loss = 1.215488076210022, GAN loss = [2.2100844, 0.7255887, 0.8580987]\n",
      "Batch 530/700: Discriminator loss = 1.186195731163025, GAN loss = [2.2355995, 0.761224, 0.8479673]\n",
      "Batch 531/700: Discriminator loss = 1.1778894662857056, GAN loss = [2.251606, 0.76217103, 0.86300796]\n",
      "Batch 532/700: Discriminator loss = 1.1937456130981445, GAN loss = [2.3173294, 0.7655231, 0.92536455]\n",
      "Batch 533/700: Discriminator loss = 1.18821120262146, GAN loss = [2.2531676, 0.7405388, 0.8861577]\n",
      "Batch 534/700: Discriminator loss = 1.1884709596633911, GAN loss = [2.2632525, 0.76203734, 0.8747322]\n",
      "Batch 535/700: Discriminator loss = 1.1880217790603638, GAN loss = [2.3205853, 0.7585191, 0.93555564]\n",
      "Batch 536/700: Discriminator loss = 1.202172040939331, GAN loss = [2.2269807, 0.7376301, 0.8627963]\n",
      "Batch 537/700: Discriminator loss = 1.194145917892456, GAN loss = [2.2343118, 0.75378937, 0.8539692]\n",
      "Batch 538/700: Discriminator loss = 1.2030397653579712, GAN loss = [2.2604575, 0.7438641, 0.8900428]\n",
      "Batch 539/700: Discriminator loss = 1.2011278867721558, GAN loss = [2.2768698, 0.7442592, 0.9060748]\n",
      "Batch 540/700: Discriminator loss = 1.1905516386032104, GAN loss = [2.2608924, 0.752197, 0.88217616]\n",
      "Batch 541/700: Discriminator loss = 1.1904902458190918, GAN loss = [2.240537, 0.7464682, 0.8675949]\n",
      "Batch 542/700: Discriminator loss = 1.1967098712921143, GAN loss = [2.2538028, 0.7397829, 0.88756186]\n",
      "Batch 543/700: Discriminator loss = 1.2013330459594727, GAN loss = [2.183558, 0.7417553, 0.8153722]\n",
      "Batch 544/700: Discriminator loss = 1.1981909275054932, GAN loss = [2.2480443, 0.74385834, 0.8777899]\n",
      "Batch 545/700: Discriminator loss = 1.2084109783172607, GAN loss = [2.2159545, 0.7409959, 0.8485749]\n",
      "Batch 546/700: Discriminator loss = 1.1864012479782104, GAN loss = [2.2308376, 0.75627446, 0.8482016]\n",
      "Batch 547/700: Discriminator loss = 1.2036728858947754, GAN loss = [2.20297, 0.7399778, 0.8366564]\n",
      "Batch 548/700: Discriminator loss = 1.1835920810699463, GAN loss = [2.2365046, 0.75385755, 0.8563221]\n",
      "Batch 549/700: Discriminator loss = 1.2253981828689575, GAN loss = [2.2509732, 0.7365294, 0.8881457]\n",
      "Batch 550/700: Discriminator loss = 1.199253797531128, GAN loss = [2.2139308, 0.7473114, 0.8403273]\n",
      "Batch 551/700: Discriminator loss = 1.230238676071167, GAN loss = [2.2169495, 0.71869326, 0.8719662]\n",
      "Batch 552/700: Discriminator loss = 1.1788804531097412, GAN loss = [2.25973, 0.77516097, 0.85830736]\n",
      "Batch 553/700: Discriminator loss = 1.168299674987793, GAN loss = [2.2648604, 0.7641364, 0.87447715]\n",
      "Batch 554/700: Discriminator loss = 1.2033618688583374, GAN loss = [2.2683082, 0.74477303, 0.89730024]\n",
      "Batch 555/700: Discriminator loss = 1.20549476146698, GAN loss = [2.2076669, 0.7464508, 0.8349791]\n",
      "Batch 556/700: Discriminator loss = 1.2101696729660034, GAN loss = [2.2365453, 0.74362206, 0.866655]\n",
      "Batch 557/700: Discriminator loss = 1.221827745437622, GAN loss = [2.2043836, 0.7433734, 0.8347383]\n",
      "Batch 558/700: Discriminator loss = 1.2035572528839111, GAN loss = [2.2480154, 0.76359075, 0.8581622]\n",
      "Batch 559/700: Discriminator loss = 1.2185713052749634, GAN loss = [2.2122982, 0.7502842, 0.8357569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 560/700: Discriminator loss = 1.2352733612060547, GAN loss = [2.1829197, 0.726711, 0.8299928]\n",
      "Batch 561/700: Discriminator loss = 1.2120134830474854, GAN loss = [2.189997, 0.73854274, 0.82529783]\n",
      "Batch 562/700: Discriminator loss = 1.2129322290420532, GAN loss = [2.2250931, 0.7393829, 0.8595989]\n",
      "Batch 563/700: Discriminator loss = 1.2046982049942017, GAN loss = [2.1681533, 0.73574364, 0.80631757]\n",
      "Batch 564/700: Discriminator loss = 1.237059235572815, GAN loss = [2.2008176, 0.72371393, 0.85104144]\n",
      "Batch 565/700: Discriminator loss = 1.209019660949707, GAN loss = [2.228765, 0.7533569, 0.84935045]\n",
      "Batch 566/700: Discriminator loss = 1.2420283555984497, GAN loss = [2.1640313, 0.7349075, 0.8030738]\n",
      "Batch 567/700: Discriminator loss = 1.2201018333435059, GAN loss = [2.1947756, 0.745291, 0.8234478]\n",
      "Batch 568/700: Discriminator loss = 1.228495717048645, GAN loss = [2.1485012, 0.7385093, 0.783972]\n",
      "Batch 569/700: Discriminator loss = 1.2284421920776367, GAN loss = [2.2007277, 0.7433559, 0.8313784]\n",
      "Batch 570/700: Discriminator loss = 1.2396920919418335, GAN loss = [2.1323352, 0.75955576, 0.74681795]\n",
      "Batch 571/700: Discriminator loss = 1.2428971529006958, GAN loss = [2.1269636, 0.73091996, 0.770093]\n",
      "Batch 572/700: Discriminator loss = 1.2053874731063843, GAN loss = [2.2105446, 0.7947655, 0.78983897]\n",
      "Batch 573/700: Discriminator loss = 1.2372500896453857, GAN loss = [2.150561, 0.760252, 0.7643602]\n",
      "Batch 574/700: Discriminator loss = 1.2357784509658813, GAN loss = [2.1391075, 0.75867957, 0.7544868]\n",
      "Batch 575/700: Discriminator loss = 1.1929266452789307, GAN loss = [2.1727917, 0.7991726, 0.7476646]\n",
      "Batch 576/700: Discriminator loss = 1.1982450485229492, GAN loss = [2.1847634, 0.78802246, 0.7707941]\n",
      "Batch 577/700: Discriminator loss = 1.1751998662948608, GAN loss = [2.2134285, 0.8146158, 0.77288824]\n",
      "Batch 578/700: Discriminator loss = 1.1872425079345703, GAN loss = [2.1996915, 0.7878639, 0.78593254]\n",
      "Batch 579/700: Discriminator loss = 1.1662406921386719, GAN loss = [2.2153893, 0.80012316, 0.7894132]\n",
      "Batch 580/700: Discriminator loss = 1.1483092308044434, GAN loss = [2.264042, 0.84011054, 0.7981256]\n",
      "Batch 581/700: Discriminator loss = 1.1563185453414917, GAN loss = [2.3022988, 0.819109, 0.85741943]\n",
      "Batch 582/700: Discriminator loss = 1.16331148147583, GAN loss = [2.2449942, 0.8050753, 0.8141997]\n",
      "Batch 583/700: Discriminator loss = 1.164382815361023, GAN loss = [2.2790387, 0.79385877, 0.85950935]\n",
      "Batch 584/700: Discriminator loss = 1.1649882793426514, GAN loss = [2.234621, 0.794365, 0.814648]\n",
      "Batch 585/700: Discriminator loss = 1.1558315753936768, GAN loss = [2.270438, 0.79346734, 0.8514246]\n",
      "Batch 586/700: Discriminator loss = 1.1687246561050415, GAN loss = [2.2791595, 0.78488, 0.86878943]\n",
      "Batch 587/700: Discriminator loss = 1.1594839096069336, GAN loss = [2.2843752, 0.80370957, 0.8552232]\n",
      "Batch 588/700: Discriminator loss = 1.1618229150772095, GAN loss = [2.335764, 0.78549355, 0.9248836]\n",
      "Batch 589/700: Discriminator loss = 1.1988537311553955, GAN loss = [2.2489736, 0.765558, 0.8580925]\n",
      "Batch 590/700: Discriminator loss = 1.2103201150894165, GAN loss = [2.264407, 0.7493022, 0.889816]\n",
      "Batch 591/700: Discriminator loss = 1.2267255783081055, GAN loss = [2.2013829, 0.7319922, 0.8441301]\n",
      "Batch 592/700: Discriminator loss = 1.2530663013458252, GAN loss = [2.2090082, 0.73392427, 0.84985864]\n",
      "Batch 593/700: Discriminator loss = 1.2190653085708618, GAN loss = [2.196898, 0.7597338, 0.8119752]\n",
      "Batch 594/700: Discriminator loss = 1.2151895761489868, GAN loss = [2.257058, 0.7674219, 0.8644798]\n",
      "Batch 595/700: Discriminator loss = 1.2036417722702026, GAN loss = [2.2129607, 0.7666919, 0.8211348]\n",
      "Batch 596/700: Discriminator loss = 1.2361395359039307, GAN loss = [2.2427988, 0.7480147, 0.8696319]\n",
      "Batch 597/700: Discriminator loss = 1.1977407932281494, GAN loss = [2.2169824, 0.7800745, 0.8117511]\n",
      "Batch 598/700: Discriminator loss = 1.2502461671829224, GAN loss = [2.1579752, 0.7476343, 0.7851703]\n",
      "Batch 599/700: Discriminator loss = 1.2278046607971191, GAN loss = [2.1912892, 0.75650054, 0.80960876]\n",
      "Batch 600/700: Discriminator loss = 1.2065470218658447, GAN loss = [2.1845396, 0.7648545, 0.7945429]\n",
      "Batch 601/700: Discriminator loss = 1.2192978858947754, GAN loss = [2.1782324, 0.75850165, 0.79461366]\n",
      "Batch 602/700: Discriminator loss = 1.207698941230774, GAN loss = [2.174256, 0.7494537, 0.7996974]\n",
      "Batch 603/700: Discriminator loss = 1.2255079746246338, GAN loss = [2.1852417, 0.746551, 0.8135886]\n",
      "Batch 604/700: Discriminator loss = 1.1822410821914673, GAN loss = [2.1882813, 0.7733551, 0.78984433]\n",
      "Batch 605/700: Discriminator loss = 1.2007426023483276, GAN loss = [2.1440833, 0.7595597, 0.75947237]\n",
      "Batch 606/700: Discriminator loss = 1.2250791788101196, GAN loss = [2.1975508, 0.7596553, 0.8128701]\n",
      "Batch 607/700: Discriminator loss = 1.1789793968200684, GAN loss = [2.2103326, 0.77627474, 0.8090527]\n",
      "Batch 608/700: Discriminator loss = 1.1746852397918701, GAN loss = [2.2364407, 0.785089, 0.82636476]\n",
      "Batch 609/700: Discriminator loss = 1.1857982873916626, GAN loss = [2.2252762, 0.76668364, 0.8336289]\n",
      "Batch 610/700: Discriminator loss = 1.200316309928894, GAN loss = [2.2000265, 0.7473442, 0.8277324]\n",
      "Batch 611/700: Discriminator loss = 1.1636930704116821, GAN loss = [2.2032433, 0.78730094, 0.7910142]\n",
      "Batch 612/700: Discriminator loss = 1.1696770191192627, GAN loss = [2.2533822, 0.7669806, 0.8615025]\n",
      "Batch 613/700: Discriminator loss = 1.1661272048950195, GAN loss = [2.247238, 0.78321695, 0.83913875]\n",
      "Batch 614/700: Discriminator loss = 1.1734635829925537, GAN loss = [2.2466624, 0.7912368, 0.8305479]\n",
      "Batch 615/700: Discriminator loss = 1.1283069849014282, GAN loss = [2.2913315, 0.8283359, 0.8381195]\n",
      "Batch 616/700: Discriminator loss = 1.1395962238311768, GAN loss = [2.223155, 0.7998342, 0.7984452]\n",
      "Batch 617/700: Discriminator loss = 1.1526484489440918, GAN loss = [2.2624671, 0.7851438, 0.85247636]\n",
      "Batch 618/700: Discriminator loss = 1.179580807685852, GAN loss = [2.2160285, 0.75685716, 0.8343376]\n",
      "Batch 619/700: Discriminator loss = 1.1586041450500488, GAN loss = [2.283433, 0.7899031, 0.8687082]\n",
      "Batch 620/700: Discriminator loss = 1.1623194217681885, GAN loss = [2.2548883, 0.7716167, 0.85844034]\n",
      "Batch 621/700: Discriminator loss = 1.1623170375823975, GAN loss = [2.2697165, 0.7798174, 0.8650698]\n",
      "Batch 622/700: Discriminator loss = 1.1769485473632812, GAN loss = [2.282298, 0.76129854, 0.89619017]\n",
      "Batch 623/700: Discriminator loss = 1.176340103149414, GAN loss = [2.274, 0.7679241, 0.8812908]\n",
      "Batch 624/700: Discriminator loss = 1.1126526594161987, GAN loss = [2.35324, 0.8418821, 0.88658226]\n",
      "Batch 625/700: Discriminator loss = 1.176762580871582, GAN loss = [2.3290012, 0.7731898, 0.9310387]\n",
      "Batch 626/700: Discriminator loss = 1.1665958166122437, GAN loss = [2.2825403, 0.778916, 0.87884855]\n",
      "Batch 627/700: Discriminator loss = 1.172215461730957, GAN loss = [2.24287, 0.7793319, 0.8387781]\n",
      "Batch 628/700: Discriminator loss = 1.1615729331970215, GAN loss = [2.3677058, 0.79813135, 0.9448374]\n",
      "Batch 629/700: Discriminator loss = 1.1775177717208862, GAN loss = [2.349188, 0.7712075, 0.95324767]\n",
      "Batch 630/700: Discriminator loss = 1.1730824708938599, GAN loss = [2.2764719, 0.7695313, 0.88221204]\n",
      "Batch 631/700: Discriminator loss = 1.2015578746795654, GAN loss = [2.2504754, 0.7574334, 0.86832666]\n",
      "Batch 632/700: Discriminator loss = 1.1937769651412964, GAN loss = [2.225228, 0.758087, 0.8424391]\n",
      "Batch 633/700: Discriminator loss = 1.1481138467788696, GAN loss = [2.3640413, 0.8273971, 0.91196305]\n",
      "Batch 634/700: Discriminator loss = 1.1610215902328491, GAN loss = [2.3228426, 0.7895799, 0.9085933]\n",
      "Batch 635/700: Discriminator loss = 1.1675041913986206, GAN loss = [2.2881656, 0.77389276, 0.8895954]\n",
      "Batch 636/700: Discriminator loss = 1.2242621183395386, GAN loss = [2.2294416, 0.72676206, 0.87799585]\n",
      "Batch 637/700: Discriminator loss = 1.221345067024231, GAN loss = [2.2533138, 0.7389047, 0.88971007]\n",
      "Batch 638/700: Discriminator loss = 1.2406163215637207, GAN loss = [2.2188616, 0.7405199, 0.8536192]\n",
      "Batch 639/700: Discriminator loss = 1.2357805967330933, GAN loss = [2.2491524, 0.7571679, 0.86725706]\n",
      "Batch 640/700: Discriminator loss = 1.237025260925293, GAN loss = [2.2129154, 0.7448324, 0.84331864]\n",
      "Batch 641/700: Discriminator loss = 1.2491811513900757, GAN loss = [2.2109554, 0.7342115, 0.8519485]\n",
      "Batch 642/700: Discriminator loss = 1.2525309324264526, GAN loss = [2.1747925, 0.73173463, 0.81824094]\n",
      "Batch 643/700: Discriminator loss = 1.2107843160629272, GAN loss = [2.2054884, 0.7493505, 0.8313028]\n",
      "Batch 644/700: Discriminator loss = 1.2340149879455566, GAN loss = [2.2010758, 0.762058, 0.8142081]\n",
      "Batch 645/700: Discriminator loss = 1.1833457946777344, GAN loss = [2.2228367, 0.7591441, 0.8388923]\n",
      "Batch 646/700: Discriminator loss = 1.182421088218689, GAN loss = [2.2297165, 0.7750694, 0.8298983]\n",
      "Batch 647/700: Discriminator loss = 1.1996842622756958, GAN loss = [2.2137914, 0.76433617, 0.8247767]\n",
      "Batch 648/700: Discriminator loss = 1.184596061706543, GAN loss = [2.2428763, 0.7735217, 0.844731]\n",
      "Batch 649/700: Discriminator loss = 1.1619786024093628, GAN loss = [2.2794843, 0.7995633, 0.8553609]\n",
      "Batch 650/700: Discriminator loss = 1.1554046869277954, GAN loss = [2.294052, 0.7914895, 0.8780687]\n",
      "Batch 651/700: Discriminator loss = 1.2048735618591309, GAN loss = [2.252835, 0.7642643, 0.864142]\n",
      "Batch 652/700: Discriminator loss = 1.196847915649414, GAN loss = [2.227286, 0.7606981, 0.8422224]\n",
      "Batch 653/700: Discriminator loss = 1.2063127756118774, GAN loss = [2.2540498, 0.74451005, 0.88523734]\n",
      "Batch 654/700: Discriminator loss = 1.1751371622085571, GAN loss = [2.2593946, 0.7737489, 0.8613956]\n",
      "Batch 655/700: Discriminator loss = 1.197459101676941, GAN loss = [2.3138983, 0.7584801, 0.93123686]\n",
      "Batch 656/700: Discriminator loss = 1.1858006715774536, GAN loss = [2.2816455, 0.7701163, 0.8874217]\n",
      "Batch 657/700: Discriminator loss = 1.2306915521621704, GAN loss = [2.2255702, 0.73382896, 0.8676967]\n",
      "Batch 658/700: Discriminator loss = 1.1914710998535156, GAN loss = [2.2459333, 0.7512727, 0.87068856]\n",
      "Batch 659/700: Discriminator loss = 1.2082124948501587, GAN loss = [2.23525, 0.7572111, 0.8541292]\n",
      "Batch 660/700: Discriminator loss = 1.2014498710632324, GAN loss = [2.2445962, 0.74605674, 0.8747082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 661/700: Discriminator loss = 1.213157057762146, GAN loss = [2.24095, 0.75045705, 0.86673546]\n",
      "Batch 662/700: Discriminator loss = 1.2130502462387085, GAN loss = [2.2292824, 0.74805206, 0.85754126]\n",
      "Batch 663/700: Discriminator loss = 1.2028895616531372, GAN loss = [2.2068708, 0.74639404, 0.8368482]\n",
      "Batch 664/700: Discriminator loss = 1.1875396966934204, GAN loss = [2.2270758, 0.7469662, 0.8565266]\n",
      "Batch 665/700: Discriminator loss = 1.205207347869873, GAN loss = [2.2096539, 0.73421156, 0.85189164]\n",
      "Batch 666/700: Discriminator loss = 1.2106927633285522, GAN loss = [2.2176182, 0.7370778, 0.85703164]\n",
      "Batch 667/700: Discriminator loss = 1.1949249505996704, GAN loss = [2.2116573, 0.73586625, 0.8523126]\n",
      "Batch 668/700: Discriminator loss = 1.2270472049713135, GAN loss = [2.1787739, 0.71340126, 0.8419313]\n",
      "Batch 669/700: Discriminator loss = 1.2196664810180664, GAN loss = [2.2291913, 0.721466, 0.88432205]\n",
      "Batch 670/700: Discriminator loss = 1.2234967947006226, GAN loss = [2.1773639, 0.71951485, 0.83447284]\n",
      "Batch 671/700: Discriminator loss = 1.2273145914077759, GAN loss = [2.1915746, 0.7436385, 0.82458895]\n",
      "Batch 672/700: Discriminator loss = 1.2278225421905518, GAN loss = [2.164338, 0.7265709, 0.81444204]\n",
      "Batch 673/700: Discriminator loss = 1.2171425819396973, GAN loss = [2.1792216, 0.7365631, 0.8193718]\n",
      "Batch 674/700: Discriminator loss = 1.204091191291809, GAN loss = [2.197149, 0.74803734, 0.8258662]\n",
      "Batch 675/700: Discriminator loss = 1.2008347511291504, GAN loss = [2.199009, 0.75411147, 0.82166743]\n",
      "Batch 676/700: Discriminator loss = 1.2174179553985596, GAN loss = [2.1951847, 0.7427992, 0.82915694]\n",
      "Batch 677/700: Discriminator loss = 1.1932344436645508, GAN loss = [2.2500992, 0.7543509, 0.87250847]\n",
      "Batch 678/700: Discriminator loss = 1.1995716094970703, GAN loss = [2.2354069, 0.74137735, 0.87079257]\n",
      "Batch 679/700: Discriminator loss = 1.1908327341079712, GAN loss = [2.2422516, 0.7570128, 0.8620216]\n",
      "Batch 680/700: Discriminator loss = 1.2117526531219482, GAN loss = [2.1858025, 0.7377441, 0.82487017]\n",
      "Batch 681/700: Discriminator loss = 1.2017580270767212, GAN loss = [2.2023335, 0.7508247, 0.8283565]\n",
      "Batch 682/700: Discriminator loss = 1.2306406497955322, GAN loss = [2.2100055, 0.73989594, 0.8469915]\n",
      "Batch 683/700: Discriminator loss = 1.1988650560379028, GAN loss = [2.1853454, 0.75664955, 0.80560815]\n",
      "Batch 684/700: Discriminator loss = 1.1997400522232056, GAN loss = [2.247866, 0.76335853, 0.861432]\n",
      "Batch 685/700: Discriminator loss = 1.206736445426941, GAN loss = [2.2276587, 0.7363083, 0.86827326]\n",
      "Batch 686/700: Discriminator loss = 1.2090017795562744, GAN loss = [2.2439027, 0.7446466, 0.8761763]\n",
      "Batch 687/700: Discriminator loss = 1.1895569562911987, GAN loss = [2.2623284, 0.75412554, 0.88515395]\n",
      "Batch 688/700: Discriminator loss = 1.1990407705307007, GAN loss = [2.2238586, 0.75797224, 0.8428591]\n",
      "Batch 689/700: Discriminator loss = 1.1740550994873047, GAN loss = [2.3000426, 0.7783198, 0.89871454]\n",
      "Batch 690/700: Discriminator loss = 1.2108300924301147, GAN loss = [2.280948, 0.74794024, 0.9100156]\n",
      "Batch 691/700: Discriminator loss = 1.181738257408142, GAN loss = [2.2103343, 0.7868247, 0.800535]\n",
      "Batch 692/700: Discriminator loss = 1.1801915168762207, GAN loss = [2.249696, 0.7870586, 0.8396656]\n",
      "Batch 693/700: Discriminator loss = 1.1912050247192383, GAN loss = [2.2206519, 0.76771975, 0.82995725]\n",
      "Batch 694/700: Discriminator loss = 1.2025469541549683, GAN loss = [2.2504852, 0.7631961, 0.8642892]\n",
      "Batch 695/700: Discriminator loss = 1.1808958053588867, GAN loss = [2.2297652, 0.79259664, 0.8141621]\n",
      "Batch 696/700: Discriminator loss = 1.2349181175231934, GAN loss = [2.1976416, 0.7230476, 0.85157907]\n",
      "Batch 697/700: Discriminator loss = 1.1906932592391968, GAN loss = [2.2532187, 0.7722228, 0.8579781]\n",
      "Batch 698/700: Discriminator loss = 1.1937967538833618, GAN loss = [2.2257578, 0.76656586, 0.8361734]\n",
      "Batch 699/700: Discriminator loss = 1.1599246263504028, GAN loss = [2.281525, 0.7956793, 0.8628244]\n",
      "Batch 700/700: Discriminator loss = 1.1922105550765991, GAN loss = [2.2490206, 0.7635202, 0.8624911]\n",
      "Epoch 23/30\n",
      "Batch 1/700: Discriminator loss = 1.1897814273834229, GAN loss = [2.3083472, 0.76542914, 0.91993415]\n",
      "Batch 2/700: Discriminator loss = 1.1608284711837769, GAN loss = [2.2900302, 0.7950357, 0.87203187]\n",
      "Batch 3/700: Discriminator loss = 1.1550687551498413, GAN loss = [2.2240012, 0.7913627, 0.80970824]\n",
      "Batch 4/700: Discriminator loss = 1.1670167446136475, GAN loss = [2.279461, 0.76770675, 0.88884974]\n",
      "Batch 5/700: Discriminator loss = 1.1420464515686035, GAN loss = [2.251741, 0.7982461, 0.8306294]\n",
      "Batch 6/700: Discriminator loss = 1.1505873203277588, GAN loss = [2.3209784, 0.7751579, 0.9230011]\n",
      "Batch 7/700: Discriminator loss = 1.1574821472167969, GAN loss = [2.252826, 0.7762901, 0.8537648]\n",
      "Batch 8/700: Discriminator loss = 1.1490039825439453, GAN loss = [2.2829688, 0.7836626, 0.87656623]\n",
      "Batch 9/700: Discriminator loss = 1.1332985162734985, GAN loss = [2.370338, 0.8012768, 0.9463664]\n",
      "Batch 10/700: Discriminator loss = 1.166259765625, GAN loss = [2.2507098, 0.7606389, 0.8674145]\n",
      "Batch 11/700: Discriminator loss = 1.1554114818572998, GAN loss = [2.304473, 0.78326005, 0.8985967]\n",
      "Batch 12/700: Discriminator loss = 1.1379121541976929, GAN loss = [2.2740695, 0.7948349, 0.8566662]\n",
      "Batch 13/700: Discriminator loss = 1.1651935577392578, GAN loss = [2.283603, 0.7667081, 0.8943655]\n",
      "Batch 14/700: Discriminator loss = 1.1747310161590576, GAN loss = [2.266228, 0.75524443, 0.88848823]\n",
      "Batch 15/700: Discriminator loss = 1.1729708909988403, GAN loss = [2.2305002, 0.75778806, 0.85025245]\n",
      "Batch 16/700: Discriminator loss = 1.1657339334487915, GAN loss = [2.227451, 0.76129097, 0.8437484]\n",
      "Batch 17/700: Discriminator loss = 1.1771626472473145, GAN loss = [2.267994, 0.7579033, 0.88771456]\n",
      "Batch 18/700: Discriminator loss = 1.1781888008117676, GAN loss = [2.2434692, 0.7447238, 0.87638664]\n",
      "Batch 19/700: Discriminator loss = 1.1452348232269287, GAN loss = [2.2789774, 0.78433174, 0.87229925]\n",
      "Batch 20/700: Discriminator loss = 1.1812942028045654, GAN loss = [2.2667797, 0.7603309, 0.8841283]\n",
      "Batch 21/700: Discriminator loss = 1.1750491857528687, GAN loss = [2.2854369, 0.76413363, 0.8990084]\n",
      "Batch 22/700: Discriminator loss = 1.1727343797683716, GAN loss = [2.304388, 0.7581855, 0.92391884]\n",
      "Batch 23/700: Discriminator loss = 1.203306794166565, GAN loss = [2.255451, 0.74341196, 0.8897435]\n",
      "Batch 24/700: Discriminator loss = 1.1880831718444824, GAN loss = [2.2655392, 0.7540766, 0.8891473]\n",
      "Batch 25/700: Discriminator loss = 1.2112337350845337, GAN loss = [2.2100508, 0.73274535, 0.8549884]\n",
      "Batch 26/700: Discriminator loss = 1.1911282539367676, GAN loss = [2.2528577, 0.74990785, 0.8806267]\n",
      "Batch 27/700: Discriminator loss = 1.2000850439071655, GAN loss = [2.234344, 0.7391503, 0.87286216]\n",
      "Batch 28/700: Discriminator loss = 1.2087410688400269, GAN loss = [2.1949174, 0.72669894, 0.8458789]\n",
      "Batch 29/700: Discriminator loss = 1.2090364694595337, GAN loss = [2.2563903, 0.73570406, 0.89833504]\n",
      "Batch 30/700: Discriminator loss = 1.2059978246688843, GAN loss = [2.2381773, 0.7401096, 0.87571025]\n",
      "Batch 31/700: Discriminator loss = 1.2182276248931885, GAN loss = [2.2198653, 0.7245427, 0.8729692]\n",
      "Batch 32/700: Discriminator loss = 1.211337924003601, GAN loss = [2.2049153, 0.73991233, 0.8426497]\n",
      "Batch 33/700: Discriminator loss = 1.2186070680618286, GAN loss = [2.222774, 0.7314652, 0.86894447]\n",
      "Batch 34/700: Discriminator loss = 1.2208876609802246, GAN loss = [2.2118106, 0.729062, 0.8603794]\n",
      "Batch 35/700: Discriminator loss = 1.2291821241378784, GAN loss = [2.167797, 0.7225097, 0.8229079]\n",
      "Batch 36/700: Discriminator loss = 1.2158925533294678, GAN loss = [2.1942809, 0.7218953, 0.85001993]\n",
      "Batch 37/700: Discriminator loss = 1.231129765510559, GAN loss = [2.1775708, 0.70508283, 0.8501249]\n",
      "Batch 38/700: Discriminator loss = 1.2000164985656738, GAN loss = [2.22804, 0.7408728, 0.86480707]\n",
      "Batch 39/700: Discriminator loss = 1.2054896354675293, GAN loss = [2.1976032, 0.72702324, 0.8482111]\n",
      "Batch 40/700: Discriminator loss = 1.1996006965637207, GAN loss = [2.2087502, 0.7273939, 0.8589936]\n",
      "Batch 41/700: Discriminator loss = 1.1995105743408203, GAN loss = [2.2483573, 0.73649246, 0.88949496]\n",
      "Batch 42/700: Discriminator loss = 1.2151384353637695, GAN loss = [2.1916456, 0.7243868, 0.84488523]\n",
      "Batch 43/700: Discriminator loss = 1.2074236869812012, GAN loss = [2.1942804, 0.7250965, 0.8467934]\n",
      "Batch 44/700: Discriminator loss = 1.2010414600372314, GAN loss = [2.1755528, 0.71889013, 0.8342735]\n",
      "Batch 45/700: Discriminator loss = 1.1866658926010132, GAN loss = [2.187474, 0.73297507, 0.83210784]\n",
      "Batch 46/700: Discriminator loss = 1.1767040491104126, GAN loss = [2.2062418, 0.7723189, 0.8115509]\n",
      "Batch 47/700: Discriminator loss = 1.1862949132919312, GAN loss = [2.2220056, 0.74767894, 0.8519737]\n",
      "Batch 48/700: Discriminator loss = 1.1939425468444824, GAN loss = [2.2440643, 0.7512548, 0.870487]\n",
      "Batch 49/700: Discriminator loss = 1.1872972249984741, GAN loss = [2.2223918, 0.74577624, 0.85430306]\n",
      "Batch 50/700: Discriminator loss = 1.1714001893997192, GAN loss = [2.216605, 0.759972, 0.8343266]\n",
      "Batch 51/700: Discriminator loss = 1.177920937538147, GAN loss = [2.2324467, 0.75355303, 0.8565924]\n",
      "Batch 52/700: Discriminator loss = 1.197866678237915, GAN loss = [2.2075584, 0.73647606, 0.8487951]\n",
      "Batch 53/700: Discriminator loss = 1.1835743188858032, GAN loss = [2.2097163, 0.74458444, 0.8428572]\n",
      "Batch 54/700: Discriminator loss = 1.183815598487854, GAN loss = [2.2127728, 0.7367139, 0.85379064]\n",
      "Batch 55/700: Discriminator loss = 1.156764030456543, GAN loss = [2.244542, 0.7717773, 0.85047525]\n",
      "Batch 56/700: Discriminator loss = 1.1891250610351562, GAN loss = [2.234832, 0.7498414, 0.86269456]\n",
      "Batch 57/700: Discriminator loss = 1.1902050971984863, GAN loss = [2.220066, 0.7367355, 0.8610573]\n",
      "Batch 58/700: Discriminator loss = 1.1849381923675537, GAN loss = [2.227987, 0.74283427, 0.86289704]\n",
      "Batch 59/700: Discriminator loss = 1.195504069328308, GAN loss = [2.2440753, 0.736367, 0.88545495]\n",
      "Batch 60/700: Discriminator loss = 1.179304838180542, GAN loss = [2.263381, 0.7532322, 0.8878842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 61/700: Discriminator loss = 1.1895842552185059, GAN loss = [2.2490687, 0.74350405, 0.8832621]\n",
      "Batch 62/700: Discriminator loss = 1.1804397106170654, GAN loss = [2.2137842, 0.7413016, 0.8501812]\n",
      "Batch 63/700: Discriminator loss = 1.1686097383499146, GAN loss = [2.2605197, 0.7631185, 0.8750968]\n",
      "Batch 64/700: Discriminator loss = 1.2086907625198364, GAN loss = [2.2649453, 0.7287387, 0.9138933]\n",
      "Batch 65/700: Discriminator loss = 1.1806029081344604, GAN loss = [2.229429, 0.7469132, 0.8601858]\n",
      "Batch 66/700: Discriminator loss = 1.2253493070602417, GAN loss = [2.1561859, 0.70320994, 0.83063287]\n",
      "Batch 67/700: Discriminator loss = 1.1948614120483398, GAN loss = [2.2444944, 0.7275279, 0.8946347]\n",
      "Batch 68/700: Discriminator loss = 1.1853077411651611, GAN loss = [2.2442744, 0.7407614, 0.88116723]\n",
      "Batch 69/700: Discriminator loss = 1.2117955684661865, GAN loss = [2.1677544, 0.7174839, 0.8279178]\n",
      "Batch 70/700: Discriminator loss = 1.1966570615768433, GAN loss = [2.2021177, 0.7248988, 0.854844]\n",
      "Batch 71/700: Discriminator loss = 1.1867432594299316, GAN loss = [2.2267733, 0.74498934, 0.8594056]\n",
      "Batch 72/700: Discriminator loss = 1.1916148662567139, GAN loss = [2.1491857, 0.7324179, 0.7944023]\n",
      "Batch 73/700: Discriminator loss = 1.2121883630752563, GAN loss = [2.1626601, 0.71558726, 0.8247253]\n",
      "Batch 74/700: Discriminator loss = 1.1859527826309204, GAN loss = [2.1874905, 0.7320876, 0.8330652]\n",
      "Batch 75/700: Discriminator loss = 1.194761037826538, GAN loss = [2.1716132, 0.7307319, 0.8185598]\n",
      "Batch 76/700: Discriminator loss = 1.181523084640503, GAN loss = [2.2005973, 0.7342654, 0.84402525]\n",
      "Batch 77/700: Discriminator loss = 1.1979612112045288, GAN loss = [2.1636755, 0.7185622, 0.8228256]\n",
      "Batch 78/700: Discriminator loss = 1.200239658355713, GAN loss = [2.1761458, 0.71751404, 0.8363743]\n",
      "Batch 79/700: Discriminator loss = 1.1800885200500488, GAN loss = [2.2301998, 0.74686736, 0.86109704]\n",
      "Batch 80/700: Discriminator loss = 1.1815160512924194, GAN loss = [2.1633263, 0.74214303, 0.7989688]\n",
      "Batch 81/700: Discriminator loss = 1.1881660223007202, GAN loss = [2.2376535, 0.74021554, 0.8752494]\n",
      "Batch 82/700: Discriminator loss = 1.1932553052902222, GAN loss = [2.1815968, 0.7373376, 0.82209086]\n",
      "Batch 83/700: Discriminator loss = 1.1999297142028809, GAN loss = [2.224205, 0.735109, 0.8669431]\n",
      "Batch 84/700: Discriminator loss = 1.1890902519226074, GAN loss = [2.1765804, 0.73530763, 0.81914085]\n",
      "Batch 85/700: Discriminator loss = 1.1857569217681885, GAN loss = [2.1962702, 0.74632156, 0.8278435]\n",
      "Batch 86/700: Discriminator loss = 1.190709114074707, GAN loss = [2.1930594, 0.7430508, 0.8279296]\n",
      "Batch 87/700: Discriminator loss = 1.1817576885223389, GAN loss = [2.206087, 0.7540515, 0.82998735]\n",
      "Batch 88/700: Discriminator loss = 1.2002127170562744, GAN loss = [2.197791, 0.7365172, 0.8392426]\n",
      "Batch 89/700: Discriminator loss = 1.200641393661499, GAN loss = [2.1950858, 0.72616494, 0.8469115]\n",
      "Batch 90/700: Discriminator loss = 1.1718846559524536, GAN loss = [2.2525022, 0.7535804, 0.87693655]\n",
      "Batch 91/700: Discriminator loss = 1.2049546241760254, GAN loss = [2.152476, 0.7272328, 0.80327255]\n",
      "Batch 92/700: Discriminator loss = 1.1785422563552856, GAN loss = [2.195571, 0.7465757, 0.82702994]\n",
      "Batch 93/700: Discriminator loss = 1.1800369024276733, GAN loss = [2.2402012, 0.7458738, 0.8723658]\n",
      "Batch 94/700: Discriminator loss = 1.1881862878799438, GAN loss = [2.18967, 0.7377254, 0.8299916]\n",
      "Batch 95/700: Discriminator loss = 1.179060459136963, GAN loss = [2.2403176, 0.75880796, 0.8595742]\n",
      "Batch 96/700: Discriminator loss = 1.1565107107162476, GAN loss = [2.1824605, 0.7682942, 0.7922412]\n",
      "Batch 97/700: Discriminator loss = 1.2117539644241333, GAN loss = [2.2041955, 0.7189593, 0.8632898]\n",
      "Batch 98/700: Discriminator loss = 1.1852303743362427, GAN loss = [2.2322006, 0.7437828, 0.8664475]\n",
      "Batch 99/700: Discriminator loss = 1.187057614326477, GAN loss = [2.228192, 0.7378948, 0.8683137]\n",
      "Batch 100/700: Discriminator loss = 1.2032829523086548, GAN loss = [2.225025, 0.7219072, 0.8811305]\n",
      "Batch 101/700: Discriminator loss = 1.1970809698104858, GAN loss = [2.268747, 0.7390368, 0.90774065]\n",
      "Batch 102/700: Discriminator loss = 1.1909527778625488, GAN loss = [2.22372, 0.7296101, 0.87216264]\n",
      "Batch 103/700: Discriminator loss = 1.1748738288879395, GAN loss = [2.2115364, 0.7518687, 0.8377596]\n",
      "Batch 104/700: Discriminator loss = 1.1629408597946167, GAN loss = [2.2646239, 0.7746369, 0.86812]\n",
      "Batch 105/700: Discriminator loss = 1.1727601289749146, GAN loss = [2.2552428, 0.75452477, 0.8788757]\n",
      "Batch 106/700: Discriminator loss = 1.1743526458740234, GAN loss = [2.2455962, 0.7517419, 0.8720405]\n",
      "Batch 107/700: Discriminator loss = 1.1570713520050049, GAN loss = [2.265931, 0.76605797, 0.87810725]\n",
      "Batch 108/700: Discriminator loss = 1.1708546876907349, GAN loss = [2.2516303, 0.7601192, 0.8697875]\n",
      "Batch 109/700: Discriminator loss = 1.1759707927703857, GAN loss = [2.211932, 0.7457496, 0.8444827]\n",
      "Batch 110/700: Discriminator loss = 1.1600863933563232, GAN loss = [2.2934039, 0.76521325, 0.9065296]\n",
      "Batch 111/700: Discriminator loss = 1.1550085544586182, GAN loss = [2.3119977, 0.77479476, 0.9155748]\n",
      "Batch 112/700: Discriminator loss = 1.1912018060684204, GAN loss = [2.2712142, 0.7541891, 0.8954178]\n",
      "Batch 113/700: Discriminator loss = 1.1485927104949951, GAN loss = [2.3415105, 0.78055274, 0.9393626]\n",
      "Batch 114/700: Discriminator loss = 1.1615562438964844, GAN loss = [2.3207638, 0.7666929, 0.93248004]\n",
      "Batch 115/700: Discriminator loss = 1.1892492771148682, GAN loss = [2.2926683, 0.7502433, 0.9208362]\n",
      "Batch 116/700: Discriminator loss = 1.174302339553833, GAN loss = [2.245747, 0.7588199, 0.8653689]\n",
      "Batch 117/700: Discriminator loss = 1.197403073310852, GAN loss = [2.2416046, 0.72322136, 0.89685386]\n",
      "Batch 118/700: Discriminator loss = 1.1964917182922363, GAN loss = [2.212378, 0.737614, 0.8532451]\n",
      "Batch 119/700: Discriminator loss = 1.2092891931533813, GAN loss = [2.2061706, 0.7258674, 0.8587924]\n",
      "Batch 120/700: Discriminator loss = 1.2215055227279663, GAN loss = [2.1924164, 0.7193833, 0.85152084]\n",
      "Batch 121/700: Discriminator loss = 1.2212178707122803, GAN loss = [2.254887, 0.7372567, 0.89611053]\n",
      "Batch 122/700: Discriminator loss = 1.2327203750610352, GAN loss = [2.1891391, 0.72327113, 0.84433174]\n",
      "Batch 123/700: Discriminator loss = 1.223284363746643, GAN loss = [2.1921766, 0.72599846, 0.84464407]\n",
      "Batch 124/700: Discriminator loss = 1.2363673448562622, GAN loss = [2.1874132, 0.7398276, 0.8260559]\n",
      "Batch 125/700: Discriminator loss = 1.2191613912582397, GAN loss = [2.2745876, 0.7641243, 0.8889377]\n",
      "Batch 126/700: Discriminator loss = 1.1989737749099731, GAN loss = [2.267771, 0.7802573, 0.8659906]\n",
      "Batch 127/700: Discriminator loss = 1.2235448360443115, GAN loss = [2.1903355, 0.7433262, 0.8254795]\n",
      "Batch 128/700: Discriminator loss = 1.1758748292922974, GAN loss = [2.2251759, 0.7769403, 0.826722]\n",
      "Batch 129/700: Discriminator loss = 1.2002419233322144, GAN loss = [2.1709871, 0.7603845, 0.78910965]\n",
      "Batch 130/700: Discriminator loss = 1.2123373746871948, GAN loss = [2.187063, 0.7471771, 0.8184243]\n",
      "Batch 131/700: Discriminator loss = 1.1687133312225342, GAN loss = [2.2071476, 0.79997575, 0.7857348]\n",
      "Batch 132/700: Discriminator loss = 1.2194513082504272, GAN loss = [2.1504478, 0.747123, 0.78192437]\n",
      "Batch 133/700: Discriminator loss = 1.2129504680633545, GAN loss = [2.1181922, 0.7520363, 0.74476427]\n",
      "Batch 134/700: Discriminator loss = 1.2009700536727905, GAN loss = [2.134172, 0.7588904, 0.7538936]\n",
      "Batch 135/700: Discriminator loss = 1.2023634910583496, GAN loss = [2.145767, 0.7619643, 0.762419]\n",
      "Batch 136/700: Discriminator loss = 1.2181321382522583, GAN loss = [2.11061, 0.73898286, 0.7502396]\n",
      "Batch 137/700: Discriminator loss = 1.211455225944519, GAN loss = [2.1258438, 0.74714804, 0.7573101]\n",
      "Batch 138/700: Discriminator loss = 1.2110424041748047, GAN loss = [2.1476939, 0.73854834, 0.78777444]\n",
      "Batch 139/700: Discriminator loss = 1.2102806568145752, GAN loss = [2.1215987, 0.7378294, 0.7624048]\n",
      "Batch 140/700: Discriminator loss = 1.1934949159622192, GAN loss = [2.1423619, 0.7598374, 0.7611792]\n",
      "Batch 141/700: Discriminator loss = 1.2195109128952026, GAN loss = [2.108517, 0.7280137, 0.75917125]\n",
      "Batch 142/700: Discriminator loss = 1.2184139490127563, GAN loss = [2.1249948, 0.7220684, 0.78159785]\n",
      "Batch 143/700: Discriminator loss = 1.2145495414733887, GAN loss = [2.107299, 0.72357893, 0.7623768]\n",
      "Batch 144/700: Discriminator loss = 1.2123056650161743, GAN loss = [2.1234398, 0.72936517, 0.772733]\n",
      "Batch 145/700: Discriminator loss = 1.2158175706863403, GAN loss = [2.0766594, 0.7143798, 0.7409644]\n",
      "Batch 146/700: Discriminator loss = 1.2118852138519287, GAN loss = [2.1415257, 0.7228592, 0.79737544]\n",
      "Batch 147/700: Discriminator loss = 1.2039316892623901, GAN loss = [2.1814983, 0.72710943, 0.83310133]\n",
      "Batch 148/700: Discriminator loss = 1.2109897136688232, GAN loss = [2.1590583, 0.7218116, 0.8159674]\n",
      "Batch 149/700: Discriminator loss = 1.1943435668945312, GAN loss = [2.1409113, 0.72924006, 0.7904022]\n",
      "Batch 150/700: Discriminator loss = 1.1989487409591675, GAN loss = [2.1564171, 0.72809553, 0.8070791]\n",
      "Batch 151/700: Discriminator loss = 1.2131221294403076, GAN loss = [2.1294384, 0.72347045, 0.7847363]\n",
      "Batch 152/700: Discriminator loss = 1.2101750373840332, GAN loss = [2.1235487, 0.71408385, 0.78823304]\n",
      "Batch 153/700: Discriminator loss = 1.2131472826004028, GAN loss = [2.130876, 0.71052915, 0.7991083]\n",
      "Batch 154/700: Discriminator loss = 1.2198173999786377, GAN loss = [2.1549354, 0.70967996, 0.82403487]\n",
      "Batch 155/700: Discriminator loss = 1.195939064025879, GAN loss = [2.1935718, 0.72704256, 0.8453249]\n",
      "Batch 156/700: Discriminator loss = 1.2042655944824219, GAN loss = [2.1597824, 0.7245401, 0.8140561]\n",
      "Batch 157/700: Discriminator loss = 1.1981877088546753, GAN loss = [2.1429436, 0.7276356, 0.7941394]\n",
      "Batch 158/700: Discriminator loss = 1.2238233089447021, GAN loss = [2.14388, 0.70908403, 0.8136441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 159/700: Discriminator loss = 1.2048529386520386, GAN loss = [2.1368845, 0.7281838, 0.78755593]\n",
      "Batch 160/700: Discriminator loss = 1.214980959892273, GAN loss = [2.1422133, 0.7145604, 0.8065181]\n",
      "Batch 161/700: Discriminator loss = 1.2176367044448853, GAN loss = [2.137862, 0.70449996, 0.8122277]\n",
      "Batch 162/700: Discriminator loss = 1.2255315780639648, GAN loss = [2.1320255, 0.7164116, 0.79449534]\n",
      "Batch 163/700: Discriminator loss = 1.197355031967163, GAN loss = [2.2397559, 0.73514867, 0.8834553]\n",
      "Batch 164/700: Discriminator loss = 1.1942739486694336, GAN loss = [2.1395354, 0.75116277, 0.767195]\n",
      "Batch 165/700: Discriminator loss = 1.208099603652954, GAN loss = [2.159788, 0.7301268, 0.8084788]\n",
      "Batch 166/700: Discriminator loss = 1.1869438886642456, GAN loss = [2.2265823, 0.7641549, 0.8412375]\n",
      "Batch 167/700: Discriminator loss = 1.1552560329437256, GAN loss = [2.2872396, 0.7747324, 0.89131415]\n",
      "Batch 168/700: Discriminator loss = 1.1644421815872192, GAN loss = [2.20692, 0.75247073, 0.83325934]\n",
      "Batch 169/700: Discriminator loss = 1.1582847833633423, GAN loss = [2.251554, 0.76403207, 0.8663339]\n",
      "Batch 170/700: Discriminator loss = 1.1700537204742432, GAN loss = [2.2468073, 0.7724863, 0.8531449]\n",
      "Batch 171/700: Discriminator loss = 1.1944046020507812, GAN loss = [2.2090073, 0.72586995, 0.86195076]\n",
      "Batch 172/700: Discriminator loss = 1.1810576915740967, GAN loss = [2.2255068, 0.74228144, 0.8620341]\n",
      "Batch 173/700: Discriminator loss = 1.1982436180114746, GAN loss = [2.2261934, 0.7368204, 0.8681845]\n",
      "Batch 174/700: Discriminator loss = 1.2034437656402588, GAN loss = [2.2473533, 0.7212403, 0.90492]\n",
      "Batch 175/700: Discriminator loss = 1.2065495252609253, GAN loss = [2.236913, 0.71663404, 0.8990791]\n",
      "Batch 176/700: Discriminator loss = 1.1622394323349, GAN loss = [2.300201, 0.76430076, 0.91467565]\n",
      "Batch 177/700: Discriminator loss = 1.190643548965454, GAN loss = [2.2435598, 0.7414666, 0.8808493]\n",
      "Batch 178/700: Discriminator loss = 1.205769419670105, GAN loss = [2.2356417, 0.72214323, 0.8922274]\n",
      "Batch 179/700: Discriminator loss = 1.1983269453048706, GAN loss = [2.2935898, 0.7432091, 0.92911017]\n",
      "Batch 180/700: Discriminator loss = 1.2040504217147827, GAN loss = [2.2198193, 0.7379083, 0.8606451]\n",
      "Batch 181/700: Discriminator loss = 1.1865838766098022, GAN loss = [2.2278411, 0.7397735, 0.86681384]\n",
      "Batch 182/700: Discriminator loss = 1.1850519180297852, GAN loss = [2.255049, 0.7418137, 0.8919994]\n",
      "Batch 183/700: Discriminator loss = 1.1978191137313843, GAN loss = [2.2480395, 0.7418753, 0.88494474]\n",
      "Batch 184/700: Discriminator loss = 1.1885695457458496, GAN loss = [2.25072, 0.73792, 0.8915931]\n",
      "Batch 185/700: Discriminator loss = 1.1766316890716553, GAN loss = [2.2956357, 0.7551496, 0.9192837]\n",
      "Batch 186/700: Discriminator loss = 1.1886094808578491, GAN loss = [2.2601695, 0.7472442, 0.8917048]\n",
      "Batch 187/700: Discriminator loss = 1.166746735572815, GAN loss = [2.289943, 0.76543623, 0.9033048]\n",
      "Batch 188/700: Discriminator loss = 1.1635076999664307, GAN loss = [2.2295322, 0.7591838, 0.8491846]\n",
      "Batch 189/700: Discriminator loss = 1.1551042795181274, GAN loss = [2.2773266, 0.76781654, 0.88839996]\n",
      "Batch 190/700: Discriminator loss = 1.180869460105896, GAN loss = [2.208202, 0.7459302, 0.8412032]\n",
      "Batch 191/700: Discriminator loss = 1.1771750450134277, GAN loss = [2.1928725, 0.7504627, 0.8213761]\n",
      "Batch 192/700: Discriminator loss = 1.175196647644043, GAN loss = [2.2208717, 0.75501883, 0.84485054]\n",
      "Batch 193/700: Discriminator loss = 1.1605874300003052, GAN loss = [2.2301137, 0.7506231, 0.85851264]\n",
      "Batch 194/700: Discriminator loss = 1.1819067001342773, GAN loss = [2.1817825, 0.7338841, 0.8269501]\n",
      "Batch 195/700: Discriminator loss = 1.1750986576080322, GAN loss = [2.250891, 0.7544254, 0.87556565]\n",
      "Batch 196/700: Discriminator loss = 1.173453450202942, GAN loss = [2.2055674, 0.74818367, 0.8365261]\n",
      "Batch 197/700: Discriminator loss = 1.1934486627578735, GAN loss = [2.2163363, 0.7387671, 0.8567342]\n",
      "Batch 198/700: Discriminator loss = 1.1994529962539673, GAN loss = [2.2220283, 0.7269077, 0.8743021]\n",
      "Batch 199/700: Discriminator loss = 1.187514066696167, GAN loss = [2.2103415, 0.7317932, 0.8577392]\n",
      "Batch 200/700: Discriminator loss = 1.1875356435775757, GAN loss = [2.2449534, 0.7345388, 0.8895962]\n",
      "Batch 201/700: Discriminator loss = 1.2112393379211426, GAN loss = [2.2113664, 0.7287941, 0.86176187]\n",
      "Batch 202/700: Discriminator loss = 1.1932108402252197, GAN loss = [2.1882412, 0.7344574, 0.83299196]\n",
      "Batch 203/700: Discriminator loss = 1.204179286956787, GAN loss = [2.170267, 0.723629, 0.8258558]\n",
      "Batch 204/700: Discriminator loss = 1.1992741823196411, GAN loss = [2.1773527, 0.71794516, 0.83862025]\n",
      "Batch 205/700: Discriminator loss = 1.2057586908340454, GAN loss = [2.1859546, 0.7186704, 0.8465028]\n",
      "Batch 206/700: Discriminator loss = 1.1757917404174805, GAN loss = [2.21843, 0.74183166, 0.8558246]\n",
      "Batch 207/700: Discriminator loss = 1.181999683380127, GAN loss = [2.1946354, 0.74162287, 0.832261]\n",
      "Batch 208/700: Discriminator loss = 1.1883633136749268, GAN loss = [2.2181237, 0.73890615, 0.85848814]\n",
      "Batch 209/700: Discriminator loss = 1.2154189348220825, GAN loss = [2.1968591, 0.7177715, 0.8583742]\n",
      "Batch 210/700: Discriminator loss = 1.2126964330673218, GAN loss = [2.1927526, 0.7218478, 0.85021883]\n",
      "Batch 211/700: Discriminator loss = 1.189137578010559, GAN loss = [2.2255108, 0.7467025, 0.8581483]\n",
      "Batch 212/700: Discriminator loss = 1.1999454498291016, GAN loss = [2.2280326, 0.73672557, 0.87065595]\n",
      "Batch 213/700: Discriminator loss = 1.1838065385818481, GAN loss = [2.2154477, 0.7468913, 0.84791166]\n",
      "Batch 214/700: Discriminator loss = 1.1976988315582275, GAN loss = [2.2024803, 0.7491329, 0.8326874]\n",
      "Batch 215/700: Discriminator loss = 1.1942510604858398, GAN loss = [2.2178323, 0.73731786, 0.8598392]\n",
      "Batch 216/700: Discriminator loss = 1.203046202659607, GAN loss = [2.2102797, 0.7352371, 0.85436547]\n",
      "Batch 217/700: Discriminator loss = 1.1712706089019775, GAN loss = [2.221344, 0.74517584, 0.8555025]\n",
      "Batch 218/700: Discriminator loss = 1.2017275094985962, GAN loss = [2.2075088, 0.72180444, 0.86505145]\n",
      "Batch 219/700: Discriminator loss = 1.175743579864502, GAN loss = [2.2253168, 0.76055694, 0.8441379]\n",
      "Batch 220/700: Discriminator loss = 1.197701334953308, GAN loss = [2.2010913, 0.7475085, 0.8329857]\n",
      "Batch 221/700: Discriminator loss = 1.1918153762817383, GAN loss = [2.160034, 0.74352765, 0.79592973]\n",
      "Batch 222/700: Discriminator loss = 1.1911203861236572, GAN loss = [2.2029788, 0.74067503, 0.84174013]\n",
      "Batch 223/700: Discriminator loss = 1.1945313215255737, GAN loss = [2.1986668, 0.74032706, 0.8377964]\n",
      "Batch 224/700: Discriminator loss = 1.1849299669265747, GAN loss = [2.182773, 0.7479253, 0.81432474]\n",
      "Batch 225/700: Discriminator loss = 1.1630953550338745, GAN loss = [2.2541635, 0.7586981, 0.87495613]\n",
      "Batch 226/700: Discriminator loss = 1.1967591047286987, GAN loss = [2.1809404, 0.73627764, 0.8241711]\n",
      "Batch 227/700: Discriminator loss = 1.1881853342056274, GAN loss = [2.172147, 0.742947, 0.8087235]\n",
      "Batch 228/700: Discriminator loss = 1.1829938888549805, GAN loss = [2.2875624, 0.75118285, 0.91590685]\n",
      "Batch 229/700: Discriminator loss = 1.1759700775146484, GAN loss = [2.2554607, 0.76167697, 0.8733166]\n",
      "Batch 230/700: Discriminator loss = 1.1885170936584473, GAN loss = [2.2473016, 0.75425994, 0.87259245]\n",
      "Batch 231/700: Discriminator loss = 1.1970871686935425, GAN loss = [2.2310555, 0.7334248, 0.87720156]\n",
      "Batch 232/700: Discriminator loss = 1.1696594953536987, GAN loss = [2.2528052, 0.7692891, 0.86309975]\n",
      "Batch 233/700: Discriminator loss = 1.1881117820739746, GAN loss = [2.213429, 0.7579133, 0.8351054]\n",
      "Batch 234/700: Discriminator loss = 1.1817905902862549, GAN loss = [2.2797027, 0.7738986, 0.8854075]\n",
      "Batch 235/700: Discriminator loss = 1.184039831161499, GAN loss = [2.2434137, 0.74912995, 0.87390983]\n",
      "Batch 236/700: Discriminator loss = 1.182586669921875, GAN loss = [2.2427735, 0.74937975, 0.87303483]\n",
      "Batch 237/700: Discriminator loss = 1.192763090133667, GAN loss = [2.2572763, 0.75600904, 0.88092154]\n",
      "Batch 238/700: Discriminator loss = 1.183156967163086, GAN loss = [2.2263112, 0.7397237, 0.8662621]\n",
      "Batch 239/700: Discriminator loss = 1.180978536605835, GAN loss = [2.2231672, 0.7566405, 0.8462202]\n",
      "Batch 240/700: Discriminator loss = 1.2145545482635498, GAN loss = [2.185854, 0.7259976, 0.83955574]\n",
      "Batch 241/700: Discriminator loss = 1.1873650550842285, GAN loss = [2.2723596, 0.7553747, 0.8966945]\n",
      "Batch 242/700: Discriminator loss = 1.1862133741378784, GAN loss = [2.2032523, 0.74176276, 0.8412219]\n",
      "Batch 243/700: Discriminator loss = 1.204495906829834, GAN loss = [2.239675, 0.7319905, 0.8874522]\n",
      "Batch 244/700: Discriminator loss = 1.1906672716140747, GAN loss = [2.2821736, 0.7442328, 0.9177331]\n",
      "Batch 245/700: Discriminator loss = 1.2029907703399658, GAN loss = [2.22346, 0.7281676, 0.8750845]\n",
      "Batch 246/700: Discriminator loss = 1.209426760673523, GAN loss = [2.2326903, 0.7362907, 0.8762039]\n",
      "Batch 247/700: Discriminator loss = 1.2213855981826782, GAN loss = [2.1972353, 0.73685056, 0.8402153]\n",
      "Batch 248/700: Discriminator loss = 1.2045530080795288, GAN loss = [2.2489076, 0.7352786, 0.89347947]\n",
      "Batch 249/700: Discriminator loss = 1.190435528755188, GAN loss = [2.206304, 0.7466516, 0.8395247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/700: Discriminator loss = 1.1918987035751343, GAN loss = [2.1848955, 0.73621637, 0.8285559]\n",
      "Batch 251/700: Discriminator loss = 1.1917425394058228, GAN loss = [2.196263, 0.7561976, 0.8199395]\n",
      "Batch 252/700: Discriminator loss = 1.2196862697601318, GAN loss = [2.1804452, 0.7203194, 0.8399915]\n",
      "Batch 253/700: Discriminator loss = 1.193977952003479, GAN loss = [2.2349772, 0.7593005, 0.8555262]\n",
      "Batch 254/700: Discriminator loss = 1.1734298467636108, GAN loss = [2.2332804, 0.7787508, 0.83435416]\n",
      "Batch 255/700: Discriminator loss = 1.2004603147506714, GAN loss = [2.1663969, 0.7503775, 0.7958372]\n",
      "Batch 256/700: Discriminator loss = 1.192328691482544, GAN loss = [2.1540606, 0.7464993, 0.78738]\n",
      "Batch 257/700: Discriminator loss = 1.2453944683074951, GAN loss = [2.1171322, 0.7056087, 0.79132813]\n",
      "Batch 258/700: Discriminator loss = 1.196602702140808, GAN loss = [2.2204607, 0.74827135, 0.8519584]\n",
      "Batch 259/700: Discriminator loss = 1.2381047010421753, GAN loss = [2.1497965, 0.71276397, 0.81676805]\n",
      "Batch 260/700: Discriminator loss = 1.2328976392745972, GAN loss = [2.1894157, 0.7179435, 0.85118234]\n",
      "Batch 261/700: Discriminator loss = 1.2140357494354248, GAN loss = [2.146317, 0.72531015, 0.80068254]\n",
      "Batch 262/700: Discriminator loss = 1.2132179737091064, GAN loss = [2.1958191, 0.73619455, 0.83924705]\n",
      "Batch 263/700: Discriminator loss = 1.2155373096466064, GAN loss = [2.1544623, 0.7350584, 0.7989798]\n",
      "Batch 264/700: Discriminator loss = 1.218388557434082, GAN loss = [2.164188, 0.733563, 0.8101783]\n",
      "Batch 265/700: Discriminator loss = 1.2431329488754272, GAN loss = [2.1320672, 0.7121236, 0.79948676]\n",
      "Batch 266/700: Discriminator loss = 1.2249798774719238, GAN loss = [2.144247, 0.7069076, 0.8168908]\n",
      "Batch 267/700: Discriminator loss = 1.2132362127304077, GAN loss = [2.109226, 0.7309534, 0.7578224]\n",
      "Batch 268/700: Discriminator loss = 1.1561826467514038, GAN loss = [2.2862048, 0.79384035, 0.8719145]\n",
      "Batch 269/700: Discriminator loss = 1.2154759168624878, GAN loss = [2.1277134, 0.7390616, 0.76820403]\n",
      "Batch 270/700: Discriminator loss = 1.1983643770217896, GAN loss = [2.170614, 0.74640167, 0.8037723]\n",
      "Batch 271/700: Discriminator loss = 1.1874773502349854, GAN loss = [2.223861, 0.75753355, 0.84590936]\n",
      "Batch 272/700: Discriminator loss = 1.1944085359573364, GAN loss = [2.1995566, 0.73669624, 0.84247863]\n",
      "Batch 273/700: Discriminator loss = 1.1888865232467651, GAN loss = [2.1601992, 0.7465501, 0.7933071]\n",
      "Batch 274/700: Discriminator loss = 1.1862964630126953, GAN loss = [2.197821, 0.75069696, 0.8268209]\n",
      "Batch 275/700: Discriminator loss = 1.171917200088501, GAN loss = [2.2008038, 0.77402693, 0.8065095]\n",
      "Batch 276/700: Discriminator loss = 1.157787799835205, GAN loss = [2.2592385, 0.78349304, 0.85549456]\n",
      "Batch 277/700: Discriminator loss = 1.1656370162963867, GAN loss = [2.2371976, 0.7726673, 0.84429145]\n",
      "Batch 278/700: Discriminator loss = 1.1922543048858643, GAN loss = [2.186436, 0.7501551, 0.81605554]\n",
      "Batch 279/700: Discriminator loss = 1.1623529195785522, GAN loss = [2.236231, 0.7700288, 0.84599966]\n",
      "Batch 280/700: Discriminator loss = 1.1870921850204468, GAN loss = [2.1908615, 0.74042463, 0.8302419]\n",
      "Batch 281/700: Discriminator loss = 1.1990522146224976, GAN loss = [2.2294014, 0.7501103, 0.8591017]\n",
      "Batch 282/700: Discriminator loss = 1.1803274154663086, GAN loss = [2.2274911, 0.74833316, 0.8589727]\n",
      "Batch 283/700: Discriminator loss = 1.161974549293518, GAN loss = [2.2309728, 0.76798743, 0.8428091]\n",
      "Batch 284/700: Discriminator loss = 1.1994214057922363, GAN loss = [2.2069867, 0.7354908, 0.8513213]\n",
      "Batch 285/700: Discriminator loss = 1.1737231016159058, GAN loss = [2.274287, 0.7525817, 0.90152377]\n",
      "Batch 286/700: Discriminator loss = 1.1800837516784668, GAN loss = [2.243961, 0.74236757, 0.88143325]\n",
      "Batch 287/700: Discriminator loss = 1.1802680492401123, GAN loss = [2.2645485, 0.75607485, 0.88833374]\n",
      "Batch 288/700: Discriminator loss = 1.1636337041854858, GAN loss = [2.254778, 0.75560945, 0.87904376]\n",
      "Batch 289/700: Discriminator loss = 1.1739602088928223, GAN loss = [2.1924822, 0.7463089, 0.82606834]\n",
      "Batch 290/700: Discriminator loss = 1.1765871047973633, GAN loss = [2.2459853, 0.75328875, 0.8725839]\n",
      "Batch 291/700: Discriminator loss = 1.1678707599639893, GAN loss = [2.2303598, 0.75098914, 0.859232]\n",
      "Batch 292/700: Discriminator loss = 1.1708991527557373, GAN loss = [2.2629254, 0.75303614, 0.8897307]\n",
      "Batch 293/700: Discriminator loss = 1.1883546113967896, GAN loss = [2.2222507, 0.7462591, 0.8558317]\n",
      "Batch 294/700: Discriminator loss = 1.1731294393539429, GAN loss = [2.257864, 0.75404924, 0.8836605]\n",
      "Batch 295/700: Discriminator loss = 1.1642260551452637, GAN loss = [2.2521935, 0.76563287, 0.86640847]\n",
      "Batch 296/700: Discriminator loss = 1.1680742502212524, GAN loss = [2.2444193, 0.75203735, 0.87222946]\n",
      "Batch 297/700: Discriminator loss = 1.1813393831253052, GAN loss = [2.2305326, 0.7388073, 0.8715605]\n",
      "Batch 298/700: Discriminator loss = 1.156529188156128, GAN loss = [2.3355098, 0.76636195, 0.94896233]\n",
      "Batch 299/700: Discriminator loss = 1.156541109085083, GAN loss = [2.2965674, 0.77219397, 0.90417457]\n",
      "Batch 300/700: Discriminator loss = 1.1808629035949707, GAN loss = [2.2408981, 0.75078225, 0.8698912]\n",
      "Batch 301/700: Discriminator loss = 1.1919231414794922, GAN loss = [2.269027, 0.7380127, 0.91076225]\n",
      "Batch 302/700: Discriminator loss = 1.1758979558944702, GAN loss = [2.2403455, 0.75526273, 0.8647946]\n",
      "Batch 303/700: Discriminator loss = 1.1909078359603882, GAN loss = [2.2330632, 0.74347615, 0.86925554]\n",
      "Batch 304/700: Discriminator loss = 1.1884843111038208, GAN loss = [2.280745, 0.74423236, 0.9161372]\n",
      "Batch 305/700: Discriminator loss = 1.2193536758422852, GAN loss = [2.2369812, 0.73981047, 0.8767483]\n",
      "Batch 306/700: Discriminator loss = 1.1642141342163086, GAN loss = [2.2567222, 0.7754707, 0.8607502]\n",
      "Batch 307/700: Discriminator loss = 1.1992193460464478, GAN loss = [2.248659, 0.7379325, 0.89015734]\n",
      "Batch 308/700: Discriminator loss = 1.1841315031051636, GAN loss = [2.2447278, 0.75350714, 0.8705695]\n",
      "Batch 309/700: Discriminator loss = 1.1851837635040283, GAN loss = [2.2969925, 0.76300323, 0.9132826]\n",
      "Batch 310/700: Discriminator loss = 1.139387607574463, GAN loss = [2.2753234, 0.79918265, 0.85537994]\n",
      "Batch 311/700: Discriminator loss = 1.1788296699523926, GAN loss = [2.2721002, 0.7628223, 0.8885099]\n",
      "Batch 312/700: Discriminator loss = 1.1580449342727661, GAN loss = [2.3036714, 0.7740075, 0.9088799]\n",
      "Batch 313/700: Discriminator loss = 1.1501129865646362, GAN loss = [2.3049474, 0.78128016, 0.90284455]\n",
      "Batch 314/700: Discriminator loss = 1.1581441164016724, GAN loss = [2.321288, 0.77647704, 0.9239657]\n",
      "Batch 315/700: Discriminator loss = 1.1531693935394287, GAN loss = [2.336223, 0.7864713, 0.92888606]\n",
      "Batch 316/700: Discriminator loss = 1.1401488780975342, GAN loss = [2.3093836, 0.786228, 0.90226835]\n",
      "Batch 317/700: Discriminator loss = 1.150890588760376, GAN loss = [2.2755952, 0.79089063, 0.86380816]\n",
      "Batch 318/700: Discriminator loss = 1.153032660484314, GAN loss = [2.2754922, 0.78111, 0.8734532]\n",
      "Batch 319/700: Discriminator loss = 1.1411724090576172, GAN loss = [2.3900247, 0.8002362, 0.9688314]\n",
      "Batch 320/700: Discriminator loss = 1.1306062936782837, GAN loss = [2.323863, 0.805135, 0.8977573]\n",
      "Batch 321/700: Discriminator loss = 1.148020625114441, GAN loss = [2.3354285, 0.79920584, 0.9152443]\n",
      "Batch 322/700: Discriminator loss = 1.138649582862854, GAN loss = [2.3552597, 0.79683113, 0.93742555]\n",
      "Batch 323/700: Discriminator loss = 1.1568647623062134, GAN loss = [2.3997202, 0.7991173, 0.979554]\n",
      "Batch 324/700: Discriminator loss = 1.1256881952285767, GAN loss = [2.3815475, 0.82359976, 0.9368529]\n",
      "Batch 325/700: Discriminator loss = 1.1318837404251099, GAN loss = [2.4461985, 0.82928634, 0.9957858]\n",
      "Batch 326/700: Discriminator loss = 1.1431039571762085, GAN loss = [2.4259508, 0.8147612, 0.9900294]\n",
      "Batch 327/700: Discriminator loss = 1.133989930152893, GAN loss = [2.3465679, 0.82260245, 0.90277094]\n",
      "Batch 328/700: Discriminator loss = 1.1286063194274902, GAN loss = [2.420622, 0.8422653, 0.9571315]\n",
      "Batch 329/700: Discriminator loss = 1.113433599472046, GAN loss = [2.4245684, 0.8404874, 0.9627674]\n",
      "Batch 330/700: Discriminator loss = 1.127548336982727, GAN loss = [2.4819, 0.8470358, 1.0135014]\n",
      "Batch 331/700: Discriminator loss = 1.1186726093292236, GAN loss = [2.4482682, 0.8439225, 0.9829663]\n",
      "Batch 332/700: Discriminator loss = 1.1412568092346191, GAN loss = [2.3936028, 0.8320832, 0.94011503]\n",
      "Batch 333/700: Discriminator loss = 1.1269479990005493, GAN loss = [2.3924098, 0.8501081, 0.9208772]\n",
      "Batch 334/700: Discriminator loss = 1.142834186553955, GAN loss = [2.4207835, 0.82022166, 0.97911257]\n",
      "Batch 335/700: Discriminator loss = 1.1397281885147095, GAN loss = [2.3805714, 0.83015615, 0.92895913]\n",
      "Batch 336/700: Discriminator loss = 1.1164076328277588, GAN loss = [2.4433038, 0.8412765, 0.98054445]\n",
      "Batch 337/700: Discriminator loss = 1.1411209106445312, GAN loss = [2.4016292, 0.8320876, 0.94801545]\n",
      "Batch 338/700: Discriminator loss = 1.1377028226852417, GAN loss = [2.4328752, 0.83411956, 0.97718394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 339/700: Discriminator loss = 1.142754316329956, GAN loss = [2.4108255, 0.8277019, 0.9615416]\n",
      "Batch 340/700: Discriminator loss = 1.1437374353408813, GAN loss = [2.3665948, 0.8335964, 0.9113947]\n",
      "Batch 341/700: Discriminator loss = 1.1496129035949707, GAN loss = [2.3822887, 0.8136706, 0.9469965]\n",
      "Batch 342/700: Discriminator loss = 1.1382378339767456, GAN loss = [2.4133785, 0.84494454, 0.9467905]\n",
      "Batch 343/700: Discriminator loss = 1.1350839138031006, GAN loss = [2.4071548, 0.825491, 0.9600122]\n",
      "Batch 344/700: Discriminator loss = 1.1463170051574707, GAN loss = [2.3542542, 0.80677986, 0.9258162]\n",
      "Batch 345/700: Discriminator loss = 1.1392629146575928, GAN loss = [2.412034, 0.8359205, 0.95443815]\n",
      "Batch 346/700: Discriminator loss = 1.1540278196334839, GAN loss = [2.4006557, 0.8076577, 0.9712795]\n",
      "Batch 347/700: Discriminator loss = 1.136608600616455, GAN loss = [2.391069, 0.83098847, 0.93833125]\n",
      "Batch 348/700: Discriminator loss = 1.1388851404190063, GAN loss = [2.4673674, 0.8271885, 1.0184199]\n",
      "Batch 349/700: Discriminator loss = 1.1346156597137451, GAN loss = [2.3941326, 0.8343621, 0.93801165]\n",
      "Batch 350/700: Discriminator loss = 1.1525002717971802, GAN loss = [2.387493, 0.82452387, 0.94122773]\n",
      "Batch 351/700: Discriminator loss = 1.1328428983688354, GAN loss = [2.4360116, 0.8419268, 0.97235227]\n",
      "Batch 352/700: Discriminator loss = 1.1330128908157349, GAN loss = [2.3798301, 0.8354015, 0.92272246]\n",
      "Batch 353/700: Discriminator loss = 1.1277059316635132, GAN loss = [2.4217055, 0.8396589, 0.9603463]\n",
      "Batch 354/700: Discriminator loss = 1.1473582983016968, GAN loss = [2.365453, 0.81919813, 0.9245275]\n",
      "Batch 355/700: Discriminator loss = 1.1660104990005493, GAN loss = [2.3637335, 0.8186056, 0.923387]\n",
      "Batch 356/700: Discriminator loss = 1.1338812112808228, GAN loss = [2.4388392, 0.83634245, 0.98074013]\n",
      "Batch 357/700: Discriminator loss = 1.161963701248169, GAN loss = [2.3952186, 0.82198876, 0.9514639]\n",
      "Batch 358/700: Discriminator loss = 1.1779454946517944, GAN loss = [2.3908725, 0.8026926, 0.96641684]\n",
      "Batch 359/700: Discriminator loss = 1.1673585176467896, GAN loss = [2.4264114, 0.8096168, 0.9950259]\n",
      "Batch 360/700: Discriminator loss = 1.150256633758545, GAN loss = [2.4225338, 0.8364078, 0.96436685]\n",
      "Batch 361/700: Discriminator loss = 1.160014033317566, GAN loss = [2.3460674, 0.79668754, 0.9276093]\n",
      "Batch 362/700: Discriminator loss = 1.1431149244308472, GAN loss = [2.3586943, 0.8167769, 0.92015404]\n",
      "Batch 363/700: Discriminator loss = 1.149670124053955, GAN loss = [2.3292012, 0.8093665, 0.8980541]\n",
      "Batch 364/700: Discriminator loss = 1.1419519186019897, GAN loss = [2.3452857, 0.8332248, 0.89025855]\n",
      "Batch 365/700: Discriminator loss = 1.14590322971344, GAN loss = [2.3707073, 0.81888425, 0.9299848]\n",
      "Batch 366/700: Discriminator loss = 1.1496963500976562, GAN loss = [2.3619983, 0.81634223, 0.9238039]\n",
      "Batch 367/700: Discriminator loss = 1.1532601118087769, GAN loss = [2.4006493, 0.81801325, 0.96077466]\n",
      "Batch 368/700: Discriminator loss = 1.1535824537277222, GAN loss = [2.3495793, 0.81386626, 0.91385865]\n",
      "Batch 369/700: Discriminator loss = 1.136916160583496, GAN loss = [2.3484554, 0.8238687, 0.90274507]\n",
      "Batch 370/700: Discriminator loss = 1.1701245307922363, GAN loss = [2.3185544, 0.80117744, 0.8955295]\n",
      "Batch 371/700: Discriminator loss = 1.1749964952468872, GAN loss = [2.3127067, 0.81193763, 0.87891984]\n",
      "Batch 372/700: Discriminator loss = 1.1494804620742798, GAN loss = [2.359734, 0.8211727, 0.91669726]\n",
      "Batch 373/700: Discriminator loss = 1.1827526092529297, GAN loss = [2.2826974, 0.7860682, 0.8747791]\n",
      "Batch 374/700: Discriminator loss = 1.1488502025604248, GAN loss = [2.3880458, 0.8252752, 0.9409206]\n",
      "Batch 375/700: Discriminator loss = 1.156328797340393, GAN loss = [2.3458476, 0.810428, 0.91358477]\n",
      "Batch 376/700: Discriminator loss = 1.1466832160949707, GAN loss = [2.3454075, 0.8265482, 0.8970487]\n",
      "Batch 377/700: Discriminator loss = 1.167081594467163, GAN loss = [2.3222091, 0.8064933, 0.89392054]\n",
      "Batch 378/700: Discriminator loss = 1.1873968839645386, GAN loss = [2.2602687, 0.76938134, 0.86909014]\n",
      "Batch 379/700: Discriminator loss = 1.1843947172164917, GAN loss = [2.3029838, 0.78479326, 0.8963913]\n",
      "Batch 380/700: Discriminator loss = 1.1821292638778687, GAN loss = [2.3143911, 0.77958524, 0.91303563]\n",
      "Batch 381/700: Discriminator loss = 1.1889268159866333, GAN loss = [2.3129063, 0.79232216, 0.89882463]\n",
      "Batch 382/700: Discriminator loss = 1.201406717300415, GAN loss = [2.2421792, 0.7697303, 0.8507157]\n",
      "Batch 383/700: Discriminator loss = 1.1733996868133545, GAN loss = [2.3198304, 0.7983685, 0.8997319]\n",
      "Batch 384/700: Discriminator loss = 1.1810168027877808, GAN loss = [2.2966628, 0.781584, 0.8933441]\n",
      "Batch 385/700: Discriminator loss = 1.196363091468811, GAN loss = [2.2812266, 0.77685606, 0.8826477]\n",
      "Batch 386/700: Discriminator loss = 1.1757900714874268, GAN loss = [2.3541834, 0.80173147, 0.9307528]\n",
      "Batch 387/700: Discriminator loss = 1.1630351543426514, GAN loss = [2.3213606, 0.81056565, 0.88911927]\n",
      "Batch 388/700: Discriminator loss = 1.1662187576293945, GAN loss = [2.315227, 0.8075306, 0.8860225]\n",
      "Batch 389/700: Discriminator loss = 1.151311993598938, GAN loss = [2.316219, 0.81638503, 0.8781695]\n",
      "Batch 390/700: Discriminator loss = 1.1572952270507812, GAN loss = [2.3268692, 0.79405123, 0.9111712]\n",
      "Batch 391/700: Discriminator loss = 1.1590237617492676, GAN loss = [2.297445, 0.809539, 0.8662766]\n",
      "Batch 392/700: Discriminator loss = 1.160858154296875, GAN loss = [2.3058968, 0.803106, 0.8811821]\n",
      "Batch 393/700: Discriminator loss = 1.1473151445388794, GAN loss = [2.3436007, 0.82410765, 0.89789027]\n",
      "Batch 394/700: Discriminator loss = 1.1392821073532104, GAN loss = [2.363031, 0.8293468, 0.91207486]\n",
      "Batch 395/700: Discriminator loss = 1.1649655103683472, GAN loss = [2.2967174, 0.8002909, 0.87483335]\n",
      "Batch 396/700: Discriminator loss = 1.1572797298431396, GAN loss = [2.3563056, 0.81748354, 0.91724855]\n",
      "Batch 397/700: Discriminator loss = 1.114175796508789, GAN loss = [2.4075103, 0.861215, 0.9247545]\n",
      "Batch 398/700: Discriminator loss = 1.1583752632141113, GAN loss = [2.4257958, 0.82602936, 0.97824675]\n",
      "Batch 399/700: Discriminator loss = 1.1323343515396118, GAN loss = [2.400182, 0.848362, 0.93031144]\n",
      "Batch 400/700: Discriminator loss = 1.1180510520935059, GAN loss = [2.4135208, 0.8714001, 0.92062455]\n",
      "Batch 401/700: Discriminator loss = 1.1031494140625, GAN loss = [2.3849854, 0.85654867, 0.90698516]\n",
      "Batch 402/700: Discriminator loss = 1.1254421472549438, GAN loss = [2.343579, 0.8292825, 0.89286774]\n",
      "Batch 403/700: Discriminator loss = 1.134407877922058, GAN loss = [2.4332352, 0.8290895, 0.9827238]\n",
      "Batch 404/700: Discriminator loss = 1.1240785121917725, GAN loss = [2.3799303, 0.83825356, 0.9202482]\n",
      "Batch 405/700: Discriminator loss = 1.1350302696228027, GAN loss = [2.3567605, 0.8300395, 0.9052956]\n",
      "Batch 406/700: Discriminator loss = 1.1303640604019165, GAN loss = [2.2911632, 0.8216015, 0.84814936]\n",
      "Batch 407/700: Discriminator loss = 1.1347970962524414, GAN loss = [2.3494623, 0.8302179, 0.89783776]\n",
      "Batch 408/700: Discriminator loss = 1.133104681968689, GAN loss = [2.3925261, 0.83436096, 0.93676686]\n",
      "Batch 409/700: Discriminator loss = 1.1154232025146484, GAN loss = [2.4610114, 0.84668124, 0.9929525]\n",
      "Batch 410/700: Discriminator loss = 1.1198798418045044, GAN loss = [2.4335837, 0.84196615, 0.97027344]\n",
      "Batch 411/700: Discriminator loss = 1.136496663093567, GAN loss = [2.4586146, 0.84532404, 0.9920001]\n",
      "Batch 412/700: Discriminator loss = 1.1334080696105957, GAN loss = [2.4485636, 0.84901613, 0.97829115]\n",
      "Batch 413/700: Discriminator loss = 1.1124533414840698, GAN loss = [2.4052799, 0.88640887, 0.8976445]\n",
      "Batch 414/700: Discriminator loss = 1.134645700454712, GAN loss = [2.451022, 0.85330117, 0.9765074]\n",
      "Batch 415/700: Discriminator loss = 1.1401137113571167, GAN loss = [2.4102373, 0.8377353, 0.9513073]\n",
      "Batch 416/700: Discriminator loss = 1.158976674079895, GAN loss = [2.4239435, 0.8240541, 0.978721]\n",
      "Batch 417/700: Discriminator loss = 1.1246325969696045, GAN loss = [2.4164298, 0.85448474, 0.94081306]\n",
      "Batch 418/700: Discriminator loss = 1.1432706117630005, GAN loss = [2.4165723, 0.84384567, 0.95162207]\n",
      "Batch 419/700: Discriminator loss = 1.151393175125122, GAN loss = [2.447833, 0.84151304, 0.98524696]\n",
      "Batch 420/700: Discriminator loss = 1.1225067377090454, GAN loss = [2.480833, 0.879816, 0.97998106]\n",
      "Batch 421/700: Discriminator loss = 1.1005713939666748, GAN loss = [2.5231788, 0.9013094, 1.0008645]\n",
      "Batch 422/700: Discriminator loss = 1.0977083444595337, GAN loss = [2.4660683, 0.8964021, 0.94869065]\n",
      "Batch 423/700: Discriminator loss = 1.1066538095474243, GAN loss = [2.4516118, 0.8834784, 0.947172]\n",
      "Batch 424/700: Discriminator loss = 1.1042792797088623, GAN loss = [2.5372882, 0.8743984, 1.0419346]\n",
      "Batch 425/700: Discriminator loss = 1.093529224395752, GAN loss = [2.5067363, 0.9021762, 0.9836155]\n",
      "Batch 426/700: Discriminator loss = 1.107406735420227, GAN loss = [2.5337317, 0.8960072, 1.0168152]\n",
      "Batch 427/700: Discriminator loss = 1.1229497194290161, GAN loss = [2.4490361, 0.85237813, 0.9757882]\n",
      "Batch 428/700: Discriminator loss = 1.1101783514022827, GAN loss = [2.5741796, 0.8831264, 1.0702262]\n",
      "Batch 429/700: Discriminator loss = 1.1178803443908691, GAN loss = [2.5750413, 0.8744308, 1.0798064]\n",
      "Batch 430/700: Discriminator loss = 1.1283631324768066, GAN loss = [2.4548485, 0.8665253, 0.9675372]\n",
      "Batch 431/700: Discriminator loss = 1.0966988801956177, GAN loss = [2.6225426, 0.89937764, 1.1023744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 432/700: Discriminator loss = 1.107652187347412, GAN loss = [2.48643, 0.8772649, 0.9883818]\n",
      "Batch 433/700: Discriminator loss = 1.1166261434555054, GAN loss = [2.4957917, 0.87615514, 0.99888873]\n",
      "Batch 434/700: Discriminator loss = 1.128283977508545, GAN loss = [2.4218605, 0.8603393, 0.94080335]\n",
      "Batch 435/700: Discriminator loss = 1.1127293109893799, GAN loss = [2.5390096, 0.86173815, 1.0565648]\n",
      "Batch 436/700: Discriminator loss = 1.0950403213500977, GAN loss = [2.5107296, 0.884061, 1.0059755]\n",
      "Batch 437/700: Discriminator loss = 1.1044948101043701, GAN loss = [2.5258834, 0.89242005, 1.0127885]\n",
      "Batch 438/700: Discriminator loss = 1.0971581935882568, GAN loss = [2.5379755, 0.90867585, 1.0086405]\n",
      "Batch 439/700: Discriminator loss = 1.0823954343795776, GAN loss = [2.5248094, 0.9067776, 0.99741256]\n",
      "Batch 440/700: Discriminator loss = 1.0825181007385254, GAN loss = [2.5501146, 0.9155948, 1.0139444]\n",
      "Batch 441/700: Discriminator loss = 1.0723206996917725, GAN loss = [2.5053895, 0.9176203, 0.9672329]\n",
      "Batch 442/700: Discriminator loss = 1.0901724100112915, GAN loss = [2.5072107, 0.8876568, 0.999069]\n",
      "Batch 443/700: Discriminator loss = 1.0776700973510742, GAN loss = [2.490459, 0.89806277, 0.9719671]\n",
      "Batch 444/700: Discriminator loss = 1.0764079093933105, GAN loss = [2.5879593, 0.88809454, 1.0794883]\n",
      "Batch 445/700: Discriminator loss = 1.0822668075561523, GAN loss = [2.5535798, 0.90028435, 1.0329547]\n",
      "Batch 446/700: Discriminator loss = 1.07274329662323, GAN loss = [2.592659, 0.90179205, 1.070567]\n",
      "Batch 447/700: Discriminator loss = 1.0717710256576538, GAN loss = [2.561052, 0.90459037, 1.0361965]\n",
      "Batch 448/700: Discriminator loss = 1.0838884115219116, GAN loss = [2.616019, 0.89883447, 1.0969431]\n",
      "Batch 449/700: Discriminator loss = 1.0931400060653687, GAN loss = [2.5247297, 0.88455236, 1.019941]\n",
      "Batch 450/700: Discriminator loss = 1.1077561378479004, GAN loss = [2.6036446, 0.87626165, 1.1071433]\n",
      "Batch 451/700: Discriminator loss = 1.0807268619537354, GAN loss = [2.555228, 0.8951316, 1.0398482]\n",
      "Batch 452/700: Discriminator loss = 1.0905689001083374, GAN loss = [2.5539606, 0.8986258, 1.0350801]\n",
      "Batch 453/700: Discriminator loss = 1.105587363243103, GAN loss = [2.6647274, 0.88462776, 1.1598308]\n",
      "Batch 454/700: Discriminator loss = 1.0983972549438477, GAN loss = [2.5997767, 0.8861591, 1.0933211]\n",
      "Batch 455/700: Discriminator loss = 1.091376543045044, GAN loss = [2.6636047, 0.9011994, 1.1421027]\n",
      "Batch 456/700: Discriminator loss = 1.0933256149291992, GAN loss = [2.550448, 0.90935045, 1.0207981]\n",
      "Batch 457/700: Discriminator loss = 1.1077371835708618, GAN loss = [2.583887, 0.8823243, 1.0812469]\n",
      "Batch 458/700: Discriminator loss = 1.1010360717773438, GAN loss = [2.6531553, 0.8892553, 1.1435864]\n",
      "Batch 459/700: Discriminator loss = 1.0915372371673584, GAN loss = [2.6390934, 0.8995857, 1.1192094]\n",
      "Batch 460/700: Discriminator loss = 1.0721062421798706, GAN loss = [2.7082338, 0.9197294, 1.1682013]\n",
      "Batch 461/700: Discriminator loss = 1.0873222351074219, GAN loss = [2.6498964, 0.91463923, 1.1149467]\n",
      "Batch 462/700: Discriminator loss = 1.0838221311569214, GAN loss = [2.6986508, 0.91653305, 1.1617906]\n",
      "Batch 463/700: Discriminator loss = 1.0932484865188599, GAN loss = [2.6868293, 0.91912216, 1.1473924]\n",
      "Batch 464/700: Discriminator loss = 1.0956393480300903, GAN loss = [2.8307943, 0.9385969, 1.2718899]\n",
      "Batch 465/700: Discriminator loss = 1.0612863302230835, GAN loss = [2.7138836, 0.95468974, 1.1388919]\n",
      "Batch 466/700: Discriminator loss = 1.0774518251419067, GAN loss = [2.6089275, 0.9406205, 1.0479997]\n",
      "Batch 467/700: Discriminator loss = 1.0743789672851562, GAN loss = [2.7280946, 0.9333565, 1.1744455]\n",
      "Batch 468/700: Discriminator loss = 1.0741620063781738, GAN loss = [2.5902631, 0.9257727, 1.0442028]\n",
      "Batch 469/700: Discriminator loss = 1.1077232360839844, GAN loss = [2.6084585, 0.89836234, 1.0898226]\n",
      "Batch 470/700: Discriminator loss = 1.1020833253860474, GAN loss = [2.6010735, 0.9067626, 1.0740517]\n",
      "Batch 471/700: Discriminator loss = 1.0934252738952637, GAN loss = [2.639554, 0.88841003, 1.1308935]\n",
      "Batch 472/700: Discriminator loss = 1.0988141298294067, GAN loss = [2.616607, 0.914701, 1.081631]\n",
      "Batch 473/700: Discriminator loss = 1.1355594396591187, GAN loss = [2.5181696, 0.8486259, 1.0491896]\n",
      "Batch 474/700: Discriminator loss = 1.1192349195480347, GAN loss = [2.650525, 0.8884497, 1.141644]\n",
      "Batch 475/700: Discriminator loss = 1.1212036609649658, GAN loss = [2.5182662, 0.86736244, 1.0304233]\n",
      "Batch 476/700: Discriminator loss = 1.1263962984085083, GAN loss = [2.4833183, 0.86233187, 1.0004452]\n",
      "Batch 477/700: Discriminator loss = 1.1627341508865356, GAN loss = [2.4792135, 0.8402561, 1.0183545]\n",
      "Batch 478/700: Discriminator loss = 1.1329123973846436, GAN loss = [2.6695964, 0.8632103, 1.1857009]\n",
      "Batch 479/700: Discriminator loss = 1.152539610862732, GAN loss = [2.4944377, 0.85639197, 1.0172529]\n",
      "Batch 480/700: Discriminator loss = 1.1597239971160889, GAN loss = [2.479451, 0.8436778, 1.0148891]\n",
      "Batch 481/700: Discriminator loss = 1.1382427215576172, GAN loss = [2.5871062, 0.89195627, 1.0742284]\n",
      "Batch 482/700: Discriminator loss = 1.1247144937515259, GAN loss = [2.4734368, 0.8688252, 0.98366743]\n",
      "Batch 483/700: Discriminator loss = 1.1205143928527832, GAN loss = [2.4905353, 0.8761518, 0.9933853]\n",
      "Batch 484/700: Discriminator loss = 1.1225461959838867, GAN loss = [2.4697344, 0.886612, 0.9620632]\n",
      "Batch 485/700: Discriminator loss = 1.1314362287521362, GAN loss = [2.3877006, 0.8500725, 0.9164904]\n",
      "Batch 486/700: Discriminator loss = 1.124119520187378, GAN loss = [2.4850647, 0.8987795, 0.9650783]\n",
      "Batch 487/700: Discriminator loss = 1.1414119005203247, GAN loss = [2.4719396, 0.87655556, 0.9741265]\n",
      "Batch 488/700: Discriminator loss = 1.1386630535125732, GAN loss = [2.5027215, 0.8521532, 1.0292542]\n",
      "Batch 489/700: Discriminator loss = 1.1412616968154907, GAN loss = [2.448337, 0.8793255, 0.94763124]\n",
      "Batch 490/700: Discriminator loss = 1.131644606590271, GAN loss = [2.486723, 0.8523671, 1.0129559]\n",
      "Batch 491/700: Discriminator loss = 1.1245156526565552, GAN loss = [2.422011, 0.8663343, 0.93423706]\n",
      "Batch 492/700: Discriminator loss = 1.1502056121826172, GAN loss = [2.4929423, 0.87312734, 0.9983198]\n",
      "Batch 493/700: Discriminator loss = 1.1481518745422363, GAN loss = [2.4029858, 0.83777404, 0.9436194]\n",
      "Batch 494/700: Discriminator loss = 1.1122018098831177, GAN loss = [2.5292969, 0.89422464, 1.0134175]\n",
      "Batch 495/700: Discriminator loss = 1.1344701051712036, GAN loss = [2.4987576, 0.8514051, 1.025633]\n",
      "Batch 496/700: Discriminator loss = 1.136550784111023, GAN loss = [2.4901357, 0.8494688, 1.0188605]\n",
      "Batch 497/700: Discriminator loss = 1.1467863321304321, GAN loss = [2.5296938, 0.85167193, 1.0561603]\n",
      "Batch 498/700: Discriminator loss = 1.13294517993927, GAN loss = [2.4606254, 0.85577697, 0.98292947]\n",
      "Batch 499/700: Discriminator loss = 1.1361278295516968, GAN loss = [2.4695077, 0.86801904, 0.9795184]\n",
      "Batch 500/700: Discriminator loss = 1.1167851686477661, GAN loss = [2.5165007, 0.88688064, 1.0076132]\n",
      "Batch 501/700: Discriminator loss = 1.1444915533065796, GAN loss = [2.450516, 0.85646325, 0.9720311]\n",
      "Batch 502/700: Discriminator loss = 1.1483092308044434, GAN loss = [2.4508011, 0.8534205, 0.9753279]\n",
      "Batch 503/700: Discriminator loss = 1.138730764389038, GAN loss = [2.4513538, 0.8742314, 0.9550192]\n",
      "Batch 504/700: Discriminator loss = 1.1319292783737183, GAN loss = [2.4836147, 0.8724545, 0.9890153]\n",
      "Batch 505/700: Discriminator loss = 1.112583041191101, GAN loss = [2.5518694, 0.8852958, 1.0444089]\n",
      "Batch 506/700: Discriminator loss = 1.114145278930664, GAN loss = [2.49784, 0.8944533, 0.9811741]\n",
      "Batch 507/700: Discriminator loss = 1.1255083084106445, GAN loss = [2.4849336, 0.87677217, 0.9859304]\n",
      "Batch 508/700: Discriminator loss = 1.093475341796875, GAN loss = [2.5520213, 0.90607023, 1.0237119]\n",
      "Batch 509/700: Discriminator loss = 1.1379547119140625, GAN loss = [2.4443426, 0.87951005, 0.9425798]\n",
      "Batch 510/700: Discriminator loss = 1.088666558265686, GAN loss = [2.6315045, 0.9252057, 1.0840253]\n",
      "Batch 511/700: Discriminator loss = 1.1328672170639038, GAN loss = [2.470632, 0.8701221, 0.97821546]\n",
      "Batch 512/700: Discriminator loss = 1.0963068008422852, GAN loss = [2.579564, 0.91613954, 1.0411147]\n",
      "Batch 513/700: Discriminator loss = 1.1053781509399414, GAN loss = [2.5788543, 0.90405965, 1.0524535]\n",
      "Batch 514/700: Discriminator loss = 1.1266449689865112, GAN loss = [2.476965, 0.8864727, 0.9681171]\n",
      "Batch 515/700: Discriminator loss = 1.1369643211364746, GAN loss = [2.5633473, 0.885349, 1.0555812]\n",
      "Batch 516/700: Discriminator loss = 1.1264173984527588, GAN loss = [2.5218477, 0.8877378, 1.0116603]\n",
      "Batch 517/700: Discriminator loss = 1.086052417755127, GAN loss = [2.6049752, 0.93489724, 1.0476124]\n",
      "Batch 518/700: Discriminator loss = 1.1073123216629028, GAN loss = [2.536911, 0.90969485, 1.0047355]\n",
      "Batch 519/700: Discriminator loss = 1.0790612697601318, GAN loss = [2.637076, 0.94173944, 1.0728413]\n",
      "Batch 520/700: Discriminator loss = 1.1044039726257324, GAN loss = [2.6630785, 0.9179504, 1.1226214]\n",
      "Batch 521/700: Discriminator loss = 1.0923246145248413, GAN loss = [2.6029475, 0.91559434, 1.0648725]\n",
      "Batch 522/700: Discriminator loss = 1.0954885482788086, GAN loss = [2.6277592, 0.90670013, 1.0985881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 523/700: Discriminator loss = 1.0908970832824707, GAN loss = [2.6069944, 0.930929, 1.0535964]\n",
      "Batch 524/700: Discriminator loss = 1.1169310808181763, GAN loss = [2.6555958, 0.8944252, 1.1386619]\n",
      "Batch 525/700: Discriminator loss = 1.1097439527511597, GAN loss = [2.5844133, 0.924503, 1.0373385]\n",
      "Batch 526/700: Discriminator loss = 1.1099853515625, GAN loss = [2.6152878, 0.9080333, 1.0846181]\n",
      "Batch 527/700: Discriminator loss = 1.1086831092834473, GAN loss = [2.5718179, 0.8996516, 1.0494895]\n",
      "Batch 528/700: Discriminator loss = 1.135473370552063, GAN loss = [2.4832664, 0.88079697, 0.9797867]\n",
      "Batch 529/700: Discriminator loss = 1.1079988479614258, GAN loss = [2.6180081, 0.91162443, 1.0837016]\n",
      "Batch 530/700: Discriminator loss = 1.1203398704528809, GAN loss = [2.5719624, 0.9019377, 1.0473044]\n",
      "Batch 531/700: Discriminator loss = 1.0947705507278442, GAN loss = [2.6604123, 0.9468948, 1.0907542]\n",
      "Batch 532/700: Discriminator loss = 1.1135261058807373, GAN loss = [2.5785244, 0.9280565, 1.0276207]\n",
      "Batch 533/700: Discriminator loss = 1.072336196899414, GAN loss = [2.5967479, 0.96798986, 1.0058455]\n",
      "Batch 534/700: Discriminator loss = 1.1036632061004639, GAN loss = [2.5887234, 0.9354308, 1.0303437]\n",
      "Batch 535/700: Discriminator loss = 1.079132318496704, GAN loss = [2.6203375, 0.97009695, 1.0272483]\n",
      "Batch 536/700: Discriminator loss = 1.0744624137878418, GAN loss = [2.598785, 0.95480835, 1.0209281]\n",
      "Batch 537/700: Discriminator loss = 1.0806061029434204, GAN loss = [2.6574485, 0.9677897, 1.0665627]\n",
      "Batch 538/700: Discriminator loss = 1.061949372291565, GAN loss = [2.6274753, 0.97893137, 1.0254333]\n",
      "Batch 539/700: Discriminator loss = 1.093667984008789, GAN loss = [2.6161497, 0.9419337, 1.0510556]\n",
      "Batch 540/700: Discriminator loss = 1.1036021709442139, GAN loss = [2.5594232, 0.91285074, 1.0233613]\n",
      "Batch 541/700: Discriminator loss = 1.0761082172393799, GAN loss = [2.6540835, 0.9399577, 1.0908641]\n",
      "Batch 542/700: Discriminator loss = 1.1061276197433472, GAN loss = [2.6920679, 0.92281526, 1.14595]\n",
      "Batch 543/700: Discriminator loss = 1.1565396785736084, GAN loss = [2.4921026, 0.8696117, 0.99912786]\n",
      "Batch 544/700: Discriminator loss = 1.1094800233840942, GAN loss = [2.6360567, 0.9227589, 1.0898874]\n",
      "Batch 545/700: Discriminator loss = 1.0880218744277954, GAN loss = [2.561014, 0.9350463, 1.002511]\n",
      "Batch 546/700: Discriminator loss = 1.1248360872268677, GAN loss = [2.4957266, 0.90268195, 0.9695175]\n",
      "Batch 547/700: Discriminator loss = 1.1219818592071533, GAN loss = [2.5432482, 0.9167584, 1.0029075]\n",
      "Batch 548/700: Discriminator loss = 1.1225454807281494, GAN loss = [2.511763, 0.8959847, 0.9921733]\n",
      "Batch 549/700: Discriminator loss = 1.1681417226791382, GAN loss = [2.4300597, 0.86182135, 0.9445782]\n",
      "Batch 550/700: Discriminator loss = 1.1355626583099365, GAN loss = [2.5563478, 0.9009831, 1.0316433]\n",
      "Batch 551/700: Discriminator loss = 1.1219502687454224, GAN loss = [2.5261605, 0.9107955, 0.99157923]\n",
      "Batch 552/700: Discriminator loss = 1.160652756690979, GAN loss = [2.4590476, 0.8699682, 0.9652798]\n",
      "Batch 553/700: Discriminator loss = 1.1229124069213867, GAN loss = [2.5353985, 0.9003912, 1.0112026]\n",
      "Batch 554/700: Discriminator loss = 1.1123898029327393, GAN loss = [2.5987086, 0.9495405, 1.0253545]\n",
      "Batch 555/700: Discriminator loss = 1.1663668155670166, GAN loss = [2.4934404, 0.915186, 0.9544026]\n",
      "Batch 556/700: Discriminator loss = 1.11453378200531, GAN loss = [2.570236, 0.94722205, 0.99918455]\n",
      "Batch 557/700: Discriminator loss = 1.1052111387252808, GAN loss = [2.5522952, 0.9351963, 0.99329084]\n",
      "Batch 558/700: Discriminator loss = 1.1373467445373535, GAN loss = [2.5293353, 0.91123986, 0.99431914]\n",
      "Batch 559/700: Discriminator loss = 1.1032556295394897, GAN loss = [2.607066, 0.9470488, 1.0363032]\n",
      "Batch 560/700: Discriminator loss = 1.0959081649780273, GAN loss = [2.5494053, 0.92963403, 0.9961024]\n",
      "Batch 561/700: Discriminator loss = 1.0698411464691162, GAN loss = [2.5919044, 0.98293525, 0.9853374]\n",
      "Batch 562/700: Discriminator loss = 1.1338194608688354, GAN loss = [2.5653987, 0.9135153, 1.0282422]\n",
      "Batch 563/700: Discriminator loss = 1.1515852212905884, GAN loss = [2.5247812, 0.88445926, 1.0166657]\n",
      "Batch 564/700: Discriminator loss = 1.1155637502670288, GAN loss = [2.5488913, 0.9267316, 0.998518]\n",
      "Batch 565/700: Discriminator loss = 1.1179496049880981, GAN loss = [2.511962, 0.9153774, 0.9729412]\n",
      "Batch 566/700: Discriminator loss = 1.106971263885498, GAN loss = [2.5236375, 0.9146675, 0.9853188]\n",
      "Batch 567/700: Discriminator loss = 1.1196600198745728, GAN loss = [2.5284321, 0.9196852, 0.9850992]\n",
      "Batch 568/700: Discriminator loss = 1.1264876127243042, GAN loss = [2.5343323, 0.9057183, 1.004959]\n",
      "Batch 569/700: Discriminator loss = 1.101100206375122, GAN loss = [2.5739849, 0.92813665, 1.0222057]\n",
      "Batch 570/700: Discriminator loss = 1.1165471076965332, GAN loss = [2.549256, 0.9391758, 0.98646575]\n",
      "Batch 571/700: Discriminator loss = 1.0959833860397339, GAN loss = [2.6402905, 0.9441832, 1.0724903]\n",
      "Batch 572/700: Discriminator loss = 1.1327790021896362, GAN loss = [2.568723, 0.88624555, 1.0588497]\n",
      "Batch 573/700: Discriminator loss = 1.1041163206100464, GAN loss = [2.5884125, 0.9222395, 1.0425403]\n",
      "Batch 574/700: Discriminator loss = 1.1332684755325317, GAN loss = [2.5256674, 0.90306854, 0.99896604]\n",
      "Batch 575/700: Discriminator loss = 1.118668794631958, GAN loss = [2.6185286, 0.90443116, 1.0904417]\n",
      "Batch 576/700: Discriminator loss = 1.132690668106079, GAN loss = [2.5594811, 0.90294486, 1.0328892]\n",
      "Batch 577/700: Discriminator loss = 1.134084701538086, GAN loss = [2.5729215, 0.896244, 1.0530009]\n",
      "Batch 578/700: Discriminator loss = 1.1681216955184937, GAN loss = [2.5396352, 0.8616411, 1.0542927]\n",
      "Batch 579/700: Discriminator loss = 1.1451243162155151, GAN loss = [2.551554, 0.9004756, 1.0273396]\n",
      "Batch 580/700: Discriminator loss = 1.1130146980285645, GAN loss = [2.5462306, 0.91788703, 1.0045942]\n",
      "Batch 581/700: Discriminator loss = 1.143493413925171, GAN loss = [2.480755, 0.9071885, 0.94981134]\n",
      "Batch 582/700: Discriminator loss = 1.1062166690826416, GAN loss = [2.574585, 0.93186545, 1.0189282]\n",
      "Batch 583/700: Discriminator loss = 1.1020493507385254, GAN loss = [2.5960455, 0.927379, 1.0448779]\n",
      "Batch 584/700: Discriminator loss = 1.1082758903503418, GAN loss = [2.5173016, 0.9433916, 0.95006585]\n",
      "Batch 585/700: Discriminator loss = 1.1367942094802856, GAN loss = [2.5814729, 0.9524443, 1.0051416]\n",
      "Batch 586/700: Discriminator loss = 1.0781875848770142, GAN loss = [2.5797029, 0.98723626, 0.9685152]\n",
      "Batch 587/700: Discriminator loss = 1.0930968523025513, GAN loss = [2.6213436, 0.9882048, 1.009145]\n",
      "Batch 588/700: Discriminator loss = 1.0757032632827759, GAN loss = [2.5663693, 0.96657974, 0.9757669]\n",
      "Batch 589/700: Discriminator loss = 1.0839262008666992, GAN loss = [2.5783868, 0.97909987, 0.9752526]\n",
      "Batch 590/700: Discriminator loss = 1.079375147819519, GAN loss = [2.619137, 0.99214065, 1.0029397]\n",
      "Batch 591/700: Discriminator loss = 1.0912466049194336, GAN loss = [2.5348055, 0.9668051, 0.94390756]\n",
      "Batch 592/700: Discriminator loss = 1.0860565900802612, GAN loss = [2.6098294, 0.97958094, 1.0061189]\n",
      "Batch 593/700: Discriminator loss = 1.1211296319961548, GAN loss = [2.5941353, 0.9732636, 0.996699]\n",
      "Batch 594/700: Discriminator loss = 1.1004743576049805, GAN loss = [2.6108, 0.9891679, 0.99740434]\n",
      "Batch 595/700: Discriminator loss = 1.0784289836883545, GAN loss = [2.6239693, 0.9639956, 1.0357112]\n",
      "Batch 596/700: Discriminator loss = 1.1026170253753662, GAN loss = [2.590965, 0.94607663, 1.0205904]\n",
      "Batch 597/700: Discriminator loss = 1.1202841997146606, GAN loss = [2.49844, 0.91058105, 0.9635729]\n",
      "Batch 598/700: Discriminator loss = 1.1525589227676392, GAN loss = [2.4530485, 0.8724733, 0.9563266]\n",
      "Batch 599/700: Discriminator loss = 1.1461520195007324, GAN loss = [2.5714526, 0.87439084, 1.0728531]\n",
      "Batch 600/700: Discriminator loss = 1.162870168685913, GAN loss = [2.5271626, 0.865522, 1.0375166]\n",
      "Batch 601/700: Discriminator loss = 1.1670385599136353, GAN loss = [2.506899, 0.85610753, 1.0267321]\n",
      "Batch 602/700: Discriminator loss = 1.1675060987472534, GAN loss = [2.4661133, 0.85575813, 0.9863666]\n",
      "Batch 603/700: Discriminator loss = 1.1592957973480225, GAN loss = [2.4055226, 0.8433631, 0.93823135]\n",
      "Batch 604/700: Discriminator loss = 1.155883550643921, GAN loss = [2.5127616, 0.86411387, 1.0247949]\n",
      "Batch 605/700: Discriminator loss = 1.1258654594421387, GAN loss = [2.5075674, 0.88983804, 0.99394417]\n",
      "Batch 606/700: Discriminator loss = 1.1285017728805542, GAN loss = [2.473644, 0.8786856, 0.9712468]\n",
      "Batch 607/700: Discriminator loss = 1.1249490976333618, GAN loss = [2.5412629, 0.90110826, 1.0165111]\n",
      "Batch 608/700: Discriminator loss = 1.1206761598587036, GAN loss = [2.5428538, 0.92309713, 0.9961736]\n",
      "Batch 609/700: Discriminator loss = 1.1342061758041382, GAN loss = [2.5224714, 0.88864726, 1.0103179]\n",
      "Batch 610/700: Discriminator loss = 1.1151363849639893, GAN loss = [2.4460716, 0.89497626, 0.9276521]\n",
      "Batch 611/700: Discriminator loss = 1.0953502655029297, GAN loss = [2.6136942, 0.9392078, 1.0510995]\n",
      "Batch 612/700: Discriminator loss = 1.1125507354736328, GAN loss = [2.4890819, 0.91340363, 0.9523234]\n",
      "Batch 613/700: Discriminator loss = 1.093074917793274, GAN loss = [2.7005312, 0.9505245, 1.1266946]\n",
      "Batch 614/700: Discriminator loss = 1.1324576139450073, GAN loss = [2.5825307, 0.8879019, 1.0713384]\n",
      "Batch 615/700: Discriminator loss = 1.1142380237579346, GAN loss = [2.5114257, 0.9137409, 0.9743971]\n",
      "Batch 616/700: Discriminator loss = 1.1308659315109253, GAN loss = [2.5429692, 0.8914073, 1.0282619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 617/700: Discriminator loss = 1.1224448680877686, GAN loss = [2.5673165, 0.9048159, 1.0391687]\n",
      "Batch 618/700: Discriminator loss = 1.1587897539138794, GAN loss = [2.496768, 0.8753317, 0.9980907]\n",
      "Batch 619/700: Discriminator loss = 1.1400516033172607, GAN loss = [2.5533948, 0.90846395, 1.0215421]\n",
      "Batch 620/700: Discriminator loss = 1.1729830503463745, GAN loss = [2.4004283, 0.8770208, 0.8999996]\n",
      "Batch 621/700: Discriminator loss = 1.1684553623199463, GAN loss = [2.4512403, 0.8822202, 0.94552505]\n",
      "Batch 622/700: Discriminator loss = 1.1637160778045654, GAN loss = [2.5036726, 0.85861397, 1.0214838]\n",
      "Batch 623/700: Discriminator loss = 1.1717607975006104, GAN loss = [2.4116557, 0.8701004, 0.9179222]\n",
      "Batch 624/700: Discriminator loss = 1.1251775026321411, GAN loss = [2.5554574, 0.8912549, 1.0405335]\n",
      "Batch 625/700: Discriminator loss = 1.1465766429901123, GAN loss = [2.4663324, 0.8626322, 0.9799783]\n",
      "Batch 626/700: Discriminator loss = 1.149163842201233, GAN loss = [2.5680852, 0.89071035, 1.0535979]\n",
      "Batch 627/700: Discriminator loss = 1.1522862911224365, GAN loss = [2.4439135, 0.8793768, 0.9407161]\n",
      "Batch 628/700: Discriminator loss = 1.1472336053848267, GAN loss = [2.4814463, 0.8706363, 0.98695534]\n",
      "Batch 629/700: Discriminator loss = 1.125845193862915, GAN loss = [2.454666, 0.875769, 0.9550029]\n",
      "Batch 630/700: Discriminator loss = 1.1236131191253662, GAN loss = [2.4771402, 0.8841678, 0.96905047]\n",
      "Batch 631/700: Discriminator loss = 1.174899697303772, GAN loss = [2.4392762, 0.8605976, 0.9547554]\n",
      "Batch 632/700: Discriminator loss = 1.1427496671676636, GAN loss = [2.4604976, 0.8942533, 0.9422679]\n",
      "Batch 633/700: Discriminator loss = 1.1744855642318726, GAN loss = [2.437307, 0.84855443, 0.9647143]\n",
      "Batch 634/700: Discriminator loss = 1.1312973499298096, GAN loss = [2.454584, 0.87664217, 0.95381296]\n",
      "Batch 635/700: Discriminator loss = 1.1369620561599731, GAN loss = [2.5411284, 0.8946236, 1.0223022]\n",
      "Batch 636/700: Discriminator loss = 1.1561199426651, GAN loss = [2.4260092, 0.8603485, 0.9414411]\n",
      "Batch 637/700: Discriminator loss = 1.147111177444458, GAN loss = [2.5003128, 0.89031196, 0.98572546]\n",
      "Batch 638/700: Discriminator loss = 1.1666347980499268, GAN loss = [2.428844, 0.8640435, 0.94041055]\n",
      "Batch 639/700: Discriminator loss = 1.1546881198883057, GAN loss = [2.5509646, 0.8927579, 1.0337201]\n",
      "Batch 640/700: Discriminator loss = 1.1658462285995483, GAN loss = [2.551498, 0.8858017, 1.0410684]\n",
      "Batch 641/700: Discriminator loss = 1.1278173923492432, GAN loss = [2.50072, 0.8872504, 0.9887382]\n",
      "Batch 642/700: Discriminator loss = 1.1335817575454712, GAN loss = [2.5074935, 0.93959314, 0.94306725]\n",
      "Batch 643/700: Discriminator loss = 1.1419814825057983, GAN loss = [2.5303607, 0.8937948, 1.0115819]\n",
      "Batch 644/700: Discriminator loss = 1.1489717960357666, GAN loss = [2.5192018, 0.91484314, 0.9792445]\n",
      "Batch 645/700: Discriminator loss = 1.1432005167007446, GAN loss = [2.5102098, 0.8837946, 1.0012184]\n",
      "Batch 646/700: Discriminator loss = 1.1372599601745605, GAN loss = [2.5618372, 0.89231575, 1.044245]\n",
      "Batch 647/700: Discriminator loss = 1.1631776094436646, GAN loss = [2.5433955, 0.8817975, 1.0362341]\n",
      "Batch 648/700: Discriminator loss = 1.1195498704910278, GAN loss = [2.600061, 0.9176579, 1.0569632]\n",
      "Batch 649/700: Discriminator loss = 1.1274421215057373, GAN loss = [2.55961, 0.9036245, 1.0304985]\n",
      "Batch 650/700: Discriminator loss = 1.1140973567962646, GAN loss = [2.6104138, 0.9396492, 1.0452378]\n",
      "Batch 651/700: Discriminator loss = 1.1385154724121094, GAN loss = [2.5606623, 0.92926246, 1.005794]\n",
      "Batch 652/700: Discriminator loss = 1.1350950002670288, GAN loss = [2.560866, 0.9151151, 1.0200868]\n",
      "Batch 653/700: Discriminator loss = 1.1362223625183105, GAN loss = [2.478771, 0.89040077, 0.9626384]\n",
      "Batch 654/700: Discriminator loss = 1.1182966232299805, GAN loss = [2.5532465, 0.910039, 1.0173981]\n",
      "Batch 655/700: Discriminator loss = 1.1338176727294922, GAN loss = [2.5430672, 0.90433383, 1.0128402]\n",
      "Batch 656/700: Discriminator loss = 1.1459527015686035, GAN loss = [2.532103, 0.8618068, 1.0443845]\n",
      "Batch 657/700: Discriminator loss = 1.1333997249603271, GAN loss = [2.5292945, 0.8842724, 1.0191083]\n",
      "Batch 658/700: Discriminator loss = 1.1608445644378662, GAN loss = [2.4546306, 0.85267776, 0.97598946]\n",
      "Batch 659/700: Discriminator loss = 1.1424938440322876, GAN loss = [2.5339446, 0.86216044, 1.0457735]\n",
      "Batch 660/700: Discriminator loss = 1.1702297925949097, GAN loss = [2.5092826, 0.84637773, 1.0368458]\n",
      "Batch 661/700: Discriminator loss = 1.1635714769363403, GAN loss = [2.5813918, 0.86943907, 1.0858747]\n",
      "Batch 662/700: Discriminator loss = 1.1551662683486938, GAN loss = [2.451086, 0.8606349, 0.9643492]\n",
      "Batch 663/700: Discriminator loss = 1.193319320678711, GAN loss = [2.454953, 0.8293027, 0.9995084]\n",
      "Batch 664/700: Discriminator loss = 1.1872740983963013, GAN loss = [2.4577317, 0.8381044, 0.9934356]\n",
      "Batch 665/700: Discriminator loss = 1.134308934211731, GAN loss = [2.5297687, 0.89699936, 1.0065821]\n",
      "Batch 666/700: Discriminator loss = 1.1888329982757568, GAN loss = [2.3479567, 0.8266072, 0.8951162]\n",
      "Batch 667/700: Discriminator loss = 1.1477851867675781, GAN loss = [2.4726717, 0.8629282, 0.98348427]\n",
      "Batch 668/700: Discriminator loss = 1.1694849729537964, GAN loss = [2.4605217, 0.85132426, 0.9829385]\n",
      "Batch 669/700: Discriminator loss = 1.1614842414855957, GAN loss = [2.449216, 0.871685, 0.95121676]\n",
      "Batch 670/700: Discriminator loss = 1.1966370344161987, GAN loss = [2.354275, 0.82543236, 0.90245306]\n",
      "Batch 671/700: Discriminator loss = 1.1892118453979492, GAN loss = [2.4482172, 0.839185, 0.982581]\n",
      "Batch 672/700: Discriminator loss = 1.1770144701004028, GAN loss = [2.4842682, 0.84901667, 1.0087546]\n",
      "Batch 673/700: Discriminator loss = 1.1996756792068481, GAN loss = [2.316142, 0.80497277, 0.884652]\n",
      "Batch 674/700: Discriminator loss = 1.2365365028381348, GAN loss = [2.3383803, 0.79722077, 0.91463494]\n",
      "Batch 675/700: Discriminator loss = 1.1827751398086548, GAN loss = [2.4157288, 0.81373644, 0.9754677]\n",
      "Batch 676/700: Discriminator loss = 1.1967825889587402, GAN loss = [2.4268587, 0.8016217, 0.99871546]\n",
      "Batch 677/700: Discriminator loss = 1.2242292165756226, GAN loss = [2.2818336, 0.78692085, 0.8684174]\n",
      "Batch 678/700: Discriminator loss = 1.1922779083251953, GAN loss = [2.3600864, 0.816551, 0.917033]\n",
      "Batch 679/700: Discriminator loss = 1.2053626775741577, GAN loss = [2.3616223, 0.8262667, 0.90886205]\n",
      "Batch 680/700: Discriminator loss = 1.202479600906372, GAN loss = [2.3132641, 0.81429404, 0.8725279]\n",
      "Batch 681/700: Discriminator loss = 1.1955593824386597, GAN loss = [2.3210447, 0.8064986, 0.8881411]\n",
      "Batch 682/700: Discriminator loss = 1.2001590728759766, GAN loss = [2.3601973, 0.8337094, 0.9001192]\n",
      "Batch 683/700: Discriminator loss = 1.2149579524993896, GAN loss = [2.320675, 0.7972432, 0.89709353]\n",
      "Batch 684/700: Discriminator loss = 1.2227259874343872, GAN loss = [2.2564673, 0.797757, 0.83239645]\n",
      "Batch 685/700: Discriminator loss = 1.225286841392517, GAN loss = [2.2754738, 0.7880469, 0.86112535]\n",
      "Batch 686/700: Discriminator loss = 1.216699242591858, GAN loss = [2.3007119, 0.78413415, 0.8903221]\n",
      "Batch 687/700: Discriminator loss = 1.1881483793258667, GAN loss = [2.367135, 0.8190032, 0.92192495]\n",
      "Batch 688/700: Discriminator loss = 1.193037986755371, GAN loss = [2.2814243, 0.81644255, 0.8388417]\n",
      "Batch 689/700: Discriminator loss = 1.1789249181747437, GAN loss = [2.357101, 0.8298898, 0.9011512]\n",
      "Batch 690/700: Discriminator loss = 1.2197798490524292, GAN loss = [2.39382, 0.8097665, 0.95807487]\n",
      "Batch 691/700: Discriminator loss = 1.196738839149475, GAN loss = [2.4308329, 0.80181557, 1.003079]\n",
      "Batch 692/700: Discriminator loss = 1.1919382810592651, GAN loss = [2.3258092, 0.82062566, 0.87928766]\n",
      "Batch 693/700: Discriminator loss = 1.186156153678894, GAN loss = [2.2618096, 0.8004298, 0.83550906]\n",
      "Batch 694/700: Discriminator loss = 1.2000709772109985, GAN loss = [2.325736, 0.795939, 0.9039399]\n",
      "Batch 695/700: Discriminator loss = 1.2042981386184692, GAN loss = [2.3237135, 0.7929515, 0.904901]\n",
      "Batch 696/700: Discriminator loss = 1.2432386875152588, GAN loss = [2.316854, 0.8074406, 0.8835442]\n",
      "Batch 697/700: Discriminator loss = 1.2211405038833618, GAN loss = [2.2648134, 0.7987172, 0.84023166]\n",
      "Batch 698/700: Discriminator loss = 1.1905797719955444, GAN loss = [2.3742704, 0.8129593, 0.93545663]\n",
      "Batch 699/700: Discriminator loss = 1.2327872514724731, GAN loss = [2.245278, 0.78408104, 0.83535326]\n",
      "Batch 700/700: Discriminator loss = 1.2676116228103638, GAN loss = [2.295778, 0.7908993, 0.8790266]\n",
      "Epoch 24/30\n",
      "Batch 1/700: Discriminator loss = 1.2110666036605835, GAN loss = [2.2984037, 0.8139621, 0.85856456]\n",
      "Batch 2/700: Discriminator loss = 1.2072970867156982, GAN loss = [2.2693758, 0.8004616, 0.84300286]\n",
      "Batch 3/700: Discriminator loss = 1.2296749353408813, GAN loss = [2.282584, 0.7832853, 0.8733542]\n",
      "Batch 4/700: Discriminator loss = 1.2152906656265259, GAN loss = [2.3177776, 0.78440803, 0.90740114]\n",
      "Batch 5/700: Discriminator loss = 1.2335044145584106, GAN loss = [2.195004, 0.7734258, 0.7955766]\n",
      "Batch 6/700: Discriminator loss = 1.2242307662963867, GAN loss = [2.2587261, 0.7883184, 0.8443763]\n",
      "Batch 7/700: Discriminator loss = 1.2162611484527588, GAN loss = [2.2149835, 0.7759898, 0.8129567]\n",
      "Batch 8/700: Discriminator loss = 1.2002679109573364, GAN loss = [2.2791133, 0.8198346, 0.83322555]\n",
      "Batch 9/700: Discriminator loss = 1.1939616203308105, GAN loss = [2.272009, 0.7980293, 0.8479151]\n",
      "Batch 10/700: Discriminator loss = 1.1949801445007324, GAN loss = [2.3066804, 0.8046725, 0.8759278]\n",
      "Batch 11/700: Discriminator loss = 1.1966761350631714, GAN loss = [2.277675, 0.81136113, 0.84025735]\n",
      "Batch 12/700: Discriminator loss = 1.2300933599472046, GAN loss = [2.2792583, 0.7779042, 0.87530077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13/700: Discriminator loss = 1.1847494840621948, GAN loss = [2.315401, 0.8178939, 0.8714436]\n",
      "Batch 14/700: Discriminator loss = 1.1926453113555908, GAN loss = [2.28548, 0.7913412, 0.86803705]\n",
      "Batch 15/700: Discriminator loss = 1.1747310161590576, GAN loss = [2.3335845, 0.8197642, 0.8876872]\n",
      "Batch 16/700: Discriminator loss = 1.1544243097305298, GAN loss = [2.3662918, 0.84285283, 0.89732355]\n",
      "Batch 17/700: Discriminator loss = 1.1713342666625977, GAN loss = [2.3219323, 0.81170875, 0.8841267]\n",
      "Batch 18/700: Discriminator loss = 1.1907691955566406, GAN loss = [2.3602946, 0.81080836, 0.92338294]\n",
      "Batch 19/700: Discriminator loss = 1.1629284620285034, GAN loss = [2.4216554, 0.8415439, 0.9540223]\n",
      "Batch 20/700: Discriminator loss = 1.1940144300460815, GAN loss = [2.3635468, 0.79490334, 0.9425589]\n",
      "Batch 21/700: Discriminator loss = 1.1862397193908691, GAN loss = [2.333174, 0.80500853, 0.90207696]\n",
      "Batch 22/700: Discriminator loss = 1.2012355327606201, GAN loss = [2.3204079, 0.80022156, 0.89407784]\n",
      "Batch 23/700: Discriminator loss = 1.2123457193374634, GAN loss = [2.2955005, 0.7874366, 0.8819387]\n",
      "Batch 24/700: Discriminator loss = 1.2099111080169678, GAN loss = [2.2827795, 0.7878573, 0.86882216]\n",
      "Batch 25/700: Discriminator loss = 1.2010753154754639, GAN loss = [2.255551, 0.76678663, 0.86268806]\n",
      "Batch 26/700: Discriminator loss = 1.2230511903762817, GAN loss = [2.2954285, 0.77235526, 0.8970328]\n",
      "Batch 27/700: Discriminator loss = 1.2028002738952637, GAN loss = [2.3610122, 0.7985794, 0.93644136]\n",
      "Batch 28/700: Discriminator loss = 1.2187247276306152, GAN loss = [2.3586292, 0.7958744, 0.93680626]\n",
      "Batch 29/700: Discriminator loss = 1.2003281116485596, GAN loss = [2.2909913, 0.80414087, 0.8609666]\n",
      "Batch 30/700: Discriminator loss = 1.203848958015442, GAN loss = [2.3565085, 0.8006899, 0.92999244]\n",
      "Batch 31/700: Discriminator loss = 1.1960538625717163, GAN loss = [2.2941935, 0.80889285, 0.8595685]\n",
      "Batch 32/700: Discriminator loss = 1.1717559099197388, GAN loss = [2.321128, 0.814896, 0.8805878]\n",
      "Batch 33/700: Discriminator loss = 1.170697808265686, GAN loss = [2.427012, 0.8394563, 0.9619846]\n",
      "Batch 34/700: Discriminator loss = 1.1824198961257935, GAN loss = [2.3251722, 0.8157019, 0.8839619]\n",
      "Batch 35/700: Discriminator loss = 1.168881893157959, GAN loss = [2.3339097, 0.82356936, 0.8848948]\n",
      "Batch 36/700: Discriminator loss = 1.1686714887619019, GAN loss = [2.4012022, 0.8477485, 0.92809194]\n",
      "Batch 37/700: Discriminator loss = 1.1627659797668457, GAN loss = [2.3125386, 0.8390882, 0.84818006]\n",
      "Batch 38/700: Discriminator loss = 1.1646645069122314, GAN loss = [2.3756669, 0.8511355, 0.8993272]\n",
      "Batch 39/700: Discriminator loss = 1.1876170635223389, GAN loss = [2.3703823, 0.81878, 0.9264421]\n",
      "Batch 40/700: Discriminator loss = 1.1776756048202515, GAN loss = [2.307336, 0.8281959, 0.8539938]\n",
      "Batch 41/700: Discriminator loss = 1.1771198511123657, GAN loss = [2.3538306, 0.8375645, 0.8911379]\n",
      "Batch 42/700: Discriminator loss = 1.1814197301864624, GAN loss = [2.322511, 0.83304733, 0.8643461]\n",
      "Batch 43/700: Discriminator loss = 1.1907353401184082, GAN loss = [2.360463, 0.85632116, 0.87906504]\n",
      "Batch 44/700: Discriminator loss = 1.173114538192749, GAN loss = [2.347729, 0.8562554, 0.86643386]\n",
      "Batch 45/700: Discriminator loss = 1.221956491470337, GAN loss = [2.3361704, 0.83038986, 0.8807605]\n",
      "Batch 46/700: Discriminator loss = 1.1706898212432861, GAN loss = [2.3300874, 0.85549194, 0.8496344]\n",
      "Batch 47/700: Discriminator loss = 1.1637253761291504, GAN loss = [2.3560102, 0.8761602, 0.8549243]\n",
      "Batch 48/700: Discriminator loss = 1.1962890625, GAN loss = [2.320666, 0.8476029, 0.8481421]\n",
      "Batch 49/700: Discriminator loss = 1.142903208732605, GAN loss = [2.5039017, 0.90328795, 0.9756939]\n",
      "Batch 50/700: Discriminator loss = 1.1900906562805176, GAN loss = [2.3041842, 0.8365996, 0.84267336]\n",
      "Batch 51/700: Discriminator loss = 1.2140824794769287, GAN loss = [2.3107224, 0.8291865, 0.85664994]\n",
      "Batch 52/700: Discriminator loss = 1.207869052886963, GAN loss = [2.311887, 0.82761383, 0.85941374]\n",
      "Batch 53/700: Discriminator loss = 1.1746798753738403, GAN loss = [2.323862, 0.8363942, 0.8626403]\n",
      "Batch 54/700: Discriminator loss = 1.194280982017517, GAN loss = [2.3599014, 0.8500132, 0.885086]\n",
      "Batch 55/700: Discriminator loss = 1.1867358684539795, GAN loss = [2.3613293, 0.85912293, 0.8774251]\n",
      "Batch 56/700: Discriminator loss = 1.2036395072937012, GAN loss = [2.3165338, 0.82001716, 0.87175894]\n",
      "Batch 57/700: Discriminator loss = 1.1995052099227905, GAN loss = [2.3416328, 0.83689773, 0.88000315]\n",
      "Batch 58/700: Discriminator loss = 1.1534391641616821, GAN loss = [2.3868089, 0.8736754, 0.88842374]\n",
      "Batch 59/700: Discriminator loss = 1.1813069581985474, GAN loss = [2.3295448, 0.834597, 0.8702486]\n",
      "Batch 60/700: Discriminator loss = 1.1875, GAN loss = [2.3036518, 0.8220768, 0.85691977]\n",
      "Batch 61/700: Discriminator loss = 1.1380369663238525, GAN loss = [2.3802629, 0.87575644, 0.8799026]\n",
      "Batch 62/700: Discriminator loss = 1.1581939458847046, GAN loss = [2.3917468, 0.860936, 0.9062722]\n",
      "Batch 63/700: Discriminator loss = 1.1615066528320312, GAN loss = [2.3575947, 0.8561497, 0.87698287]\n",
      "Batch 64/700: Discriminator loss = 1.1900367736816406, GAN loss = [2.3486934, 0.8162883, 0.9080009]\n",
      "Batch 65/700: Discriminator loss = 1.173385500907898, GAN loss = [2.3774354, 0.837195, 0.91585386]\n",
      "Batch 66/700: Discriminator loss = 1.1912418603897095, GAN loss = [2.3602567, 0.8340655, 0.90182287]\n",
      "Batch 67/700: Discriminator loss = 1.2020670175552368, GAN loss = [2.361091, 0.8118054, 0.92494464]\n",
      "Batch 68/700: Discriminator loss = 1.1575368642807007, GAN loss = [2.3480778, 0.84604514, 0.87771016]\n",
      "Batch 69/700: Discriminator loss = 1.1671768426895142, GAN loss = [2.4082084, 0.87263715, 0.9112582]\n",
      "Batch 70/700: Discriminator loss = 1.1904053688049316, GAN loss = [2.2863314, 0.80669516, 0.8553328]\n",
      "Batch 71/700: Discriminator loss = 1.2150694131851196, GAN loss = [2.2909894, 0.791126, 0.87554747]\n",
      "Batch 72/700: Discriminator loss = 1.165492057800293, GAN loss = [2.388937, 0.83465266, 0.9299796]\n",
      "Batch 73/700: Discriminator loss = 1.183661699295044, GAN loss = [2.2978663, 0.8150897, 0.85848725]\n",
      "Batch 74/700: Discriminator loss = 1.1894748210906982, GAN loss = [2.3272955, 0.8054646, 0.89756805]\n",
      "Batch 75/700: Discriminator loss = 1.20895254611969, GAN loss = [2.3507748, 0.7856919, 0.9408236]\n",
      "Batch 76/700: Discriminator loss = 1.186740517616272, GAN loss = [2.3158712, 0.80607843, 0.88553375]\n",
      "Batch 77/700: Discriminator loss = 1.174695372581482, GAN loss = [2.3548236, 0.82847196, 0.90210295]\n",
      "Batch 78/700: Discriminator loss = 1.1588162183761597, GAN loss = [2.307449, 0.8232128, 0.8599979]\n",
      "Batch 79/700: Discriminator loss = 1.1862256526947021, GAN loss = [2.2573662, 0.79746467, 0.83567756]\n",
      "Batch 80/700: Discriminator loss = 1.1880735158920288, GAN loss = [2.3310707, 0.8087625, 0.8981236]\n",
      "Batch 81/700: Discriminator loss = 1.1698411703109741, GAN loss = [2.2935674, 0.81744456, 0.85200197]\n",
      "Batch 82/700: Discriminator loss = 1.178745150566101, GAN loss = [2.360675, 0.8151668, 0.9214567]\n",
      "Batch 83/700: Discriminator loss = 1.175362229347229, GAN loss = [2.29118, 0.7935849, 0.87360865]\n",
      "Batch 84/700: Discriminator loss = 1.1769770383834839, GAN loss = [2.3168402, 0.8005305, 0.8923774]\n",
      "Batch 85/700: Discriminator loss = 1.1700502634048462, GAN loss = [2.2626843, 0.7986594, 0.8401473]\n",
      "Batch 86/700: Discriminator loss = 1.166089653968811, GAN loss = [2.3625731, 0.8123584, 0.92638606]\n",
      "Batch 87/700: Discriminator loss = 1.179319977760315, GAN loss = [2.3121912, 0.80389845, 0.88448966]\n",
      "Batch 88/700: Discriminator loss = 1.190645456314087, GAN loss = [2.328285, 0.79943174, 0.90507203]\n",
      "Batch 89/700: Discriminator loss = 1.1699601411819458, GAN loss = [2.3545403, 0.81358904, 0.9172206]\n",
      "Batch 90/700: Discriminator loss = 1.213371753692627, GAN loss = [2.2296937, 0.772707, 0.83330214]\n",
      "Batch 91/700: Discriminator loss = 1.1763741970062256, GAN loss = [2.3320153, 0.8191416, 0.88921946]\n",
      "Batch 92/700: Discriminator loss = 1.1661572456359863, GAN loss = [2.3999164, 0.81905, 0.9572454]\n",
      "Batch 93/700: Discriminator loss = 1.1555466651916504, GAN loss = [2.3598015, 0.81934404, 0.9169096]\n",
      "Batch 94/700: Discriminator loss = 1.1685575246810913, GAN loss = [2.3803363, 0.802926, 0.9538948]\n",
      "Batch 95/700: Discriminator loss = 1.2000584602355957, GAN loss = [2.2845905, 0.7887856, 0.87230474]\n",
      "Batch 96/700: Discriminator loss = 1.222429871559143, GAN loss = [2.237261, 0.77453095, 0.839265]\n",
      "Batch 97/700: Discriminator loss = 1.1842641830444336, GAN loss = [2.3606746, 0.80113226, 0.93612176]\n",
      "Batch 98/700: Discriminator loss = 1.2009170055389404, GAN loss = [2.2947693, 0.7775125, 0.8938732]\n",
      "Batch 99/700: Discriminator loss = 1.1858134269714355, GAN loss = [2.3462057, 0.7964441, 0.926406]\n",
      "Batch 100/700: Discriminator loss = 1.1976288557052612, GAN loss = [2.2859292, 0.77285975, 0.8897431]\n",
      "Batch 101/700: Discriminator loss = 1.1971977949142456, GAN loss = [2.3282704, 0.7849022, 0.92010283]\n",
      "Batch 102/700: Discriminator loss = 1.1845171451568604, GAN loss = [2.372999, 0.8255403, 0.92423546]\n",
      "Batch 103/700: Discriminator loss = 1.1825278997421265, GAN loss = [2.3283427, 0.79538697, 0.9097835]\n",
      "Batch 104/700: Discriminator loss = 1.1514232158660889, GAN loss = [2.4116776, 0.8467663, 0.94176185]\n",
      "Batch 105/700: Discriminator loss = 1.1889313459396362, GAN loss = [2.3401802, 0.7941912, 0.9228404]\n",
      "Batch 106/700: Discriminator loss = 1.1732778549194336, GAN loss = [2.3723047, 0.8007496, 0.94841594]\n",
      "Batch 107/700: Discriminator loss = 1.1904388666152954, GAN loss = [2.3081462, 0.8140453, 0.8709726]\n",
      "Batch 108/700: Discriminator loss = 1.1765589714050293, GAN loss = [2.295366, 0.81405884, 0.8581836]\n",
      "Batch 109/700: Discriminator loss = 1.1744718551635742, GAN loss = [2.3564494, 0.81472117, 0.91858757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 110/700: Discriminator loss = 1.2148162126541138, GAN loss = [2.3283901, 0.7943299, 0.91091454]\n",
      "Batch 111/700: Discriminator loss = 1.1785218715667725, GAN loss = [2.3594308, 0.818413, 0.9178652]\n",
      "Batch 112/700: Discriminator loss = 1.187705159187317, GAN loss = [2.3781772, 0.8098368, 0.94518363]\n",
      "Batch 113/700: Discriminator loss = 1.1823915243148804, GAN loss = [2.363694, 0.8131588, 0.9273556]\n",
      "Batch 114/700: Discriminator loss = 1.131014347076416, GAN loss = [2.3668294, 0.85866046, 0.88499343]\n",
      "Batch 115/700: Discriminator loss = 1.1634052991867065, GAN loss = [2.370671, 0.823359, 0.92415446]\n",
      "Batch 116/700: Discriminator loss = 1.146929383277893, GAN loss = [2.3862262, 0.8452249, 0.9178688]\n",
      "Batch 117/700: Discriminator loss = 1.1784088611602783, GAN loss = [2.334645, 0.8227097, 0.88882643]\n",
      "Batch 118/700: Discriminator loss = 1.1537694931030273, GAN loss = [2.3739572, 0.83174914, 0.9190951]\n",
      "Batch 119/700: Discriminator loss = 1.171297311782837, GAN loss = [2.3014867, 0.80315745, 0.8752365]\n",
      "Batch 120/700: Discriminator loss = 1.1750447750091553, GAN loss = [2.388237, 0.8109638, 0.9542029]\n",
      "Batch 121/700: Discriminator loss = 1.182755708694458, GAN loss = [2.3969436, 0.81272453, 0.9612075]\n",
      "Batch 122/700: Discriminator loss = 1.157605767250061, GAN loss = [2.3801167, 0.8246357, 0.93253386]\n",
      "Batch 123/700: Discriminator loss = 1.1687153577804565, GAN loss = [2.3716269, 0.8244981, 0.9242023]\n",
      "Batch 124/700: Discriminator loss = 1.1782416105270386, GAN loss = [2.361849, 0.8027112, 0.9362307]\n",
      "Batch 125/700: Discriminator loss = 1.168320655822754, GAN loss = [2.3730044, 0.83124083, 0.9188756]\n",
      "Batch 126/700: Discriminator loss = 1.1717137098312378, GAN loss = [2.2977786, 0.8236058, 0.8513038]\n",
      "Batch 127/700: Discriminator loss = 1.1798368692398071, GAN loss = [2.3298771, 0.8217224, 0.8853221]\n",
      "Batch 128/700: Discriminator loss = 1.1838511228561401, GAN loss = [2.3264973, 0.82539827, 0.8782923]\n",
      "Batch 129/700: Discriminator loss = 1.1843034029006958, GAN loss = [2.3135347, 0.8111502, 0.8795817]\n",
      "Batch 130/700: Discriminator loss = 1.1806905269622803, GAN loss = [2.344649, 0.80822635, 0.9136284]\n",
      "Batch 131/700: Discriminator loss = 1.2058264017105103, GAN loss = [2.2585218, 0.8004873, 0.83523095]\n",
      "Batch 132/700: Discriminator loss = 1.1877959966659546, GAN loss = [2.3370652, 0.79817754, 0.9160696]\n",
      "Batch 133/700: Discriminator loss = 1.1908742189407349, GAN loss = [2.2941422, 0.788901, 0.8824311]\n",
      "Batch 134/700: Discriminator loss = 1.2081141471862793, GAN loss = [2.2375705, 0.7848825, 0.8298964]\n",
      "Batch 135/700: Discriminator loss = 1.2045133113861084, GAN loss = [2.2848644, 0.79218656, 0.8698892]\n",
      "Batch 136/700: Discriminator loss = 1.188073992729187, GAN loss = [2.254445, 0.7896361, 0.84202105]\n",
      "Batch 137/700: Discriminator loss = 1.1986970901489258, GAN loss = [2.3171551, 0.7940227, 0.90034175]\n",
      "Batch 138/700: Discriminator loss = 1.1990418434143066, GAN loss = [2.2845323, 0.7662331, 0.8954803]\n",
      "Batch 139/700: Discriminator loss = 1.1990166902542114, GAN loss = [2.308238, 0.80124825, 0.88418114]\n",
      "Batch 140/700: Discriminator loss = 1.1808961629867554, GAN loss = [2.324204, 0.8102893, 0.89113]\n",
      "Batch 141/700: Discriminator loss = 1.2066295146942139, GAN loss = [2.2945418, 0.80522704, 0.86651945]\n",
      "Batch 142/700: Discriminator loss = 1.1946353912353516, GAN loss = [2.2973099, 0.7946399, 0.87987757]\n",
      "Batch 143/700: Discriminator loss = 1.2156028747558594, GAN loss = [2.259638, 0.77809393, 0.85875183]\n",
      "Batch 144/700: Discriminator loss = 1.2052490711212158, GAN loss = [2.2101064, 0.7694784, 0.8178318]\n",
      "Batch 145/700: Discriminator loss = 1.2298816442489624, GAN loss = [2.2957492, 0.76020235, 0.91274774]\n",
      "Batch 146/700: Discriminator loss = 1.1840882301330566, GAN loss = [2.2952008, 0.7963194, 0.8760605]\n",
      "Batch 147/700: Discriminator loss = 1.21759033203125, GAN loss = [2.271122, 0.7876912, 0.86060005]\n",
      "Batch 148/700: Discriminator loss = 1.1818227767944336, GAN loss = [2.312061, 0.80298775, 0.88624924]\n",
      "Batch 149/700: Discriminator loss = 1.1788376569747925, GAN loss = [2.3430564, 0.81307733, 0.9071761]\n",
      "Batch 150/700: Discriminator loss = 1.1899858713150024, GAN loss = [2.302479, 0.7978127, 0.8819049]\n",
      "Batch 151/700: Discriminator loss = 1.197164535522461, GAN loss = [2.3427844, 0.8021582, 0.91792107]\n",
      "Batch 152/700: Discriminator loss = 1.1696332693099976, GAN loss = [2.313303, 0.8153711, 0.87528455]\n",
      "Batch 153/700: Discriminator loss = 1.1611695289611816, GAN loss = [2.3436477, 0.82105744, 0.89997125]\n",
      "Batch 154/700: Discriminator loss = 1.170668363571167, GAN loss = [2.3091555, 0.8357247, 0.8508184]\n",
      "Batch 155/700: Discriminator loss = 1.1708476543426514, GAN loss = [2.25288, 0.8101834, 0.8201014]\n",
      "Batch 156/700: Discriminator loss = 1.1696677207946777, GAN loss = [2.2676709, 0.8124893, 0.8326326]\n",
      "Batch 157/700: Discriminator loss = 1.154535174369812, GAN loss = [2.3538914, 0.82396317, 0.9074225]\n",
      "Batch 158/700: Discriminator loss = 1.1849371194839478, GAN loss = [2.2835298, 0.8178245, 0.843214]\n",
      "Batch 159/700: Discriminator loss = 1.1460849046707153, GAN loss = [2.299888, 0.8423438, 0.83506346]\n",
      "Batch 160/700: Discriminator loss = 1.1680442094802856, GAN loss = [2.313638, 0.8281383, 0.8630376]\n",
      "Batch 161/700: Discriminator loss = 1.1587181091308594, GAN loss = [2.3305044, 0.8463806, 0.8617001]\n",
      "Batch 162/700: Discriminator loss = 1.160022258758545, GAN loss = [2.370363, 0.86374474, 0.88419783]\n",
      "Batch 163/700: Discriminator loss = 1.179650902748108, GAN loss = [2.3421385, 0.8466686, 0.8730246]\n",
      "Batch 164/700: Discriminator loss = 1.1482917070388794, GAN loss = [2.3027093, 0.8379235, 0.84232736]\n",
      "Batch 165/700: Discriminator loss = 1.145105242729187, GAN loss = [2.3558996, 0.8625188, 0.87091315]\n",
      "Batch 166/700: Discriminator loss = 1.1879394054412842, GAN loss = [2.2989273, 0.83383447, 0.8426227]\n",
      "Batch 167/700: Discriminator loss = 1.1355046033859253, GAN loss = [2.3167672, 0.86593384, 0.828365]\n",
      "Batch 168/700: Discriminator loss = 1.1347535848617554, GAN loss = [2.3676946, 0.87514395, 0.87008804]\n",
      "Batch 169/700: Discriminator loss = 1.145283818244934, GAN loss = [2.3710523, 0.8567564, 0.8918579]\n",
      "Batch 170/700: Discriminator loss = 1.1552404165267944, GAN loss = [2.3068652, 0.8332592, 0.8511792]\n",
      "Batch 171/700: Discriminator loss = 1.1758533716201782, GAN loss = [2.3311613, 0.8009674, 0.9077415]\n",
      "Batch 172/700: Discriminator loss = 1.1480381488800049, GAN loss = [2.359314, 0.84490937, 0.89192235]\n",
      "Batch 173/700: Discriminator loss = 1.18136727809906, GAN loss = [2.2603824, 0.7975587, 0.84034216]\n",
      "Batch 174/700: Discriminator loss = 1.1576231718063354, GAN loss = [2.3055332, 0.8184265, 0.8646362]\n",
      "Batch 175/700: Discriminator loss = 1.1307258605957031, GAN loss = [2.357919, 0.8611451, 0.8743208]\n",
      "Batch 176/700: Discriminator loss = 1.155403971672058, GAN loss = [2.334296, 0.8149115, 0.89691347]\n",
      "Batch 177/700: Discriminator loss = 1.1346796751022339, GAN loss = [2.3193805, 0.8340301, 0.86288625]\n",
      "Batch 178/700: Discriminator loss = 1.1394877433776855, GAN loss = [2.4149506, 0.8414813, 0.9510278]\n",
      "Batch 179/700: Discriminator loss = 1.1682891845703125, GAN loss = [2.339933, 0.817319, 0.9001758]\n",
      "Batch 180/700: Discriminator loss = 1.1332350969314575, GAN loss = [2.3745475, 0.8391938, 0.91293645]\n",
      "Batch 181/700: Discriminator loss = 1.140553593635559, GAN loss = [2.3885138, 0.843861, 0.922253]\n",
      "Batch 182/700: Discriminator loss = 1.161146640777588, GAN loss = [2.3841622, 0.83129233, 0.93049157]\n",
      "Batch 183/700: Discriminator loss = 1.205924153327942, GAN loss = [2.3827534, 0.78781945, 0.9725431]\n",
      "Batch 184/700: Discriminator loss = 1.152411699295044, GAN loss = [2.441685, 0.82531416, 0.9939708]\n",
      "Batch 185/700: Discriminator loss = 1.168491005897522, GAN loss = [2.3339362, 0.8171521, 0.89440155]\n",
      "Batch 186/700: Discriminator loss = 1.1728466749191284, GAN loss = [2.379152, 0.83849853, 0.9182763]\n",
      "Batch 187/700: Discriminator loss = 1.1702911853790283, GAN loss = [2.3605638, 0.81764024, 0.920515]\n",
      "Batch 188/700: Discriminator loss = 1.172164797782898, GAN loss = [2.3788335, 0.82065225, 0.93575174]\n",
      "Batch 189/700: Discriminator loss = 1.1625256538391113, GAN loss = [2.3311837, 0.8223708, 0.8864002]\n",
      "Batch 190/700: Discriminator loss = 1.1361907720565796, GAN loss = [2.471404, 0.85113066, 0.99788254]\n",
      "Batch 191/700: Discriminator loss = 1.166435718536377, GAN loss = [2.4178414, 0.8176152, 0.9778496]\n",
      "Batch 192/700: Discriminator loss = 1.1281453371047974, GAN loss = [2.3769624, 0.8624567, 0.8921451]\n",
      "Batch 193/700: Discriminator loss = 1.1505838632583618, GAN loss = [2.464774, 0.84464896, 0.9977834]\n",
      "Batch 194/700: Discriminator loss = 1.1623694896697998, GAN loss = [2.3950794, 0.82710814, 0.9456179]\n",
      "Batch 195/700: Discriminator loss = 1.1930744647979736, GAN loss = [2.3916738, 0.8182659, 0.9510239]\n",
      "Batch 196/700: Discriminator loss = 1.140468955039978, GAN loss = [2.4025142, 0.8405048, 0.9396201]\n",
      "Batch 197/700: Discriminator loss = 1.130506157875061, GAN loss = [2.45953, 0.859654, 0.97750795]\n",
      "Batch 198/700: Discriminator loss = 1.1451181173324585, GAN loss = [2.349166, 0.8420479, 0.8847439]\n",
      "Batch 199/700: Discriminator loss = 1.1651642322540283, GAN loss = [2.377397, 0.80575645, 0.94927186]\n",
      "Batch 200/700: Discriminator loss = 1.1370421648025513, GAN loss = [2.3690631, 0.85048383, 0.8962151]\n",
      "Batch 201/700: Discriminator loss = 1.1547185182571411, GAN loss = [2.3455765, 0.8243697, 0.8988476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 202/700: Discriminator loss = 1.1525442600250244, GAN loss = [2.4604516, 0.8479769, 0.99012315]\n",
      "Batch 203/700: Discriminator loss = 1.158503770828247, GAN loss = [2.4892702, 0.83786535, 1.0290295]\n",
      "Batch 204/700: Discriminator loss = 1.2150444984436035, GAN loss = [2.3595922, 0.7894402, 0.9477449]\n",
      "Batch 205/700: Discriminator loss = 1.2038835287094116, GAN loss = [2.326981, 0.8327612, 0.87177527]\n",
      "Batch 206/700: Discriminator loss = 1.2258110046386719, GAN loss = [2.3571432, 0.8545116, 0.88011956]\n",
      "Batch 207/700: Discriminator loss = 1.222345232963562, GAN loss = [2.351701, 0.8272468, 0.90188307]\n",
      "Batch 208/700: Discriminator loss = 1.183548927307129, GAN loss = [2.376942, 0.8371208, 0.9171755]\n",
      "Batch 209/700: Discriminator loss = 1.2212947607040405, GAN loss = [2.2969005, 0.8443326, 0.8298621]\n",
      "Batch 210/700: Discriminator loss = 1.178327202796936, GAN loss = [2.3622754, 0.89502543, 0.84447235]\n",
      "Batch 211/700: Discriminator loss = 1.1853370666503906, GAN loss = [2.2817066, 0.8486335, 0.81023335]\n",
      "Batch 212/700: Discriminator loss = 1.1951626539230347, GAN loss = [2.4294488, 0.8753564, 0.931169]\n",
      "Batch 213/700: Discriminator loss = 1.1693497896194458, GAN loss = [2.433155, 0.9003462, 0.90981346]\n",
      "Batch 214/700: Discriminator loss = 1.188398838043213, GAN loss = [2.3545778, 0.8603244, 0.871204]\n",
      "Batch 215/700: Discriminator loss = 1.1948264837265015, GAN loss = [2.251811, 0.84022707, 0.78841436]\n",
      "Batch 216/700: Discriminator loss = 1.2194827795028687, GAN loss = [2.2992735, 0.8120844, 0.8639492]\n",
      "Batch 217/700: Discriminator loss = 1.2156175374984741, GAN loss = [2.2410169, 0.8226545, 0.7950954]\n",
      "Batch 218/700: Discriminator loss = 1.207679033279419, GAN loss = [2.2620285, 0.7993294, 0.8394274]\n",
      "Batch 219/700: Discriminator loss = 1.2347112894058228, GAN loss = [2.2515154, 0.76999456, 0.8581995]\n",
      "Batch 220/700: Discriminator loss = 1.2168012857437134, GAN loss = [2.1966689, 0.77898896, 0.79428786]\n",
      "Batch 221/700: Discriminator loss = 1.1951124668121338, GAN loss = [2.2872336, 0.8134325, 0.850362]\n",
      "Batch 222/700: Discriminator loss = 1.2298911809921265, GAN loss = [2.20171, 0.7793997, 0.79883194]\n",
      "Batch 223/700: Discriminator loss = 1.2173030376434326, GAN loss = [2.2627952, 0.76359385, 0.87571603]\n",
      "Batch 224/700: Discriminator loss = 1.2298502922058105, GAN loss = [2.1717486, 0.75691724, 0.7913355]\n",
      "Batch 225/700: Discriminator loss = 1.2241469621658325, GAN loss = [2.2468781, 0.7641269, 0.8592842]\n",
      "Batch 226/700: Discriminator loss = 1.201135516166687, GAN loss = [2.2421103, 0.8055681, 0.8130416]\n",
      "Batch 227/700: Discriminator loss = 1.1890907287597656, GAN loss = [2.273918, 0.8059311, 0.84447205]\n",
      "Batch 228/700: Discriminator loss = 1.177018165588379, GAN loss = [2.2577202, 0.81117386, 0.82299393]\n",
      "Batch 229/700: Discriminator loss = 1.2255746126174927, GAN loss = [2.2348077, 0.76703185, 0.84420127]\n",
      "Batch 230/700: Discriminator loss = 1.1321866512298584, GAN loss = [2.3947365, 0.8711674, 0.89995056]\n",
      "Batch 231/700: Discriminator loss = 1.1561534404754639, GAN loss = [2.3645365, 0.8501142, 0.89075243]\n",
      "Batch 232/700: Discriminator loss = 1.1869029998779297, GAN loss = [2.288739, 0.79474413, 0.8702929]\n",
      "Batch 233/700: Discriminator loss = 1.1992496252059937, GAN loss = [2.2567773, 0.79131645, 0.8417746]\n",
      "Batch 234/700: Discriminator loss = 1.1874597072601318, GAN loss = [2.2990599, 0.8082376, 0.86713433]\n",
      "Batch 235/700: Discriminator loss = 1.1658884286880493, GAN loss = [2.2805405, 0.8017336, 0.8550833]\n",
      "Batch 236/700: Discriminator loss = 1.2112547159194946, GAN loss = [2.304857, 0.78195834, 0.899142]\n",
      "Batch 237/700: Discriminator loss = 1.1989907026290894, GAN loss = [2.3148873, 0.7793866, 0.9117421]\n",
      "Batch 238/700: Discriminator loss = 1.217692255973816, GAN loss = [2.3144565, 0.77822554, 0.91246575]\n",
      "Batch 239/700: Discriminator loss = 1.202103853225708, GAN loss = [2.2991369, 0.7655241, 0.9098332]\n",
      "Batch 240/700: Discriminator loss = 1.1763453483581543, GAN loss = [2.3485458, 0.79318506, 0.93158376]\n",
      "Batch 241/700: Discriminator loss = 1.184828519821167, GAN loss = [2.2941105, 0.77556306, 0.89478004]\n",
      "Batch 242/700: Discriminator loss = 1.180349349975586, GAN loss = [2.2701929, 0.78825307, 0.8581742]\n",
      "Batch 243/700: Discriminator loss = 1.233051061630249, GAN loss = [2.2525947, 0.757016, 0.871821]\n",
      "Batch 244/700: Discriminator loss = 1.1960660219192505, GAN loss = [2.2570963, 0.766411, 0.8669297]\n",
      "Batch 245/700: Discriminator loss = 1.200535535812378, GAN loss = [2.3263376, 0.7678762, 0.9347]\n",
      "Batch 246/700: Discriminator loss = 1.1974737644195557, GAN loss = [2.2849996, 0.76462555, 0.8966244]\n",
      "Batch 247/700: Discriminator loss = 1.198677897453308, GAN loss = [2.2552874, 0.76549983, 0.8660384]\n",
      "Batch 248/700: Discriminator loss = 1.1958065032958984, GAN loss = [2.2388902, 0.7735543, 0.8415982]\n",
      "Batch 249/700: Discriminator loss = 1.2005430459976196, GAN loss = [2.2730112, 0.80384254, 0.84545416]\n",
      "Batch 250/700: Discriminator loss = 1.2154967784881592, GAN loss = [2.3312302, 0.77401304, 0.93349975]\n",
      "Batch 251/700: Discriminator loss = 1.188378095626831, GAN loss = [2.2686834, 0.77626526, 0.8687174]\n",
      "Batch 252/700: Discriminator loss = 1.1717361211776733, GAN loss = [2.2988646, 0.7926368, 0.8825538]\n",
      "Batch 253/700: Discriminator loss = 1.1800941228866577, GAN loss = [2.2570517, 0.78487915, 0.84851855]\n",
      "Batch 254/700: Discriminator loss = 1.174559473991394, GAN loss = [2.290168, 0.7765042, 0.8900209]\n",
      "Batch 255/700: Discriminator loss = 1.1717373132705688, GAN loss = [2.3390117, 0.79933816, 0.91603714]\n",
      "Batch 256/700: Discriminator loss = 1.1592082977294922, GAN loss = [2.3119376, 0.79624176, 0.89208925]\n",
      "Batch 257/700: Discriminator loss = 1.17819082736969, GAN loss = [2.3465567, 0.79242975, 0.93053025]\n",
      "Batch 258/700: Discriminator loss = 1.1575367450714111, GAN loss = [2.2970588, 0.80562866, 0.8678215]\n",
      "Batch 259/700: Discriminator loss = 1.1516165733337402, GAN loss = [2.3374376, 0.81263614, 0.90119153]\n",
      "Batch 260/700: Discriminator loss = 1.157961368560791, GAN loss = [2.3604364, 0.8137615, 0.92307925]\n",
      "Batch 261/700: Discriminator loss = 1.1580886840820312, GAN loss = [2.3061035, 0.8053708, 0.87715423]\n",
      "Batch 262/700: Discriminator loss = 1.1565943956375122, GAN loss = [2.361311, 0.80854195, 0.9292055]\n",
      "Batch 263/700: Discriminator loss = 1.1490893363952637, GAN loss = [2.3461294, 0.8206043, 0.90196687]\n",
      "Batch 264/700: Discriminator loss = 1.1583845615386963, GAN loss = [2.3557622, 0.8278166, 0.9043824]\n",
      "Batch 265/700: Discriminator loss = 1.1604233980178833, GAN loss = [2.3832223, 0.8089494, 0.95069104]\n",
      "Batch 266/700: Discriminator loss = 1.1533839702606201, GAN loss = [2.3474221, 0.827137, 0.8967004]\n",
      "Batch 267/700: Discriminator loss = 1.129726529121399, GAN loss = [2.4223213, 0.8456849, 0.95305705]\n",
      "Batch 268/700: Discriminator loss = 1.138519048690796, GAN loss = [2.3796575, 0.8304355, 0.9256685]\n",
      "Batch 269/700: Discriminator loss = 1.1238893270492554, GAN loss = [2.3809614, 0.83335584, 0.9240899]\n",
      "Batch 270/700: Discriminator loss = 1.1571612358093262, GAN loss = [2.4091914, 0.8201185, 0.96559936]\n",
      "Batch 271/700: Discriminator loss = 1.1575559377670288, GAN loss = [2.3445857, 0.80903715, 0.912093]\n",
      "Batch 272/700: Discriminator loss = 1.1855899095535278, GAN loss = [2.3911657, 0.8351974, 0.93253917]\n",
      "Batch 273/700: Discriminator loss = 1.160854697227478, GAN loss = [2.3161557, 0.8084224, 0.8843123]\n",
      "Batch 274/700: Discriminator loss = 1.1614197492599487, GAN loss = [2.4040074, 0.8212518, 0.9593405]\n",
      "Batch 275/700: Discriminator loss = 1.1534290313720703, GAN loss = [2.3895955, 0.83663946, 0.9295867]\n",
      "Batch 276/700: Discriminator loss = 1.149718165397644, GAN loss = [2.3905504, 0.83469224, 0.9325186]\n",
      "Batch 277/700: Discriminator loss = 1.1435807943344116, GAN loss = [2.350112, 0.8334805, 0.8933246]\n",
      "Batch 278/700: Discriminator loss = 1.118926763534546, GAN loss = [2.3971853, 0.86068255, 0.91323656]\n",
      "Batch 279/700: Discriminator loss = 1.1154747009277344, GAN loss = [2.4626343, 0.86207086, 0.97732675]\n",
      "Batch 280/700: Discriminator loss = 1.1160831451416016, GAN loss = [2.4454045, 0.8488469, 0.9733417]\n",
      "Batch 281/700: Discriminator loss = 1.103061318397522, GAN loss = [2.4419787, 0.8639349, 0.95485884]\n",
      "Batch 282/700: Discriminator loss = 1.1421159505844116, GAN loss = [2.3711991, 0.8302114, 0.9178425]\n",
      "Batch 283/700: Discriminator loss = 1.1347798109054565, GAN loss = [2.409793, 0.8341716, 0.95252466]\n",
      "Batch 284/700: Discriminator loss = 1.11842942237854, GAN loss = [2.3774152, 0.8499541, 0.9043977]\n",
      "Batch 285/700: Discriminator loss = 1.1282196044921875, GAN loss = [2.42811, 0.8455832, 0.9595082]\n",
      "Batch 286/700: Discriminator loss = 1.1180553436279297, GAN loss = [2.432044, 0.8451345, 0.9639095]\n",
      "Batch 287/700: Discriminator loss = 1.1436760425567627, GAN loss = [2.4261804, 0.82845026, 0.9747635]\n",
      "Batch 288/700: Discriminator loss = 1.1670399904251099, GAN loss = [2.3888962, 0.814916, 0.95106804]\n",
      "Batch 289/700: Discriminator loss = 1.1629658937454224, GAN loss = [2.4205494, 0.8181686, 0.9795168]\n",
      "Batch 290/700: Discriminator loss = 1.1566424369812012, GAN loss = [2.3862326, 0.8196504, 0.9437513]\n",
      "Batch 291/700: Discriminator loss = 1.1318248510360718, GAN loss = [2.3991475, 0.83505595, 0.9412854]\n",
      "Batch 292/700: Discriminator loss = 1.1639094352722168, GAN loss = [2.3538, 0.811782, 0.9192369]\n",
      "Batch 293/700: Discriminator loss = 1.1739133596420288, GAN loss = [2.3617325, 0.8084264, 0.9305437]\n",
      "Batch 294/700: Discriminator loss = 1.1814672946929932, GAN loss = [2.3212302, 0.79289764, 0.9055927]\n",
      "Batch 295/700: Discriminator loss = 1.1900938749313354, GAN loss = [2.293929, 0.78256804, 0.88863236]\n",
      "Batch 296/700: Discriminator loss = 1.1834521293640137, GAN loss = [2.343112, 0.79475677, 0.9256614]\n",
      "Batch 297/700: Discriminator loss = 1.162157654762268, GAN loss = [2.400511, 0.81524694, 0.96258307]\n",
      "Batch 298/700: Discriminator loss = 1.1713097095489502, GAN loss = [2.412712, 0.82047784, 0.9695649]\n",
      "Batch 299/700: Discriminator loss = 1.1628867387771606, GAN loss = [2.37905, 0.80704206, 0.9493815]\n",
      "Batch 300/700: Discriminator loss = 1.1553854942321777, GAN loss = [2.4083536, 0.83555377, 0.95021594]\n",
      "Batch 301/700: Discriminator loss = 1.1471590995788574, GAN loss = [2.410189, 0.8191171, 0.9685293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 302/700: Discriminator loss = 1.1799734830856323, GAN loss = [2.4097369, 0.81867814, 0.9685431]\n",
      "Batch 303/700: Discriminator loss = 1.1306357383728027, GAN loss = [2.328492, 0.8389421, 0.86705923]\n",
      "Batch 304/700: Discriminator loss = 1.1307859420776367, GAN loss = [2.4646294, 0.85385567, 0.9883275]\n",
      "Batch 305/700: Discriminator loss = 1.1284140348434448, GAN loss = [2.432172, 0.8444261, 0.9653484]\n",
      "Batch 306/700: Discriminator loss = 1.152031660079956, GAN loss = [2.4336817, 0.8400118, 0.9712946]\n",
      "Batch 307/700: Discriminator loss = 1.1555955410003662, GAN loss = [2.3861094, 0.8324669, 0.93128514]\n",
      "Batch 308/700: Discriminator loss = 1.146911382675171, GAN loss = [2.4809854, 0.8457653, 1.0128841]\n",
      "Batch 309/700: Discriminator loss = 1.1495344638824463, GAN loss = [2.386123, 0.83388054, 0.92991966]\n",
      "Batch 310/700: Discriminator loss = 1.1367899179458618, GAN loss = [2.4130342, 0.8514434, 0.9392702]\n",
      "Batch 311/700: Discriminator loss = 1.14205002784729, GAN loss = [2.3770003, 0.8458934, 0.90879667]\n",
      "Batch 312/700: Discriminator loss = 1.1473720073699951, GAN loss = [2.3575606, 0.8439944, 0.8912619]\n",
      "Batch 313/700: Discriminator loss = 1.155992865562439, GAN loss = [2.3170578, 0.8187818, 0.8760159]\n",
      "Batch 314/700: Discriminator loss = 1.1507409811019897, GAN loss = [2.438936, 0.8434247, 0.9732922]\n",
      "Batch 315/700: Discriminator loss = 1.2098901271820068, GAN loss = [2.3597445, 0.8060022, 0.9315319]\n",
      "Batch 316/700: Discriminator loss = 1.165142297744751, GAN loss = [2.4581623, 0.8460592, 0.98991394]\n",
      "Batch 317/700: Discriminator loss = 1.1585428714752197, GAN loss = [2.4100256, 0.82788277, 0.9599637]\n",
      "Batch 318/700: Discriminator loss = 1.168696403503418, GAN loss = [2.3691795, 0.83297735, 0.914021]\n",
      "Batch 319/700: Discriminator loss = 1.1767488718032837, GAN loss = [2.342673, 0.82250196, 0.8979991]\n",
      "Batch 320/700: Discriminator loss = 1.204033374786377, GAN loss = [2.3208268, 0.82278246, 0.87584794]\n",
      "Batch 321/700: Discriminator loss = 1.189697504043579, GAN loss = [2.3595614, 0.8458638, 0.8914566]\n",
      "Batch 322/700: Discriminator loss = 1.1801655292510986, GAN loss = [2.384927, 0.8501121, 0.9125248]\n",
      "Batch 323/700: Discriminator loss = 1.2139461040496826, GAN loss = [2.3416502, 0.83108157, 0.8882259]\n",
      "Batch 324/700: Discriminator loss = 1.1980693340301514, GAN loss = [2.318031, 0.80526876, 0.89037794]\n",
      "Batch 325/700: Discriminator loss = 1.214457392692566, GAN loss = [2.2927089, 0.8118166, 0.85847604]\n",
      "Batch 326/700: Discriminator loss = 1.2285511493682861, GAN loss = [2.3035355, 0.7844208, 0.89669114]\n",
      "Batch 327/700: Discriminator loss = 1.1973124742507935, GAN loss = [2.3139737, 0.8211179, 0.8704156]\n",
      "Batch 328/700: Discriminator loss = 1.1966956853866577, GAN loss = [2.3135996, 0.8219162, 0.8692012]\n",
      "Batch 329/700: Discriminator loss = 1.183115005493164, GAN loss = [2.3548198, 0.8340709, 0.8982253]\n",
      "Batch 330/700: Discriminator loss = 1.2439639568328857, GAN loss = [2.267271, 0.7659907, 0.87872964]\n",
      "Batch 331/700: Discriminator loss = 1.231345295906067, GAN loss = [2.2694235, 0.78168315, 0.8651799]\n",
      "Batch 332/700: Discriminator loss = 1.1771095991134644, GAN loss = [2.3422382, 0.8153962, 0.9042757]\n",
      "Batch 333/700: Discriminator loss = 1.1813453435897827, GAN loss = [2.3068829, 0.8081346, 0.876164]\n",
      "Batch 334/700: Discriminator loss = 1.1745446920394897, GAN loss = [2.3150926, 0.8066798, 0.8858162]\n",
      "Batch 335/700: Discriminator loss = 1.1886404752731323, GAN loss = [2.2401743, 0.7865491, 0.8310007]\n",
      "Batch 336/700: Discriminator loss = 1.2016589641571045, GAN loss = [2.2283347, 0.776613, 0.82910544]\n",
      "Batch 337/700: Discriminator loss = 1.2091032266616821, GAN loss = [2.311251, 0.7803261, 0.90828586]\n",
      "Batch 338/700: Discriminator loss = 1.180579662322998, GAN loss = [2.2745552, 0.79518014, 0.8566914]\n",
      "Batch 339/700: Discriminator loss = 1.1906805038452148, GAN loss = [2.2798848, 0.7902576, 0.8669145]\n",
      "Batch 340/700: Discriminator loss = 1.1962494850158691, GAN loss = [2.2126026, 0.7753027, 0.8145679]\n",
      "Batch 341/700: Discriminator loss = 1.1816773414611816, GAN loss = [2.2924263, 0.78531617, 0.88437086]\n",
      "Batch 342/700: Discriminator loss = 1.1708556413650513, GAN loss = [2.3131573, 0.794811, 0.8956176]\n",
      "Batch 343/700: Discriminator loss = 1.1944624185562134, GAN loss = [2.2643132, 0.7878581, 0.85372895]\n",
      "Batch 344/700: Discriminator loss = 1.1839993000030518, GAN loss = [2.3170342, 0.78399545, 0.9103142]\n",
      "Batch 345/700: Discriminator loss = 1.1902250051498413, GAN loss = [2.2801247, 0.77853847, 0.87887824]\n",
      "Batch 346/700: Discriminator loss = 1.1674647331237793, GAN loss = [2.340239, 0.8105637, 0.90698415]\n",
      "Batch 347/700: Discriminator loss = 1.1917619705200195, GAN loss = [2.2728722, 0.78969383, 0.8604818]\n",
      "Batch 348/700: Discriminator loss = 1.1911755800247192, GAN loss = [2.2693157, 0.7775814, 0.86903954]\n",
      "Batch 349/700: Discriminator loss = 1.1678128242492676, GAN loss = [2.363158, 0.81624585, 0.9242112]\n",
      "Batch 350/700: Discriminator loss = 1.178381323814392, GAN loss = [2.2621925, 0.7880513, 0.85144615]\n",
      "Batch 351/700: Discriminator loss = 1.1790008544921875, GAN loss = [2.3443015, 0.79952705, 0.9220612]\n",
      "Batch 352/700: Discriminator loss = 1.205354928970337, GAN loss = [2.2419078, 0.77866864, 0.8405197]\n",
      "Batch 353/700: Discriminator loss = 1.1749101877212524, GAN loss = [2.3084369, 0.80076134, 0.88498384]\n",
      "Batch 354/700: Discriminator loss = 1.199713110923767, GAN loss = [2.2608464, 0.77555174, 0.8626342]\n",
      "Batch 355/700: Discriminator loss = 1.2125670909881592, GAN loss = [2.274496, 0.7870769, 0.8648014]\n",
      "Batch 356/700: Discriminator loss = 1.213083028793335, GAN loss = [2.2827692, 0.7717448, 0.8884534]\n",
      "Batch 357/700: Discriminator loss = 1.1898553371429443, GAN loss = [2.3445723, 0.8039003, 0.91812307]\n",
      "Batch 358/700: Discriminator loss = 1.2436184883117676, GAN loss = [2.2294614, 0.78242767, 0.82448196]\n",
      "Batch 359/700: Discriminator loss = 1.1900928020477295, GAN loss = [2.3352377, 0.8212245, 0.8914309]\n",
      "Batch 360/700: Discriminator loss = 1.229640007019043, GAN loss = [2.1906352, 0.77482915, 0.7932071]\n",
      "Batch 361/700: Discriminator loss = 1.2136255502700806, GAN loss = [2.2895036, 0.7782612, 0.8886365]\n",
      "Batch 362/700: Discriminator loss = 1.2065411806106567, GAN loss = [2.2797306, 0.7865726, 0.87056786]\n",
      "Batch 363/700: Discriminator loss = 1.2002419233322144, GAN loss = [2.2387495, 0.784095, 0.83206487]\n",
      "Batch 364/700: Discriminator loss = 1.1983891725540161, GAN loss = [2.3299775, 0.80487067, 0.90252966]\n",
      "Batch 365/700: Discriminator loss = 1.1913362741470337, GAN loss = [2.2908063, 0.8156543, 0.85260767]\n",
      "Batch 366/700: Discriminator loss = 1.202069640159607, GAN loss = [2.2955074, 0.80158883, 0.87139374]\n",
      "Batch 367/700: Discriminator loss = 1.2012921571731567, GAN loss = [2.3270934, 0.8171157, 0.88745046]\n",
      "Batch 368/700: Discriminator loss = 1.1619592905044556, GAN loss = [2.3245888, 0.8297075, 0.87239546]\n",
      "Batch 369/700: Discriminator loss = 1.18364417552948, GAN loss = [2.2566652, 0.81365854, 0.8205989]\n",
      "Batch 370/700: Discriminator loss = 1.205640196800232, GAN loss = [2.2255692, 0.7773082, 0.8258755]\n",
      "Batch 371/700: Discriminator loss = 1.2237699031829834, GAN loss = [2.284593, 0.7881605, 0.87405145]\n",
      "Batch 372/700: Discriminator loss = 1.2272976636886597, GAN loss = [2.2179968, 0.7659677, 0.8296549]\n",
      "Batch 373/700: Discriminator loss = 1.2576656341552734, GAN loss = [2.1458485, 0.73021317, 0.793265]\n",
      "Batch 374/700: Discriminator loss = 1.2317779064178467, GAN loss = [2.2347252, 0.7597834, 0.85257775]\n",
      "Batch 375/700: Discriminator loss = 1.2270848751068115, GAN loss = [2.2414534, 0.77440286, 0.8446953]\n",
      "Batch 376/700: Discriminator loss = 1.2397633790969849, GAN loss = [2.2323227, 0.76563907, 0.8443468]\n",
      "Batch 377/700: Discriminator loss = 1.2052104473114014, GAN loss = [2.2366853, 0.7890766, 0.8253093]\n",
      "Batch 378/700: Discriminator loss = 1.2032488584518433, GAN loss = [2.2652934, 0.7994303, 0.84362394]\n",
      "Batch 379/700: Discriminator loss = 1.2018017768859863, GAN loss = [2.241462, 0.7646132, 0.8546641]\n",
      "Batch 380/700: Discriminator loss = 1.2465202808380127, GAN loss = [2.2549677, 0.74540484, 0.8874252]\n",
      "Batch 381/700: Discriminator loss = 1.2132877111434937, GAN loss = [2.230636, 0.755292, 0.85324425]\n",
      "Batch 382/700: Discriminator loss = 1.227550745010376, GAN loss = [2.2236848, 0.75573814, 0.8458737]\n",
      "Batch 383/700: Discriminator loss = 1.1976367235183716, GAN loss = [2.2254481, 0.782151, 0.82125556]\n",
      "Batch 384/700: Discriminator loss = 1.1917740106582642, GAN loss = [2.2449474, 0.77998054, 0.84296685]\n",
      "Batch 385/700: Discriminator loss = 1.1956980228424072, GAN loss = [2.303656, 0.7850246, 0.8966707]\n",
      "Batch 386/700: Discriminator loss = 1.1767840385437012, GAN loss = [2.2590485, 0.79579926, 0.8413312]\n",
      "Batch 387/700: Discriminator loss = 1.176044225692749, GAN loss = [2.3041897, 0.8099746, 0.872367]\n",
      "Batch 388/700: Discriminator loss = 1.1772985458374023, GAN loss = [2.2528813, 0.7907139, 0.84037614]\n",
      "Batch 389/700: Discriminator loss = 1.1739293336868286, GAN loss = [2.2546675, 0.79934096, 0.8335923]\n",
      "Batch 390/700: Discriminator loss = 1.1942185163497925, GAN loss = [2.3164117, 0.7868857, 0.9078585]\n",
      "Batch 391/700: Discriminator loss = 1.1816505193710327, GAN loss = [2.248023, 0.78079176, 0.8456152]\n",
      "Batch 392/700: Discriminator loss = 1.1857317686080933, GAN loss = [2.249801, 0.7959398, 0.83229506]\n",
      "Batch 393/700: Discriminator loss = 1.1833189725875854, GAN loss = [2.2847054, 0.80562776, 0.85755134]\n",
      "Batch 394/700: Discriminator loss = 1.1851632595062256, GAN loss = [2.210808, 0.7952984, 0.79401135]\n",
      "Batch 395/700: Discriminator loss = 1.187081217765808, GAN loss = [2.289294, 0.8097746, 0.85805374]\n",
      "Batch 396/700: Discriminator loss = 1.165757417678833, GAN loss = [2.2680337, 0.8173158, 0.8292604]\n",
      "Batch 397/700: Discriminator loss = 1.1840651035308838, GAN loss = [2.250701, 0.79363906, 0.83561325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 398/700: Discriminator loss = 1.194097638130188, GAN loss = [2.2622125, 0.78627455, 0.85449654]\n",
      "Batch 399/700: Discriminator loss = 1.17958402633667, GAN loss = [2.2957826, 0.7947786, 0.8795752]\n",
      "Batch 400/700: Discriminator loss = 1.1811388731002808, GAN loss = [2.26439, 0.79285514, 0.8501337]\n",
      "Batch 401/700: Discriminator loss = 1.1630563735961914, GAN loss = [2.3119123, 0.8027184, 0.88779664]\n",
      "Batch 402/700: Discriminator loss = 1.1699172258377075, GAN loss = [2.339124, 0.80350775, 0.91420954]\n",
      "Batch 403/700: Discriminator loss = 1.1694315671920776, GAN loss = [2.2598839, 0.80960715, 0.8288835]\n",
      "Batch 404/700: Discriminator loss = 1.1742666959762573, GAN loss = [2.3409595, 0.79791564, 0.92166936]\n",
      "Batch 405/700: Discriminator loss = 1.16814386844635, GAN loss = [2.2880921, 0.7906378, 0.8760938]\n",
      "Batch 406/700: Discriminator loss = 1.164455771446228, GAN loss = [2.3314245, 0.7950328, 0.9150425]\n",
      "Batch 407/700: Discriminator loss = 1.1903637647628784, GAN loss = [2.3419633, 0.7969605, 0.9236462]\n",
      "Batch 408/700: Discriminator loss = 1.1763536930084229, GAN loss = [2.3342335, 0.8041012, 0.9087634]\n",
      "Batch 409/700: Discriminator loss = 1.1704221963882446, GAN loss = [2.286892, 0.79063916, 0.8748649]\n",
      "Batch 410/700: Discriminator loss = 1.1876283884048462, GAN loss = [2.3172235, 0.7902578, 0.90556926]\n",
      "Batch 411/700: Discriminator loss = 1.1710761785507202, GAN loss = [2.3546908, 0.79247206, 0.94081205]\n",
      "Batch 412/700: Discriminator loss = 1.1965587139129639, GAN loss = [2.2902727, 0.7932923, 0.87557495]\n",
      "Batch 413/700: Discriminator loss = 1.1890993118286133, GAN loss = [2.365955, 0.80234474, 0.94221234]\n",
      "Batch 414/700: Discriminator loss = 1.1701337099075317, GAN loss = [2.3220794, 0.794751, 0.9059388]\n",
      "Batch 415/700: Discriminator loss = 1.1740742921829224, GAN loss = [2.3517787, 0.8009663, 0.9294125]\n",
      "Batch 416/700: Discriminator loss = 1.1804912090301514, GAN loss = [2.330514, 0.7903952, 0.9187238]\n",
      "Batch 417/700: Discriminator loss = 1.1448776721954346, GAN loss = [2.3346066, 0.83652616, 0.8767152]\n",
      "Batch 418/700: Discriminator loss = 1.189538598060608, GAN loss = [2.3633873, 0.80540854, 0.9366478]\n",
      "Batch 419/700: Discriminator loss = 1.1968351602554321, GAN loss = [2.2964547, 0.8145553, 0.86061066]\n",
      "Batch 420/700: Discriminator loss = 1.1884771585464478, GAN loss = [2.3172343, 0.8011491, 0.8948178]\n",
      "Batch 421/700: Discriminator loss = 1.183170199394226, GAN loss = [2.3125057, 0.7934048, 0.89782584]\n",
      "Batch 422/700: Discriminator loss = 1.1897505521774292, GAN loss = [2.2933028, 0.79302424, 0.8790169]\n",
      "Batch 423/700: Discriminator loss = 1.1756759881973267, GAN loss = [2.305965, 0.8132877, 0.8714355]\n",
      "Batch 424/700: Discriminator loss = 1.168856143951416, GAN loss = [2.2828925, 0.82799834, 0.83364916]\n",
      "Batch 425/700: Discriminator loss = 1.1778539419174194, GAN loss = [2.3134205, 0.7869048, 0.90529877]\n",
      "Batch 426/700: Discriminator loss = 1.1728012561798096, GAN loss = [2.3347297, 0.81347543, 0.9000803]\n",
      "Batch 427/700: Discriminator loss = 1.191064476966858, GAN loss = [2.3596334, 0.78582716, 0.95269173]\n",
      "Batch 428/700: Discriminator loss = 1.19610595703125, GAN loss = [2.2496364, 0.7809844, 0.8475608]\n",
      "Batch 429/700: Discriminator loss = 1.2218683958053589, GAN loss = [2.219205, 0.74932045, 0.848778]\n",
      "Batch 430/700: Discriminator loss = 1.2133175134658813, GAN loss = [2.3458118, 0.79351526, 0.9311956]\n",
      "Batch 431/700: Discriminator loss = 1.2063428163528442, GAN loss = [2.2795458, 0.77150583, 0.88693833]\n",
      "Batch 432/700: Discriminator loss = 1.219668984413147, GAN loss = [2.328632, 0.7940352, 0.91348505]\n",
      "Batch 433/700: Discriminator loss = 1.197702407836914, GAN loss = [2.2855933, 0.7855274, 0.87896913]\n",
      "Batch 434/700: Discriminator loss = 1.2095725536346436, GAN loss = [2.2910264, 0.7674968, 0.90244865]\n",
      "Batch 435/700: Discriminator loss = 1.1976220607757568, GAN loss = [2.280147, 0.78668386, 0.8723886]\n",
      "Batch 436/700: Discriminator loss = 1.202032208442688, GAN loss = [2.2525299, 0.76708794, 0.8643749]\n",
      "Batch 437/700: Discriminator loss = 1.2164181470870972, GAN loss = [2.2889636, 0.76784, 0.90007097]\n",
      "Batch 438/700: Discriminator loss = 1.2013622522354126, GAN loss = [2.2923098, 0.77673525, 0.8945536]\n",
      "Batch 439/700: Discriminator loss = 1.1792672872543335, GAN loss = [2.334918, 0.80685395, 0.9071055]\n",
      "Batch 440/700: Discriminator loss = 1.1917874813079834, GAN loss = [2.339898, 0.7995758, 0.9194119]\n",
      "Batch 441/700: Discriminator loss = 1.157915472984314, GAN loss = [2.3834865, 0.81323075, 0.9493725]\n",
      "Batch 442/700: Discriminator loss = 1.172567367553711, GAN loss = [2.2950983, 0.79361504, 0.8806247]\n",
      "Batch 443/700: Discriminator loss = 1.1575301885604858, GAN loss = [2.326868, 0.8163868, 0.8896405]\n",
      "Batch 444/700: Discriminator loss = 1.169594168663025, GAN loss = [2.3730228, 0.82581747, 0.9263742]\n",
      "Batch 445/700: Discriminator loss = 1.186380386352539, GAN loss = [2.3249328, 0.7897541, 0.91434836]\n",
      "Batch 446/700: Discriminator loss = 1.1863305568695068, GAN loss = [2.3499694, 0.7938562, 0.9352831]\n",
      "Batch 447/700: Discriminator loss = 1.1956446170806885, GAN loss = [2.3584476, 0.8087059, 0.9289155]\n",
      "Batch 448/700: Discriminator loss = 1.1805264949798584, GAN loss = [2.3690002, 0.82388407, 0.92428124]\n",
      "Batch 449/700: Discriminator loss = 1.183919906616211, GAN loss = [2.2930446, 0.79894483, 0.8732782]\n",
      "Batch 450/700: Discriminator loss = 1.1707996129989624, GAN loss = [2.3560517, 0.8140866, 0.92117447]\n",
      "Batch 451/700: Discriminator loss = 1.1732146739959717, GAN loss = [2.2932403, 0.8539543, 0.81852317]\n",
      "Batch 452/700: Discriminator loss = 1.1639868021011353, GAN loss = [2.3327246, 0.826794, 0.8851986]\n",
      "Batch 453/700: Discriminator loss = 1.1601444482803345, GAN loss = [2.3123517, 0.8390745, 0.85256964]\n",
      "Batch 454/700: Discriminator loss = 1.168784499168396, GAN loss = [2.3246675, 0.8256562, 0.8783136]\n",
      "Batch 455/700: Discriminator loss = 1.1230913400650024, GAN loss = [2.3563344, 0.8760071, 0.85963404]\n",
      "Batch 456/700: Discriminator loss = 1.1380045413970947, GAN loss = [2.354569, 0.8618556, 0.87202376]\n",
      "Batch 457/700: Discriminator loss = 1.1331393718719482, GAN loss = [2.3640065, 0.8462053, 0.8971204]\n",
      "Batch 458/700: Discriminator loss = 1.1563997268676758, GAN loss = [2.3819656, 0.8283191, 0.9329746]\n",
      "Batch 459/700: Discriminator loss = 1.1604208946228027, GAN loss = [2.3342505, 0.83958083, 0.8740132]\n",
      "Batch 460/700: Discriminator loss = 1.1394317150115967, GAN loss = [2.3444831, 0.8424144, 0.8814191]\n",
      "Batch 461/700: Discriminator loss = 1.165867567062378, GAN loss = [2.310099, 0.8149107, 0.87453705]\n",
      "Batch 462/700: Discriminator loss = 1.144323468208313, GAN loss = [2.365283, 0.8390234, 0.90559125]\n",
      "Batch 463/700: Discriminator loss = 1.1690202951431274, GAN loss = [2.3635612, 0.80124444, 0.941643]\n",
      "Batch 464/700: Discriminator loss = 1.1459624767303467, GAN loss = [2.3721163, 0.84107965, 0.9103369]\n",
      "Batch 465/700: Discriminator loss = 1.1606141328811646, GAN loss = [2.3564947, 0.833897, 0.90190095]\n",
      "Batch 466/700: Discriminator loss = 1.1916306018829346, GAN loss = [2.3812659, 0.8440448, 0.91654444]\n",
      "Batch 467/700: Discriminator loss = 1.1587036848068237, GAN loss = [2.3339958, 0.83414, 0.8791915]\n",
      "Batch 468/700: Discriminator loss = 1.122678279876709, GAN loss = [2.3934608, 0.86502236, 0.9077914]\n",
      "Batch 469/700: Discriminator loss = 1.1413836479187012, GAN loss = [2.4082077, 0.857292, 0.93028647]\n",
      "Batch 470/700: Discriminator loss = 1.1721152067184448, GAN loss = [2.286618, 0.81290597, 0.8530758]\n",
      "Batch 471/700: Discriminator loss = 1.15651273727417, GAN loss = [2.3747985, 0.82784355, 0.92631495]\n",
      "Batch 472/700: Discriminator loss = 1.1868433952331543, GAN loss = [2.2698476, 0.8018106, 0.8474057]\n",
      "Batch 473/700: Discriminator loss = 1.165033221244812, GAN loss = [2.3021376, 0.82263494, 0.85888773]\n",
      "Batch 474/700: Discriminator loss = 1.1807329654693604, GAN loss = [2.3176057, 0.8171021, 0.87990874]\n",
      "Batch 475/700: Discriminator loss = 1.1770623922348022, GAN loss = [2.3560221, 0.823861, 0.9115834]\n",
      "Batch 476/700: Discriminator loss = 1.164222240447998, GAN loss = [2.300735, 0.8132458, 0.8668976]\n",
      "Batch 477/700: Discriminator loss = 1.1518263816833496, GAN loss = [2.3455985, 0.8266476, 0.898353]\n",
      "Batch 478/700: Discriminator loss = 1.1780891418457031, GAN loss = [2.3361762, 0.82174563, 0.89385384]\n",
      "Batch 479/700: Discriminator loss = 1.1558562517166138, GAN loss = [2.3751254, 0.8568036, 0.89777017]\n",
      "Batch 480/700: Discriminator loss = 1.1364191770553589, GAN loss = [2.3962564, 0.8474548, 0.9282821]\n",
      "Batch 481/700: Discriminator loss = 1.1692063808441162, GAN loss = [2.4194841, 0.8422863, 0.95669365]\n",
      "Batch 482/700: Discriminator loss = 1.1369128227233887, GAN loss = [2.336879, 0.8501327, 0.8662641]\n",
      "Batch 483/700: Discriminator loss = 1.1484239101409912, GAN loss = [2.3176334, 0.8281154, 0.86905026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 484/700: Discriminator loss = 1.145277738571167, GAN loss = [2.403486, 0.85547805, 0.92755586]\n",
      "Batch 485/700: Discriminator loss = 1.185604214668274, GAN loss = [2.3032756, 0.7945022, 0.8883455]\n",
      "Batch 486/700: Discriminator loss = 1.1670116186141968, GAN loss = [2.2770967, 0.796836, 0.8598354]\n",
      "Batch 487/700: Discriminator loss = 1.1624921560287476, GAN loss = [2.2869844, 0.8058886, 0.8606661]\n",
      "Batch 488/700: Discriminator loss = 1.1483476161956787, GAN loss = [2.3439007, 0.81653917, 0.90691537]\n",
      "Batch 489/700: Discriminator loss = 1.1800228357315063, GAN loss = [2.2910016, 0.7672074, 0.90335035]\n",
      "Batch 490/700: Discriminator loss = 1.1808257102966309, GAN loss = [2.3284872, 0.7658847, 0.94218135]\n",
      "Batch 491/700: Discriminator loss = 1.175173282623291, GAN loss = [2.3196516, 0.78255045, 0.9167274]\n",
      "Batch 492/700: Discriminator loss = 1.1775758266448975, GAN loss = [2.29633, 0.77199954, 0.9039885]\n",
      "Batch 493/700: Discriminator loss = 1.1720079183578491, GAN loss = [2.30688, 0.77994734, 0.9066095]\n",
      "Batch 494/700: Discriminator loss = 1.167555809020996, GAN loss = [2.342771, 0.79238397, 0.93007797]\n",
      "Batch 495/700: Discriminator loss = 1.162460446357727, GAN loss = [2.342392, 0.799978, 0.9221301]\n",
      "Batch 496/700: Discriminator loss = 1.1882317066192627, GAN loss = [2.3106897, 0.78725, 0.90317017]\n",
      "Batch 497/700: Discriminator loss = 1.1462632417678833, GAN loss = [2.4058785, 0.8329218, 0.95269936]\n",
      "Batch 498/700: Discriminator loss = 1.1257641315460205, GAN loss = [2.3919501, 0.84091973, 0.93078226]\n",
      "Batch 499/700: Discriminator loss = 1.1484745740890503, GAN loss = [2.3325126, 0.81211936, 0.9001555]\n",
      "Batch 500/700: Discriminator loss = 1.128112554550171, GAN loss = [2.324576, 0.8280119, 0.8763393]\n",
      "Batch 501/700: Discriminator loss = 1.1607102155685425, GAN loss = [2.3198555, 0.79372466, 0.90591097]\n",
      "Batch 502/700: Discriminator loss = 1.1525635719299316, GAN loss = [2.3272688, 0.7975991, 0.9094592]\n",
      "Batch 503/700: Discriminator loss = 1.1416723728179932, GAN loss = [2.3456352, 0.84006333, 0.88537437]\n",
      "Batch 504/700: Discriminator loss = 1.1350678205490112, GAN loss = [2.397175, 0.8433683, 0.9336305]\n",
      "Batch 505/700: Discriminator loss = 1.1275362968444824, GAN loss = [2.3835738, 0.84052575, 0.9228981]\n",
      "Batch 506/700: Discriminator loss = 1.1353691816329956, GAN loss = [2.3720095, 0.83222777, 0.9196464]\n",
      "Batch 507/700: Discriminator loss = 1.118977427482605, GAN loss = [2.390113, 0.8460958, 0.9239104]\n",
      "Batch 508/700: Discriminator loss = 1.1225508451461792, GAN loss = [2.3238087, 0.8329775, 0.87075454]\n",
      "Batch 509/700: Discriminator loss = 1.1291532516479492, GAN loss = [2.36926, 0.8345896, 0.9146298]\n",
      "Batch 510/700: Discriminator loss = 1.12357759475708, GAN loss = [2.4078877, 0.8571325, 0.9307608]\n",
      "Batch 511/700: Discriminator loss = 1.1406089067459106, GAN loss = [2.382372, 0.8301015, 0.9323194]\n",
      "Batch 512/700: Discriminator loss = 1.120856523513794, GAN loss = [2.422704, 0.8326, 0.9701759]\n",
      "Batch 513/700: Discriminator loss = 1.1093711853027344, GAN loss = [2.4017599, 0.840267, 0.9415926]\n",
      "Batch 514/700: Discriminator loss = 1.108851432800293, GAN loss = [2.4307973, 0.8466754, 0.96424055]\n",
      "Batch 515/700: Discriminator loss = 1.1196519136428833, GAN loss = [2.385676, 0.84651136, 0.9193148]\n",
      "Batch 516/700: Discriminator loss = 1.1231878995895386, GAN loss = [2.4083915, 0.8416382, 0.9469192]\n",
      "Batch 517/700: Discriminator loss = 1.1254470348358154, GAN loss = [2.3781645, 0.825561, 0.9327977]\n",
      "Batch 518/700: Discriminator loss = 1.1301220655441284, GAN loss = [2.3834379, 0.8339386, 0.92971146]\n",
      "Batch 519/700: Discriminator loss = 1.1366839408874512, GAN loss = [2.4545484, 0.83490646, 0.9998814]\n",
      "Batch 520/700: Discriminator loss = 1.1219141483306885, GAN loss = [2.386465, 0.85319066, 0.9135187]\n",
      "Batch 521/700: Discriminator loss = 1.131021499633789, GAN loss = [2.3971753, 0.8454612, 0.9319695]\n",
      "Batch 522/700: Discriminator loss = 1.1145062446594238, GAN loss = [2.3974857, 0.85475916, 0.9229882]\n",
      "Batch 523/700: Discriminator loss = 1.1322475671768188, GAN loss = [2.4351835, 0.8438148, 0.97163355]\n",
      "Batch 524/700: Discriminator loss = 1.1401786804199219, GAN loss = [2.368056, 0.82003564, 0.92826253]\n",
      "Batch 525/700: Discriminator loss = 1.155478835105896, GAN loss = [2.412577, 0.81337404, 0.979433]\n",
      "Batch 526/700: Discriminator loss = 1.129058837890625, GAN loss = [2.4054046, 0.834982, 0.9506498]\n",
      "Batch 527/700: Discriminator loss = 1.1300023794174194, GAN loss = [2.3837292, 0.8481998, 0.9157745]\n",
      "Batch 528/700: Discriminator loss = 1.1345411539077759, GAN loss = [2.388664, 0.83760715, 0.9313114]\n",
      "Batch 529/700: Discriminator loss = 1.1576334238052368, GAN loss = [2.3853688, 0.8287016, 0.9369427]\n",
      "Batch 530/700: Discriminator loss = 1.1488890647888184, GAN loss = [2.3775518, 0.8261264, 0.9317035]\n",
      "Batch 531/700: Discriminator loss = 1.1552454233169556, GAN loss = [2.3579895, 0.8312285, 0.9070427]\n",
      "Batch 532/700: Discriminator loss = 1.155588984489441, GAN loss = [2.4125297, 0.8276951, 0.9651136]\n",
      "Batch 533/700: Discriminator loss = 1.1617891788482666, GAN loss = [2.3793786, 0.82168365, 0.9379611]\n",
      "Batch 534/700: Discriminator loss = 1.1580510139465332, GAN loss = [2.4171894, 0.82604307, 0.97140825]\n",
      "Batch 535/700: Discriminator loss = 1.158173680305481, GAN loss = [2.3888159, 0.82710373, 0.9419334]\n",
      "Batch 536/700: Discriminator loss = 1.1730561256408691, GAN loss = [2.4021764, 0.84545463, 0.93689674]\n",
      "Batch 537/700: Discriminator loss = 1.1618726253509521, GAN loss = [2.3966694, 0.85058504, 0.92619073]\n",
      "Batch 538/700: Discriminator loss = 1.1790908575057983, GAN loss = [2.3993502, 0.83522683, 0.9441695]\n",
      "Batch 539/700: Discriminator loss = 1.1494585275650024, GAN loss = [2.3583643, 0.8532624, 0.88505965]\n",
      "Batch 540/700: Discriminator loss = 1.164088249206543, GAN loss = [2.4204245, 0.8754685, 0.92484945]\n",
      "Batch 541/700: Discriminator loss = 1.1605682373046875, GAN loss = [2.4048703, 0.85656923, 0.9281423]\n",
      "Batch 542/700: Discriminator loss = 1.151749849319458, GAN loss = [2.4120505, 0.8610009, 0.9308448]\n",
      "Batch 543/700: Discriminator loss = 1.133341908454895, GAN loss = [2.4702919, 0.90332776, 0.9467307]\n",
      "Batch 544/700: Discriminator loss = 1.1604933738708496, GAN loss = [2.4096017, 0.85660285, 0.9327177]\n",
      "Batch 545/700: Discriminator loss = 1.1078548431396484, GAN loss = [2.5092382, 0.9190023, 0.96996534]\n",
      "Batch 546/700: Discriminator loss = 1.132264494895935, GAN loss = [2.4265049, 0.8818452, 0.92441607]\n",
      "Batch 547/700: Discriminator loss = 1.1278483867645264, GAN loss = [2.5098104, 0.905859, 0.9837416]\n",
      "Batch 548/700: Discriminator loss = 1.134759545326233, GAN loss = [2.4328818, 0.88813263, 0.9245696]\n",
      "Batch 549/700: Discriminator loss = 1.113585352897644, GAN loss = [2.4556804, 0.9251234, 0.9104264]\n",
      "Batch 550/700: Discriminator loss = 1.1227535009384155, GAN loss = [2.503696, 0.9036037, 0.98001784]\n",
      "Batch 551/700: Discriminator loss = 1.1273781061172485, GAN loss = [2.5076077, 0.91062856, 0.9769774]\n",
      "Batch 552/700: Discriminator loss = 1.1128606796264648, GAN loss = [2.5566986, 0.9037486, 1.0329994]\n",
      "Batch 553/700: Discriminator loss = 1.10663902759552, GAN loss = [2.5456793, 0.9365905, 0.9891809]\n",
      "Batch 554/700: Discriminator loss = 1.1407395601272583, GAN loss = [2.5056808, 0.87561154, 1.0101963]\n",
      "Batch 555/700: Discriminator loss = 1.1605570316314697, GAN loss = [2.469395, 0.8670904, 0.9824973]\n",
      "Batch 556/700: Discriminator loss = 1.1632888317108154, GAN loss = [2.4730775, 0.8604415, 0.9928655]\n",
      "Batch 557/700: Discriminator loss = 1.180098056793213, GAN loss = [2.4213555, 0.83132124, 0.9702803]\n",
      "Batch 558/700: Discriminator loss = 1.1730722188949585, GAN loss = [2.4000425, 0.8599276, 0.92038286]\n",
      "Batch 559/700: Discriminator loss = 1.1683536767959595, GAN loss = [2.4299464, 0.8663987, 0.943819]\n",
      "Batch 560/700: Discriminator loss = 1.159713864326477, GAN loss = [2.488392, 0.88518775, 0.9834894]\n",
      "Batch 561/700: Discriminator loss = 1.1629921197891235, GAN loss = [2.4419174, 0.85952264, 0.9626889]\n",
      "Batch 562/700: Discriminator loss = 1.1605830192565918, GAN loss = [2.3414726, 0.83886147, 0.88292193]\n",
      "Batch 563/700: Discriminator loss = 1.1676077842712402, GAN loss = [2.370858, 0.8255353, 0.92564744]\n",
      "Batch 564/700: Discriminator loss = 1.172835350036621, GAN loss = [2.344673, 0.8341384, 0.8908713]\n",
      "Batch 565/700: Discriminator loss = 1.1723458766937256, GAN loss = [2.3191485, 0.8401303, 0.8593528]\n",
      "Batch 566/700: Discriminator loss = 1.1675771474838257, GAN loss = [2.3511593, 0.8178286, 0.91362864]\n",
      "Batch 567/700: Discriminator loss = 1.15323007106781, GAN loss = [2.3778858, 0.84169394, 0.91645277]\n",
      "Batch 568/700: Discriminator loss = 1.1748217344284058, GAN loss = [2.359451, 0.8630679, 0.87662446]\n",
      "Batch 569/700: Discriminator loss = 1.1279234886169434, GAN loss = [2.39779, 0.8648499, 0.9131748]\n",
      "Batch 570/700: Discriminator loss = 1.15578031539917, GAN loss = [2.3182013, 0.84436625, 0.8540564]\n",
      "Batch 571/700: Discriminator loss = 1.1654343605041504, GAN loss = [2.4461756, 0.8444693, 0.98190475]\n",
      "Batch 572/700: Discriminator loss = 1.1657999753952026, GAN loss = [2.321868, 0.84885216, 0.85320973]\n",
      "Batch 573/700: Discriminator loss = 1.1603903770446777, GAN loss = [2.4295325, 0.8729749, 0.93672836]\n",
      "Batch 574/700: Discriminator loss = 1.1656473875045776, GAN loss = [2.4391878, 0.8506478, 0.9686623]\n",
      "Batch 575/700: Discriminator loss = 1.19447922706604, GAN loss = [2.3231049, 0.8190387, 0.88414377]\n",
      "Batch 576/700: Discriminator loss = 1.1803407669067383, GAN loss = [2.3343036, 0.8366808, 0.8776612]\n",
      "Batch 577/700: Discriminator loss = 1.198423981666565, GAN loss = [2.3075516, 0.79988134, 0.8876741]\n",
      "Batch 578/700: Discriminator loss = 1.1780427694320679, GAN loss = [2.3212457, 0.8054548, 0.8957816]\n",
      "Batch 579/700: Discriminator loss = 1.2125579118728638, GAN loss = [2.318159, 0.79414696, 0.9039836]\n",
      "Batch 580/700: Discriminator loss = 1.199550986289978, GAN loss = [2.3109179, 0.80975515, 0.8811286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 581/700: Discriminator loss = 1.2033824920654297, GAN loss = [2.311132, 0.8083696, 0.8826875]\n",
      "Batch 582/700: Discriminator loss = 1.1901757717132568, GAN loss = [2.352869, 0.8349297, 0.8978604]\n",
      "Batch 583/700: Discriminator loss = 1.1805205345153809, GAN loss = [2.3279886, 0.82924545, 0.8786283]\n",
      "Batch 584/700: Discriminator loss = 1.1890140771865845, GAN loss = [2.3095145, 0.8055508, 0.88385636]\n",
      "Batch 585/700: Discriminator loss = 1.2375932931900024, GAN loss = [2.2721279, 0.7598996, 0.892101]\n",
      "Batch 586/700: Discriminator loss = 1.1917881965637207, GAN loss = [2.233235, 0.81801707, 0.7950578]\n",
      "Batch 587/700: Discriminator loss = 1.2034735679626465, GAN loss = [2.3405793, 0.8374821, 0.88290644]\n",
      "Batch 588/700: Discriminator loss = 1.1896284818649292, GAN loss = [2.3109457, 0.8390799, 0.851605]\n",
      "Batch 589/700: Discriminator loss = 1.20599365234375, GAN loss = [2.260252, 0.79033446, 0.84965533]\n",
      "Batch 590/700: Discriminator loss = 1.1930584907531738, GAN loss = [2.2632368, 0.8023439, 0.84059846]\n",
      "Batch 591/700: Discriminator loss = 1.1807844638824463, GAN loss = [2.2902372, 0.8167298, 0.8532122]\n",
      "Batch 592/700: Discriminator loss = 1.2042841911315918, GAN loss = [2.251014, 0.81057554, 0.8201518]\n",
      "Batch 593/700: Discriminator loss = 1.1814560890197754, GAN loss = [2.2900338, 0.8254749, 0.84428304]\n",
      "Batch 594/700: Discriminator loss = 1.1911602020263672, GAN loss = [2.2756746, 0.8142161, 0.84115034]\n",
      "Batch 595/700: Discriminator loss = 1.1795830726623535, GAN loss = [2.2869856, 0.84030664, 0.82634795]\n",
      "Batch 596/700: Discriminator loss = 1.1826190948486328, GAN loss = [2.2850213, 0.83029854, 0.8343711]\n",
      "Batch 597/700: Discriminator loss = 1.229598879814148, GAN loss = [2.2308335, 0.77239305, 0.838062]\n",
      "Batch 598/700: Discriminator loss = 1.1908085346221924, GAN loss = [2.2640624, 0.80277425, 0.840896]\n",
      "Batch 599/700: Discriminator loss = 1.2069494724273682, GAN loss = [2.2076206, 0.76803976, 0.81916857]\n",
      "Batch 600/700: Discriminator loss = 1.2109930515289307, GAN loss = [2.2453043, 0.7813566, 0.8435133]\n",
      "Batch 601/700: Discriminator loss = 1.2577142715454102, GAN loss = [2.2261329, 0.7813393, 0.8243274]\n",
      "Batch 602/700: Discriminator loss = 1.2314584255218506, GAN loss = [2.231436, 0.77628744, 0.834667]\n",
      "Batch 603/700: Discriminator loss = 1.2461026906967163, GAN loss = [2.192182, 0.7478409, 0.8238506]\n",
      "Batch 604/700: Discriminator loss = 1.2426011562347412, GAN loss = [2.1924703, 0.76338387, 0.8085919]\n",
      "Batch 605/700: Discriminator loss = 1.240522027015686, GAN loss = [2.2461984, 0.7650785, 0.8606012]\n",
      "Batch 606/700: Discriminator loss = 1.215145468711853, GAN loss = [2.2977097, 0.8151997, 0.8619485]\n",
      "Batch 607/700: Discriminator loss = 1.1837470531463623, GAN loss = [2.269771, 0.83221763, 0.8170019]\n",
      "Batch 608/700: Discriminator loss = 1.2120792865753174, GAN loss = [2.3172176, 0.8132517, 0.8834226]\n",
      "Batch 609/700: Discriminator loss = 1.1894891262054443, GAN loss = [2.3244624, 0.81180674, 0.8921511]\n",
      "Batch 610/700: Discriminator loss = 1.1891255378723145, GAN loss = [2.3045268, 0.80740213, 0.876649]\n",
      "Batch 611/700: Discriminator loss = 1.2064348459243774, GAN loss = [2.2569828, 0.7922508, 0.8442835]\n",
      "Batch 612/700: Discriminator loss = 1.1795034408569336, GAN loss = [2.2587867, 0.8165949, 0.82175916]\n",
      "Batch 613/700: Discriminator loss = 1.1787562370300293, GAN loss = [2.2719636, 0.8184725, 0.8330757]\n",
      "Batch 614/700: Discriminator loss = 1.2050899267196655, GAN loss = [2.3092372, 0.8115543, 0.8772818]\n",
      "Batch 615/700: Discriminator loss = 1.2078276872634888, GAN loss = [2.265097, 0.8186041, 0.826138]\n",
      "Batch 616/700: Discriminator loss = 1.1739376783370972, GAN loss = [2.3110316, 0.8288939, 0.8618036]\n",
      "Batch 617/700: Discriminator loss = 1.1807678937911987, GAN loss = [2.3049295, 0.8414013, 0.843216]\n",
      "Batch 618/700: Discriminator loss = 1.1877083778381348, GAN loss = [2.256145, 0.8293408, 0.8065303]\n",
      "Batch 619/700: Discriminator loss = 1.1641405820846558, GAN loss = [2.298485, 0.84361297, 0.8346594]\n",
      "Batch 620/700: Discriminator loss = 1.1825191974639893, GAN loss = [2.295606, 0.828416, 0.8470153]\n",
      "Batch 621/700: Discriminator loss = 1.1806368827819824, GAN loss = [2.3111997, 0.8213051, 0.8697593]\n",
      "Batch 622/700: Discriminator loss = 1.182352900505066, GAN loss = [2.3226314, 0.8140479, 0.8884923]\n",
      "Batch 623/700: Discriminator loss = 1.147362232208252, GAN loss = [2.3573887, 0.86895454, 0.86837816]\n",
      "Batch 624/700: Discriminator loss = 1.1667536497116089, GAN loss = [2.3369298, 0.82934654, 0.8875844]\n",
      "Batch 625/700: Discriminator loss = 1.179531216621399, GAN loss = [2.3169315, 0.81144106, 0.8855507]\n",
      "Batch 626/700: Discriminator loss = 1.1427549123764038, GAN loss = [2.3312905, 0.87009054, 0.84131783]\n",
      "Batch 627/700: Discriminator loss = 1.1453174352645874, GAN loss = [2.3945682, 0.85919404, 0.9155276]\n",
      "Batch 628/700: Discriminator loss = 1.1614545583724976, GAN loss = [2.3697436, 0.83821785, 0.9117209]\n",
      "Batch 629/700: Discriminator loss = 1.1726394891738892, GAN loss = [2.3441107, 0.82734114, 0.8970193]\n",
      "Batch 630/700: Discriminator loss = 1.133654236793518, GAN loss = [2.332683, 0.85735273, 0.8556202]\n",
      "Batch 631/700: Discriminator loss = 1.1588506698608398, GAN loss = [2.3395462, 0.8366465, 0.8832253]\n",
      "Batch 632/700: Discriminator loss = 1.157190203666687, GAN loss = [2.3409636, 0.8305809, 0.89073616]\n",
      "Batch 633/700: Discriminator loss = 1.167245864868164, GAN loss = [2.369123, 0.8233852, 0.9261383]\n",
      "Batch 634/700: Discriminator loss = 1.162103533744812, GAN loss = [2.3720891, 0.8255327, 0.92702156]\n",
      "Batch 635/700: Discriminator loss = 1.148441195487976, GAN loss = [2.4291682, 0.8392392, 0.9704502]\n",
      "Batch 636/700: Discriminator loss = 1.1672143936157227, GAN loss = [2.3687105, 0.8256052, 0.92369944]\n",
      "Batch 637/700: Discriminator loss = 1.1220531463623047, GAN loss = [2.477915, 0.86125875, 0.99732643]\n",
      "Batch 638/700: Discriminator loss = 1.1359312534332275, GAN loss = [2.384577, 0.84603006, 0.91930497]\n",
      "Batch 639/700: Discriminator loss = 1.1522598266601562, GAN loss = [2.3969748, 0.83025885, 0.947531]\n",
      "Batch 640/700: Discriminator loss = 1.138687252998352, GAN loss = [2.4102361, 0.8299152, 0.9611907]\n",
      "Batch 641/700: Discriminator loss = 1.165715217590332, GAN loss = [2.3860633, 0.80321765, 0.9637767]\n",
      "Batch 642/700: Discriminator loss = 1.171544075012207, GAN loss = [2.4346933, 0.8184117, 0.99726456]\n",
      "Batch 643/700: Discriminator loss = 1.1518027782440186, GAN loss = [2.4479258, 0.8315407, 0.9974011]\n",
      "Batch 644/700: Discriminator loss = 1.1553670167922974, GAN loss = [2.3684244, 0.84893143, 0.90056366]\n",
      "Batch 645/700: Discriminator loss = 1.1779735088348389, GAN loss = [2.375792, 0.79038805, 0.96653634]\n",
      "Batch 646/700: Discriminator loss = 1.128157377243042, GAN loss = [2.4523218, 0.8422509, 0.9912678]\n",
      "Batch 647/700: Discriminator loss = 1.1474964618682861, GAN loss = [2.4143758, 0.8326553, 0.96297854]\n",
      "Batch 648/700: Discriminator loss = 1.1564680337905884, GAN loss = [2.3473277, 0.82833934, 0.9002917]\n",
      "Batch 649/700: Discriminator loss = 1.1508808135986328, GAN loss = [2.4231737, 0.81914693, 0.98533213]\n",
      "Batch 650/700: Discriminator loss = 1.162597894668579, GAN loss = [2.4128096, 0.8045164, 0.9895961]\n",
      "Batch 651/700: Discriminator loss = 1.1736949682235718, GAN loss = [2.3641582, 0.8254424, 0.9200323]\n",
      "Batch 652/700: Discriminator loss = 1.1411725282669067, GAN loss = [2.4453745, 0.84638464, 0.98031825]\n",
      "Batch 653/700: Discriminator loss = 1.1618196964263916, GAN loss = [2.3948889, 0.8402495, 0.9359509]\n",
      "Batch 654/700: Discriminator loss = 1.179556131362915, GAN loss = [2.373849, 0.83221924, 0.92291933]\n",
      "Batch 655/700: Discriminator loss = 1.1796034574508667, GAN loss = [2.3440797, 0.82184976, 0.9034955]\n",
      "Batch 656/700: Discriminator loss = 1.176429033279419, GAN loss = [2.3857229, 0.8411224, 0.92585343]\n",
      "Batch 657/700: Discriminator loss = 1.1836495399475098, GAN loss = [2.353836, 0.8307467, 0.90431315]\n",
      "Batch 658/700: Discriminator loss = 1.1708282232284546, GAN loss = [2.293475, 0.82868105, 0.8459716]\n",
      "Batch 659/700: Discriminator loss = 1.2154968976974487, GAN loss = [2.305264, 0.80099785, 0.88539416]\n",
      "Batch 660/700: Discriminator loss = 1.1909102201461792, GAN loss = [2.3436956, 0.80465376, 0.92011374]\n",
      "Batch 661/700: Discriminator loss = 1.1897225379943848, GAN loss = [2.3032215, 0.8062074, 0.8780334]\n",
      "Batch 662/700: Discriminator loss = 1.1819864511489868, GAN loss = [2.3559954, 0.85044676, 0.8865353]\n",
      "Batch 663/700: Discriminator loss = 1.1781013011932373, GAN loss = [2.3726504, 0.87142783, 0.88216096]\n",
      "Batch 664/700: Discriminator loss = 1.1855262517929077, GAN loss = [2.3420331, 0.8176444, 0.90526825]\n",
      "Batch 665/700: Discriminator loss = 1.1806600093841553, GAN loss = [2.3391678, 0.8065265, 0.91348696]\n",
      "Batch 666/700: Discriminator loss = 1.1970819234848022, GAN loss = [2.3457873, 0.7994001, 0.92719847]\n",
      "Batch 667/700: Discriminator loss = 1.1859183311462402, GAN loss = [2.2894564, 0.8228577, 0.84737694]\n",
      "Batch 668/700: Discriminator loss = 1.1838136911392212, GAN loss = [2.318015, 0.81322014, 0.88556755]\n",
      "Batch 669/700: Discriminator loss = 1.2088550329208374, GAN loss = [2.2746415, 0.7848525, 0.87054986]\n",
      "Batch 670/700: Discriminator loss = 1.1566228866577148, GAN loss = [2.3658772, 0.8344866, 0.91212106]\n",
      "Batch 671/700: Discriminator loss = 1.1879565715789795, GAN loss = [2.3423, 0.7880146, 0.9349834]\n",
      "Batch 672/700: Discriminator loss = 1.1787973642349243, GAN loss = [2.3313692, 0.814983, 0.8970655]\n",
      "Batch 673/700: Discriminator loss = 1.1886898279190063, GAN loss = [2.3482232, 0.8108118, 0.9180728]\n",
      "Batch 674/700: Discriminator loss = 1.1753121614456177, GAN loss = [2.3599956, 0.8178704, 0.92275566]\n",
      "Batch 675/700: Discriminator loss = 1.209447979927063, GAN loss = [2.2742584, 0.79790217, 0.85696936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 676/700: Discriminator loss = 1.1961324214935303, GAN loss = [2.2725606, 0.7909458, 0.86222994]\n",
      "Batch 677/700: Discriminator loss = 1.2056708335876465, GAN loss = [2.2705805, 0.79255265, 0.8586223]\n",
      "Batch 678/700: Discriminator loss = 1.2268017530441284, GAN loss = [2.2869956, 0.78520465, 0.88237745]\n",
      "Batch 679/700: Discriminator loss = 1.2046034336090088, GAN loss = [2.2378793, 0.7869381, 0.83153856]\n",
      "Batch 680/700: Discriminator loss = 1.2086505889892578, GAN loss = [2.2073257, 0.7745555, 0.81340307]\n",
      "Batch 681/700: Discriminator loss = 1.2072324752807617, GAN loss = [2.2819242, 0.77211225, 0.8904964]\n",
      "Batch 682/700: Discriminator loss = 1.206916093826294, GAN loss = [2.2079225, 0.7736596, 0.8149924]\n",
      "Batch 683/700: Discriminator loss = 1.1756960153579712, GAN loss = [2.265812, 0.7966233, 0.8499593]\n",
      "Batch 684/700: Discriminator loss = 1.2040780782699585, GAN loss = [2.1906726, 0.78866464, 0.782792]\n",
      "Batch 685/700: Discriminator loss = 1.1948235034942627, GAN loss = [2.2987642, 0.79396164, 0.88558626]\n",
      "Batch 686/700: Discriminator loss = 1.1821118593215942, GAN loss = [2.2554095, 0.8076479, 0.82853067]\n",
      "Batch 687/700: Discriminator loss = 1.191652774810791, GAN loss = [2.2352068, 0.7718966, 0.84404474]\n",
      "Batch 688/700: Discriminator loss = 1.2151392698287964, GAN loss = [2.203135, 0.7650738, 0.81881905]\n",
      "Batch 689/700: Discriminator loss = 1.1694437265396118, GAN loss = [2.2762275, 0.8060971, 0.8509126]\n",
      "Batch 690/700: Discriminator loss = 1.17513108253479, GAN loss = [2.2327664, 0.7890369, 0.8245286]\n",
      "Batch 691/700: Discriminator loss = 1.161316990852356, GAN loss = [2.2709987, 0.8174536, 0.8343626]\n",
      "Batch 692/700: Discriminator loss = 1.172059178352356, GAN loss = [2.2747505, 0.798369, 0.8572188]\n",
      "Batch 693/700: Discriminator loss = 1.1532331705093384, GAN loss = [2.2271273, 0.7972448, 0.810734]\n",
      "Batch 694/700: Discriminator loss = 1.1836743354797363, GAN loss = [2.3097363, 0.80351484, 0.8870828]\n",
      "Batch 695/700: Discriminator loss = 1.1576290130615234, GAN loss = [2.278306, 0.8074762, 0.85170114]\n",
      "Batch 696/700: Discriminator loss = 1.158815622329712, GAN loss = [2.251747, 0.7986553, 0.8340108]\n",
      "Batch 697/700: Discriminator loss = 1.1573470830917358, GAN loss = [2.2647324, 0.7980167, 0.8476933]\n",
      "Batch 698/700: Discriminator loss = 1.1610692739486694, GAN loss = [2.302097, 0.823247, 0.8598752]\n",
      "Batch 699/700: Discriminator loss = 1.1571787595748901, GAN loss = [2.3170521, 0.82151985, 0.8765969]\n",
      "Batch 700/700: Discriminator loss = 1.15665864944458, GAN loss = [2.3000674, 0.8001146, 0.8810353]\n",
      "Epoch 25/30\n",
      "Batch 1/700: Discriminator loss = 1.1525795459747314, GAN loss = [2.2884867, 0.7951146, 0.8744703]\n",
      "Batch 2/700: Discriminator loss = 1.1654301881790161, GAN loss = [2.3083878, 0.78169334, 0.90778196]\n",
      "Batch 3/700: Discriminator loss = 1.1735576391220093, GAN loss = [2.2929847, 0.7905601, 0.8835071]\n",
      "Batch 4/700: Discriminator loss = 1.1691088676452637, GAN loss = [2.2238765, 0.7693656, 0.8355972]\n",
      "Batch 5/700: Discriminator loss = 1.1791011095046997, GAN loss = [2.2787197, 0.78170806, 0.8781086]\n",
      "Batch 6/700: Discriminator loss = 1.1683406829833984, GAN loss = [2.2804573, 0.78177553, 0.87979937]\n",
      "Batch 7/700: Discriminator loss = 1.1769239902496338, GAN loss = [2.271828, 0.7985442, 0.8544139]\n",
      "Batch 8/700: Discriminator loss = 1.1706446409225464, GAN loss = [2.261922, 0.79251266, 0.8505314]\n",
      "Batch 9/700: Discriminator loss = 1.2018895149230957, GAN loss = [2.2711084, 0.771685, 0.8805477]\n",
      "Batch 10/700: Discriminator loss = 1.1866562366485596, GAN loss = [2.2886953, 0.7814693, 0.8883275]\n",
      "Batch 11/700: Discriminator loss = 1.1980196237564087, GAN loss = [2.2201936, 0.7602813, 0.8409991]\n",
      "Batch 12/700: Discriminator loss = 1.1846976280212402, GAN loss = [2.2480655, 0.77912813, 0.8500056]\n",
      "Batch 13/700: Discriminator loss = 1.1848610639572144, GAN loss = [2.2201347, 0.7809598, 0.820245]\n",
      "Batch 14/700: Discriminator loss = 1.189180612564087, GAN loss = [2.2324672, 0.7742878, 0.839244]\n",
      "Batch 15/700: Discriminator loss = 1.1785078048706055, GAN loss = [2.3067002, 0.8085943, 0.8791732]\n",
      "Batch 16/700: Discriminator loss = 1.1751437187194824, GAN loss = [2.2787087, 0.7941584, 0.86559844]\n",
      "Batch 17/700: Discriminator loss = 1.167478084564209, GAN loss = [2.3370745, 0.80747145, 0.91066086]\n",
      "Batch 18/700: Discriminator loss = 1.1539430618286133, GAN loss = [2.3013175, 0.8203879, 0.8619962]\n",
      "Batch 19/700: Discriminator loss = 1.167886734008789, GAN loss = [2.263612, 0.8089719, 0.8357039]\n",
      "Batch 20/700: Discriminator loss = 1.1553786993026733, GAN loss = [2.3194537, 0.8067873, 0.89369994]\n",
      "Batch 21/700: Discriminator loss = 1.1528505086898804, GAN loss = [2.369597, 0.8170458, 0.93356496]\n",
      "Batch 22/700: Discriminator loss = 1.1529312133789062, GAN loss = [2.3677719, 0.8122894, 0.93647105]\n",
      "Batch 23/700: Discriminator loss = 1.1578813791275024, GAN loss = [2.402111, 0.8244992, 0.95859057]\n",
      "Batch 24/700: Discriminator loss = 1.1656209230422974, GAN loss = [2.3278203, 0.80980843, 0.8989972]\n",
      "Batch 25/700: Discriminator loss = 1.1795300245285034, GAN loss = [2.2498279, 0.7862258, 0.84459203]\n",
      "Batch 26/700: Discriminator loss = 1.1578296422958374, GAN loss = [2.3541696, 0.8236734, 0.91151243]\n",
      "Batch 27/700: Discriminator loss = 1.1561250686645508, GAN loss = [2.328416, 0.823401, 0.88606125]\n",
      "Batch 28/700: Discriminator loss = 1.1337671279907227, GAN loss = [2.3313239, 0.8408916, 0.8715134]\n",
      "Batch 29/700: Discriminator loss = 1.1415876150131226, GAN loss = [2.3401954, 0.82019824, 0.901105]\n",
      "Batch 30/700: Discriminator loss = 1.1730564832687378, GAN loss = [2.3812892, 0.8145597, 0.9478688]\n",
      "Batch 31/700: Discriminator loss = 1.1697852611541748, GAN loss = [2.3950574, 0.8043888, 0.9717835]\n",
      "Batch 32/700: Discriminator loss = 1.1704974174499512, GAN loss = [2.3798833, 0.7988864, 0.9621059]\n",
      "Batch 33/700: Discriminator loss = 1.1484192609786987, GAN loss = [2.360629, 0.8485604, 0.8932003]\n",
      "Batch 34/700: Discriminator loss = 1.1730856895446777, GAN loss = [2.3197079, 0.8090008, 0.89186335]\n",
      "Batch 35/700: Discriminator loss = 1.1719869375228882, GAN loss = [2.2767353, 0.79198545, 0.8659175]\n",
      "Batch 36/700: Discriminator loss = 1.1716703176498413, GAN loss = [2.3032053, 0.80457777, 0.87979054]\n",
      "Batch 37/700: Discriminator loss = 1.1753110885620117, GAN loss = [2.354813, 0.79643595, 0.9395551]\n",
      "Batch 38/700: Discriminator loss = 1.144780158996582, GAN loss = [2.3879023, 0.8268051, 0.9422975]\n",
      "Batch 39/700: Discriminator loss = 1.1548758745193481, GAN loss = [2.3386807, 0.82470506, 0.89521426]\n",
      "Batch 40/700: Discriminator loss = 1.1471036672592163, GAN loss = [2.3312325, 0.82837874, 0.8841199]\n",
      "Batch 41/700: Discriminator loss = 1.153322458267212, GAN loss = [2.4335496, 0.8482968, 0.9665336]\n",
      "Batch 42/700: Discriminator loss = 1.158168911933899, GAN loss = [2.3132088, 0.81894416, 0.8755523]\n",
      "Batch 43/700: Discriminator loss = 1.1384762525558472, GAN loss = [2.4124813, 0.84435606, 0.9494256]\n",
      "Batch 44/700: Discriminator loss = 1.1505671739578247, GAN loss = [2.3595679, 0.83156836, 0.9092825]\n",
      "Batch 45/700: Discriminator loss = 1.145349383354187, GAN loss = [2.3815448, 0.8294187, 0.93341446]\n",
      "Batch 46/700: Discriminator loss = 1.1684634685516357, GAN loss = [2.3258395, 0.8136044, 0.8935167]\n",
      "Batch 47/700: Discriminator loss = 1.163206696510315, GAN loss = [2.3679883, 0.8187986, 0.93047476]\n",
      "Batch 48/700: Discriminator loss = 1.1897298097610474, GAN loss = [2.3731453, 0.80885947, 0.9455654]\n",
      "Batch 49/700: Discriminator loss = 1.189008355140686, GAN loss = [2.319078, 0.7969459, 0.9034206]\n",
      "Batch 50/700: Discriminator loss = 1.1374235153198242, GAN loss = [2.4497466, 0.8585183, 0.9725]\n",
      "Batch 51/700: Discriminator loss = 1.1362440586090088, GAN loss = [2.4245117, 0.855485, 0.9502732]\n",
      "Batch 52/700: Discriminator loss = 1.174005389213562, GAN loss = [2.336295, 0.8098213, 0.90773445]\n",
      "Batch 53/700: Discriminator loss = 1.1356209516525269, GAN loss = [2.5092618, 0.8618061, 1.028732]\n",
      "Batch 54/700: Discriminator loss = 1.14395272731781, GAN loss = [2.3801703, 0.85441697, 0.90702146]\n",
      "Batch 55/700: Discriminator loss = 1.1339712142944336, GAN loss = [2.388208, 0.85593444, 0.9135489]\n",
      "Batch 56/700: Discriminator loss = 1.1455014944076538, GAN loss = [2.398319, 0.8578284, 0.9217673]\n",
      "Batch 57/700: Discriminator loss = 1.1281458139419556, GAN loss = [2.434014, 0.8540693, 0.9612615]\n",
      "Batch 58/700: Discriminator loss = 1.1498463153839111, GAN loss = [2.424218, 0.8410889, 0.96449625]\n",
      "Batch 59/700: Discriminator loss = 1.1458803415298462, GAN loss = [2.3393042, 0.84192187, 0.8787653]\n",
      "Batch 60/700: Discriminator loss = 1.11971116065979, GAN loss = [2.4578152, 0.87223727, 0.96694094]\n",
      "Batch 61/700: Discriminator loss = 1.1503831148147583, GAN loss = [2.438145, 0.8292812, 0.99022084]\n",
      "Batch 62/700: Discriminator loss = 1.1327366828918457, GAN loss = [2.411215, 0.8364713, 0.9561379]\n",
      "Batch 63/700: Discriminator loss = 1.1145837306976318, GAN loss = [2.4808776, 0.8719574, 0.9903216]\n",
      "Batch 64/700: Discriminator loss = 1.1055655479431152, GAN loss = [2.5313323, 0.90659416, 1.0061544]\n",
      "Batch 65/700: Discriminator loss = 1.1244720220565796, GAN loss = [2.4467402, 0.8568715, 0.9713032]\n",
      "Batch 66/700: Discriminator loss = 1.1198512315750122, GAN loss = [2.5313845, 0.85647774, 1.0563599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 67/700: Discriminator loss = 1.135149598121643, GAN loss = [2.5045855, 0.8542227, 1.0318258]\n",
      "Batch 68/700: Discriminator loss = 1.1506872177124023, GAN loss = [2.3955703, 0.8322672, 0.94475985]\n",
      "Batch 69/700: Discriminator loss = 1.1901617050170898, GAN loss = [2.355699, 0.81053054, 0.92659926]\n",
      "Batch 70/700: Discriminator loss = 1.1767524480819702, GAN loss = [2.3774328, 0.8061336, 0.9526942]\n",
      "Batch 71/700: Discriminator loss = 1.179779291152954, GAN loss = [2.4021044, 0.8117439, 0.9717311]\n",
      "Batch 72/700: Discriminator loss = 1.1528079509735107, GAN loss = [2.4382339, 0.81361014, 1.0059884]\n",
      "Batch 73/700: Discriminator loss = 1.1627672910690308, GAN loss = [2.4699829, 0.83024734, 1.0210831]\n",
      "Batch 74/700: Discriminator loss = 1.1882599592208862, GAN loss = [2.379659, 0.813448, 0.94758284]\n",
      "Batch 75/700: Discriminator loss = 1.1818972826004028, GAN loss = [2.4034517, 0.8357705, 0.9490499]\n",
      "Batch 76/700: Discriminator loss = 1.1616450548171997, GAN loss = [2.4014037, 0.82055, 0.9622084]\n",
      "Batch 77/700: Discriminator loss = 1.1842942237854004, GAN loss = [2.3465633, 0.82722, 0.9006814]\n",
      "Batch 78/700: Discriminator loss = 1.1929547786712646, GAN loss = [2.481944, 0.8323683, 1.0309267]\n",
      "Batch 79/700: Discriminator loss = 1.1730204820632935, GAN loss = [2.4241786, 0.8469961, 0.95854497]\n",
      "Batch 80/700: Discriminator loss = 1.1475563049316406, GAN loss = [2.437, 0.84906983, 0.9693085]\n",
      "Batch 81/700: Discriminator loss = 1.171378254890442, GAN loss = [2.3499599, 0.83772904, 0.8936072]\n",
      "Batch 82/700: Discriminator loss = 1.1386547088623047, GAN loss = [2.4812703, 0.8514296, 1.0111927]\n",
      "Batch 83/700: Discriminator loss = 1.1208935976028442, GAN loss = [2.4206865, 0.88392675, 0.918103]\n",
      "Batch 84/700: Discriminator loss = 1.147495985031128, GAN loss = [2.4482465, 0.853699, 0.9759198]\n",
      "Batch 85/700: Discriminator loss = 1.139472484588623, GAN loss = [2.4151413, 0.8546747, 0.9418523]\n",
      "Batch 86/700: Discriminator loss = 1.1324039697647095, GAN loss = [2.3827627, 0.85034317, 0.91381717]\n",
      "Batch 87/700: Discriminator loss = 1.118080496788025, GAN loss = [2.4019299, 0.8544507, 0.9288996]\n",
      "Batch 88/700: Discriminator loss = 1.1354939937591553, GAN loss = [2.490155, 0.8500075, 1.0215747]\n",
      "Batch 89/700: Discriminator loss = 1.1325525045394897, GAN loss = [2.4922376, 0.854879, 1.0187979]\n",
      "Batch 90/700: Discriminator loss = 1.1116421222686768, GAN loss = [2.510939, 0.8759089, 1.0164759]\n",
      "Batch 91/700: Discriminator loss = 1.1287778615951538, GAN loss = [2.4125562, 0.85600954, 0.9379964]\n",
      "Batch 92/700: Discriminator loss = 1.1157749891281128, GAN loss = [2.4831905, 0.88871527, 0.9759311]\n",
      "Batch 93/700: Discriminator loss = 1.1550675630569458, GAN loss = [2.4832401, 0.84716016, 1.0175567]\n",
      "Batch 94/700: Discriminator loss = 1.1526762247085571, GAN loss = [2.40473, 0.86017776, 0.92602956]\n",
      "Batch 95/700: Discriminator loss = 1.1435436010360718, GAN loss = [2.4392257, 0.877245, 0.94344574]\n",
      "Batch 96/700: Discriminator loss = 1.140656590461731, GAN loss = [2.4106925, 0.86272544, 0.92941004]\n",
      "Batch 97/700: Discriminator loss = 1.1658381223678589, GAN loss = [2.4162092, 0.8598439, 0.9378006]\n",
      "Batch 98/700: Discriminator loss = 1.1570229530334473, GAN loss = [2.4071052, 0.88412255, 0.90440583]\n",
      "Batch 99/700: Discriminator loss = 1.1528494358062744, GAN loss = [2.44029, 0.87633777, 0.945369]\n",
      "Batch 100/700: Discriminator loss = 1.168290376663208, GAN loss = [2.3588843, 0.8574379, 0.8828382]\n",
      "Batch 101/700: Discriminator loss = 1.153756022453308, GAN loss = [2.4195812, 0.8871771, 0.91374934]\n",
      "Batch 102/700: Discriminator loss = 1.1530709266662598, GAN loss = [2.3898094, 0.88370675, 0.88739866]\n",
      "Batch 103/700: Discriminator loss = 1.16079843044281, GAN loss = [2.3860297, 0.89812464, 0.8691412]\n",
      "Batch 104/700: Discriminator loss = 1.1772065162658691, GAN loss = [2.353119, 0.8446519, 0.8896354]\n",
      "Batch 105/700: Discriminator loss = 1.1632049083709717, GAN loss = [2.4608903, 0.8658541, 0.9761777]\n",
      "Batch 106/700: Discriminator loss = 1.1693099737167358, GAN loss = [2.3825378, 0.84846795, 0.91517484]\n",
      "Batch 107/700: Discriminator loss = 1.1970890760421753, GAN loss = [2.3876686, 0.850729, 0.91800463]\n",
      "Batch 108/700: Discriminator loss = 1.1587473154067993, GAN loss = [2.4289763, 0.8941672, 0.915859]\n",
      "Batch 109/700: Discriminator loss = 1.1577450037002563, GAN loss = [2.4495838, 0.89253855, 0.93806356]\n",
      "Batch 110/700: Discriminator loss = 1.159233808517456, GAN loss = [2.406416, 0.8820025, 0.9053709]\n",
      "Batch 111/700: Discriminator loss = 1.17376708984375, GAN loss = [2.4287107, 0.8558745, 0.9537362]\n",
      "Batch 112/700: Discriminator loss = 1.1525611877441406, GAN loss = [2.4446993, 0.8826073, 0.94292367]\n",
      "Batch 113/700: Discriminator loss = 1.1599559783935547, GAN loss = [2.5272765, 0.8961068, 1.0119625]\n",
      "Batch 114/700: Discriminator loss = 1.1976191997528076, GAN loss = [2.4101954, 0.850243, 0.9407006]\n",
      "Batch 115/700: Discriminator loss = 1.15382719039917, GAN loss = [2.478074, 0.898741, 0.96005225]\n",
      "Batch 116/700: Discriminator loss = 1.1663100719451904, GAN loss = [2.4654062, 0.8620447, 0.98402613]\n",
      "Batch 117/700: Discriminator loss = 1.2093453407287598, GAN loss = [2.4606884, 0.8628016, 0.97849435]\n",
      "Batch 118/700: Discriminator loss = 1.1661032438278198, GAN loss = [2.4228098, 0.8684641, 0.9349009]\n",
      "Batch 119/700: Discriminator loss = 1.1988353729248047, GAN loss = [2.360941, 0.83835375, 0.90310913]\n",
      "Batch 120/700: Discriminator loss = 1.1618798971176147, GAN loss = [2.4239175, 0.879455, 0.9249794]\n",
      "Batch 121/700: Discriminator loss = 1.1581873893737793, GAN loss = [2.3925307, 0.87219095, 0.900883]\n",
      "Batch 122/700: Discriminator loss = 1.1303399801254272, GAN loss = [2.513116, 0.91263825, 0.98105973]\n",
      "Batch 123/700: Discriminator loss = 1.1459052562713623, GAN loss = [2.5299418, 0.88998187, 1.0205684]\n",
      "Batch 124/700: Discriminator loss = 1.155892014503479, GAN loss = [2.4294112, 0.88037324, 0.92966413]\n",
      "Batch 125/700: Discriminator loss = 1.1316936016082764, GAN loss = [2.479353, 0.8788364, 0.98117185]\n",
      "Batch 126/700: Discriminator loss = 1.1137665510177612, GAN loss = [2.515231, 0.90996224, 0.9859753]\n",
      "Batch 127/700: Discriminator loss = 1.134745478630066, GAN loss = [2.4624517, 0.88641375, 0.9567863]\n",
      "Batch 128/700: Discriminator loss = 1.0946732759475708, GAN loss = [2.5923276, 0.9372068, 1.0358949]\n",
      "Batch 129/700: Discriminator loss = 1.1178792715072632, GAN loss = [2.4495525, 0.90598106, 0.9243568]\n",
      "Batch 130/700: Discriminator loss = 1.1171361207962036, GAN loss = [2.4385974, 0.8855092, 0.9338944]\n",
      "Batch 131/700: Discriminator loss = 1.1338030099868774, GAN loss = [2.4306402, 0.8698322, 0.94163]\n",
      "Batch 132/700: Discriminator loss = 1.1159820556640625, GAN loss = [2.490929, 0.89408076, 0.9777063]\n",
      "Batch 133/700: Discriminator loss = 1.1318461894989014, GAN loss = [2.5413084, 0.88553816, 1.0366868]\n",
      "Batch 134/700: Discriminator loss = 1.1406258344650269, GAN loss = [2.514072, 0.8816738, 1.0133625]\n",
      "Batch 135/700: Discriminator loss = 1.1555280685424805, GAN loss = [2.39357, 0.85789835, 0.91665316]\n",
      "Batch 136/700: Discriminator loss = 1.1779578924179077, GAN loss = [2.4078398, 0.84847677, 0.9403436]\n",
      "Batch 137/700: Discriminator loss = 1.1699002981185913, GAN loss = [2.4544547, 0.85585463, 0.9795874]\n",
      "Batch 138/700: Discriminator loss = 1.1700352430343628, GAN loss = [2.4449933, 0.8605189, 0.96546435]\n",
      "Batch 139/700: Discriminator loss = 1.1990244388580322, GAN loss = [2.357669, 0.8166024, 0.92207444]\n",
      "Batch 140/700: Discriminator loss = 1.1994513273239136, GAN loss = [2.421889, 0.82549256, 0.9773848]\n",
      "Batch 141/700: Discriminator loss = 1.1941189765930176, GAN loss = [2.3434346, 0.82993144, 0.8944647]\n",
      "Batch 142/700: Discriminator loss = 1.2059106826782227, GAN loss = [2.3599145, 0.8235491, 0.9172804]\n",
      "Batch 143/700: Discriminator loss = 1.2037330865859985, GAN loss = [2.4259129, 0.8369544, 0.96981704]\n",
      "Batch 144/700: Discriminator loss = 1.207713007926941, GAN loss = [2.3386276, 0.83586806, 0.88356346]\n",
      "Batch 145/700: Discriminator loss = 1.1590654850006104, GAN loss = [2.4290953, 0.8801817, 0.929653]\n",
      "Batch 146/700: Discriminator loss = 1.1891957521438599, GAN loss = [2.3627439, 0.85092616, 0.8925001]\n",
      "Batch 147/700: Discriminator loss = 1.154168725013733, GAN loss = [2.4259615, 0.8842258, 0.92237204]\n",
      "Batch 148/700: Discriminator loss = 1.1483960151672363, GAN loss = [2.3812764, 0.8760888, 0.8858202]\n",
      "Batch 149/700: Discriminator loss = 1.1572428941726685, GAN loss = [2.4970167, 0.8872483, 0.99041444]\n",
      "Batch 150/700: Discriminator loss = 1.120039939880371, GAN loss = [2.4384272, 0.9025727, 0.916527]\n",
      "Batch 151/700: Discriminator loss = 1.1480687856674194, GAN loss = [2.4211824, 0.8859758, 0.9158928]\n",
      "Batch 152/700: Discriminator loss = 1.1693528890609741, GAN loss = [2.4719768, 0.8753185, 0.977362]\n",
      "Batch 153/700: Discriminator loss = 1.1377766132354736, GAN loss = [2.485197, 0.89379424, 0.9721183]\n",
      "Batch 154/700: Discriminator loss = 1.1452447175979614, GAN loss = [2.431585, 0.873369, 0.9389521]\n",
      "Batch 155/700: Discriminator loss = 1.1377440690994263, GAN loss = [2.5368986, 0.9009085, 1.016763]\n",
      "Batch 156/700: Discriminator loss = 1.1431519985198975, GAN loss = [2.418912, 0.8867204, 0.91301566]\n",
      "Batch 157/700: Discriminator loss = 1.1149442195892334, GAN loss = [2.5987449, 0.8927884, 1.0868192]\n",
      "Batch 158/700: Discriminator loss = 1.1490185260772705, GAN loss = [2.7040215, 0.91481733, 1.1700786]\n",
      "Batch 159/700: Discriminator loss = 1.152504801750183, GAN loss = [2.4072852, 0.86400884, 0.9241655]\n",
      "Batch 160/700: Discriminator loss = 1.1533693075180054, GAN loss = [2.5501175, 0.8662199, 1.0647974]\n",
      "Batch 161/700: Discriminator loss = 1.1508759260177612, GAN loss = [2.4472375, 0.86266524, 0.96546614]\n",
      "Batch 162/700: Discriminator loss = 1.187641978263855, GAN loss = [2.5203853, 0.8820048, 1.0192518]\n",
      "Batch 163/700: Discriminator loss = 1.1652008295059204, GAN loss = [2.501155, 0.86844426, 1.013586]\n",
      "Batch 164/700: Discriminator loss = 1.1323058605194092, GAN loss = [2.4575143, 0.8624995, 0.9759083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 165/700: Discriminator loss = 1.1527866125106812, GAN loss = [2.4192045, 0.8529483, 0.94716996]\n",
      "Batch 166/700: Discriminator loss = 1.1531680822372437, GAN loss = [2.425169, 0.8649173, 0.94117683]\n",
      "Batch 167/700: Discriminator loss = 1.1583218574523926, GAN loss = [2.4327319, 0.8639505, 0.94969195]\n",
      "Batch 168/700: Discriminator loss = 1.1546838283538818, GAN loss = [2.4589372, 0.8832055, 0.95660424]\n",
      "Batch 169/700: Discriminator loss = 1.1673775911331177, GAN loss = [2.3797944, 0.8564075, 0.9042355]\n",
      "Batch 170/700: Discriminator loss = 1.1736743450164795, GAN loss = [2.380282, 0.8773253, 0.8837874]\n",
      "Batch 171/700: Discriminator loss = 1.1391279697418213, GAN loss = [2.4720507, 0.91015697, 0.94269514]\n",
      "Batch 172/700: Discriminator loss = 1.1460171937942505, GAN loss = [2.4625273, 0.89795333, 0.9453507]\n",
      "Batch 173/700: Discriminator loss = 1.123868465423584, GAN loss = [2.4302275, 0.90904826, 0.9019467]\n",
      "Batch 174/700: Discriminator loss = 1.1390334367752075, GAN loss = [2.4622207, 0.90045446, 0.9425274]\n",
      "Batch 175/700: Discriminator loss = 1.136916995048523, GAN loss = [2.5361805, 0.9071142, 1.0098077]\n",
      "Batch 176/700: Discriminator loss = 1.1425682306289673, GAN loss = [2.4839783, 0.89149684, 0.9731745]\n",
      "Batch 177/700: Discriminator loss = 1.1531063318252563, GAN loss = [2.3792338, 0.87337273, 0.8865094]\n",
      "Batch 178/700: Discriminator loss = 1.1594730615615845, GAN loss = [2.4935644, 0.89462686, 0.97954893]\n",
      "Batch 179/700: Discriminator loss = 1.1359961032867432, GAN loss = [2.4877818, 0.89162135, 0.97675276]\n",
      "Batch 180/700: Discriminator loss = 1.1362651586532593, GAN loss = [2.4300988, 0.8986651, 0.9120001]\n",
      "Batch 181/700: Discriminator loss = 1.1263924837112427, GAN loss = [2.46522, 0.88924956, 0.9565176]\n",
      "Batch 182/700: Discriminator loss = 1.1214901208877563, GAN loss = [2.4834044, 0.9069056, 0.9570432]\n",
      "Batch 183/700: Discriminator loss = 1.1367045640945435, GAN loss = [2.5071096, 0.8914082, 0.9962625]\n",
      "Batch 184/700: Discriminator loss = 1.136383295059204, GAN loss = [2.4789922, 0.8791745, 0.9803495]\n",
      "Batch 185/700: Discriminator loss = 1.1660256385803223, GAN loss = [2.4195805, 0.8468326, 0.95323366]\n",
      "Batch 186/700: Discriminator loss = 1.1401957273483276, GAN loss = [2.5424123, 0.8769539, 1.0459212]\n",
      "Batch 187/700: Discriminator loss = 1.1705936193466187, GAN loss = [2.409889, 0.8519041, 0.9384297]\n",
      "Batch 188/700: Discriminator loss = 1.1261366605758667, GAN loss = [2.5136437, 0.88603014, 1.0080582]\n",
      "Batch 189/700: Discriminator loss = 1.1479222774505615, GAN loss = [2.42012, 0.86914843, 0.9313889]\n",
      "Batch 190/700: Discriminator loss = 1.1944749355316162, GAN loss = [2.3777108, 0.81333077, 0.94479614]\n",
      "Batch 191/700: Discriminator loss = 1.1987568140029907, GAN loss = [2.4039729, 0.83900964, 0.9453556]\n",
      "Batch 192/700: Discriminator loss = 1.1591525077819824, GAN loss = [2.4337165, 0.8328754, 0.9811933]\n",
      "Batch 193/700: Discriminator loss = 1.1831943988800049, GAN loss = [2.4383128, 0.83713776, 0.981484]\n",
      "Batch 194/700: Discriminator loss = 1.1809000968933105, GAN loss = [2.3332736, 0.8376744, 0.87588274]\n",
      "Batch 195/700: Discriminator loss = 1.1556564569473267, GAN loss = [2.4824066, 0.86457604, 0.9981175]\n",
      "Batch 196/700: Discriminator loss = 1.1597816944122314, GAN loss = [2.325586, 0.83907557, 0.86679727]\n",
      "Batch 197/700: Discriminator loss = 1.1560876369476318, GAN loss = [2.498512, 0.84132165, 1.0374548]\n",
      "Batch 198/700: Discriminator loss = 1.1500877141952515, GAN loss = [2.3958764, 0.83189535, 0.94424707]\n",
      "Batch 199/700: Discriminator loss = 1.1350176334381104, GAN loss = [2.5250294, 0.8553586, 1.0499378]\n",
      "Batch 200/700: Discriminator loss = 1.150150179862976, GAN loss = [2.4472928, 0.8407127, 0.98685485]\n",
      "Batch 201/700: Discriminator loss = 1.1286624670028687, GAN loss = [2.4561265, 0.86297125, 0.97343135]\n",
      "Batch 202/700: Discriminator loss = 1.1327362060546875, GAN loss = [2.4497864, 0.8394525, 0.9906016]\n",
      "Batch 203/700: Discriminator loss = 1.1425890922546387, GAN loss = [2.3932788, 0.8352852, 0.93824]\n",
      "Batch 204/700: Discriminator loss = 1.1594940423965454, GAN loss = [2.397385, 0.8593505, 0.9182693]\n",
      "Batch 205/700: Discriminator loss = 1.1599634885787964, GAN loss = [2.3259897, 0.8318632, 0.8743562]\n",
      "Batch 206/700: Discriminator loss = 1.1599853038787842, GAN loss = [2.4099789, 0.8709942, 0.91917175]\n",
      "Batch 207/700: Discriminator loss = 1.1300848722457886, GAN loss = [2.4322007, 0.841434, 0.97090745]\n",
      "Batch 208/700: Discriminator loss = 1.156957983970642, GAN loss = [2.3588805, 0.8160616, 0.9229391]\n",
      "Batch 209/700: Discriminator loss = 1.1519107818603516, GAN loss = [2.5067854, 0.8898054, 0.9971017]\n",
      "Batch 210/700: Discriminator loss = 1.1352319717407227, GAN loss = [2.4447398, 0.8626934, 0.96213096]\n",
      "Batch 211/700: Discriminator loss = 1.1347471475601196, GAN loss = [2.3974924, 0.84494805, 0.93257165]\n",
      "Batch 212/700: Discriminator loss = 1.1516737937927246, GAN loss = [2.483276, 0.88092506, 0.9823713]\n",
      "Batch 213/700: Discriminator loss = 1.1534532308578491, GAN loss = [2.4205778, 0.85214895, 0.94839424]\n",
      "Batch 214/700: Discriminator loss = 1.1448158025741577, GAN loss = [2.5423226, 0.88586134, 1.0363116]\n",
      "Batch 215/700: Discriminator loss = 1.1318304538726807, GAN loss = [2.5578606, 0.90810156, 1.0295415]\n",
      "Batch 216/700: Discriminator loss = 1.1255220174789429, GAN loss = [2.6084433, 0.9166423, 1.0715156]\n",
      "Batch 217/700: Discriminator loss = 1.1409095525741577, GAN loss = [2.5496871, 0.92031944, 1.0090432]\n",
      "Batch 218/700: Discriminator loss = 1.14554762840271, GAN loss = [2.502027, 0.90022033, 0.98146075]\n",
      "Batch 219/700: Discriminator loss = 1.143595576286316, GAN loss = [2.5663328, 0.91476095, 1.0311567]\n",
      "Batch 220/700: Discriminator loss = 1.1408770084381104, GAN loss = [2.4359689, 0.91416556, 0.9012808]\n",
      "Batch 221/700: Discriminator loss = 1.157996654510498, GAN loss = [2.5158126, 0.88669986, 1.0084958]\n",
      "Batch 222/700: Discriminator loss = 1.1758400201797485, GAN loss = [2.5386844, 0.87961876, 1.0383862]\n",
      "Batch 223/700: Discriminator loss = 1.12686026096344, GAN loss = [2.6422527, 0.96364844, 1.0578517]\n",
      "Batch 224/700: Discriminator loss = 1.1098257303237915, GAN loss = [2.7337422, 0.9862951, 1.1266934]\n",
      "Batch 225/700: Discriminator loss = 1.1326075792312622, GAN loss = [2.664642, 0.9588373, 1.0850408]\n",
      "Batch 226/700: Discriminator loss = 1.1421016454696655, GAN loss = [2.6686573, 0.9222227, 1.1256464]\n",
      "Batch 227/700: Discriminator loss = 1.144730806350708, GAN loss = [2.6225255, 0.9469454, 1.0547174]\n",
      "Batch 228/700: Discriminator loss = 1.1573601961135864, GAN loss = [2.5945802, 0.92563367, 1.0480366]\n",
      "Batch 229/700: Discriminator loss = 1.1652532815933228, GAN loss = [2.5538697, 0.91139984, 1.0214494]\n",
      "Batch 230/700: Discriminator loss = 1.1866856813430786, GAN loss = [2.4876962, 0.902786, 0.96376985]\n",
      "Batch 231/700: Discriminator loss = 1.1629300117492676, GAN loss = [2.482007, 0.87748915, 0.9833388]\n",
      "Batch 232/700: Discriminator loss = 1.1462537050247192, GAN loss = [2.502516, 0.8954477, 0.98589087]\n",
      "Batch 233/700: Discriminator loss = 1.17012357711792, GAN loss = [2.4425657, 0.889116, 0.93229365]\n",
      "Batch 234/700: Discriminator loss = 1.1193978786468506, GAN loss = [2.4950697, 0.91726965, 0.95662993]\n",
      "Batch 235/700: Discriminator loss = 1.1353569030761719, GAN loss = [2.4755645, 0.88804656, 0.96634626]\n",
      "Batch 236/700: Discriminator loss = 1.141657829284668, GAN loss = [2.4621687, 0.8990512, 0.94192344]\n",
      "Batch 237/700: Discriminator loss = 1.1320263147354126, GAN loss = [2.3567722, 0.85916877, 0.87638384]\n",
      "Batch 238/700: Discriminator loss = 1.1034631729125977, GAN loss = [2.4777572, 0.89978325, 0.9567414]\n",
      "Batch 239/700: Discriminator loss = 1.1042309999465942, GAN loss = [2.4517963, 0.89037675, 0.9401477]\n",
      "Batch 240/700: Discriminator loss = 1.1114838123321533, GAN loss = [2.465274, 0.8792846, 0.9647113]\n",
      "Batch 241/700: Discriminator loss = 1.1155188083648682, GAN loss = [2.409317, 0.8801353, 0.907892]\n",
      "Batch 242/700: Discriminator loss = 1.1169551610946655, GAN loss = [2.508544, 0.8843052, 1.0029522]\n",
      "Batch 243/700: Discriminator loss = 1.0861455202102661, GAN loss = [2.4867249, 0.90342474, 0.962026]\n",
      "Batch 244/700: Discriminator loss = 1.1205036640167236, GAN loss = [2.4642894, 0.880234, 0.96282285]\n",
      "Batch 245/700: Discriminator loss = 1.0879790782928467, GAN loss = [2.591673, 0.9226703, 1.0478213]\n",
      "Batch 246/700: Discriminator loss = 1.0979892015457153, GAN loss = [2.5207994, 0.9271856, 0.97246844]\n",
      "Batch 247/700: Discriminator loss = 1.0645610094070435, GAN loss = [2.5253048, 0.95456207, 0.94963056]\n",
      "Batch 248/700: Discriminator loss = 1.0831844806671143, GAN loss = [2.5999668, 0.9094709, 1.069428]\n",
      "Batch 249/700: Discriminator loss = 1.112389087677002, GAN loss = [2.5454113, 0.898786, 1.025591]\n",
      "Batch 250/700: Discriminator loss = 1.1017643213272095, GAN loss = [2.5708425, 0.9019419, 1.0478786]\n",
      "Batch 251/700: Discriminator loss = 1.0845794677734375, GAN loss = [2.6116996, 0.9455197, 1.0451734]\n",
      "Batch 252/700: Discriminator loss = 1.0975366830825806, GAN loss = [2.5780096, 0.9092069, 1.0478384]\n",
      "Batch 253/700: Discriminator loss = 1.0743131637573242, GAN loss = [2.6275334, 0.95393395, 1.0526912]\n",
      "Batch 254/700: Discriminator loss = 1.1121357679367065, GAN loss = [2.5417635, 0.91235375, 1.0085553]\n",
      "Batch 255/700: Discriminator loss = 1.089410424232483, GAN loss = [2.6056361, 0.94013304, 1.0446838]\n",
      "Batch 256/700: Discriminator loss = 1.1019245386123657, GAN loss = [2.6454763, 0.9102171, 1.1144776]\n",
      "Batch 257/700: Discriminator loss = 1.0903332233428955, GAN loss = [2.6965563, 0.9351589, 1.1406381]\n",
      "Batch 258/700: Discriminator loss = 1.0903970003128052, GAN loss = [2.6409469, 0.9440795, 1.0761056]\n",
      "Batch 259/700: Discriminator loss = 1.1175041198730469, GAN loss = [2.61603, 0.9023235, 1.092955]\n",
      "Batch 260/700: Discriminator loss = 1.1074657440185547, GAN loss = [2.653302, 0.93128806, 1.1012845]\n",
      "Batch 261/700: Discriminator loss = 1.1044983863830566, GAN loss = [2.629906, 0.92495775, 1.0842272]\n",
      "Batch 262/700: Discriminator loss = 1.1341171264648438, GAN loss = [2.6077442, 0.9136067, 1.0734339]\n",
      "Batch 263/700: Discriminator loss = 1.1473379135131836, GAN loss = [2.5319304, 0.88984716, 1.0214309]\n",
      "Batch 264/700: Discriminator loss = 1.1116266250610352, GAN loss = [2.6177497, 0.96648216, 1.0306486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 265/700: Discriminator loss = 1.1279999017715454, GAN loss = [2.5706863, 0.93488157, 1.0152258]\n",
      "Batch 266/700: Discriminator loss = 1.1425501108169556, GAN loss = [2.5093782, 0.90921575, 0.97959197]\n",
      "Batch 267/700: Discriminator loss = 1.154079794883728, GAN loss = [2.5657518, 0.8993189, 1.0458347]\n",
      "Batch 268/700: Discriminator loss = 1.1418476104736328, GAN loss = [2.5233045, 0.9058554, 0.996867]\n",
      "Batch 269/700: Discriminator loss = 1.1265150308609009, GAN loss = [2.4741187, 0.9333376, 0.9201979]\n",
      "Batch 270/700: Discriminator loss = 1.1055192947387695, GAN loss = [2.546675, 0.946488, 0.9796066]\n",
      "Batch 271/700: Discriminator loss = 1.1071951389312744, GAN loss = [2.5836895, 0.94388753, 1.0192416]\n",
      "Batch 272/700: Discriminator loss = 1.0991475582122803, GAN loss = [2.6030447, 0.95147324, 1.0310553]\n",
      "Batch 273/700: Discriminator loss = 1.1264623403549194, GAN loss = [2.4856782, 0.9107399, 0.9544549]\n",
      "Batch 274/700: Discriminator loss = 1.1488431692123413, GAN loss = [2.4560733, 0.8852465, 0.95034784]\n",
      "Batch 275/700: Discriminator loss = 1.1408969163894653, GAN loss = [2.4814665, 0.9102851, 0.95070183]\n",
      "Batch 276/700: Discriminator loss = 1.1571825742721558, GAN loss = [2.4181023, 0.86139756, 0.9362273]\n",
      "Batch 277/700: Discriminator loss = 1.1279383897781372, GAN loss = [2.5412788, 0.905907, 1.0149018]\n",
      "Batch 278/700: Discriminator loss = 1.1194053888320923, GAN loss = [2.4903092, 0.9134799, 0.9563844]\n",
      "Batch 279/700: Discriminator loss = 1.120907187461853, GAN loss = [2.5179887, 0.9240267, 0.9735352]\n",
      "Batch 280/700: Discriminator loss = 1.1455273628234863, GAN loss = [2.4975326, 0.8927028, 0.9844608]\n",
      "Batch 281/700: Discriminator loss = 1.1386123895645142, GAN loss = [2.5102327, 0.9132874, 0.97661394]\n",
      "Batch 282/700: Discriminator loss = 1.128073811531067, GAN loss = [2.5575612, 0.9272701, 1.0099782]\n",
      "Batch 283/700: Discriminator loss = 1.1036427021026611, GAN loss = [2.5548527, 0.9196358, 1.0148965]\n",
      "Batch 284/700: Discriminator loss = 1.1363232135772705, GAN loss = [2.5199409, 0.89873403, 1.0008701]\n",
      "Batch 285/700: Discriminator loss = 1.1297144889831543, GAN loss = [2.5172703, 0.90010214, 0.99682325]\n",
      "Batch 286/700: Discriminator loss = 1.1343713998794556, GAN loss = [2.611573, 0.9071429, 1.0840888]\n",
      "Batch 287/700: Discriminator loss = 1.1220967769622803, GAN loss = [2.5733454, 0.90715134, 1.0458716]\n",
      "Batch 288/700: Discriminator loss = 1.114903211593628, GAN loss = [2.66283, 0.9166927, 1.1258363]\n",
      "Batch 289/700: Discriminator loss = 1.1193758249282837, GAN loss = [2.5521634, 0.91920626, 1.0126768]\n",
      "Batch 290/700: Discriminator loss = 1.111896276473999, GAN loss = [2.602502, 0.92416567, 1.058065]\n",
      "Batch 291/700: Discriminator loss = 1.1118545532226562, GAN loss = [2.688905, 0.9339643, 1.1346962]\n",
      "Batch 292/700: Discriminator loss = 1.1129873991012573, GAN loss = [2.6933262, 0.93148786, 1.1415809]\n",
      "Batch 293/700: Discriminator loss = 1.143196940422058, GAN loss = [2.4982646, 0.90614486, 0.9718467]\n",
      "Batch 294/700: Discriminator loss = 1.1295716762542725, GAN loss = [2.5953815, 0.92683, 1.0482707]\n",
      "Batch 295/700: Discriminator loss = 1.140008568763733, GAN loss = [2.544257, 0.9050529, 1.0189104]\n",
      "Batch 296/700: Discriminator loss = 1.1290006637573242, GAN loss = [2.5881763, 0.9273019, 1.0405345]\n",
      "Batch 297/700: Discriminator loss = 1.11789870262146, GAN loss = [2.6187496, 0.9524285, 1.0459229]\n",
      "Batch 298/700: Discriminator loss = 1.1122105121612549, GAN loss = [2.506305, 0.923663, 0.96221644]\n",
      "Batch 299/700: Discriminator loss = 1.1254135370254517, GAN loss = [2.671468, 0.94192123, 1.1090686]\n",
      "Batch 300/700: Discriminator loss = 1.1193504333496094, GAN loss = [2.5148616, 0.924562, 0.9697389]\n",
      "Batch 301/700: Discriminator loss = 1.1120091676712036, GAN loss = [2.5138218, 0.9142959, 0.97893906]\n",
      "Batch 302/700: Discriminator loss = 1.1430548429489136, GAN loss = [2.4863148, 0.90387434, 0.96176535]\n",
      "Batch 303/700: Discriminator loss = 1.1391240358352661, GAN loss = [2.5480897, 0.9287768, 0.9985672]\n",
      "Batch 304/700: Discriminator loss = 1.1222537755966187, GAN loss = [2.6356165, 0.94429964, 1.070501]\n",
      "Batch 305/700: Discriminator loss = 1.133275032043457, GAN loss = [2.55746, 0.9328918, 1.0036603]\n",
      "Batch 306/700: Discriminator loss = 1.1263188123703003, GAN loss = [2.5333703, 0.9373616, 0.9750792]\n",
      "Batch 307/700: Discriminator loss = 1.1544454097747803, GAN loss = [2.497237, 0.9146567, 0.96165115]\n",
      "Batch 308/700: Discriminator loss = 1.140773892402649, GAN loss = [2.4804149, 0.91503906, 0.9443859]\n",
      "Batch 309/700: Discriminator loss = 1.158921480178833, GAN loss = [2.5463011, 0.92168486, 1.0035341]\n",
      "Batch 310/700: Discriminator loss = 1.1742912530899048, GAN loss = [2.4526885, 0.8985972, 0.93292373]\n",
      "Batch 311/700: Discriminator loss = 1.1997874975204468, GAN loss = [2.534707, 0.8977936, 1.0157226]\n",
      "Batch 312/700: Discriminator loss = 1.1744716167449951, GAN loss = [2.437338, 0.90252113, 0.91360307]\n",
      "Batch 313/700: Discriminator loss = 1.1948705911636353, GAN loss = [2.5016181, 0.93508667, 0.94528276]\n",
      "Batch 314/700: Discriminator loss = 1.1415176391601562, GAN loss = [2.5456157, 0.9198406, 1.0044546]\n",
      "Batch 315/700: Discriminator loss = 1.1831446886062622, GAN loss = [2.4843483, 0.9325588, 0.9303987]\n",
      "Batch 316/700: Discriminator loss = 1.2208271026611328, GAN loss = [2.366214, 0.8458049, 0.89895606]\n",
      "Batch 317/700: Discriminator loss = 1.1753824949264526, GAN loss = [2.3703675, 0.87465554, 0.8742235]\n",
      "Batch 318/700: Discriminator loss = 1.1900763511657715, GAN loss = [2.4081151, 0.86382586, 0.92277575]\n",
      "Batch 319/700: Discriminator loss = 1.2139854431152344, GAN loss = [2.4092188, 0.83952665, 0.94819754]\n",
      "Batch 320/700: Discriminator loss = 1.182891845703125, GAN loss = [2.3980958, 0.8723832, 0.9042214]\n",
      "Batch 321/700: Discriminator loss = 1.1971653699874878, GAN loss = [2.4313993, 0.8508175, 0.95910174]\n",
      "Batch 322/700: Discriminator loss = 1.234688639640808, GAN loss = [2.3178306, 0.84103674, 0.8553219]\n",
      "Batch 323/700: Discriminator loss = 1.205513596534729, GAN loss = [2.3596237, 0.84107924, 0.89699495]\n",
      "Batch 324/700: Discriminator loss = 1.2290884256362915, GAN loss = [2.3211217, 0.8113548, 0.88815355]\n",
      "Batch 325/700: Discriminator loss = 1.209002137184143, GAN loss = [2.3843741, 0.86237556, 0.90036803]\n",
      "Batch 326/700: Discriminator loss = 1.2004386186599731, GAN loss = [2.4303553, 0.8592446, 0.9494555]\n",
      "Batch 327/700: Discriminator loss = 1.2099430561065674, GAN loss = [2.30314, 0.80796343, 0.8734528]\n",
      "Batch 328/700: Discriminator loss = 1.2155165672302246, GAN loss = [2.3374534, 0.7944493, 0.9212114]\n",
      "Batch 329/700: Discriminator loss = 1.2268662452697754, GAN loss = [2.2564535, 0.7962416, 0.8383384]\n",
      "Batch 330/700: Discriminator loss = 1.2238489389419556, GAN loss = [2.357617, 0.7996284, 0.9360719]\n",
      "Batch 331/700: Discriminator loss = 1.1984117031097412, GAN loss = [2.284208, 0.802149, 0.8600849]\n",
      "Batch 332/700: Discriminator loss = 1.2252416610717773, GAN loss = [2.319347, 0.8036483, 0.8936714]\n",
      "Batch 333/700: Discriminator loss = 1.223025918006897, GAN loss = [2.3293035, 0.80801535, 0.89917755]\n",
      "Batch 334/700: Discriminator loss = 1.2321527004241943, GAN loss = [2.237783, 0.7902081, 0.8254254]\n",
      "Batch 335/700: Discriminator loss = 1.2372913360595703, GAN loss = [2.2463233, 0.80947495, 0.81463003]\n",
      "Batch 336/700: Discriminator loss = 1.2260706424713135, GAN loss = [2.2987797, 0.8144693, 0.86206526]\n",
      "Batch 337/700: Discriminator loss = 1.2081019878387451, GAN loss = [2.281433, 0.8163003, 0.8428622]\n",
      "Batch 338/700: Discriminator loss = 1.2090331315994263, GAN loss = [2.2689767, 0.8108069, 0.8358395]\n",
      "Batch 339/700: Discriminator loss = 1.2034850120544434, GAN loss = [2.326663, 0.82182395, 0.8825043]\n",
      "Batch 340/700: Discriminator loss = 1.197892427444458, GAN loss = [2.3877835, 0.83269155, 0.932809]\n",
      "Batch 341/700: Discriminator loss = 1.1698403358459473, GAN loss = [2.36869, 0.88316447, 0.8632707]\n",
      "Batch 342/700: Discriminator loss = 1.1883411407470703, GAN loss = [2.3609333, 0.8424634, 0.8962236]\n",
      "Batch 343/700: Discriminator loss = 1.174451470375061, GAN loss = [2.3220267, 0.8293369, 0.8703836]\n",
      "Batch 344/700: Discriminator loss = 1.1757773160934448, GAN loss = [2.356435, 0.8635818, 0.8705411]\n",
      "Batch 345/700: Discriminator loss = 1.1716382503509521, GAN loss = [2.3775096, 0.8475102, 0.9076987]\n",
      "Batch 346/700: Discriminator loss = 1.1470898389816284, GAN loss = [2.4414957, 0.884295, 0.9349085]\n",
      "Batch 347/700: Discriminator loss = 1.1896088123321533, GAN loss = [2.511052, 0.90051055, 0.98828804]\n",
      "Batch 348/700: Discriminator loss = 1.1573246717453003, GAN loss = [2.452112, 0.89744157, 0.9324024]\n",
      "Batch 349/700: Discriminator loss = 1.1229089498519897, GAN loss = [2.433506, 0.8999096, 0.9112934]\n",
      "Batch 350/700: Discriminator loss = 1.160821795463562, GAN loss = [2.4057212, 0.88898546, 0.89442325]\n",
      "Batch 351/700: Discriminator loss = 1.1436270475387573, GAN loss = [2.4530487, 0.91124094, 0.91952485]\n",
      "Batch 352/700: Discriminator loss = 1.132087230682373, GAN loss = [2.4274492, 0.9133339, 0.8918816]\n",
      "Batch 353/700: Discriminator loss = 1.1670920848846436, GAN loss = [2.4497485, 0.89130133, 0.9362231]\n",
      "Batch 354/700: Discriminator loss = 1.1881734132766724, GAN loss = [2.3785355, 0.8418276, 0.91450655]\n",
      "Batch 355/700: Discriminator loss = 1.1640280485153198, GAN loss = [2.3975794, 0.87961286, 0.8958598]\n",
      "Batch 356/700: Discriminator loss = 1.1630791425704956, GAN loss = [2.4436362, 0.884394, 0.9371931]\n",
      "Batch 357/700: Discriminator loss = 1.2065470218658447, GAN loss = [2.3998804, 0.84415084, 0.9337087]\n",
      "Batch 358/700: Discriminator loss = 1.1939418315887451, GAN loss = [2.409788, 0.842157, 0.9456378]\n",
      "Batch 359/700: Discriminator loss = 1.1909704208374023, GAN loss = [2.3469858, 0.86133415, 0.86368006]\n",
      "Batch 360/700: Discriminator loss = 1.1709449291229248, GAN loss = [2.3350244, 0.8431785, 0.86989814]\n",
      "Batch 361/700: Discriminator loss = 1.1878936290740967, GAN loss = [2.336359, 0.8471697, 0.8672485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 362/700: Discriminator loss = 1.1617920398712158, GAN loss = [2.4409113, 0.879166, 0.9398117]\n",
      "Batch 363/700: Discriminator loss = 1.1678522825241089, GAN loss = [2.4137204, 0.8570831, 0.93470347]\n",
      "Batch 364/700: Discriminator loss = 1.128526210784912, GAN loss = [2.4320617, 0.8972666, 0.91290504]\n",
      "Batch 365/700: Discriminator loss = 1.166903018951416, GAN loss = [2.394431, 0.8725149, 0.9000399]\n",
      "Batch 366/700: Discriminator loss = 1.1723089218139648, GAN loss = [2.3389256, 0.8667501, 0.8503212]\n",
      "Batch 367/700: Discriminator loss = 1.1881532669067383, GAN loss = [2.3630748, 0.838416, 0.90281564]\n",
      "Batch 368/700: Discriminator loss = 1.1723146438598633, GAN loss = [2.3947983, 0.8464615, 0.9264904]\n",
      "Batch 369/700: Discriminator loss = 1.2006025314331055, GAN loss = [2.3739204, 0.82884187, 0.92318815]\n",
      "Batch 370/700: Discriminator loss = 1.167384386062622, GAN loss = [2.434704, 0.8851712, 0.92761713]\n",
      "Batch 371/700: Discriminator loss = 1.1918607950210571, GAN loss = [2.3108416, 0.81568927, 0.8732575]\n",
      "Batch 372/700: Discriminator loss = 1.1804128885269165, GAN loss = [2.3461792, 0.8179117, 0.90640104]\n",
      "Batch 373/700: Discriminator loss = 1.2214561700820923, GAN loss = [2.263276, 0.8018308, 0.8396261]\n",
      "Batch 374/700: Discriminator loss = 1.1909433603286743, GAN loss = [2.3251617, 0.82883865, 0.8745458]\n",
      "Batch 375/700: Discriminator loss = 1.1884675025939941, GAN loss = [2.2711248, 0.8280326, 0.82136816]\n",
      "Batch 376/700: Discriminator loss = 1.188933253288269, GAN loss = [2.2909324, 0.81720436, 0.85201174]\n",
      "Batch 377/700: Discriminator loss = 1.1807291507720947, GAN loss = [2.3409615, 0.83780617, 0.8814609]\n",
      "Batch 378/700: Discriminator loss = 1.1932235956192017, GAN loss = [2.3069992, 0.8165754, 0.8687693]\n",
      "Batch 379/700: Discriminator loss = 1.207302451133728, GAN loss = [2.339934, 0.7968631, 0.92148554]\n",
      "Batch 380/700: Discriminator loss = 1.1990752220153809, GAN loss = [2.3531249, 0.82191116, 0.9096791]\n",
      "Batch 381/700: Discriminator loss = 1.1589555740356445, GAN loss = [2.4484832, 0.85771006, 0.9692849]\n",
      "Batch 382/700: Discriminator loss = 1.1757174730300903, GAN loss = [2.3193126, 0.82158244, 0.8762883]\n",
      "Batch 383/700: Discriminator loss = 1.1914851665496826, GAN loss = [2.3134658, 0.8100504, 0.8820438]\n",
      "Batch 384/700: Discriminator loss = 1.190934658050537, GAN loss = [2.3354385, 0.81958026, 0.89456177]\n",
      "Batch 385/700: Discriminator loss = 1.170766830444336, GAN loss = [2.317297, 0.8411952, 0.85487145]\n",
      "Batch 386/700: Discriminator loss = 1.1564079523086548, GAN loss = [2.4269419, 0.8715689, 0.9342316]\n",
      "Batch 387/700: Discriminator loss = 1.192345142364502, GAN loss = [2.2954524, 0.8272609, 0.84711593]\n",
      "Batch 388/700: Discriminator loss = 1.1986720561981201, GAN loss = [2.2728643, 0.8303654, 0.8214491]\n",
      "Batch 389/700: Discriminator loss = 1.1820112466812134, GAN loss = [2.3393643, 0.8482418, 0.8701248]\n",
      "Batch 390/700: Discriminator loss = 1.163490891456604, GAN loss = [2.4236903, 0.868111, 0.9346419]\n",
      "Batch 391/700: Discriminator loss = 1.1954758167266846, GAN loss = [2.3131356, 0.8230545, 0.8692069]\n",
      "Batch 392/700: Discriminator loss = 1.2048691511154175, GAN loss = [2.2914934, 0.7965671, 0.8741178]\n",
      "Batch 393/700: Discriminator loss = 1.156786322593689, GAN loss = [2.3794162, 0.87924033, 0.8794214]\n",
      "Batch 394/700: Discriminator loss = 1.1819394826889038, GAN loss = [2.2862482, 0.8280989, 0.8374111]\n",
      "Batch 395/700: Discriminator loss = 1.1462140083312988, GAN loss = [2.3687437, 0.85646224, 0.8915744]\n",
      "Batch 396/700: Discriminator loss = 1.2116060256958008, GAN loss = [2.326666, 0.8059689, 0.90004367]\n",
      "Batch 397/700: Discriminator loss = 1.1686681509017944, GAN loss = [2.3229935, 0.8343501, 0.8680188]\n",
      "Batch 398/700: Discriminator loss = 1.171967625617981, GAN loss = [2.3269928, 0.86167055, 0.844714]\n",
      "Batch 399/700: Discriminator loss = 1.198116660118103, GAN loss = [2.3003464, 0.8186444, 0.8610992]\n",
      "Batch 400/700: Discriminator loss = 1.150723934173584, GAN loss = [2.3387015, 0.85521066, 0.86288935]\n",
      "Batch 401/700: Discriminator loss = 1.1529247760772705, GAN loss = [2.337788, 0.84916663, 0.8680624]\n",
      "Batch 402/700: Discriminator loss = 1.164849042892456, GAN loss = [2.3427439, 0.84590393, 0.8763509]\n",
      "Batch 403/700: Discriminator loss = 1.1794341802597046, GAN loss = [2.287393, 0.83845246, 0.82850295]\n",
      "Batch 404/700: Discriminator loss = 1.1961456537246704, GAN loss = [2.2788138, 0.81059843, 0.847832]\n",
      "Batch 405/700: Discriminator loss = 1.1828416585922241, GAN loss = [2.2565656, 0.81822467, 0.817992]\n",
      "Batch 406/700: Discriminator loss = 1.21036696434021, GAN loss = [2.2032456, 0.78888583, 0.79404604]\n",
      "Batch 407/700: Discriminator loss = 1.2192068099975586, GAN loss = [2.2540507, 0.78795755, 0.84580237]\n",
      "Batch 408/700: Discriminator loss = 1.2159124612808228, GAN loss = [2.2884707, 0.78007287, 0.88813776]\n",
      "Batch 409/700: Discriminator loss = 1.2279841899871826, GAN loss = [2.2385488, 0.7681917, 0.8501437]\n",
      "Batch 410/700: Discriminator loss = 1.2541371583938599, GAN loss = [2.1943867, 0.74278617, 0.8314124]\n",
      "Batch 411/700: Discriminator loss = 1.2518184185028076, GAN loss = [2.182712, 0.76903564, 0.7935232]\n",
      "Batch 412/700: Discriminator loss = 1.2360366582870483, GAN loss = [2.2192047, 0.7579657, 0.8411007]\n",
      "Batch 413/700: Discriminator loss = 1.235949993133545, GAN loss = [2.1821594, 0.75684303, 0.8051957]\n",
      "Batch 414/700: Discriminator loss = 1.2528300285339355, GAN loss = [2.207476, 0.7464286, 0.8409507]\n",
      "Batch 415/700: Discriminator loss = 1.215627908706665, GAN loss = [2.2197843, 0.8024855, 0.7972202]\n",
      "Batch 416/700: Discriminator loss = 1.2209503650665283, GAN loss = [2.2235553, 0.764151, 0.8393543]\n",
      "Batch 417/700: Discriminator loss = 1.2409452199935913, GAN loss = [2.156102, 0.73373675, 0.80233794]\n",
      "Batch 418/700: Discriminator loss = 1.2541898488998413, GAN loss = [2.187443, 0.72928405, 0.8381361]\n",
      "Batch 419/700: Discriminator loss = 1.231339693069458, GAN loss = [2.167454, 0.7412254, 0.8062161]\n",
      "Batch 420/700: Discriminator loss = 1.2572389841079712, GAN loss = [2.1327553, 0.73887205, 0.77391005]\n",
      "Batch 421/700: Discriminator loss = 1.252933144569397, GAN loss = [2.177823, 0.73771584, 0.8201856]\n",
      "Batch 422/700: Discriminator loss = 1.2053601741790771, GAN loss = [2.1894963, 0.7538889, 0.8157376]\n",
      "Batch 423/700: Discriminator loss = 1.2229994535446167, GAN loss = [2.1847885, 0.76386297, 0.8011104]\n",
      "Batch 424/700: Discriminator loss = 1.2206250429153442, GAN loss = [2.2182717, 0.7586631, 0.83983207]\n",
      "Batch 425/700: Discriminator loss = 1.2053134441375732, GAN loss = [2.1609929, 0.7747819, 0.76647055]\n",
      "Batch 426/700: Discriminator loss = 1.2176764011383057, GAN loss = [2.1999037, 0.75660866, 0.8235822]\n",
      "Batch 427/700: Discriminator loss = 1.2061535120010376, GAN loss = [2.187349, 0.7585883, 0.8090826]\n",
      "Batch 428/700: Discriminator loss = 1.1918296813964844, GAN loss = [2.2363966, 0.7667988, 0.8499596]\n",
      "Batch 429/700: Discriminator loss = 1.2087067365646362, GAN loss = [2.2568483, 0.7705815, 0.8666663]\n",
      "Batch 430/700: Discriminator loss = 1.2086580991744995, GAN loss = [2.253085, 0.7571555, 0.87638575]\n",
      "Batch 431/700: Discriminator loss = 1.2019752264022827, GAN loss = [2.246731, 0.77787316, 0.84935015]\n",
      "Batch 432/700: Discriminator loss = 1.2041094303131104, GAN loss = [2.2229745, 0.7894819, 0.81401044]\n",
      "Batch 433/700: Discriminator loss = 1.197328805923462, GAN loss = [2.2340446, 0.77398145, 0.84063154]\n",
      "Batch 434/700: Discriminator loss = 1.188663363456726, GAN loss = [2.266345, 0.7771175, 0.8698713]\n",
      "Batch 435/700: Discriminator loss = 1.18849778175354, GAN loss = [2.3123796, 0.8038618, 0.8891983]\n",
      "Batch 436/700: Discriminator loss = 1.1943594217300415, GAN loss = [2.2697937, 0.80109614, 0.84941846]\n",
      "Batch 437/700: Discriminator loss = 1.1754869222640991, GAN loss = [2.2752686, 0.8023333, 0.8536706]\n",
      "Batch 438/700: Discriminator loss = 1.187727451324463, GAN loss = [2.2251506, 0.7763255, 0.82959497]\n",
      "Batch 439/700: Discriminator loss = 1.166396141052246, GAN loss = [2.2704167, 0.7937627, 0.8574551]\n",
      "Batch 440/700: Discriminator loss = 1.1782206296920776, GAN loss = [2.240625, 0.7988601, 0.8225987]\n",
      "Batch 441/700: Discriminator loss = 1.1670345067977905, GAN loss = [2.2764025, 0.8006485, 0.8566262]\n",
      "Batch 442/700: Discriminator loss = 1.1890606880187988, GAN loss = [2.2879212, 0.7838676, 0.8849279]\n",
      "Batch 443/700: Discriminator loss = 1.185305118560791, GAN loss = [2.2913692, 0.800466, 0.87180215]\n",
      "Batch 444/700: Discriminator loss = 1.1415156126022339, GAN loss = [2.3223803, 0.84264857, 0.8606753]\n",
      "Batch 445/700: Discriminator loss = 1.1459190845489502, GAN loss = [2.3426497, 0.8300054, 0.8936211]\n",
      "Batch 446/700: Discriminator loss = 1.174654245376587, GAN loss = [2.2446759, 0.8056925, 0.8199827]\n",
      "Batch 447/700: Discriminator loss = 1.170161247253418, GAN loss = [2.3256004, 0.80837077, 0.8982596]\n",
      "Batch 448/700: Discriminator loss = 1.172278881072998, GAN loss = [2.2913206, 0.80983764, 0.86255217]\n",
      "Batch 449/700: Discriminator loss = 1.168705701828003, GAN loss = [2.3015997, 0.81719315, 0.8655114]\n",
      "Batch 450/700: Discriminator loss = 1.1705299615859985, GAN loss = [2.2776287, 0.8086194, 0.850158]\n",
      "Batch 451/700: Discriminator loss = 1.1749176979064941, GAN loss = [2.2738805, 0.8139255, 0.8411453]\n",
      "Batch 452/700: Discriminator loss = 1.193711757659912, GAN loss = [2.3558056, 0.7946805, 0.94236135]\n",
      "Batch 453/700: Discriminator loss = 1.172936201095581, GAN loss = [2.2936027, 0.8032316, 0.8716257]\n",
      "Batch 454/700: Discriminator loss = 1.169395089149475, GAN loss = [2.2960157, 0.801965, 0.87532645]\n",
      "Batch 455/700: Discriminator loss = 1.1709319353103638, GAN loss = [2.2637095, 0.80562806, 0.83938676]\n",
      "Batch 456/700: Discriminator loss = 1.1564438343048096, GAN loss = [2.3609943, 0.82271856, 0.9196074]\n",
      "Batch 457/700: Discriminator loss = 1.142399549484253, GAN loss = [2.3936787, 0.82769036, 0.94733596]\n",
      "Batch 458/700: Discriminator loss = 1.1615650653839111, GAN loss = [2.282065, 0.8099979, 0.85345274]\n",
      "Batch 459/700: Discriminator loss = 1.1760247945785522, GAN loss = [2.2762592, 0.8016925, 0.85600096]\n",
      "Batch 460/700: Discriminator loss = 1.144019603729248, GAN loss = [2.3400364, 0.81892085, 0.9025995]\n",
      "Batch 461/700: Discriminator loss = 1.1737805604934692, GAN loss = [2.2935243, 0.82055384, 0.8544987]\n",
      "Batch 462/700: Discriminator loss = 1.1829391717910767, GAN loss = [2.3003085, 0.8222863, 0.85956687]\n",
      "Batch 463/700: Discriminator loss = 1.1770882606506348, GAN loss = [2.2876933, 0.80473936, 0.86449015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 464/700: Discriminator loss = 1.17767333984375, GAN loss = [2.3134673, 0.7977644, 0.89724123]\n",
      "Batch 465/700: Discriminator loss = 1.188068151473999, GAN loss = [2.2637386, 0.79571235, 0.8495592]\n",
      "Batch 466/700: Discriminator loss = 1.1924972534179688, GAN loss = [2.3235433, 0.7962548, 0.90880847]\n",
      "Batch 467/700: Discriminator loss = 1.180245041847229, GAN loss = [2.266696, 0.8046654, 0.84356356]\n",
      "Batch 468/700: Discriminator loss = 1.1524578332901, GAN loss = [2.3414645, 0.84836775, 0.8746393]\n",
      "Batch 469/700: Discriminator loss = 1.17753005027771, GAN loss = [2.2936926, 0.8002938, 0.8749852]\n",
      "Batch 470/700: Discriminator loss = 1.1713991165161133, GAN loss = [2.3130853, 0.8151836, 0.87950736]\n",
      "Batch 471/700: Discriminator loss = 1.1577483415603638, GAN loss = [2.3174005, 0.81758165, 0.8814311]\n",
      "Batch 472/700: Discriminator loss = 1.1636322736740112, GAN loss = [2.352299, 0.8185923, 0.91531837]\n",
      "Batch 473/700: Discriminator loss = 1.1669191122055054, GAN loss = [2.3510833, 0.81205404, 0.9206198]\n",
      "Batch 474/700: Discriminator loss = 1.180050015449524, GAN loss = [2.3656976, 0.8137138, 0.93358666]\n",
      "Batch 475/700: Discriminator loss = 1.1589586734771729, GAN loss = [2.3232586, 0.8250997, 0.87979066]\n",
      "Batch 476/700: Discriminator loss = 1.1448591947555542, GAN loss = [2.3975205, 0.83856016, 0.9406068]\n",
      "Batch 477/700: Discriminator loss = 1.1510496139526367, GAN loss = [2.3458645, 0.8257079, 0.90183085]\n",
      "Batch 478/700: Discriminator loss = 1.1400202512741089, GAN loss = [2.4003997, 0.8447141, 0.9374012]\n",
      "Batch 479/700: Discriminator loss = 1.149843454360962, GAN loss = [2.3497634, 0.826498, 0.905017]\n",
      "Batch 480/700: Discriminator loss = 1.1385918855667114, GAN loss = [2.426563, 0.84347445, 0.9648793]\n",
      "Batch 481/700: Discriminator loss = 1.1375263929367065, GAN loss = [2.384664, 0.8362017, 0.93027604]\n",
      "Batch 482/700: Discriminator loss = 1.151931643486023, GAN loss = [2.3980591, 0.842101, 0.9378348]\n",
      "Batch 483/700: Discriminator loss = 1.1368303298950195, GAN loss = [2.440941, 0.84542596, 0.977444]\n",
      "Batch 484/700: Discriminator loss = 1.1167101860046387, GAN loss = [2.3578653, 0.86497056, 0.87487304]\n",
      "Batch 485/700: Discriminator loss = 1.134053111076355, GAN loss = [2.4150565, 0.850101, 0.9469807]\n",
      "Batch 486/700: Discriminator loss = 1.1297571659088135, GAN loss = [2.3993342, 0.84658194, 0.9348254]\n",
      "Batch 487/700: Discriminator loss = 1.1482192277908325, GAN loss = [2.320444, 0.84029764, 0.8622651]\n",
      "Batch 488/700: Discriminator loss = 1.1464519500732422, GAN loss = [2.4306214, 0.8293448, 0.9834233]\n",
      "Batch 489/700: Discriminator loss = 1.145066738128662, GAN loss = [2.3871396, 0.8430836, 0.92624366]\n",
      "Batch 490/700: Discriminator loss = 1.146095633506775, GAN loss = [2.3779628, 0.8246856, 0.93548083]\n",
      "Batch 491/700: Discriminator loss = 1.1655726432800293, GAN loss = [2.3366804, 0.82573164, 0.8931757]\n",
      "Batch 492/700: Discriminator loss = 1.1624844074249268, GAN loss = [2.3638916, 0.8117, 0.9344309]\n",
      "Batch 493/700: Discriminator loss = 1.1702690124511719, GAN loss = [2.3350372, 0.80034554, 0.91696745]\n",
      "Batch 494/700: Discriminator loss = 1.1702189445495605, GAN loss = [2.3496957, 0.79284805, 0.93913734]\n",
      "Batch 495/700: Discriminator loss = 1.1682450771331787, GAN loss = [2.4122746, 0.80646443, 0.988125]\n",
      "Batch 496/700: Discriminator loss = 1.1827068328857422, GAN loss = [2.2659612, 0.782563, 0.86575896]\n",
      "Batch 497/700: Discriminator loss = 1.1771906614303589, GAN loss = [2.3166747, 0.80358154, 0.895461]\n",
      "Batch 498/700: Discriminator loss = 1.154207468032837, GAN loss = [2.3644588, 0.8029248, 0.94389427]\n",
      "Batch 499/700: Discriminator loss = 1.1745816469192505, GAN loss = [2.354795, 0.78249204, 0.9546741]\n",
      "Batch 500/700: Discriminator loss = 1.1403173208236694, GAN loss = [2.467682, 0.8223144, 1.0277395]\n",
      "Batch 501/700: Discriminator loss = 1.1640000343322754, GAN loss = [2.2950537, 0.7986973, 0.87874496]\n",
      "Batch 502/700: Discriminator loss = 1.1450815200805664, GAN loss = [2.3654587, 0.81482065, 0.9330505]\n",
      "Batch 503/700: Discriminator loss = 1.1643998622894287, GAN loss = [2.3024814, 0.79941535, 0.8855107]\n",
      "Batch 504/700: Discriminator loss = 1.1650341749191284, GAN loss = [2.412986, 0.8230957, 0.97234416]\n",
      "Batch 505/700: Discriminator loss = 1.1487210988998413, GAN loss = [2.3693552, 0.82586867, 0.9259745]\n",
      "Batch 506/700: Discriminator loss = 1.1496658325195312, GAN loss = [2.3262677, 0.8210073, 0.8877798]\n",
      "Batch 507/700: Discriminator loss = 1.1366455554962158, GAN loss = [2.3961463, 0.83685666, 0.94186866]\n",
      "Batch 508/700: Discriminator loss = 1.1567026376724243, GAN loss = [2.3428907, 0.8090722, 0.9164154]\n",
      "Batch 509/700: Discriminator loss = 1.109477162361145, GAN loss = [2.458531, 0.86168706, 0.9794698]\n",
      "Batch 510/700: Discriminator loss = 1.149680256843567, GAN loss = [2.3379564, 0.816869, 0.9037272]\n",
      "Batch 511/700: Discriminator loss = 1.1351392269134521, GAN loss = [2.3148634, 0.82765883, 0.8698599]\n",
      "Batch 512/700: Discriminator loss = 1.1312320232391357, GAN loss = [2.412022, 0.8415874, 0.9531082]\n",
      "Batch 513/700: Discriminator loss = 1.1488193273544312, GAN loss = [2.4055364, 0.8284294, 0.9597853]\n",
      "Batch 514/700: Discriminator loss = 1.1437913179397583, GAN loss = [2.4599717, 0.83175284, 1.0109051]\n",
      "Batch 515/700: Discriminator loss = 1.1688015460968018, GAN loss = [2.3431017, 0.80789584, 0.9178906]\n",
      "Batch 516/700: Discriminator loss = 1.1295756101608276, GAN loss = [2.3371108, 0.8399535, 0.8798473]\n",
      "Batch 517/700: Discriminator loss = 1.1408872604370117, GAN loss = [2.377089, 0.8387203, 0.9210856]\n",
      "Batch 518/700: Discriminator loss = 1.1530325412750244, GAN loss = [2.3939934, 0.8411767, 0.9355777]\n",
      "Batch 519/700: Discriminator loss = 1.1421895027160645, GAN loss = [2.4610221, 0.86281466, 0.98096955]\n",
      "Batch 520/700: Discriminator loss = 1.1441303491592407, GAN loss = [2.4426992, 0.836282, 0.98920494]\n",
      "Batch 521/700: Discriminator loss = 1.1514794826507568, GAN loss = [2.4151502, 0.8276489, 0.9703216]\n",
      "Batch 522/700: Discriminator loss = 1.1223033666610718, GAN loss = [2.4507565, 0.8643225, 0.9692933]\n",
      "Batch 523/700: Discriminator loss = 1.1460026502609253, GAN loss = [2.4209542, 0.86247736, 0.94136775]\n",
      "Batch 524/700: Discriminator loss = 1.1006965637207031, GAN loss = [2.6503744, 0.9070617, 1.1262542]\n",
      "Batch 525/700: Discriminator loss = 1.0971144437789917, GAN loss = [2.533351, 0.894879, 1.0214611]\n",
      "Batch 526/700: Discriminator loss = 1.1315057277679443, GAN loss = [2.4729085, 0.85818774, 0.9977662]\n",
      "Batch 527/700: Discriminator loss = 1.1103333234786987, GAN loss = [2.5005524, 0.89174795, 0.99189216]\n",
      "Batch 528/700: Discriminator loss = 1.132044792175293, GAN loss = [2.4551284, 0.8610796, 0.9771623]\n",
      "Batch 529/700: Discriminator loss = 1.1295958757400513, GAN loss = [2.455178, 0.8516195, 0.9866802]\n",
      "Batch 530/700: Discriminator loss = 1.1402195692062378, GAN loss = [2.4460847, 0.8532161, 0.9759676]\n",
      "Batch 531/700: Discriminator loss = 1.144385814666748, GAN loss = [2.5376904, 0.8576564, 1.0631291]\n",
      "Batch 532/700: Discriminator loss = 1.1351515054702759, GAN loss = [2.5388193, 0.84197485, 1.0799409]\n",
      "Batch 533/700: Discriminator loss = 1.1171540021896362, GAN loss = [2.4889603, 0.8703404, 1.0017138]\n",
      "Batch 534/700: Discriminator loss = 1.1460530757904053, GAN loss = [2.432994, 0.8437205, 0.9723781]\n",
      "Batch 535/700: Discriminator loss = 1.1415666341781616, GAN loss = [2.4030464, 0.8380442, 0.94812936]\n",
      "Batch 536/700: Discriminator loss = 1.1452906131744385, GAN loss = [2.4072666, 0.82787967, 0.9625393]\n",
      "Batch 537/700: Discriminator loss = 1.1226623058319092, GAN loss = [2.496012, 0.8620371, 1.0171618]\n",
      "Batch 538/700: Discriminator loss = 1.1184666156768799, GAN loss = [2.4784136, 0.8660501, 0.99556684]\n",
      "Batch 539/700: Discriminator loss = 1.1347894668579102, GAN loss = [2.4570205, 0.8595529, 0.9807042]\n",
      "Batch 540/700: Discriminator loss = 1.1548045873641968, GAN loss = [2.3835564, 0.838566, 0.92825335]\n",
      "Batch 541/700: Discriminator loss = 1.1590549945831299, GAN loss = [2.4817655, 0.8195494, 1.0454913]\n",
      "Batch 542/700: Discriminator loss = 1.1806577444076538, GAN loss = [2.404045, 0.80224574, 0.98506963]\n",
      "Batch 543/700: Discriminator loss = 1.169413685798645, GAN loss = [2.5136752, 0.81688845, 1.0800662]\n",
      "Batch 544/700: Discriminator loss = 1.1926640272140503, GAN loss = [2.4633653, 0.8308384, 1.0158054]\n",
      "Batch 545/700: Discriminator loss = 1.1776829957962036, GAN loss = [2.4389071, 0.81487703, 1.0072895]\n",
      "Batch 546/700: Discriminator loss = 1.1497551202774048, GAN loss = [2.3906457, 0.85008484, 0.9237976]\n",
      "Batch 547/700: Discriminator loss = 1.2522013187408447, GAN loss = [2.3177676, 0.7689178, 0.93209565]\n",
      "Batch 548/700: Discriminator loss = 1.2137515544891357, GAN loss = [2.3955112, 0.794785, 0.98395187]\n",
      "Batch 549/700: Discriminator loss = 1.21208918094635, GAN loss = [2.3933973, 0.81487465, 0.9617225]\n",
      "Batch 550/700: Discriminator loss = 1.2021406888961792, GAN loss = [2.3862622, 0.83561957, 0.9338012]\n",
      "Batch 551/700: Discriminator loss = 1.1947304010391235, GAN loss = [2.3780434, 0.83854204, 0.92263305]\n",
      "Batch 552/700: Discriminator loss = 1.212009310722351, GAN loss = [2.2986722, 0.8389137, 0.8428456]\n",
      "Batch 553/700: Discriminator loss = 1.220665693283081, GAN loss = [2.3275237, 0.84374475, 0.8668303]\n",
      "Batch 554/700: Discriminator loss = 1.174730658531189, GAN loss = [2.2967923, 0.86819494, 0.81159455]\n",
      "Batch 555/700: Discriminator loss = 1.170990228652954, GAN loss = [2.416602, 0.9133932, 0.8861496]\n",
      "Batch 556/700: Discriminator loss = 1.1839221715927124, GAN loss = [2.3169222, 0.85011214, 0.8497184]\n",
      "Batch 557/700: Discriminator loss = 1.2014086246490479, GAN loss = [2.3147528, 0.8549124, 0.842743]\n",
      "Batch 558/700: Discriminator loss = 1.163004994392395, GAN loss = [2.4305778, 0.9046887, 0.9087685]\n",
      "Batch 559/700: Discriminator loss = 1.1584664583206177, GAN loss = [2.345011, 0.89646995, 0.8313776]\n",
      "Batch 560/700: Discriminator loss = 1.1898834705352783, GAN loss = [2.4088473, 0.9042006, 0.8874665]\n",
      "Batch 561/700: Discriminator loss = 1.1955931186676025, GAN loss = [2.3749928, 0.8911011, 0.86669314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 562/700: Discriminator loss = 1.2113147974014282, GAN loss = [2.2989569, 0.8296012, 0.8521497]\n",
      "Batch 563/700: Discriminator loss = 1.1702364683151245, GAN loss = [2.3948715, 0.89536786, 0.8822809]\n",
      "Batch 564/700: Discriminator loss = 1.1978386640548706, GAN loss = [2.3870983, 0.857548, 0.91226846]\n",
      "Batch 565/700: Discriminator loss = 1.152265191078186, GAN loss = [2.3819351, 0.9030083, 0.8616326]\n",
      "Batch 566/700: Discriminator loss = 1.1626405715942383, GAN loss = [2.4037857, 0.88924235, 0.897255]\n",
      "Batch 567/700: Discriminator loss = 1.169905662536621, GAN loss = [2.3762882, 0.8666805, 0.89235085]\n",
      "Batch 568/700: Discriminator loss = 1.1452418565750122, GAN loss = [2.3351214, 0.90175515, 0.8161442]\n",
      "Batch 569/700: Discriminator loss = 1.1400080919265747, GAN loss = [2.4473605, 0.90216196, 0.92799807]\n",
      "Batch 570/700: Discriminator loss = 1.1388169527053833, GAN loss = [2.444945, 0.8919133, 0.93584013]\n",
      "Batch 571/700: Discriminator loss = 1.1393463611602783, GAN loss = [2.4421601, 0.90420586, 0.92079973]\n",
      "Batch 572/700: Discriminator loss = 1.1741306781768799, GAN loss = [2.4311981, 0.86612505, 0.947959]\n",
      "Batch 573/700: Discriminator loss = 1.103490948677063, GAN loss = [2.5025256, 0.9102009, 0.97521424]\n",
      "Batch 574/700: Discriminator loss = 1.1054081916809082, GAN loss = [2.5094185, 0.9344284, 0.95790094]\n",
      "Batch 575/700: Discriminator loss = 1.129209041595459, GAN loss = [2.4386556, 0.9020394, 0.91955966]\n",
      "Batch 576/700: Discriminator loss = 1.1251355409622192, GAN loss = [2.4546523, 0.90092516, 0.9366487]\n",
      "Batch 577/700: Discriminator loss = 1.1310253143310547, GAN loss = [2.4812312, 0.8823822, 0.98174405]\n",
      "Batch 578/700: Discriminator loss = 1.1332594156265259, GAN loss = [2.487772, 0.8773054, 0.9933561]\n",
      "Batch 579/700: Discriminator loss = 1.1468275785446167, GAN loss = [2.4759035, 0.8788343, 0.9799575]\n",
      "Batch 580/700: Discriminator loss = 1.1325925588607788, GAN loss = [2.447362, 0.8753646, 0.9548891]\n",
      "Batch 581/700: Discriminator loss = 1.1205729246139526, GAN loss = [2.4524662, 0.87188804, 0.9634768]\n",
      "Batch 582/700: Discriminator loss = 1.1216100454330444, GAN loss = [2.461845, 0.9058683, 0.9389106]\n",
      "Batch 583/700: Discriminator loss = 1.1182106733322144, GAN loss = [2.389326, 0.8690496, 0.90324646]\n",
      "Batch 584/700: Discriminator loss = 1.1441935300827026, GAN loss = [2.3784852, 0.8736474, 0.88784987]\n",
      "Batch 585/700: Discriminator loss = 1.1187822818756104, GAN loss = [2.4225974, 0.8895248, 0.9161131]\n",
      "Batch 586/700: Discriminator loss = 1.127748966217041, GAN loss = [2.4953034, 0.8784234, 0.9999495]\n",
      "Batch 587/700: Discriminator loss = 1.1131492853164673, GAN loss = [2.4266481, 0.88542694, 0.92431265]\n",
      "Batch 588/700: Discriminator loss = 1.1211633682250977, GAN loss = [2.5791667, 0.88289046, 1.0793828]\n",
      "Batch 589/700: Discriminator loss = 1.1731541156768799, GAN loss = [2.4275677, 0.84208834, 0.9686211]\n",
      "Batch 590/700: Discriminator loss = 1.1063964366912842, GAN loss = [2.532578, 0.8886285, 1.0270919]\n",
      "Batch 591/700: Discriminator loss = 1.115736484527588, GAN loss = [2.5260603, 0.88362044, 1.0255855]\n",
      "Batch 592/700: Discriminator loss = 1.152833104133606, GAN loss = [2.4301867, 0.8217006, 0.9916038]\n",
      "Batch 593/700: Discriminator loss = 1.1474783420562744, GAN loss = [2.4236183, 0.845568, 0.96114266]\n",
      "Batch 594/700: Discriminator loss = 1.1291793584823608, GAN loss = [2.5052056, 0.8652389, 1.0230489]\n",
      "Batch 595/700: Discriminator loss = 1.1668224334716797, GAN loss = [2.4662714, 0.8342756, 1.0150965]\n",
      "Batch 596/700: Discriminator loss = 1.1820991039276123, GAN loss = [2.3829682, 0.83554155, 0.93054056]\n",
      "Batch 597/700: Discriminator loss = 1.142436146736145, GAN loss = [2.4127805, 0.84909546, 0.94680595]\n",
      "Batch 598/700: Discriminator loss = 1.1592845916748047, GAN loss = [2.397719, 0.84753066, 0.9333183]\n",
      "Batch 599/700: Discriminator loss = 1.149418592453003, GAN loss = [2.4229994, 0.8343486, 0.97175336]\n",
      "Batch 600/700: Discriminator loss = 1.1600956916809082, GAN loss = [2.4046772, 0.84817576, 0.9395953]\n",
      "Batch 601/700: Discriminator loss = 1.1538970470428467, GAN loss = [2.3991017, 0.8478353, 0.93433607]\n",
      "Batch 602/700: Discriminator loss = 1.1408796310424805, GAN loss = [2.4375017, 0.8451129, 0.975448]\n",
      "Batch 603/700: Discriminator loss = 1.1425985097885132, GAN loss = [2.430293, 0.8484102, 0.96495956]\n",
      "Batch 604/700: Discriminator loss = 1.1121962070465088, GAN loss = [2.4449723, 0.8698351, 0.9582309]\n",
      "Batch 605/700: Discriminator loss = 1.1284103393554688, GAN loss = [2.460205, 0.8942219, 0.9490741]\n",
      "Batch 606/700: Discriminator loss = 1.1347146034240723, GAN loss = [2.471119, 0.8550371, 0.9992003]\n",
      "Batch 607/700: Discriminator loss = 1.138313889503479, GAN loss = [2.429856, 0.8468694, 0.9661391]\n",
      "Batch 608/700: Discriminator loss = 1.1303777694702148, GAN loss = [2.432578, 0.8624703, 0.9533076]\n",
      "Batch 609/700: Discriminator loss = 1.1290533542633057, GAN loss = [2.504183, 0.8501805, 1.0372132]\n",
      "Batch 610/700: Discriminator loss = 1.1134679317474365, GAN loss = [2.5127409, 0.8783018, 1.0176764]\n",
      "Batch 611/700: Discriminator loss = 1.1047154664993286, GAN loss = [2.5023181, 0.8889248, 0.99665076]\n",
      "Batch 612/700: Discriminator loss = 1.1166497468948364, GAN loss = [2.509305, 0.872238, 1.020327]\n",
      "Batch 613/700: Discriminator loss = 1.0989251136779785, GAN loss = [2.616219, 0.9174669, 1.082002]\n",
      "Batch 614/700: Discriminator loss = 1.115348219871521, GAN loss = [2.5629196, 0.8954323, 1.0507087]\n",
      "Batch 615/700: Discriminator loss = 1.1408637762069702, GAN loss = [2.375235, 0.8486953, 0.909766]\n",
      "Batch 616/700: Discriminator loss = 1.1163480281829834, GAN loss = [2.585929, 0.86347115, 1.1056968]\n",
      "Batch 617/700: Discriminator loss = 1.157609224319458, GAN loss = [2.5269487, 0.8695109, 1.0406964]\n",
      "Batch 618/700: Discriminator loss = 1.1159418821334839, GAN loss = [2.4989598, 0.9083023, 0.973942]\n",
      "Batch 619/700: Discriminator loss = 1.1743748188018799, GAN loss = [2.5419462, 0.8583221, 1.0669188]\n",
      "Batch 620/700: Discriminator loss = 1.1302989721298218, GAN loss = [2.4788597, 0.8807526, 0.9814022]\n",
      "Batch 621/700: Discriminator loss = 1.180229663848877, GAN loss = [2.3884654, 0.8231425, 0.94862276]\n",
      "Batch 622/700: Discriminator loss = 1.1623951196670532, GAN loss = [2.3790743, 0.8305775, 0.93180186]\n",
      "Batch 623/700: Discriminator loss = 1.1592249870300293, GAN loss = [2.395538, 0.8453163, 0.9335566]\n",
      "Batch 624/700: Discriminator loss = 1.1754870414733887, GAN loss = [2.4265046, 0.83595663, 0.9738938]\n",
      "Batch 625/700: Discriminator loss = 1.157987117767334, GAN loss = [2.3808362, 0.8409988, 0.9232132]\n",
      "Batch 626/700: Discriminator loss = 1.1990231275558472, GAN loss = [2.3628633, 0.8130618, 0.93319887]\n",
      "Batch 627/700: Discriminator loss = 1.1873154640197754, GAN loss = [2.330064, 0.82740515, 0.88607097]\n",
      "Batch 628/700: Discriminator loss = 1.1694066524505615, GAN loss = [2.389828, 0.81907684, 0.95419097]\n",
      "Batch 629/700: Discriminator loss = 1.1608965396881104, GAN loss = [2.4028182, 0.82915026, 0.9571287]\n",
      "Batch 630/700: Discriminator loss = 1.1846195459365845, GAN loss = [2.3750284, 0.81320363, 0.945313]\n",
      "Batch 631/700: Discriminator loss = 1.1899269819259644, GAN loss = [2.3022256, 0.8019737, 0.88375056]\n",
      "Batch 632/700: Discriminator loss = 1.1598408222198486, GAN loss = [2.348553, 0.8336555, 0.8984173]\n",
      "Batch 633/700: Discriminator loss = 1.1765269041061401, GAN loss = [2.2719617, 0.8002764, 0.8552416]\n",
      "Batch 634/700: Discriminator loss = 1.1968073844909668, GAN loss = [2.3141284, 0.8150608, 0.88266975]\n",
      "Batch 635/700: Discriminator loss = 1.1950222253799438, GAN loss = [2.308354, 0.7921165, 0.8998673]\n",
      "Batch 636/700: Discriminator loss = 1.1632106304168701, GAN loss = [2.3476117, 0.82583064, 0.90542966]\n",
      "Batch 637/700: Discriminator loss = 1.1439865827560425, GAN loss = [2.374477, 0.847292, 0.91085356]\n",
      "Batch 638/700: Discriminator loss = 1.1644556522369385, GAN loss = [2.3569045, 0.83056015, 0.9100111]\n",
      "Batch 639/700: Discriminator loss = 1.1796510219573975, GAN loss = [2.2991993, 0.80907035, 0.87380296]\n",
      "Batch 640/700: Discriminator loss = 1.1788272857666016, GAN loss = [2.3264887, 0.79712754, 0.91301554]\n",
      "Batch 641/700: Discriminator loss = 1.2068120241165161, GAN loss = [2.2795017, 0.78464067, 0.87851244]\n",
      "Batch 642/700: Discriminator loss = 1.1693884134292603, GAN loss = [2.340938, 0.80077493, 0.9238054]\n",
      "Batch 643/700: Discriminator loss = 1.1667085886001587, GAN loss = [2.3626199, 0.8333721, 0.9128764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 644/700: Discriminator loss = 1.194015622138977, GAN loss = [2.3265142, 0.8071744, 0.902948]\n",
      "Batch 645/700: Discriminator loss = 1.201224684715271, GAN loss = [2.2555504, 0.7837416, 0.8553913]\n",
      "Batch 646/700: Discriminator loss = 1.217651128768921, GAN loss = [2.2897468, 0.7844727, 0.88883287]\n",
      "Batch 647/700: Discriminator loss = 1.1615381240844727, GAN loss = [2.3901458, 0.8216706, 0.95201105]\n",
      "Batch 648/700: Discriminator loss = 1.1861028671264648, GAN loss = [2.3707142, 0.82424265, 0.9300006]\n",
      "Batch 649/700: Discriminator loss = 1.2009639739990234, GAN loss = [2.3146365, 0.81499344, 0.88315415]\n",
      "Batch 650/700: Discriminator loss = 1.2013543844223022, GAN loss = [2.3019416, 0.8175296, 0.86788183]\n",
      "Batch 651/700: Discriminator loss = 1.181318759918213, GAN loss = [2.3525734, 0.8078685, 0.9281481]\n",
      "Batch 652/700: Discriminator loss = 1.1677446365356445, GAN loss = [2.3173878, 0.8246356, 0.87616533]\n",
      "Batch 653/700: Discriminator loss = 1.183721661567688, GAN loss = [2.3291733, 0.83881813, 0.8737425]\n",
      "Batch 654/700: Discriminator loss = 1.2245341539382935, GAN loss = [2.225511, 0.77153933, 0.8373321]\n",
      "Batch 655/700: Discriminator loss = 1.1939045190811157, GAN loss = [2.2434766, 0.80576754, 0.82103294]\n",
      "Batch 656/700: Discriminator loss = 1.2021104097366333, GAN loss = [2.2442067, 0.8018203, 0.8256958]\n",
      "Batch 657/700: Discriminator loss = 1.1804593801498413, GAN loss = [2.3205454, 0.7944565, 0.9094046]\n",
      "Batch 658/700: Discriminator loss = 1.177464246749878, GAN loss = [2.3009233, 0.8106652, 0.8735739]\n",
      "Batch 659/700: Discriminator loss = 1.1832295656204224, GAN loss = [2.3469987, 0.8133555, 0.91697305]\n",
      "Batch 660/700: Discriminator loss = 1.1702451705932617, GAN loss = [2.3516834, 0.8210957, 0.9139029]\n",
      "Batch 661/700: Discriminator loss = 1.1947755813598633, GAN loss = [2.3494303, 0.8033785, 0.9293636]\n",
      "Batch 662/700: Discriminator loss = 1.1854504346847534, GAN loss = [2.2880936, 0.80025, 0.87116]\n",
      "Batch 663/700: Discriminator loss = 1.1904667615890503, GAN loss = [2.3277502, 0.81070626, 0.9003659]\n",
      "Batch 664/700: Discriminator loss = 1.1757327318191528, GAN loss = [2.2765641, 0.8061464, 0.8537494]\n",
      "Batch 665/700: Discriminator loss = 1.1573482751846313, GAN loss = [2.3512356, 0.8300289, 0.9045372]\n",
      "Batch 666/700: Discriminator loss = 1.158847451210022, GAN loss = [2.338263, 0.84777343, 0.8738227]\n",
      "Batch 667/700: Discriminator loss = 1.1863272190093994, GAN loss = [2.3528852, 0.81896317, 0.91725916]\n",
      "Batch 668/700: Discriminator loss = 1.1641130447387695, GAN loss = [2.3130333, 0.8175588, 0.87881315]\n",
      "Batch 669/700: Discriminator loss = 1.1424468755722046, GAN loss = [2.3792765, 0.82814467, 0.9344283]\n",
      "Batch 670/700: Discriminator loss = 1.1960053443908691, GAN loss = [2.2683735, 0.77957857, 0.8720758]\n",
      "Batch 671/700: Discriminator loss = 1.1448702812194824, GAN loss = [2.3482468, 0.8279228, 0.90360504]\n",
      "Batch 672/700: Discriminator loss = 1.1774711608886719, GAN loss = [2.3394961, 0.82549727, 0.89727515]\n",
      "Batch 673/700: Discriminator loss = 1.1793946027755737, GAN loss = [2.302444, 0.80525315, 0.8804463]\n",
      "Batch 674/700: Discriminator loss = 1.1733660697937012, GAN loss = [2.3107667, 0.8172514, 0.87671834]\n",
      "Batch 675/700: Discriminator loss = 1.2102932929992676, GAN loss = [2.291478, 0.78786635, 0.88674456]\n",
      "Batch 676/700: Discriminator loss = 1.1805310249328613, GAN loss = [2.268745, 0.8033094, 0.84851784]\n",
      "Batch 677/700: Discriminator loss = 1.1981538534164429, GAN loss = [2.3403034, 0.80532235, 0.9180645]\n",
      "Batch 678/700: Discriminator loss = 1.2080305814743042, GAN loss = [2.3298361, 0.8191931, 0.89373505]\n",
      "Batch 679/700: Discriminator loss = 1.1656919717788696, GAN loss = [2.3715737, 0.8348149, 0.9198818]\n",
      "Batch 680/700: Discriminator loss = 1.1831449270248413, GAN loss = [2.343139, 0.821324, 0.9049482]\n",
      "Batch 681/700: Discriminator loss = 1.1671990156173706, GAN loss = [2.3864377, 0.8438187, 0.92574096]\n",
      "Batch 682/700: Discriminator loss = 1.198786735534668, GAN loss = [2.3482792, 0.80768794, 0.92369294]\n",
      "Batch 683/700: Discriminator loss = 1.1925979852676392, GAN loss = [2.3225622, 0.8249147, 0.88074416]\n",
      "Batch 684/700: Discriminator loss = 1.1701123714447021, GAN loss = [2.2414274, 0.8323087, 0.7922319]\n",
      "Batch 685/700: Discriminator loss = 1.1798934936523438, GAN loss = [2.3129797, 0.82432145, 0.8717855]\n",
      "Batch 686/700: Discriminator loss = 1.167341709136963, GAN loss = [2.3546479, 0.85222566, 0.8855446]\n",
      "Batch 687/700: Discriminator loss = 1.1618313789367676, GAN loss = [2.373013, 0.8390306, 0.917099]\n",
      "Batch 688/700: Discriminator loss = 1.1861125230789185, GAN loss = [2.3260338, 0.83123815, 0.8779136]\n",
      "Batch 689/700: Discriminator loss = 1.1663763523101807, GAN loss = [2.346957, 0.82553726, 0.90455604]\n",
      "Batch 690/700: Discriminator loss = 1.1766701936721802, GAN loss = [2.3364897, 0.81567764, 0.90396357]\n",
      "Batch 691/700: Discriminator loss = 1.1506071090698242, GAN loss = [2.3744676, 0.82990617, 0.92773277]\n",
      "Batch 692/700: Discriminator loss = 1.1630642414093018, GAN loss = [2.4911366, 0.8411163, 1.0332258]\n",
      "Batch 693/700: Discriminator loss = 1.1596616506576538, GAN loss = [2.391847, 0.83068067, 0.94438684]\n",
      "Batch 694/700: Discriminator loss = 1.1947085857391357, GAN loss = [2.3263824, 0.8157325, 0.8938921]\n",
      "Batch 695/700: Discriminator loss = 1.1585111618041992, GAN loss = [2.3106728, 0.8209642, 0.87296313]\n",
      "Batch 696/700: Discriminator loss = 1.1915932893753052, GAN loss = [2.2875311, 0.8077148, 0.86308897]\n",
      "Batch 697/700: Discriminator loss = 1.16404128074646, GAN loss = [2.367701, 0.8279119, 0.92309916]\n",
      "Batch 698/700: Discriminator loss = 1.1447932720184326, GAN loss = [2.3280332, 0.83087397, 0.88048804]\n",
      "Batch 699/700: Discriminator loss = 1.1893558502197266, GAN loss = [2.2828596, 0.8107815, 0.8554232]\n",
      "Batch 700/700: Discriminator loss = 1.1579668521881104, GAN loss = [2.4449713, 0.8449126, 0.9834076]\n",
      "Epoch 26/30\n",
      "Batch 1/700: Discriminator loss = 1.1618551015853882, GAN loss = [2.3312862, 0.8164672, 0.89819634]\n",
      "Batch 2/700: Discriminator loss = 1.1795032024383545, GAN loss = [2.3696554, 0.8368253, 0.91624236]\n",
      "Batch 3/700: Discriminator loss = 1.1362805366516113, GAN loss = [2.3927886, 0.84910357, 0.9271391]\n",
      "Batch 4/700: Discriminator loss = 1.1485223770141602, GAN loss = [2.4267602, 0.8596928, 0.9505855]\n",
      "Batch 5/700: Discriminator loss = 1.1234941482543945, GAN loss = [2.3575122, 0.8558707, 0.8852102]\n",
      "Batch 6/700: Discriminator loss = 1.1223385334014893, GAN loss = [2.4343362, 0.8562077, 0.9617331]\n",
      "Batch 7/700: Discriminator loss = 1.1314960718154907, GAN loss = [2.4000552, 0.8511363, 0.9325638]\n",
      "Batch 8/700: Discriminator loss = 1.11767578125, GAN loss = [2.3999074, 0.8561074, 0.92748]\n",
      "Batch 9/700: Discriminator loss = 1.1451011896133423, GAN loss = [2.5209196, 0.8410138, 1.0636376]\n",
      "Batch 10/700: Discriminator loss = 1.1229820251464844, GAN loss = [2.5492606, 0.86975116, 1.063272]\n",
      "Batch 11/700: Discriminator loss = 1.1274404525756836, GAN loss = [2.436609, 0.84632033, 0.97410333]\n",
      "Batch 12/700: Discriminator loss = 1.156593918800354, GAN loss = [2.4406765, 0.854989, 0.9695306]\n",
      "Batch 13/700: Discriminator loss = 1.142491340637207, GAN loss = [2.3866942, 0.8342308, 0.9363295]\n",
      "Batch 14/700: Discriminator loss = 1.1341875791549683, GAN loss = [2.483173, 0.84912896, 1.0179172]\n",
      "Batch 15/700: Discriminator loss = 1.133660078048706, GAN loss = [2.4929178, 0.8468956, 1.0298722]\n",
      "Batch 16/700: Discriminator loss = 1.1509417295455933, GAN loss = [2.4747603, 0.8417568, 1.0168408]\n",
      "Batch 17/700: Discriminator loss = 1.16909921169281, GAN loss = [2.4542077, 0.8319637, 1.0060829]\n",
      "Batch 18/700: Discriminator loss = 1.1473585367202759, GAN loss = [2.4268482, 0.8451574, 0.96554375]\n",
      "Batch 19/700: Discriminator loss = 1.1397711038589478, GAN loss = [2.5060656, 0.8782359, 1.0116924]\n",
      "Batch 20/700: Discriminator loss = 1.093686819076538, GAN loss = [2.5348341, 0.9074663, 1.0112472]\n",
      "Batch 21/700: Discriminator loss = 1.1626261472702026, GAN loss = [2.4062667, 0.8307345, 0.95940363]\n",
      "Batch 22/700: Discriminator loss = 1.1383531093597412, GAN loss = [2.4680855, 0.8401505, 1.0118053]\n",
      "Batch 23/700: Discriminator loss = 1.1509644985198975, GAN loss = [2.5184011, 0.8636668, 1.0385894]\n",
      "Batch 24/700: Discriminator loss = 1.1678893566131592, GAN loss = [2.418885, 0.8394397, 0.9633031]\n",
      "Batch 25/700: Discriminator loss = 1.1613069772720337, GAN loss = [2.4329424, 0.83689356, 0.9798967]\n",
      "Batch 26/700: Discriminator loss = 1.1829956769943237, GAN loss = [2.390602, 0.8237459, 0.9506576]\n",
      "Batch 27/700: Discriminator loss = 1.2246816158294678, GAN loss = [2.3943613, 0.79902476, 0.979093]\n",
      "Batch 28/700: Discriminator loss = 1.2168300151824951, GAN loss = [2.3144398, 0.8005573, 0.89758354]\n",
      "Batch 29/700: Discriminator loss = 1.187987208366394, GAN loss = [2.4343355, 0.8454124, 0.97256064]\n",
      "Batch 30/700: Discriminator loss = 1.2183680534362793, GAN loss = [2.3353555, 0.80983925, 0.9090687]\n",
      "Batch 31/700: Discriminator loss = 1.2205979824066162, GAN loss = [2.3104591, 0.80092347, 0.89303607]\n",
      "Batch 32/700: Discriminator loss = 1.2225346565246582, GAN loss = [2.3787978, 0.80145967, 0.96079355]\n",
      "Batch 33/700: Discriminator loss = 1.2011761665344238, GAN loss = [2.3334887, 0.80140555, 0.9155156]\n",
      "Batch 34/700: Discriminator loss = 1.1856966018676758, GAN loss = [2.368512, 0.8294402, 0.92248183]\n",
      "Batch 35/700: Discriminator loss = 1.184805989265442, GAN loss = [2.3232005, 0.817718, 0.88888085]\n",
      "Batch 36/700: Discriminator loss = 1.1762205362319946, GAN loss = [2.3026118, 0.83027285, 0.85571516]\n",
      "Batch 37/700: Discriminator loss = 1.2073938846588135, GAN loss = [2.2948794, 0.7981489, 0.88008475]\n",
      "Batch 38/700: Discriminator loss = 1.1913293600082397, GAN loss = [2.3135173, 0.83393824, 0.8628998]\n",
      "Batch 39/700: Discriminator loss = 1.1706053018569946, GAN loss = [2.3490717, 0.82328576, 0.9090803]\n",
      "Batch 40/700: Discriminator loss = 1.2135543823242188, GAN loss = [2.2817943, 0.7840739, 0.8810002]\n",
      "Batch 41/700: Discriminator loss = 1.1538017988204956, GAN loss = [2.3464034, 0.837646, 0.8920068]\n",
      "Batch 42/700: Discriminator loss = 1.1656007766723633, GAN loss = [2.3293374, 0.8246399, 0.8879268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 43/700: Discriminator loss = 1.1862144470214844, GAN loss = [2.2661755, 0.8142227, 0.835192]\n",
      "Batch 44/700: Discriminator loss = 1.1585246324539185, GAN loss = [2.342981, 0.8148317, 0.9113905]\n",
      "Batch 45/700: Discriminator loss = 1.15984046459198, GAN loss = [2.350882, 0.83555514, 0.8985887]\n",
      "Batch 46/700: Discriminator loss = 1.1416276693344116, GAN loss = [2.4138072, 0.83505243, 0.9620403]\n",
      "Batch 47/700: Discriminator loss = 1.1177445650100708, GAN loss = [2.4302928, 0.8636493, 0.9499684]\n",
      "Batch 48/700: Discriminator loss = 1.1425541639328003, GAN loss = [2.3634343, 0.84813356, 0.8986682]\n",
      "Batch 49/700: Discriminator loss = 1.1329749822616577, GAN loss = [2.3061092, 0.8405092, 0.8489817]\n",
      "Batch 50/700: Discriminator loss = 1.1402931213378906, GAN loss = [2.4313126, 0.84234804, 0.9723698]\n",
      "Batch 51/700: Discriminator loss = 1.1346241235733032, GAN loss = [2.4618611, 0.8415465, 1.0037163]\n",
      "Batch 52/700: Discriminator loss = 1.1268116235733032, GAN loss = [2.3995836, 0.85158885, 0.9313991]\n",
      "Batch 53/700: Discriminator loss = 1.1333614587783813, GAN loss = [2.350401, 0.8424322, 0.89137614]\n",
      "Batch 54/700: Discriminator loss = 1.1489148139953613, GAN loss = [2.3739514, 0.84689856, 0.91047454]\n",
      "Batch 55/700: Discriminator loss = 1.1220484972000122, GAN loss = [2.4774404, 0.8653676, 0.99551606]\n",
      "Batch 56/700: Discriminator loss = 1.1094441413879395, GAN loss = [2.4451947, 0.8681403, 0.9605345]\n",
      "Batch 57/700: Discriminator loss = 1.111373782157898, GAN loss = [2.5329747, 0.87291116, 1.0435779]\n",
      "Batch 58/700: Discriminator loss = 1.096793532371521, GAN loss = [2.5336998, 0.8876193, 1.0296141]\n",
      "Batch 59/700: Discriminator loss = 1.109680414199829, GAN loss = [2.5350287, 0.87561536, 1.0429899]\n",
      "Batch 60/700: Discriminator loss = 1.0933583974838257, GAN loss = [2.4934278, 0.8917759, 0.98526466]\n",
      "Batch 61/700: Discriminator loss = 1.0836621522903442, GAN loss = [2.5872972, 0.9227521, 1.0481844]\n",
      "Batch 62/700: Discriminator loss = 1.0843514204025269, GAN loss = [2.5579298, 0.9172701, 1.0243398]\n",
      "Batch 63/700: Discriminator loss = 1.0913535356521606, GAN loss = [2.5470824, 0.90604836, 1.0247412]\n",
      "Batch 64/700: Discriminator loss = 1.1086885929107666, GAN loss = [2.4634936, 0.8752525, 0.97198915]\n",
      "Batch 65/700: Discriminator loss = 1.10683012008667, GAN loss = [2.5117955, 0.8706638, 1.0249245]\n",
      "Batch 66/700: Discriminator loss = 1.0907407999038696, GAN loss = [2.5356293, 0.9104462, 1.0090209]\n",
      "Batch 67/700: Discriminator loss = 1.1101449728012085, GAN loss = [2.5131497, 0.8820719, 1.0149632]\n",
      "Batch 68/700: Discriminator loss = 1.1114411354064941, GAN loss = [2.567187, 0.8858854, 1.0652239]\n",
      "Batch 69/700: Discriminator loss = 1.1116008758544922, GAN loss = [2.4912646, 0.8784904, 0.99670047]\n",
      "Batch 70/700: Discriminator loss = 1.1388094425201416, GAN loss = [2.4294095, 0.85144395, 0.9618949]\n",
      "Batch 71/700: Discriminator loss = 1.1244691610336304, GAN loss = [2.4728103, 0.87533104, 0.9814023]\n",
      "Batch 72/700: Discriminator loss = 1.1515769958496094, GAN loss = [2.4361424, 0.87105143, 0.94902605]\n",
      "Batch 73/700: Discriminator loss = 1.1591790914535522, GAN loss = [2.478307, 0.8497248, 1.0124955]\n",
      "Batch 74/700: Discriminator loss = 1.159912347793579, GAN loss = [2.4326694, 0.8570195, 0.9595294]\n",
      "Batch 75/700: Discriminator loss = 1.172943353652954, GAN loss = [2.4446673, 0.8588794, 0.96964175]\n",
      "Batch 76/700: Discriminator loss = 1.1624675989151, GAN loss = [2.4685693, 0.8859403, 0.96644026]\n",
      "Batch 77/700: Discriminator loss = 1.1743881702423096, GAN loss = [2.42626, 0.8731509, 0.93687636]\n",
      "Batch 78/700: Discriminator loss = 1.1810742616653442, GAN loss = [2.3496416, 0.8462976, 0.887074]\n",
      "Batch 79/700: Discriminator loss = 1.2127066850662231, GAN loss = [2.4021966, 0.84737706, 0.93851966]\n",
      "Batch 80/700: Discriminator loss = 1.1912654638290405, GAN loss = [2.3593774, 0.84176743, 0.9012505]\n",
      "Batch 81/700: Discriminator loss = 1.151688575744629, GAN loss = [2.4224842, 0.8997129, 0.9063748]\n",
      "Batch 82/700: Discriminator loss = 1.179402470588684, GAN loss = [2.3711352, 0.8735422, 0.8811613]\n",
      "Batch 83/700: Discriminator loss = 1.1890279054641724, GAN loss = [2.405487, 0.83380103, 0.9552073]\n",
      "Batch 84/700: Discriminator loss = 1.138574242591858, GAN loss = [2.499227, 0.9150886, 0.96760595]\n",
      "Batch 85/700: Discriminator loss = 1.1995453834533691, GAN loss = [2.4235759, 0.8547382, 0.9522822]\n",
      "Batch 86/700: Discriminator loss = 1.1836506128311157, GAN loss = [2.4295895, 0.85921586, 0.9538179]\n",
      "Batch 87/700: Discriminator loss = 1.1821178197860718, GAN loss = [2.3943274, 0.8849562, 0.8928171]\n",
      "Batch 88/700: Discriminator loss = 1.181520938873291, GAN loss = [2.4510913, 0.9035628, 0.9309507]\n",
      "Batch 89/700: Discriminator loss = 1.1826367378234863, GAN loss = [2.4232879, 0.8456712, 0.9610416]\n",
      "Batch 90/700: Discriminator loss = 1.2065672874450684, GAN loss = [2.4051402, 0.84717745, 0.9414007]\n",
      "Batch 91/700: Discriminator loss = 1.1729490756988525, GAN loss = [2.4266558, 0.8821632, 0.9279471]\n",
      "Batch 92/700: Discriminator loss = 1.207360863685608, GAN loss = [2.3874025, 0.8359708, 0.9349224]\n",
      "Batch 93/700: Discriminator loss = 1.1457359790802002, GAN loss = [2.3929255, 0.93060845, 0.8458364]\n",
      "Batch 94/700: Discriminator loss = 1.179237723350525, GAN loss = [2.4705865, 0.89082724, 0.9632819]\n",
      "Batch 95/700: Discriminator loss = 1.1771574020385742, GAN loss = [2.4619718, 0.8921842, 0.9533249]\n",
      "Batch 96/700: Discriminator loss = 1.156376600265503, GAN loss = [2.410444, 0.8842441, 0.90975815]\n",
      "Batch 97/700: Discriminator loss = 1.1802301406860352, GAN loss = [2.3570738, 0.84753114, 0.89311844]\n",
      "Batch 98/700: Discriminator loss = 1.1736177206039429, GAN loss = [2.393907, 0.88633543, 0.89115524]\n",
      "Batch 99/700: Discriminator loss = 1.142710566520691, GAN loss = [2.4456756, 0.9031399, 0.9261158]\n",
      "Batch 100/700: Discriminator loss = 1.1762182712554932, GAN loss = [2.398049, 0.8605497, 0.9210992]\n",
      "Batch 101/700: Discriminator loss = 1.1583858728408813, GAN loss = [2.310192, 0.8654854, 0.828322]\n",
      "Batch 102/700: Discriminator loss = 1.164147973060608, GAN loss = [2.3435228, 0.86443555, 0.8627259]\n",
      "Batch 103/700: Discriminator loss = 1.1704412698745728, GAN loss = [2.415294, 0.8806098, 0.91833204]\n",
      "Batch 104/700: Discriminator loss = 1.1833876371383667, GAN loss = [2.3548932, 0.8533423, 0.8852191]\n",
      "Batch 105/700: Discriminator loss = 1.1996301412582397, GAN loss = [2.3220634, 0.8397069, 0.866019]\n",
      "Batch 106/700: Discriminator loss = 1.1283011436462402, GAN loss = [2.4763553, 0.91872734, 0.94127035]\n",
      "Batch 107/700: Discriminator loss = 1.180828332901001, GAN loss = [2.3674371, 0.851651, 0.8994742]\n",
      "Batch 108/700: Discriminator loss = 1.1649731397628784, GAN loss = [2.412108, 0.8647856, 0.93105286]\n",
      "Batch 109/700: Discriminator loss = 1.1623812913894653, GAN loss = [2.3755345, 0.8507694, 0.90854]\n",
      "Batch 110/700: Discriminator loss = 1.1451152563095093, GAN loss = [2.4114149, 0.8724738, 0.92274475]\n",
      "Batch 111/700: Discriminator loss = 1.14104163646698, GAN loss = [2.328001, 0.89639306, 0.8154465]\n",
      "Batch 112/700: Discriminator loss = 1.1429047584533691, GAN loss = [2.4371665, 0.87483764, 0.94622964]\n",
      "Batch 113/700: Discriminator loss = 1.1337617635726929, GAN loss = [2.3807747, 0.9019065, 0.86283416]\n",
      "Batch 114/700: Discriminator loss = 1.125599980354309, GAN loss = [2.4238994, 0.8784374, 0.92948866]\n",
      "Batch 115/700: Discriminator loss = 1.133269190788269, GAN loss = [2.3734012, 0.9057342, 0.85171133]\n",
      "Batch 116/700: Discriminator loss = 1.1486525535583496, GAN loss = [2.3356092, 0.87265617, 0.8470037]\n",
      "Batch 117/700: Discriminator loss = 1.143635630607605, GAN loss = [2.392795, 0.8489633, 0.9279311]\n",
      "Batch 118/700: Discriminator loss = 1.1165105104446411, GAN loss = [2.4063497, 0.8734332, 0.91709435]\n",
      "Batch 119/700: Discriminator loss = 1.1347895860671997, GAN loss = [2.354776, 0.8662817, 0.872732]\n",
      "Batch 120/700: Discriminator loss = 1.1230230331420898, GAN loss = [2.4394953, 0.87723386, 0.9465512]\n",
      "Batch 121/700: Discriminator loss = 1.1065661907196045, GAN loss = [2.4339476, 0.8783359, 0.93996376]\n",
      "Batch 122/700: Discriminator loss = 1.103991985321045, GAN loss = [2.4888682, 0.890098, 0.9831929]\n",
      "Batch 123/700: Discriminator loss = 1.1001149415969849, GAN loss = [2.5108862, 0.89959586, 0.9957773]\n",
      "Batch 124/700: Discriminator loss = 1.1217010021209717, GAN loss = [2.4278107, 0.8980259, 0.9143042]\n",
      "Batch 125/700: Discriminator loss = 1.0991849899291992, GAN loss = [2.4380147, 0.885652, 0.93691194]\n",
      "Batch 126/700: Discriminator loss = 1.111867904663086, GAN loss = [2.5754185, 0.88184136, 1.078181]\n",
      "Batch 127/700: Discriminator loss = 1.0892187356948853, GAN loss = [2.492347, 0.9119968, 0.9650026]\n",
      "Batch 128/700: Discriminator loss = 1.1003926992416382, GAN loss = [2.4432733, 0.8769734, 0.9509857]\n",
      "Batch 129/700: Discriminator loss = 1.0991655588150024, GAN loss = [2.415577, 0.8841368, 0.91617656]\n",
      "Batch 130/700: Discriminator loss = 1.1069133281707764, GAN loss = [2.4466517, 0.87229776, 0.9591272]\n",
      "Batch 131/700: Discriminator loss = 1.1169853210449219, GAN loss = [2.424109, 0.86620146, 0.9427185]\n",
      "Batch 132/700: Discriminator loss = 1.118695616722107, GAN loss = [2.4446807, 0.8554398, 0.974071]\n",
      "Batch 133/700: Discriminator loss = 1.0878022909164429, GAN loss = [2.5363636, 0.8986579, 1.0225252]\n",
      "Batch 134/700: Discriminator loss = 1.0979721546173096, GAN loss = [2.5620816, 0.8863086, 1.0606202]\n",
      "Batch 135/700: Discriminator loss = 1.1157294511795044, GAN loss = [2.4846153, 0.87755126, 0.991942]\n",
      "Batch 136/700: Discriminator loss = 1.1081396341323853, GAN loss = [2.599012, 0.90096, 1.0829461]\n",
      "Batch 137/700: Discriminator loss = 1.1082547903060913, GAN loss = [2.6025314, 0.8838327, 1.103586]\n",
      "Batch 138/700: Discriminator loss = 1.1279561519622803, GAN loss = [2.4779015, 0.8631883, 0.9995855]\n",
      "Batch 139/700: Discriminator loss = 1.1175726652145386, GAN loss = [2.4371438, 0.86923146, 0.9527962]\n",
      "Batch 140/700: Discriminator loss = 1.13419771194458, GAN loss = [2.4592876, 0.87384874, 0.9703658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 141/700: Discriminator loss = 1.1231169700622559, GAN loss = [2.584541, 0.87207323, 1.0974495]\n",
      "Batch 142/700: Discriminator loss = 1.1414076089859009, GAN loss = [2.496998, 0.86248106, 1.0195358]\n",
      "Batch 143/700: Discriminator loss = 1.1308586597442627, GAN loss = [2.5293465, 0.8892061, 1.025181]\n",
      "Batch 144/700: Discriminator loss = 1.1292434930801392, GAN loss = [2.486087, 0.8820208, 0.98908776]\n",
      "Batch 145/700: Discriminator loss = 1.1292871236801147, GAN loss = [2.4800496, 0.86454004, 1.0005233]\n",
      "Batch 146/700: Discriminator loss = 1.1250427961349487, GAN loss = [2.4560416, 0.86203665, 0.9790315]\n",
      "Batch 147/700: Discriminator loss = 1.1485700607299805, GAN loss = [2.4742196, 0.84832466, 1.0109632]\n",
      "Batch 148/700: Discriminator loss = 1.1795300245285034, GAN loss = [2.41243, 0.82359916, 0.97393936]\n",
      "Batch 149/700: Discriminator loss = 1.1818256378173828, GAN loss = [2.3798935, 0.82365257, 0.94136846]\n",
      "Batch 150/700: Discriminator loss = 1.1529208421707153, GAN loss = [2.468283, 0.8479559, 1.005471]\n",
      "Batch 151/700: Discriminator loss = 1.1592024564743042, GAN loss = [2.4246285, 0.82936555, 0.9804256]\n",
      "Batch 152/700: Discriminator loss = 1.1430214643478394, GAN loss = [2.5170324, 0.8444645, 1.0577565]\n",
      "Batch 153/700: Discriminator loss = 1.148650884628296, GAN loss = [2.4800699, 0.8401175, 1.025152]\n",
      "Batch 154/700: Discriminator loss = 1.1599007844924927, GAN loss = [2.4714966, 0.8515156, 1.0051966]\n",
      "Batch 155/700: Discriminator loss = 1.1555161476135254, GAN loss = [2.4105427, 0.85748374, 0.938291]\n",
      "Batch 156/700: Discriminator loss = 1.1594465970993042, GAN loss = [2.4630296, 0.85253555, 0.9957423]\n",
      "Batch 157/700: Discriminator loss = 1.142539381980896, GAN loss = [2.4586475, 0.8657038, 0.9782235]\n",
      "Batch 158/700: Discriminator loss = 1.1434617042541504, GAN loss = [2.3651032, 0.85834014, 0.8920467]\n",
      "Batch 159/700: Discriminator loss = 1.1548130512237549, GAN loss = [2.4058912, 0.86495507, 0.92623734]\n",
      "Batch 160/700: Discriminator loss = 1.1729388236999512, GAN loss = [2.4044309, 0.8570854, 0.93265814]\n",
      "Batch 161/700: Discriminator loss = 1.178511381149292, GAN loss = [2.3709369, 0.85307807, 0.90315384]\n",
      "Batch 162/700: Discriminator loss = 1.1698187589645386, GAN loss = [2.3948944, 0.8627436, 0.9174236]\n",
      "Batch 163/700: Discriminator loss = 1.158645510673523, GAN loss = [2.3606741, 0.856089, 0.889825]\n",
      "Batch 164/700: Discriminator loss = 1.1687239408493042, GAN loss = [2.3649786, 0.8497984, 0.9004229]\n",
      "Batch 165/700: Discriminator loss = 1.161268711090088, GAN loss = [2.358804, 0.8413209, 0.9027488]\n",
      "Batch 166/700: Discriminator loss = 1.1894086599349976, GAN loss = [2.2961566, 0.8131466, 0.86831427]\n",
      "Batch 167/700: Discriminator loss = 1.2401084899902344, GAN loss = [2.3519113, 0.7941778, 0.9430683]\n",
      "Batch 168/700: Discriminator loss = 1.1966605186462402, GAN loss = [2.4511533, 0.8275507, 1.0089251]\n",
      "Batch 169/700: Discriminator loss = 1.1773408651351929, GAN loss = [2.3280625, 0.8484807, 0.86488336]\n",
      "Batch 170/700: Discriminator loss = 1.2259891033172607, GAN loss = [2.3219593, 0.8000016, 0.90726775]\n",
      "Batch 171/700: Discriminator loss = 1.149458408355713, GAN loss = [2.3595247, 0.8842038, 0.860626]\n",
      "Batch 172/700: Discriminator loss = 1.1883866786956787, GAN loss = [2.2734075, 0.81307393, 0.8456405]\n",
      "Batch 173/700: Discriminator loss = 1.192616581916809, GAN loss = [2.3046734, 0.83251417, 0.8574818]\n",
      "Batch 174/700: Discriminator loss = 1.2374768257141113, GAN loss = [2.2853563, 0.7860182, 0.8846697]\n",
      "Batch 175/700: Discriminator loss = 1.2314932346343994, GAN loss = [2.2811944, 0.78191686, 0.88459635]\n",
      "Batch 176/700: Discriminator loss = 1.1919372081756592, GAN loss = [2.3239124, 0.81528383, 0.8939435]\n",
      "Batch 177/700: Discriminator loss = 1.1699628829956055, GAN loss = [2.2638896, 0.8315094, 0.8176913]\n",
      "Batch 178/700: Discriminator loss = 1.1985207796096802, GAN loss = [2.2500567, 0.78777826, 0.8476043]\n",
      "Batch 179/700: Discriminator loss = 1.203720211982727, GAN loss = [2.28399, 0.81694734, 0.8523882]\n",
      "Batch 180/700: Discriminator loss = 1.1841042041778564, GAN loss = [2.3598373, 0.8136933, 0.9315049]\n",
      "Batch 181/700: Discriminator loss = 1.1930269002914429, GAN loss = [2.3093681, 0.810436, 0.8843068]\n",
      "Batch 182/700: Discriminator loss = 1.1683827638626099, GAN loss = [2.2878842, 0.82475644, 0.8485263]\n",
      "Batch 183/700: Discriminator loss = 1.17628812789917, GAN loss = [2.3232894, 0.8210792, 0.88763976]\n",
      "Batch 184/700: Discriminator loss = 1.1530455350875854, GAN loss = [2.3688393, 0.8406967, 0.9136121]\n",
      "Batch 185/700: Discriminator loss = 1.1696399450302124, GAN loss = [2.3420773, 0.8351279, 0.8924414]\n",
      "Batch 186/700: Discriminator loss = 1.179274320602417, GAN loss = [2.3084857, 0.8146704, 0.879316]\n",
      "Batch 187/700: Discriminator loss = 1.169106125831604, GAN loss = [2.3579972, 0.8313587, 0.91215575]\n",
      "Batch 188/700: Discriminator loss = 1.1710878610610962, GAN loss = [2.3051934, 0.8178222, 0.87291354]\n",
      "Batch 189/700: Discriminator loss = 1.1352213621139526, GAN loss = [2.369978, 0.8506946, 0.90485173]\n",
      "Batch 190/700: Discriminator loss = 1.1588938236236572, GAN loss = [2.4304576, 0.81580615, 1.0002656]\n",
      "Batch 191/700: Discriminator loss = 1.1456050872802734, GAN loss = [2.4037182, 0.83352685, 0.9558504]\n",
      "Batch 192/700: Discriminator loss = 1.1603022813796997, GAN loss = [2.30772, 0.8168758, 0.87655085]\n",
      "Batch 193/700: Discriminator loss = 1.1527082920074463, GAN loss = [2.2799196, 0.8152544, 0.85041434]\n",
      "Batch 194/700: Discriminator loss = 1.1710631847381592, GAN loss = [2.2959547, 0.7976056, 0.8841638]\n",
      "Batch 195/700: Discriminator loss = 1.1431149244308472, GAN loss = [2.3026114, 0.8283757, 0.86012787]\n",
      "Batch 196/700: Discriminator loss = 1.161870002746582, GAN loss = [2.3300745, 0.8174566, 0.8985863]\n",
      "Batch 197/700: Discriminator loss = 1.1644715070724487, GAN loss = [2.3505175, 0.8202995, 0.9162565]\n",
      "Batch 198/700: Discriminator loss = 1.1599860191345215, GAN loss = [2.303218, 0.8254801, 0.8638002]\n",
      "Batch 199/700: Discriminator loss = 1.176504373550415, GAN loss = [2.3371437, 0.8016264, 0.92160845]\n",
      "Batch 200/700: Discriminator loss = 1.1663342714309692, GAN loss = [2.3366888, 0.82093996, 0.9018624]\n",
      "Batch 201/700: Discriminator loss = 1.1610922813415527, GAN loss = [2.2763097, 0.8164344, 0.84601426]\n",
      "Batch 202/700: Discriminator loss = 1.1573113203048706, GAN loss = [2.3138103, 0.840534, 0.8594407]\n",
      "Batch 203/700: Discriminator loss = 1.1554042100906372, GAN loss = [2.3426623, 0.838399, 0.8904519]\n",
      "Batch 204/700: Discriminator loss = 1.1513075828552246, GAN loss = [2.4014926, 0.8638036, 0.9239041]\n",
      "Batch 205/700: Discriminator loss = 1.1582841873168945, GAN loss = [2.358907, 0.8290834, 0.9160611]\n",
      "Batch 206/700: Discriminator loss = 1.1409025192260742, GAN loss = [2.388239, 0.8522699, 0.922249]\n",
      "Batch 207/700: Discriminator loss = 1.1714510917663574, GAN loss = [2.2932422, 0.8063836, 0.87317556]\n",
      "Batch 208/700: Discriminator loss = 1.1508979797363281, GAN loss = [2.3473945, 0.8306773, 0.9030562]\n",
      "Batch 209/700: Discriminator loss = 1.1514242887496948, GAN loss = [2.35648, 0.83635676, 0.90645844]\n",
      "Batch 210/700: Discriminator loss = 1.1594066619873047, GAN loss = [2.3334594, 0.82701564, 0.89280915]\n",
      "Batch 211/700: Discriminator loss = 1.1613502502441406, GAN loss = [2.3160546, 0.82195383, 0.8804632]\n",
      "Batch 212/700: Discriminator loss = 1.1805611848831177, GAN loss = [2.3040926, 0.82050425, 0.86994094]\n",
      "Batch 213/700: Discriminator loss = 1.1612882614135742, GAN loss = [2.3481197, 0.8225844, 0.9118836]\n",
      "Batch 214/700: Discriminator loss = 1.1595547199249268, GAN loss = [2.3499234, 0.8195243, 0.91675985]\n",
      "Batch 215/700: Discriminator loss = 1.148018479347229, GAN loss = [2.3806329, 0.8322836, 0.934708]\n",
      "Batch 216/700: Discriminator loss = 1.154030680656433, GAN loss = [2.311279, 0.82222307, 0.87540936]\n",
      "Batch 217/700: Discriminator loss = 1.1508363485336304, GAN loss = [2.3058174, 0.8219814, 0.87019104]\n",
      "Batch 218/700: Discriminator loss = 1.1680536270141602, GAN loss = [2.2991574, 0.8221896, 0.8633219]\n",
      "Batch 219/700: Discriminator loss = 1.1529772281646729, GAN loss = [2.308729, 0.82708365, 0.8680002]\n",
      "Batch 220/700: Discriminator loss = 1.175401210784912, GAN loss = [2.2396412, 0.797284, 0.8287149]\n",
      "Batch 221/700: Discriminator loss = 1.1530842781066895, GAN loss = [2.3020194, 0.8240041, 0.8643635]\n",
      "Batch 222/700: Discriminator loss = 1.1573420763015747, GAN loss = [2.3620224, 0.8190544, 0.9293242]\n",
      "Batch 223/700: Discriminator loss = 1.1556222438812256, GAN loss = [2.3510687, 0.8293561, 0.9080648]\n",
      "Batch 224/700: Discriminator loss = 1.1392170190811157, GAN loss = [2.334628, 0.83452034, 0.88646555]\n",
      "Batch 225/700: Discriminator loss = 1.1493587493896484, GAN loss = [2.306226, 0.82451093, 0.86806184]\n",
      "Batch 226/700: Discriminator loss = 1.1499834060668945, GAN loss = [2.2885973, 0.84030145, 0.83464986]\n",
      "Batch 227/700: Discriminator loss = 1.1670377254486084, GAN loss = [2.3113225, 0.8177289, 0.8799431]\n",
      "Batch 228/700: Discriminator loss = 1.143944263458252, GAN loss = [2.345732, 0.8253093, 0.90677714]\n",
      "Batch 229/700: Discriminator loss = 1.1396005153656006, GAN loss = [2.3757176, 0.8324346, 0.92964804]\n",
      "Batch 230/700: Discriminator loss = 1.135316252708435, GAN loss = [2.374724, 0.8409987, 0.9200854]\n",
      "Batch 231/700: Discriminator loss = 1.152103304862976, GAN loss = [2.2927296, 0.825548, 0.8535315]\n",
      "Batch 232/700: Discriminator loss = 1.1452075242996216, GAN loss = [2.301623, 0.8136134, 0.87435776]\n",
      "Batch 233/700: Discriminator loss = 1.1397135257720947, GAN loss = [2.349681, 0.8338616, 0.90218765]\n",
      "Batch 234/700: Discriminator loss = 1.1444153785705566, GAN loss = [2.3136935, 0.8224724, 0.87760293]\n",
      "Batch 235/700: Discriminator loss = 1.1367493867874146, GAN loss = [2.3485441, 0.8222093, 0.9127276]\n",
      "Batch 236/700: Discriminator loss = 1.1320592164993286, GAN loss = [2.3464427, 0.83435607, 0.8984863]\n",
      "Batch 237/700: Discriminator loss = 1.145157814025879, GAN loss = [2.3494139, 0.8322802, 0.9035423]\n",
      "Batch 238/700: Discriminator loss = 1.1721739768981934, GAN loss = [2.267178, 0.7974415, 0.8561739]\n",
      "Batch 239/700: Discriminator loss = 1.1483452320098877, GAN loss = [2.3612995, 0.81746995, 0.9302753]\n",
      "Batch 240/700: Discriminator loss = 1.156865119934082, GAN loss = [2.310583, 0.8147082, 0.88231856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 241/700: Discriminator loss = 1.1466622352600098, GAN loss = [2.306725, 0.80686736, 0.88628554]\n",
      "Batch 242/700: Discriminator loss = 1.148675560951233, GAN loss = [2.3847773, 0.83280593, 0.93839777]\n",
      "Batch 243/700: Discriminator loss = 1.161068320274353, GAN loss = [2.2840493, 0.80791825, 0.8625756]\n",
      "Batch 244/700: Discriminator loss = 1.1737394332885742, GAN loss = [2.2764387, 0.7884259, 0.8744845]\n",
      "Batch 245/700: Discriminator loss = 1.1640204191207886, GAN loss = [2.3670864, 0.7958323, 0.9577349]\n",
      "Batch 246/700: Discriminator loss = 1.1730481386184692, GAN loss = [2.3479664, 0.807676, 0.9267772]\n",
      "Batch 247/700: Discriminator loss = 1.1634442806243896, GAN loss = [2.3085961, 0.80018735, 0.89488393]\n",
      "Batch 248/700: Discriminator loss = 1.159724235534668, GAN loss = [2.3682835, 0.79979765, 0.9549659]\n",
      "Batch 249/700: Discriminator loss = 1.1469076871871948, GAN loss = [2.3340516, 0.8236029, 0.89696634]\n",
      "Batch 250/700: Discriminator loss = 1.1424182653427124, GAN loss = [2.430587, 0.8193146, 0.9977942]\n",
      "Batch 251/700: Discriminator loss = 1.155302882194519, GAN loss = [2.3766754, 0.81779826, 0.94539285]\n",
      "Batch 252/700: Discriminator loss = 1.166906714439392, GAN loss = [2.3671322, 0.8300517, 0.92357606]\n",
      "Batch 253/700: Discriminator loss = 1.1696327924728394, GAN loss = [2.350882, 0.8455732, 0.8917812]\n",
      "Batch 254/700: Discriminator loss = 1.1686012744903564, GAN loss = [2.3343086, 0.836972, 0.88377786]\n",
      "Batch 255/700: Discriminator loss = 1.1937683820724487, GAN loss = [2.2693927, 0.79561675, 0.8601797]\n",
      "Batch 256/700: Discriminator loss = 1.1515086889266968, GAN loss = [2.3982017, 0.83049226, 0.9540898]\n",
      "Batch 257/700: Discriminator loss = 1.1616299152374268, GAN loss = [2.4382565, 0.85586977, 0.96874]\n",
      "Batch 258/700: Discriminator loss = 1.1966685056686401, GAN loss = [2.268986, 0.7992417, 0.85603213]\n",
      "Batch 259/700: Discriminator loss = 1.181235671043396, GAN loss = [2.4007561, 0.8116091, 0.97537404]\n",
      "Batch 260/700: Discriminator loss = 1.172435998916626, GAN loss = [2.3552465, 0.8335715, 0.90785766]\n",
      "Batch 261/700: Discriminator loss = 1.1743618249893188, GAN loss = [2.353325, 0.82449234, 0.9149692]\n",
      "Batch 262/700: Discriminator loss = 1.1555217504501343, GAN loss = [2.3735905, 0.8312352, 0.92846864]\n",
      "Batch 263/700: Discriminator loss = 1.1896082162857056, GAN loss = [2.3585474, 0.79522055, 0.94940084]\n",
      "Batch 264/700: Discriminator loss = 1.1708139181137085, GAN loss = [2.3593268, 0.8177551, 0.92760503]\n",
      "Batch 265/700: Discriminator loss = 1.1543526649475098, GAN loss = [2.326791, 0.8244912, 0.88829887]\n",
      "Batch 266/700: Discriminator loss = 1.1677734851837158, GAN loss = [2.3258057, 0.8293554, 0.8824275]\n",
      "Batch 267/700: Discriminator loss = 1.1638981103897095, GAN loss = [2.3502638, 0.8128501, 0.9233343]\n",
      "Batch 268/700: Discriminator loss = 1.1756527423858643, GAN loss = [2.3514917, 0.83576185, 0.9016133]\n",
      "Batch 269/700: Discriminator loss = 1.1504594087600708, GAN loss = [2.3763168, 0.89165956, 0.8704992]\n",
      "Batch 270/700: Discriminator loss = 1.1694931983947754, GAN loss = [2.3240218, 0.83724284, 0.87259614]\n",
      "Batch 271/700: Discriminator loss = 1.1719666719436646, GAN loss = [2.3034842, 0.8307632, 0.8585318]\n",
      "Batch 272/700: Discriminator loss = 1.1822702884674072, GAN loss = [2.3345144, 0.8346665, 0.8856404]\n",
      "Batch 273/700: Discriminator loss = 1.1434931755065918, GAN loss = [2.3854978, 0.84341085, 0.9278665]\n",
      "Batch 274/700: Discriminator loss = 1.16842520236969, GAN loss = [2.321462, 0.8328013, 0.8744199]\n",
      "Batch 275/700: Discriminator loss = 1.1538203954696655, GAN loss = [2.4342206, 0.8597136, 0.9602437]\n",
      "Batch 276/700: Discriminator loss = 1.1471748352050781, GAN loss = [2.4272783, 0.83889246, 0.9740672]\n",
      "Batch 277/700: Discriminator loss = 1.168157935142517, GAN loss = [2.433887, 0.86163926, 0.9578912]\n",
      "Batch 278/700: Discriminator loss = 1.1632598638534546, GAN loss = [2.3544483, 0.8437301, 0.89632165]\n",
      "Batch 279/700: Discriminator loss = 1.207397699356079, GAN loss = [2.325538, 0.81263626, 0.89847404]\n",
      "Batch 280/700: Discriminator loss = 1.1252634525299072, GAN loss = [2.4290285, 0.8792945, 0.935263]\n",
      "Batch 281/700: Discriminator loss = 1.1309847831726074, GAN loss = [2.4351156, 0.85301626, 0.9675764]\n",
      "Batch 282/700: Discriminator loss = 1.1624387502670288, GAN loss = [2.3495688, 0.848259, 0.88673913]\n",
      "Batch 283/700: Discriminator loss = 1.1522178649902344, GAN loss = [2.3273168, 0.8398362, 0.8728764]\n",
      "Batch 284/700: Discriminator loss = 1.1570203304290771, GAN loss = [2.324103, 0.8298489, 0.87963176]\n",
      "Batch 285/700: Discriminator loss = 1.1567707061767578, GAN loss = [2.3829093, 0.8507867, 0.9174961]\n",
      "Batch 286/700: Discriminator loss = 1.146009922027588, GAN loss = [2.4372594, 0.85246885, 0.97015166]\n",
      "Batch 287/700: Discriminator loss = 1.1515493392944336, GAN loss = [2.3697307, 0.84321123, 0.91185164]\n",
      "Batch 288/700: Discriminator loss = 1.176401138305664, GAN loss = [2.4425676, 0.8289001, 0.9989933]\n",
      "Batch 289/700: Discriminator loss = 1.1364550590515137, GAN loss = [2.479121, 0.8625731, 1.0018765]\n",
      "Batch 290/700: Discriminator loss = 1.1617830991744995, GAN loss = [2.4007657, 0.8512036, 0.9348777]\n",
      "Batch 291/700: Discriminator loss = 1.1346614360809326, GAN loss = [2.4789028, 0.87480026, 0.9894177]\n",
      "Batch 292/700: Discriminator loss = 1.1324280500411987, GAN loss = [2.4795363, 0.900919, 0.9639431]\n",
      "Batch 293/700: Discriminator loss = 1.1549272537231445, GAN loss = [2.4304903, 0.8511379, 0.9646645]\n",
      "Batch 294/700: Discriminator loss = 1.1296169757843018, GAN loss = [2.339262, 0.8636936, 0.8608734]\n",
      "Batch 295/700: Discriminator loss = 1.1591041088104248, GAN loss = [2.3849628, 0.8348333, 0.93543315]\n",
      "Batch 296/700: Discriminator loss = 1.161337971687317, GAN loss = [2.4539585, 0.87157226, 0.9676954]\n",
      "Batch 297/700: Discriminator loss = 1.1527575254440308, GAN loss = [2.4868684, 0.8347644, 1.0374266]\n",
      "Batch 298/700: Discriminator loss = 1.1341661214828491, GAN loss = [2.4385371, 0.85872644, 0.9651125]\n",
      "Batch 299/700: Discriminator loss = 1.1392184495925903, GAN loss = [2.4737175, 0.86171234, 0.99732125]\n",
      "Batch 300/700: Discriminator loss = 1.1538165807724, GAN loss = [2.5537105, 0.8699924, 1.0690476]\n",
      "Batch 301/700: Discriminator loss = 1.1229227781295776, GAN loss = [2.510302, 0.88608724, 1.0095189]\n",
      "Batch 302/700: Discriminator loss = 1.1313486099243164, GAN loss = [2.4328473, 0.8847859, 0.93334633]\n",
      "Batch 303/700: Discriminator loss = 1.130735158920288, GAN loss = [2.5539067, 0.8657949, 1.073396]\n",
      "Batch 304/700: Discriminator loss = 1.1381187438964844, GAN loss = [2.487396, 0.86725307, 1.0054325]\n",
      "Batch 305/700: Discriminator loss = 1.1431105136871338, GAN loss = [2.39763, 0.8531394, 0.92977816]\n",
      "Batch 306/700: Discriminator loss = 1.1147055625915527, GAN loss = [2.4722853, 0.877951, 0.97960144]\n",
      "Batch 307/700: Discriminator loss = 1.1198482513427734, GAN loss = [2.4578664, 0.8688403, 0.9742647]\n",
      "Batch 308/700: Discriminator loss = 1.1183050870895386, GAN loss = [2.5001545, 0.88025755, 1.0051146]\n",
      "Batch 309/700: Discriminator loss = 1.130271077156067, GAN loss = [2.4348688, 0.86022305, 0.9598204]\n",
      "Batch 310/700: Discriminator loss = 1.123342752456665, GAN loss = [2.4524508, 0.8784047, 0.95920885]\n",
      "Batch 311/700: Discriminator loss = 1.1419342756271362, GAN loss = [2.5045707, 0.8811654, 1.0085489]\n",
      "Batch 312/700: Discriminator loss = 1.1369588375091553, GAN loss = [2.421202, 0.86316496, 0.9431579]\n",
      "Batch 313/700: Discriminator loss = 1.1320991516113281, GAN loss = [2.4890742, 0.8889236, 0.9852278]\n",
      "Batch 314/700: Discriminator loss = 1.1400890350341797, GAN loss = [2.4573514, 0.8582016, 0.9841791]\n",
      "Batch 315/700: Discriminator loss = 1.1651320457458496, GAN loss = [2.4604714, 0.8729254, 0.9725654]\n",
      "Batch 316/700: Discriminator loss = 1.1480666399002075, GAN loss = [2.4926245, 0.85978997, 1.0178758]\n",
      "Batch 317/700: Discriminator loss = 1.1271944046020508, GAN loss = [2.5252, 0.89497393, 1.0152797]\n",
      "Batch 318/700: Discriminator loss = 1.1151201725006104, GAN loss = [2.5341425, 0.89557725, 1.023628]\n",
      "Batch 319/700: Discriminator loss = 1.1356242895126343, GAN loss = [2.5126312, 0.8832509, 1.0144255]\n",
      "Batch 320/700: Discriminator loss = 1.1264100074768066, GAN loss = [2.4647067, 0.86029816, 0.9894373]\n",
      "Batch 321/700: Discriminator loss = 1.1524931192398071, GAN loss = [2.4768186, 0.837293, 1.0245829]\n",
      "Batch 322/700: Discriminator loss = 1.1518621444702148, GAN loss = [2.4401755, 0.8414142, 0.9838237]\n",
      "Batch 323/700: Discriminator loss = 1.1302403211593628, GAN loss = [2.5415761, 0.8746036, 1.0520283]\n",
      "Batch 324/700: Discriminator loss = 1.1192691326141357, GAN loss = [2.528618, 0.896884, 1.0167928]\n",
      "Batch 325/700: Discriminator loss = 1.1592028141021729, GAN loss = [2.4557838, 0.8501307, 0.99071807]\n",
      "Batch 326/700: Discriminator loss = 1.122483730316162, GAN loss = [2.4605753, 0.87655014, 0.96909577]\n",
      "Batch 327/700: Discriminator loss = 1.1428601741790771, GAN loss = [2.5261161, 0.8707128, 1.040492]\n",
      "Batch 328/700: Discriminator loss = 1.1078826189041138, GAN loss = [2.5620575, 0.91600305, 1.0311749]\n",
      "Batch 329/700: Discriminator loss = 1.1367201805114746, GAN loss = [2.5478146, 0.8858852, 1.0470906]\n",
      "Batch 330/700: Discriminator loss = 1.1393887996673584, GAN loss = [2.4495754, 0.8855853, 0.9491864]\n",
      "Batch 331/700: Discriminator loss = 1.1382962465286255, GAN loss = [2.5819192, 0.89932704, 1.0678142]\n",
      "Batch 332/700: Discriminator loss = 1.1180492639541626, GAN loss = [2.4692106, 0.907648, 0.9468048]\n",
      "Batch 333/700: Discriminator loss = 1.1257381439208984, GAN loss = [2.4902546, 0.8855308, 0.98998964]\n",
      "Batch 334/700: Discriminator loss = 1.1309419870376587, GAN loss = [2.527728, 0.90578187, 1.0072676]\n",
      "Batch 335/700: Discriminator loss = 1.117194414138794, GAN loss = [2.5249403, 0.9221009, 0.9882044]\n",
      "Batch 336/700: Discriminator loss = 1.1213340759277344, GAN loss = [2.5645843, 0.9308235, 1.0191631]\n",
      "Batch 337/700: Discriminator loss = 1.1373965740203857, GAN loss = [2.4671922, 0.9050321, 0.94760805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 338/700: Discriminator loss = 1.1524690389633179, GAN loss = [2.4892375, 0.8817545, 0.9929712]\n",
      "Batch 339/700: Discriminator loss = 1.1458534002304077, GAN loss = [2.400459, 0.91201574, 0.8739384]\n",
      "Batch 340/700: Discriminator loss = 1.1639840602874756, GAN loss = [2.424143, 0.87279695, 0.93684614]\n",
      "Batch 341/700: Discriminator loss = 1.1596031188964844, GAN loss = [2.4381773, 0.8818902, 0.9417978]\n",
      "Batch 342/700: Discriminator loss = 1.133442759513855, GAN loss = [2.4609888, 0.91878587, 0.92775]\n",
      "Batch 343/700: Discriminator loss = 1.1229650974273682, GAN loss = [2.4308305, 0.8983203, 0.9180995]\n",
      "Batch 344/700: Discriminator loss = 1.1257827281951904, GAN loss = [2.4294918, 0.8974291, 0.9177169]\n",
      "Batch 345/700: Discriminator loss = 1.1167638301849365, GAN loss = [2.3953547, 0.8978375, 0.88324666]\n",
      "Batch 346/700: Discriminator loss = 1.141191005706787, GAN loss = [2.409218, 0.89785856, 0.8971641]\n",
      "Batch 347/700: Discriminator loss = 1.1291472911834717, GAN loss = [2.463519, 0.88909566, 0.96031684]\n",
      "Batch 348/700: Discriminator loss = 1.104773759841919, GAN loss = [2.463885, 0.91928947, 0.93055725]\n",
      "Batch 349/700: Discriminator loss = 1.139846682548523, GAN loss = [2.4567966, 0.8718011, 0.97101176]\n",
      "Batch 350/700: Discriminator loss = 1.1579610109329224, GAN loss = [2.5268257, 0.8627952, 1.0500866]\n",
      "Batch 351/700: Discriminator loss = 1.1264376640319824, GAN loss = [2.5257828, 0.9040225, 1.0078549]\n",
      "Batch 352/700: Discriminator loss = 1.1361418962478638, GAN loss = [2.418764, 0.8815951, 0.92328244]\n",
      "Batch 353/700: Discriminator loss = 1.1546558141708374, GAN loss = [2.4055853, 0.8629879, 0.9287376]\n",
      "Batch 354/700: Discriminator loss = 1.1456695795059204, GAN loss = [2.3355389, 0.87211776, 0.8495821]\n",
      "Batch 355/700: Discriminator loss = 1.1085559129714966, GAN loss = [2.4975061, 0.9061393, 0.97753316]\n",
      "Batch 356/700: Discriminator loss = 1.164254069328308, GAN loss = [2.4435635, 0.84700006, 0.98273337]\n",
      "Batch 357/700: Discriminator loss = 1.1719484329223633, GAN loss = [2.422183, 0.8529545, 0.95540076]\n",
      "Batch 358/700: Discriminator loss = 1.1454100608825684, GAN loss = [2.4187148, 0.8827478, 0.9221505]\n",
      "Batch 359/700: Discriminator loss = 1.162424921989441, GAN loss = [2.3980653, 0.86492735, 0.9193045]\n",
      "Batch 360/700: Discriminator loss = 1.1963797807693481, GAN loss = [2.3959029, 0.87091845, 0.91113836]\n",
      "Batch 361/700: Discriminator loss = 1.1567434072494507, GAN loss = [2.429031, 0.89320207, 0.9219551]\n",
      "Batch 362/700: Discriminator loss = 1.1243375539779663, GAN loss = [2.4255052, 0.90840834, 0.9031866]\n",
      "Batch 363/700: Discriminator loss = 1.14248526096344, GAN loss = [2.3873315, 0.88924086, 0.88415986]\n",
      "Batch 364/700: Discriminator loss = 1.1513127088546753, GAN loss = [2.3531075, 0.86852264, 0.8706676]\n",
      "Batch 365/700: Discriminator loss = 1.1691572666168213, GAN loss = [2.4029815, 0.88546747, 0.9035907]\n",
      "Batch 366/700: Discriminator loss = 1.152753472328186, GAN loss = [2.4246955, 0.881731, 0.9290483]\n",
      "Batch 367/700: Discriminator loss = 1.140542984008789, GAN loss = [2.409677, 0.87370515, 0.92207474]\n",
      "Batch 368/700: Discriminator loss = 1.1418323516845703, GAN loss = [2.4019663, 0.8588524, 0.92924285]\n",
      "Batch 369/700: Discriminator loss = 1.1607195138931274, GAN loss = [2.325384, 0.8492762, 0.86227036]\n",
      "Batch 370/700: Discriminator loss = 1.1655975580215454, GAN loss = [2.347657, 0.84745604, 0.8863816]\n",
      "Batch 371/700: Discriminator loss = 1.1550463438034058, GAN loss = [2.3298995, 0.8572039, 0.8588712]\n",
      "Batch 372/700: Discriminator loss = 1.1687569618225098, GAN loss = [2.366068, 0.8470808, 0.9051568]\n",
      "Batch 373/700: Discriminator loss = 1.1917154788970947, GAN loss = [2.3507981, 0.8548876, 0.8820588]\n",
      "Batch 374/700: Discriminator loss = 1.180375337600708, GAN loss = [2.352054, 0.824822, 0.91336477]\n",
      "Batch 375/700: Discriminator loss = 1.1698800325393677, GAN loss = [2.3993974, 0.85248345, 0.9330403]\n",
      "Batch 376/700: Discriminator loss = 1.1904990673065186, GAN loss = [2.3545818, 0.8605146, 0.88016456]\n",
      "Batch 377/700: Discriminator loss = 1.1703910827636719, GAN loss = [2.3486755, 0.84157073, 0.8931506]\n",
      "Batch 378/700: Discriminator loss = 1.1909738779067993, GAN loss = [2.3717115, 0.8503241, 0.90743804]\n",
      "Batch 379/700: Discriminator loss = 1.1963237524032593, GAN loss = [2.306635, 0.8282932, 0.86439097]\n",
      "Batch 380/700: Discriminator loss = 1.1624902486801147, GAN loss = [2.3733506, 0.8744137, 0.8849719]\n",
      "Batch 381/700: Discriminator loss = 1.1715096235275269, GAN loss = [2.3661304, 0.85088575, 0.9012623]\n",
      "Batch 382/700: Discriminator loss = 1.2237979173660278, GAN loss = [2.2990599, 0.80795854, 0.8771229]\n",
      "Batch 383/700: Discriminator loss = 1.200886845588684, GAN loss = [2.3698852, 0.80924934, 0.9466528]\n",
      "Batch 384/700: Discriminator loss = 1.1992521286010742, GAN loss = [2.2829578, 0.8162005, 0.85276526]\n",
      "Batch 385/700: Discriminator loss = 1.1704621315002441, GAN loss = [2.373484, 0.82876414, 0.9307197]\n",
      "Batch 386/700: Discriminator loss = 1.1756316423416138, GAN loss = [2.381013, 0.8161139, 0.95090437]\n",
      "Batch 387/700: Discriminator loss = 1.1425799131393433, GAN loss = [2.4000819, 0.8572081, 0.92890984]\n",
      "Batch 388/700: Discriminator loss = 1.1629705429077148, GAN loss = [2.3376665, 0.82877195, 0.89497536]\n",
      "Batch 389/700: Discriminator loss = 1.1615078449249268, GAN loss = [2.4099488, 0.832825, 0.96324813]\n",
      "Batch 390/700: Discriminator loss = 1.1462160348892212, GAN loss = [2.4012742, 0.85551727, 0.93191755]\n",
      "Batch 391/700: Discriminator loss = 1.1249254941940308, GAN loss = [2.433499, 0.8720365, 0.9476519]\n",
      "Batch 392/700: Discriminator loss = 1.1281790733337402, GAN loss = [2.4268968, 0.89865714, 0.91447777]\n",
      "Batch 393/700: Discriminator loss = 1.1207969188690186, GAN loss = [2.4075897, 0.889801, 0.904069]\n",
      "Batch 394/700: Discriminator loss = 1.1633257865905762, GAN loss = [2.438253, 0.83113426, 0.9934499]\n",
      "Batch 395/700: Discriminator loss = 1.1698477268218994, GAN loss = [2.5029914, 0.8923815, 0.9969823]\n",
      "Batch 396/700: Discriminator loss = 1.1706920862197876, GAN loss = [2.4058957, 0.86687547, 0.92540634]\n",
      "Batch 397/700: Discriminator loss = 1.1587857007980347, GAN loss = [2.4159005, 0.84156764, 0.9607443]\n",
      "Batch 398/700: Discriminator loss = 1.1594010591506958, GAN loss = [2.4398246, 0.8440865, 0.9821666]\n",
      "Batch 399/700: Discriminator loss = 1.1728523969650269, GAN loss = [2.4149597, 0.8704825, 0.930925]\n",
      "Batch 400/700: Discriminator loss = 1.1395580768585205, GAN loss = [2.484721, 0.8782045, 0.9929846]\n",
      "Batch 401/700: Discriminator loss = 1.1130656003952026, GAN loss = [2.4846766, 0.8936895, 0.9774811]\n",
      "Batch 402/700: Discriminator loss = 1.1364768743515015, GAN loss = [2.4080915, 0.8857719, 0.9088223]\n",
      "Batch 403/700: Discriminator loss = 1.1437369585037231, GAN loss = [2.4723902, 0.8737878, 0.98508716]\n",
      "Batch 404/700: Discriminator loss = 1.1415272951126099, GAN loss = [2.4680438, 0.85541075, 0.999107]\n",
      "Batch 405/700: Discriminator loss = 1.1345621347427368, GAN loss = [2.4823408, 0.8896872, 0.97912383]\n",
      "Batch 406/700: Discriminator loss = 1.1864510774612427, GAN loss = [2.4686365, 0.8485767, 1.0064992]\n",
      "Batch 407/700: Discriminator loss = 1.166821837425232, GAN loss = [2.4211192, 0.87304306, 0.93447936]\n",
      "Batch 408/700: Discriminator loss = 1.1413822174072266, GAN loss = [2.498044, 0.9019307, 0.9824973]\n",
      "Batch 409/700: Discriminator loss = 1.1590054035186768, GAN loss = [2.4189744, 0.85452354, 0.95081]\n",
      "Batch 410/700: Discriminator loss = 1.1395719051361084, GAN loss = [2.4738166, 0.89026535, 0.9698925]\n",
      "Batch 411/700: Discriminator loss = 1.165237545967102, GAN loss = [2.4006152, 0.876524, 0.91041446]\n",
      "Batch 412/700: Discriminator loss = 1.179362177848816, GAN loss = [2.386605, 0.84670115, 0.9262237]\n",
      "Batch 413/700: Discriminator loss = 1.1750227212905884, GAN loss = [2.3455238, 0.8586162, 0.8732389]\n",
      "Batch 414/700: Discriminator loss = 1.144417643547058, GAN loss = [2.4600675, 0.8774335, 0.9689648]\n",
      "Batch 415/700: Discriminator loss = 1.1832786798477173, GAN loss = [2.4427733, 0.85364395, 0.97546935]\n",
      "Batch 416/700: Discriminator loss = 1.159289836883545, GAN loss = [2.417011, 0.8686371, 0.9347112]\n",
      "Batch 417/700: Discriminator loss = 1.192936897277832, GAN loss = [2.3699093, 0.8261274, 0.93008345]\n",
      "Batch 418/700: Discriminator loss = 1.1779146194458008, GAN loss = [2.4148178, 0.85462487, 0.9464269]\n",
      "Batch 419/700: Discriminator loss = 1.2386513948440552, GAN loss = [2.3718836, 0.8205635, 0.93748695]\n",
      "Batch 420/700: Discriminator loss = 1.2000945806503296, GAN loss = [2.3575733, 0.86068636, 0.88299376]\n",
      "Batch 421/700: Discriminator loss = 1.166813850402832, GAN loss = [2.378222, 0.8824356, 0.88186955]\n",
      "Batch 422/700: Discriminator loss = 1.2085374593734741, GAN loss = [2.317621, 0.82866776, 0.8750439]\n",
      "Batch 423/700: Discriminator loss = 1.1699492931365967, GAN loss = [2.379182, 0.8707807, 0.89450353]\n",
      "Batch 424/700: Discriminator loss = 1.197095513343811, GAN loss = [2.3456626, 0.82758576, 0.90421426]\n",
      "Batch 425/700: Discriminator loss = 1.1960641145706177, GAN loss = [2.400247, 0.8809897, 0.9054194]\n",
      "Batch 426/700: Discriminator loss = 1.163453459739685, GAN loss = [2.3709857, 0.84570885, 0.9114453]\n",
      "Batch 427/700: Discriminator loss = 1.1734750270843506, GAN loss = [2.3672113, 0.88067, 0.87272376]\n",
      "Batch 428/700: Discriminator loss = 1.1658594608306885, GAN loss = [2.359526, 0.8690945, 0.8766277]\n",
      "Batch 429/700: Discriminator loss = 1.2099974155426025, GAN loss = [2.3094249, 0.8248883, 0.8707445]\n",
      "Batch 430/700: Discriminator loss = 1.1619234085083008, GAN loss = [2.3938966, 0.8540921, 0.9260233]\n",
      "Batch 431/700: Discriminator loss = 1.1519181728363037, GAN loss = [2.381687, 0.8735943, 0.89432883]\n",
      "Batch 432/700: Discriminator loss = 1.1491621732711792, GAN loss = [2.42721, 0.8827024, 0.9307735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 433/700: Discriminator loss = 1.1802427768707275, GAN loss = [2.3380485, 0.8390651, 0.8852643]\n",
      "Batch 434/700: Discriminator loss = 1.1843452453613281, GAN loss = [2.3401709, 0.83193636, 0.8945365]\n",
      "Batch 435/700: Discriminator loss = 1.1573373079299927, GAN loss = [2.3580494, 0.86086273, 0.8835123]\n",
      "Batch 436/700: Discriminator loss = 1.1637072563171387, GAN loss = [2.3635342, 0.84616876, 0.90370697]\n",
      "Batch 437/700: Discriminator loss = 1.1628210544586182, GAN loss = [2.3481414, 0.8484729, 0.88602096]\n",
      "Batch 438/700: Discriminator loss = 1.1566916704177856, GAN loss = [2.4470654, 0.85286677, 0.98056895]\n",
      "Batch 439/700: Discriminator loss = 1.1735056638717651, GAN loss = [2.3569975, 0.8277435, 0.9156446]\n",
      "Batch 440/700: Discriminator loss = 1.1603611707687378, GAN loss = [2.3290024, 0.8385167, 0.87687635]\n",
      "Batch 441/700: Discriminator loss = 1.1615328788757324, GAN loss = [2.3834045, 0.83878225, 0.9310278]\n",
      "Batch 442/700: Discriminator loss = 1.1727052927017212, GAN loss = [2.362558, 0.80889285, 0.940085]\n",
      "Batch 443/700: Discriminator loss = 1.2124662399291992, GAN loss = [2.3032436, 0.7934197, 0.896277]\n",
      "Batch 444/700: Discriminator loss = 1.1435840129852295, GAN loss = [2.3962286, 0.8479512, 0.93476623]\n",
      "Batch 445/700: Discriminator loss = 1.152964472770691, GAN loss = [2.4151752, 0.8394954, 0.96220934]\n",
      "Batch 446/700: Discriminator loss = 1.1781024932861328, GAN loss = [2.2829585, 0.794779, 0.87474203]\n",
      "Batch 447/700: Discriminator loss = 1.1462291479110718, GAN loss = [2.4415534, 0.8654521, 0.9626936]\n",
      "Batch 448/700: Discriminator loss = 1.1607345342636108, GAN loss = [2.419602, 0.84478676, 0.96143097]\n",
      "Batch 449/700: Discriminator loss = 1.1543875932693481, GAN loss = [2.463764, 0.8315789, 1.0188124]\n",
      "Batch 450/700: Discriminator loss = 1.1380831003189087, GAN loss = [2.4237425, 0.8614862, 0.9489198]\n",
      "Batch 451/700: Discriminator loss = 1.1278879642486572, GAN loss = [2.4551291, 0.8724032, 0.9694345]\n",
      "Batch 452/700: Discriminator loss = 1.1388167142868042, GAN loss = [2.4632075, 0.86668664, 0.98327285]\n",
      "Batch 453/700: Discriminator loss = 1.1501519680023193, GAN loss = [2.431303, 0.82299227, 0.9950957]\n",
      "Batch 454/700: Discriminator loss = 1.130126953125, GAN loss = [2.436596, 0.8673134, 0.95609355]\n",
      "Batch 455/700: Discriminator loss = 1.129965901374817, GAN loss = [2.501807, 0.859875, 1.0287623]\n",
      "Batch 456/700: Discriminator loss = 1.1251040697097778, GAN loss = [2.4761531, 0.85205483, 1.0109389]\n",
      "Batch 457/700: Discriminator loss = 1.1384646892547607, GAN loss = [2.4481122, 0.88134503, 0.9536218]\n",
      "Batch 458/700: Discriminator loss = 1.0906331539154053, GAN loss = [2.5050607, 0.9169753, 0.97496986]\n",
      "Batch 459/700: Discriminator loss = 1.117568016052246, GAN loss = [2.5143135, 0.89316416, 1.0080652]\n",
      "Batch 460/700: Discriminator loss = 1.111534595489502, GAN loss = [2.5110102, 0.9155705, 0.9823922]\n",
      "Batch 461/700: Discriminator loss = 1.1482423543930054, GAN loss = [2.56718, 0.8835787, 1.0705627]\n",
      "Batch 462/700: Discriminator loss = 1.1352707147598267, GAN loss = [2.425915, 0.8898208, 0.923073]\n",
      "Batch 463/700: Discriminator loss = 1.111999750137329, GAN loss = [2.4821875, 0.899062, 0.97013015]\n",
      "Batch 464/700: Discriminator loss = 1.1503607034683228, GAN loss = [2.4255664, 0.89450425, 0.918087]\n",
      "Batch 465/700: Discriminator loss = 1.1221970319747925, GAN loss = [2.4364936, 0.9133723, 0.91018516]\n",
      "Batch 466/700: Discriminator loss = 1.1322044134140015, GAN loss = [2.4271438, 0.8892541, 0.92498404]\n",
      "Batch 467/700: Discriminator loss = 1.1456836462020874, GAN loss = [2.5036836, 0.88101697, 1.0097736]\n",
      "Batch 468/700: Discriminator loss = 1.1596637964248657, GAN loss = [2.4370897, 0.88483757, 0.93936557]\n",
      "Batch 469/700: Discriminator loss = 1.140098214149475, GAN loss = [2.4259355, 0.88432676, 0.9287216]\n",
      "Batch 470/700: Discriminator loss = 1.1411646604537964, GAN loss = [2.439642, 0.8956958, 0.9310352]\n",
      "Batch 471/700: Discriminator loss = 1.1146029233932495, GAN loss = [2.4581673, 0.93586516, 0.90939695]\n",
      "Batch 472/700: Discriminator loss = 1.1374884843826294, GAN loss = [2.3729353, 0.87534815, 0.88466746]\n",
      "Batch 473/700: Discriminator loss = 1.1148183345794678, GAN loss = [2.5402088, 0.9562406, 0.97103953]\n",
      "Batch 474/700: Discriminator loss = 1.1204102039337158, GAN loss = [2.4744585, 0.8941026, 0.9674299]\n",
      "Batch 475/700: Discriminator loss = 1.1514942646026611, GAN loss = [2.388234, 0.87012744, 0.90519094]\n",
      "Batch 476/700: Discriminator loss = 1.130836844444275, GAN loss = [2.4175081, 0.93219995, 0.8723997]\n",
      "Batch 477/700: Discriminator loss = 1.1172349452972412, GAN loss = [2.5061932, 0.91303825, 0.98025316]\n",
      "Batch 478/700: Discriminator loss = 1.1417043209075928, GAN loss = [2.41321, 0.8799938, 0.9203141]\n",
      "Batch 479/700: Discriminator loss = 1.1963800191879272, GAN loss = [2.3609066, 0.8515617, 0.89645416]\n",
      "Batch 480/700: Discriminator loss = 1.1439210176467896, GAN loss = [2.386887, 0.84861666, 0.9253729]\n",
      "Batch 481/700: Discriminator loss = 1.1539279222488403, GAN loss = [2.4530418, 0.86443543, 0.9757157]\n",
      "Batch 482/700: Discriminator loss = 1.1156851053237915, GAN loss = [2.4704077, 0.89245415, 0.965095]\n",
      "Batch 483/700: Discriminator loss = 1.1372004747390747, GAN loss = [2.4889674, 0.8884522, 0.98768854]\n",
      "Batch 484/700: Discriminator loss = 1.132336139678955, GAN loss = [2.4668953, 0.8753932, 0.9786979]\n",
      "Batch 485/700: Discriminator loss = 1.149557113647461, GAN loss = [2.4336874, 0.8607306, 0.96017814]\n",
      "Batch 486/700: Discriminator loss = 1.1301378011703491, GAN loss = [2.362167, 0.86078733, 0.8886466]\n",
      "Batch 487/700: Discriminator loss = 1.1406686305999756, GAN loss = [2.4884648, 0.89729935, 0.97846746]\n",
      "Batch 488/700: Discriminator loss = 1.1181340217590332, GAN loss = [2.4845035, 0.88199073, 0.9898479]\n",
      "Batch 489/700: Discriminator loss = 1.1253310441970825, GAN loss = [2.481448, 0.8826177, 0.98621076]\n",
      "Batch 490/700: Discriminator loss = 1.1252546310424805, GAN loss = [2.5081434, 0.88485307, 1.0107063]\n",
      "Batch 491/700: Discriminator loss = 1.1523841619491577, GAN loss = [2.414812, 0.848695, 0.9535593]\n",
      "Batch 492/700: Discriminator loss = 1.1972885131835938, GAN loss = [2.438895, 0.8142704, 1.0120968]\n",
      "Batch 493/700: Discriminator loss = 1.1949141025543213, GAN loss = [2.3784933, 0.81883186, 0.9471413]\n",
      "Batch 494/700: Discriminator loss = 1.2003345489501953, GAN loss = [2.382165, 0.83238083, 0.93729955]\n",
      "Batch 495/700: Discriminator loss = 1.1765743494033813, GAN loss = [2.3273976, 0.8170494, 0.8978901]\n",
      "Batch 496/700: Discriminator loss = 1.1886801719665527, GAN loss = [2.4437165, 0.8372595, 0.9940328]\n",
      "Batch 497/700: Discriminator loss = 1.2016762495040894, GAN loss = [2.3518188, 0.8572113, 0.8821988]\n",
      "Batch 498/700: Discriminator loss = 1.1874408721923828, GAN loss = [2.367689, 0.8544544, 0.9008497]\n",
      "Batch 499/700: Discriminator loss = 1.1462055444717407, GAN loss = [2.3622112, 0.8589947, 0.8908432]\n",
      "Batch 500/700: Discriminator loss = 1.1361243724822998, GAN loss = [2.4074483, 0.88182855, 0.91326576]\n",
      "Batch 501/700: Discriminator loss = 1.1316838264465332, GAN loss = [2.4190528, 0.8954107, 0.91131014]\n",
      "Batch 502/700: Discriminator loss = 1.1364028453826904, GAN loss = [2.4276314, 0.86161023, 0.9537166]\n",
      "Batch 503/700: Discriminator loss = 1.149091362953186, GAN loss = [2.4456763, 0.8972068, 0.93621206]\n",
      "Batch 504/700: Discriminator loss = 1.1175211668014526, GAN loss = [2.3977575, 0.89635307, 0.88919145]\n",
      "Batch 505/700: Discriminator loss = 1.1371877193450928, GAN loss = [2.5451136, 0.8886688, 1.0442766]\n",
      "Batch 506/700: Discriminator loss = 1.1083354949951172, GAN loss = [2.453309, 0.88578093, 0.9553972]\n",
      "Batch 507/700: Discriminator loss = 1.1006826162338257, GAN loss = [2.4496255, 0.8954267, 0.9421028]\n",
      "Batch 508/700: Discriminator loss = 1.1090809106826782, GAN loss = [2.4873416, 0.87707466, 0.99821824]\n",
      "Batch 509/700: Discriminator loss = 1.1125956773757935, GAN loss = [2.5325196, 0.88055646, 1.0399424]\n",
      "Batch 510/700: Discriminator loss = 1.145823359489441, GAN loss = [2.4612932, 0.8572135, 0.99208015]\n",
      "Batch 511/700: Discriminator loss = 1.1251325607299805, GAN loss = [2.5374885, 0.8641751, 1.0613511]\n",
      "Batch 512/700: Discriminator loss = 1.1152501106262207, GAN loss = [2.447808, 0.8672622, 0.9686284]\n",
      "Batch 513/700: Discriminator loss = 1.1188515424728394, GAN loss = [2.587975, 0.8803028, 1.0957963]\n",
      "Batch 514/700: Discriminator loss = 1.1030051708221436, GAN loss = [2.4965959, 0.89232516, 0.9924257]\n",
      "Batch 515/700: Discriminator loss = 1.1197117567062378, GAN loss = [2.4466937, 0.87119776, 0.96367407]\n",
      "Batch 516/700: Discriminator loss = 1.1302438974380493, GAN loss = [2.4185307, 0.8693747, 0.937349]\n",
      "Batch 517/700: Discriminator loss = 1.1214585304260254, GAN loss = [2.447195, 0.8664701, 0.9689247]\n",
      "Batch 518/700: Discriminator loss = 1.1215846538543701, GAN loss = [2.5692074, 0.88185364, 1.0755794]\n",
      "Batch 519/700: Discriminator loss = 1.1399341821670532, GAN loss = [2.4967015, 0.8679967, 1.0169456]\n",
      "Batch 520/700: Discriminator loss = 1.1374715566635132, GAN loss = [2.544267, 0.89157754, 1.0409297]\n",
      "Batch 521/700: Discriminator loss = 1.1314631700515747, GAN loss = [2.4729297, 0.8900953, 0.97106165]\n",
      "Batch 522/700: Discriminator loss = 1.1498092412948608, GAN loss = [2.4534388, 0.86955786, 0.97207505]\n",
      "Batch 523/700: Discriminator loss = 1.1660698652267456, GAN loss = [2.4108636, 0.8396299, 0.95942163]\n",
      "Batch 524/700: Discriminator loss = 1.1621638536453247, GAN loss = [2.463877, 0.8879692, 0.96403414]\n",
      "Batch 525/700: Discriminator loss = 1.1730427742004395, GAN loss = [2.4481976, 0.8881666, 0.9480571]\n",
      "Batch 526/700: Discriminator loss = 1.167047381401062, GAN loss = [2.491507, 0.85917854, 1.0202086]\n",
      "Batch 527/700: Discriminator loss = 1.1753673553466797, GAN loss = [2.4052608, 0.8933343, 0.89967763]\n",
      "Batch 528/700: Discriminator loss = 1.1531908512115479, GAN loss = [2.430314, 0.86649126, 0.95145905]\n",
      "Batch 529/700: Discriminator loss = 1.1467714309692383, GAN loss = [2.364553, 0.88230866, 0.8698189]\n",
      "Batch 530/700: Discriminator loss = 1.173504114151001, GAN loss = [2.3951383, 0.84213316, 0.9405153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 531/700: Discriminator loss = 1.1678544282913208, GAN loss = [2.3641498, 0.84521246, 0.9064095]\n",
      "Batch 532/700: Discriminator loss = 1.159307837486267, GAN loss = [2.3648922, 0.84344053, 0.9088769]\n",
      "Batch 533/700: Discriminator loss = 1.2012205123901367, GAN loss = [2.3892274, 0.8307102, 0.94591826]\n",
      "Batch 534/700: Discriminator loss = 1.1748460531234741, GAN loss = [2.3462439, 0.83757615, 0.89602906]\n",
      "Batch 535/700: Discriminator loss = 1.1576058864593506, GAN loss = [2.336103, 0.8486413, 0.87480354]\n",
      "Batch 536/700: Discriminator loss = 1.1440175771713257, GAN loss = [2.4019403, 0.86762655, 0.9216188]\n",
      "Batch 537/700: Discriminator loss = 1.1725045442581177, GAN loss = [2.379851, 0.83087707, 0.9362413]\n",
      "Batch 538/700: Discriminator loss = 1.1488145589828491, GAN loss = [2.4859731, 0.86104965, 1.012176]\n",
      "Batch 539/700: Discriminator loss = 1.1797431707382202, GAN loss = [2.378066, 0.8216545, 0.9436593]\n",
      "Batch 540/700: Discriminator loss = 1.2044470310211182, GAN loss = [2.3884335, 0.7916633, 0.9840053]\n",
      "Batch 541/700: Discriminator loss = 1.1414680480957031, GAN loss = [2.3806283, 0.86780286, 0.90005773]\n",
      "Batch 542/700: Discriminator loss = 1.1830540895462036, GAN loss = [2.3738453, 0.8245397, 0.93653405]\n",
      "Batch 543/700: Discriminator loss = 1.1609629392623901, GAN loss = [2.389193, 0.87059695, 0.9058311]\n",
      "Batch 544/700: Discriminator loss = 1.1305360794067383, GAN loss = [2.4549012, 0.90490997, 0.93722177]\n",
      "Batch 545/700: Discriminator loss = 1.1319886445999146, GAN loss = [2.391721, 0.89178026, 0.8871724]\n",
      "Batch 546/700: Discriminator loss = 1.1265957355499268, GAN loss = [2.4352188, 0.88913035, 0.933326]\n",
      "Batch 547/700: Discriminator loss = 1.1366841793060303, GAN loss = [2.4499712, 0.8939414, 0.9433252]\n",
      "Batch 548/700: Discriminator loss = 1.1471627950668335, GAN loss = [2.4057121, 0.87397367, 0.91906446]\n",
      "Batch 549/700: Discriminator loss = 1.104853630065918, GAN loss = [2.46657, 0.90923196, 0.94465286]\n",
      "Batch 550/700: Discriminator loss = 1.154773473739624, GAN loss = [2.5047793, 0.86608523, 1.026001]\n",
      "Batch 551/700: Discriminator loss = 1.1228400468826294, GAN loss = [2.44732, 0.87895554, 0.9556773]\n",
      "Batch 552/700: Discriminator loss = 1.1322579383850098, GAN loss = [2.4059513, 0.8804204, 0.91285276]\n",
      "Batch 553/700: Discriminator loss = 1.1425814628601074, GAN loss = [2.4461172, 0.8785978, 0.954825]\n",
      "Batch 554/700: Discriminator loss = 1.117830753326416, GAN loss = [2.465458, 0.88211846, 0.97060186]\n",
      "Batch 555/700: Discriminator loss = 1.150545597076416, GAN loss = [2.4276164, 0.8493698, 0.96549386]\n",
      "Batch 556/700: Discriminator loss = 1.1457931995391846, GAN loss = [2.4803047, 0.8919122, 0.9756004]\n",
      "Batch 557/700: Discriminator loss = 1.1442220211029053, GAN loss = [2.452262, 0.8661025, 0.9733503]\n",
      "Batch 558/700: Discriminator loss = 1.1377019882202148, GAN loss = [2.4548857, 0.8924133, 0.94964194]\n",
      "Batch 559/700: Discriminator loss = 1.150731086730957, GAN loss = [2.4236238, 0.8550296, 0.955736]\n",
      "Batch 560/700: Discriminator loss = 1.1283212900161743, GAN loss = [2.5357063, 0.9223571, 1.0004768]\n",
      "Batch 561/700: Discriminator loss = 1.1340786218643188, GAN loss = [2.4445565, 0.8835571, 0.94810325]\n",
      "Batch 562/700: Discriminator loss = 1.144126296043396, GAN loss = [2.5077999, 0.86576056, 1.0291209]\n",
      "Batch 563/700: Discriminator loss = 1.128836750984192, GAN loss = [2.4847546, 0.9004412, 0.9713658]\n",
      "Batch 564/700: Discriminator loss = 1.106269121170044, GAN loss = [2.4406664, 0.8912071, 0.9365084]\n",
      "Batch 565/700: Discriminator loss = 1.1386098861694336, GAN loss = [2.4610057, 0.8828166, 0.96523833]\n",
      "Batch 566/700: Discriminator loss = 1.1039282083511353, GAN loss = [2.497531, 0.8997738, 0.98480684]\n",
      "Batch 567/700: Discriminator loss = 1.110059380531311, GAN loss = [2.4882824, 0.9208026, 0.9545539]\n",
      "Batch 568/700: Discriminator loss = 1.1350789070129395, GAN loss = [2.54577, 0.90865207, 1.0242403]\n",
      "Batch 569/700: Discriminator loss = 1.1107579469680786, GAN loss = [2.5174384, 0.9119462, 0.9926044]\n",
      "Batch 570/700: Discriminator loss = 1.1402475833892822, GAN loss = [2.4973195, 0.89650613, 0.98792654]\n",
      "Batch 571/700: Discriminator loss = 1.134049892425537, GAN loss = [2.5021389, 0.88323534, 1.0060365]\n",
      "Batch 572/700: Discriminator loss = 1.1388568878173828, GAN loss = [2.5067177, 0.8857798, 1.0080835]\n",
      "Batch 573/700: Discriminator loss = 1.135733962059021, GAN loss = [2.4879832, 0.88009804, 0.99505997]\n",
      "Batch 574/700: Discriminator loss = 1.1376367807388306, GAN loss = [2.4951403, 0.9180399, 0.96429366]\n",
      "Batch 575/700: Discriminator loss = 1.1485286951065063, GAN loss = [2.4230442, 0.89615476, 0.91405237]\n",
      "Batch 576/700: Discriminator loss = 1.143860936164856, GAN loss = [2.4570096, 0.884473, 0.9596669]\n",
      "Batch 577/700: Discriminator loss = 1.135025978088379, GAN loss = [2.4530127, 0.87615186, 0.96395963]\n",
      "Batch 578/700: Discriminator loss = 1.1656306982040405, GAN loss = [2.4593608, 0.8560695, 0.99036455]\n",
      "Batch 579/700: Discriminator loss = 1.1516473293304443, GAN loss = [2.452448, 0.86511976, 0.9743657]\n",
      "Batch 580/700: Discriminator loss = 1.1897273063659668, GAN loss = [2.4091156, 0.8476778, 0.9484615]\n",
      "Batch 581/700: Discriminator loss = 1.154207468032837, GAN loss = [2.45348, 0.8681344, 0.9723655]\n",
      "Batch 582/700: Discriminator loss = 1.192530632019043, GAN loss = [2.3861392, 0.8564106, 0.9167237]\n",
      "Batch 583/700: Discriminator loss = 1.144189476966858, GAN loss = [2.4632466, 0.87704885, 0.97319627]\n",
      "Batch 584/700: Discriminator loss = 1.165172815322876, GAN loss = [2.355895, 0.85205376, 0.89085805]\n",
      "Batch 585/700: Discriminator loss = 1.1466772556304932, GAN loss = [2.4746926, 0.88588417, 0.9758266]\n",
      "Batch 586/700: Discriminator loss = 1.1576504707336426, GAN loss = [2.4519944, 0.87837034, 0.9606546]\n",
      "Batch 587/700: Discriminator loss = 1.1632158756256104, GAN loss = [2.4132028, 0.8607504, 0.9394809]\n",
      "Batch 588/700: Discriminator loss = 1.1878316402435303, GAN loss = [2.4141617, 0.84240186, 0.95877093]\n",
      "Batch 589/700: Discriminator loss = 1.172013521194458, GAN loss = [2.3740773, 0.8323579, 0.92872435]\n",
      "Batch 590/700: Discriminator loss = 1.1501563787460327, GAN loss = [2.3996315, 0.8473228, 0.9393116]\n",
      "Batch 591/700: Discriminator loss = 1.2111554145812988, GAN loss = [2.3803697, 0.8221367, 0.9452281]\n",
      "Batch 592/700: Discriminator loss = 1.194322109222412, GAN loss = [2.2995682, 0.8348418, 0.8517063]\n",
      "Batch 593/700: Discriminator loss = 1.2235914468765259, GAN loss = [2.2283747, 0.79527664, 0.8200987]\n",
      "Batch 594/700: Discriminator loss = 1.1910158395767212, GAN loss = [2.3354561, 0.83602744, 0.8864344]\n",
      "Batch 595/700: Discriminator loss = 1.177076816558838, GAN loss = [2.345567, 0.8476487, 0.88492393]\n",
      "Batch 596/700: Discriminator loss = 1.1676554679870605, GAN loss = [2.330947, 0.83881325, 0.87914395]\n",
      "Batch 597/700: Discriminator loss = 1.1585999727249146, GAN loss = [2.3349316, 0.8586471, 0.8633026]\n",
      "Batch 598/700: Discriminator loss = 1.180013656616211, GAN loss = [2.340449, 0.8369194, 0.8905516]\n",
      "Batch 599/700: Discriminator loss = 1.1622262001037598, GAN loss = [2.3447344, 0.84884346, 0.8829163]\n",
      "Batch 600/700: Discriminator loss = 1.156434178352356, GAN loss = [2.3409271, 0.8707828, 0.85718375]\n",
      "Batch 601/700: Discriminator loss = 1.1413811445236206, GAN loss = [2.4338536, 0.8628512, 0.9580581]\n",
      "Batch 602/700: Discriminator loss = 1.132946491241455, GAN loss = [2.3564897, 0.8848324, 0.85873705]\n",
      "Batch 603/700: Discriminator loss = 1.152768850326538, GAN loss = [2.3722296, 0.86053705, 0.89877754]\n",
      "Batch 604/700: Discriminator loss = 1.1436960697174072, GAN loss = [2.3914876, 0.8625161, 0.91604704]\n",
      "Batch 605/700: Discriminator loss = 1.1208670139312744, GAN loss = [2.3835278, 0.8763133, 0.8942843]\n",
      "Batch 606/700: Discriminator loss = 1.1412601470947266, GAN loss = [2.3679428, 0.87875444, 0.87628263]\n",
      "Batch 607/700: Discriminator loss = 1.1218509674072266, GAN loss = [2.4323294, 0.88052744, 0.93892336]\n",
      "Batch 608/700: Discriminator loss = 1.1458313465118408, GAN loss = [2.3783283, 0.87060326, 0.89486486]\n",
      "Batch 609/700: Discriminator loss = 1.1167762279510498, GAN loss = [2.4375064, 0.8817866, 0.9428886]\n",
      "Batch 610/700: Discriminator loss = 1.1207743883132935, GAN loss = [2.4779081, 0.8773259, 0.987785]\n",
      "Batch 611/700: Discriminator loss = 1.1226648092269897, GAN loss = [2.4036748, 0.88350165, 0.9074034]\n",
      "Batch 612/700: Discriminator loss = 1.1513855457305908, GAN loss = [2.3429132, 0.8686486, 0.86155725]\n",
      "Batch 613/700: Discriminator loss = 1.1269519329071045, GAN loss = [2.472679, 0.8988277, 0.96120065]\n",
      "Batch 614/700: Discriminator loss = 1.163394808769226, GAN loss = [2.4382696, 0.85723364, 0.96842414]\n",
      "Batch 615/700: Discriminator loss = 1.116349697113037, GAN loss = [2.4103138, 0.89234316, 0.90539116]\n",
      "Batch 616/700: Discriminator loss = 1.1421756744384766, GAN loss = [2.4261987, 0.8874833, 0.9261532]\n",
      "Batch 617/700: Discriminator loss = 1.1320610046386719, GAN loss = [2.4476163, 0.8795709, 0.95550644]\n",
      "Batch 618/700: Discriminator loss = 1.138805866241455, GAN loss = [2.4110596, 0.87064254, 0.9278967]\n",
      "Batch 619/700: Discriminator loss = 1.1231787204742432, GAN loss = [2.4314885, 0.88604134, 0.9329599]\n",
      "Batch 620/700: Discriminator loss = 1.1360164880752563, GAN loss = [2.4344141, 0.8756457, 0.9462816]\n",
      "Batch 621/700: Discriminator loss = 1.141705870628357, GAN loss = [2.4412239, 0.8735125, 0.9552168]\n",
      "Batch 622/700: Discriminator loss = 1.1586157083511353, GAN loss = [2.4277027, 0.8580184, 0.9571704]\n",
      "Batch 623/700: Discriminator loss = 1.1442867517471313, GAN loss = [2.460123, 0.88365245, 0.9639306]\n",
      "Batch 624/700: Discriminator loss = 1.1584486961364746, GAN loss = [2.4433794, 0.8850977, 0.94571614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 625/700: Discriminator loss = 1.1409136056900024, GAN loss = [2.5901003, 0.9296606, 1.0478604]\n",
      "Batch 626/700: Discriminator loss = 1.1284477710723877, GAN loss = [2.4982805, 0.95314527, 0.93252444]\n",
      "Batch 627/700: Discriminator loss = 1.1544607877731323, GAN loss = [2.524072, 0.89126664, 1.0201504]\n",
      "Batch 628/700: Discriminator loss = 1.126496434211731, GAN loss = [2.518981, 0.9620408, 0.94422174]\n",
      "Batch 629/700: Discriminator loss = 1.125952124595642, GAN loss = [2.4845295, 0.93313843, 0.9385919]\n",
      "Batch 630/700: Discriminator loss = 1.1194615364074707, GAN loss = [2.4846737, 0.91593033, 0.9558673]\n",
      "Batch 631/700: Discriminator loss = 1.1132378578186035, GAN loss = [2.5105755, 0.9184997, 0.9791499]\n",
      "Batch 632/700: Discriminator loss = 1.1273338794708252, GAN loss = [2.5184171, 0.91380423, 0.9916552]\n",
      "Batch 633/700: Discriminator loss = 1.137938380241394, GAN loss = [2.5601158, 0.9263798, 1.0207121]\n",
      "Batch 634/700: Discriminator loss = 1.1422942876815796, GAN loss = [2.5423784, 0.9069396, 1.0223875]\n",
      "Batch 635/700: Discriminator loss = 1.1363036632537842, GAN loss = [2.5992837, 0.9207583, 1.0654281]\n",
      "Batch 636/700: Discriminator loss = 1.1719731092453003, GAN loss = [2.4685047, 0.8605262, 0.99483764]\n",
      "Batch 637/700: Discriminator loss = 1.1571286916732788, GAN loss = [2.386142, 0.8863815, 0.8866131]\n",
      "Batch 638/700: Discriminator loss = 1.1708728075027466, GAN loss = [2.4760802, 0.87870795, 0.98422575]\n",
      "Batch 639/700: Discriminator loss = 1.152857780456543, GAN loss = [2.55585, 0.9166244, 1.026024]\n",
      "Batch 640/700: Discriminator loss = 1.178620457649231, GAN loss = [2.4074988, 0.88794017, 0.90631735]\n",
      "Batch 641/700: Discriminator loss = 1.1869009733200073, GAN loss = [2.384887, 0.869735, 0.9018702]\n",
      "Batch 642/700: Discriminator loss = 1.1883693933486938, GAN loss = [2.43784, 0.8893669, 0.9351185]\n",
      "Batch 643/700: Discriminator loss = 1.2223877906799316, GAN loss = [2.4171298, 0.8625175, 0.9411781]\n",
      "Batch 644/700: Discriminator loss = 1.1500637531280518, GAN loss = [2.5080786, 0.91396576, 0.98060274]\n",
      "Batch 645/700: Discriminator loss = 1.188245177268982, GAN loss = [2.4596944, 0.91272044, 0.9333825]\n",
      "Batch 646/700: Discriminator loss = 1.1756467819213867, GAN loss = [2.452833, 0.8935337, 0.9456102]\n",
      "Batch 647/700: Discriminator loss = 1.1737345457077026, GAN loss = [2.391229, 0.92734957, 0.850114]\n",
      "Batch 648/700: Discriminator loss = 1.1796784400939941, GAN loss = [2.3601885, 0.88505656, 0.86130995]\n",
      "Batch 649/700: Discriminator loss = 1.167158842086792, GAN loss = [2.4044569, 0.9109808, 0.87961286]\n",
      "Batch 650/700: Discriminator loss = 1.1970223188400269, GAN loss = [2.4595678, 0.88867587, 0.9570218]\n",
      "Batch 651/700: Discriminator loss = 1.1436086893081665, GAN loss = [2.4674807, 0.9266927, 0.9269007]\n",
      "Batch 652/700: Discriminator loss = 1.1367530822753906, GAN loss = [2.5179775, 0.95080537, 0.9532705]\n",
      "Batch 653/700: Discriminator loss = 1.1304675340652466, GAN loss = [2.4959, 0.97068316, 0.91127396]\n",
      "Batch 654/700: Discriminator loss = 1.1271785497665405, GAN loss = [2.5225973, 0.94509125, 0.96354604]\n",
      "Batch 655/700: Discriminator loss = 1.1665550470352173, GAN loss = [2.4428766, 0.9045407, 0.9243327]\n",
      "Batch 656/700: Discriminator loss = 1.1477206945419312, GAN loss = [2.512264, 0.924676, 0.97358185]\n",
      "Batch 657/700: Discriminator loss = 1.1330010890960693, GAN loss = [2.3950896, 0.9081154, 0.8729735]\n",
      "Batch 658/700: Discriminator loss = 1.1606392860412598, GAN loss = [2.3922544, 0.88456374, 0.8936931]\n",
      "Batch 659/700: Discriminator loss = 1.1347780227661133, GAN loss = [2.5137594, 0.8975532, 1.002213]\n",
      "Batch 660/700: Discriminator loss = 1.144868016242981, GAN loss = [2.4487875, 0.90882385, 0.9259791]\n",
      "Batch 661/700: Discriminator loss = 1.1103571653366089, GAN loss = [2.4781678, 0.9168722, 0.9473097]\n",
      "Batch 662/700: Discriminator loss = 1.126050591468811, GAN loss = [2.456021, 0.89251196, 0.9495011]\n",
      "Batch 663/700: Discriminator loss = 1.1301766633987427, GAN loss = [2.48064, 0.8988328, 0.96779174]\n",
      "Batch 664/700: Discriminator loss = 1.1124354600906372, GAN loss = [2.4917169, 0.90961456, 0.9681056]\n",
      "Batch 665/700: Discriminator loss = 1.1401362419128418, GAN loss = [2.4820154, 0.8901215, 0.977915]\n",
      "Batch 666/700: Discriminator loss = 1.1225528717041016, GAN loss = [2.6168518, 0.90415007, 1.098748]\n",
      "Batch 667/700: Discriminator loss = 1.110424518585205, GAN loss = [2.5377216, 0.8989946, 1.0248053]\n",
      "Batch 668/700: Discriminator loss = 1.1463004350662231, GAN loss = [2.4458861, 0.87106985, 0.9609315]\n",
      "Batch 669/700: Discriminator loss = 1.1357932090759277, GAN loss = [2.4227643, 0.9028244, 0.9061178]\n",
      "Batch 670/700: Discriminator loss = 1.1280933618545532, GAN loss = [2.4601572, 0.9007485, 0.9456331]\n",
      "Batch 671/700: Discriminator loss = 1.134395718574524, GAN loss = [2.4677944, 0.90187144, 0.9521801]\n",
      "Batch 672/700: Discriminator loss = 1.093939185142517, GAN loss = [2.5124464, 0.93708634, 0.96166]\n",
      "Batch 673/700: Discriminator loss = 1.1052844524383545, GAN loss = [2.6591206, 0.9409265, 1.1045188]\n",
      "Batch 674/700: Discriminator loss = 1.0817711353302002, GAN loss = [2.585284, 0.9247902, 1.0468402]\n",
      "Batch 675/700: Discriminator loss = 1.072713851928711, GAN loss = [2.5916348, 0.9462733, 1.031755]\n",
      "Batch 676/700: Discriminator loss = 1.0925205945968628, GAN loss = [2.5433104, 0.93081987, 0.9989298]\n",
      "Batch 677/700: Discriminator loss = 1.0659737586975098, GAN loss = [2.6715212, 0.9586986, 1.0993199]\n",
      "Batch 678/700: Discriminator loss = 1.1326892375946045, GAN loss = [2.6240227, 0.8924223, 1.1181169]\n",
      "Batch 679/700: Discriminator loss = 1.0941166877746582, GAN loss = [2.5768585, 0.9325046, 1.0308666]\n",
      "Batch 680/700: Discriminator loss = 1.0748393535614014, GAN loss = [2.7683382, 0.9537128, 1.2011597]\n",
      "Batch 681/700: Discriminator loss = 1.1192200183868408, GAN loss = [2.7020755, 0.9081448, 1.180466]\n",
      "Batch 682/700: Discriminator loss = 1.0817965269088745, GAN loss = [2.6242146, 0.95253646, 1.0582061]\n",
      "Batch 683/700: Discriminator loss = 1.1167821884155273, GAN loss = [2.640783, 0.90244585, 1.1248728]\n",
      "Batch 684/700: Discriminator loss = 1.105682611465454, GAN loss = [2.6093183, 0.94546914, 1.0503975]\n",
      "Batch 685/700: Discriminator loss = 1.114577293395996, GAN loss = [2.5626106, 0.90719813, 1.0419853]\n",
      "Batch 686/700: Discriminator loss = 1.1102190017700195, GAN loss = [2.6390386, 0.92158914, 1.1040462]\n",
      "Batch 687/700: Discriminator loss = 1.1103624105453491, GAN loss = [2.6119282, 0.9426423, 1.0558959]\n",
      "Batch 688/700: Discriminator loss = 1.0856016874313354, GAN loss = [2.7750368, 0.94787955, 1.2137619]\n",
      "Batch 689/700: Discriminator loss = 1.1114555597305298, GAN loss = [2.6590247, 0.93118495, 1.1144255]\n",
      "Batch 690/700: Discriminator loss = 1.175431489944458, GAN loss = [2.6171107, 0.90756285, 1.0961033]\n",
      "Batch 691/700: Discriminator loss = 1.1330114603042603, GAN loss = [2.5687802, 0.92536855, 1.0299495]\n",
      "Batch 692/700: Discriminator loss = 1.1103419065475464, GAN loss = [2.5823343, 0.95400214, 1.0148681]\n",
      "Batch 693/700: Discriminator loss = 1.097050666809082, GAN loss = [2.604981, 0.9652606, 1.0262394]\n",
      "Batch 694/700: Discriminator loss = 1.1415828466415405, GAN loss = [2.5428138, 0.924172, 1.0051603]\n",
      "Batch 695/700: Discriminator loss = 1.0894877910614014, GAN loss = [2.5216823, 0.96283287, 0.9453669]\n",
      "Batch 696/700: Discriminator loss = 1.1159954071044922, GAN loss = [2.5867646, 0.9200027, 1.0532539]\n",
      "Batch 697/700: Discriminator loss = 1.1102041006088257, GAN loss = [2.6596806, 0.9511027, 1.0950924]\n",
      "Batch 698/700: Discriminator loss = 1.1077450513839722, GAN loss = [2.5482013, 0.96770835, 0.9670328]\n",
      "Batch 699/700: Discriminator loss = 1.0842069387435913, GAN loss = [2.6042397, 0.999354, 0.9914221]\n",
      "Batch 700/700: Discriminator loss = 1.0693389177322388, GAN loss = [2.7581694, 0.99269867, 1.1519731]\n",
      "Epoch 27/30\n",
      "Batch 1/700: Discriminator loss = 1.1242561340332031, GAN loss = [2.5997293, 0.92484593, 1.0613369]\n",
      "Batch 2/700: Discriminator loss = 1.0887577533721924, GAN loss = [2.6286016, 0.97671247, 1.0383079]\n",
      "Batch 3/700: Discriminator loss = 1.10759699344635, GAN loss = [2.5511138, 0.91983914, 1.0177013]\n",
      "Batch 4/700: Discriminator loss = 1.111922264099121, GAN loss = [2.5321603, 0.9333577, 0.98522407]\n",
      "Batch 5/700: Discriminator loss = 1.1139596700668335, GAN loss = [2.565922, 0.92266333, 1.0296752]\n",
      "Batch 6/700: Discriminator loss = 1.1308258771896362, GAN loss = [2.4705076, 0.896347, 0.96054184]\n",
      "Batch 7/700: Discriminator loss = 1.1442331075668335, GAN loss = [2.5286772, 0.8905141, 1.0245193]\n",
      "Batch 8/700: Discriminator loss = 1.1465201377868652, GAN loss = [2.5586338, 0.90059453, 1.0443921]\n",
      "Batch 9/700: Discriminator loss = 1.1430896520614624, GAN loss = [2.4880884, 0.86998934, 1.0044636]\n",
      "Batch 10/700: Discriminator loss = 1.1263177394866943, GAN loss = [2.647448, 0.9043055, 1.1295431]\n",
      "Batch 11/700: Discriminator loss = 1.1513692140579224, GAN loss = [2.5205266, 0.88984215, 1.0171092]\n",
      "Batch 12/700: Discriminator loss = 1.1148542165756226, GAN loss = [2.5186944, 0.89669806, 1.0084518]\n",
      "Batch 13/700: Discriminator loss = 1.1066315174102783, GAN loss = [2.5549471, 0.9084239, 1.0329885]\n",
      "Batch 14/700: Discriminator loss = 1.117482304573059, GAN loss = [2.496843, 0.92131263, 0.9620214]\n",
      "Batch 15/700: Discriminator loss = 1.1529343128204346, GAN loss = [2.4760268, 0.86460793, 0.99791205]\n",
      "Batch 16/700: Discriminator loss = 1.1326148509979248, GAN loss = [2.4945529, 0.88346815, 0.99757993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17/700: Discriminator loss = 1.1237491369247437, GAN loss = [2.5409408, 0.9096396, 1.0177952]\n",
      "Batch 18/700: Discriminator loss = 1.1433541774749756, GAN loss = [2.519594, 0.8906283, 1.0154747]\n",
      "Batch 19/700: Discriminator loss = 1.1401015520095825, GAN loss = [2.542078, 0.9028611, 1.0257359]\n",
      "Batch 20/700: Discriminator loss = 1.1306407451629639, GAN loss = [2.459319, 0.886141, 0.95968187]\n",
      "Batch 21/700: Discriminator loss = 1.130932092666626, GAN loss = [2.5066018, 0.87591416, 1.0171523]\n",
      "Batch 22/700: Discriminator loss = 1.159383773803711, GAN loss = [2.550801, 0.8818965, 1.0553427]\n",
      "Batch 23/700: Discriminator loss = 1.1237236261367798, GAN loss = [2.5250359, 0.90355515, 1.0079219]\n",
      "Batch 24/700: Discriminator loss = 1.117795705795288, GAN loss = [2.4735663, 0.90067726, 0.9593149]\n",
      "Batch 25/700: Discriminator loss = 1.1458063125610352, GAN loss = [2.500682, 0.8856817, 1.0014379]\n",
      "Batch 26/700: Discriminator loss = 1.1193695068359375, GAN loss = [2.5893662, 0.9084626, 1.0673385]\n",
      "Batch 27/700: Discriminator loss = 1.1029353141784668, GAN loss = [2.5944738, 0.9123592, 1.0685549]\n",
      "Batch 28/700: Discriminator loss = 1.1297963857650757, GAN loss = [2.5632882, 0.88865083, 1.0610925]\n",
      "Batch 29/700: Discriminator loss = 1.1312286853790283, GAN loss = [2.4201617, 0.87640536, 0.9302159]\n",
      "Batch 30/700: Discriminator loss = 1.127609372138977, GAN loss = [2.485325, 0.8720753, 0.9997226]\n",
      "Batch 31/700: Discriminator loss = 1.130312442779541, GAN loss = [2.555811, 0.8735772, 1.0687171]\n",
      "Batch 32/700: Discriminator loss = 1.1296271085739136, GAN loss = [2.517501, 0.87580055, 1.0281799]\n",
      "Batch 33/700: Discriminator loss = 1.1512598991394043, GAN loss = [2.5311918, 0.88463914, 1.0330278]\n",
      "Batch 34/700: Discriminator loss = 1.1302661895751953, GAN loss = [2.580869, 0.8934525, 1.0738475]\n",
      "Batch 35/700: Discriminator loss = 1.144865870475769, GAN loss = [2.4681394, 0.87416387, 0.9803649]\n",
      "Batch 36/700: Discriminator loss = 1.083640456199646, GAN loss = [2.6103082, 0.9325227, 1.0641712]\n",
      "Batch 37/700: Discriminator loss = 1.143429160118103, GAN loss = [2.467614, 0.8947893, 0.95921683]\n",
      "Batch 38/700: Discriminator loss = 1.1090868711471558, GAN loss = [2.5742593, 0.91086006, 1.0498043]\n",
      "Batch 39/700: Discriminator loss = 1.115896463394165, GAN loss = [2.5617044, 0.90457296, 1.0435566]\n",
      "Batch 40/700: Discriminator loss = 1.0818078517913818, GAN loss = [2.5657089, 0.92433447, 1.0278025]\n",
      "Batch 41/700: Discriminator loss = 1.0901107788085938, GAN loss = [2.550277, 0.9165794, 1.0201222]\n",
      "Batch 42/700: Discriminator loss = 1.1060214042663574, GAN loss = [2.691863, 0.93266845, 1.1456485]\n",
      "Batch 43/700: Discriminator loss = 1.0853205919265747, GAN loss = [2.5558152, 0.92918724, 1.013123]\n",
      "Batch 44/700: Discriminator loss = 1.0970734357833862, GAN loss = [2.5647483, 0.94400805, 1.0072871]\n",
      "Batch 45/700: Discriminator loss = 1.0743720531463623, GAN loss = [2.7042584, 0.9378965, 1.1529311]\n",
      "Batch 46/700: Discriminator loss = 1.0800244808197021, GAN loss = [2.5597825, 0.9498087, 0.9965895]\n",
      "Batch 47/700: Discriminator loss = 1.0754709243774414, GAN loss = [2.69517, 0.9581637, 1.1236255]\n",
      "Batch 48/700: Discriminator loss = 1.106675148010254, GAN loss = [2.6368985, 0.9568253, 1.06669]\n",
      "Batch 49/700: Discriminator loss = 1.1142120361328125, GAN loss = [2.5572689, 0.90753657, 1.0363042]\n",
      "Batch 50/700: Discriminator loss = 1.1039429903030396, GAN loss = [2.637364, 0.91574675, 1.1081567]\n",
      "Batch 51/700: Discriminator loss = 1.1025949716567993, GAN loss = [2.6339839, 0.97834116, 1.0421807]\n",
      "Batch 52/700: Discriminator loss = 1.0764340162277222, GAN loss = [2.6741803, 0.9604588, 1.1002246]\n",
      "Batch 53/700: Discriminator loss = 1.1055407524108887, GAN loss = [2.5901058, 0.9600742, 1.016513]\n",
      "Batch 54/700: Discriminator loss = 1.0866135358810425, GAN loss = [2.61111, 0.9464029, 1.0511671]\n",
      "Batch 55/700: Discriminator loss = 1.082935094833374, GAN loss = [2.758565, 0.9586342, 1.1863778]\n",
      "Batch 56/700: Discriminator loss = 1.0723168849945068, GAN loss = [2.761946, 0.9651549, 1.1832175]\n",
      "Batch 57/700: Discriminator loss = 1.0730713605880737, GAN loss = [2.7860205, 0.9911472, 1.1812862]\n",
      "Batch 58/700: Discriminator loss = 1.0745168924331665, GAN loss = [2.6224632, 0.97435004, 1.0344881]\n",
      "Batch 59/700: Discriminator loss = 1.1003906726837158, GAN loss = [2.6945684, 0.93625647, 1.1446189]\n",
      "Batch 60/700: Discriminator loss = 1.1071759462356567, GAN loss = [2.61444, 0.94207525, 1.0586228]\n",
      "Batch 61/700: Discriminator loss = 1.092259407043457, GAN loss = [2.6541677, 0.94604707, 1.0943199]\n",
      "Batch 62/700: Discriminator loss = 1.105996012687683, GAN loss = [2.6803486, 0.9476342, 1.1188798]\n",
      "Batch 63/700: Discriminator loss = 1.0931328535079956, GAN loss = [2.7020872, 0.9763262, 1.1118977]\n",
      "Batch 64/700: Discriminator loss = 1.1103383302688599, GAN loss = [2.6112347, 0.9481293, 1.0491714]\n",
      "Batch 65/700: Discriminator loss = 1.128470778465271, GAN loss = [2.728108, 0.9455589, 1.1685351]\n",
      "Batch 66/700: Discriminator loss = 1.1511290073394775, GAN loss = [2.6325464, 0.94785094, 1.0706124]\n",
      "Batch 67/700: Discriminator loss = 1.127596139907837, GAN loss = [2.5431244, 0.9525498, 0.97642547]\n",
      "Batch 68/700: Discriminator loss = 1.1650192737579346, GAN loss = [2.560524, 0.9447815, 1.0015064]\n",
      "Batch 69/700: Discriminator loss = 1.1664735078811646, GAN loss = [2.5861561, 0.9386073, 1.0332477]\n",
      "Batch 70/700: Discriminator loss = 1.123611330986023, GAN loss = [2.4944866, 0.9463896, 0.93374205]\n",
      "Batch 71/700: Discriminator loss = 1.1837687492370605, GAN loss = [2.420955, 0.8954547, 0.9111252]\n",
      "Batch 72/700: Discriminator loss = 1.20339035987854, GAN loss = [2.4189327, 0.8992553, 0.9052587]\n",
      "Batch 73/700: Discriminator loss = 1.1658823490142822, GAN loss = [2.512694, 0.90534484, 0.99289477]\n",
      "Batch 74/700: Discriminator loss = 1.176157832145691, GAN loss = [2.4361088, 0.9486334, 0.8729441]\n",
      "Batch 75/700: Discriminator loss = 1.1717956066131592, GAN loss = [2.50092, 0.92833275, 0.9579792]\n",
      "Batch 76/700: Discriminator loss = 1.1673582792282104, GAN loss = [2.4726598, 0.92997825, 0.9280172]\n",
      "Batch 77/700: Discriminator loss = 1.1906036138534546, GAN loss = [2.4486382, 0.9059764, 0.9278823]\n",
      "Batch 78/700: Discriminator loss = 1.1981306076049805, GAN loss = [2.3832629, 0.9010975, 0.86724]\n",
      "Batch 79/700: Discriminator loss = 1.1745936870574951, GAN loss = [2.3839319, 0.90353656, 0.86529374]\n",
      "Batch 80/700: Discriminator loss = 1.215491771697998, GAN loss = [2.3674247, 0.87897444, 0.87316483]\n",
      "Batch 81/700: Discriminator loss = 1.2368524074554443, GAN loss = [2.3921201, 0.8820457, 0.8946112]\n",
      "Batch 82/700: Discriminator loss = 1.1981282234191895, GAN loss = [2.435501, 0.90377694, 0.91619116]\n",
      "Batch 83/700: Discriminator loss = 1.159045934677124, GAN loss = [2.4996758, 0.8973626, 0.98664594]\n",
      "Batch 84/700: Discriminator loss = 1.1759083271026611, GAN loss = [2.5228403, 0.91652334, 0.9905369]\n",
      "Batch 85/700: Discriminator loss = 1.137966275215149, GAN loss = [2.5014315, 0.9452354, 0.9403088]\n",
      "Batch 86/700: Discriminator loss = 1.1423470973968506, GAN loss = [2.474446, 0.9318516, 0.92662]\n",
      "Batch 87/700: Discriminator loss = 1.1717280149459839, GAN loss = [2.4087212, 0.9038776, 0.88879716]\n",
      "Batch 88/700: Discriminator loss = 1.169503092765808, GAN loss = [2.5170746, 0.8994808, 1.0015078]\n",
      "Batch 89/700: Discriminator loss = 1.1703827381134033, GAN loss = [2.5339813, 0.94010615, 0.97774315]\n",
      "Batch 90/700: Discriminator loss = 1.1193641424179077, GAN loss = [2.607364, 1.0010769, 0.9901347]\n",
      "Batch 91/700: Discriminator loss = 1.1668424606323242, GAN loss = [2.510738, 0.9380498, 0.956436]\n",
      "Batch 92/700: Discriminator loss = 1.1370587348937988, GAN loss = [2.4836547, 0.93702364, 0.9302776]\n",
      "Batch 93/700: Discriminator loss = 1.1934853792190552, GAN loss = [2.5329726, 0.91587794, 1.0006611]\n",
      "Batch 94/700: Discriminator loss = 1.1381419897079468, GAN loss = [2.5442932, 0.95767766, 0.97019404]\n",
      "Batch 95/700: Discriminator loss = 1.1223106384277344, GAN loss = [2.6205053, 0.96773314, 1.0363512]\n",
      "Batch 96/700: Discriminator loss = 1.1188039779663086, GAN loss = [2.6340516, 0.96584517, 1.0517814]\n",
      "Batch 97/700: Discriminator loss = 1.171881079673767, GAN loss = [2.4989252, 0.92610735, 0.95638]\n",
      "Batch 98/700: Discriminator loss = 1.1099773645401, GAN loss = [2.550746, 0.9689005, 0.9653778]\n",
      "Batch 99/700: Discriminator loss = 1.1207934617996216, GAN loss = [2.6482172, 0.97482526, 1.0569286]\n",
      "Batch 100/700: Discriminator loss = 1.1447117328643799, GAN loss = [2.5770338, 0.9557715, 1.0047928]\n",
      "Batch 101/700: Discriminator loss = 1.1478099822998047, GAN loss = [2.5498471, 0.951351, 0.9819957]\n",
      "Batch 102/700: Discriminator loss = 1.1452895402908325, GAN loss = [2.6139448, 0.93345886, 1.0639209]\n",
      "Batch 103/700: Discriminator loss = 1.1437839269638062, GAN loss = [2.4767373, 0.9047532, 0.9554078]\n",
      "Batch 104/700: Discriminator loss = 1.1436952352523804, GAN loss = [2.584295, 0.90791756, 1.0598085]\n",
      "Batch 105/700: Discriminator loss = 1.171689748764038, GAN loss = [2.4796932, 0.84549254, 1.0176439]\n",
      "Batch 106/700: Discriminator loss = 1.1214985847473145, GAN loss = [2.5167637, 0.92459697, 0.9756244]\n",
      "Batch 107/700: Discriminator loss = 1.134416103363037, GAN loss = [2.6045465, 0.91722375, 1.0708109]\n",
      "Batch 108/700: Discriminator loss = 1.137701392173767, GAN loss = [2.6224463, 0.9243429, 1.0816307]\n",
      "Batch 109/700: Discriminator loss = 1.1351286172866821, GAN loss = [2.4925992, 0.8927124, 0.98341507]\n",
      "Batch 110/700: Discriminator loss = 1.1526979207992554, GAN loss = [2.468104, 0.88147354, 0.970176]\n",
      "Batch 111/700: Discriminator loss = 1.1379135847091675, GAN loss = [2.4636178, 0.90792525, 0.939269]\n",
      "Batch 112/700: Discriminator loss = 1.129480242729187, GAN loss = [2.533942, 0.8984083, 1.0191314]\n",
      "Batch 113/700: Discriminator loss = 1.1351587772369385, GAN loss = [2.5258045, 0.8970421, 1.012384]\n",
      "Batch 114/700: Discriminator loss = 1.1585999727249146, GAN loss = [2.4683158, 0.8730621, 0.9788894]\n",
      "Batch 115/700: Discriminator loss = 1.149721622467041, GAN loss = [2.4562452, 0.8671954, 0.9726863]\n",
      "Batch 116/700: Discriminator loss = 1.1504522562026978, GAN loss = [2.463596, 0.88670534, 0.9605351]\n",
      "Batch 117/700: Discriminator loss = 1.1299737691879272, GAN loss = [2.4538124, 0.8992395, 0.938236]\n",
      "Batch 118/700: Discriminator loss = 1.1217656135559082, GAN loss = [2.504737, 0.9006097, 0.98782545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 119/700: Discriminator loss = 1.1473497152328491, GAN loss = [2.4542007, 0.89848024, 0.93946475]\n",
      "Batch 120/700: Discriminator loss = 1.1132097244262695, GAN loss = [2.5929594, 0.91547084, 1.0612456]\n",
      "Batch 121/700: Discriminator loss = 1.1286548376083374, GAN loss = [2.5123427, 0.9120915, 0.98400396]\n",
      "Batch 122/700: Discriminator loss = 1.109048843383789, GAN loss = [2.5478578, 0.9217958, 1.0098081]\n",
      "Batch 123/700: Discriminator loss = 1.1406277418136597, GAN loss = [2.4773054, 0.915366, 0.9456409]\n",
      "Batch 124/700: Discriminator loss = 1.1506221294403076, GAN loss = [2.5143056, 0.90514404, 0.99283373]\n",
      "Batch 125/700: Discriminator loss = 1.125611662864685, GAN loss = [2.5183942, 0.9030541, 0.99902487]\n",
      "Batch 126/700: Discriminator loss = 1.139477014541626, GAN loss = [2.4906175, 0.8855899, 0.9887423]\n",
      "Batch 127/700: Discriminator loss = 1.1330370903015137, GAN loss = [2.4898803, 0.9097544, 0.9638572]\n",
      "Batch 128/700: Discriminator loss = 1.157430648803711, GAN loss = [2.4667442, 0.8881292, 0.96233344]\n",
      "Batch 129/700: Discriminator loss = 1.163374662399292, GAN loss = [2.520142, 0.86849153, 1.0353125]\n",
      "Batch 130/700: Discriminator loss = 1.1360527276992798, GAN loss = [2.4357328, 0.89389724, 0.9254636]\n",
      "Batch 131/700: Discriminator loss = 1.161312222480774, GAN loss = [2.4454937, 0.8782578, 0.95084745]\n",
      "Batch 132/700: Discriminator loss = 1.1604253053665161, GAN loss = [2.5055196, 0.9080658, 0.98105997]\n",
      "Batch 133/700: Discriminator loss = 1.1949080228805542, GAN loss = [2.4089954, 0.8755963, 0.917001]\n",
      "Batch 134/700: Discriminator loss = 1.1650046110153198, GAN loss = [2.4659812, 0.9071497, 0.94239706]\n",
      "Batch 135/700: Discriminator loss = 1.1799260377883911, GAN loss = [2.4731688, 0.8862986, 0.9703936]\n",
      "Batch 136/700: Discriminator loss = 1.1910579204559326, GAN loss = [2.4284906, 0.87420326, 0.9377716]\n",
      "Batch 137/700: Discriminator loss = 1.1764603853225708, GAN loss = [2.4115026, 0.8402293, 0.954729]\n",
      "Batch 138/700: Discriminator loss = 1.1909477710723877, GAN loss = [2.3618515, 0.8698284, 0.87546235]\n",
      "Batch 139/700: Discriminator loss = 1.2322598695755005, GAN loss = [2.4271872, 0.86618185, 0.9444539]\n",
      "Batch 140/700: Discriminator loss = 1.2126553058624268, GAN loss = [2.36205, 0.8311752, 0.91428757]\n",
      "Batch 141/700: Discriminator loss = 1.2184476852416992, GAN loss = [2.4236271, 0.8617414, 0.9452834]\n",
      "Batch 142/700: Discriminator loss = 1.1782207489013672, GAN loss = [2.3526864, 0.85232514, 0.8837408]\n",
      "Batch 143/700: Discriminator loss = 1.1977614164352417, GAN loss = [2.3558583, 0.85023165, 0.88902223]\n",
      "Batch 144/700: Discriminator loss = 1.1742902994155884, GAN loss = [2.4017797, 0.8564105, 0.9287865]\n",
      "Batch 145/700: Discriminator loss = 1.1716712713241577, GAN loss = [2.3907993, 0.87434953, 0.89990103]\n",
      "Batch 146/700: Discriminator loss = 1.1965118646621704, GAN loss = [2.3980317, 0.8888286, 0.8926787]\n",
      "Batch 147/700: Discriminator loss = 1.1759517192840576, GAN loss = [2.3190224, 0.8485804, 0.85394114]\n",
      "Batch 148/700: Discriminator loss = 1.1559633016586304, GAN loss = [2.4248552, 0.87200844, 0.9363706]\n",
      "Batch 149/700: Discriminator loss = 1.1587214469909668, GAN loss = [2.4536548, 0.8915768, 0.94566035]\n",
      "Batch 150/700: Discriminator loss = 1.1361713409423828, GAN loss = [2.4419615, 0.9029454, 0.92264974]\n",
      "Batch 151/700: Discriminator loss = 1.1565207242965698, GAN loss = [2.3533945, 0.8609444, 0.87612486]\n",
      "Batch 152/700: Discriminator loss = 1.1382629871368408, GAN loss = [2.4687808, 0.89400816, 0.9585013]\n",
      "Batch 153/700: Discriminator loss = 1.1390211582183838, GAN loss = [2.4485946, 0.8990192, 0.93336725]\n",
      "Batch 154/700: Discriminator loss = 1.1195976734161377, GAN loss = [2.4812155, 0.89704627, 0.96802163]\n",
      "Batch 155/700: Discriminator loss = 1.1209304332733154, GAN loss = [2.3911848, 0.8844444, 0.89064133]\n",
      "Batch 156/700: Discriminator loss = 1.1267845630645752, GAN loss = [2.4706752, 0.87255067, 0.9821074]\n",
      "Batch 157/700: Discriminator loss = 1.1015350818634033, GAN loss = [2.5214903, 0.88870084, 1.0168828]\n",
      "Batch 158/700: Discriminator loss = 1.107521414756775, GAN loss = [2.4671242, 0.88610786, 0.9652054]\n",
      "Batch 159/700: Discriminator loss = 1.1067802906036377, GAN loss = [2.4976933, 0.8865785, 0.9953799]\n",
      "Batch 160/700: Discriminator loss = 1.1153240203857422, GAN loss = [2.5281374, 0.87443924, 1.0380265]\n",
      "Batch 161/700: Discriminator loss = 1.0932377576828003, GAN loss = [2.5853984, 0.902342, 1.0674607]\n",
      "Batch 162/700: Discriminator loss = 1.1153095960617065, GAN loss = [2.581605, 0.8895061, 1.076576]\n",
      "Batch 163/700: Discriminator loss = 1.1051729917526245, GAN loss = [2.6046946, 0.9243529, 1.0648857]\n",
      "Batch 164/700: Discriminator loss = 1.089817762374878, GAN loss = [2.687798, 0.9368332, 1.1355553]\n",
      "Batch 165/700: Discriminator loss = 1.093353033065796, GAN loss = [2.6347773, 0.9290347, 1.0903672]\n",
      "Batch 166/700: Discriminator loss = 1.1095963716506958, GAN loss = [2.619111, 0.9068607, 1.0969627]\n",
      "Batch 167/700: Discriminator loss = 1.1048252582550049, GAN loss = [2.6714363, 0.92568034, 1.1305325]\n",
      "Batch 168/700: Discriminator loss = 1.1045433282852173, GAN loss = [2.8001175, 0.92913306, 1.255815]\n",
      "Batch 169/700: Discriminator loss = 1.1366604566574097, GAN loss = [2.6535711, 0.91385305, 1.1246037]\n",
      "Batch 170/700: Discriminator loss = 1.1006523370742798, GAN loss = [2.701143, 0.9352109, 1.1508751]\n",
      "Batch 171/700: Discriminator loss = 1.1244418621063232, GAN loss = [2.5951164, 0.9200853, 1.060017]\n",
      "Batch 172/700: Discriminator loss = 1.1355654001235962, GAN loss = [2.614325, 0.9262131, 1.0731475]\n",
      "Batch 173/700: Discriminator loss = 1.139201283454895, GAN loss = [2.5673833, 0.9330151, 1.0194478]\n",
      "Batch 174/700: Discriminator loss = 1.1495503187179565, GAN loss = [2.4885805, 0.9159862, 0.95772177]\n",
      "Batch 175/700: Discriminator loss = 1.1316685676574707, GAN loss = [2.55337, 0.9155455, 1.0229788]\n",
      "Batch 176/700: Discriminator loss = 1.135643720626831, GAN loss = [2.6522596, 0.9501929, 1.0872594]\n",
      "Batch 177/700: Discriminator loss = 1.143857717514038, GAN loss = [2.5822523, 0.9109667, 1.0565184]\n",
      "Batch 178/700: Discriminator loss = 1.1749330759048462, GAN loss = [2.5142438, 0.8793676, 1.0201496]\n",
      "Batch 179/700: Discriminator loss = 1.14539635181427, GAN loss = [2.5343163, 0.8867883, 1.0328254]\n",
      "Batch 180/700: Discriminator loss = 1.1302517652511597, GAN loss = [2.5728703, 0.9120268, 1.0461583]\n",
      "Batch 181/700: Discriminator loss = 1.166506290435791, GAN loss = [2.5413537, 0.89703196, 1.0296587]\n",
      "Batch 182/700: Discriminator loss = 1.1875592470169067, GAN loss = [2.3487344, 0.8780837, 0.85597193]\n",
      "Batch 183/700: Discriminator loss = 1.2267649173736572, GAN loss = [2.4947243, 0.87866396, 1.0013616]\n",
      "Batch 184/700: Discriminator loss = 1.1366140842437744, GAN loss = [2.5456421, 0.9070149, 1.0238868]\n",
      "Batch 185/700: Discriminator loss = 1.1635432243347168, GAN loss = [2.4764473, 0.9201529, 0.9415448]\n",
      "Batch 186/700: Discriminator loss = 1.1240109205245972, GAN loss = [2.4781718, 0.94173324, 0.92166436]\n",
      "Batch 187/700: Discriminator loss = 1.1115617752075195, GAN loss = [2.56451, 0.9758924, 0.973826]\n",
      "Batch 188/700: Discriminator loss = 1.1465895175933838, GAN loss = [2.4826002, 0.9159981, 0.9517884]\n",
      "Batch 189/700: Discriminator loss = 1.1280792951583862, GAN loss = [2.4830227, 0.9430984, 0.92510015]\n",
      "Batch 190/700: Discriminator loss = 1.156686782836914, GAN loss = [2.484015, 0.93220294, 0.93697554]\n",
      "Batch 191/700: Discriminator loss = 1.1638026237487793, GAN loss = [2.525326, 0.9505352, 0.95991904]\n",
      "Batch 192/700: Discriminator loss = 1.1703298091888428, GAN loss = [2.4633589, 0.88786894, 0.960571]\n",
      "Batch 193/700: Discriminator loss = 1.1723496913909912, GAN loss = [2.5163453, 0.9981798, 0.9031941]\n",
      "Batch 194/700: Discriminator loss = 1.176656723022461, GAN loss = [2.4516218, 0.95275337, 0.8838631]\n",
      "Batch 195/700: Discriminator loss = 1.1494327783584595, GAN loss = [2.4491954, 0.9713868, 0.8626843]\n",
      "Batch 196/700: Discriminator loss = 1.190045714378357, GAN loss = [2.4921064, 0.9611818, 0.91572237]\n",
      "Batch 197/700: Discriminator loss = 1.2124730348587036, GAN loss = [2.4939563, 1.0545363, 0.82407874]\n",
      "Batch 198/700: Discriminator loss = 1.1384999752044678, GAN loss = [2.4932008, 0.98652893, 0.8911718]\n",
      "Batch 199/700: Discriminator loss = 1.162148356437683, GAN loss = [2.4463608, 0.97031295, 0.8604083]\n",
      "Batch 200/700: Discriminator loss = 1.1667993068695068, GAN loss = [2.4212053, 0.90685457, 0.8986027]\n",
      "Batch 201/700: Discriminator loss = 1.1563103199005127, GAN loss = [2.4265904, 0.9213031, 0.8894866]\n",
      "Batch 202/700: Discriminator loss = 1.1735011339187622, GAN loss = [2.460628, 0.87911665, 0.9656857]\n",
      "Batch 203/700: Discriminator loss = 1.165741205215454, GAN loss = [2.4189615, 0.9061113, 0.89700663]\n",
      "Batch 204/700: Discriminator loss = 1.1955757141113281, GAN loss = [2.4248357, 0.8674014, 0.94158745]\n",
      "Batch 205/700: Discriminator loss = 1.1361761093139648, GAN loss = [2.4114728, 0.9182518, 0.8773803]\n",
      "Batch 206/700: Discriminator loss = 1.2101935148239136, GAN loss = [2.4472427, 0.82764035, 1.0038222]\n",
      "Batch 207/700: Discriminator loss = 1.1722389459609985, GAN loss = [2.3923879, 0.8647944, 0.9118654]\n",
      "Batch 208/700: Discriminator loss = 1.1691089868545532, GAN loss = [2.4723134, 0.86685944, 0.9898036]\n",
      "Batch 209/700: Discriminator loss = 1.1272437572479248, GAN loss = [2.538015, 0.90325284, 1.019162]\n",
      "Batch 210/700: Discriminator loss = 1.1745896339416504, GAN loss = [2.353302, 0.83036995, 0.90738493]\n",
      "Batch 211/700: Discriminator loss = 1.1397968530654907, GAN loss = [2.4296842, 0.87923735, 0.9349504]\n",
      "Batch 212/700: Discriminator loss = 1.169326663017273, GAN loss = [2.3881474, 0.865741, 0.9069649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 213/700: Discriminator loss = 1.14063560962677, GAN loss = [2.3944037, 0.87079734, 0.90819544]\n",
      "Batch 214/700: Discriminator loss = 1.109917163848877, GAN loss = [2.4668162, 0.9151513, 0.93630713]\n",
      "Batch 215/700: Discriminator loss = 1.1448067426681519, GAN loss = [2.4177535, 0.8821054, 0.92033064]\n",
      "Batch 216/700: Discriminator loss = 1.107366681098938, GAN loss = [2.548991, 0.93373215, 1.0000266]\n",
      "Batch 217/700: Discriminator loss = 1.122799277305603, GAN loss = [2.547592, 0.91983765, 1.0125905]\n",
      "Batch 218/700: Discriminator loss = 1.1119662523269653, GAN loss = [2.4985702, 0.9018196, 0.98165596]\n",
      "Batch 219/700: Discriminator loss = 1.1373074054718018, GAN loss = [2.4750404, 0.89428246, 0.96572965]\n",
      "Batch 220/700: Discriminator loss = 1.1233011484146118, GAN loss = [2.5517993, 0.92773366, 1.0091028]\n",
      "Batch 221/700: Discriminator loss = 1.1061203479766846, GAN loss = [2.4841404, 0.92716026, 0.9420607]\n",
      "Batch 222/700: Discriminator loss = 1.1187708377838135, GAN loss = [2.4982677, 0.9449109, 0.9384662]\n",
      "Batch 223/700: Discriminator loss = 1.0969785451889038, GAN loss = [2.537402, 0.95000106, 0.97256875]\n",
      "Batch 224/700: Discriminator loss = 1.0843584537506104, GAN loss = [2.5878115, 0.9622378, 1.0107908]\n",
      "Batch 225/700: Discriminator loss = 1.0826069116592407, GAN loss = [2.4725027, 0.955549, 0.9022171]\n",
      "Batch 226/700: Discriminator loss = 1.0655088424682617, GAN loss = [2.6917639, 0.9663492, 1.110736]\n",
      "Batch 227/700: Discriminator loss = 1.0727211236953735, GAN loss = [2.6269572, 0.96943253, 1.0428889]\n",
      "Batch 228/700: Discriminator loss = 1.1070938110351562, GAN loss = [2.516335, 0.92860717, 0.97311354]\n",
      "Batch 229/700: Discriminator loss = 1.0956758260726929, GAN loss = [2.5905764, 0.94375503, 1.0322492]\n",
      "Batch 230/700: Discriminator loss = 1.093648076057434, GAN loss = [2.5095088, 0.92541504, 0.96952546]\n",
      "Batch 231/700: Discriminator loss = 1.110897421836853, GAN loss = [2.5162773, 0.8983584, 1.0033664]\n",
      "Batch 232/700: Discriminator loss = 1.1286635398864746, GAN loss = [2.4732337, 0.88688964, 0.9718032]\n",
      "Batch 233/700: Discriminator loss = 1.1342089176177979, GAN loss = [2.5034199, 0.87950164, 1.0093889]\n",
      "Batch 234/700: Discriminator loss = 1.1154425144195557, GAN loss = [2.4871314, 0.9005348, 0.9720887]\n",
      "Batch 235/700: Discriminator loss = 1.138393521308899, GAN loss = [2.5576737, 0.86984307, 1.0733309]\n",
      "Batch 236/700: Discriminator loss = 1.1160268783569336, GAN loss = [2.5065718, 0.9184759, 0.97359955]\n",
      "Batch 237/700: Discriminator loss = 1.14609694480896, GAN loss = [2.441832, 0.86776316, 0.95953393]\n",
      "Batch 238/700: Discriminator loss = 1.150728702545166, GAN loss = [2.4723458, 0.86594164, 0.991833]\n",
      "Batch 239/700: Discriminator loss = 1.1738367080688477, GAN loss = [2.4706128, 0.86574554, 0.99025106]\n",
      "Batch 240/700: Discriminator loss = 1.156599760055542, GAN loss = [2.476415, 0.8669233, 0.9948344]\n",
      "Batch 241/700: Discriminator loss = 1.1597322225570679, GAN loss = [2.4904556, 0.8648965, 1.0108341]\n",
      "Batch 242/700: Discriminator loss = 1.1581004858016968, GAN loss = [2.4834077, 0.86773, 1.0008887]\n",
      "Batch 243/700: Discriminator loss = 1.118608832359314, GAN loss = [2.4988356, 0.9162355, 0.96772623]\n",
      "Batch 244/700: Discriminator loss = 1.1597391366958618, GAN loss = [2.4543052, 0.87972593, 0.95964694]\n",
      "Batch 245/700: Discriminator loss = 1.190598964691162, GAN loss = [2.475788, 0.8786769, 0.9820952]\n",
      "Batch 246/700: Discriminator loss = 1.1688529253005981, GAN loss = [2.5048242, 0.9189901, 0.9707359]\n",
      "Batch 247/700: Discriminator loss = 1.15107262134552, GAN loss = [2.414865, 0.9044036, 0.89526993]\n",
      "Batch 248/700: Discriminator loss = 1.1738189458847046, GAN loss = [2.454462, 0.90776366, 0.93142563]\n",
      "Batch 249/700: Discriminator loss = 1.1779814958572388, GAN loss = [2.445576, 0.8924157, 0.9378401]\n",
      "Batch 250/700: Discriminator loss = 1.1577728986740112, GAN loss = [2.400704, 0.88409907, 0.9012389]\n",
      "Batch 251/700: Discriminator loss = 1.1432865858078003, GAN loss = [2.4819677, 0.9225646, 0.943985]\n",
      "Batch 252/700: Discriminator loss = 1.1757519245147705, GAN loss = [2.4438608, 0.8598105, 0.96858376]\n",
      "Batch 253/700: Discriminator loss = 1.1515499353408813, GAN loss = [2.4349802, 0.905429, 0.9140382]\n",
      "Batch 254/700: Discriminator loss = 1.1677215099334717, GAN loss = [2.4337196, 0.8683959, 0.9498199]\n",
      "Batch 255/700: Discriminator loss = 1.1471385955810547, GAN loss = [2.4266148, 0.9037742, 0.9073449]\n",
      "Batch 256/700: Discriminator loss = 1.1598846912384033, GAN loss = [2.4992306, 0.8898084, 0.9939531]\n",
      "Batch 257/700: Discriminator loss = 1.1423981189727783, GAN loss = [2.465375, 0.9042486, 0.9456698]\n",
      "Batch 258/700: Discriminator loss = 1.1147985458374023, GAN loss = [2.4421499, 0.9478916, 0.87881875]\n",
      "Batch 259/700: Discriminator loss = 1.1152101755142212, GAN loss = [2.497057, 0.93919647, 0.94243455]\n",
      "Batch 260/700: Discriminator loss = 1.1280453205108643, GAN loss = [2.540768, 0.93509513, 0.9902426]\n",
      "Batch 261/700: Discriminator loss = 1.1396044492721558, GAN loss = [2.54182, 0.9065865, 1.0198286]\n",
      "Batch 262/700: Discriminator loss = 1.1352354288101196, GAN loss = [2.483436, 0.9074015, 0.9606754]\n",
      "Batch 263/700: Discriminator loss = 1.1404026746749878, GAN loss = [2.5718672, 0.8973898, 1.0591462]\n",
      "Batch 264/700: Discriminator loss = 1.1223987340927124, GAN loss = [2.5170565, 0.90130293, 1.0004462]\n",
      "Batch 265/700: Discriminator loss = 1.1195898056030273, GAN loss = [2.5000527, 0.89767724, 0.98711854]\n",
      "Batch 266/700: Discriminator loss = 1.1243605613708496, GAN loss = [2.5263147, 0.90623546, 1.0048634]\n",
      "Batch 267/700: Discriminator loss = 1.0995314121246338, GAN loss = [2.5410292, 0.9209712, 1.0048696]\n",
      "Batch 268/700: Discriminator loss = 1.123150110244751, GAN loss = [2.5452375, 0.8974379, 1.03265]\n",
      "Batch 269/700: Discriminator loss = 1.0983754396438599, GAN loss = [2.5965893, 0.9222986, 1.059198]\n",
      "Batch 270/700: Discriminator loss = 1.1028321981430054, GAN loss = [2.570159, 0.91399103, 1.0411456]\n",
      "Batch 271/700: Discriminator loss = 1.1045948266983032, GAN loss = [2.5231092, 0.90722024, 1.0009358]\n",
      "Batch 272/700: Discriminator loss = 1.1274943351745605, GAN loss = [2.4498994, 0.88060224, 0.95440507]\n",
      "Batch 273/700: Discriminator loss = 1.123763084411621, GAN loss = [2.4758587, 0.9033177, 0.9577157]\n",
      "Batch 274/700: Discriminator loss = 1.1132471561431885, GAN loss = [2.555684, 0.89987814, 1.0410562]\n",
      "Batch 275/700: Discriminator loss = 1.1111514568328857, GAN loss = [2.566567, 0.9042522, 1.0476345]\n",
      "Batch 276/700: Discriminator loss = 1.101735234260559, GAN loss = [2.5660641, 0.9119162, 1.0395217]\n",
      "Batch 277/700: Discriminator loss = 1.123595952987671, GAN loss = [2.548954, 0.89288, 1.0414891]\n",
      "Batch 278/700: Discriminator loss = 1.1218146085739136, GAN loss = [2.4936063, 0.9000596, 0.97899735]\n",
      "Batch 279/700: Discriminator loss = 1.1101969480514526, GAN loss = [2.4865787, 0.9010909, 0.97099185]\n",
      "Batch 280/700: Discriminator loss = 1.117253065109253, GAN loss = [2.5022829, 0.89708495, 0.9907373]\n",
      "Batch 281/700: Discriminator loss = 1.1083060503005981, GAN loss = [2.605883, 0.9234252, 1.0680301]\n",
      "Batch 282/700: Discriminator loss = 1.1572751998901367, GAN loss = [2.4754815, 0.8659207, 0.9951753]\n",
      "Batch 283/700: Discriminator loss = 1.1018240451812744, GAN loss = [2.575954, 0.92734754, 1.034261]\n",
      "Batch 284/700: Discriminator loss = 1.1186010837554932, GAN loss = [2.4757311, 0.8911953, 0.9702141]\n",
      "Batch 285/700: Discriminator loss = 1.1479229927062988, GAN loss = [2.4938767, 0.88662857, 0.992929]\n",
      "Batch 286/700: Discriminator loss = 1.1132087707519531, GAN loss = [2.5184422, 0.9010865, 1.0030497]\n",
      "Batch 287/700: Discriminator loss = 1.1279106140136719, GAN loss = [2.4347432, 0.89421237, 0.9262326]\n",
      "Batch 288/700: Discriminator loss = 1.113385558128357, GAN loss = [2.528927, 0.90505, 1.0095807]\n",
      "Batch 289/700: Discriminator loss = 1.1301578283309937, GAN loss = [2.450615, 0.9058878, 0.93042755]\n",
      "Batch 290/700: Discriminator loss = 1.0876648426055908, GAN loss = [2.641672, 0.97500724, 1.0523779]\n",
      "Batch 291/700: Discriminator loss = 1.132951259613037, GAN loss = [2.507258, 0.89602387, 0.99696183]\n",
      "Batch 292/700: Discriminator loss = 1.1191120147705078, GAN loss = [2.428395, 0.89583886, 0.91829467]\n",
      "Batch 293/700: Discriminator loss = 1.1239839792251587, GAN loss = [2.5062213, 0.90601903, 0.98597693]\n",
      "Batch 294/700: Discriminator loss = 1.1112349033355713, GAN loss = [2.6227868, 0.94604975, 1.0625519]\n",
      "Batch 295/700: Discriminator loss = 1.114363193511963, GAN loss = [2.594313, 0.9361594, 1.0440022]\n",
      "Batch 296/700: Discriminator loss = 1.094681739807129, GAN loss = [2.5104039, 0.9485337, 0.947727]\n",
      "Batch 297/700: Discriminator loss = 1.0947411060333252, GAN loss = [2.554242, 0.9426569, 0.9974487]\n",
      "Batch 298/700: Discriminator loss = 1.1022553443908691, GAN loss = [2.5336282, 0.92797357, 0.99153954]\n",
      "Batch 299/700: Discriminator loss = 1.100855827331543, GAN loss = [2.5178318, 0.9265654, 0.9771786]\n",
      "Batch 300/700: Discriminator loss = 1.0960724353790283, GAN loss = [2.5584328, 0.9473549, 0.9970079]\n",
      "Batch 301/700: Discriminator loss = 1.119889497756958, GAN loss = [2.5501733, 0.9364611, 0.99965614]\n",
      "Batch 302/700: Discriminator loss = 1.1417629718780518, GAN loss = [2.474606, 0.89098704, 0.9695656]\n",
      "Batch 303/700: Discriminator loss = 1.1273655891418457, GAN loss = [2.5839965, 0.90220404, 1.0677192]\n",
      "Batch 304/700: Discriminator loss = 1.1468355655670166, GAN loss = [2.5220203, 0.8847804, 1.0231674]\n",
      "Batch 305/700: Discriminator loss = 1.1412569284439087, GAN loss = [2.5622003, 0.96103036, 0.9870933]\n",
      "Batch 306/700: Discriminator loss = 1.1283679008483887, GAN loss = [2.4774177, 0.92949957, 0.9338017]\n",
      "Batch 307/700: Discriminator loss = 1.1340737342834473, GAN loss = [2.5229542, 0.91904837, 0.98977953]\n",
      "Batch 308/700: Discriminator loss = 1.1892216205596924, GAN loss = [2.3719208, 0.8685547, 0.88922983]\n",
      "Batch 309/700: Discriminator loss = 1.1520007848739624, GAN loss = [2.481694, 0.8858719, 0.9816803]\n",
      "Batch 310/700: Discriminator loss = 1.1273694038391113, GAN loss = [2.5791926, 0.9121405, 1.0529087]\n",
      "Batch 311/700: Discriminator loss = 1.1324058771133423, GAN loss = [2.5145133, 0.90628594, 0.9940706]\n",
      "Batch 312/700: Discriminator loss = 1.1343209743499756, GAN loss = [2.482135, 0.9001557, 0.9678148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 313/700: Discriminator loss = 1.1522036790847778, GAN loss = [2.4906814, 0.8897628, 0.9867324]\n",
      "Batch 314/700: Discriminator loss = 1.1304486989974976, GAN loss = [2.619839, 0.913095, 1.0925483]\n",
      "Batch 315/700: Discriminator loss = 1.1306451559066772, GAN loss = [2.5537806, 0.9248363, 1.0147684]\n",
      "Batch 316/700: Discriminator loss = 1.1509710550308228, GAN loss = [2.4803262, 0.9155424, 0.950634]\n",
      "Batch 317/700: Discriminator loss = 1.133183479309082, GAN loss = [2.4595208, 0.9230165, 0.92238474]\n",
      "Batch 318/700: Discriminator loss = 1.0951173305511475, GAN loss = [2.588166, 0.9304442, 1.0436261]\n",
      "Batch 319/700: Discriminator loss = 1.1128120422363281, GAN loss = [2.590914, 0.9324919, 1.0443717]\n",
      "Batch 320/700: Discriminator loss = 1.1432594060897827, GAN loss = [2.6001675, 0.92413867, 1.062028]\n",
      "Batch 321/700: Discriminator loss = 1.117353081703186, GAN loss = [2.5428195, 0.9276497, 1.0012126]\n",
      "Batch 322/700: Discriminator loss = 1.167816400527954, GAN loss = [2.495654, 0.9234376, 0.9582754]\n",
      "Batch 323/700: Discriminator loss = 1.1493136882781982, GAN loss = [2.5663066, 0.9423764, 1.0100143]\n",
      "Batch 324/700: Discriminator loss = 1.1573954820632935, GAN loss = [2.4789507, 0.917344, 0.94773835]\n",
      "Batch 325/700: Discriminator loss = 1.1372673511505127, GAN loss = [2.5885708, 0.9607591, 1.0139915]\n",
      "Batch 326/700: Discriminator loss = 1.1339234113693237, GAN loss = [2.460606, 0.9410354, 0.9057806]\n",
      "Batch 327/700: Discriminator loss = 1.1377408504486084, GAN loss = [2.4744828, 0.9009235, 0.9598005]\n",
      "Batch 328/700: Discriminator loss = 1.1783292293548584, GAN loss = [2.410677, 0.9124091, 0.8845175]\n",
      "Batch 329/700: Discriminator loss = 1.1404569149017334, GAN loss = [2.458799, 0.9280791, 0.91697586]\n",
      "Batch 330/700: Discriminator loss = 1.1585614681243896, GAN loss = [2.40784, 0.90400726, 0.8900991]\n",
      "Batch 331/700: Discriminator loss = 1.1747267246246338, GAN loss = [2.516048, 0.9808632, 0.92146975]\n",
      "Batch 332/700: Discriminator loss = 1.1602058410644531, GAN loss = [2.4925094, 0.9292823, 0.9494743]\n",
      "Batch 333/700: Discriminator loss = 1.1744506359100342, GAN loss = [2.3867912, 0.90036637, 0.87262607]\n",
      "Batch 334/700: Discriminator loss = 1.178059458732605, GAN loss = [2.4043362, 0.92415166, 0.8663372]\n",
      "Batch 335/700: Discriminator loss = 1.1884584426879883, GAN loss = [2.4177873, 0.9067946, 0.8970959]\n",
      "Batch 336/700: Discriminator loss = 1.1573251485824585, GAN loss = [2.362379, 0.8908194, 0.8576223]\n",
      "Batch 337/700: Discriminator loss = 1.1502480506896973, GAN loss = [2.376614, 0.9061928, 0.85646707]\n",
      "Batch 338/700: Discriminator loss = 1.172288179397583, GAN loss = [2.3761225, 0.8878319, 0.87434006]\n",
      "Batch 339/700: Discriminator loss = 1.1686184406280518, GAN loss = [2.4201643, 0.898355, 0.90783453]\n",
      "Batch 340/700: Discriminator loss = 1.162630558013916, GAN loss = [2.4470942, 0.906762, 0.92626727]\n",
      "Batch 341/700: Discriminator loss = 1.1662541627883911, GAN loss = [2.3490994, 0.87640494, 0.8585526]\n",
      "Batch 342/700: Discriminator loss = 1.1412758827209473, GAN loss = [2.4396245, 0.8847261, 0.9407155]\n",
      "Batch 343/700: Discriminator loss = 1.1521315574645996, GAN loss = [2.4697034, 0.9066129, 0.9488975]\n",
      "Batch 344/700: Discriminator loss = 1.1741275787353516, GAN loss = [2.383807, 0.8681253, 0.90145755]\n",
      "Batch 345/700: Discriminator loss = 1.1626206636428833, GAN loss = [2.4843004, 0.8990767, 0.9710022]\n",
      "Batch 346/700: Discriminator loss = 1.106309175491333, GAN loss = [2.5396357, 0.97187215, 0.95354193]\n",
      "Batch 347/700: Discriminator loss = 1.1438716650009155, GAN loss = [2.455411, 0.9020351, 0.9391596]\n",
      "Batch 348/700: Discriminator loss = 1.1463823318481445, GAN loss = [2.453341, 0.92517745, 0.91397095]\n",
      "Batch 349/700: Discriminator loss = 1.1619044542312622, GAN loss = [2.4634938, 0.8907148, 0.95856375]\n",
      "Batch 350/700: Discriminator loss = 1.1359015703201294, GAN loss = [2.5729244, 0.9521221, 1.0065651]\n",
      "Batch 351/700: Discriminator loss = 1.146565556526184, GAN loss = [2.5506158, 0.90135217, 1.0349923]\n",
      "Batch 352/700: Discriminator loss = 1.1461882591247559, GAN loss = [2.5584786, 0.90354425, 1.040648]\n",
      "Batch 353/700: Discriminator loss = 1.119688630104065, GAN loss = [2.5253544, 0.94127536, 0.96975154]\n",
      "Batch 354/700: Discriminator loss = 1.1608989238739014, GAN loss = [2.4333332, 0.8925313, 0.92646044]\n",
      "Batch 355/700: Discriminator loss = 1.1878291368484497, GAN loss = [2.341544, 0.8773436, 0.8498738]\n",
      "Batch 356/700: Discriminator loss = 1.1841739416122437, GAN loss = [2.4587164, 0.90494025, 0.93946123]\n",
      "Batch 357/700: Discriminator loss = 1.1664695739746094, GAN loss = [2.4517035, 0.87675995, 0.96063447]\n",
      "Batch 358/700: Discriminator loss = 1.2014271020889282, GAN loss = [2.4799933, 0.8760408, 0.98967195]\n",
      "Batch 359/700: Discriminator loss = 1.1695343255996704, GAN loss = [2.557438, 0.93806124, 1.0051181]\n",
      "Batch 360/700: Discriminator loss = 1.1633574962615967, GAN loss = [2.4059289, 0.90626264, 0.88539314]\n",
      "Batch 361/700: Discriminator loss = 1.149317741394043, GAN loss = [2.4979067, 0.8994419, 0.98415464]\n",
      "Batch 362/700: Discriminator loss = 1.1466437578201294, GAN loss = [2.4836571, 0.92076856, 0.94854677]\n",
      "Batch 363/700: Discriminator loss = 1.1613227128982544, GAN loss = [2.3601398, 0.87602204, 0.86978185]\n",
      "Batch 364/700: Discriminator loss = 1.155616283416748, GAN loss = [2.4328852, 0.93833435, 0.8802128]\n",
      "Batch 365/700: Discriminator loss = 1.1437277793884277, GAN loss = [2.4710128, 0.91223013, 0.9444324]\n",
      "Batch 366/700: Discriminator loss = 1.1405589580535889, GAN loss = [2.4414308, 0.90443563, 0.9226396]\n",
      "Batch 367/700: Discriminator loss = 1.136149287223816, GAN loss = [2.3946073, 0.90421927, 0.87601066]\n",
      "Batch 368/700: Discriminator loss = 1.153313398361206, GAN loss = [2.4045494, 0.87139374, 0.91873205]\n",
      "Batch 369/700: Discriminator loss = 1.1624513864517212, GAN loss = [2.422828, 0.86263925, 0.9457556]\n",
      "Batch 370/700: Discriminator loss = 1.1582001447677612, GAN loss = [2.4418223, 0.846587, 0.9807813]\n",
      "Batch 371/700: Discriminator loss = 1.181897521018982, GAN loss = [2.3417478, 0.83717346, 0.8901002]\n",
      "Batch 372/700: Discriminator loss = 1.1706219911575317, GAN loss = [2.4384868, 0.8775468, 0.94641066]\n",
      "Batch 373/700: Discriminator loss = 1.1666768789291382, GAN loss = [2.4370134, 0.8482664, 0.97418517]\n",
      "Batch 374/700: Discriminator loss = 1.132588267326355, GAN loss = [2.41861, 0.8703835, 0.93367475]\n",
      "Batch 375/700: Discriminator loss = 1.1590908765792847, GAN loss = [2.42113, 0.86781, 0.9387547]\n",
      "Batch 376/700: Discriminator loss = 1.178132176399231, GAN loss = [2.3793182, 0.82633054, 0.93838483]\n",
      "Batch 377/700: Discriminator loss = 1.177960991859436, GAN loss = [2.4113247, 0.8330497, 0.9636323]\n",
      "Batch 378/700: Discriminator loss = 1.1505012512207031, GAN loss = [2.3435464, 0.840528, 0.8883431]\n",
      "Batch 379/700: Discriminator loss = 1.1850957870483398, GAN loss = [2.3388972, 0.8115954, 0.9126152]\n",
      "Batch 380/700: Discriminator loss = 1.1617923974990845, GAN loss = [2.4274194, 0.8552554, 0.9574519]\n",
      "Batch 381/700: Discriminator loss = 1.1951229572296143, GAN loss = [2.4777253, 0.84847087, 1.0145022]\n",
      "Batch 382/700: Discriminator loss = 1.151876449584961, GAN loss = [2.4131207, 0.87075806, 0.92759347]\n",
      "Batch 383/700: Discriminator loss = 1.1288641691207886, GAN loss = [2.4075425, 0.89599234, 0.8967729]\n",
      "Batch 384/700: Discriminator loss = 1.1597400903701782, GAN loss = [2.3709917, 0.8547617, 0.9014511]\n",
      "Batch 385/700: Discriminator loss = 1.1540313959121704, GAN loss = [2.3909361, 0.8744577, 0.9016626]\n",
      "Batch 386/700: Discriminator loss = 1.1729544401168823, GAN loss = [2.4934375, 0.84785265, 1.0307078]\n",
      "Batch 387/700: Discriminator loss = 1.133670449256897, GAN loss = [2.4729424, 0.8982326, 0.95978576]\n",
      "Batch 388/700: Discriminator loss = 1.1439207792282104, GAN loss = [2.4274347, 0.8729526, 0.9395228]\n",
      "Batch 389/700: Discriminator loss = 1.1352660655975342, GAN loss = [2.4432878, 0.87864244, 0.94968796]\n",
      "Batch 390/700: Discriminator loss = 1.1609578132629395, GAN loss = [2.491075, 0.8540647, 1.0220506]\n",
      "Batch 391/700: Discriminator loss = 1.1683353185653687, GAN loss = [2.4570076, 0.84782934, 0.9941856]\n",
      "Batch 392/700: Discriminator loss = 1.1615841388702393, GAN loss = [2.4425914, 0.87374014, 0.9538264]\n",
      "Batch 393/700: Discriminator loss = 1.1827521324157715, GAN loss = [2.505541, 0.8499033, 1.0405902]\n",
      "Batch 394/700: Discriminator loss = 1.1607966423034668, GAN loss = [2.4861372, 0.8700327, 1.0010272]\n",
      "Batch 395/700: Discriminator loss = 1.1345489025115967, GAN loss = [2.5712645, 0.9247409, 1.0314182]\n",
      "Batch 396/700: Discriminator loss = 1.1229524612426758, GAN loss = [2.503754, 0.9019133, 0.98670024]\n",
      "Batch 397/700: Discriminator loss = 1.1860060691833496, GAN loss = [2.3597612, 0.8855747, 0.85900366]\n",
      "Batch 398/700: Discriminator loss = 1.1493275165557861, GAN loss = [2.4545715, 0.8638935, 0.9754671]\n",
      "Batch 399/700: Discriminator loss = 1.1295905113220215, GAN loss = [2.4274874, 0.89526945, 0.916983]\n",
      "Batch 400/700: Discriminator loss = 1.1986243724822998, GAN loss = [2.4660633, 0.86737704, 0.98341715]\n",
      "Batch 401/700: Discriminator loss = 1.1518323421478271, GAN loss = [2.461636, 0.8775295, 0.9687963]\n",
      "Batch 402/700: Discriminator loss = 1.163522481918335, GAN loss = [2.4797406, 0.89191824, 0.9724653]\n",
      "Batch 403/700: Discriminator loss = 1.1545329093933105, GAN loss = [2.4694397, 0.8753245, 0.9787217]\n",
      "Batch 404/700: Discriminator loss = 1.158522605895996, GAN loss = [2.4194841, 0.86438453, 0.9396799]\n",
      "Batch 405/700: Discriminator loss = 1.1655030250549316, GAN loss = [2.4559958, 0.8586088, 0.98195195]\n",
      "Batch 406/700: Discriminator loss = 1.145302414894104, GAN loss = [2.4405637, 0.87248766, 0.952598]\n",
      "Batch 407/700: Discriminator loss = 1.1395940780639648, GAN loss = [2.4201984, 0.8746382, 0.9300348]\n",
      "Batch 408/700: Discriminator loss = 1.1824853420257568, GAN loss = [2.492494, 0.88127446, 0.9956667]\n",
      "Batch 409/700: Discriminator loss = 1.1254794597625732, GAN loss = [2.5816092, 0.8822574, 1.0837567]\n",
      "Batch 410/700: Discriminator loss = 1.1637579202651978, GAN loss = [2.4536138, 0.86858565, 0.96937644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 411/700: Discriminator loss = 1.1291499137878418, GAN loss = [2.4816518, 0.8918338, 0.97410524]\n",
      "Batch 412/700: Discriminator loss = 1.1234087944030762, GAN loss = [2.4036045, 0.8808235, 0.90696335]\n",
      "Batch 413/700: Discriminator loss = 1.146332859992981, GAN loss = [2.5824313, 0.8857108, 1.0808353]\n",
      "Batch 414/700: Discriminator loss = 1.1268304586410522, GAN loss = [2.4709988, 0.86943686, 0.98563826]\n",
      "Batch 415/700: Discriminator loss = 1.1434381008148193, GAN loss = [2.6052654, 0.8924437, 1.0968487]\n",
      "Batch 416/700: Discriminator loss = 1.1213041543960571, GAN loss = [2.525638, 0.8812967, 1.0283308]\n",
      "Batch 417/700: Discriminator loss = 1.1176644563674927, GAN loss = [2.518662, 0.8925515, 1.010062]\n",
      "Batch 418/700: Discriminator loss = 1.1248860359191895, GAN loss = [2.5015085, 0.88924927, 0.99618226]\n",
      "Batch 419/700: Discriminator loss = 1.1323885917663574, GAN loss = [2.5444953, 0.8679441, 1.0604639]\n",
      "Batch 420/700: Discriminator loss = 1.1036163568496704, GAN loss = [2.697915, 0.92739713, 1.1544061]\n",
      "Batch 421/700: Discriminator loss = 1.1132246255874634, GAN loss = [2.5434694, 0.91002464, 1.0172751]\n",
      "Batch 422/700: Discriminator loss = 1.1109966039657593, GAN loss = [2.5386424, 0.8970467, 1.0253661]\n",
      "Batch 423/700: Discriminator loss = 1.1494815349578857, GAN loss = [2.4685123, 0.8725883, 0.979662]\n",
      "Batch 424/700: Discriminator loss = 1.126754879951477, GAN loss = [2.5120144, 0.8731874, 1.0225501]\n",
      "Batch 425/700: Discriminator loss = 1.1368346214294434, GAN loss = [2.5782082, 0.8967257, 1.0652137]\n",
      "Batch 426/700: Discriminator loss = 1.1137560606002808, GAN loss = [2.5992422, 0.91333854, 1.0696328]\n",
      "Batch 427/700: Discriminator loss = 1.1174906492233276, GAN loss = [2.6092513, 0.90206796, 1.0909035]\n",
      "Batch 428/700: Discriminator loss = 1.0948995351791382, GAN loss = [2.553181, 0.894807, 1.0420914]\n",
      "Batch 429/700: Discriminator loss = 1.123157262802124, GAN loss = [2.4847522, 0.8544948, 1.0139611]\n",
      "Batch 430/700: Discriminator loss = 1.1073899269104004, GAN loss = [2.6166646, 0.8961661, 1.1041871]\n",
      "Batch 431/700: Discriminator loss = 1.1398504972457886, GAN loss = [2.5841498, 0.8736367, 1.0941728]\n",
      "Batch 432/700: Discriminator loss = 1.1270840167999268, GAN loss = [2.5604827, 0.8671312, 1.0770006]\n",
      "Batch 433/700: Discriminator loss = 1.1091820001602173, GAN loss = [2.6096685, 0.89795905, 1.0953745]\n",
      "Batch 434/700: Discriminator loss = 1.117296576499939, GAN loss = [2.6199172, 0.8858237, 1.1177598]\n",
      "Batch 435/700: Discriminator loss = 1.125309944152832, GAN loss = [2.59069, 0.88326764, 1.0910792]\n",
      "Batch 436/700: Discriminator loss = 1.1459741592407227, GAN loss = [2.5647566, 0.86272985, 1.0856938]\n",
      "Batch 437/700: Discriminator loss = 1.123849630355835, GAN loss = [2.5775092, 0.8988464, 1.0623466]\n",
      "Batch 438/700: Discriminator loss = 1.1540091037750244, GAN loss = [2.5269084, 0.8809046, 1.0297295]\n",
      "Batch 439/700: Discriminator loss = 1.1219655275344849, GAN loss = [2.558486, 0.89609957, 1.046107]\n",
      "Batch 440/700: Discriminator loss = 1.153210163116455, GAN loss = [2.4379337, 0.872336, 0.94931877]\n",
      "Batch 441/700: Discriminator loss = 1.1485357284545898, GAN loss = [2.5051076, 0.86887723, 1.019957]\n",
      "Batch 442/700: Discriminator loss = 1.1285945177078247, GAN loss = [2.6513803, 0.8901503, 1.1449424]\n",
      "Batch 443/700: Discriminator loss = 1.1921420097351074, GAN loss = [2.5230267, 0.8698319, 1.0368861]\n",
      "Batch 444/700: Discriminator loss = 1.1448289155960083, GAN loss = [2.4993124, 0.8989603, 0.9840374]\n",
      "Batch 445/700: Discriminator loss = 1.1497514247894287, GAN loss = [2.5111442, 0.871405, 1.0233891]\n",
      "Batch 446/700: Discriminator loss = 1.1963558197021484, GAN loss = [2.4424481, 0.8292817, 0.9968041]\n",
      "Batch 447/700: Discriminator loss = 1.1604361534118652, GAN loss = [2.430794, 0.8613025, 0.9531361]\n",
      "Batch 448/700: Discriminator loss = 1.1665570735931396, GAN loss = [2.4420288, 0.8566883, 0.96898043]\n",
      "Batch 449/700: Discriminator loss = 1.1653846502304077, GAN loss = [2.484047, 0.8613518, 1.0063223]\n",
      "Batch 450/700: Discriminator loss = 1.1237815618515015, GAN loss = [2.502189, 0.89774656, 0.98805815]\n",
      "Batch 451/700: Discriminator loss = 1.1329394578933716, GAN loss = [2.5019572, 0.8769766, 1.0085791]\n",
      "Batch 452/700: Discriminator loss = 1.1591042280197144, GAN loss = [2.412106, 0.8743066, 0.9213908]\n",
      "Batch 453/700: Discriminator loss = 1.1174912452697754, GAN loss = [2.4742787, 0.90584296, 0.9520316]\n",
      "Batch 454/700: Discriminator loss = 1.131463646888733, GAN loss = [2.5379562, 0.9178417, 1.0037216]\n",
      "Batch 455/700: Discriminator loss = 1.1037875413894653, GAN loss = [2.583484, 0.92454726, 1.0425291]\n",
      "Batch 456/700: Discriminator loss = 1.0985928773880005, GAN loss = [2.55332, 0.9429732, 0.99392396]\n",
      "Batch 457/700: Discriminator loss = 1.1016370058059692, GAN loss = [2.55174, 0.9341929, 1.0011032]\n",
      "Batch 458/700: Discriminator loss = 1.1196706295013428, GAN loss = [2.4828968, 0.9143401, 0.95209855]\n",
      "Batch 459/700: Discriminator loss = 1.104199767112732, GAN loss = [2.6384714, 0.9393224, 1.0826483]\n",
      "Batch 460/700: Discriminator loss = 1.130666732788086, GAN loss = [2.5442, 0.89728117, 1.0303727]\n",
      "Batch 461/700: Discriminator loss = 1.1031078100204468, GAN loss = [2.5744102, 0.9346369, 1.0232017]\n",
      "Batch 462/700: Discriminator loss = 1.1002132892608643, GAN loss = [2.581008, 0.93482, 1.0295652]\n",
      "Batch 463/700: Discriminator loss = 1.115707516670227, GAN loss = [2.5515351, 0.9138966, 1.0210044]\n",
      "Batch 464/700: Discriminator loss = 1.119071125984192, GAN loss = [2.4500713, 0.906157, 0.92726386]\n",
      "Batch 465/700: Discriminator loss = 1.1344696283340454, GAN loss = [2.466183, 0.9209497, 0.9285739]\n",
      "Batch 466/700: Discriminator loss = 1.1204177141189575, GAN loss = [2.6078632, 0.9229655, 1.0682274]\n",
      "Batch 467/700: Discriminator loss = 1.1169233322143555, GAN loss = [2.5639162, 0.9135763, 1.03363]\n",
      "Batch 468/700: Discriminator loss = 1.1552419662475586, GAN loss = [2.4890983, 0.87939143, 0.99298155]\n",
      "Batch 469/700: Discriminator loss = 1.108617901802063, GAN loss = [2.5067184, 0.9259853, 0.9639748]\n",
      "Batch 470/700: Discriminator loss = 1.1300816535949707, GAN loss = [2.4827256, 0.9016156, 0.9643441]\n",
      "Batch 471/700: Discriminator loss = 1.125437617301941, GAN loss = [2.563005, 0.91798806, 1.0282663]\n",
      "Batch 472/700: Discriminator loss = 1.1132804155349731, GAN loss = [2.5422857, 0.90751755, 1.018014]\n",
      "Batch 473/700: Discriminator loss = 1.117868423461914, GAN loss = [2.5098426, 0.91851103, 0.974542]\n",
      "Batch 474/700: Discriminator loss = 1.114250659942627, GAN loss = [2.5918808, 0.9026463, 1.0724237]\n",
      "Batch 475/700: Discriminator loss = 1.1493165493011475, GAN loss = [2.5277586, 0.8818672, 1.0290475]\n",
      "Batch 476/700: Discriminator loss = 1.15663480758667, GAN loss = [2.4313302, 0.88956916, 0.9248779]\n",
      "Batch 477/700: Discriminator loss = 1.1278079748153687, GAN loss = [2.538736, 0.93058294, 0.991246]\n",
      "Batch 478/700: Discriminator loss = 1.1150389909744263, GAN loss = [2.5545433, 0.91991496, 1.0176901]\n",
      "Batch 479/700: Discriminator loss = 1.138019323348999, GAN loss = [2.5929458, 0.89268243, 1.0832971]\n",
      "Batch 480/700: Discriminator loss = 1.1578490734100342, GAN loss = [2.5135164, 0.8997158, 0.9968114]\n",
      "Batch 481/700: Discriminator loss = 1.1707661151885986, GAN loss = [2.4526043, 0.8830379, 0.9525341]\n",
      "Batch 482/700: Discriminator loss = 1.134935975074768, GAN loss = [2.4315822, 0.89140123, 0.9231115]\n",
      "Batch 483/700: Discriminator loss = 1.1418895721435547, GAN loss = [2.5869596, 0.9275275, 1.0423398]\n",
      "Batch 484/700: Discriminator loss = 1.1605448722839355, GAN loss = [2.4844487, 0.8675948, 0.9997217]\n",
      "Batch 485/700: Discriminator loss = 1.1393202543258667, GAN loss = [2.50028, 0.89549476, 0.9876347]\n",
      "Batch 486/700: Discriminator loss = 1.1279783248901367, GAN loss = [2.4247208, 0.8996042, 0.9079535]\n",
      "Batch 487/700: Discriminator loss = 1.1166462898254395, GAN loss = [2.5455143, 0.9235689, 1.0047787]\n",
      "Batch 488/700: Discriminator loss = 1.1136231422424316, GAN loss = [2.4893982, 0.8968272, 0.9754031]\n",
      "Batch 489/700: Discriminator loss = 1.1016453504562378, GAN loss = [2.7027476, 0.9709181, 1.114654]\n",
      "Batch 490/700: Discriminator loss = 1.0932823419570923, GAN loss = [2.597179, 0.94071, 1.0392998]\n",
      "Batch 491/700: Discriminator loss = 1.076170802116394, GAN loss = [2.6265495, 0.9682876, 1.0410812]\n",
      "Batch 492/700: Discriminator loss = 1.1192963123321533, GAN loss = [2.5090587, 0.9140285, 0.9778267]\n",
      "Batch 493/700: Discriminator loss = 1.093866229057312, GAN loss = [2.5870936, 0.92317736, 1.0467192]\n",
      "Batch 494/700: Discriminator loss = 1.1006138324737549, GAN loss = [2.518446, 0.92777014, 0.97347915]\n",
      "Batch 495/700: Discriminator loss = 1.1273516416549683, GAN loss = [2.5361836, 0.90761095, 1.0113868]\n",
      "Batch 496/700: Discriminator loss = 1.1178117990493774, GAN loss = [2.578817, 0.9013107, 1.0603356]\n",
      "Batch 497/700: Discriminator loss = 1.122759222984314, GAN loss = [2.5489619, 0.88997877, 1.041813]\n",
      "Batch 498/700: Discriminator loss = 1.1309404373168945, GAN loss = [2.6091993, 0.89148504, 1.1005259]\n",
      "Batch 499/700: Discriminator loss = 1.1214314699172974, GAN loss = [2.558938, 0.8981876, 1.0435548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/700: Discriminator loss = 1.1567012071609497, GAN loss = [2.5941799, 0.932163, 1.0447876]\n",
      "Batch 501/700: Discriminator loss = 1.1276246309280396, GAN loss = [2.5629027, 0.93296564, 1.0126445]\n",
      "Batch 502/700: Discriminator loss = 1.1127828359603882, GAN loss = [2.5516546, 0.9409376, 0.9933947]\n",
      "Batch 503/700: Discriminator loss = 1.1356241703033447, GAN loss = [2.550998, 0.8939301, 1.0397414]\n",
      "Batch 504/700: Discriminator loss = 1.151157259941101, GAN loss = [2.5444345, 0.8942242, 1.0328419]\n",
      "Batch 505/700: Discriminator loss = 1.136220932006836, GAN loss = [2.524883, 0.9215671, 0.9859202]\n",
      "Batch 506/700: Discriminator loss = 1.145426869392395, GAN loss = [2.5729089, 0.88470536, 1.0707884]\n",
      "Batch 507/700: Discriminator loss = 1.1982901096343994, GAN loss = [2.5561557, 0.8521224, 1.0865829]\n",
      "Batch 508/700: Discriminator loss = 1.1532506942749023, GAN loss = [2.4928575, 0.88351804, 0.99187624]\n",
      "Batch 509/700: Discriminator loss = 1.12894868850708, GAN loss = [2.6100345, 0.9057114, 1.0868413]\n",
      "Batch 510/700: Discriminator loss = 1.1331524848937988, GAN loss = [2.657972, 0.89752734, 1.1429541]\n",
      "Batch 511/700: Discriminator loss = 1.1160106658935547, GAN loss = [2.6434636, 0.9163555, 1.1095903]\n",
      "Batch 512/700: Discriminator loss = 1.1477409601211548, GAN loss = [2.6938243, 0.90152496, 1.1747805]\n",
      "Batch 513/700: Discriminator loss = 1.118483304977417, GAN loss = [2.6360102, 0.9296138, 1.0888482]\n",
      "Batch 514/700: Discriminator loss = 1.1274206638336182, GAN loss = [2.6380572, 0.90398765, 1.1164881]\n",
      "Batch 515/700: Discriminator loss = 1.1312981843948364, GAN loss = [2.716127, 0.90429425, 1.1941961]\n",
      "Batch 516/700: Discriminator loss = 1.1456762552261353, GAN loss = [2.6266897, 0.8873032, 1.1217301]\n",
      "Batch 517/700: Discriminator loss = 1.1394083499908447, GAN loss = [2.578628, 0.9136661, 1.0472751]\n",
      "Batch 518/700: Discriminator loss = 1.149093747138977, GAN loss = [2.4915392, 0.88869256, 0.98514366]\n",
      "Batch 519/700: Discriminator loss = 1.109400987625122, GAN loss = [2.6459987, 0.94889015, 1.0793796]\n",
      "Batch 520/700: Discriminator loss = 1.1456245183944702, GAN loss = [2.4606843, 0.914984, 0.9279631]\n",
      "Batch 521/700: Discriminator loss = 1.1253598928451538, GAN loss = [2.643729, 0.9149944, 1.1109871]\n",
      "Batch 522/700: Discriminator loss = 1.1190487146377563, GAN loss = [2.5536878, 0.9022299, 1.0336953]\n",
      "Batch 523/700: Discriminator loss = 1.102588176727295, GAN loss = [2.6999252, 0.948104, 1.1340231]\n",
      "Batch 524/700: Discriminator loss = 1.1345609426498413, GAN loss = [2.5480933, 0.8945817, 1.0356966]\n",
      "Batch 525/700: Discriminator loss = 1.126286268234253, GAN loss = [2.5626996, 0.9092165, 1.0356553]\n",
      "Batch 526/700: Discriminator loss = 1.1065289974212646, GAN loss = [2.685229, 0.926567, 1.1408019]\n",
      "Batch 527/700: Discriminator loss = 1.1370213031768799, GAN loss = [2.7608147, 0.90257215, 1.2403588]\n",
      "Batch 528/700: Discriminator loss = 1.1146098375320435, GAN loss = [2.7074623, 0.92563456, 1.1639172]\n",
      "Batch 529/700: Discriminator loss = 1.1266883611679077, GAN loss = [2.5873153, 0.91559595, 1.0537882]\n",
      "Batch 530/700: Discriminator loss = 1.1017552614212036, GAN loss = [2.5861452, 0.94621813, 1.0219749]\n",
      "Batch 531/700: Discriminator loss = 1.1030309200286865, GAN loss = [2.6795318, 0.9523851, 1.1091729]\n",
      "Batch 532/700: Discriminator loss = 1.0921590328216553, GAN loss = [2.7167387, 0.95393753, 1.1447762]\n",
      "Batch 533/700: Discriminator loss = 1.092384934425354, GAN loss = [2.866591, 0.95801073, 1.2904822]\n",
      "Batch 534/700: Discriminator loss = 1.108837366104126, GAN loss = [2.6603606, 0.9470601, 1.0951207]\n",
      "Batch 535/700: Discriminator loss = 1.136004090309143, GAN loss = [2.5514321, 0.92048734, 1.0127268]\n",
      "Batch 536/700: Discriminator loss = 1.1068482398986816, GAN loss = [2.828277, 0.9452904, 1.2647473]\n",
      "Batch 537/700: Discriminator loss = 1.117039442062378, GAN loss = [2.6519501, 0.9355987, 1.098103]\n",
      "Batch 538/700: Discriminator loss = 1.1037726402282715, GAN loss = [2.5851138, 0.95279914, 1.0140444]\n",
      "Batch 539/700: Discriminator loss = 1.0821254253387451, GAN loss = [2.6577492, 0.946669, 1.0928146]\n",
      "Batch 540/700: Discriminator loss = 1.0784536600112915, GAN loss = [2.630848, 0.95770425, 1.0549148]\n",
      "Batch 541/700: Discriminator loss = 1.0673370361328125, GAN loss = [2.6393414, 0.9683731, 1.0527645]\n",
      "Batch 542/700: Discriminator loss = 1.0817415714263916, GAN loss = [2.770485, 0.946276, 1.2060323]\n",
      "Batch 543/700: Discriminator loss = 1.0592578649520874, GAN loss = [2.672368, 0.95224863, 1.1019158]\n",
      "Batch 544/700: Discriminator loss = 1.0784584283828735, GAN loss = [2.7040122, 0.9497569, 1.1360255]\n",
      "Batch 545/700: Discriminator loss = 1.0720207691192627, GAN loss = [2.8152916, 0.9494202, 1.2476422]\n",
      "Batch 546/700: Discriminator loss = 1.08086359500885, GAN loss = [2.6353137, 0.946736, 1.0703431]\n",
      "Batch 547/700: Discriminator loss = 1.0735689401626587, GAN loss = [2.7966685, 0.93701535, 1.241379]\n",
      "Batch 548/700: Discriminator loss = 1.0945230722427368, GAN loss = [2.7585874, 0.9412709, 1.1990097]\n",
      "Batch 549/700: Discriminator loss = 1.0621342658996582, GAN loss = [2.8679917, 0.9738781, 1.2757738]\n",
      "Batch 550/700: Discriminator loss = 1.0823887586593628, GAN loss = [2.8086386, 0.95475054, 1.2355539]\n",
      "Batch 551/700: Discriminator loss = 1.0655286312103271, GAN loss = [2.7241197, 0.9488087, 1.1569768]\n",
      "Batch 552/700: Discriminator loss = 1.0716400146484375, GAN loss = [2.865259, 0.9629299, 1.2840009]\n",
      "Batch 553/700: Discriminator loss = 1.0608441829681396, GAN loss = [2.9318924, 0.98800105, 1.3255466]\n",
      "Batch 554/700: Discriminator loss = 1.066045880317688, GAN loss = [2.7725565, 0.9756963, 1.1785163]\n",
      "Batch 555/700: Discriminator loss = 1.0902001857757568, GAN loss = [2.650979, 0.93838364, 1.0942248]\n",
      "Batch 556/700: Discriminator loss = 1.0564149618148804, GAN loss = [2.9816785, 0.97591394, 1.3873816]\n",
      "Batch 557/700: Discriminator loss = 1.0637314319610596, GAN loss = [2.7947824, 0.9607048, 1.2156528]\n",
      "Batch 558/700: Discriminator loss = 1.0421416759490967, GAN loss = [2.8397686, 0.9969728, 1.2243438]\n",
      "Batch 559/700: Discriminator loss = 1.0728163719177246, GAN loss = [2.8430548, 0.96054655, 1.2640419]\n",
      "Batch 560/700: Discriminator loss = 1.06052565574646, GAN loss = [2.7607293, 0.9660579, 1.1761749]\n",
      "Batch 561/700: Discriminator loss = 1.0582334995269775, GAN loss = [2.7839863, 0.9605576, 1.2049011]\n",
      "Batch 562/700: Discriminator loss = 1.0568767786026, GAN loss = [2.984061, 0.9761598, 1.3893456]\n",
      "Batch 563/700: Discriminator loss = 1.0783967971801758, GAN loss = [2.9270716, 0.9703659, 1.3381239]\n",
      "Batch 564/700: Discriminator loss = 1.0596730709075928, GAN loss = [2.944642, 0.98260194, 1.3434281]\n",
      "Batch 565/700: Discriminator loss = 1.0754050016403198, GAN loss = [2.79624, 0.9810399, 1.1965598]\n",
      "Batch 566/700: Discriminator loss = 1.0939624309539795, GAN loss = [2.9162223, 0.9533185, 1.3442256]\n",
      "Batch 567/700: Discriminator loss = 1.0879806280136108, GAN loss = [2.8759117, 0.95394236, 1.3032771]\n",
      "Batch 568/700: Discriminator loss = 1.062943935394287, GAN loss = [2.6859188, 0.9691018, 1.0981147]\n",
      "Batch 569/700: Discriminator loss = 1.0497912168502808, GAN loss = [2.7975917, 0.9799077, 1.1989678]\n",
      "Batch 570/700: Discriminator loss = 1.071936011314392, GAN loss = [2.9891095, 0.9592279, 1.4111553]\n",
      "Batch 571/700: Discriminator loss = 1.03947114944458, GAN loss = [3.041119, 1.0067475, 1.4156129]\n",
      "Batch 572/700: Discriminator loss = 1.0371226072311401, GAN loss = [3.05021, 1.0088271, 1.4226118]\n",
      "Batch 573/700: Discriminator loss = 1.0395514965057373, GAN loss = [3.2114842, 1.0258877, 1.5668122]\n",
      "Batch 574/700: Discriminator loss = 1.062896490097046, GAN loss = [2.8113348, 1.0072998, 1.1852233]\n",
      "Batch 575/700: Discriminator loss = 1.0474872589111328, GAN loss = [3.0907302, 1.0290908, 1.4428159]\n",
      "Batch 576/700: Discriminator loss = 1.0734978914260864, GAN loss = [2.7418087, 0.9688523, 1.154143]\n",
      "Batch 577/700: Discriminator loss = 1.0647263526916504, GAN loss = [2.7822516, 1.0007446, 1.1626941]\n",
      "Batch 578/700: Discriminator loss = 1.0880954265594482, GAN loss = [2.8603203, 0.96055436, 1.280935]\n",
      "Batch 579/700: Discriminator loss = 1.1188324689865112, GAN loss = [2.8379178, 0.9483905, 1.2706764]\n",
      "Batch 580/700: Discriminator loss = 1.1243644952774048, GAN loss = [2.8044097, 0.967847, 1.2176827]\n",
      "Batch 581/700: Discriminator loss = 1.120275855064392, GAN loss = [3.1838827, 0.98952377, 1.5754483]\n",
      "Batch 582/700: Discriminator loss = 1.1015214920043945, GAN loss = [2.7603354, 0.96628, 1.1750859]\n",
      "Batch 583/700: Discriminator loss = 1.1356663703918457, GAN loss = [2.7360725, 0.947957, 1.169106]\n",
      "Batch 584/700: Discriminator loss = 1.1279716491699219, GAN loss = [2.7665231, 0.9438627, 1.20362]\n",
      "Batch 585/700: Discriminator loss = 1.1738747358322144, GAN loss = [2.82987, 0.9381262, 1.2726611]\n",
      "Batch 586/700: Discriminator loss = 1.1542590856552124, GAN loss = [2.6493948, 0.93813276, 1.092127]\n",
      "Batch 587/700: Discriminator loss = 1.1514707803726196, GAN loss = [2.857566, 0.9765783, 1.2617803]\n",
      "Batch 588/700: Discriminator loss = 1.1426926851272583, GAN loss = [2.6899765, 0.9733987, 1.0972863]\n",
      "Batch 589/700: Discriminator loss = 1.2158540487289429, GAN loss = [2.5783246, 0.9061903, 1.0527607]\n",
      "Batch 590/700: Discriminator loss = 1.1530039310455322, GAN loss = [2.762433, 0.9466312, 1.1963801]\n",
      "Batch 591/700: Discriminator loss = 1.1796845197677612, GAN loss = [2.5440419, 0.9159448, 1.0086042]\n",
      "Batch 592/700: Discriminator loss = 1.1932625770568848, GAN loss = [2.5835266, 0.952412, 1.0115539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 593/700: Discriminator loss = 1.181482195854187, GAN loss = [2.57757, 0.92923194, 1.028668]\n",
      "Batch 594/700: Discriminator loss = 1.1845539808273315, GAN loss = [2.6253662, 1.0318894, 0.9737355]\n",
      "Batch 595/700: Discriminator loss = 1.1937434673309326, GAN loss = [2.5957153, 0.99005425, 0.9858522]\n",
      "Batch 596/700: Discriminator loss = 1.215474009513855, GAN loss = [2.5938509, 0.942981, 1.0309668]\n",
      "Batch 597/700: Discriminator loss = 1.1774705648422241, GAN loss = [2.5951545, 0.9533272, 1.0218202]\n",
      "Batch 598/700: Discriminator loss = 1.240857481956482, GAN loss = [2.4968204, 0.90959686, 0.9671053]\n",
      "Batch 599/700: Discriminator loss = 1.228838562965393, GAN loss = [2.4453082, 0.9067938, 0.9182845]\n",
      "Batch 600/700: Discriminator loss = 1.1843727827072144, GAN loss = [2.5044901, 0.9166623, 0.9674783]\n",
      "Batch 601/700: Discriminator loss = 1.1938010454177856, GAN loss = [2.578704, 0.94310373, 1.0151561]\n",
      "Batch 602/700: Discriminator loss = 1.189922571182251, GAN loss = [2.4450161, 0.94341683, 0.88101876]\n",
      "Batch 603/700: Discriminator loss = 1.2026785612106323, GAN loss = [2.4238167, 0.921257, 0.88186777]\n",
      "Batch 604/700: Discriminator loss = 1.169412612915039, GAN loss = [2.484281, 0.9410493, 0.92244005]\n",
      "Batch 605/700: Discriminator loss = 1.1720178127288818, GAN loss = [2.5663643, 0.9911975, 0.95423025]\n",
      "Batch 606/700: Discriminator loss = 1.1917486190795898, GAN loss = [2.4079177, 0.950923, 0.8359139]\n",
      "Batch 607/700: Discriminator loss = 1.159868836402893, GAN loss = [2.514167, 0.9647375, 0.9282373]\n",
      "Batch 608/700: Discriminator loss = 1.120810866355896, GAN loss = [2.582257, 0.9795483, 0.98141026]\n",
      "Batch 609/700: Discriminator loss = 1.1189937591552734, GAN loss = [2.66034, 1.0228204, 1.01615]\n",
      "Batch 610/700: Discriminator loss = 1.1016579866409302, GAN loss = [2.5131505, 0.98743325, 0.90425456]\n",
      "Batch 611/700: Discriminator loss = 1.1045383214950562, GAN loss = [2.5219247, 0.9722619, 0.92809343]\n",
      "Batch 612/700: Discriminator loss = 1.1155158281326294, GAN loss = [2.498046, 0.93506014, 0.9413501]\n",
      "Batch 613/700: Discriminator loss = 1.0890651941299438, GAN loss = [2.5859137, 0.937369, 1.0268785]\n",
      "Batch 614/700: Discriminator loss = 1.1024211645126343, GAN loss = [2.586871, 0.9447209, 1.0204825]\n",
      "Batch 615/700: Discriminator loss = 1.100035309791565, GAN loss = [2.6219516, 0.9303035, 1.0699811]\n",
      "Batch 616/700: Discriminator loss = 1.1343210935592651, GAN loss = [2.4730184, 0.91064525, 0.94072044]\n",
      "Batch 617/700: Discriminator loss = 1.1249874830245972, GAN loss = [2.5171764, 0.90322053, 0.99226]\n",
      "Batch 618/700: Discriminator loss = 1.1679880619049072, GAN loss = [2.459928, 0.8570303, 0.9811835]\n",
      "Batch 619/700: Discriminator loss = 1.1127077341079712, GAN loss = [2.624699, 0.9181096, 1.0848644]\n",
      "Batch 620/700: Discriminator loss = 1.140310525894165, GAN loss = [2.5424235, 0.8900299, 1.0306445]\n",
      "Batch 621/700: Discriminator loss = 1.1368366479873657, GAN loss = [2.585268, 0.89573455, 1.067811]\n",
      "Batch 622/700: Discriminator loss = 1.1347999572753906, GAN loss = [2.502358, 0.89603233, 0.98465466]\n",
      "Batch 623/700: Discriminator loss = 1.1232972145080566, GAN loss = [2.5688908, 0.9233057, 1.023917]\n",
      "Batch 624/700: Discriminator loss = 1.1329517364501953, GAN loss = [2.5084517, 0.88007474, 1.0067146]\n",
      "Batch 625/700: Discriminator loss = 1.1551501750946045, GAN loss = [2.4758904, 0.88443774, 0.9698133]\n",
      "Batch 626/700: Discriminator loss = 1.1396733522415161, GAN loss = [2.495504, 0.9039946, 0.96990836]\n",
      "Batch 627/700: Discriminator loss = 1.1361476182937622, GAN loss = [2.5714586, 0.88478386, 1.0650963]\n",
      "Batch 628/700: Discriminator loss = 1.1676641702651978, GAN loss = [2.423222, 0.86370206, 0.93795425]\n",
      "Batch 629/700: Discriminator loss = 1.1382298469543457, GAN loss = [2.460458, 0.89652574, 0.94239455]\n",
      "Batch 630/700: Discriminator loss = 1.1645692586898804, GAN loss = [2.4091322, 0.8509334, 0.9366946]\n",
      "Batch 631/700: Discriminator loss = 1.141221046447754, GAN loss = [2.578196, 0.8928139, 1.0639225]\n",
      "Batch 632/700: Discriminator loss = 1.156527042388916, GAN loss = [2.5592592, 0.87754637, 1.0602928]\n",
      "Batch 633/700: Discriminator loss = 1.1227481365203857, GAN loss = [2.6154451, 0.90600157, 1.0880573]\n",
      "Batch 634/700: Discriminator loss = 1.1295100450515747, GAN loss = [2.48379, 0.88774383, 0.9746805]\n",
      "Batch 635/700: Discriminator loss = 1.1355078220367432, GAN loss = [2.6004047, 0.92539537, 1.0536469]\n",
      "Batch 636/700: Discriminator loss = 1.1274043321609497, GAN loss = [2.5427392, 0.9208105, 1.0005958]\n",
      "Batch 637/700: Discriminator loss = 1.1539686918258667, GAN loss = [2.5024774, 0.88098085, 1.0001715]\n",
      "Batch 638/700: Discriminator loss = 1.150998592376709, GAN loss = [2.5397708, 0.8807378, 1.0377244]\n",
      "Batch 639/700: Discriminator loss = 1.137336254119873, GAN loss = [2.4754057, 0.86268026, 0.99139464]\n",
      "Batch 640/700: Discriminator loss = 1.1543149948120117, GAN loss = [2.5190253, 0.8905887, 1.007086]\n",
      "Batch 641/700: Discriminator loss = 1.1744502782821655, GAN loss = [2.4760327, 0.90508026, 0.94959104]\n",
      "Batch 642/700: Discriminator loss = 1.1495630741119385, GAN loss = [2.5232604, 0.8806196, 1.021262]\n",
      "Batch 643/700: Discriminator loss = 1.1332389116287231, GAN loss = [2.4584825, 0.90729296, 0.92984724]\n",
      "Batch 644/700: Discriminator loss = 1.155877709388733, GAN loss = [2.4649558, 0.88213885, 0.9615137]\n",
      "Batch 645/700: Discriminator loss = 1.150444507598877, GAN loss = [2.4114184, 0.8788602, 0.91129214]\n",
      "Batch 646/700: Discriminator loss = 1.121652364730835, GAN loss = [2.5397687, 0.8934891, 1.0250273]\n",
      "Batch 647/700: Discriminator loss = 1.1285114288330078, GAN loss = [2.574496, 0.9055746, 1.0476921]\n",
      "Batch 648/700: Discriminator loss = 1.1131659746170044, GAN loss = [2.4892476, 0.9195463, 0.94847757]\n",
      "Batch 649/700: Discriminator loss = 1.1488275527954102, GAN loss = [2.5007374, 0.8697112, 1.0097998]\n",
      "Batch 650/700: Discriminator loss = 1.1679091453552246, GAN loss = [2.5130837, 0.8718496, 1.0200243]\n",
      "Batch 651/700: Discriminator loss = 1.165157437324524, GAN loss = [2.4907682, 0.8580668, 1.0114856]\n",
      "Batch 652/700: Discriminator loss = 1.1320867538452148, GAN loss = [2.487212, 0.90635335, 0.95965105]\n",
      "Batch 653/700: Discriminator loss = 1.1576486825942993, GAN loss = [2.4781682, 0.8763674, 0.98061395]\n",
      "Batch 654/700: Discriminator loss = 1.12557053565979, GAN loss = [2.4834962, 0.8972141, 0.9650926]\n",
      "Batch 655/700: Discriminator loss = 1.1118165254592896, GAN loss = [2.5344355, 0.9170574, 0.9961796]\n",
      "Batch 656/700: Discriminator loss = 1.1411994695663452, GAN loss = [2.4515965, 0.871814, 0.9585898]\n",
      "Batch 657/700: Discriminator loss = 1.1216938495635986, GAN loss = [2.5124984, 0.88751864, 1.0037786]\n",
      "Batch 658/700: Discriminator loss = 1.1254249811172485, GAN loss = [2.553814, 0.8936642, 1.0389357]\n",
      "Batch 659/700: Discriminator loss = 1.1262779235839844, GAN loss = [2.4621682, 0.90701866, 0.9339294]\n",
      "Batch 660/700: Discriminator loss = 1.1408987045288086, GAN loss = [2.426701, 0.8782206, 0.92726725]\n",
      "Batch 661/700: Discriminator loss = 1.135697841644287, GAN loss = [2.5366154, 0.8958689, 1.0195361]\n",
      "Batch 662/700: Discriminator loss = 1.1132853031158447, GAN loss = [2.575757, 0.9124875, 1.0420746]\n",
      "Batch 663/700: Discriminator loss = 1.1061928272247314, GAN loss = [2.5763202, 0.9099497, 1.0451566]\n",
      "Batch 664/700: Discriminator loss = 1.1283543109893799, GAN loss = [2.5666041, 0.89198214, 1.0534136]\n",
      "Batch 665/700: Discriminator loss = 1.1192413568496704, GAN loss = [2.5288644, 0.89236224, 1.0153099]\n",
      "Batch 666/700: Discriminator loss = 1.1316461563110352, GAN loss = [2.5281441, 0.8860012, 1.0209621]\n",
      "Batch 667/700: Discriminator loss = 1.143339991569519, GAN loss = [2.5014489, 0.87932235, 1.0009769]\n",
      "Batch 668/700: Discriminator loss = 1.123886227607727, GAN loss = [2.6548388, 0.924422, 1.1092886]\n",
      "Batch 669/700: Discriminator loss = 1.1163216829299927, GAN loss = [2.5221615, 0.9277103, 0.97335154]\n",
      "Batch 670/700: Discriminator loss = 1.1336236000061035, GAN loss = [2.5109978, 0.90506625, 0.9848527]\n",
      "Batch 671/700: Discriminator loss = 1.1351442337036133, GAN loss = [2.5517302, 0.919605, 1.0110911]\n",
      "Batch 672/700: Discriminator loss = 1.1124825477600098, GAN loss = [2.563509, 0.9297815, 1.0127156]\n",
      "Batch 673/700: Discriminator loss = 1.1498297452926636, GAN loss = [2.5032325, 0.9005198, 0.9816968]\n",
      "Batch 674/700: Discriminator loss = 1.146216630935669, GAN loss = [2.525961, 0.89489275, 1.0100582]\n",
      "Batch 675/700: Discriminator loss = 1.1338340044021606, GAN loss = [2.5273564, 0.90760523, 0.9987564]\n",
      "Batch 676/700: Discriminator loss = 1.1392922401428223, GAN loss = [2.4913378, 0.8835572, 0.98681587]\n",
      "Batch 677/700: Discriminator loss = 1.1312105655670166, GAN loss = [2.4680672, 0.9143562, 0.93277854]\n",
      "Batch 678/700: Discriminator loss = 1.1276379823684692, GAN loss = [2.5504382, 0.9216433, 1.007893]\n",
      "Batch 679/700: Discriminator loss = 1.11845862865448, GAN loss = [2.5342581, 0.9181739, 0.9951964]\n",
      "Batch 680/700: Discriminator loss = 1.1335395574569702, GAN loss = [2.5259457, 0.91423064, 0.99084467]\n",
      "Batch 681/700: Discriminator loss = 1.1306555271148682, GAN loss = [2.51078, 0.91102403, 0.978915]\n",
      "Batch 682/700: Discriminator loss = 1.141446590423584, GAN loss = [2.5109677, 0.8901923, 0.99995637]\n",
      "Batch 683/700: Discriminator loss = 1.1662317514419556, GAN loss = [2.4755516, 0.8783684, 0.97639596]\n",
      "Batch 684/700: Discriminator loss = 1.131460189819336, GAN loss = [2.4883406, 0.9259061, 0.9416711]\n",
      "Batch 685/700: Discriminator loss = 1.1657917499542236, GAN loss = [2.4340327, 0.8839579, 0.929318]\n",
      "Batch 686/700: Discriminator loss = 1.1344330310821533, GAN loss = [2.541116, 0.90568674, 1.0146755]\n",
      "Batch 687/700: Discriminator loss = 1.1765941381454468, GAN loss = [2.3878942, 0.8303974, 0.9367637]\n",
      "Batch 688/700: Discriminator loss = 1.1931428909301758, GAN loss = [2.409287, 0.8466796, 0.94192195]\n",
      "Batch 689/700: Discriminator loss = 1.1729363203048706, GAN loss = [2.3985183, 0.8599807, 0.91787755]\n",
      "Batch 690/700: Discriminator loss = 1.1740930080413818, GAN loss = [2.4138935, 0.85703325, 0.9362037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 691/700: Discriminator loss = 1.1666674613952637, GAN loss = [2.437449, 0.8722241, 0.94459534]\n",
      "Batch 692/700: Discriminator loss = 1.2171646356582642, GAN loss = [2.3239396, 0.8235131, 0.8798017]\n",
      "Batch 693/700: Discriminator loss = 1.1871299743652344, GAN loss = [2.4576015, 0.8770419, 0.95997214]\n",
      "Batch 694/700: Discriminator loss = 1.1919938325881958, GAN loss = [2.429343, 0.88232905, 0.92643714]\n",
      "Batch 695/700: Discriminator loss = 1.200859546661377, GAN loss = [2.3159752, 0.8321141, 0.86324865]\n",
      "Batch 696/700: Discriminator loss = 1.1830036640167236, GAN loss = [2.4574273, 0.9193096, 0.9174879]\n",
      "Batch 697/700: Discriminator loss = 1.2011748552322388, GAN loss = [2.4144888, 0.848118, 0.94574136]\n",
      "Batch 698/700: Discriminator loss = 1.20827317237854, GAN loss = [2.2842476, 0.82892716, 0.83467865]\n",
      "Batch 699/700: Discriminator loss = 1.2173523902893066, GAN loss = [2.2422824, 0.83176553, 0.7898491]\n",
      "Batch 700/700: Discriminator loss = 1.2097716331481934, GAN loss = [2.365911, 0.8467519, 0.8984854]\n",
      "Epoch 28/30\n",
      "Batch 1/700: Discriminator loss = 1.2061102390289307, GAN loss = [2.3279457, 0.85884607, 0.8484877]\n",
      "Batch 2/700: Discriminator loss = 1.203780174255371, GAN loss = [2.3200908, 0.83889824, 0.86063194]\n",
      "Batch 3/700: Discriminator loss = 1.1552432775497437, GAN loss = [2.3929114, 0.8830816, 0.8892872]\n",
      "Batch 4/700: Discriminator loss = 1.1995688676834106, GAN loss = [2.403548, 0.874621, 0.9083761]\n",
      "Batch 5/700: Discriminator loss = 1.1461652517318726, GAN loss = [2.3511336, 0.88369393, 0.8468857]\n",
      "Batch 6/700: Discriminator loss = 1.1782841682434082, GAN loss = [2.3549914, 0.8458658, 0.8885823]\n",
      "Batch 7/700: Discriminator loss = 1.1794090270996094, GAN loss = [2.3687649, 0.82490784, 0.9233306]\n",
      "Batch 8/700: Discriminator loss = 1.1771817207336426, GAN loss = [2.3702812, 0.8657766, 0.88401437]\n",
      "Batch 9/700: Discriminator loss = 1.1637176275253296, GAN loss = [2.3344247, 0.8649997, 0.8489693]\n",
      "Batch 10/700: Discriminator loss = 1.1535365581512451, GAN loss = [2.408553, 0.8626317, 0.9254717]\n",
      "Batch 11/700: Discriminator loss = 1.1761596202850342, GAN loss = [2.3029366, 0.84125924, 0.8412274]\n",
      "Batch 12/700: Discriminator loss = 1.2039650678634644, GAN loss = [2.371228, 0.8241616, 0.92662233]\n",
      "Batch 13/700: Discriminator loss = 1.229886531829834, GAN loss = [2.2562637, 0.7923345, 0.8434847]\n",
      "Batch 14/700: Discriminator loss = 1.2009292840957642, GAN loss = [2.2927525, 0.8188536, 0.8534305]\n",
      "Batch 15/700: Discriminator loss = 1.2050081491470337, GAN loss = [2.3219335, 0.816739, 0.8847315]\n",
      "Batch 16/700: Discriminator loss = 1.2083896398544312, GAN loss = [2.319199, 0.83930224, 0.85942185]\n",
      "Batch 17/700: Discriminator loss = 1.193941354751587, GAN loss = [2.328485, 0.8395113, 0.8684948]\n",
      "Batch 18/700: Discriminator loss = 1.2040663957595825, GAN loss = [2.2680857, 0.8159297, 0.83169454]\n",
      "Batch 19/700: Discriminator loss = 1.1959882974624634, GAN loss = [2.418058, 0.8143486, 0.98327476]\n",
      "Batch 20/700: Discriminator loss = 1.1626458168029785, GAN loss = [2.452041, 0.8744483, 0.9571906]\n",
      "Batch 21/700: Discriminator loss = 1.199388861656189, GAN loss = [2.2897804, 0.8217867, 0.8476254]\n",
      "Batch 22/700: Discriminator loss = 1.2178722620010376, GAN loss = [2.368736, 0.80734587, 0.9410269]\n",
      "Batch 23/700: Discriminator loss = 1.191967248916626, GAN loss = [2.342511, 0.82902116, 0.8931219]\n",
      "Batch 24/700: Discriminator loss = 1.206368088722229, GAN loss = [2.2927256, 0.80589586, 0.8664869]\n",
      "Batch 25/700: Discriminator loss = 1.1991490125656128, GAN loss = [2.3360853, 0.81058973, 0.9051612]\n",
      "Batch 26/700: Discriminator loss = 1.2018582820892334, GAN loss = [2.3564243, 0.80074483, 0.9353591]\n",
      "Batch 27/700: Discriminator loss = 1.1888364553451538, GAN loss = [2.3299315, 0.82204837, 0.8875874]\n",
      "Batch 28/700: Discriminator loss = 1.1993752717971802, GAN loss = [2.315908, 0.8091556, 0.8864847]\n",
      "Batch 29/700: Discriminator loss = 1.1729233264923096, GAN loss = [2.3418133, 0.8374814, 0.88408685]\n",
      "Batch 30/700: Discriminator loss = 1.2200292348861694, GAN loss = [2.3206995, 0.7956698, 0.9048157]\n",
      "Batch 31/700: Discriminator loss = 1.2261821031570435, GAN loss = [2.3088593, 0.8185766, 0.8700907]\n",
      "Batch 32/700: Discriminator loss = 1.2023239135742188, GAN loss = [2.3509455, 0.84130174, 0.88945466]\n",
      "Batch 33/700: Discriminator loss = 1.1874265670776367, GAN loss = [2.304073, 0.81304306, 0.87081045]\n",
      "Batch 34/700: Discriminator loss = 1.191752314567566, GAN loss = [2.3455937, 0.82250625, 0.902854]\n",
      "Batch 35/700: Discriminator loss = 1.2084999084472656, GAN loss = [2.3099463, 0.7985244, 0.89118445]\n",
      "Batch 36/700: Discriminator loss = 1.2074791193008423, GAN loss = [2.4383957, 0.81100875, 1.0071434]\n",
      "Batch 37/700: Discriminator loss = 1.1955755949020386, GAN loss = [2.3227067, 0.80294347, 0.899508]\n",
      "Batch 38/700: Discriminator loss = 1.225276231765747, GAN loss = [2.3052409, 0.76294065, 0.92201596]\n",
      "Batch 39/700: Discriminator loss = 1.2229201793670654, GAN loss = [2.2453063, 0.7924078, 0.83260226]\n",
      "Batch 40/700: Discriminator loss = 1.1834962368011475, GAN loss = [2.329479, 0.8030772, 0.9060873]\n",
      "Batch 41/700: Discriminator loss = 1.1878936290740967, GAN loss = [2.376236, 0.8059986, 0.9499005]\n",
      "Batch 42/700: Discriminator loss = 1.230599045753479, GAN loss = [2.340088, 0.7890743, 0.93069047]\n",
      "Batch 43/700: Discriminator loss = 1.2245656251907349, GAN loss = [2.2993736, 0.81076044, 0.8682676]\n",
      "Batch 44/700: Discriminator loss = 1.1862385272979736, GAN loss = [2.39156, 0.8196668, 0.9515365]\n",
      "Batch 45/700: Discriminator loss = 1.1853691339492798, GAN loss = [2.2941434, 0.8138298, 0.8599676]\n",
      "Batch 46/700: Discriminator loss = 1.186274766921997, GAN loss = [2.3194494, 0.8201344, 0.878977]\n",
      "Batch 47/700: Discriminator loss = 1.204060435295105, GAN loss = [2.3312118, 0.8160976, 0.89479554]\n",
      "Batch 48/700: Discriminator loss = 1.179239273071289, GAN loss = [2.3386352, 0.8332557, 0.8850682]\n",
      "Batch 49/700: Discriminator loss = 1.175620436668396, GAN loss = [2.3788443, 0.83640134, 0.9221565]\n",
      "Batch 50/700: Discriminator loss = 1.1869957447052002, GAN loss = [2.2864978, 0.8090255, 0.8571756]\n",
      "Batch 51/700: Discriminator loss = 1.177488923072815, GAN loss = [2.3351915, 0.8407837, 0.8741069]\n",
      "Batch 52/700: Discriminator loss = 1.178363561630249, GAN loss = [2.343352, 0.83381104, 0.88924193]\n",
      "Batch 53/700: Discriminator loss = 1.168496012687683, GAN loss = [2.388972, 0.84567916, 0.9229666]\n",
      "Batch 54/700: Discriminator loss = 1.1743113994598389, GAN loss = [2.3231246, 0.8187424, 0.8840424]\n",
      "Batch 55/700: Discriminator loss = 1.1740015745162964, GAN loss = [2.3428185, 0.8264171, 0.89604425]\n",
      "Batch 56/700: Discriminator loss = 1.1691715717315674, GAN loss = [2.3347993, 0.83171344, 0.882733]\n",
      "Batch 57/700: Discriminator loss = 1.1633049249649048, GAN loss = [2.4148772, 0.8353894, 0.9591566]\n",
      "Batch 58/700: Discriminator loss = 1.163041591644287, GAN loss = [2.3331594, 0.82043266, 0.8924119]\n",
      "Batch 59/700: Discriminator loss = 1.1567742824554443, GAN loss = [2.3531656, 0.8331582, 0.8997233]\n",
      "Batch 60/700: Discriminator loss = 1.1471686363220215, GAN loss = [2.4715145, 0.8635462, 0.98770404]\n",
      "Batch 61/700: Discriminator loss = 1.1697901487350464, GAN loss = [2.3891037, 0.8287566, 0.9400803]\n",
      "Batch 62/700: Discriminator loss = 1.1485729217529297, GAN loss = [2.3710442, 0.85344756, 0.8973463]\n",
      "Batch 63/700: Discriminator loss = 1.1527843475341797, GAN loss = [2.448105, 0.82845503, 0.99938875]\n",
      "Batch 64/700: Discriminator loss = 1.1522090435028076, GAN loss = [2.3812997, 0.8295121, 0.931524]\n",
      "Batch 65/700: Discriminator loss = 1.1572651863098145, GAN loss = [2.4081953, 0.8348386, 0.95312345]\n",
      "Batch 66/700: Discriminator loss = 1.1557843685150146, GAN loss = [2.3927982, 0.8550876, 0.9175353]\n",
      "Batch 67/700: Discriminator loss = 1.154377818107605, GAN loss = [2.3819804, 0.84298897, 0.9188305]\n",
      "Batch 68/700: Discriminator loss = 1.1413203477859497, GAN loss = [2.3559191, 0.85000664, 0.88575715]\n",
      "Batch 69/700: Discriminator loss = 1.1542038917541504, GAN loss = [2.4287465, 0.8408191, 0.9677961]\n",
      "Batch 70/700: Discriminator loss = 1.1495715379714966, GAN loss = [2.443644, 0.86407936, 0.95948076]\n",
      "Batch 71/700: Discriminator loss = 1.1507716178894043, GAN loss = [2.371509, 0.8530252, 0.898431]\n",
      "Batch 72/700: Discriminator loss = 1.1386734247207642, GAN loss = [2.409921, 0.85075897, 0.93913096]\n",
      "Batch 73/700: Discriminator loss = 1.1462675333023071, GAN loss = [2.414681, 0.8287075, 0.96598375]\n",
      "Batch 74/700: Discriminator loss = 1.1338409185409546, GAN loss = [2.3943553, 0.8372557, 0.9371614]\n",
      "Batch 75/700: Discriminator loss = 1.1548278331756592, GAN loss = [2.3614414, 0.83427817, 0.90727943]\n",
      "Batch 76/700: Discriminator loss = 1.1578564643859863, GAN loss = [2.382646, 0.8580752, 0.9047367]\n",
      "Batch 77/700: Discriminator loss = 1.1511304378509521, GAN loss = [2.3934777, 0.8437765, 0.92990184]\n",
      "Batch 78/700: Discriminator loss = 1.1651802062988281, GAN loss = [2.3613582, 0.8075941, 0.9340095]\n",
      "Batch 79/700: Discriminator loss = 1.1472152471542358, GAN loss = [2.3697047, 0.8232739, 0.92673993]\n",
      "Batch 80/700: Discriminator loss = 1.1478370428085327, GAN loss = [2.4242573, 0.8362415, 0.96839553]\n",
      "Batch 81/700: Discriminator loss = 1.165494680404663, GAN loss = [2.4164464, 0.82452416, 0.9723571]\n",
      "Batch 82/700: Discriminator loss = 1.1519747972488403, GAN loss = [2.3768964, 0.81971735, 0.9376724]\n",
      "Batch 83/700: Discriminator loss = 1.1556676626205444, GAN loss = [2.4523613, 0.8153136, 1.0175776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 84/700: Discriminator loss = 1.156034231185913, GAN loss = [2.3602238, 0.83514476, 0.905649]\n",
      "Batch 85/700: Discriminator loss = 1.1849112510681152, GAN loss = [2.3213434, 0.809379, 0.8925865]\n",
      "Batch 86/700: Discriminator loss = 1.1447241306304932, GAN loss = [2.4077704, 0.86701196, 0.9214363]\n",
      "Batch 87/700: Discriminator loss = 1.1550638675689697, GAN loss = [2.4413943, 0.8293844, 0.99272764]\n",
      "Batch 88/700: Discriminator loss = 1.1330814361572266, GAN loss = [2.39169, 0.85606027, 0.9163849]\n",
      "Batch 89/700: Discriminator loss = 1.1289291381835938, GAN loss = [2.3929715, 0.8638801, 0.90987486]\n",
      "Batch 90/700: Discriminator loss = 1.1251516342163086, GAN loss = [2.453664, 0.86939156, 0.96508616]\n",
      "Batch 91/700: Discriminator loss = 1.138693928718567, GAN loss = [2.4417398, 0.85567546, 0.9668942]\n",
      "Batch 92/700: Discriminator loss = 1.1412909030914307, GAN loss = [2.412314, 0.86929303, 0.9238516]\n",
      "Batch 93/700: Discriminator loss = 1.1358914375305176, GAN loss = [2.4597087, 0.86645097, 0.97410667]\n",
      "Batch 94/700: Discriminator loss = 1.1418296098709106, GAN loss = [2.5218873, 0.85831773, 1.0444539]\n",
      "Batch 95/700: Discriminator loss = 1.1580417156219482, GAN loss = [2.4112465, 0.8726747, 0.9194865]\n",
      "Batch 96/700: Discriminator loss = 1.15921151638031, GAN loss = [2.3687468, 0.84681654, 0.9028669]\n",
      "Batch 97/700: Discriminator loss = 1.1777416467666626, GAN loss = [2.4078958, 0.84307027, 0.945779]\n",
      "Batch 98/700: Discriminator loss = 1.1598252058029175, GAN loss = [2.3796585, 0.8241409, 0.9364776]\n",
      "Batch 99/700: Discriminator loss = 1.1758201122283936, GAN loss = [2.3868074, 0.82018226, 0.9475966]\n",
      "Batch 100/700: Discriminator loss = 1.181815266609192, GAN loss = [2.3823588, 0.8221408, 0.9412066]\n",
      "Batch 101/700: Discriminator loss = 1.1770930290222168, GAN loss = [2.3298185, 0.81538755, 0.8954274]\n",
      "Batch 102/700: Discriminator loss = 1.1823824644088745, GAN loss = [2.3662515, 0.82461923, 0.9226393]\n",
      "Batch 103/700: Discriminator loss = 1.199910283088684, GAN loss = [2.3800774, 0.8195613, 0.94154406]\n",
      "Batch 104/700: Discriminator loss = 1.160062551498413, GAN loss = [2.4368916, 0.8565892, 0.96134675]\n",
      "Batch 105/700: Discriminator loss = 1.153579592704773, GAN loss = [2.440117, 0.8509192, 0.9702452]\n",
      "Batch 106/700: Discriminator loss = 1.1623746156692505, GAN loss = [2.4016898, 0.8535104, 0.92921585]\n",
      "Batch 107/700: Discriminator loss = 1.157081127166748, GAN loss = [2.3806782, 0.8562728, 0.90542746]\n",
      "Batch 108/700: Discriminator loss = 1.1415719985961914, GAN loss = [2.3728049, 0.8669322, 0.8868991]\n",
      "Batch 109/700: Discriminator loss = 1.1295663118362427, GAN loss = [2.4127316, 0.88368994, 0.9100765]\n",
      "Batch 110/700: Discriminator loss = 1.1245853900909424, GAN loss = [2.511453, 0.8856056, 1.006908]\n",
      "Batch 111/700: Discriminator loss = 1.136486291885376, GAN loss = [2.4245, 0.88142717, 0.9241347]\n",
      "Batch 112/700: Discriminator loss = 1.1265461444854736, GAN loss = [2.5718026, 0.8978579, 1.0549946]\n",
      "Batch 113/700: Discriminator loss = 1.1075818538665771, GAN loss = [2.5194309, 0.9134349, 0.9870355]\n",
      "Batch 114/700: Discriminator loss = 1.1157310009002686, GAN loss = [2.4130807, 0.9008268, 0.89328986]\n",
      "Batch 115/700: Discriminator loss = 1.1007733345031738, GAN loss = [2.492562, 0.92729723, 0.946334]\n",
      "Batch 116/700: Discriminator loss = 1.1002702713012695, GAN loss = [2.5710373, 0.9142518, 1.0378829]\n",
      "Batch 117/700: Discriminator loss = 1.1221369504928589, GAN loss = [2.499874, 0.89377004, 0.9872097]\n",
      "Batch 118/700: Discriminator loss = 1.1007205247879028, GAN loss = [2.6364558, 0.9244698, 1.0931206]\n",
      "Batch 119/700: Discriminator loss = 1.130905032157898, GAN loss = [2.4246097, 0.8953237, 0.9104391]\n",
      "Batch 120/700: Discriminator loss = 1.1485944986343384, GAN loss = [2.5675972, 0.871154, 1.0776205]\n",
      "Batch 121/700: Discriminator loss = 1.137917160987854, GAN loss = [2.5175734, 0.8836051, 1.0151439]\n",
      "Batch 122/700: Discriminator loss = 1.1269606351852417, GAN loss = [2.5097225, 0.886355, 1.0045513]\n",
      "Batch 123/700: Discriminator loss = 1.159282922744751, GAN loss = [2.4906616, 0.856271, 1.0155816]\n",
      "Batch 124/700: Discriminator loss = 1.1545437574386597, GAN loss = [2.4331286, 0.8828054, 0.93150055]\n",
      "Batch 125/700: Discriminator loss = 1.1550040245056152, GAN loss = [2.5058162, 0.8921109, 0.99488074]\n",
      "Batch 126/700: Discriminator loss = 1.1423240900039673, GAN loss = [2.5086927, 0.88303894, 1.0068097]\n",
      "Batch 127/700: Discriminator loss = 1.1530344486236572, GAN loss = [2.5234878, 0.8662221, 1.0383878]\n",
      "Batch 128/700: Discriminator loss = 1.1511276960372925, GAN loss = [2.5642085, 0.9155754, 1.0297436]\n",
      "Batch 129/700: Discriminator loss = 1.1460963487625122, GAN loss = [2.3997338, 0.88841736, 0.8924229]\n",
      "Batch 130/700: Discriminator loss = 1.1431748867034912, GAN loss = [2.4463289, 0.8722654, 0.95515615]\n",
      "Batch 131/700: Discriminator loss = 1.1548317670822144, GAN loss = [2.4544277, 0.8672636, 0.9682609]\n",
      "Batch 132/700: Discriminator loss = 1.1170575618743896, GAN loss = [2.5099409, 0.9215695, 0.969474]\n",
      "Batch 133/700: Discriminator loss = 1.1521542072296143, GAN loss = [2.4352214, 0.86226, 0.95407027]\n",
      "Batch 134/700: Discriminator loss = 1.141922116279602, GAN loss = [2.4671874, 0.86622286, 0.9820758]\n",
      "Batch 135/700: Discriminator loss = 1.1388072967529297, GAN loss = [2.4438896, 0.88161147, 0.943391]\n",
      "Batch 136/700: Discriminator loss = 1.1630396842956543, GAN loss = [2.528756, 0.8600714, 1.049795]\n",
      "Batch 137/700: Discriminator loss = 1.144636631011963, GAN loss = [2.4909048, 0.8753012, 0.99671835]\n",
      "Batch 138/700: Discriminator loss = 1.1426721811294556, GAN loss = [2.4371967, 0.8573775, 0.96091825]\n",
      "Batch 139/700: Discriminator loss = 1.1604499816894531, GAN loss = [2.478347, 0.859843, 0.9995787]\n",
      "Batch 140/700: Discriminator loss = 1.1477582454681396, GAN loss = [2.5100179, 0.8818561, 1.0092047]\n",
      "Batch 141/700: Discriminator loss = 1.141371250152588, GAN loss = [2.5088353, 0.88699645, 1.0028392]\n",
      "Batch 142/700: Discriminator loss = 1.1136858463287354, GAN loss = [2.4746993, 0.92440367, 0.93125707]\n",
      "Batch 143/700: Discriminator loss = 1.151626467704773, GAN loss = [2.4213765, 0.87228566, 0.9300277]\n",
      "Batch 144/700: Discriminator loss = 1.125238299369812, GAN loss = [2.5759432, 0.9244066, 1.0324379]\n",
      "Batch 145/700: Discriminator loss = 1.1057862043380737, GAN loss = [2.5344486, 0.8935789, 1.0217227]\n",
      "Batch 146/700: Discriminator loss = 1.1134403944015503, GAN loss = [2.5267048, 0.8966784, 1.0108608]\n",
      "Batch 147/700: Discriminator loss = 1.1345674991607666, GAN loss = [2.4823747, 0.8780091, 0.9852094]\n",
      "Batch 148/700: Discriminator loss = 1.1266759634017944, GAN loss = [2.4947588, 0.89360666, 0.98200876]\n",
      "Batch 149/700: Discriminator loss = 1.1106586456298828, GAN loss = [2.6080315, 0.91418, 1.0747331]\n",
      "Batch 150/700: Discriminator loss = 1.1193561553955078, GAN loss = [2.5398245, 0.9456428, 0.97509384]\n",
      "Batch 151/700: Discriminator loss = 1.1277552843093872, GAN loss = [2.516344, 0.90972847, 0.98752326]\n",
      "Batch 152/700: Discriminator loss = 1.072729229927063, GAN loss = [2.4939735, 0.9440623, 0.9308202]\n",
      "Batch 153/700: Discriminator loss = 1.1243526935577393, GAN loss = [2.5125906, 0.8837481, 1.0097746]\n",
      "Batch 154/700: Discriminator loss = 1.09915030002594, GAN loss = [2.4670208, 0.9038171, 0.94414896]\n",
      "Batch 155/700: Discriminator loss = 1.102503776550293, GAN loss = [2.535816, 0.9020691, 1.0147219]\n",
      "Batch 156/700: Discriminator loss = 1.0851385593414307, GAN loss = [2.6353092, 0.94364715, 1.0726687]\n",
      "Batch 157/700: Discriminator loss = 1.101212978363037, GAN loss = [2.5709486, 0.91687906, 1.0350872]\n",
      "Batch 158/700: Discriminator loss = 1.104228138923645, GAN loss = [2.5939207, 0.94244695, 1.0325041]\n",
      "Batch 159/700: Discriminator loss = 1.0858657360076904, GAN loss = [2.6728632, 0.9336663, 1.1202301]\n",
      "Batch 160/700: Discriminator loss = 1.1100404262542725, GAN loss = [2.5409942, 0.90287745, 1.0191443]\n",
      "Batch 161/700: Discriminator loss = 1.1000325679779053, GAN loss = [2.6078427, 0.9012999, 1.0875785]\n",
      "Batch 162/700: Discriminator loss = 1.1218005418777466, GAN loss = [2.6224825, 0.88901865, 1.1145173]\n",
      "Batch 163/700: Discriminator loss = 1.144061803817749, GAN loss = [2.7030137, 0.89685845, 1.1872368]\n",
      "Batch 164/700: Discriminator loss = 1.1340028047561646, GAN loss = [2.57728, 0.9092037, 1.0491595]\n",
      "Batch 165/700: Discriminator loss = 1.1346184015274048, GAN loss = [2.4243724, 0.8648387, 0.94063467]\n",
      "Batch 166/700: Discriminator loss = 1.1468294858932495, GAN loss = [2.6316922, 0.8800316, 1.1327541]\n",
      "Batch 167/700: Discriminator loss = 1.1110234260559082, GAN loss = [2.5821037, 0.90602994, 1.0571511]\n",
      "Batch 168/700: Discriminator loss = 1.1317318677902222, GAN loss = [2.648219, 0.8950473, 1.1342473]\n",
      "Batch 169/700: Discriminator loss = 1.1460356712341309, GAN loss = [2.6072073, 0.90685415, 1.0814242]\n",
      "Batch 170/700: Discriminator loss = 1.151181936264038, GAN loss = [2.6146903, 0.87520003, 1.1205584]\n",
      "Batch 171/700: Discriminator loss = 1.1754733324050903, GAN loss = [2.445433, 0.8490642, 0.9774477]\n",
      "Batch 172/700: Discriminator loss = 1.1417292356491089, GAN loss = [2.5388944, 0.94415265, 0.97585225]\n",
      "Batch 173/700: Discriminator loss = 1.1295537948608398, GAN loss = [2.6765966, 0.90345514, 1.1542953]\n",
      "Batch 174/700: Discriminator loss = 1.144898533821106, GAN loss = [2.5612056, 0.9031416, 1.0392629]\n",
      "Batch 175/700: Discriminator loss = 1.1587437391281128, GAN loss = [2.5486193, 0.89012116, 1.0397229]\n",
      "Batch 176/700: Discriminator loss = 1.119652271270752, GAN loss = [2.6039588, 0.9373757, 1.0478444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 177/700: Discriminator loss = 1.1525871753692627, GAN loss = [2.6035316, 0.90720904, 1.0776205]\n",
      "Batch 178/700: Discriminator loss = 1.1448389291763306, GAN loss = [2.6376023, 0.9183166, 1.1006261]\n",
      "Batch 179/700: Discriminator loss = 1.159244418144226, GAN loss = [2.5751772, 0.9280384, 1.0285074]\n",
      "Batch 180/700: Discriminator loss = 1.1154050827026367, GAN loss = [2.667393, 0.95003974, 1.098741]\n",
      "Batch 181/700: Discriminator loss = 1.10935378074646, GAN loss = [2.6731272, 0.9311932, 1.123318]\n",
      "Batch 182/700: Discriminator loss = 1.1471328735351562, GAN loss = [2.5728104, 0.8952222, 1.0589985]\n",
      "Batch 183/700: Discriminator loss = 1.1470526456832886, GAN loss = [2.4987578, 0.88304573, 0.9971245]\n",
      "Batch 184/700: Discriminator loss = 1.156516194343567, GAN loss = [2.4385078, 0.8545427, 0.965399]\n",
      "Batch 185/700: Discriminator loss = 1.1226835250854492, GAN loss = [2.6597748, 0.8966339, 1.1446052]\n",
      "Batch 186/700: Discriminator loss = 1.1212366819381714, GAN loss = [2.6188407, 0.91406286, 1.0862718]\n",
      "Batch 187/700: Discriminator loss = 1.1217390298843384, GAN loss = [2.5580583, 0.93315434, 1.0063907]\n",
      "Batch 188/700: Discriminator loss = 1.1326500177383423, GAN loss = [2.802507, 0.9285244, 1.2554691]\n",
      "Batch 189/700: Discriminator loss = 1.14712655544281, GAN loss = [2.524843, 0.91231185, 0.9940184]\n",
      "Batch 190/700: Discriminator loss = 1.1097257137298584, GAN loss = [2.6332705, 0.9467349, 1.0680455]\n",
      "Batch 191/700: Discriminator loss = 1.0947515964508057, GAN loss = [2.7060297, 0.92751306, 1.1600746]\n",
      "Batch 192/700: Discriminator loss = 1.1161431074142456, GAN loss = [2.5111668, 0.9140078, 0.9787506]\n",
      "Batch 193/700: Discriminator loss = 1.0829557180404663, GAN loss = [2.6571198, 0.95105606, 1.0876964]\n",
      "Batch 194/700: Discriminator loss = 1.105107069015503, GAN loss = [2.59759, 0.92461276, 1.0546442]\n",
      "Batch 195/700: Discriminator loss = 1.1070951223373413, GAN loss = [2.5492942, 0.9054056, 1.0255814]\n",
      "Batch 196/700: Discriminator loss = 1.1121127605438232, GAN loss = [2.623084, 0.9196108, 1.0851933]\n",
      "Batch 197/700: Discriminator loss = 1.1126031875610352, GAN loss = [2.7654595, 0.9402484, 1.2069802]\n",
      "Batch 198/700: Discriminator loss = 1.1024898290634155, GAN loss = [2.6453576, 0.9328282, 1.0943043]\n",
      "Batch 199/700: Discriminator loss = 1.1103202104568481, GAN loss = [2.674928, 0.91665643, 1.1400485]\n",
      "Batch 200/700: Discriminator loss = 1.1156129837036133, GAN loss = [2.538887, 0.8985336, 1.0221195]\n",
      "Batch 201/700: Discriminator loss = 1.1325784921646118, GAN loss = [2.621203, 0.9440626, 1.0589128]\n",
      "Batch 202/700: Discriminator loss = 1.128879189491272, GAN loss = [2.616982, 0.93686414, 1.0618762]\n",
      "Batch 203/700: Discriminator loss = 1.0961151123046875, GAN loss = [2.747132, 0.93164885, 1.1972159]\n",
      "Batch 204/700: Discriminator loss = 1.124995231628418, GAN loss = [2.6166594, 0.8911942, 1.1071831]\n",
      "Batch 205/700: Discriminator loss = 1.127751350402832, GAN loss = [2.6264641, 0.9679586, 1.0402333]\n",
      "Batch 206/700: Discriminator loss = 1.1281838417053223, GAN loss = [2.5064874, 0.8918856, 0.9962941]\n",
      "Batch 207/700: Discriminator loss = 1.143450140953064, GAN loss = [2.5669782, 0.9235421, 1.0251169]\n",
      "Batch 208/700: Discriminator loss = 1.1643633842468262, GAN loss = [2.5716264, 0.8799112, 1.0733554]\n",
      "Batch 209/700: Discriminator loss = 1.1455307006835938, GAN loss = [2.5303586, 0.90779704, 1.0041685]\n",
      "Batch 210/700: Discriminator loss = 1.165279507637024, GAN loss = [2.577086, 0.9038881, 1.0548116]\n",
      "Batch 211/700: Discriminator loss = 1.1422191858291626, GAN loss = [2.6963403, 0.94032633, 1.1376352]\n",
      "Batch 212/700: Discriminator loss = 1.1162919998168945, GAN loss = [2.5433612, 0.9329295, 0.9920908]\n",
      "Batch 213/700: Discriminator loss = 1.13291597366333, GAN loss = [2.5409982, 0.90321654, 1.0194765]\n",
      "Batch 214/700: Discriminator loss = 1.1473345756530762, GAN loss = [2.4915853, 0.8978018, 0.97551286]\n",
      "Batch 215/700: Discriminator loss = 1.1415221691131592, GAN loss = [2.6071098, 0.9148731, 1.0739889]\n",
      "Batch 216/700: Discriminator loss = 1.1211761236190796, GAN loss = [2.5806003, 0.9193576, 1.0430146]\n",
      "Batch 217/700: Discriminator loss = 1.1602082252502441, GAN loss = [2.5839665, 0.8731174, 1.0926268]\n",
      "Batch 218/700: Discriminator loss = 1.1327024698257446, GAN loss = [2.716546, 0.92419815, 1.1741277]\n",
      "Batch 219/700: Discriminator loss = 1.1337945461273193, GAN loss = [2.5453644, 0.8855803, 1.0415572]\n",
      "Batch 220/700: Discriminator loss = 1.0922850370407104, GAN loss = [2.71516, 0.963459, 1.1334963]\n",
      "Batch 221/700: Discriminator loss = 1.0848742723464966, GAN loss = [2.5976977, 0.9566024, 1.0229193]\n",
      "Batch 222/700: Discriminator loss = 1.1259878873825073, GAN loss = [2.5933094, 0.91958076, 1.055578]\n",
      "Batch 223/700: Discriminator loss = 1.1229380369186401, GAN loss = [2.496542, 0.9194262, 0.95899564]\n",
      "Batch 224/700: Discriminator loss = 1.1510202884674072, GAN loss = [2.5122888, 0.88307405, 1.0111154]\n",
      "Batch 225/700: Discriminator loss = 1.1362707614898682, GAN loss = [2.5311027, 0.89187235, 1.021156]\n",
      "Batch 226/700: Discriminator loss = 1.143200397491455, GAN loss = [2.6332026, 0.92505896, 1.0901015]\n",
      "Batch 227/700: Discriminator loss = 1.1311825513839722, GAN loss = [2.5602102, 0.9333338, 1.0088341]\n",
      "Batch 228/700: Discriminator loss = 1.1331055164337158, GAN loss = [2.622544, 0.92517257, 1.0793328]\n",
      "Batch 229/700: Discriminator loss = 1.14247727394104, GAN loss = [2.4719298, 0.929467, 0.92443204]\n",
      "Batch 230/700: Discriminator loss = 1.095339298248291, GAN loss = [2.6659374, 0.9801891, 1.06774]\n",
      "Batch 231/700: Discriminator loss = 1.0897629261016846, GAN loss = [2.676145, 0.9944943, 1.0636424]\n",
      "Batch 232/700: Discriminator loss = 1.113953948020935, GAN loss = [2.4962842, 0.9429787, 0.93528724]\n",
      "Batch 233/700: Discriminator loss = 1.1141430139541626, GAN loss = [2.615251, 0.972857, 1.0243814]\n",
      "Batch 234/700: Discriminator loss = 1.1646147966384888, GAN loss = [2.458037, 0.88483626, 0.9551973]\n",
      "Batch 235/700: Discriminator loss = 1.1086163520812988, GAN loss = [2.657344, 0.93206894, 1.1073029]\n",
      "Batch 236/700: Discriminator loss = 1.1326888799667358, GAN loss = [2.5317943, 0.90474963, 1.0091134]\n",
      "Batch 237/700: Discriminator loss = 1.10525381565094, GAN loss = [2.6126702, 0.94715345, 1.0476173]\n",
      "Batch 238/700: Discriminator loss = 1.0901118516921997, GAN loss = [2.635301, 0.94619447, 1.0712396]\n",
      "Batch 239/700: Discriminator loss = 1.101548194885254, GAN loss = [2.5370486, 0.94496137, 0.9742399]\n",
      "Batch 240/700: Discriminator loss = 1.1188973188400269, GAN loss = [2.596572, 0.93204534, 1.0467037]\n",
      "Batch 241/700: Discriminator loss = 1.1275568008422852, GAN loss = [2.5469017, 0.9062222, 1.0228844]\n",
      "Batch 242/700: Discriminator loss = 1.1264042854309082, GAN loss = [2.524317, 0.90492415, 1.0016177]\n",
      "Batch 243/700: Discriminator loss = 1.122549057006836, GAN loss = [2.580737, 0.9019293, 1.0610545]\n",
      "Batch 244/700: Discriminator loss = 1.1510909795761108, GAN loss = [2.4414945, 0.86800253, 0.95574397]\n",
      "Batch 245/700: Discriminator loss = 1.123945713043213, GAN loss = [2.564877, 0.8962068, 1.0509247]\n",
      "Batch 246/700: Discriminator loss = 1.1221812963485718, GAN loss = [2.7497091, 0.9201394, 1.2118248]\n",
      "Batch 247/700: Discriminator loss = 1.1535696983337402, GAN loss = [2.5083969, 0.88912034, 1.0015159]\n",
      "Batch 248/700: Discriminator loss = 1.1350325345993042, GAN loss = [2.54678, 0.9407201, 0.98827547]\n",
      "Batch 249/700: Discriminator loss = 1.1211620569229126, GAN loss = [2.67373, 0.9309275, 1.1249944]\n",
      "Batch 250/700: Discriminator loss = 1.1557327508926392, GAN loss = [2.5285788, 0.9030471, 1.0077224]\n",
      "Batch 251/700: Discriminator loss = 1.1499677896499634, GAN loss = [2.454789, 0.8972672, 0.93970853]\n",
      "Batch 252/700: Discriminator loss = 1.1407678127288818, GAN loss = [2.4823003, 0.91731066, 0.9471775]\n",
      "Batch 253/700: Discriminator loss = 1.1116933822631836, GAN loss = [2.588896, 0.9343619, 1.0367198]\n",
      "Batch 254/700: Discriminator loss = 1.1176540851593018, GAN loss = [2.51828, 0.91946167, 0.98100036]\n",
      "Batch 255/700: Discriminator loss = 1.149677038192749, GAN loss = [2.541308, 0.9305993, 0.9929144]\n",
      "Batch 256/700: Discriminator loss = 1.109245777130127, GAN loss = [2.5824935, 0.96838164, 0.99635196]\n",
      "Batch 257/700: Discriminator loss = 1.100195050239563, GAN loss = [2.6331031, 0.9583835, 1.0569718]\n",
      "Batch 258/700: Discriminator loss = 1.102474331855774, GAN loss = [2.6545236, 0.9451594, 1.0915867]\n",
      "Batch 259/700: Discriminator loss = 1.0965747833251953, GAN loss = [2.5706005, 0.9651557, 0.98766756]\n",
      "Batch 260/700: Discriminator loss = 1.084742546081543, GAN loss = [2.6663609, 0.9714727, 1.0771414]\n",
      "Batch 261/700: Discriminator loss = 1.1129071712493896, GAN loss = [2.54297, 0.9481173, 0.9771364]\n",
      "Batch 262/700: Discriminator loss = 1.1027122735977173, GAN loss = [2.664893, 0.9777573, 1.069425]\n",
      "Batch 263/700: Discriminator loss = 1.1106947660446167, GAN loss = [2.5875642, 0.98902977, 0.9807985]\n",
      "Batch 264/700: Discriminator loss = 1.1140491962432861, GAN loss = [2.5919352, 0.9282846, 1.0458877]\n",
      "Batch 265/700: Discriminator loss = 1.131171703338623, GAN loss = [2.6029658, 0.9878637, 0.99732035]\n",
      "Batch 266/700: Discriminator loss = 1.1693297624588013, GAN loss = [2.5028768, 0.9304099, 0.954676]\n",
      "Batch 267/700: Discriminator loss = 1.1445661783218384, GAN loss = [2.587493, 0.9105153, 1.0592113]\n",
      "Batch 268/700: Discriminator loss = 1.1368328332901, GAN loss = [2.6047697, 0.9311487, 1.0558771]\n",
      "Batch 269/700: Discriminator loss = 1.1269035339355469, GAN loss = [2.540059, 0.92529863, 0.9970491]\n",
      "Batch 270/700: Discriminator loss = 1.1155047416687012, GAN loss = [2.697551, 0.94405174, 1.1358079]\n",
      "Batch 271/700: Discriminator loss = 1.1465624570846558, GAN loss = [2.593841, 0.8938756, 1.0822643]\n",
      "Batch 272/700: Discriminator loss = 1.1484538316726685, GAN loss = [2.533734, 0.92046005, 0.99557626]\n",
      "Batch 273/700: Discriminator loss = 1.1455329656600952, GAN loss = [2.5009797, 0.9078697, 0.9754053]\n",
      "Batch 274/700: Discriminator loss = 1.139972448348999, GAN loss = [2.5776825, 0.92094743, 1.0390123]\n",
      "Batch 275/700: Discriminator loss = 1.1323455572128296, GAN loss = [2.5457458, 0.93825823, 0.98973924]\n",
      "Batch 276/700: Discriminator loss = 1.1466423273086548, GAN loss = [2.5106945, 0.9034501, 0.98947144]\n",
      "Batch 277/700: Discriminator loss = 1.1407604217529297, GAN loss = [2.5256636, 0.90845525, 0.9994142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 278/700: Discriminator loss = 1.1255779266357422, GAN loss = [2.7098508, 0.9729254, 1.1191269]\n",
      "Batch 279/700: Discriminator loss = 1.108214020729065, GAN loss = [2.574247, 0.9501719, 1.0062687]\n",
      "Batch 280/700: Discriminator loss = 1.1228700876235962, GAN loss = [2.545954, 0.93100715, 0.99712324]\n",
      "Batch 281/700: Discriminator loss = 1.1184606552124023, GAN loss = [2.4700775, 0.92527235, 0.92694116]\n",
      "Batch 282/700: Discriminator loss = 1.1218208074569702, GAN loss = [2.5139062, 0.9159857, 0.9800393]\n",
      "Batch 283/700: Discriminator loss = 1.1251517534255981, GAN loss = [2.6035938, 0.9018179, 1.0838865]\n",
      "Batch 284/700: Discriminator loss = 1.117409348487854, GAN loss = [2.5503297, 0.9128682, 1.0195758]\n",
      "Batch 285/700: Discriminator loss = 1.10869562625885, GAN loss = [2.6351948, 0.9310723, 1.0862278]\n",
      "Batch 286/700: Discriminator loss = 1.099263072013855, GAN loss = [2.6264179, 0.9253234, 1.083194]\n",
      "Batch 287/700: Discriminator loss = 1.109484076499939, GAN loss = [2.6030314, 0.9534331, 1.0316854]\n",
      "Batch 288/700: Discriminator loss = 1.1160997152328491, GAN loss = [2.5214467, 0.9254686, 0.9780454]\n",
      "Batch 289/700: Discriminator loss = 1.1160575151443481, GAN loss = [2.4954042, 0.92883945, 0.94861025]\n",
      "Batch 290/700: Discriminator loss = 1.1096572875976562, GAN loss = [2.6095314, 0.9439857, 1.0475821]\n",
      "Batch 291/700: Discriminator loss = 1.1230581998825073, GAN loss = [2.5604892, 0.920444, 1.0220957]\n",
      "Batch 292/700: Discriminator loss = 1.1096659898757935, GAN loss = [2.5424724, 0.92519873, 0.99932706]\n",
      "Batch 293/700: Discriminator loss = 1.0981652736663818, GAN loss = [2.5423493, 0.9295085, 0.9949076]\n",
      "Batch 294/700: Discriminator loss = 1.091524600982666, GAN loss = [2.6352944, 0.9445215, 1.0728657]\n",
      "Batch 295/700: Discriminator loss = 1.1079450845718384, GAN loss = [2.6284401, 0.93919635, 1.0713481]\n",
      "Batch 296/700: Discriminator loss = 1.0829635858535767, GAN loss = [2.6568463, 0.94285864, 1.0960853]\n",
      "Batch 297/700: Discriminator loss = 1.1169427633285522, GAN loss = [2.5551512, 0.913607, 1.0236449]\n",
      "Batch 298/700: Discriminator loss = 1.095420479774475, GAN loss = [2.5500934, 0.95073974, 0.98146576]\n",
      "Batch 299/700: Discriminator loss = 1.1156542301177979, GAN loss = [2.656906, 0.9373129, 1.1017139]\n",
      "Batch 300/700: Discriminator loss = 1.1176886558532715, GAN loss = [2.5174522, 0.9175891, 0.9819725]\n",
      "Batch 301/700: Discriminator loss = 1.1157751083374023, GAN loss = [2.5459468, 0.92440444, 1.0036216]\n",
      "Batch 302/700: Discriminator loss = 1.1449811458587646, GAN loss = [2.5852165, 0.9245994, 1.0426899]\n",
      "Batch 303/700: Discriminator loss = 1.1097402572631836, GAN loss = [2.4778621, 0.9312775, 0.92865264]\n",
      "Batch 304/700: Discriminator loss = 1.111068844795227, GAN loss = [2.4908524, 0.91216284, 0.960773]\n",
      "Batch 305/700: Discriminator loss = 1.1516659259796143, GAN loss = [2.5235302, 0.8936651, 1.011983]\n",
      "Batch 306/700: Discriminator loss = 1.1080113649368286, GAN loss = [2.5554464, 0.94255537, 0.9950296]\n",
      "Batch 307/700: Discriminator loss = 1.1008609533309937, GAN loss = [2.5655913, 0.9239831, 1.0237551]\n",
      "Batch 308/700: Discriminator loss = 1.1057462692260742, GAN loss = [2.538621, 0.9331009, 0.9876926]\n",
      "Batch 309/700: Discriminator loss = 1.101889967918396, GAN loss = [2.6423662, 0.9268652, 1.0976857]\n",
      "Batch 310/700: Discriminator loss = 1.1349307298660278, GAN loss = [2.5231516, 0.92877614, 0.97655815]\n",
      "Batch 311/700: Discriminator loss = 1.1033623218536377, GAN loss = [2.5366118, 0.9252673, 0.9935461]\n",
      "Batch 312/700: Discriminator loss = 1.1295121908187866, GAN loss = [2.5224512, 0.9134976, 0.99117136]\n",
      "Batch 313/700: Discriminator loss = 1.116498351097107, GAN loss = [2.588554, 0.93268824, 1.038081]\n",
      "Batch 314/700: Discriminator loss = 1.116931438446045, GAN loss = [2.524297, 0.934924, 0.9715847]\n",
      "Batch 315/700: Discriminator loss = 1.119653344154358, GAN loss = [2.5991266, 0.94388026, 1.0374721]\n",
      "Batch 316/700: Discriminator loss = 1.1190460920333862, GAN loss = [2.5555272, 0.9927021, 0.9450495]\n",
      "Batch 317/700: Discriminator loss = 1.1225500106811523, GAN loss = [2.520934, 0.93915784, 0.9639978]\n",
      "Batch 318/700: Discriminator loss = 1.1181913614273071, GAN loss = [2.5739424, 0.9407297, 1.0154322]\n",
      "Batch 319/700: Discriminator loss = 1.1044961214065552, GAN loss = [2.5939221, 0.9411236, 1.0350165]\n",
      "Batch 320/700: Discriminator loss = 1.09433114528656, GAN loss = [2.5716736, 0.962157, 0.99172616]\n",
      "Batch 321/700: Discriminator loss = 1.108718752861023, GAN loss = [2.5388288, 0.940904, 0.9801081]\n",
      "Batch 322/700: Discriminator loss = 1.1497236490249634, GAN loss = [2.6050694, 0.97598094, 1.0112695]\n",
      "Batch 323/700: Discriminator loss = 1.1044725179672241, GAN loss = [2.682807, 0.9914757, 1.0735137]\n",
      "Batch 324/700: Discriminator loss = 1.112114667892456, GAN loss = [2.5239668, 0.92139536, 0.98474455]\n",
      "Batch 325/700: Discriminator loss = 1.107956886291504, GAN loss = [2.5980916, 0.9412254, 1.0390344]\n",
      "Batch 326/700: Discriminator loss = 1.1110963821411133, GAN loss = [2.6150231, 0.9731466, 1.0240349]\n",
      "Batch 327/700: Discriminator loss = 1.079722285270691, GAN loss = [2.7068865, 0.970787, 1.1182628]\n",
      "Batch 328/700: Discriminator loss = 1.0992857217788696, GAN loss = [2.6385787, 0.9483034, 1.0724086]\n",
      "Batch 329/700: Discriminator loss = 1.1059938669204712, GAN loss = [2.5759187, 0.96043617, 0.9975865]\n",
      "Batch 330/700: Discriminator loss = 1.0670408010482788, GAN loss = [2.7391655, 0.99368554, 1.1275693]\n",
      "Batch 331/700: Discriminator loss = 1.0949405431747437, GAN loss = [2.5855033, 0.9524958, 1.0151216]\n",
      "Batch 332/700: Discriminator loss = 1.0742162466049194, GAN loss = [2.6866124, 0.98642516, 1.0823295]\n",
      "Batch 333/700: Discriminator loss = 1.0637195110321045, GAN loss = [2.7196765, 0.992991, 1.1088642]\n",
      "Batch 334/700: Discriminator loss = 1.0753347873687744, GAN loss = [2.7107236, 1.0336471, 1.0592898]\n",
      "Batch 335/700: Discriminator loss = 1.0533385276794434, GAN loss = [2.7380278, 1.0031807, 1.1170877]\n",
      "Batch 336/700: Discriminator loss = 1.077467679977417, GAN loss = [2.7397864, 0.9735197, 1.1485425]\n",
      "Batch 337/700: Discriminator loss = 1.0617234706878662, GAN loss = [2.7138293, 0.977426, 1.1187228]\n",
      "Batch 338/700: Discriminator loss = 1.0817285776138306, GAN loss = [2.7042787, 0.9810744, 1.1055748]\n",
      "Batch 339/700: Discriminator loss = 1.0736333131790161, GAN loss = [2.7222843, 0.9360134, 1.1686938]\n",
      "Batch 340/700: Discriminator loss = 1.0643426179885864, GAN loss = [2.782072, 0.96395606, 1.2005807]\n",
      "Batch 341/700: Discriminator loss = 1.0597566366195679, GAN loss = [2.7629883, 0.9633515, 1.1821557]\n",
      "Batch 342/700: Discriminator loss = 1.0935900211334229, GAN loss = [2.817196, 0.94264543, 1.2571118]\n",
      "Batch 343/700: Discriminator loss = 1.0978766679763794, GAN loss = [2.6933026, 0.94422567, 1.1316317]\n",
      "Batch 344/700: Discriminator loss = 1.0979390144348145, GAN loss = [2.5966158, 0.9248489, 1.0543045]\n",
      "Batch 345/700: Discriminator loss = 1.0783271789550781, GAN loss = [2.7175176, 0.96210456, 1.1379497]\n",
      "Batch 346/700: Discriminator loss = 1.082180380821228, GAN loss = [2.702044, 0.9542061, 1.1303889]\n",
      "Batch 347/700: Discriminator loss = 1.1046977043151855, GAN loss = [2.6413503, 0.9831732, 1.0407462]\n",
      "Batch 348/700: Discriminator loss = 1.0741068124771118, GAN loss = [2.7740054, 1.0113573, 1.1452428]\n",
      "Batch 349/700: Discriminator loss = 1.0712957382202148, GAN loss = [2.7398207, 0.96836877, 1.1540471]\n",
      "Batch 350/700: Discriminator loss = 1.0772411823272705, GAN loss = [2.8205125, 0.9807455, 1.2223692]\n",
      "Batch 351/700: Discriminator loss = 1.0832288265228271, GAN loss = [2.6491287, 0.9741547, 1.0575637]\n",
      "Batch 352/700: Discriminator loss = 1.103241205215454, GAN loss = [2.6469073, 0.95198447, 1.0775119]\n",
      "Batch 353/700: Discriminator loss = 1.1136400699615479, GAN loss = [2.5609894, 0.93810105, 1.0054928]\n",
      "Batch 354/700: Discriminator loss = 1.099990963935852, GAN loss = [2.720555, 0.94678736, 1.1563733]\n",
      "Batch 355/700: Discriminator loss = 1.1214648485183716, GAN loss = [2.7147446, 0.94695807, 1.1503822]\n",
      "Batch 356/700: Discriminator loss = 1.1446545124053955, GAN loss = [2.6306555, 0.97494936, 1.0383182]\n",
      "Batch 357/700: Discriminator loss = 1.1173709630966187, GAN loss = [2.604589, 0.97961897, 1.007579]\n",
      "Batch 358/700: Discriminator loss = 1.068790078163147, GAN loss = [2.72342, 0.99804187, 1.1080076]\n",
      "Batch 359/700: Discriminator loss = 1.0928239822387695, GAN loss = [2.6725588, 0.977129, 1.078093]\n",
      "Batch 360/700: Discriminator loss = 1.1161435842514038, GAN loss = [2.6788151, 0.98023933, 1.0813023]\n",
      "Batch 361/700: Discriminator loss = 1.0830349922180176, GAN loss = [2.6687448, 0.9791597, 1.0723352]\n",
      "Batch 362/700: Discriminator loss = 1.0873922109603882, GAN loss = [2.7267573, 0.97229177, 1.1372341]\n",
      "Batch 363/700: Discriminator loss = 1.107298493385315, GAN loss = [2.6029072, 0.994378, 0.99131846]\n",
      "Batch 364/700: Discriminator loss = 1.084608793258667, GAN loss = [2.7053916, 0.9923655, 1.0958552]\n",
      "Batch 365/700: Discriminator loss = 1.1302440166473389, GAN loss = [2.5267537, 0.95063126, 0.9589738]\n",
      "Batch 366/700: Discriminator loss = 1.104325532913208, GAN loss = [2.600648, 0.9639485, 1.019595]\n",
      "Batch 367/700: Discriminator loss = 1.0978764295578003, GAN loss = [2.746023, 0.9882048, 1.1407528]\n",
      "Batch 368/700: Discriminator loss = 1.098911166191101, GAN loss = [2.635393, 0.9762728, 1.0420884]\n",
      "Batch 369/700: Discriminator loss = 1.1064413785934448, GAN loss = [2.6092815, 1.003569, 0.988702]\n",
      "Batch 370/700: Discriminator loss = 1.0989636182785034, GAN loss = [2.6049538, 0.9650463, 1.0229063]\n",
      "Batch 371/700: Discriminator loss = 1.1098731756210327, GAN loss = [2.6545124, 0.992891, 1.0446373]\n",
      "Batch 372/700: Discriminator loss = 1.1156113147735596, GAN loss = [2.5698535, 0.95306706, 0.99982345]\n",
      "Batch 373/700: Discriminator loss = 1.152468204498291, GAN loss = [2.5801065, 0.9077413, 1.0554237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 374/700: Discriminator loss = 1.103018045425415, GAN loss = [2.6495516, 0.95553076, 1.0770991]\n",
      "Batch 375/700: Discriminator loss = 1.0957849025726318, GAN loss = [2.7994823, 1.0259845, 1.1565822]\n",
      "Batch 376/700: Discriminator loss = 1.125171422958374, GAN loss = [2.5973248, 0.9758077, 1.0045892]\n",
      "Batch 377/700: Discriminator loss = 1.0887775421142578, GAN loss = [2.6524835, 0.9612075, 1.0743259]\n",
      "Batch 378/700: Discriminator loss = 1.1185754537582397, GAN loss = [2.6886804, 0.9839669, 1.0877364]\n",
      "Batch 379/700: Discriminator loss = 1.1001503467559814, GAN loss = [2.5702515, 0.9922892, 0.9609495]\n",
      "Batch 380/700: Discriminator loss = 1.096421480178833, GAN loss = [2.6295898, 0.96535903, 1.0471874]\n",
      "Batch 381/700: Discriminator loss = 1.1298738718032837, GAN loss = [2.5964978, 0.9454044, 1.0340171]\n",
      "Batch 382/700: Discriminator loss = 1.1069108247756958, GAN loss = [2.7187152, 1.0270528, 1.0745505]\n",
      "Batch 383/700: Discriminator loss = 1.122475028038025, GAN loss = [2.6211534, 0.9377496, 1.0662781]\n",
      "Batch 384/700: Discriminator loss = 1.1581509113311768, GAN loss = [2.620273, 0.9579241, 1.0452073]\n",
      "Batch 385/700: Discriminator loss = 1.1008740663528442, GAN loss = [2.6099765, 0.9929535, 0.9998701]\n",
      "Batch 386/700: Discriminator loss = 1.0652859210968018, GAN loss = [2.6272016, 1.0193561, 0.99069166]\n",
      "Batch 387/700: Discriminator loss = 1.1514286994934082, GAN loss = [2.5435548, 0.98485875, 0.94155073]\n",
      "Batch 388/700: Discriminator loss = 1.1465833187103271, GAN loss = [2.4423916, 0.9433153, 0.8819145]\n",
      "Batch 389/700: Discriminator loss = 1.1365180015563965, GAN loss = [2.5651536, 0.94166535, 1.0062804]\n",
      "Batch 390/700: Discriminator loss = 1.1389319896697998, GAN loss = [2.5169437, 0.95199794, 0.94770014]\n",
      "Batch 391/700: Discriminator loss = 1.129625916481018, GAN loss = [2.5395951, 0.93396515, 0.988348]\n",
      "Batch 392/700: Discriminator loss = 1.1252045631408691, GAN loss = [2.6080327, 1.0032026, 0.98754996]\n",
      "Batch 393/700: Discriminator loss = 1.1097365617752075, GAN loss = [2.5325303, 0.9704108, 0.94485235]\n",
      "Batch 394/700: Discriminator loss = 1.063968539237976, GAN loss = [2.657016, 1.0179992, 1.0217683]\n",
      "Batch 395/700: Discriminator loss = 1.084761619567871, GAN loss = [2.5867734, 0.9977158, 0.97182727]\n",
      "Batch 396/700: Discriminator loss = 1.1374887228012085, GAN loss = [2.465573, 0.96254176, 0.88579005]\n",
      "Batch 397/700: Discriminator loss = 1.1256983280181885, GAN loss = [2.5660052, 0.94109106, 1.0076742]\n",
      "Batch 398/700: Discriminator loss = 1.1054848432540894, GAN loss = [2.5815651, 0.9852238, 0.9791309]\n",
      "Batch 399/700: Discriminator loss = 1.0914796590805054, GAN loss = [2.5824926, 0.9636838, 1.0016131]\n",
      "Batch 400/700: Discriminator loss = 1.1208876371383667, GAN loss = [2.5517159, 0.92510164, 1.0094535]\n",
      "Batch 401/700: Discriminator loss = 1.1780744791030884, GAN loss = [2.4545612, 0.93414533, 0.90325934]\n",
      "Batch 402/700: Discriminator loss = 1.1333972215652466, GAN loss = [2.509127, 0.9339644, 0.95798737]\n",
      "Batch 403/700: Discriminator loss = 1.1404564380645752, GAN loss = [2.5304928, 0.9241382, 0.989148]\n",
      "Batch 404/700: Discriminator loss = 1.1230255365371704, GAN loss = [2.5475285, 0.9454502, 0.98484564]\n",
      "Batch 405/700: Discriminator loss = 1.1157095432281494, GAN loss = [2.5163698, 0.9461087, 0.9530386]\n",
      "Batch 406/700: Discriminator loss = 1.130425214767456, GAN loss = [2.522476, 0.9405616, 0.9646779]\n",
      "Batch 407/700: Discriminator loss = 1.1087522506713867, GAN loss = [2.5736787, 0.95583045, 1.0005971]\n",
      "Batch 408/700: Discriminator loss = 1.146027684211731, GAN loss = [2.478986, 0.91374105, 0.9479877]\n",
      "Batch 409/700: Discriminator loss = 1.113993763923645, GAN loss = [2.533074, 0.92810386, 0.98772573]\n",
      "Batch 410/700: Discriminator loss = 1.1094350814819336, GAN loss = [2.614538, 0.9347208, 1.062577]\n",
      "Batch 411/700: Discriminator loss = 1.1433926820755005, GAN loss = [2.6283047, 1.0002885, 1.0107563]\n",
      "Batch 412/700: Discriminator loss = 1.1397637128829956, GAN loss = [2.5547235, 0.9276965, 1.00978]\n",
      "Batch 413/700: Discriminator loss = 1.1142537593841553, GAN loss = [2.473965, 0.92746484, 0.9292256]\n",
      "Batch 414/700: Discriminator loss = 1.1524258852005005, GAN loss = [2.487703, 0.8994631, 0.97095513]\n",
      "Batch 415/700: Discriminator loss = 1.130183458328247, GAN loss = [2.5282435, 0.9301584, 0.9808072]\n",
      "Batch 416/700: Discriminator loss = 1.1215779781341553, GAN loss = [2.5028567, 0.9336457, 0.9519168]\n",
      "Batch 417/700: Discriminator loss = 1.0878204107284546, GAN loss = [2.6061594, 0.9826505, 1.006218]\n",
      "Batch 418/700: Discriminator loss = 1.0995768308639526, GAN loss = [2.644603, 0.9681525, 1.0591677]\n",
      "Batch 419/700: Discriminator loss = 1.1171464920043945, GAN loss = [2.5109906, 0.93514025, 0.9585523]\n",
      "Batch 420/700: Discriminator loss = 1.1297787427902222, GAN loss = [2.6414204, 0.92272735, 1.1013858]\n",
      "Batch 421/700: Discriminator loss = 1.1009924411773682, GAN loss = [2.6317093, 0.9499639, 1.0644132]\n",
      "Batch 422/700: Discriminator loss = 1.1040536165237427, GAN loss = [2.5968711, 0.94034964, 1.0391669]\n",
      "Batch 423/700: Discriminator loss = 1.1071107387542725, GAN loss = [2.4953084, 0.94319963, 0.9347258]\n",
      "Batch 424/700: Discriminator loss = 1.1215882301330566, GAN loss = [2.555606, 0.92356455, 1.0146247]\n",
      "Batch 425/700: Discriminator loss = 1.1419016122817993, GAN loss = [2.5195992, 0.93570524, 0.96642715]\n",
      "Batch 426/700: Discriminator loss = 1.1144887208938599, GAN loss = [2.5792925, 0.9229462, 1.0388138]\n",
      "Batch 427/700: Discriminator loss = 1.136651873588562, GAN loss = [2.5781338, 0.9292147, 1.0313659]\n",
      "Batch 428/700: Discriminator loss = 1.1271134614944458, GAN loss = [2.59927, 0.9236614, 1.0580369]\n",
      "Batch 429/700: Discriminator loss = 1.1127315759658813, GAN loss = [2.5498621, 0.9725342, 0.9597249]\n",
      "Batch 430/700: Discriminator loss = 1.1109106540679932, GAN loss = [2.5615966, 0.9269155, 1.0170376]\n",
      "Batch 431/700: Discriminator loss = 1.0956114530563354, GAN loss = [2.6126041, 0.9909788, 1.0039557]\n",
      "Batch 432/700: Discriminator loss = 1.1648555994033813, GAN loss = [2.4994948, 0.90464777, 0.97714883]\n",
      "Batch 433/700: Discriminator loss = 1.1352640390396118, GAN loss = [2.5201404, 0.90711427, 0.99529374]\n",
      "Batch 434/700: Discriminator loss = 1.1248562335968018, GAN loss = [2.5926187, 0.98373955, 0.9911142]\n",
      "Batch 435/700: Discriminator loss = 1.1023821830749512, GAN loss = [2.5934513, 0.95072764, 1.0249617]\n",
      "Batch 436/700: Discriminator loss = 1.1015781164169312, GAN loss = [2.6159663, 0.9629422, 1.0352602]\n",
      "Batch 437/700: Discriminator loss = 1.110460638999939, GAN loss = [2.6064608, 0.9308134, 1.0578806]\n",
      "Batch 438/700: Discriminator loss = 1.1185832023620605, GAN loss = [2.4925652, 0.9363259, 0.93846494]\n",
      "Batch 439/700: Discriminator loss = 1.1134006977081299, GAN loss = [2.5922196, 0.9435144, 1.0309453]\n",
      "Batch 440/700: Discriminator loss = 1.1225616931915283, GAN loss = [2.6314514, 0.9481136, 1.0655849]\n",
      "Batch 441/700: Discriminator loss = 1.119428277015686, GAN loss = [2.5611722, 0.9311287, 1.0122502]\n",
      "Batch 442/700: Discriminator loss = 1.109514832496643, GAN loss = [2.611946, 0.919769, 1.0743364]\n",
      "Batch 443/700: Discriminator loss = 1.1121633052825928, GAN loss = [2.5501986, 0.951725, 0.98058873]\n",
      "Batch 444/700: Discriminator loss = 1.1151853799819946, GAN loss = [2.542105, 0.923123, 1.0011035]\n",
      "Batch 445/700: Discriminator loss = 1.1197171211242676, GAN loss = [2.6377258, 0.9350962, 1.0847375]\n",
      "Batch 446/700: Discriminator loss = 1.122376561164856, GAN loss = [2.684019, 0.9473816, 1.1187146]\n",
      "Batch 447/700: Discriminator loss = 1.1169748306274414, GAN loss = [2.5755854, 0.91174036, 1.0459036]\n",
      "Batch 448/700: Discriminator loss = 1.1352193355560303, GAN loss = [2.5742595, 0.9018232, 1.054475]\n",
      "Batch 449/700: Discriminator loss = 1.125093698501587, GAN loss = [2.7113857, 0.92490196, 1.1684976]\n",
      "Batch 450/700: Discriminator loss = 1.1052359342575073, GAN loss = [2.6481917, 0.92940795, 1.1007794]\n",
      "Batch 451/700: Discriminator loss = 1.1312347650527954, GAN loss = [2.6023448, 0.8908141, 1.0935276]\n",
      "Batch 452/700: Discriminator loss = 1.1138588190078735, GAN loss = [2.5879338, 0.89947474, 1.0704467]\n",
      "Batch 453/700: Discriminator loss = 1.104077696800232, GAN loss = [2.5068972, 0.9317141, 0.9571665]\n",
      "Batch 454/700: Discriminator loss = 1.1494007110595703, GAN loss = [2.6280966, 0.8789145, 1.1311759]\n",
      "Batch 455/700: Discriminator loss = 1.1366933584213257, GAN loss = [2.5388682, 0.8924726, 1.0283717]\n",
      "Batch 456/700: Discriminator loss = 1.1287803649902344, GAN loss = [2.5509784, 0.91128504, 1.0216441]\n",
      "Batch 457/700: Discriminator loss = 1.143251895904541, GAN loss = [2.5357137, 0.88770515, 1.0299542]\n",
      "Batch 458/700: Discriminator loss = 1.1388555765151978, GAN loss = [2.629253, 0.8816601, 1.1295586]\n",
      "Batch 459/700: Discriminator loss = 1.1468544006347656, GAN loss = [2.5311215, 0.8618252, 1.051266]\n",
      "Batch 460/700: Discriminator loss = 1.107054352760315, GAN loss = [2.673777, 0.9348862, 1.1208322]\n",
      "Batch 461/700: Discriminator loss = 1.1307066679000854, GAN loss = [2.7127948, 0.9058391, 1.1889141]\n",
      "Batch 462/700: Discriminator loss = 1.1502000093460083, GAN loss = [2.5081851, 0.87358075, 1.0165737]\n",
      "Batch 463/700: Discriminator loss = 1.1407301425933838, GAN loss = [2.579463, 0.88515425, 1.0762725]\n",
      "Batch 464/700: Discriminator loss = 1.10136878490448, GAN loss = [2.6792169, 0.9350532, 1.1261356]\n",
      "Batch 465/700: Discriminator loss = 1.0806481838226318, GAN loss = [2.6941469, 0.95896584, 1.1171544]\n",
      "Batch 466/700: Discriminator loss = 1.1100744009017944, GAN loss = [2.6301382, 0.90477455, 1.1072923]\n",
      "Batch 467/700: Discriminator loss = 1.116185188293457, GAN loss = [2.541288, 0.8905022, 1.0326629]\n",
      "Batch 468/700: Discriminator loss = 1.1035480499267578, GAN loss = [2.6741529, 0.91495967, 1.1410336]\n",
      "Batch 469/700: Discriminator loss = 1.107879400253296, GAN loss = [2.6606054, 0.9168959, 1.1254988]\n",
      "Batch 470/700: Discriminator loss = 1.1189264059066772, GAN loss = [2.6345646, 0.90240324, 1.1139404]\n",
      "Batch 471/700: Discriminator loss = 1.1229819059371948, GAN loss = [2.5520015, 0.905231, 1.028543]\n",
      "Batch 472/700: Discriminator loss = 1.1078988313674927, GAN loss = [2.619837, 0.90131134, 1.1003033]\n",
      "Batch 473/700: Discriminator loss = 1.1087933778762817, GAN loss = [2.5434513, 0.9288657, 0.99638206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 474/700: Discriminator loss = 1.1037592887878418, GAN loss = [2.6486754, 0.94705415, 1.083411]\n",
      "Batch 475/700: Discriminator loss = 1.0960512161254883, GAN loss = [2.6891193, 0.95646346, 1.1144288]\n",
      "Batch 476/700: Discriminator loss = 1.1183438301086426, GAN loss = [2.7228644, 0.9178207, 1.186785]\n",
      "Batch 477/700: Discriminator loss = 1.0802735090255737, GAN loss = [2.7222338, 0.9690704, 1.1348872]\n",
      "Batch 478/700: Discriminator loss = 1.0957283973693848, GAN loss = [2.854551, 0.9770282, 1.2592397]\n",
      "Batch 479/700: Discriminator loss = 1.0901051759719849, GAN loss = [2.7420728, 0.9569506, 1.1668179]\n",
      "Batch 480/700: Discriminator loss = 1.101217269897461, GAN loss = [2.6518738, 0.9598441, 1.0737371]\n",
      "Batch 481/700: Discriminator loss = 1.0947750806808472, GAN loss = [2.8050575, 0.9818082, 1.2049761]\n",
      "Batch 482/700: Discriminator loss = 1.1246600151062012, GAN loss = [2.6021192, 0.93948114, 1.0443734]\n",
      "Batch 483/700: Discriminator loss = 1.098915934562683, GAN loss = [2.560606, 0.94851494, 0.99380255]\n",
      "Batch 484/700: Discriminator loss = 1.118597388267517, GAN loss = [2.608689, 0.9291501, 1.0612465]\n",
      "Batch 485/700: Discriminator loss = 1.0895063877105713, GAN loss = [2.6649265, 0.9733562, 1.0732864]\n",
      "Batch 486/700: Discriminator loss = 1.106213927268982, GAN loss = [2.6882646, 0.944478, 1.1254884]\n",
      "Batch 487/700: Discriminator loss = 1.13004732131958, GAN loss = [2.6197531, 0.9471373, 1.0542886]\n",
      "Batch 488/700: Discriminator loss = 1.099623441696167, GAN loss = [2.6062393, 0.94459504, 1.0433248]\n",
      "Batch 489/700: Discriminator loss = 1.124651312828064, GAN loss = [2.5939758, 0.93090576, 1.0447605]\n",
      "Batch 490/700: Discriminator loss = 1.1193536520004272, GAN loss = [2.7011383, 0.9635037, 1.1193357]\n",
      "Batch 491/700: Discriminator loss = 1.1064105033874512, GAN loss = [2.7090106, 0.99587035, 1.0948741]\n",
      "Batch 492/700: Discriminator loss = 1.1232420206069946, GAN loss = [2.567305, 0.9645504, 0.98447067]\n",
      "Batch 493/700: Discriminator loss = 1.1218079328536987, GAN loss = [2.5579906, 0.94298697, 0.99674135]\n",
      "Batch 494/700: Discriminator loss = 1.1095428466796875, GAN loss = [2.6423693, 0.97080964, 1.0533208]\n",
      "Batch 495/700: Discriminator loss = 1.1391267776489258, GAN loss = [2.7059865, 0.95167834, 1.1360497]\n",
      "Batch 496/700: Discriminator loss = 1.1135015487670898, GAN loss = [2.7246923, 0.98316693, 1.1232032]\n",
      "Batch 497/700: Discriminator loss = 1.0964621305465698, GAN loss = [2.7248137, 0.9914483, 1.1150197]\n",
      "Batch 498/700: Discriminator loss = 1.1278852224349976, GAN loss = [2.554022, 0.9580459, 0.97764236]\n",
      "Batch 499/700: Discriminator loss = 1.1369835138320923, GAN loss = [2.5995255, 0.9493433, 1.0318564]\n",
      "Batch 500/700: Discriminator loss = 1.1188783645629883, GAN loss = [2.6426127, 0.9315035, 1.0927943]\n",
      "Batch 501/700: Discriminator loss = 1.1356126070022583, GAN loss = [2.591617, 0.91677314, 1.0565565]\n",
      "Batch 502/700: Discriminator loss = 1.1142237186431885, GAN loss = [2.598484, 0.95113504, 1.029084]\n",
      "Batch 503/700: Discriminator loss = 1.096425175666809, GAN loss = [2.774049, 0.98966384, 1.1661519]\n",
      "Batch 504/700: Discriminator loss = 1.1259839534759521, GAN loss = [2.697198, 0.94653976, 1.1324252]\n",
      "Batch 505/700: Discriminator loss = 1.133975863456726, GAN loss = [2.5336652, 0.87923604, 1.0362207]\n",
      "Batch 506/700: Discriminator loss = 1.128427267074585, GAN loss = [2.5569038, 0.91750544, 1.0212228]\n",
      "Batch 507/700: Discriminator loss = 1.120442271232605, GAN loss = [2.6322381, 0.9363358, 1.0777215]\n",
      "Batch 508/700: Discriminator loss = 1.174033522605896, GAN loss = [2.5380657, 0.88343155, 1.0364169]\n",
      "Batch 509/700: Discriminator loss = 1.1380360126495361, GAN loss = [2.67868, 0.92825246, 1.1321901]\n",
      "Batch 510/700: Discriminator loss = 1.1497218608856201, GAN loss = [2.588171, 0.94001025, 1.0298946]\n",
      "Batch 511/700: Discriminator loss = 1.1174328327178955, GAN loss = [2.6555202, 0.95666575, 1.0805528]\n",
      "Batch 512/700: Discriminator loss = 1.1154556274414062, GAN loss = [2.676315, 0.9289618, 1.1290469]\n",
      "Batch 513/700: Discriminator loss = 1.1649932861328125, GAN loss = [2.6247363, 0.921812, 1.0846175]\n",
      "Batch 514/700: Discriminator loss = 1.1468431949615479, GAN loss = [2.5239785, 0.89857936, 1.0070823]\n",
      "Batch 515/700: Discriminator loss = 1.14742910861969, GAN loss = [2.4736555, 0.90220714, 0.9531301]\n",
      "Batch 516/700: Discriminator loss = 1.1361740827560425, GAN loss = [2.549451, 0.89986753, 1.0312595]\n",
      "Batch 517/700: Discriminator loss = 1.1610366106033325, GAN loss = [2.5424814, 0.89149725, 1.0326927]\n",
      "Batch 518/700: Discriminator loss = 1.1350716352462769, GAN loss = [2.6023362, 0.9025643, 1.0815462]\n",
      "Batch 519/700: Discriminator loss = 1.137233853340149, GAN loss = [2.5921128, 0.9260333, 1.0478972]\n",
      "Batch 520/700: Discriminator loss = 1.120011806488037, GAN loss = [2.6020463, 0.94944686, 1.0344522]\n",
      "Batch 521/700: Discriminator loss = 1.1180288791656494, GAN loss = [2.599688, 0.9194867, 1.0620657]\n",
      "Batch 522/700: Discriminator loss = 1.0956778526306152, GAN loss = [2.5600967, 0.9573907, 0.98459125]\n",
      "Batch 523/700: Discriminator loss = 1.104209065437317, GAN loss = [2.5905461, 1.0002055, 0.9722688]\n",
      "Batch 524/700: Discriminator loss = 1.1720497608184814, GAN loss = [2.485091, 0.9104729, 0.95656776]\n",
      "Batch 525/700: Discriminator loss = 1.1615979671478271, GAN loss = [2.5594432, 0.93764514, 1.0037909]\n",
      "Batch 526/700: Discriminator loss = 1.1454561948776245, GAN loss = [2.5802274, 0.9560309, 1.0062189]\n",
      "Batch 527/700: Discriminator loss = 1.1364502906799316, GAN loss = [2.5598161, 0.9408414, 1.0010394]\n",
      "Batch 528/700: Discriminator loss = 1.1647409200668335, GAN loss = [2.527084, 0.934811, 0.9743868]\n",
      "Batch 529/700: Discriminator loss = 1.1473758220672607, GAN loss = [2.4470387, 0.9313836, 0.89777946]\n",
      "Batch 530/700: Discriminator loss = 1.200707197189331, GAN loss = [2.497878, 0.95721674, 0.922809]\n",
      "Batch 531/700: Discriminator loss = 1.1683706045150757, GAN loss = [2.43675, 0.9027587, 0.9161191]\n",
      "Batch 532/700: Discriminator loss = 1.1688640117645264, GAN loss = [2.5822115, 0.9778911, 0.9864391]\n",
      "Batch 533/700: Discriminator loss = 1.1926835775375366, GAN loss = [2.4191947, 0.92896265, 0.87233055]\n",
      "Batch 534/700: Discriminator loss = 1.1987355947494507, GAN loss = [2.4500828, 0.9077062, 0.9244377]\n",
      "Batch 535/700: Discriminator loss = 1.1642000675201416, GAN loss = [2.4421842, 0.9678714, 0.85636735]\n",
      "Batch 536/700: Discriminator loss = 1.1714653968811035, GAN loss = [2.3675356, 0.91232085, 0.8372607]\n",
      "Batch 537/700: Discriminator loss = 1.169057011604309, GAN loss = [2.436801, 0.9199601, 0.8989103]\n",
      "Batch 538/700: Discriminator loss = 1.1396145820617676, GAN loss = [2.4346874, 0.9505313, 0.8662415]\n",
      "Batch 539/700: Discriminator loss = 1.1718522310256958, GAN loss = [2.4044049, 0.9018995, 0.88460684]\n",
      "Batch 540/700: Discriminator loss = 1.1662652492523193, GAN loss = [2.4104698, 0.887795, 0.9047897]\n",
      "Batch 541/700: Discriminator loss = 1.1617220640182495, GAN loss = [2.4218283, 0.9000234, 0.9039345]\n",
      "Batch 542/700: Discriminator loss = 1.1578471660614014, GAN loss = [2.4516883, 0.92963403, 0.9042137]\n",
      "Batch 543/700: Discriminator loss = 1.1534172296524048, GAN loss = [2.4364836, 0.9053955, 0.91326094]\n",
      "Batch 544/700: Discriminator loss = 1.1470017433166504, GAN loss = [2.4528933, 0.9094204, 0.92567366]\n",
      "Batch 545/700: Discriminator loss = 1.1391514539718628, GAN loss = [2.4846277, 0.9247469, 0.9421229]\n",
      "Batch 546/700: Discriminator loss = 1.1639740467071533, GAN loss = [2.4636877, 0.94927406, 0.8966966]\n",
      "Batch 547/700: Discriminator loss = 1.1571369171142578, GAN loss = [2.4536152, 0.88458145, 0.95134443]\n",
      "Batch 548/700: Discriminator loss = 1.1269896030426025, GAN loss = [2.482445, 0.90991575, 0.9548588]\n",
      "Batch 549/700: Discriminator loss = 1.1534589529037476, GAN loss = [2.4801736, 0.9364458, 0.9260783]\n",
      "Batch 550/700: Discriminator loss = 1.1390045881271362, GAN loss = [2.474377, 0.9223955, 0.93436754]\n",
      "Batch 551/700: Discriminator loss = 1.1717535257339478, GAN loss = [2.4723084, 0.88318545, 0.97155166]\n",
      "Batch 552/700: Discriminator loss = 1.135658860206604, GAN loss = [2.4799156, 0.90127563, 0.9610522]\n",
      "Batch 553/700: Discriminator loss = 1.149398922920227, GAN loss = [2.5131931, 0.8930296, 1.0025572]\n",
      "Batch 554/700: Discriminator loss = 1.1815072298049927, GAN loss = [2.3481858, 0.8521534, 0.87847066]\n",
      "Batch 555/700: Discriminator loss = 1.1540826559066772, GAN loss = [2.4295323, 0.8776747, 0.93433815]\n",
      "Batch 556/700: Discriminator loss = 1.170129418373108, GAN loss = [2.459357, 0.86149716, 0.9803669]\n",
      "Batch 557/700: Discriminator loss = 1.1328898668289185, GAN loss = [2.4725194, 0.8838133, 0.9712048]\n",
      "Batch 558/700: Discriminator loss = 1.150221824645996, GAN loss = [2.4724538, 0.86965895, 0.98529136]\n",
      "Batch 559/700: Discriminator loss = 1.1416586637496948, GAN loss = [2.3624334, 0.88435507, 0.8605766]\n",
      "Batch 560/700: Discriminator loss = 1.1404004096984863, GAN loss = [2.499715, 0.8829912, 0.9992246]\n",
      "Batch 561/700: Discriminator loss = 1.1477924585342407, GAN loss = [2.462575, 0.8787858, 0.9663017]\n",
      "Batch 562/700: Discriminator loss = 1.1552118062973022, GAN loss = [2.4383028, 0.8883773, 0.93244034]\n",
      "Batch 563/700: Discriminator loss = 1.1224145889282227, GAN loss = [2.5416625, 0.90264845, 1.0215422]\n",
      "Batch 564/700: Discriminator loss = 1.1057968139648438, GAN loss = [2.5917985, 0.93799543, 1.0363469]\n",
      "Batch 565/700: Discriminator loss = 1.1349635124206543, GAN loss = [2.4275777, 0.88676786, 0.9233671]\n",
      "Batch 566/700: Discriminator loss = 1.1176730394363403, GAN loss = [2.528886, 0.92478514, 0.9866704]\n",
      "Batch 567/700: Discriminator loss = 1.1311291456222534, GAN loss = [2.5197654, 0.9281885, 0.9741261]\n",
      "Batch 568/700: Discriminator loss = 1.1299844980239868, GAN loss = [2.5244038, 0.8946422, 1.0123088]\n",
      "Batch 569/700: Discriminator loss = 1.0985411405563354, GAN loss = [2.484698, 0.9394706, 0.9277861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 570/700: Discriminator loss = 1.1317801475524902, GAN loss = [2.5214639, 0.9206445, 0.98339486]\n",
      "Batch 571/700: Discriminator loss = 1.1493946313858032, GAN loss = [2.5319703, 0.9253137, 0.9892379]\n",
      "Batch 572/700: Discriminator loss = 1.0850062370300293, GAN loss = [2.6321137, 0.96501136, 1.0496845]\n",
      "Batch 573/700: Discriminator loss = 1.0901515483856201, GAN loss = [2.629596, 0.95167136, 1.0604846]\n",
      "Batch 574/700: Discriminator loss = 1.1220438480377197, GAN loss = [2.5021052, 0.9124075, 0.9722297]\n",
      "Batch 575/700: Discriminator loss = 1.1511390209197998, GAN loss = [2.381008, 0.87936664, 0.8841419]\n",
      "Batch 576/700: Discriminator loss = 1.1644541025161743, GAN loss = [2.4910994, 0.8655588, 1.0080283]\n",
      "Batch 577/700: Discriminator loss = 1.1357334852218628, GAN loss = [2.5795023, 0.9101535, 1.051857]\n",
      "Batch 578/700: Discriminator loss = 1.1783174276351929, GAN loss = [2.4397035, 0.88233066, 0.93987954]\n",
      "Batch 579/700: Discriminator loss = 1.151200532913208, GAN loss = [2.512811, 0.90384185, 0.99148613]\n",
      "Batch 580/700: Discriminator loss = 1.1409302949905396, GAN loss = [2.470141, 0.9077631, 0.9448923]\n",
      "Batch 581/700: Discriminator loss = 1.1444933414459229, GAN loss = [2.3941796, 0.8731919, 0.90351295]\n",
      "Batch 582/700: Discriminator loss = 1.133836030960083, GAN loss = [2.5054505, 0.89898866, 0.9890057]\n",
      "Batch 583/700: Discriminator loss = 1.1388367414474487, GAN loss = [2.4580443, 0.9067963, 0.9338111]\n",
      "Batch 584/700: Discriminator loss = 1.1469296216964722, GAN loss = [2.4657774, 0.8876307, 0.96072066]\n",
      "Batch 585/700: Discriminator loss = 1.1199579238891602, GAN loss = [2.4738631, 0.92933655, 0.9271295]\n",
      "Batch 586/700: Discriminator loss = 1.1126922369003296, GAN loss = [2.408627, 0.9283622, 0.8628814]\n",
      "Batch 587/700: Discriminator loss = 1.1394715309143066, GAN loss = [2.5705252, 0.9248213, 1.0283169]\n",
      "Batch 588/700: Discriminator loss = 1.1105945110321045, GAN loss = [2.4697447, 0.91353697, 0.9388313]\n",
      "Batch 589/700: Discriminator loss = 1.1175445318222046, GAN loss = [2.4713438, 0.89583725, 0.9581208]\n",
      "Batch 590/700: Discriminator loss = 1.1203163862228394, GAN loss = [2.5147765, 0.9294925, 0.96791625]\n",
      "Batch 591/700: Discriminator loss = 1.1106607913970947, GAN loss = [2.5920904, 0.93836486, 1.0363965]\n",
      "Batch 592/700: Discriminator loss = 1.1215345859527588, GAN loss = [2.4699113, 0.9073806, 0.94521224]\n",
      "Batch 593/700: Discriminator loss = 1.130899429321289, GAN loss = [2.4846792, 0.9083851, 0.9589655]\n",
      "Batch 594/700: Discriminator loss = 1.1206167936325073, GAN loss = [2.5161324, 0.91725373, 0.98152465]\n",
      "Batch 595/700: Discriminator loss = 1.1161746978759766, GAN loss = [2.4986377, 0.9364711, 0.9447928]\n",
      "Batch 596/700: Discriminator loss = 1.1287128925323486, GAN loss = [2.5718021, 0.9263943, 1.0280472]\n",
      "Batch 597/700: Discriminator loss = 1.0695439577102661, GAN loss = [2.6503098, 1.0096135, 1.0233706]\n",
      "Batch 598/700: Discriminator loss = 1.098581075668335, GAN loss = [2.6315684, 0.9542599, 1.0600197]\n",
      "Batch 599/700: Discriminator loss = 1.1040295362472534, GAN loss = [2.5503259, 0.94771254, 0.9853585]\n",
      "Batch 600/700: Discriminator loss = 1.115804672241211, GAN loss = [2.5236375, 0.9123341, 0.9940937]\n",
      "Batch 601/700: Discriminator loss = 1.1050481796264648, GAN loss = [2.6153417, 0.96305877, 1.0350959]\n",
      "Batch 602/700: Discriminator loss = 1.1103180646896362, GAN loss = [2.7177145, 0.9667275, 1.1338091]\n",
      "Batch 603/700: Discriminator loss = 1.1132397651672363, GAN loss = [2.578148, 0.9407828, 1.0201983]\n",
      "Batch 604/700: Discriminator loss = 1.1306504011154175, GAN loss = [2.582377, 0.9277351, 1.0374905]\n",
      "Batch 605/700: Discriminator loss = 1.150061845779419, GAN loss = [2.5359502, 0.91550034, 1.0033054]\n",
      "Batch 606/700: Discriminator loss = 1.1002051830291748, GAN loss = [2.5863485, 0.9832274, 0.98593277]\n",
      "Batch 607/700: Discriminator loss = 1.1611096858978271, GAN loss = [2.513771, 0.9069418, 0.98960567]\n",
      "Batch 608/700: Discriminator loss = 1.190230369567871, GAN loss = [2.4530876, 0.89428115, 0.94154114]\n",
      "Batch 609/700: Discriminator loss = 1.1428296566009521, GAN loss = [2.5345263, 0.90843236, 1.0088061]\n",
      "Batch 610/700: Discriminator loss = 1.1503220796585083, GAN loss = [2.4787438, 0.886758, 0.97468984]\n",
      "Batch 611/700: Discriminator loss = 1.1807942390441895, GAN loss = [2.399315, 0.8856383, 0.8963688]\n",
      "Batch 612/700: Discriminator loss = 1.12921941280365, GAN loss = [2.4238193, 0.90818113, 0.89832085]\n",
      "Batch 613/700: Discriminator loss = 1.170752763748169, GAN loss = [2.4879951, 0.88687545, 0.9838154]\n",
      "Batch 614/700: Discriminator loss = 1.1299997568130493, GAN loss = [2.564781, 0.9224195, 1.0250766]\n",
      "Batch 615/700: Discriminator loss = 1.1529672145843506, GAN loss = [2.4310315, 0.8689502, 0.9447906]\n",
      "Batch 616/700: Discriminator loss = 1.1610584259033203, GAN loss = [2.5101378, 0.89606017, 0.996791]\n",
      "Batch 617/700: Discriminator loss = 1.1378791332244873, GAN loss = [2.4349313, 0.8894215, 0.9282338]\n",
      "Batch 618/700: Discriminator loss = 1.1350497007369995, GAN loss = [2.493062, 0.89093, 0.9848678]\n",
      "Batch 619/700: Discriminator loss = 1.111438274383545, GAN loss = [2.5604117, 0.92834467, 1.0148311]\n",
      "Batch 620/700: Discriminator loss = 1.1395227909088135, GAN loss = [2.4749713, 0.8927564, 0.96499413]\n",
      "Batch 621/700: Discriminator loss = 1.1309349536895752, GAN loss = [2.5855668, 0.925401, 1.0429627]\n",
      "Batch 622/700: Discriminator loss = 1.1214122772216797, GAN loss = [2.5779011, 0.9237008, 1.0370305]\n",
      "Batch 623/700: Discriminator loss = 1.1771812438964844, GAN loss = [2.3902357, 0.88537616, 0.8877316]\n",
      "Batch 624/700: Discriminator loss = 1.1389442682266235, GAN loss = [2.543236, 0.9134506, 1.0126578]\n",
      "Batch 625/700: Discriminator loss = 1.0987244844436646, GAN loss = [2.5534778, 0.95565957, 0.980699]\n",
      "Batch 626/700: Discriminator loss = 1.1218583583831787, GAN loss = [2.5242383, 0.9262633, 0.98086303]\n",
      "Batch 627/700: Discriminator loss = 1.104084849357605, GAN loss = [2.5876617, 0.93730444, 1.0332682]\n",
      "Batch 628/700: Discriminator loss = 1.1392490863800049, GAN loss = [2.495802, 0.9128285, 0.96589714]\n",
      "Batch 629/700: Discriminator loss = 1.1502313613891602, GAN loss = [2.5735838, 0.90783, 1.0486866]\n",
      "Batch 630/700: Discriminator loss = 1.1150909662246704, GAN loss = [2.5413465, 0.91448486, 1.0098214]\n",
      "Batch 631/700: Discriminator loss = 1.113381028175354, GAN loss = [2.590082, 0.94939595, 1.0236886]\n",
      "Batch 632/700: Discriminator loss = 1.1038727760314941, GAN loss = [2.667502, 0.9481128, 1.1024377]\n",
      "Batch 633/700: Discriminator loss = 1.1300296783447266, GAN loss = [2.6404297, 0.9297196, 1.0938152]\n",
      "Batch 634/700: Discriminator loss = 1.1370296478271484, GAN loss = [2.677322, 0.937512, 1.12295]\n",
      "Batch 635/700: Discriminator loss = 1.10836923122406, GAN loss = [2.5714471, 0.9615122, 0.9931001]\n",
      "Batch 636/700: Discriminator loss = 1.1058703660964966, GAN loss = [2.651873, 0.9757826, 1.059303]\n",
      "Batch 637/700: Discriminator loss = 1.110408902168274, GAN loss = [2.6145759, 0.94591403, 1.0519274]\n",
      "Batch 638/700: Discriminator loss = 1.0930423736572266, GAN loss = [2.6978738, 0.9795257, 1.1016713]\n",
      "Batch 639/700: Discriminator loss = 1.1039748191833496, GAN loss = [2.7904346, 0.9593384, 1.2144632]\n",
      "Batch 640/700: Discriminator loss = 1.078119158744812, GAN loss = [2.5801148, 0.9637595, 0.9997675]\n",
      "Batch 641/700: Discriminator loss = 1.0793253183364868, GAN loss = [2.6933382, 0.9947374, 1.0820643]\n",
      "Batch 642/700: Discriminator loss = 1.091274380683899, GAN loss = [2.6714427, 0.9963445, 1.0586065]\n",
      "Batch 643/700: Discriminator loss = 1.0821677446365356, GAN loss = [2.6754649, 0.9806679, 1.0783278]\n",
      "Batch 644/700: Discriminator loss = 1.105985164642334, GAN loss = [2.713068, 0.98294073, 1.1136699]\n",
      "Batch 645/700: Discriminator loss = 1.1045317649841309, GAN loss = [2.6062138, 0.9625364, 1.0272717]\n",
      "Batch 646/700: Discriminator loss = 1.1019580364227295, GAN loss = [2.6788347, 0.95588005, 1.1065927]\n",
      "Batch 647/700: Discriminator loss = 1.087601900100708, GAN loss = [2.856676, 0.98211265, 1.2582256]\n",
      "Batch 648/700: Discriminator loss = 1.0644043684005737, GAN loss = [2.724339, 1.0226036, 1.0854406]\n",
      "Batch 649/700: Discriminator loss = 1.1128484010696411, GAN loss = [2.5750253, 0.9420707, 1.0167025]\n",
      "Batch 650/700: Discriminator loss = 1.124191164970398, GAN loss = [2.5778248, 0.9407945, 1.0208195]\n",
      "Batch 651/700: Discriminator loss = 1.1369683742523193, GAN loss = [2.7106426, 0.9241715, 1.1702948]\n",
      "Batch 652/700: Discriminator loss = 1.1627888679504395, GAN loss = [2.619177, 0.94170463, 1.061318]\n",
      "Batch 653/700: Discriminator loss = 1.144850254058838, GAN loss = [2.630771, 0.9698546, 1.0448023]\n",
      "Batch 654/700: Discriminator loss = 1.1410340070724487, GAN loss = [2.5443933, 0.9697043, 0.9585887]\n",
      "Batch 655/700: Discriminator loss = 1.1525589227676392, GAN loss = [2.540423, 0.94678146, 0.97754747]\n",
      "Batch 656/700: Discriminator loss = 1.1648629903793335, GAN loss = [2.5124288, 0.93591475, 0.960437]\n",
      "Batch 657/700: Discriminator loss = 1.1646562814712524, GAN loss = [2.6459193, 0.9317863, 1.0980971]\n",
      "Batch 658/700: Discriminator loss = 1.1678611040115356, GAN loss = [2.455882, 0.9304488, 0.90940857]\n",
      "Batch 659/700: Discriminator loss = 1.191323161125183, GAN loss = [2.4428086, 0.9018182, 0.92493]\n",
      "Batch 660/700: Discriminator loss = 1.1711571216583252, GAN loss = [2.4460728, 0.90483564, 0.9251402]\n",
      "Batch 661/700: Discriminator loss = 1.1665475368499756, GAN loss = [2.4316847, 0.9336237, 0.881907]\n",
      "Batch 662/700: Discriminator loss = 1.2033591270446777, GAN loss = [2.4324663, 0.91503745, 0.90121007]\n",
      "Batch 663/700: Discriminator loss = 1.1780468225479126, GAN loss = [2.4896216, 0.91589904, 0.9574643]\n",
      "Batch 664/700: Discriminator loss = 1.1639747619628906, GAN loss = [2.4910448, 0.90340495, 0.97137016]\n",
      "Batch 665/700: Discriminator loss = 1.1417638063430786, GAN loss = [2.5074618, 0.91030425, 0.9808816]\n",
      "Batch 666/700: Discriminator loss = 1.147629976272583, GAN loss = [2.4528906, 0.8966314, 0.9399691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 667/700: Discriminator loss = 1.1272205114364624, GAN loss = [2.4765947, 0.923012, 0.93726903]\n",
      "Batch 668/700: Discriminator loss = 1.13102126121521, GAN loss = [2.5113976, 0.9105648, 0.9844944]\n",
      "Batch 669/700: Discriminator loss = 1.146684169769287, GAN loss = [2.4619684, 0.91326874, 0.93235534]\n",
      "Batch 670/700: Discriminator loss = 1.136723279953003, GAN loss = [2.5198324, 0.9278584, 0.9756289]\n",
      "Batch 671/700: Discriminator loss = 1.1512360572814941, GAN loss = [2.6194236, 0.9492968, 1.0537906]\n",
      "Batch 672/700: Discriminator loss = 1.1480255126953125, GAN loss = [2.4745264, 0.89465433, 0.96354294]\n",
      "Batch 673/700: Discriminator loss = 1.1298718452453613, GAN loss = [2.5167177, 0.89753044, 1.0028625]\n",
      "Batch 674/700: Discriminator loss = 1.1314336061477661, GAN loss = [2.5376923, 0.9378611, 0.9834976]\n",
      "Batch 675/700: Discriminator loss = 1.1454027891159058, GAN loss = [2.608217, 0.9350049, 1.056867]\n",
      "Batch 676/700: Discriminator loss = 1.1297049522399902, GAN loss = [2.5425482, 0.8978099, 1.0283821]\n",
      "Batch 677/700: Discriminator loss = 1.1258941888809204, GAN loss = [2.5092945, 0.9339416, 0.95899165]\n",
      "Batch 678/700: Discriminator loss = 1.1229008436203003, GAN loss = [2.5282137, 0.9260176, 0.9858384]\n",
      "Batch 679/700: Discriminator loss = 1.135591983795166, GAN loss = [2.5301187, 0.89773196, 1.015994]\n",
      "Batch 680/700: Discriminator loss = 1.1301640272140503, GAN loss = [2.5386739, 0.915472, 1.0068034]\n",
      "Batch 681/700: Discriminator loss = 1.1146942377090454, GAN loss = [2.5110962, 0.94094956, 0.9537636]\n",
      "Batch 682/700: Discriminator loss = 1.1180208921432495, GAN loss = [2.4945223, 0.9231676, 0.95499206]\n",
      "Batch 683/700: Discriminator loss = 1.1157974004745483, GAN loss = [2.6003718, 0.9401996, 1.0438405]\n",
      "Batch 684/700: Discriminator loss = 1.129824161529541, GAN loss = [2.5146751, 0.9228375, 0.9755378]\n",
      "Batch 685/700: Discriminator loss = 1.1531996726989746, GAN loss = [2.5971024, 0.9615929, 1.019225]\n",
      "Batch 686/700: Discriminator loss = 1.1272614002227783, GAN loss = [2.6831784, 0.995419, 1.071464]\n",
      "Batch 687/700: Discriminator loss = 1.102516531944275, GAN loss = [2.5864966, 0.97599715, 0.99421173]\n",
      "Batch 688/700: Discriminator loss = 1.0964568853378296, GAN loss = [2.5792644, 0.9751208, 0.98787385]\n",
      "Batch 689/700: Discriminator loss = 1.149686574935913, GAN loss = [2.5961142, 0.96359277, 1.0162747]\n",
      "Batch 690/700: Discriminator loss = 1.1245321035385132, GAN loss = [2.5405612, 0.99828887, 0.9260294]\n",
      "Batch 691/700: Discriminator loss = 1.056510090827942, GAN loss = [2.597047, 1.0078696, 0.9729588]\n",
      "Batch 692/700: Discriminator loss = 1.0720351934432983, GAN loss = [2.7136123, 1.0225136, 1.074898]\n",
      "Batch 693/700: Discriminator loss = 1.086568832397461, GAN loss = [2.6232085, 1.0016683, 1.0053515]\n",
      "Batch 694/700: Discriminator loss = 1.0934089422225952, GAN loss = [2.684963, 0.97790647, 1.0908813]\n",
      "Batch 695/700: Discriminator loss = 1.086601972579956, GAN loss = [2.720906, 1.0309223, 1.0738473]\n",
      "Batch 696/700: Discriminator loss = 1.069798231124878, GAN loss = [2.706306, 0.99590796, 1.0943028]\n",
      "Batch 697/700: Discriminator loss = 1.096645712852478, GAN loss = [2.703146, 0.98909074, 1.0979785]\n",
      "Batch 698/700: Discriminator loss = 1.0810657739639282, GAN loss = [2.6355655, 0.9920881, 1.0274495]\n",
      "Batch 699/700: Discriminator loss = 1.0741745233535767, GAN loss = [2.7181044, 1.0085567, 1.0935487]\n",
      "Batch 700/700: Discriminator loss = 1.0821212530136108, GAN loss = [2.7121756, 1.0170652, 1.0791398]\n",
      "Epoch 29/30\n",
      "Batch 1/700: Discriminator loss = 1.070468783378601, GAN loss = [2.7847369, 1.0504832, 1.1182873]\n",
      "Batch 2/700: Discriminator loss = 1.0717068910598755, GAN loss = [2.674807, 1.0060191, 1.0528018]\n",
      "Batch 3/700: Discriminator loss = 1.073816180229187, GAN loss = [2.8208568, 0.98001856, 1.2248619]\n",
      "Batch 4/700: Discriminator loss = 1.0925213098526, GAN loss = [2.73313, 0.98804855, 1.1291181]\n",
      "Batch 5/700: Discriminator loss = 1.12249755859375, GAN loss = [2.734701, 0.9816717, 1.1370552]\n",
      "Batch 6/700: Discriminator loss = 1.0999783277511597, GAN loss = [2.7096252, 0.9914929, 1.1021371]\n",
      "Batch 7/700: Discriminator loss = 1.0975147485733032, GAN loss = [2.761552, 1.0275542, 1.1179882]\n",
      "Batch 8/700: Discriminator loss = 1.0976312160491943, GAN loss = [2.6983495, 1.009912, 1.07239]\n",
      "Batch 9/700: Discriminator loss = 1.1119601726531982, GAN loss = [2.6557794, 0.97939026, 1.0602839]\n",
      "Batch 10/700: Discriminator loss = 1.113945722579956, GAN loss = [2.6556175, 0.93681794, 1.1026119]\n",
      "Batch 11/700: Discriminator loss = 1.142242431640625, GAN loss = [2.650577, 0.97334963, 1.06098]\n",
      "Batch 12/700: Discriminator loss = 1.1305480003356934, GAN loss = [2.593083, 0.988408, 0.9883473]\n",
      "Batch 13/700: Discriminator loss = 1.0880926847457886, GAN loss = [2.6618466, 0.989605, 1.0558373]\n",
      "Batch 14/700: Discriminator loss = 1.095847725868225, GAN loss = [2.5323534, 0.9629479, 0.9529477]\n",
      "Batch 15/700: Discriminator loss = 1.103651523590088, GAN loss = [2.6286507, 0.98360366, 1.0285408]\n",
      "Batch 16/700: Discriminator loss = 1.1388758420944214, GAN loss = [2.5275168, 0.954489, 0.95650756]\n",
      "Batch 17/700: Discriminator loss = 1.1164896488189697, GAN loss = [2.5875742, 0.94964266, 1.0214074]\n",
      "Batch 18/700: Discriminator loss = 1.1384129524230957, GAN loss = [2.5856407, 0.98997587, 0.9791452]\n",
      "Batch 19/700: Discriminator loss = 1.20346200466156, GAN loss = [2.569231, 0.97267157, 0.9800052]\n",
      "Batch 20/700: Discriminator loss = 1.2307493686676025, GAN loss = [2.5454996, 0.9309727, 0.99792516]\n",
      "Batch 21/700: Discriminator loss = 1.1706111431121826, GAN loss = [2.5898013, 0.970813, 1.0023179]\n",
      "Batch 22/700: Discriminator loss = 1.1528232097625732, GAN loss = [2.5000951, 0.96654916, 0.916836]\n",
      "Batch 23/700: Discriminator loss = 1.164455533027649, GAN loss = [2.5476685, 0.9525966, 0.97833633]\n",
      "Batch 24/700: Discriminator loss = 1.1507402658462524, GAN loss = [2.5712144, 0.9942076, 0.96022826]\n",
      "Batch 25/700: Discriminator loss = 1.138410210609436, GAN loss = [2.5965476, 0.9796353, 1.0001235]\n",
      "Batch 26/700: Discriminator loss = 1.1454142332077026, GAN loss = [2.649307, 1.011722, 1.0208056]\n",
      "Batch 27/700: Discriminator loss = 1.1501660346984863, GAN loss = [2.5278935, 1.012163, 0.8989592]\n",
      "Batch 28/700: Discriminator loss = 1.138429045677185, GAN loss = [2.5287378, 0.9850384, 0.9269189]\n",
      "Batch 29/700: Discriminator loss = 1.1533451080322266, GAN loss = [2.5695643, 0.9716314, 0.98111427]\n",
      "Batch 30/700: Discriminator loss = 1.1237279176712036, GAN loss = [2.5072846, 0.96902335, 0.921427]\n",
      "Batch 31/700: Discriminator loss = 1.163286805152893, GAN loss = [2.495793, 0.9175728, 0.96136075]\n",
      "Batch 32/700: Discriminator loss = 1.1533260345458984, GAN loss = [2.5178816, 0.9717078, 0.9292972]\n",
      "Batch 33/700: Discriminator loss = 1.171128273010254, GAN loss = [2.4656973, 0.9145853, 0.9341785]\n",
      "Batch 34/700: Discriminator loss = 1.1768935918807983, GAN loss = [2.460242, 0.90861803, 0.9346209]\n",
      "Batch 35/700: Discriminator loss = 1.1545391082763672, GAN loss = [2.476347, 0.92495054, 0.93434983]\n",
      "Batch 36/700: Discriminator loss = 1.1303231716156006, GAN loss = [2.502721, 0.9389343, 0.94671285]\n",
      "Batch 37/700: Discriminator loss = 1.1384762525558472, GAN loss = [2.4551287, 0.94007474, 0.8979889]\n",
      "Batch 38/700: Discriminator loss = 1.1823831796646118, GAN loss = [2.3920841, 0.9011467, 0.8738882]\n",
      "Batch 39/700: Discriminator loss = 1.1479464769363403, GAN loss = [2.4983172, 0.96642774, 0.91485083]\n",
      "Batch 40/700: Discriminator loss = 1.1667897701263428, GAN loss = [2.4569387, 0.9038955, 0.93600774]\n",
      "Batch 41/700: Discriminator loss = 1.1671403646469116, GAN loss = [2.561284, 0.95156074, 0.99268645]\n",
      "Batch 42/700: Discriminator loss = 1.1665762662887573, GAN loss = [2.3944008, 0.89844096, 0.87892365]\n",
      "Batch 43/700: Discriminator loss = 1.1836395263671875, GAN loss = [2.4655259, 0.8971592, 0.9513413]\n",
      "Batch 44/700: Discriminator loss = 1.1804643869400024, GAN loss = [2.4449153, 0.8960663, 0.9318567]\n",
      "Batch 45/700: Discriminator loss = 1.1707823276519775, GAN loss = [2.4811263, 0.8960637, 0.9680849]\n",
      "Batch 46/700: Discriminator loss = 1.15750253200531, GAN loss = [2.4899755, 0.90360403, 0.9694148]\n",
      "Batch 47/700: Discriminator loss = 1.1842445135116577, GAN loss = [2.391224, 0.8984722, 0.87582284]\n",
      "Batch 48/700: Discriminator loss = 1.1823980808258057, GAN loss = [2.422942, 0.920956, 0.8850781]\n",
      "Batch 49/700: Discriminator loss = 1.1747534275054932, GAN loss = [2.3746965, 0.8951407, 0.86265826]\n",
      "Batch 50/700: Discriminator loss = 1.1848143339157104, GAN loss = [2.3994517, 0.89093554, 0.8916217]\n",
      "Batch 51/700: Discriminator loss = 1.1469457149505615, GAN loss = [2.4824128, 0.93208086, 0.9334426]\n",
      "Batch 52/700: Discriminator loss = 1.1676762104034424, GAN loss = [2.4112747, 0.9103439, 0.88404036]\n",
      "Batch 53/700: Discriminator loss = 1.1536957025527954, GAN loss = [2.3992043, 0.90099496, 0.88130105]\n",
      "Batch 54/700: Discriminator loss = 1.1566245555877686, GAN loss = [2.421984, 0.90284556, 0.90222955]\n",
      "Batch 55/700: Discriminator loss = 1.123382329940796, GAN loss = [2.4221854, 0.93859446, 0.8667163]\n",
      "Batch 56/700: Discriminator loss = 1.1261606216430664, GAN loss = [2.486488, 0.9382772, 0.9313297]\n",
      "Batch 57/700: Discriminator loss = 1.1571470499038696, GAN loss = [2.4899578, 0.9299234, 0.94313264]\n",
      "Batch 58/700: Discriminator loss = 1.140836477279663, GAN loss = [2.5254598, 0.94879514, 0.95975167]\n",
      "Batch 59/700: Discriminator loss = 1.1435409784317017, GAN loss = [2.500378, 0.9472108, 0.93626]\n",
      "Batch 60/700: Discriminator loss = 1.1391005516052246, GAN loss = [2.4846165, 0.91852933, 0.94920105]\n",
      "Batch 61/700: Discriminator loss = 1.1297935247421265, GAN loss = [2.499365, 0.92893404, 0.9535498]\n",
      "Batch 62/700: Discriminator loss = 1.15396249294281, GAN loss = [2.487537, 0.94229335, 0.92835706]\n",
      "Batch 63/700: Discriminator loss = 1.1344894170761108, GAN loss = [2.4906855, 0.93046373, 0.94330955]\n",
      "Batch 64/700: Discriminator loss = 1.133304476737976, GAN loss = [2.5481691, 0.9723241, 0.9588789]\n",
      "Batch 65/700: Discriminator loss = 1.1442949771881104, GAN loss = [2.5511184, 0.9227894, 1.0112796]\n",
      "Batch 66/700: Discriminator loss = 1.139507532119751, GAN loss = [2.5496874, 0.93529135, 0.9972899]\n",
      "Batch 67/700: Discriminator loss = 1.145372986793518, GAN loss = [2.5708077, 0.93551993, 1.0181172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 68/700: Discriminator loss = 1.1305391788482666, GAN loss = [2.474842, 0.9243242, 0.93328506]\n",
      "Batch 69/700: Discriminator loss = 1.1787973642349243, GAN loss = [2.4734206, 0.89304906, 0.96311754]\n",
      "Batch 70/700: Discriminator loss = 1.1366798877716064, GAN loss = [2.4762518, 0.91142255, 0.9475402]\n",
      "Batch 71/700: Discriminator loss = 1.1275604963302612, GAN loss = [2.5366905, 0.90183467, 1.0175412]\n",
      "Batch 72/700: Discriminator loss = 1.1162630319595337, GAN loss = [2.5683105, 0.9757622, 0.9751827]\n",
      "Batch 73/700: Discriminator loss = 1.141701579093933, GAN loss = [2.515514, 0.919982, 0.97809225]\n",
      "Batch 74/700: Discriminator loss = 1.1178863048553467, GAN loss = [2.5677156, 0.9233593, 1.0268494]\n",
      "Batch 75/700: Discriminator loss = 1.1397637128829956, GAN loss = [2.5607374, 0.9067569, 1.0364144]\n",
      "Batch 76/700: Discriminator loss = 1.1381068229675293, GAN loss = [2.6281443, 0.9585594, 1.0520012]\n",
      "Batch 77/700: Discriminator loss = 1.1058592796325684, GAN loss = [2.600102, 0.96806693, 1.0144466]\n",
      "Batch 78/700: Discriminator loss = 1.1093906164169312, GAN loss = [2.5742052, 0.95364726, 1.0029386]\n",
      "Batch 79/700: Discriminator loss = 1.1103036403656006, GAN loss = [2.6240118, 0.977533, 1.0288273]\n",
      "Batch 80/700: Discriminator loss = 1.1050432920455933, GAN loss = [2.697808, 0.99180984, 1.0883163]\n",
      "Batch 81/700: Discriminator loss = 1.096108078956604, GAN loss = [2.6224496, 0.9807919, 1.0239507]\n",
      "Batch 82/700: Discriminator loss = 1.106661081314087, GAN loss = [2.690671, 0.98170984, 1.0912533]\n",
      "Batch 83/700: Discriminator loss = 1.0661014318466187, GAN loss = [2.7092886, 1.0086845, 1.0828869]\n",
      "Batch 84/700: Discriminator loss = 1.0669224262237549, GAN loss = [2.7338982, 1.0191644, 1.0970362]\n",
      "Batch 85/700: Discriminator loss = 1.103245496749878, GAN loss = [2.6395857, 0.97871476, 1.043206]\n",
      "Batch 86/700: Discriminator loss = 1.1461204290390015, GAN loss = [2.5618546, 0.9523, 0.9918903]\n",
      "Batch 87/700: Discriminator loss = 1.1180566549301147, GAN loss = [2.660763, 0.9916249, 1.051485]\n",
      "Batch 88/700: Discriminator loss = 1.0858790874481201, GAN loss = [2.707982, 1.0106465, 1.0796835]\n",
      "Batch 89/700: Discriminator loss = 1.1445378065109253, GAN loss = [2.6730132, 0.99301267, 1.0623795]\n",
      "Batch 90/700: Discriminator loss = 1.0906336307525635, GAN loss = [2.756553, 1.0172548, 1.1217098]\n",
      "Batch 91/700: Discriminator loss = 1.1039376258850098, GAN loss = [2.7840972, 1.0087717, 1.1577487]\n",
      "Batch 92/700: Discriminator loss = 1.103833794593811, GAN loss = [2.7554493, 1.0086713, 1.1292086]\n",
      "Batch 93/700: Discriminator loss = 1.0426362752914429, GAN loss = [2.8458889, 1.0642779, 1.1640264]\n",
      "Batch 94/700: Discriminator loss = 1.0636361837387085, GAN loss = [2.8299525, 1.082736, 1.1296327]\n",
      "Batch 95/700: Discriminator loss = 1.086510181427002, GAN loss = [2.7261107, 1.004439, 1.104079]\n",
      "Batch 96/700: Discriminator loss = 1.075074553489685, GAN loss = [2.7034235, 1.0028859, 1.0829467]\n",
      "Batch 97/700: Discriminator loss = 1.062524676322937, GAN loss = [2.718169, 1.045511, 1.0550728]\n",
      "Batch 98/700: Discriminator loss = 1.0918247699737549, GAN loss = [2.7480762, 1.001613, 1.12887]\n",
      "Batch 99/700: Discriminator loss = 1.0691194534301758, GAN loss = [2.7344317, 1.0250974, 1.0917451]\n",
      "Batch 100/700: Discriminator loss = 1.0528733730316162, GAN loss = [2.7985404, 1.0490086, 1.1319575]\n",
      "Batch 101/700: Discriminator loss = 1.0637993812561035, GAN loss = [2.7068973, 1.0276204, 1.0617386]\n",
      "Batch 102/700: Discriminator loss = 1.0854504108428955, GAN loss = [2.6368678, 0.9730499, 1.0463281]\n",
      "Batch 103/700: Discriminator loss = 1.0521188974380493, GAN loss = [2.7133234, 1.0218918, 1.0739625]\n",
      "Batch 104/700: Discriminator loss = 1.0914053916931152, GAN loss = [2.634443, 0.95700526, 1.0599998]\n",
      "Batch 105/700: Discriminator loss = 1.095788836479187, GAN loss = [2.745996, 0.9597957, 1.1687815]\n",
      "Batch 106/700: Discriminator loss = 1.0848668813705444, GAN loss = [2.6461754, 0.96176994, 1.0669928]\n",
      "Batch 107/700: Discriminator loss = 1.0887212753295898, GAN loss = [2.9545226, 1.001888, 1.3352532]\n",
      "Batch 108/700: Discriminator loss = 1.1193678379058838, GAN loss = [2.589892, 0.94496024, 1.0275388]\n",
      "Batch 109/700: Discriminator loss = 1.0883727073669434, GAN loss = [2.6539006, 0.9881108, 1.0483944]\n",
      "Batch 110/700: Discriminator loss = 1.111606240272522, GAN loss = [2.6104994, 0.9643937, 1.0286801]\n",
      "Batch 111/700: Discriminator loss = 1.1119883060455322, GAN loss = [2.6296048, 0.96153647, 1.0506248]\n",
      "Batch 112/700: Discriminator loss = 1.1108520030975342, GAN loss = [2.6464107, 0.96702766, 1.0619314]\n",
      "Batch 113/700: Discriminator loss = 1.1224390268325806, GAN loss = [2.5946505, 0.95103514, 1.0261312]\n",
      "Batch 114/700: Discriminator loss = 1.124337911605835, GAN loss = [2.594987, 0.95775366, 1.01969]\n",
      "Batch 115/700: Discriminator loss = 1.1001055240631104, GAN loss = [2.7621794, 1.0028268, 1.1417681]\n",
      "Batch 116/700: Discriminator loss = 1.0819673538208008, GAN loss = [2.6961803, 1.0119799, 1.0666026]\n",
      "Batch 117/700: Discriminator loss = 1.0734429359436035, GAN loss = [2.6852858, 1.0009142, 1.0667609]\n",
      "Batch 118/700: Discriminator loss = 1.0914725065231323, GAN loss = [2.7255745, 0.9863391, 1.1216038]\n",
      "Batch 119/700: Discriminator loss = 1.0926116704940796, GAN loss = [2.672709, 0.9778687, 1.0771536]\n",
      "Batch 120/700: Discriminator loss = 1.0860099792480469, GAN loss = [2.773902, 1.0084915, 1.1476643]\n",
      "Batch 121/700: Discriminator loss = 1.10857093334198, GAN loss = [2.7539039, 0.99187446, 1.144193]\n",
      "Batch 122/700: Discriminator loss = 1.0931776762008667, GAN loss = [2.7289407, 1.0986817, 1.0123284]\n",
      "Batch 123/700: Discriminator loss = 1.0845924615859985, GAN loss = [2.7103086, 1.026642, 1.0656508]\n",
      "Batch 124/700: Discriminator loss = 1.1204674243927002, GAN loss = [2.643498, 0.9425638, 1.0828384]\n",
      "Batch 125/700: Discriminator loss = 1.128184199333191, GAN loss = [2.7122905, 0.978301, 1.115839]\n",
      "Batch 126/700: Discriminator loss = 1.1080193519592285, GAN loss = [2.7033062, 0.99835515, 1.0867668]\n",
      "Batch 127/700: Discriminator loss = 1.1132594347000122, GAN loss = [2.768077, 1.0125782, 1.1372651]\n",
      "Batch 128/700: Discriminator loss = 1.114162564277649, GAN loss = [2.7116008, 0.9964799, 1.0967797]\n",
      "Batch 129/700: Discriminator loss = 1.1483333110809326, GAN loss = [2.5873046, 0.9736511, 0.9952564]\n",
      "Batch 130/700: Discriminator loss = 1.1522282361984253, GAN loss = [2.5560632, 0.9751585, 0.9624298]\n",
      "Batch 131/700: Discriminator loss = 1.1848386526107788, GAN loss = [2.6239233, 0.9265434, 1.0787936]\n",
      "Batch 132/700: Discriminator loss = 1.1605561971664429, GAN loss = [2.61141, 0.940587, 1.0521362]\n",
      "Batch 133/700: Discriminator loss = 1.1586087942123413, GAN loss = [2.6250715, 0.9601519, 1.0461669]\n",
      "Batch 134/700: Discriminator loss = 1.150433897972107, GAN loss = [2.7130523, 0.9770585, 1.1171534]\n",
      "Batch 135/700: Discriminator loss = 1.1610453128814697, GAN loss = [2.7040653, 0.97223246, 1.1129068]\n",
      "Batch 136/700: Discriminator loss = 1.170830249786377, GAN loss = [2.5648983, 0.9256957, 1.0201441]\n",
      "Batch 137/700: Discriminator loss = 1.1306482553482056, GAN loss = [2.6241198, 0.9811603, 1.0238137]\n",
      "Batch 138/700: Discriminator loss = 1.1407947540283203, GAN loss = [2.576355, 0.94724864, 1.0099769]\n",
      "Batch 139/700: Discriminator loss = 1.1139795780181885, GAN loss = [2.6376233, 0.99076164, 1.0277339]\n",
      "Batch 140/700: Discriminator loss = 1.14154052734375, GAN loss = [2.5496914, 0.949329, 0.9812149]\n",
      "Batch 141/700: Discriminator loss = 1.1121318340301514, GAN loss = [2.4923005, 0.97249, 0.9006089]\n",
      "Batch 142/700: Discriminator loss = 1.126590371131897, GAN loss = [2.6052976, 0.9514947, 1.0345618]\n",
      "Batch 143/700: Discriminator loss = 1.0915651321411133, GAN loss = [2.6635752, 0.9781499, 1.066154]\n",
      "Batch 144/700: Discriminator loss = 1.0700666904449463, GAN loss = [2.7082963, 1.0166581, 1.0723543]\n",
      "Batch 145/700: Discriminator loss = 1.0968213081359863, GAN loss = [2.6860406, 0.97914016, 1.0876122]\n",
      "Batch 146/700: Discriminator loss = 1.0830018520355225, GAN loss = [2.688457, 0.9773112, 1.0918792]\n",
      "Batch 147/700: Discriminator loss = 1.0960960388183594, GAN loss = [2.5843956, 0.9675619, 0.9975829]\n",
      "Batch 148/700: Discriminator loss = 1.1221654415130615, GAN loss = [2.5919952, 0.95480746, 1.017925]\n",
      "Batch 149/700: Discriminator loss = 1.0898231267929077, GAN loss = [2.636167, 0.97587496, 1.0410464]\n",
      "Batch 150/700: Discriminator loss = 1.1049165725708008, GAN loss = [2.7228258, 0.95653415, 1.1470568]\n",
      "Batch 151/700: Discriminator loss = 1.1201772689819336, GAN loss = [2.6146376, 0.93430936, 1.0610999]\n",
      "Batch 152/700: Discriminator loss = 1.114307165145874, GAN loss = [2.6232414, 0.93264574, 1.0713704]\n",
      "Batch 153/700: Discriminator loss = 1.1147292852401733, GAN loss = [2.7328205, 0.9654587, 1.1481376]\n",
      "Batch 154/700: Discriminator loss = 1.0995559692382812, GAN loss = [2.6765425, 0.9746821, 1.0826147]\n",
      "Batch 155/700: Discriminator loss = 1.1054304838180542, GAN loss = [2.6354234, 0.95693153, 1.0591989]\n",
      "Batch 156/700: Discriminator loss = 1.1053260564804077, GAN loss = [2.6933866, 0.9729847, 1.1011288]\n",
      "Batch 157/700: Discriminator loss = 1.113240122795105, GAN loss = [2.6655219, 0.9647258, 1.0815628]\n",
      "Batch 158/700: Discriminator loss = 1.1243141889572144, GAN loss = [2.5814068, 0.9444587, 1.0176979]\n",
      "Batch 159/700: Discriminator loss = 1.1215978860855103, GAN loss = [2.582621, 0.9486545, 1.0146921]\n",
      "Batch 160/700: Discriminator loss = 1.1383074522018433, GAN loss = [2.6596806, 0.962504, 1.0778934]\n",
      "Batch 161/700: Discriminator loss = 1.1524956226348877, GAN loss = [2.6229012, 0.9333148, 1.0703353]\n",
      "Batch 162/700: Discriminator loss = 1.1306160688400269, GAN loss = [2.6249259, 0.9514128, 1.054308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 163/700: Discriminator loss = 1.1208081245422363, GAN loss = [2.5983658, 0.9723385, 1.0068374]\n",
      "Batch 164/700: Discriminator loss = 1.1079471111297607, GAN loss = [2.6747878, 0.9861208, 1.0695165]\n",
      "Batch 165/700: Discriminator loss = 1.1272873878479004, GAN loss = [2.7199914, 0.990826, 1.110069]\n",
      "Batch 166/700: Discriminator loss = 1.1088370084762573, GAN loss = [2.53783, 0.9822048, 0.9365789]\n",
      "Batch 167/700: Discriminator loss = 1.1201491355895996, GAN loss = [2.6741831, 0.9651923, 1.0899976]\n",
      "Batch 168/700: Discriminator loss = 1.0837939977645874, GAN loss = [2.8065317, 0.99610484, 1.1914783]\n",
      "Batch 169/700: Discriminator loss = 1.0938180685043335, GAN loss = [2.7412946, 0.97966105, 1.142738]\n",
      "Batch 170/700: Discriminator loss = 1.1136093139648438, GAN loss = [2.6673753, 0.9607144, 1.0878127]\n",
      "Batch 171/700: Discriminator loss = 1.0881822109222412, GAN loss = [2.7092185, 1.0105428, 1.0798736]\n",
      "Batch 172/700: Discriminator loss = 1.0964137315750122, GAN loss = [2.6904252, 1.0548255, 1.0168277]\n",
      "Batch 173/700: Discriminator loss = 1.1093851327896118, GAN loss = [2.6556215, 0.9927595, 1.0441056]\n",
      "Batch 174/700: Discriminator loss = 1.1214921474456787, GAN loss = [2.6920059, 0.97163206, 1.1016433]\n",
      "Batch 175/700: Discriminator loss = 1.112648606300354, GAN loss = [2.5907793, 0.9582097, 1.0138643]\n",
      "Batch 176/700: Discriminator loss = 1.1105560064315796, GAN loss = [2.7070851, 0.96184355, 1.1265721]\n",
      "Batch 177/700: Discriminator loss = 1.0951451063156128, GAN loss = [2.6364074, 0.98582846, 1.0319134]\n",
      "Batch 178/700: Discriminator loss = 1.0957057476043701, GAN loss = [2.6496377, 0.9729069, 1.0580667]\n",
      "Batch 179/700: Discriminator loss = 1.1297663450241089, GAN loss = [2.5872586, 0.95963484, 1.0089793]\n",
      "Batch 180/700: Discriminator loss = 1.1316030025482178, GAN loss = [2.5919466, 0.96100324, 1.012292]\n",
      "Batch 181/700: Discriminator loss = 1.0963317155838013, GAN loss = [2.7021382, 0.9837294, 1.0997559]\n",
      "Batch 182/700: Discriminator loss = 1.1256153583526611, GAN loss = [2.673999, 0.9689338, 1.0864267]\n",
      "Batch 183/700: Discriminator loss = 1.1026077270507812, GAN loss = [2.7687316, 0.9959504, 1.1541661]\n",
      "Batch 184/700: Discriminator loss = 1.1384823322296143, GAN loss = [2.7065566, 0.9887654, 1.0991722]\n",
      "Batch 185/700: Discriminator loss = 1.1069910526275635, GAN loss = [2.6402345, 1.0002625, 1.021366]\n",
      "Batch 186/700: Discriminator loss = 1.1016499996185303, GAN loss = [2.7285268, 1.0000769, 1.1098653]\n",
      "Batch 187/700: Discriminator loss = 1.1070678234100342, GAN loss = [2.7005897, 0.95996124, 1.1220465]\n",
      "Batch 188/700: Discriminator loss = 1.0946813821792603, GAN loss = [2.760147, 0.99440527, 1.1471747]\n",
      "Batch 189/700: Discriminator loss = 1.1330372095108032, GAN loss = [2.6344547, 0.9615961, 1.0542972]\n",
      "Batch 190/700: Discriminator loss = 1.106028437614441, GAN loss = [2.6958702, 0.9839409, 1.0933771]\n",
      "Batch 191/700: Discriminator loss = 1.1150213479995728, GAN loss = [2.6747632, 0.9776642, 1.0785584]\n",
      "Batch 192/700: Discriminator loss = 1.0723190307617188, GAN loss = [2.6919894, 0.9957435, 1.0777158]\n",
      "Batch 193/700: Discriminator loss = 1.0903414487838745, GAN loss = [2.6557224, 0.98521155, 1.0519916]\n",
      "Batch 194/700: Discriminator loss = 1.1072911024093628, GAN loss = [2.6329925, 0.9580562, 1.0564312]\n",
      "Batch 195/700: Discriminator loss = 1.0888502597808838, GAN loss = [2.7133868, 0.9861946, 1.1087043]\n",
      "Batch 196/700: Discriminator loss = 1.1069990396499634, GAN loss = [2.723777, 0.9616342, 1.1436744]\n",
      "Batch 197/700: Discriminator loss = 1.1186141967773438, GAN loss = [2.6862526, 0.9632944, 1.1045079]\n",
      "Batch 198/700: Discriminator loss = 1.0822958946228027, GAN loss = [2.794373, 0.99265176, 1.1833057]\n",
      "Batch 199/700: Discriminator loss = 1.1202905178070068, GAN loss = [2.6477427, 0.9440746, 1.0852944]\n",
      "Batch 200/700: Discriminator loss = 1.1380093097686768, GAN loss = [2.7057776, 0.94366217, 1.143776]\n",
      "Batch 201/700: Discriminator loss = 1.1281015872955322, GAN loss = [2.631441, 0.94467324, 1.0684458]\n",
      "Batch 202/700: Discriminator loss = 1.094178318977356, GAN loss = [2.785393, 0.98817235, 1.1789223]\n",
      "Batch 203/700: Discriminator loss = 1.1075676679611206, GAN loss = [2.7143445, 0.97723067, 1.1188453]\n",
      "Batch 204/700: Discriminator loss = 1.1228103637695312, GAN loss = [2.6191144, 0.9520281, 1.0488697]\n",
      "Batch 205/700: Discriminator loss = 1.1163009405136108, GAN loss = [2.597667, 0.946492, 1.0330161]\n",
      "Batch 206/700: Discriminator loss = 1.1306005716323853, GAN loss = [2.7178109, 0.9692495, 1.1304473]\n",
      "Batch 207/700: Discriminator loss = 1.125491976737976, GAN loss = [2.625435, 0.943098, 1.0642782]\n",
      "Batch 208/700: Discriminator loss = 1.0912363529205322, GAN loss = [2.7227573, 0.959507, 1.1452388]\n",
      "Batch 209/700: Discriminator loss = 1.1233164072036743, GAN loss = [2.5985017, 0.9523763, 1.028163]\n",
      "Batch 210/700: Discriminator loss = 1.1311118602752686, GAN loss = [2.551604, 0.9321967, 1.00149]\n",
      "Batch 211/700: Discriminator loss = 1.1400444507598877, GAN loss = [2.6125202, 0.91303366, 1.081608]\n",
      "Batch 212/700: Discriminator loss = 1.1483664512634277, GAN loss = [2.583282, 0.94619423, 1.0192493]\n",
      "Batch 213/700: Discriminator loss = 1.1053863763809204, GAN loss = [2.7189646, 0.9609275, 1.1402352]\n",
      "Batch 214/700: Discriminator loss = 1.120691180229187, GAN loss = [2.5424645, 0.93970186, 0.98499864]\n",
      "Batch 215/700: Discriminator loss = 1.1274819374084473, GAN loss = [2.50668, 0.9337463, 0.95519936]\n",
      "Batch 216/700: Discriminator loss = 1.1056517362594604, GAN loss = [2.6381147, 0.9380076, 1.082401]\n",
      "Batch 217/700: Discriminator loss = 1.1326876878738403, GAN loss = [2.5967114, 0.9384568, 1.0405419]\n",
      "Batch 218/700: Discriminator loss = 1.1174957752227783, GAN loss = [2.596728, 0.96388227, 1.0151305]\n",
      "Batch 219/700: Discriminator loss = 1.1167696714401245, GAN loss = [2.5481708, 0.93201476, 0.99845046]\n",
      "Batch 220/700: Discriminator loss = 1.122106671333313, GAN loss = [2.6320565, 0.94249, 1.0718793]\n",
      "Batch 221/700: Discriminator loss = 1.133727788925171, GAN loss = [2.5952277, 0.93588454, 1.0416648]\n",
      "Batch 222/700: Discriminator loss = 1.1502655744552612, GAN loss = [2.6543624, 0.9358151, 1.1008667]\n",
      "Batch 223/700: Discriminator loss = 1.138404369354248, GAN loss = [2.4869726, 0.93666655, 0.93261456]\n",
      "Batch 224/700: Discriminator loss = 1.1705316305160522, GAN loss = [2.5161963, 0.9366068, 0.96191657]\n",
      "Batch 225/700: Discriminator loss = 1.1612067222595215, GAN loss = [2.5451012, 0.90820783, 1.0192038]\n",
      "Batch 226/700: Discriminator loss = 1.1581079959869385, GAN loss = [2.5564733, 0.9288801, 1.0098857]\n",
      "Batch 227/700: Discriminator loss = 1.1324506998062134, GAN loss = [2.6111193, 0.9453449, 1.0480454]\n",
      "Batch 228/700: Discriminator loss = 1.1475350856781006, GAN loss = [2.5394735, 0.9536629, 0.96806043]\n",
      "Batch 229/700: Discriminator loss = 1.1141585111618042, GAN loss = [2.5934973, 0.96359473, 1.0121262]\n",
      "Batch 230/700: Discriminator loss = 1.1561440229415894, GAN loss = [2.5163958, 0.9312346, 0.9673401]\n",
      "Batch 231/700: Discriminator loss = 1.1432369947433472, GAN loss = [2.4553719, 0.94886446, 0.888618]\n",
      "Batch 232/700: Discriminator loss = 1.1399564743041992, GAN loss = [2.501491, 0.95531565, 0.92823]\n",
      "Batch 233/700: Discriminator loss = 1.1532530784606934, GAN loss = [2.5290437, 0.9007394, 1.0103261]\n",
      "Batch 234/700: Discriminator loss = 1.1676967144012451, GAN loss = [2.435507, 0.8974301, 0.9200728]\n",
      "Batch 235/700: Discriminator loss = 1.1685619354248047, GAN loss = [2.4648347, 0.94753045, 0.89929384]\n",
      "Batch 236/700: Discriminator loss = 1.1692744493484497, GAN loss = [2.4622407, 0.8797129, 0.9645201]\n",
      "Batch 237/700: Discriminator loss = 1.168156623840332, GAN loss = [2.3978674, 0.8708111, 0.90904486]\n",
      "Batch 238/700: Discriminator loss = 1.1676530838012695, GAN loss = [2.4772553, 0.90066874, 0.95858306]\n",
      "Batch 239/700: Discriminator loss = 1.1829553842544556, GAN loss = [2.4339056, 0.88495386, 0.93092614]\n",
      "Batch 240/700: Discriminator loss = 1.165009617805481, GAN loss = [2.4076009, 0.862287, 0.92727554]\n",
      "Batch 241/700: Discriminator loss = 1.159253716468811, GAN loss = [2.4664826, 0.85777175, 0.99067575]\n",
      "Batch 242/700: Discriminator loss = 1.187789797782898, GAN loss = [2.4490392, 0.8650065, 0.96601886]\n",
      "Batch 243/700: Discriminator loss = 1.1694093942642212, GAN loss = [2.4931257, 0.89001757, 0.9851136]\n",
      "Batch 244/700: Discriminator loss = 1.1473569869995117, GAN loss = [2.4565842, 0.88675916, 0.9518379]\n",
      "Batch 245/700: Discriminator loss = 1.154043197631836, GAN loss = [2.486955, 0.870639, 0.9983117]\n",
      "Batch 246/700: Discriminator loss = 1.1712701320648193, GAN loss = [2.4465759, 0.8815586, 0.94701004]\n",
      "Batch 247/700: Discriminator loss = 1.1575912237167358, GAN loss = [2.4481668, 0.87730074, 0.9528688]\n",
      "Batch 248/700: Discriminator loss = 1.1648207902908325, GAN loss = [2.4654067, 0.8711841, 0.9762111]\n",
      "Batch 249/700: Discriminator loss = 1.1722538471221924, GAN loss = [2.5023792, 0.86756784, 1.0167863]\n",
      "Batch 250/700: Discriminator loss = 1.153389573097229, GAN loss = [2.5037649, 0.8742478, 1.0114914]\n",
      "Batch 251/700: Discriminator loss = 1.1766340732574463, GAN loss = [2.4384894, 0.89386994, 0.926609]\n",
      "Batch 252/700: Discriminator loss = 1.1362042427062988, GAN loss = [2.4614754, 0.9094375, 0.93406785]\n",
      "Batch 253/700: Discriminator loss = 1.1157779693603516, GAN loss = [2.4993856, 0.8977917, 0.98365754]\n",
      "Batch 254/700: Discriminator loss = 1.1216728687286377, GAN loss = [2.5445955, 0.88963264, 1.037054]\n",
      "Batch 255/700: Discriminator loss = 1.1427112817764282, GAN loss = [2.4688637, 0.9104793, 0.94052255]\n",
      "Batch 256/700: Discriminator loss = 1.1253989934921265, GAN loss = [2.4808013, 0.89320314, 0.9697598]\n",
      "Batch 257/700: Discriminator loss = 1.1350440979003906, GAN loss = [2.4965343, 0.90067893, 0.9780505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 258/700: Discriminator loss = 1.1210256814956665, GAN loss = [2.4694383, 0.9050557, 0.9466131]\n",
      "Batch 259/700: Discriminator loss = 1.105454683303833, GAN loss = [2.6211715, 0.9397599, 1.0636733]\n",
      "Batch 260/700: Discriminator loss = 1.135099172592163, GAN loss = [2.4786747, 0.92701745, 0.93396455]\n",
      "Batch 261/700: Discriminator loss = 1.1024340391159058, GAN loss = [2.551248, 0.94711465, 0.9864955]\n",
      "Batch 262/700: Discriminator loss = 1.1019012928009033, GAN loss = [2.6565905, 0.94172096, 1.0972829]\n",
      "Batch 263/700: Discriminator loss = 1.1220675706863403, GAN loss = [2.5261958, 0.89444375, 1.0141993]\n",
      "Batch 264/700: Discriminator loss = 1.1107062101364136, GAN loss = [2.605763, 0.92933875, 1.0588989]\n",
      "Batch 265/700: Discriminator loss = 1.1261345148086548, GAN loss = [2.5497067, 0.8998247, 1.0323607]\n",
      "Batch 266/700: Discriminator loss = 1.126673698425293, GAN loss = [2.5659945, 0.89054054, 1.0579712]\n",
      "Batch 267/700: Discriminator loss = 1.1510595083236694, GAN loss = [2.5586383, 0.9220777, 1.0190963]\n",
      "Batch 268/700: Discriminator loss = 1.148036003112793, GAN loss = [2.5203245, 0.89679474, 1.0060954]\n",
      "Batch 269/700: Discriminator loss = 1.1065354347229004, GAN loss = [2.5057535, 0.93033487, 0.9579958]\n",
      "Batch 270/700: Discriminator loss = 1.111709713935852, GAN loss = [2.5742958, 0.9265915, 1.0303115]\n",
      "Batch 271/700: Discriminator loss = 1.117941975593567, GAN loss = [2.5340636, 0.90945035, 1.0072566]\n",
      "Batch 272/700: Discriminator loss = 1.1581045389175415, GAN loss = [2.5500495, 0.8939703, 1.038731]\n",
      "Batch 273/700: Discriminator loss = 1.163222074508667, GAN loss = [2.5958076, 0.9112069, 1.0672287]\n",
      "Batch 274/700: Discriminator loss = 1.1517623662948608, GAN loss = [2.600964, 0.8826175, 1.1009566]\n",
      "Batch 275/700: Discriminator loss = 1.1650700569152832, GAN loss = [2.570972, 0.88968444, 1.063885]\n",
      "Batch 276/700: Discriminator loss = 1.110206127166748, GAN loss = [2.6943035, 0.9394748, 1.1374327]\n",
      "Batch 277/700: Discriminator loss = 1.1095237731933594, GAN loss = [2.6393137, 0.9187474, 1.1031932]\n",
      "Batch 278/700: Discriminator loss = 1.1259568929672241, GAN loss = [2.6022182, 0.91834414, 1.0665184]\n",
      "Batch 279/700: Discriminator loss = 1.1414563655853271, GAN loss = [2.567579, 0.90590805, 1.0443196]\n",
      "Batch 280/700: Discriminator loss = 1.123256802558899, GAN loss = [2.6129384, 0.94485426, 1.0507531]\n",
      "Batch 281/700: Discriminator loss = 1.1043198108673096, GAN loss = [2.6467566, 0.9187722, 1.1106802]\n",
      "Batch 282/700: Discriminator loss = 1.1182684898376465, GAN loss = [2.6613553, 0.9147402, 1.1293373]\n",
      "Batch 283/700: Discriminator loss = 1.1166496276855469, GAN loss = [2.6117876, 0.92026114, 1.0742642]\n",
      "Batch 284/700: Discriminator loss = 1.108046054840088, GAN loss = [2.5923746, 0.92157155, 1.0535619]\n",
      "Batch 285/700: Discriminator loss = 1.1040480136871338, GAN loss = [2.6761284, 0.9457935, 1.1130943]\n",
      "Batch 286/700: Discriminator loss = 1.0997308492660522, GAN loss = [2.6475084, 0.95761836, 1.0726535]\n",
      "Batch 287/700: Discriminator loss = 1.0930408239364624, GAN loss = [2.7270803, 0.9525075, 1.157349]\n",
      "Batch 288/700: Discriminator loss = 1.0967309474945068, GAN loss = [2.5682461, 0.94560343, 1.0054276]\n",
      "Batch 289/700: Discriminator loss = 1.1352194547653198, GAN loss = [2.6624994, 0.96139246, 1.0838978]\n",
      "Batch 290/700: Discriminator loss = 1.0884816646575928, GAN loss = [2.665867, 0.96649957, 1.0821437]\n",
      "Batch 291/700: Discriminator loss = 1.0786442756652832, GAN loss = [2.66672, 0.98561454, 1.0638509]\n",
      "Batch 292/700: Discriminator loss = 1.0844755172729492, GAN loss = [2.7649448, 0.99103564, 1.1566119]\n",
      "Batch 293/700: Discriminator loss = 1.0896414518356323, GAN loss = [2.6960948, 0.97237146, 1.1064025]\n",
      "Batch 294/700: Discriminator loss = 1.0767275094985962, GAN loss = [2.7398746, 0.98316604, 1.1393665]\n",
      "Batch 295/700: Discriminator loss = 1.0922950506210327, GAN loss = [2.6345901, 0.95545506, 1.0617721]\n",
      "Batch 296/700: Discriminator loss = 1.1052347421646118, GAN loss = [2.6252546, 0.9388302, 1.0690312]\n",
      "Batch 297/700: Discriminator loss = 1.082423448562622, GAN loss = [2.6773357, 0.9802258, 1.079676]\n",
      "Batch 298/700: Discriminator loss = 1.1139869689941406, GAN loss = [2.7487206, 0.9792886, 1.1519785]\n",
      "Batch 299/700: Discriminator loss = 1.0945507287979126, GAN loss = [2.6048884, 0.95922965, 1.0281521]\n",
      "Batch 300/700: Discriminator loss = 1.111863374710083, GAN loss = [2.651722, 0.9480852, 1.0860668]\n",
      "Batch 301/700: Discriminator loss = 1.0895898342132568, GAN loss = [2.7009385, 0.9981012, 1.0852115]\n",
      "Batch 302/700: Discriminator loss = 1.0840468406677246, GAN loss = [2.5864162, 0.98792136, 0.98084867]\n",
      "Batch 303/700: Discriminator loss = 1.1193777322769165, GAN loss = [2.686168, 0.99329257, 1.0752461]\n",
      "Batch 304/700: Discriminator loss = 1.0951573848724365, GAN loss = [2.5814416, 1.0107126, 0.95309204]\n",
      "Batch 305/700: Discriminator loss = 1.102517008781433, GAN loss = [2.7223585, 1.0195426, 1.0851649]\n",
      "Batch 306/700: Discriminator loss = 1.1061426401138306, GAN loss = [2.6402524, 0.9722007, 1.0503672]\n",
      "Batch 307/700: Discriminator loss = 1.1289876699447632, GAN loss = [2.714095, 0.97554857, 1.1208345]\n",
      "Batch 308/700: Discriminator loss = 1.1625343561172485, GAN loss = [2.6334693, 0.9216256, 1.0940944]\n",
      "Batch 309/700: Discriminator loss = 1.1351892948150635, GAN loss = [2.593339, 0.9715946, 1.0039015]\n",
      "Batch 310/700: Discriminator loss = 1.1616637706756592, GAN loss = [2.6594648, 0.936161, 1.1053603]\n",
      "Batch 311/700: Discriminator loss = 1.105132818222046, GAN loss = [2.6189585, 0.99376404, 1.0071654]\n",
      "Batch 312/700: Discriminator loss = 1.1226109266281128, GAN loss = [2.7433653, 0.96211886, 1.1631424]\n",
      "Batch 313/700: Discriminator loss = 1.1234314441680908, GAN loss = [2.5952897, 0.9729634, 1.0041795]\n",
      "Batch 314/700: Discriminator loss = 1.1398917436599731, GAN loss = [2.525466, 0.9399471, 0.9673178]\n",
      "Batch 315/700: Discriminator loss = 1.138837218284607, GAN loss = [2.6344275, 0.9404604, 1.0757309]\n",
      "Batch 316/700: Discriminator loss = 1.1321282386779785, GAN loss = [2.543758, 0.9795925, 0.9458525]\n",
      "Batch 317/700: Discriminator loss = 1.1481279134750366, GAN loss = [2.647202, 0.9855297, 1.0432681]\n",
      "Batch 318/700: Discriminator loss = 1.1146349906921387, GAN loss = [2.7402296, 1.0117896, 1.1099893]\n",
      "Batch 319/700: Discriminator loss = 1.0807770490646362, GAN loss = [2.744874, 1.0634483, 1.0628974]\n",
      "Batch 320/700: Discriminator loss = 1.0838156938552856, GAN loss = [2.7430124, 1.0388316, 1.0855936]\n",
      "Batch 321/700: Discriminator loss = 1.1108962297439575, GAN loss = [2.7552364, 1.0432673, 1.0933318]\n",
      "Batch 322/700: Discriminator loss = 1.1153626441955566, GAN loss = [2.6743555, 1.0191475, 1.0365505]\n",
      "Batch 323/700: Discriminator loss = 1.1064025163650513, GAN loss = [2.7169843, 1.0583525, 1.0399158]\n",
      "Batch 324/700: Discriminator loss = 1.0700682401657104, GAN loss = [2.769735, 1.0750949, 1.0758611]\n",
      "Batch 325/700: Discriminator loss = 1.0921708345413208, GAN loss = [2.863568, 1.0584154, 1.18634]\n",
      "Batch 326/700: Discriminator loss = 1.0808138847351074, GAN loss = [2.889151, 1.1077783, 1.1625581]\n",
      "Batch 327/700: Discriminator loss = 1.0580164194107056, GAN loss = [2.7464166, 1.063433, 1.0641679]\n",
      "Batch 328/700: Discriminator loss = 1.1075305938720703, GAN loss = [2.8133588, 1.0082248, 1.1862901]\n",
      "Batch 329/700: Discriminator loss = 1.06931734085083, GAN loss = [2.8079422, 1.0497773, 1.1393082]\n",
      "Batch 330/700: Discriminator loss = 1.0887401103973389, GAN loss = [2.755496, 1.0260283, 1.1105655]\n",
      "Batch 331/700: Discriminator loss = 1.1347765922546387, GAN loss = [2.6869316, 0.9842502, 1.0837361]\n",
      "Batch 332/700: Discriminator loss = 1.0721672773361206, GAN loss = [2.7979379, 1.0548327, 1.1241363]\n",
      "Batch 333/700: Discriminator loss = 1.1089286804199219, GAN loss = [2.7196474, 0.9975042, 1.1031548]\n",
      "Batch 334/700: Discriminator loss = 1.0958845615386963, GAN loss = [2.6921766, 0.99122757, 1.0819383]\n",
      "Batch 335/700: Discriminator loss = 1.121820092201233, GAN loss = [2.643798, 0.9753824, 1.0493891]\n",
      "Batch 336/700: Discriminator loss = 1.108476161956787, GAN loss = [2.6715784, 1.0176812, 1.034842]\n",
      "Batch 337/700: Discriminator loss = 1.110785961151123, GAN loss = [2.6957004, 0.9790783, 1.0975394]\n",
      "Batch 338/700: Discriminator loss = 1.0956312417984009, GAN loss = [2.689775, 1.0555465, 1.0151012]\n",
      "Batch 339/700: Discriminator loss = 1.099223256111145, GAN loss = [2.77072, 1.002144, 1.1494415]\n",
      "Batch 340/700: Discriminator loss = 1.1191619634628296, GAN loss = [2.656867, 0.99866563, 1.0390499]\n",
      "Batch 341/700: Discriminator loss = 1.0972719192504883, GAN loss = [2.709777, 1.0029732, 1.0876523]\n",
      "Batch 342/700: Discriminator loss = 1.133283257484436, GAN loss = [2.7471194, 0.9894777, 1.1384808]\n",
      "Batch 343/700: Discriminator loss = 1.1086657047271729, GAN loss = [2.616489, 1.0144869, 0.9828243]\n",
      "Batch 344/700: Discriminator loss = 1.1216987371444702, GAN loss = [2.6107857, 0.9693676, 1.0222337]\n",
      "Batch 345/700: Discriminator loss = 1.1295111179351807, GAN loss = [2.6742675, 1.0104048, 1.0446697]\n",
      "Batch 346/700: Discriminator loss = 1.1001083850860596, GAN loss = [2.6346085, 0.9824559, 1.0329474]\n",
      "Batch 347/700: Discriminator loss = 1.1355957984924316, GAN loss = [2.6525106, 0.98540545, 1.0479376]\n",
      "Batch 348/700: Discriminator loss = 1.1442461013793945, GAN loss = [2.5364249, 0.95807403, 0.959189]\n",
      "Batch 349/700: Discriminator loss = 1.107718825340271, GAN loss = [2.7227721, 1.000614, 1.1030028]\n",
      "Batch 350/700: Discriminator loss = 1.1249510049819946, GAN loss = [2.5784218, 0.9871085, 0.97218215]\n",
      "Batch 351/700: Discriminator loss = 1.1331121921539307, GAN loss = [2.5197618, 0.94323295, 0.95743996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 352/700: Discriminator loss = 1.138811707496643, GAN loss = [2.5165641, 0.9352357, 0.96224105]\n",
      "Batch 353/700: Discriminator loss = 1.142009973526001, GAN loss = [2.6085398, 0.9448235, 1.0446359]\n",
      "Batch 354/700: Discriminator loss = 1.1448848247528076, GAN loss = [2.5146868, 0.92723596, 0.9683569]\n",
      "Batch 355/700: Discriminator loss = 1.1469638347625732, GAN loss = [2.583518, 0.9437555, 1.0206696]\n",
      "Batch 356/700: Discriminator loss = 1.1183161735534668, GAN loss = [2.637531, 0.95333993, 1.0651058]\n",
      "Batch 357/700: Discriminator loss = 1.1376359462738037, GAN loss = [2.5744627, 0.93889964, 1.0164938]\n",
      "Batch 358/700: Discriminator loss = 1.1340372562408447, GAN loss = [2.4835067, 0.9600615, 0.9043934]\n",
      "Batch 359/700: Discriminator loss = 1.1671638488769531, GAN loss = [2.3891137, 0.88856184, 0.881506]\n",
      "Batch 360/700: Discriminator loss = 1.1211097240447998, GAN loss = [2.6183188, 0.9503825, 1.0489087]\n",
      "Batch 361/700: Discriminator loss = 1.1183645725250244, GAN loss = [2.5828843, 0.94661707, 1.0172462]\n",
      "Batch 362/700: Discriminator loss = 1.1585242748260498, GAN loss = [2.6279597, 0.91512305, 1.0938064]\n",
      "Batch 363/700: Discriminator loss = 1.1816270351409912, GAN loss = [2.4030507, 0.88534856, 0.8986628]\n",
      "Batch 364/700: Discriminator loss = 1.1620689630508423, GAN loss = [2.4924867, 0.89171046, 0.98171556]\n",
      "Batch 365/700: Discriminator loss = 1.1359782218933105, GAN loss = [2.4927692, 0.9368811, 0.9368287]\n",
      "Batch 366/700: Discriminator loss = 1.1390392780303955, GAN loss = [2.4696424, 0.91804343, 0.9325746]\n",
      "Batch 367/700: Discriminator loss = 1.142012596130371, GAN loss = [2.5550263, 0.9101688, 1.0258656]\n",
      "Batch 368/700: Discriminator loss = 1.135301947593689, GAN loss = [2.4780664, 0.9095114, 0.94958794]\n",
      "Batch 369/700: Discriminator loss = 1.1234403848648071, GAN loss = [2.5176942, 0.94157135, 0.9571541]\n",
      "Batch 370/700: Discriminator loss = 1.14263117313385, GAN loss = [2.485261, 0.90197325, 0.9643057]\n",
      "Batch 371/700: Discriminator loss = 1.1206165552139282, GAN loss = [2.5839663, 0.92836183, 1.0366106]\n",
      "Batch 372/700: Discriminator loss = 1.1181650161743164, GAN loss = [2.5539825, 0.9363837, 0.99861383]\n",
      "Batch 373/700: Discriminator loss = 1.1506462097167969, GAN loss = [2.462098, 0.8927591, 0.9503781]\n",
      "Batch 374/700: Discriminator loss = 1.1227364540100098, GAN loss = [2.5601244, 0.93479055, 1.0063835]\n",
      "Batch 375/700: Discriminator loss = 1.1469464302062988, GAN loss = [2.5268962, 0.9048342, 1.0031167]\n",
      "Batch 376/700: Discriminator loss = 1.1069647073745728, GAN loss = [2.5317152, 0.9495014, 0.96325564]\n",
      "Batch 377/700: Discriminator loss = 1.1183140277862549, GAN loss = [2.6204627, 0.9585034, 1.0429776]\n",
      "Batch 378/700: Discriminator loss = 1.094457983970642, GAN loss = [2.5486162, 0.96755075, 0.9620629]\n",
      "Batch 379/700: Discriminator loss = 1.0925096273422241, GAN loss = [2.6592083, 0.995264, 1.044941]\n",
      "Batch 380/700: Discriminator loss = 1.1025956869125366, GAN loss = [2.6145992, 0.9706499, 1.024904]\n",
      "Batch 381/700: Discriminator loss = 1.0671342611312866, GAN loss = [2.7005858, 0.998746, 1.0827535]\n",
      "Batch 382/700: Discriminator loss = 1.0989378690719604, GAN loss = [2.563052, 0.96777666, 0.97616404]\n",
      "Batch 383/700: Discriminator loss = 1.1085166931152344, GAN loss = [2.6246493, 0.9424618, 1.0630486]\n",
      "Batch 384/700: Discriminator loss = 1.104220986366272, GAN loss = [2.653809, 0.97680825, 1.0578612]\n",
      "Batch 385/700: Discriminator loss = 1.1002403497695923, GAN loss = [2.5000255, 0.94722015, 0.9336597]\n",
      "Batch 386/700: Discriminator loss = 1.1019070148468018, GAN loss = [2.682932, 0.96550834, 1.0982949]\n",
      "Batch 387/700: Discriminator loss = 1.1326186656951904, GAN loss = [2.4378123, 0.9155905, 0.9030975]\n",
      "Batch 388/700: Discriminator loss = 1.1056159734725952, GAN loss = [2.4943924, 0.93574595, 0.9395196]\n",
      "Batch 389/700: Discriminator loss = 1.1195342540740967, GAN loss = [2.623007, 0.9304576, 1.0734404]\n",
      "Batch 390/700: Discriminator loss = 1.0865883827209473, GAN loss = [2.6398735, 0.95910156, 1.061684]\n",
      "Batch 391/700: Discriminator loss = 1.1175744533538818, GAN loss = [2.61184, 0.937039, 1.0557109]\n",
      "Batch 392/700: Discriminator loss = 1.0992608070373535, GAN loss = [2.7074723, 0.95264214, 1.135727]\n",
      "Batch 393/700: Discriminator loss = 1.0842193365097046, GAN loss = [2.6242623, 0.96877813, 1.0363681]\n",
      "Batch 394/700: Discriminator loss = 1.0987231731414795, GAN loss = [2.6888814, 0.9472325, 1.1225058]\n",
      "Batch 395/700: Discriminator loss = 1.112147569656372, GAN loss = [2.6609325, 0.9515229, 1.0902419]\n",
      "Batch 396/700: Discriminator loss = 1.1027129888534546, GAN loss = [2.6102772, 0.950793, 1.0403098]\n",
      "Batch 397/700: Discriminator loss = 1.1172515153884888, GAN loss = [2.6570237, 0.9428893, 1.0949619]\n",
      "Batch 398/700: Discriminator loss = 1.1169929504394531, GAN loss = [2.6481335, 0.94944763, 1.0795372]\n",
      "Batch 399/700: Discriminator loss = 1.139769434928894, GAN loss = [2.5672352, 0.93315077, 1.0149662]\n",
      "Batch 400/700: Discriminator loss = 1.1302545070648193, GAN loss = [2.4912155, 0.91598517, 0.9561143]\n",
      "Batch 401/700: Discriminator loss = 1.123669147491455, GAN loss = [2.581416, 0.958152, 1.0041598]\n",
      "Batch 402/700: Discriminator loss = 1.0988529920578003, GAN loss = [2.6501708, 0.96213377, 1.0689766]\n",
      "Batch 403/700: Discriminator loss = 1.0948333740234375, GAN loss = [2.6573863, 0.9659127, 1.0724425]\n",
      "Batch 404/700: Discriminator loss = 1.123356580734253, GAN loss = [2.5575073, 0.95876664, 0.97970396]\n",
      "Batch 405/700: Discriminator loss = 1.1089072227478027, GAN loss = [2.6289425, 0.9659132, 1.0439885]\n",
      "Batch 406/700: Discriminator loss = 1.1075003147125244, GAN loss = [2.6816213, 0.9865224, 1.0760581]\n",
      "Batch 407/700: Discriminator loss = 1.1089608669281006, GAN loss = [2.5551922, 0.9706554, 0.9655127]\n",
      "Batch 408/700: Discriminator loss = 1.1033998727798462, GAN loss = [2.5303593, 0.9841308, 0.92720217]\n",
      "Batch 409/700: Discriminator loss = 1.1348023414611816, GAN loss = [2.5421844, 0.9338834, 0.98924756]\n",
      "Batch 410/700: Discriminator loss = 1.1060912609100342, GAN loss = [2.586837, 0.9895075, 0.97828424]\n",
      "Batch 411/700: Discriminator loss = 1.1262444257736206, GAN loss = [2.5790932, 0.96279955, 0.9972714]\n",
      "Batch 412/700: Discriminator loss = 1.1162112951278687, GAN loss = [2.594494, 0.99964744, 0.97584826]\n",
      "Batch 413/700: Discriminator loss = 1.1255559921264648, GAN loss = [2.6091812, 0.946149, 1.0440648]\n",
      "Batch 414/700: Discriminator loss = 1.1108345985412598, GAN loss = [2.5645802, 0.9795943, 0.9660323]\n",
      "Batch 415/700: Discriminator loss = 1.1398427486419678, GAN loss = [2.5047688, 0.90984184, 0.9760167]\n",
      "Batch 416/700: Discriminator loss = 1.1596462726593018, GAN loss = [2.538581, 0.9154268, 1.0042782]\n",
      "Batch 417/700: Discriminator loss = 1.0991570949554443, GAN loss = [2.6590889, 0.9725763, 1.0676451]\n",
      "Batch 418/700: Discriminator loss = 1.1481858491897583, GAN loss = [2.539982, 0.93546456, 0.985667]\n",
      "Batch 419/700: Discriminator loss = 1.1104140281677246, GAN loss = [2.6136987, 1.0116243, 0.9832521]\n",
      "Batch 420/700: Discriminator loss = 1.0900719165802002, GAN loss = [2.661712, 0.96837294, 1.0745254]\n",
      "Batch 421/700: Discriminator loss = 1.1364421844482422, GAN loss = [2.5434034, 0.92721695, 0.99736243]\n",
      "Batch 422/700: Discriminator loss = 1.1481777429580688, GAN loss = [2.5791833, 0.9054596, 1.0548911]\n",
      "Batch 423/700: Discriminator loss = 1.1354511976242065, GAN loss = [2.6390464, 0.97846925, 1.0417341]\n",
      "Batch 424/700: Discriminator loss = 1.1233562231063843, GAN loss = [2.636675, 0.94192034, 1.0759053]\n",
      "Batch 425/700: Discriminator loss = 1.1520812511444092, GAN loss = [2.538424, 0.9047478, 1.0148388]\n",
      "Batch 426/700: Discriminator loss = 1.1498111486434937, GAN loss = [2.6188865, 0.9399547, 1.0600854]\n",
      "Batch 427/700: Discriminator loss = 1.1364398002624512, GAN loss = [2.5981526, 0.9236306, 1.0556673]\n",
      "Batch 428/700: Discriminator loss = 1.1222442388534546, GAN loss = [2.6930451, 0.9781884, 1.0960218]\n",
      "Batch 429/700: Discriminator loss = 1.0980920791625977, GAN loss = [2.7075627, 1.0217513, 1.0669796]\n",
      "Batch 430/700: Discriminator loss = 1.1305404901504517, GAN loss = [2.859268, 0.99623865, 1.2441797]\n",
      "Batch 431/700: Discriminator loss = 1.1732382774353027, GAN loss = [2.5895638, 0.93052655, 1.0401988]\n",
      "Batch 432/700: Discriminator loss = 1.13702392578125, GAN loss = [2.5746431, 0.97201616, 0.983779]\n",
      "Batch 433/700: Discriminator loss = 1.1423115730285645, GAN loss = [2.6018884, 0.9745941, 1.0084189]\n",
      "Batch 434/700: Discriminator loss = 1.178045630455017, GAN loss = [2.6410053, 0.9561683, 1.0659405]\n",
      "Batch 435/700: Discriminator loss = 1.125448226928711, GAN loss = [2.5649576, 0.97516227, 0.9708799]\n",
      "Batch 436/700: Discriminator loss = 1.1300829648971558, GAN loss = [2.636102, 1.0024137, 1.0147675]\n",
      "Batch 437/700: Discriminator loss = 1.186075210571289, GAN loss = [2.557449, 1.0102023, 0.9283098]\n",
      "Batch 438/700: Discriminator loss = 1.1519771814346313, GAN loss = [2.580644, 0.97911245, 0.9825925]\n",
      "Batch 439/700: Discriminator loss = 1.1558326482772827, GAN loss = [2.5371578, 0.9677618, 0.95042574]\n",
      "Batch 440/700: Discriminator loss = 1.192308783531189, GAN loss = [2.4324284, 0.90516794, 0.90825874]\n",
      "Batch 441/700: Discriminator loss = 1.163116216659546, GAN loss = [2.5783863, 0.9473959, 1.0119312]\n",
      "Batch 442/700: Discriminator loss = 1.1347559690475464, GAN loss = [2.5433831, 0.92754745, 0.996754]\n",
      "Batch 443/700: Discriminator loss = 1.1533019542694092, GAN loss = [2.527141, 0.9272049, 0.9808401]\n",
      "Batch 444/700: Discriminator loss = 1.1611876487731934, GAN loss = [2.4606354, 0.9009083, 0.94062877]\n",
      "Batch 445/700: Discriminator loss = 1.1742037534713745, GAN loss = [2.4613922, 0.8942932, 0.9480175]\n",
      "Batch 446/700: Discriminator loss = 1.1560295820236206, GAN loss = [2.570882, 0.91949236, 1.0323231]\n",
      "Batch 447/700: Discriminator loss = 1.1238963603973389, GAN loss = [2.5479617, 0.921141, 1.0077664]\n",
      "Batch 448/700: Discriminator loss = 1.1109603643417358, GAN loss = [2.5435371, 0.9331902, 0.99129546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 449/700: Discriminator loss = 1.1397554874420166, GAN loss = [2.4473672, 0.908214, 0.9201229]\n",
      "Batch 450/700: Discriminator loss = 1.107655644416809, GAN loss = [2.643216, 0.9310254, 1.0931602]\n",
      "Batch 451/700: Discriminator loss = 1.140675663948059, GAN loss = [2.4623857, 0.89792526, 0.9454277]\n",
      "Batch 452/700: Discriminator loss = 1.1473983526229858, GAN loss = [2.5375178, 0.8883872, 1.0300943]\n",
      "Batch 453/700: Discriminator loss = 1.1165248155593872, GAN loss = [2.5620918, 0.9078846, 1.0351765]\n",
      "Batch 454/700: Discriminator loss = 1.1271092891693115, GAN loss = [2.55641, 0.9173628, 1.0200213]\n",
      "Batch 455/700: Discriminator loss = 1.0917134284973145, GAN loss = [2.5778885, 0.9381147, 1.0207537]\n",
      "Batch 456/700: Discriminator loss = 1.107772946357727, GAN loss = [2.5712233, 0.91315186, 1.0390962]\n",
      "Batch 457/700: Discriminator loss = 1.1330829858779907, GAN loss = [2.4840322, 0.8939312, 0.97119635]\n",
      "Batch 458/700: Discriminator loss = 1.1096324920654297, GAN loss = [2.6145406, 0.9074691, 1.0882325]\n",
      "Batch 459/700: Discriminator loss = 1.080588459968567, GAN loss = [2.6666539, 0.92778665, 1.1200687]\n",
      "Batch 460/700: Discriminator loss = 1.120808720588684, GAN loss = [2.4996784, 0.90540045, 0.9755256]\n",
      "Batch 461/700: Discriminator loss = 1.1095483303070068, GAN loss = [2.5298967, 0.91230285, 0.9988722]\n",
      "Batch 462/700: Discriminator loss = 1.0970124006271362, GAN loss = [2.639746, 0.9299032, 1.0911553]\n",
      "Batch 463/700: Discriminator loss = 1.0964500904083252, GAN loss = [2.6806593, 0.94078344, 1.1212152]\n",
      "Batch 464/700: Discriminator loss = 1.119657278060913, GAN loss = [2.530034, 0.89568466, 1.0157082]\n",
      "Batch 465/700: Discriminator loss = 1.1081840991973877, GAN loss = [2.5558586, 0.9008908, 1.0363811]\n",
      "Batch 466/700: Discriminator loss = 1.1053190231323242, GAN loss = [2.5168993, 0.8988841, 0.9994768]\n",
      "Batch 467/700: Discriminator loss = 1.1199445724487305, GAN loss = [2.5965893, 0.9287267, 1.0493531]\n",
      "Batch 468/700: Discriminator loss = 1.0806695222854614, GAN loss = [2.691255, 0.94886756, 1.1238925]\n",
      "Batch 469/700: Discriminator loss = 1.097882628440857, GAN loss = [2.5133524, 0.9214409, 0.97344786]\n",
      "Batch 470/700: Discriminator loss = 1.1322288513183594, GAN loss = [2.6145287, 0.9303709, 1.0657303]\n",
      "Batch 471/700: Discriminator loss = 1.1015640497207642, GAN loss = [2.5799575, 0.9147366, 1.046802]\n",
      "Batch 472/700: Discriminator loss = 1.1173592805862427, GAN loss = [2.5778058, 0.9189129, 1.040479]\n",
      "Batch 473/700: Discriminator loss = 1.0913258790969849, GAN loss = [2.7311397, 0.9502727, 1.1624427]\n",
      "Batch 474/700: Discriminator loss = 1.140173077583313, GAN loss = [2.5724144, 0.91719264, 1.0368024]\n",
      "Batch 475/700: Discriminator loss = 1.090989351272583, GAN loss = [2.7137337, 0.97835726, 1.1169602]\n",
      "Batch 476/700: Discriminator loss = 1.0788915157318115, GAN loss = [2.6466222, 0.9736352, 1.0545759]\n",
      "Batch 477/700: Discriminator loss = 1.1147007942199707, GAN loss = [2.6565993, 0.91589475, 1.1223205]\n",
      "Batch 478/700: Discriminator loss = 1.1012136936187744, GAN loss = [2.6483288, 0.9426574, 1.0873164]\n",
      "Batch 479/700: Discriminator loss = 1.0788942575454712, GAN loss = [2.6094074, 0.9623105, 1.0287572]\n",
      "Batch 480/700: Discriminator loss = 1.0837830305099487, GAN loss = [2.698335, 0.9554161, 1.1246]\n",
      "Batch 481/700: Discriminator loss = 1.1035432815551758, GAN loss = [2.6479201, 0.9483552, 1.0812657]\n",
      "Batch 482/700: Discriminator loss = 1.0963910818099976, GAN loss = [2.644659, 0.9689818, 1.0573919]\n",
      "Batch 483/700: Discriminator loss = 1.0968432426452637, GAN loss = [2.7224364, 0.96537316, 1.1387954]\n",
      "Batch 484/700: Discriminator loss = 1.0852130651474, GAN loss = [2.7783046, 0.9730976, 1.1869423]\n",
      "Batch 485/700: Discriminator loss = 1.0898550748825073, GAN loss = [2.6186707, 0.9719369, 1.028485]\n",
      "Batch 486/700: Discriminator loss = 1.0832513570785522, GAN loss = [2.7592013, 0.98047906, 1.1604967]\n",
      "Batch 487/700: Discriminator loss = 1.1232037544250488, GAN loss = [2.647514, 0.9534309, 1.0758799]\n",
      "Batch 488/700: Discriminator loss = 1.0973042249679565, GAN loss = [2.733439, 0.9747637, 1.1404972]\n",
      "Batch 489/700: Discriminator loss = 1.0908995866775513, GAN loss = [2.611598, 0.97526723, 1.0181539]\n",
      "Batch 490/700: Discriminator loss = 1.1090258359909058, GAN loss = [2.7518892, 0.9894777, 1.1442211]\n",
      "Batch 491/700: Discriminator loss = 1.093083381652832, GAN loss = [2.7133803, 1.0143957, 1.0807973]\n",
      "Batch 492/700: Discriminator loss = 1.0949369668960571, GAN loss = [2.7100284, 0.99238974, 1.0994855]\n",
      "Batch 493/700: Discriminator loss = 1.0693256855010986, GAN loss = [2.7935648, 1.026285, 1.149148]\n",
      "Batch 494/700: Discriminator loss = 1.083149790763855, GAN loss = [2.7946544, 1.0062175, 1.1703134]\n",
      "Batch 495/700: Discriminator loss = 1.0435879230499268, GAN loss = [2.8283558, 1.0628446, 1.147407]\n",
      "Batch 496/700: Discriminator loss = 1.0914798974990845, GAN loss = [2.7632933, 1.0041081, 1.1410623]\n",
      "Batch 497/700: Discriminator loss = 1.096361517906189, GAN loss = [2.7054422, 0.97861207, 1.1086984]\n",
      "Batch 498/700: Discriminator loss = 1.0694913864135742, GAN loss = [2.7483296, 0.99798316, 1.1322467]\n",
      "Batch 499/700: Discriminator loss = 1.0797234773635864, GAN loss = [2.6551201, 0.9969245, 1.0401281]\n",
      "Batch 500/700: Discriminator loss = 1.1130163669586182, GAN loss = [2.677691, 0.9564485, 1.103182]\n",
      "Batch 501/700: Discriminator loss = 1.1095054149627686, GAN loss = [2.626863, 0.96926343, 1.0395377]\n",
      "Batch 502/700: Discriminator loss = 1.1421374082565308, GAN loss = [2.633377, 0.95514494, 1.0601487]\n",
      "Batch 503/700: Discriminator loss = 1.118269681930542, GAN loss = [2.7200744, 0.96815544, 1.1338167]\n",
      "Batch 504/700: Discriminator loss = 1.0968388319015503, GAN loss = [2.6753807, 0.97209686, 1.0851773]\n",
      "Batch 505/700: Discriminator loss = 1.1145272254943848, GAN loss = [2.6127517, 0.9662938, 1.0283747]\n",
      "Batch 506/700: Discriminator loss = 1.1040416955947876, GAN loss = [2.6955812, 0.9783032, 1.0992107]\n",
      "Batch 507/700: Discriminator loss = 1.0768927335739136, GAN loss = [2.843386, 0.97680765, 1.2485329]\n",
      "Batch 508/700: Discriminator loss = 1.0716801881790161, GAN loss = [2.669071, 0.97315687, 1.0778799]\n",
      "Batch 509/700: Discriminator loss = 1.08069908618927, GAN loss = [2.6921916, 0.9727917, 1.1013783]\n",
      "Batch 510/700: Discriminator loss = 1.1196343898773193, GAN loss = [2.6137462, 0.9313587, 1.0643895]\n",
      "Batch 511/700: Discriminator loss = 1.087554693222046, GAN loss = [2.7322311, 0.9566659, 1.1575959]\n",
      "Batch 512/700: Discriminator loss = 1.1421295404434204, GAN loss = [2.7248256, 0.9245663, 1.1823081]\n",
      "Batch 513/700: Discriminator loss = 1.119496464729309, GAN loss = [2.7404065, 0.94412786, 1.1783429]\n",
      "Batch 514/700: Discriminator loss = 1.1004185676574707, GAN loss = [2.7121482, 0.9610205, 1.1331939]\n",
      "Batch 515/700: Discriminator loss = 1.1230316162109375, GAN loss = [2.6697216, 0.95241463, 1.0993787]\n",
      "Batch 516/700: Discriminator loss = 1.134071946144104, GAN loss = [2.6082902, 0.9497514, 1.0405961]\n",
      "Batch 517/700: Discriminator loss = 1.124211311340332, GAN loss = [2.6368961, 0.94302964, 1.0758941]\n",
      "Batch 518/700: Discriminator loss = 1.1648496389389038, GAN loss = [2.720879, 0.964467, 1.1384418]\n",
      "Batch 519/700: Discriminator loss = 1.0950424671173096, GAN loss = [2.7104497, 0.9608647, 1.131616]\n",
      "Batch 520/700: Discriminator loss = 1.10627281665802, GAN loss = [2.6458664, 0.998475, 1.02943]\n",
      "Batch 521/700: Discriminator loss = 1.1269383430480957, GAN loss = [2.667574, 0.98456645, 1.0650183]\n",
      "Batch 522/700: Discriminator loss = 1.0918567180633545, GAN loss = [2.6476402, 0.9648465, 1.0647846]\n",
      "Batch 523/700: Discriminator loss = 1.1162149906158447, GAN loss = [2.5831857, 0.9741242, 0.99102855]\n",
      "Batch 524/700: Discriminator loss = 1.1335912942886353, GAN loss = [2.8352764, 0.9879779, 1.2292317]\n",
      "Batch 525/700: Discriminator loss = 1.1105324029922485, GAN loss = [2.5895972, 0.9834214, 0.9880877]\n",
      "Batch 526/700: Discriminator loss = 1.179566740989685, GAN loss = [2.6533315, 0.9749801, 1.0602089]\n",
      "Batch 527/700: Discriminator loss = 1.0907248258590698, GAN loss = [2.7618022, 1.0201263, 1.1234995]\n",
      "Batch 528/700: Discriminator loss = 1.1253079175949097, GAN loss = [2.6723368, 0.9610979, 1.0930599]\n",
      "Batch 529/700: Discriminator loss = 1.0984115600585938, GAN loss = [2.780619, 1.000318, 1.1621625]\n",
      "Batch 530/700: Discriminator loss = 1.1018726825714111, GAN loss = [2.6637318, 0.97113127, 1.0744773]\n",
      "Batch 531/700: Discriminator loss = 1.1151195764541626, GAN loss = [2.6746845, 1.0210973, 1.0354927]\n",
      "Batch 532/700: Discriminator loss = 1.1280204057693481, GAN loss = [2.693958, 0.98127425, 1.094588]\n",
      "Batch 533/700: Discriminator loss = 1.0999047756195068, GAN loss = [2.6733143, 1.0109049, 1.044328]\n",
      "Batch 534/700: Discriminator loss = 1.1167049407958984, GAN loss = [2.6711042, 0.9969954, 1.0560384]\n",
      "Batch 535/700: Discriminator loss = 1.133378028869629, GAN loss = [2.5440707, 0.97150475, 0.95449984]\n",
      "Batch 536/700: Discriminator loss = 1.156224250793457, GAN loss = [2.6862783, 0.97199446, 1.0962127]\n",
      "Batch 537/700: Discriminator loss = 1.1504347324371338, GAN loss = [2.6541588, 0.9955392, 1.0405517]\n",
      "Batch 538/700: Discriminator loss = 1.1100045442581177, GAN loss = [2.6076732, 1.0224787, 0.9671223]\n",
      "Batch 539/700: Discriminator loss = 1.111788272857666, GAN loss = [2.5849621, 1.0188992, 0.94798124]\n",
      "Batch 540/700: Discriminator loss = 1.1276437044143677, GAN loss = [2.6468263, 1.0210807, 1.0076481]\n",
      "Batch 541/700: Discriminator loss = 1.1502245664596558, GAN loss = [2.5956674, 0.9901419, 0.9874321]\n",
      "Batch 542/700: Discriminator loss = 1.141858458518982, GAN loss = [2.5100715, 0.9718341, 0.92017055]\n",
      "Batch 543/700: Discriminator loss = 1.1521375179290771, GAN loss = [2.5483105, 0.95214033, 0.9781241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 544/700: Discriminator loss = 1.1452001333236694, GAN loss = [2.5739515, 0.95581037, 1.0001025]\n",
      "Batch 545/700: Discriminator loss = 1.1242420673370361, GAN loss = [2.542746, 1.0071268, 0.9175634]\n",
      "Batch 546/700: Discriminator loss = 1.1349936723709106, GAN loss = [2.5465293, 0.9637288, 0.9647198]\n",
      "Batch 547/700: Discriminator loss = 1.143617868423462, GAN loss = [2.5777838, 1.010577, 0.94910157]\n",
      "Batch 548/700: Discriminator loss = 1.1292694807052612, GAN loss = [2.5200176, 0.96345216, 0.93846285]\n",
      "Batch 549/700: Discriminator loss = 1.1548106670379639, GAN loss = [2.5593796, 0.94273925, 0.99854296]\n",
      "Batch 550/700: Discriminator loss = 1.12483811378479, GAN loss = [2.6302466, 0.98631036, 1.025817]\n",
      "Batch 551/700: Discriminator loss = 1.152408242225647, GAN loss = [2.5571442, 0.95247126, 0.98650914]\n",
      "Batch 552/700: Discriminator loss = 1.1751450300216675, GAN loss = [2.535218, 0.95796776, 0.9590907]\n",
      "Batch 553/700: Discriminator loss = 1.1468284130096436, GAN loss = [2.6124597, 0.9497694, 1.0445329]\n",
      "Batch 554/700: Discriminator loss = 1.1280717849731445, GAN loss = [2.5831563, 1.0011299, 0.9638694]\n",
      "Batch 555/700: Discriminator loss = 1.107505202293396, GAN loss = [2.6292067, 0.984693, 1.0263581]\n",
      "Batch 556/700: Discriminator loss = 1.0991441011428833, GAN loss = [2.6202023, 1.0204421, 0.98161966]\n",
      "Batch 557/700: Discriminator loss = 1.1357001066207886, GAN loss = [2.6011662, 0.9609076, 1.0221483]\n",
      "Batch 558/700: Discriminator loss = 1.174285650253296, GAN loss = [2.587467, 0.9522339, 1.017135]\n",
      "Batch 559/700: Discriminator loss = 1.124919056892395, GAN loss = [2.6771793, 0.9948876, 1.0641837]\n",
      "Batch 560/700: Discriminator loss = 1.123209834098816, GAN loss = [2.5642724, 0.97957903, 0.9665805]\n",
      "Batch 561/700: Discriminator loss = 1.1561070680618286, GAN loss = [2.5887403, 0.9647042, 1.0059301]\n",
      "Batch 562/700: Discriminator loss = 1.1174529790878296, GAN loss = [2.6019194, 0.9724227, 1.0113964]\n",
      "Batch 563/700: Discriminator loss = 1.1402710676193237, GAN loss = [2.5616345, 0.9742974, 0.9692584]\n",
      "Batch 564/700: Discriminator loss = 1.1321735382080078, GAN loss = [2.6281564, 0.99402213, 1.0160905]\n",
      "Batch 565/700: Discriminator loss = 1.1619813442230225, GAN loss = [2.5610366, 0.94552445, 0.9974733]\n",
      "Batch 566/700: Discriminator loss = 1.1656371355056763, GAN loss = [2.4924383, 0.94866323, 0.92570746]\n",
      "Batch 567/700: Discriminator loss = 1.132961392402649, GAN loss = [2.565736, 0.97057724, 0.9770504]\n",
      "Batch 568/700: Discriminator loss = 1.147606372833252, GAN loss = [2.467519, 0.94445264, 0.9049298]\n",
      "Batch 569/700: Discriminator loss = 1.1605018377304077, GAN loss = [2.5004303, 0.93816423, 0.9441152]\n",
      "Batch 570/700: Discriminator loss = 1.1375911235809326, GAN loss = [2.588974, 0.97303045, 0.9977922]\n",
      "Batch 571/700: Discriminator loss = 1.134528636932373, GAN loss = [2.604305, 1.0046405, 0.98153436]\n",
      "Batch 572/700: Discriminator loss = 1.1353081464767456, GAN loss = [2.4880266, 0.9474664, 0.9224327]\n",
      "Batch 573/700: Discriminator loss = 1.134670615196228, GAN loss = [2.4982297, 0.9516629, 0.92841566]\n",
      "Batch 574/700: Discriminator loss = 1.0998096466064453, GAN loss = [2.5778666, 0.9972914, 0.9624456]\n",
      "Batch 575/700: Discriminator loss = 1.1023163795471191, GAN loss = [2.5765367, 0.9824123, 0.976002]\n",
      "Batch 576/700: Discriminator loss = 1.1042839288711548, GAN loss = [2.522183, 0.95084226, 0.9531786]\n",
      "Batch 577/700: Discriminator loss = 1.1313546895980835, GAN loss = [2.5952783, 0.95158166, 1.0255073]\n",
      "Batch 578/700: Discriminator loss = 1.1296635866165161, GAN loss = [2.529109, 0.9508389, 0.9600503]\n",
      "Batch 579/700: Discriminator loss = 1.0945955514907837, GAN loss = [2.5780985, 0.9810936, 0.9787581]\n",
      "Batch 580/700: Discriminator loss = 1.1089885234832764, GAN loss = [2.6017826, 0.98518425, 0.9983625]\n",
      "Batch 581/700: Discriminator loss = 1.0983288288116455, GAN loss = [2.6306763, 1.0337526, 0.97866684]\n",
      "Batch 582/700: Discriminator loss = 1.107982873916626, GAN loss = [2.647889, 1.0203555, 1.0092639]\n",
      "Batch 583/700: Discriminator loss = 1.09530770778656, GAN loss = [2.5755663, 0.97970307, 0.977518]\n",
      "Batch 584/700: Discriminator loss = 1.0871169567108154, GAN loss = [2.6388311, 1.0271654, 0.993267]\n",
      "Batch 585/700: Discriminator loss = 1.1387630701065063, GAN loss = [2.5786238, 0.99251336, 0.96768755]\n",
      "Batch 586/700: Discriminator loss = 1.0817261934280396, GAN loss = [2.6544664, 1.0477617, 0.988247]\n",
      "Batch 587/700: Discriminator loss = 1.1343153715133667, GAN loss = [2.5989633, 1.0071557, 0.9733417]\n",
      "Batch 588/700: Discriminator loss = 1.1130127906799316, GAN loss = [2.5821943, 1.0221822, 0.94151205]\n",
      "Batch 589/700: Discriminator loss = 1.1230990886688232, GAN loss = [2.7201486, 1.0708209, 1.0307907]\n",
      "Batch 590/700: Discriminator loss = 1.1158872842788696, GAN loss = [2.6608064, 1.0372692, 1.0050001]\n",
      "Batch 591/700: Discriminator loss = 1.2079492807388306, GAN loss = [2.4433053, 0.93149835, 0.89329165]\n",
      "Batch 592/700: Discriminator loss = 1.134719729423523, GAN loss = [2.5830483, 0.9988813, 0.96565133]\n",
      "Batch 593/700: Discriminator loss = 1.1326786279678345, GAN loss = [2.57498, 0.98474914, 0.97171974]\n",
      "Batch 594/700: Discriminator loss = 1.1006085872650146, GAN loss = [2.6314628, 1.0513654, 0.9615899]\n",
      "Batch 595/700: Discriminator loss = 1.1506428718566895, GAN loss = [2.5505574, 0.9791818, 0.95286316]\n",
      "Batch 596/700: Discriminator loss = 1.1182063817977905, GAN loss = [2.5942242, 1.00137, 0.9743211]\n",
      "Batch 597/700: Discriminator loss = 1.1558804512023926, GAN loss = [2.5608296, 0.9760803, 0.9661711]\n",
      "Batch 598/700: Discriminator loss = 1.1540920734405518, GAN loss = [2.5522487, 0.99814904, 0.9354599]\n",
      "Batch 599/700: Discriminator loss = 1.152057409286499, GAN loss = [2.547909, 0.95890427, 0.97035336]\n",
      "Batch 600/700: Discriminator loss = 1.1661913394927979, GAN loss = [2.5093582, 0.9374648, 0.95322686]\n",
      "Batch 601/700: Discriminator loss = 1.131758451461792, GAN loss = [2.5453217, 1.008297, 0.91830474]\n",
      "Batch 602/700: Discriminator loss = 1.167703628540039, GAN loss = [2.4807453, 0.9862796, 0.8757259]\n",
      "Batch 603/700: Discriminator loss = 1.1744635105133057, GAN loss = [2.5294094, 0.954491, 0.9561477]\n",
      "Batch 604/700: Discriminator loss = 1.2032462358474731, GAN loss = [2.3474379, 0.87209, 0.85652906]\n",
      "Batch 605/700: Discriminator loss = 1.1722793579101562, GAN loss = [2.5079236, 0.9171215, 0.9719345]\n",
      "Batch 606/700: Discriminator loss = 1.1881983280181885, GAN loss = [2.4618905, 0.94372344, 0.89922875]\n",
      "Batch 607/700: Discriminator loss = 1.1392252445220947, GAN loss = [2.4599545, 0.9590641, 0.88190323]\n",
      "Batch 608/700: Discriminator loss = 1.1949214935302734, GAN loss = [2.4318776, 0.8637597, 0.94913054]\n",
      "Batch 609/700: Discriminator loss = 1.187968134880066, GAN loss = [2.375417, 0.8825779, 0.87383544]\n",
      "Batch 610/700: Discriminator loss = 1.1753379106521606, GAN loss = [2.43427, 0.9153553, 0.89989036]\n",
      "Batch 611/700: Discriminator loss = 1.139166235923767, GAN loss = [2.4997506, 0.9252641, 0.9554612]\n",
      "Batch 612/700: Discriminator loss = 1.1343157291412354, GAN loss = [2.5511897, 0.9474787, 0.9846871]\n",
      "Batch 613/700: Discriminator loss = 1.128577709197998, GAN loss = [2.5987213, 0.96005076, 1.0196595]\n",
      "Batch 614/700: Discriminator loss = 1.1117366552352905, GAN loss = [2.577596, 0.93148696, 1.0270807]\n",
      "Batch 615/700: Discriminator loss = 1.1273119449615479, GAN loss = [2.4578347, 0.94245714, 0.8963221]\n",
      "Batch 616/700: Discriminator loss = 1.1291897296905518, GAN loss = [2.47616, 0.908383, 0.9487159]\n",
      "Batch 617/700: Discriminator loss = 1.14010488986969, GAN loss = [2.674816, 0.94001853, 1.1157551]\n",
      "Batch 618/700: Discriminator loss = 1.1160160303115845, GAN loss = [2.6123383, 0.9268398, 1.0664575]\n",
      "Batch 619/700: Discriminator loss = 1.1300742626190186, GAN loss = [2.6025329, 0.9388028, 1.0446628]\n",
      "Batch 620/700: Discriminator loss = 1.1416767835617065, GAN loss = [2.5958717, 0.9189639, 1.0577995]\n",
      "Batch 621/700: Discriminator loss = 1.1213552951812744, GAN loss = [2.5710287, 0.92895323, 1.0229719]\n",
      "Batch 622/700: Discriminator loss = 1.1120134592056274, GAN loss = [2.6596851, 0.9674919, 1.0731409]\n",
      "Batch 623/700: Discriminator loss = 1.1419177055358887, GAN loss = [2.5246437, 0.89952797, 1.0061237]\n",
      "Batch 624/700: Discriminator loss = 1.1200131177902222, GAN loss = [2.611209, 0.9238481, 1.0683997]\n",
      "Batch 625/700: Discriminator loss = 1.146246075630188, GAN loss = [2.634504, 0.9267013, 1.0888408]\n",
      "Batch 626/700: Discriminator loss = 1.1274135112762451, GAN loss = [2.5726435, 0.91894877, 1.0347263]\n",
      "Batch 627/700: Discriminator loss = 1.111458420753479, GAN loss = [2.6258814, 0.93951064, 1.0674095]\n",
      "Batch 628/700: Discriminator loss = 1.0863112211227417, GAN loss = [2.7652037, 0.99557847, 1.1507076]\n",
      "Batch 629/700: Discriminator loss = 1.0896763801574707, GAN loss = [2.7318716, 0.979328, 1.1336663]\n",
      "Batch 630/700: Discriminator loss = 1.0694667100906372, GAN loss = [2.7018468, 0.9959496, 1.0870559]\n",
      "Batch 631/700: Discriminator loss = 1.088696002960205, GAN loss = [2.614306, 0.94847333, 1.0470332]\n",
      "Batch 632/700: Discriminator loss = 1.0940968990325928, GAN loss = [2.6738868, 0.96813124, 1.0869956]\n",
      "Batch 633/700: Discriminator loss = 1.0991930961608887, GAN loss = [2.6691718, 0.9703624, 1.0800586]\n",
      "Batch 634/700: Discriminator loss = 1.0845272541046143, GAN loss = [2.7282376, 0.9490454, 1.1604514]\n",
      "Batch 635/700: Discriminator loss = 1.0672873258590698, GAN loss = [2.7625039, 0.9811557, 1.1626396]\n",
      "Batch 636/700: Discriminator loss = 1.1031711101531982, GAN loss = [2.6661205, 0.9823786, 1.0650293]\n",
      "Batch 637/700: Discriminator loss = 1.0584038496017456, GAN loss = [2.7625792, 1.0063344, 1.1375154]\n",
      "Batch 638/700: Discriminator loss = 1.0879590511322021, GAN loss = [2.6919515, 0.9757216, 1.0974646]\n",
      "Batch 639/700: Discriminator loss = 1.070395588874817, GAN loss = [2.773732, 1.033448, 1.1214972]\n",
      "Batch 640/700: Discriminator loss = 1.056021809577942, GAN loss = [2.713527, 1.0242617, 1.0704453]\n",
      "Batch 641/700: Discriminator loss = 1.0841823816299438, GAN loss = [2.7883155, 0.9842388, 1.1852157]\n",
      "Batch 642/700: Discriminator loss = 1.1025627851486206, GAN loss = [2.6255014, 0.98458046, 1.022023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 643/700: Discriminator loss = 1.092922568321228, GAN loss = [2.759, 1.0327511, 1.1073517]\n",
      "Batch 644/700: Discriminator loss = 1.0887279510498047, GAN loss = [2.7731142, 1.0084212, 1.1457858]\n",
      "Batch 645/700: Discriminator loss = 1.125408411026001, GAN loss = [2.6558392, 0.9914507, 1.0454746]\n",
      "Batch 646/700: Discriminator loss = 1.1089668273925781, GAN loss = [2.6316416, 0.9718938, 1.0408349]\n",
      "Batch 647/700: Discriminator loss = 1.1178925037384033, GAN loss = [2.7666712, 0.98027194, 1.1674821]\n",
      "Batch 648/700: Discriminator loss = 1.1054619550704956, GAN loss = [2.7036328, 0.98078316, 1.1038973]\n",
      "Batch 649/700: Discriminator loss = 1.1304330825805664, GAN loss = [2.5905879, 0.9473155, 1.0243307]\n",
      "Batch 650/700: Discriminator loss = 1.1178526878356934, GAN loss = [2.7621553, 0.96872735, 1.1744831]\n",
      "Batch 651/700: Discriminator loss = 1.1238292455673218, GAN loss = [2.6827211, 0.9560344, 1.1077598]\n",
      "Batch 652/700: Discriminator loss = 1.143775224685669, GAN loss = [2.6278985, 0.94764054, 1.0613192]\n",
      "Batch 653/700: Discriminator loss = 1.1053516864776611, GAN loss = [2.648148, 0.9880434, 1.041156]\n",
      "Batch 654/700: Discriminator loss = 1.1167144775390625, GAN loss = [2.686509, 0.97482955, 1.092724]\n",
      "Batch 655/700: Discriminator loss = 1.1426669359207153, GAN loss = [2.6391578, 0.9250708, 1.0951157]\n",
      "Batch 656/700: Discriminator loss = 1.158543586730957, GAN loss = [2.5580623, 0.94957864, 0.9895011]\n",
      "Batch 657/700: Discriminator loss = 1.147765040397644, GAN loss = [2.5790803, 0.94832534, 1.0117568]\n",
      "Batch 658/700: Discriminator loss = 1.1612852811813354, GAN loss = [2.5271332, 0.9120698, 0.9960439]\n",
      "Batch 659/700: Discriminator loss = 1.1331065893173218, GAN loss = [2.6603465, 0.9930365, 1.0482868]\n",
      "Batch 660/700: Discriminator loss = 1.116584062576294, GAN loss = [2.6116126, 0.96771985, 1.0248535]\n",
      "Batch 661/700: Discriminator loss = 1.1202914714813232, GAN loss = [2.6164296, 0.99284285, 1.0045301]\n",
      "Batch 662/700: Discriminator loss = 1.1077402830123901, GAN loss = [2.5839894, 0.97462386, 0.9902872]\n",
      "Batch 663/700: Discriminator loss = 1.11434805393219, GAN loss = [2.6292894, 0.99911046, 1.0110708]\n",
      "Batch 664/700: Discriminator loss = 1.078041434288025, GAN loss = [2.6787364, 1.0068972, 1.0526978]\n",
      "Batch 665/700: Discriminator loss = 1.092036247253418, GAN loss = [2.7269294, 0.9888715, 1.1188755]\n",
      "Batch 666/700: Discriminator loss = 1.1120412349700928, GAN loss = [2.6740582, 1.0044342, 1.0504196]\n",
      "Batch 667/700: Discriminator loss = 1.08392333984375, GAN loss = [2.753032, 1.0247109, 1.1091073]\n",
      "Batch 668/700: Discriminator loss = 1.112398386001587, GAN loss = [2.674414, 1.0051408, 1.0500021]\n",
      "Batch 669/700: Discriminator loss = 1.0941334962844849, GAN loss = [2.6341069, 1.0139794, 1.0008126]\n",
      "Batch 670/700: Discriminator loss = 1.1253435611724854, GAN loss = [2.7009287, 0.99161017, 1.0899364]\n",
      "Batch 671/700: Discriminator loss = 1.124080777168274, GAN loss = [2.6283443, 0.9793164, 1.0296009]\n",
      "Batch 672/700: Discriminator loss = 1.1272495985031128, GAN loss = [2.5899434, 0.9696013, 1.0008647]\n",
      "Batch 673/700: Discriminator loss = 1.1097800731658936, GAN loss = [2.6793377, 0.97928244, 1.0805212]\n",
      "Batch 674/700: Discriminator loss = 1.1174302101135254, GAN loss = [2.6926498, 0.9863289, 1.0867695]\n",
      "Batch 675/700: Discriminator loss = 1.1009546518325806, GAN loss = [2.5856907, 0.95469785, 1.0114158]\n",
      "Batch 676/700: Discriminator loss = 1.0952386856079102, GAN loss = [2.6198137, 0.9922293, 1.0080009]\n",
      "Batch 677/700: Discriminator loss = 1.1278111934661865, GAN loss = [2.632875, 0.95816565, 1.0551265]\n",
      "Batch 678/700: Discriminator loss = 1.0947123765945435, GAN loss = [2.7993677, 0.99946314, 1.180353]\n",
      "Batch 679/700: Discriminator loss = 1.0893888473510742, GAN loss = [2.719472, 1.0011129, 1.098844]\n",
      "Batch 680/700: Discriminator loss = 1.0902934074401855, GAN loss = [2.6552424, 0.98947644, 1.0462723]\n",
      "Batch 681/700: Discriminator loss = 1.0670124292373657, GAN loss = [2.8372202, 1.0376073, 1.1801246]\n",
      "Batch 682/700: Discriminator loss = 1.103791356086731, GAN loss = [2.6905403, 1.0123162, 1.0587208]\n",
      "Batch 683/700: Discriminator loss = 1.0767759084701538, GAN loss = [2.835614, 1.0313514, 1.1847503]\n",
      "Batch 684/700: Discriminator loss = 1.059178113937378, GAN loss = [2.8000746, 1.0529197, 1.1276375]\n",
      "Batch 685/700: Discriminator loss = 1.0866798162460327, GAN loss = [2.800802, 1.0113552, 1.1699111]\n",
      "Batch 686/700: Discriminator loss = 1.1000003814697266, GAN loss = [2.7623885, 0.9910644, 1.1517903]\n",
      "Batch 687/700: Discriminator loss = 1.0735868215560913, GAN loss = [2.762419, 1.0210953, 1.1217825]\n",
      "Batch 688/700: Discriminator loss = 1.1044776439666748, GAN loss = [2.6209576, 0.99071795, 1.010661]\n",
      "Batch 689/700: Discriminator loss = 1.0929073095321655, GAN loss = [2.7858233, 1.0280504, 1.138178]\n",
      "Batch 690/700: Discriminator loss = 1.1150786876678467, GAN loss = [2.7012024, 1.0083841, 1.0732358]\n",
      "Batch 691/700: Discriminator loss = 1.0581698417663574, GAN loss = [2.7531922, 1.052003, 1.0816113]\n",
      "Batch 692/700: Discriminator loss = 1.1078766584396362, GAN loss = [2.781665, 1.0270834, 1.1349714]\n",
      "Batch 693/700: Discriminator loss = 1.1083728075027466, GAN loss = [2.7268798, 1.0407876, 1.0664388]\n",
      "Batch 694/700: Discriminator loss = 1.1382311582565308, GAN loss = [2.6128087, 1.0526116, 0.9405157]\n",
      "Batch 695/700: Discriminator loss = 1.1075273752212524, GAN loss = [2.6411364, 1.0170382, 1.0044186]\n",
      "Batch 696/700: Discriminator loss = 1.1039015054702759, GAN loss = [2.6562212, 1.0090842, 1.0274624]\n",
      "Batch 697/700: Discriminator loss = 1.1344808340072632, GAN loss = [2.7141838, 1.0037339, 1.0907422]\n",
      "Batch 698/700: Discriminator loss = 1.079495906829834, GAN loss = [2.7595751, 1.0327847, 1.1070528]\n",
      "Batch 699/700: Discriminator loss = 1.1244251728057861, GAN loss = [2.6577768, 0.97946465, 1.0585462]\n",
      "Batch 700/700: Discriminator loss = 1.1077333688735962, GAN loss = [2.7203178, 0.9987433, 1.1017746]\n",
      "Epoch 30/30\n",
      "Batch 1/700: Discriminator loss = 1.084957242012024, GAN loss = [2.7104602, 1.0246395, 1.0660045]\n",
      "Batch 2/700: Discriminator loss = 1.1078190803527832, GAN loss = [2.7069027, 0.99793977, 1.0891182]\n",
      "Batch 3/700: Discriminator loss = 1.0876637697219849, GAN loss = [2.7429159, 1.0457547, 1.0772935]\n",
      "Batch 4/700: Discriminator loss = 1.118302822113037, GAN loss = [2.764335, 1.0085565, 1.1359025]\n",
      "Batch 5/700: Discriminator loss = 1.1201711893081665, GAN loss = [2.7953491, 1.0126865, 1.1627318]\n",
      "Batch 6/700: Discriminator loss = 1.1178691387176514, GAN loss = [2.7324467, 1.0254563, 1.0869654]\n",
      "Batch 7/700: Discriminator loss = 1.1422860622406006, GAN loss = [2.6846776, 0.99649376, 1.0680925]\n",
      "Batch 8/700: Discriminator loss = 1.1213196516036987, GAN loss = [2.6588957, 1.0024773, 1.0362531]\n",
      "Batch 9/700: Discriminator loss = 1.145116925239563, GAN loss = [2.7084532, 0.9790649, 1.1091549]\n",
      "Batch 10/700: Discriminator loss = 1.1521884202957153, GAN loss = [2.5992134, 0.9999764, 0.97892594]\n",
      "Batch 11/700: Discriminator loss = 1.1533727645874023, GAN loss = [2.6265862, 0.98131233, 1.0249033]\n",
      "Batch 12/700: Discriminator loss = 1.1284363269805908, GAN loss = [2.6345518, 1.0181115, 0.99605215]\n",
      "Batch 13/700: Discriminator loss = 1.2030253410339355, GAN loss = [2.6843193, 0.9683418, 1.0955743]\n",
      "Batch 14/700: Discriminator loss = 1.1735111474990845, GAN loss = [2.6417294, 0.9819339, 1.0393864]\n",
      "Batch 15/700: Discriminator loss = 1.1427404880523682, GAN loss = [2.6602948, 1.0209669, 1.0188562]\n",
      "Batch 16/700: Discriminator loss = 1.2099970579147339, GAN loss = [2.6047754, 0.9616948, 1.0225071]\n",
      "Batch 17/700: Discriminator loss = 1.15598464012146, GAN loss = [2.6220076, 0.9785503, 1.0227808]\n",
      "Batch 18/700: Discriminator loss = 1.149245023727417, GAN loss = [2.6732366, 1.022428, 1.0300964]\n",
      "Batch 19/700: Discriminator loss = 1.1801174879074097, GAN loss = [2.544581, 0.96074873, 0.963102]\n",
      "Batch 20/700: Discriminator loss = 1.1509709358215332, GAN loss = [2.585216, 0.986181, 0.97831404]\n",
      "Batch 21/700: Discriminator loss = 1.16187584400177, GAN loss = [2.5858297, 0.97178686, 0.99332166]\n",
      "Batch 22/700: Discriminator loss = 1.1597530841827393, GAN loss = [2.586383, 0.9961392, 0.9695541]\n",
      "Batch 23/700: Discriminator loss = 1.136832356452942, GAN loss = [2.6328049, 0.9991207, 1.013017]\n",
      "Batch 24/700: Discriminator loss = 1.1618977785110474, GAN loss = [2.5752058, 0.98757225, 0.9669642]\n",
      "Batch 25/700: Discriminator loss = 1.1149747371673584, GAN loss = [2.5458188, 0.976945, 0.9481905]\n",
      "Batch 26/700: Discriminator loss = 1.1237703561782837, GAN loss = [2.644788, 1.0165448, 1.0075759]\n",
      "Batch 27/700: Discriminator loss = 1.0826265811920166, GAN loss = [2.6577654, 1.0091931, 1.0279229]\n",
      "Batch 28/700: Discriminator loss = 1.1147164106369019, GAN loss = [2.6103241, 0.96772575, 1.0219723]\n",
      "Batch 29/700: Discriminator loss = 1.1270536184310913, GAN loss = [2.595924, 0.99241006, 0.98291063]\n",
      "Batch 30/700: Discriminator loss = 1.1205973625183105, GAN loss = [2.6164894, 1.0139829, 0.98193413]\n",
      "Batch 31/700: Discriminator loss = 1.0777547359466553, GAN loss = [2.6443322, 1.0311121, 0.9926588]\n",
      "Batch 32/700: Discriminator loss = 1.0686384439468384, GAN loss = [2.8107717, 1.0545045, 1.1357194]\n",
      "Batch 33/700: Discriminator loss = 1.0595636367797852, GAN loss = [2.6753156, 1.0257792, 1.02902]\n",
      "Batch 34/700: Discriminator loss = 1.0882383584976196, GAN loss = [2.7894876, 1.0212387, 1.1477897]\n",
      "Batch 35/700: Discriminator loss = 1.0886350870132446, GAN loss = [2.6900458, 1.0049181, 1.0646936]\n",
      "Batch 36/700: Discriminator loss = 1.087612271308899, GAN loss = [2.700286, 0.9994152, 1.0804614]\n",
      "Batch 37/700: Discriminator loss = 1.0846518278121948, GAN loss = [2.7466507, 1.0422659, 1.0840374]\n",
      "Batch 38/700: Discriminator loss = 1.0823291540145874, GAN loss = [2.6899078, 0.9969066, 1.0726843]\n",
      "Batch 39/700: Discriminator loss = 1.0775235891342163, GAN loss = [2.693841, 1.0099484, 1.0635982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40/700: Discriminator loss = 1.0982588529586792, GAN loss = [2.613216, 0.98913574, 1.0038242]\n",
      "Batch 41/700: Discriminator loss = 1.1003373861312866, GAN loss = [2.7027612, 0.97871447, 1.1038158]\n",
      "Batch 42/700: Discriminator loss = 1.0530500411987305, GAN loss = [2.7576962, 1.0370997, 1.1004065]\n",
      "Batch 43/700: Discriminator loss = 1.0935664176940918, GAN loss = [2.6228306, 0.969356, 1.033331]\n",
      "Batch 44/700: Discriminator loss = 1.1445914506912231, GAN loss = [2.6025195, 0.946958, 1.0354662]\n",
      "Batch 45/700: Discriminator loss = 1.1171950101852417, GAN loss = [2.7589607, 0.9565071, 1.1823945]\n",
      "Batch 46/700: Discriminator loss = 1.1558458805084229, GAN loss = [2.6504955, 0.95620406, 1.0742704]\n",
      "Batch 47/700: Discriminator loss = 1.1337448358535767, GAN loss = [2.5773108, 0.9500695, 1.0072283]\n",
      "Batch 48/700: Discriminator loss = 1.066899061203003, GAN loss = [2.7642322, 0.9988049, 1.1454244]\n",
      "Batch 49/700: Discriminator loss = 1.120510220527649, GAN loss = [2.744615, 0.9532618, 1.1713803]\n",
      "Batch 50/700: Discriminator loss = 1.072115182876587, GAN loss = [2.7771647, 1.0081395, 1.1490769]\n",
      "Batch 51/700: Discriminator loss = 1.1191774606704712, GAN loss = [2.563487, 0.9448545, 0.9986984]\n",
      "Batch 52/700: Discriminator loss = 1.1088308095932007, GAN loss = [2.6544983, 0.99178433, 1.0427613]\n",
      "Batch 53/700: Discriminator loss = 1.0935173034667969, GAN loss = [2.7013817, 0.9651113, 1.1163102]\n",
      "Batch 54/700: Discriminator loss = 1.0984876155853271, GAN loss = [2.736275, 0.97452337, 1.141787]\n",
      "Batch 55/700: Discriminator loss = 1.101520299911499, GAN loss = [2.6129684, 0.99073374, 1.0022641]\n",
      "Batch 56/700: Discriminator loss = 1.1034587621688843, GAN loss = [2.6665955, 1.0033073, 1.0433193]\n",
      "Batch 57/700: Discriminator loss = 1.0872735977172852, GAN loss = [2.8493521, 1.0321447, 1.1972134]\n",
      "Batch 58/700: Discriminator loss = 1.144479751586914, GAN loss = [2.680357, 0.93503165, 1.1253163]\n",
      "Batch 59/700: Discriminator loss = 1.1005704402923584, GAN loss = [2.699206, 0.9904172, 1.0887622]\n",
      "Batch 60/700: Discriminator loss = 1.1233935356140137, GAN loss = [2.5846548, 0.97991663, 0.98468345]\n",
      "Batch 61/700: Discriminator loss = 1.1296659708023071, GAN loss = [2.6413107, 0.9398474, 1.0813723]\n",
      "Batch 62/700: Discriminator loss = 1.1148240566253662, GAN loss = [2.657498, 0.96736753, 1.0700063]\n",
      "Batch 63/700: Discriminator loss = 1.153975248336792, GAN loss = [2.6315958, 0.97937346, 1.032055]\n",
      "Batch 64/700: Discriminator loss = 1.1270841360092163, GAN loss = [2.6211777, 0.9705352, 1.0304204]\n",
      "Batch 65/700: Discriminator loss = 1.1377947330474854, GAN loss = [2.6169817, 0.95063674, 1.0460904]\n",
      "Batch 66/700: Discriminator loss = 1.1926453113555908, GAN loss = [2.5094357, 0.9241412, 0.9650168]\n",
      "Batch 67/700: Discriminator loss = 1.1641706228256226, GAN loss = [2.750761, 0.93923706, 1.1912364]\n",
      "Batch 68/700: Discriminator loss = 1.1281335353851318, GAN loss = [2.6021454, 0.947798, 1.0340514]\n",
      "Batch 69/700: Discriminator loss = 1.1664414405822754, GAN loss = [2.5708554, 0.9311152, 1.0194331]\n",
      "Batch 70/700: Discriminator loss = 1.1155390739440918, GAN loss = [2.5732908, 0.970135, 0.982833]\n",
      "Batch 71/700: Discriminator loss = 1.1353858709335327, GAN loss = [2.5783193, 0.9702491, 0.98773843]\n",
      "Batch 72/700: Discriminator loss = 1.1121890544891357, GAN loss = [2.751587, 1.000963, 1.1302758]\n",
      "Batch 73/700: Discriminator loss = 1.1437463760375977, GAN loss = [2.6269608, 0.970265, 1.0363245]\n",
      "Batch 74/700: Discriminator loss = 1.1016287803649902, GAN loss = [2.504455, 0.9698449, 0.91424173]\n",
      "Batch 75/700: Discriminator loss = 1.144242525100708, GAN loss = [2.6585555, 0.970628, 1.0675675]\n",
      "Batch 76/700: Discriminator loss = 1.1243088245391846, GAN loss = [2.596041, 0.9635449, 1.0121473]\n",
      "Batch 77/700: Discriminator loss = 1.1115589141845703, GAN loss = [2.580493, 0.9506833, 1.0094649]\n",
      "Batch 78/700: Discriminator loss = 1.1281664371490479, GAN loss = [2.6274583, 0.981656, 1.0254779]\n",
      "Batch 79/700: Discriminator loss = 1.1202421188354492, GAN loss = [2.6257741, 0.94590837, 1.0595657]\n",
      "Batch 80/700: Discriminator loss = 1.1172051429748535, GAN loss = [2.616232, 0.9674363, 1.0285172]\n",
      "Batch 81/700: Discriminator loss = 1.0797079801559448, GAN loss = [2.7165334, 1.0340955, 1.0621517]\n",
      "Batch 82/700: Discriminator loss = 1.082798719406128, GAN loss = [2.7180078, 0.9909005, 1.1068245]\n",
      "Batch 83/700: Discriminator loss = 1.1505979299545288, GAN loss = [2.4596362, 0.960789, 0.8785651]\n",
      "Batch 84/700: Discriminator loss = 1.0879356861114502, GAN loss = [2.7455266, 0.99338335, 1.1318581]\n",
      "Batch 85/700: Discriminator loss = 1.0854368209838867, GAN loss = [2.7613683, 1.0189123, 1.122162]\n",
      "Batch 86/700: Discriminator loss = 1.1234347820281982, GAN loss = [2.6042514, 0.97862214, 1.0053058]\n",
      "Batch 87/700: Discriminator loss = 1.1010726690292358, GAN loss = [2.6373928, 0.9745713, 1.0424726]\n",
      "Batch 88/700: Discriminator loss = 1.084062933921814, GAN loss = [2.7199917, 1.0241852, 1.0754635]\n",
      "Batch 89/700: Discriminator loss = 1.1622365713119507, GAN loss = [2.5503888, 0.9726231, 0.95743775]\n",
      "Batch 90/700: Discriminator loss = 1.0982754230499268, GAN loss = [2.6085892, 0.9730691, 1.0151651]\n",
      "Batch 91/700: Discriminator loss = 1.0710573196411133, GAN loss = [2.8104117, 1.0238409, 1.1662062]\n",
      "Batch 92/700: Discriminator loss = 1.0655397176742554, GAN loss = [2.8062203, 1.030168, 1.1556656]\n",
      "Batch 93/700: Discriminator loss = 1.0901631116867065, GAN loss = [2.7605767, 1.0162573, 1.1239156]\n",
      "Batch 94/700: Discriminator loss = 1.1084213256835938, GAN loss = [2.6333334, 1.0044824, 1.0084436]\n",
      "Batch 95/700: Discriminator loss = 1.081199049949646, GAN loss = [2.7981248, 1.0085088, 1.1692225]\n",
      "Batch 96/700: Discriminator loss = 1.0700243711471558, GAN loss = [2.7817745, 1.023143, 1.1382451]\n",
      "Batch 97/700: Discriminator loss = 1.0651278495788574, GAN loss = [2.7727008, 1.0302815, 1.1220361]\n",
      "Batch 98/700: Discriminator loss = 1.0929750204086304, GAN loss = [2.7322679, 0.9869848, 1.1249179]\n",
      "Batch 99/700: Discriminator loss = 1.0797417163848877, GAN loss = [2.7528527, 1.0233195, 1.109185]\n",
      "Batch 100/700: Discriminator loss = 1.0666615962982178, GAN loss = [2.7491062, 1.0137072, 1.1150799]\n",
      "Batch 101/700: Discriminator loss = 1.0638326406478882, GAN loss = [2.886672, 1.0400931, 1.2262712]\n",
      "Batch 102/700: Discriminator loss = 1.0768836736679077, GAN loss = [2.7618954, 1.0102328, 1.1313508]\n",
      "Batch 103/700: Discriminator loss = 1.0692986249923706, GAN loss = [2.7495258, 0.9908038, 1.1384355]\n",
      "Batch 104/700: Discriminator loss = 1.0855988264083862, GAN loss = [2.6846442, 1.0074251, 1.0569828]\n",
      "Batch 105/700: Discriminator loss = 1.0948116779327393, GAN loss = [2.6647058, 0.9751224, 1.0694088]\n",
      "Batch 106/700: Discriminator loss = 1.0839818716049194, GAN loss = [2.7818809, 1.0208385, 1.1409161]\n",
      "Batch 107/700: Discriminator loss = 1.0683220624923706, GAN loss = [2.784438, 1.0150467, 1.1492985]\n",
      "Batch 108/700: Discriminator loss = 1.0827997922897339, GAN loss = [2.917525, 1.0425256, 1.2549307]\n",
      "Batch 109/700: Discriminator loss = 1.047157883644104, GAN loss = [2.9601622, 1.0417, 1.2984691]\n",
      "Batch 110/700: Discriminator loss = 1.0438469648361206, GAN loss = [2.757133, 1.0263565, 1.1108266]\n",
      "Batch 111/700: Discriminator loss = 1.0793529748916626, GAN loss = [2.7284565, 1.0093457, 1.099195]\n",
      "Batch 112/700: Discriminator loss = 1.0943552255630493, GAN loss = [2.8366365, 1.0081027, 1.2086496]\n",
      "Batch 113/700: Discriminator loss = 1.0882219076156616, GAN loss = [2.805868, 1.0164824, 1.1694962]\n",
      "Batch 114/700: Discriminator loss = 1.0625975131988525, GAN loss = [2.8214178, 1.0231911, 1.1783226]\n",
      "Batch 115/700: Discriminator loss = 1.0748111009597778, GAN loss = [2.7940702, 1.0306057, 1.143583]\n",
      "Batch 116/700: Discriminator loss = 1.102012276649475, GAN loss = [2.7853956, 1.0199728, 1.1455891]\n",
      "Batch 117/700: Discriminator loss = 1.1204932928085327, GAN loss = [2.767113, 1.0102291, 1.1370859]\n",
      "Batch 118/700: Discriminator loss = 1.0730395317077637, GAN loss = [2.7662964, 1.0392054, 1.1073302]\n",
      "Batch 119/700: Discriminator loss = 1.1199264526367188, GAN loss = [2.5625837, 0.9561977, 0.98665375]\n",
      "Batch 120/700: Discriminator loss = 1.152925729751587, GAN loss = [2.629027, 0.9584084, 1.05092]\n",
      "Batch 121/700: Discriminator loss = 1.1623750925064087, GAN loss = [2.6369295, 0.977408, 1.0398569]\n",
      "Batch 122/700: Discriminator loss = 1.1014177799224854, GAN loss = [2.7216885, 1.0072527, 1.0947938]\n",
      "Batch 123/700: Discriminator loss = 1.1045172214508057, GAN loss = [2.7129164, 1.0291376, 1.064162]\n",
      "Batch 124/700: Discriminator loss = 1.1488425731658936, GAN loss = [2.616888, 0.9521869, 1.0451045]\n",
      "Batch 125/700: Discriminator loss = 1.1554780006408691, GAN loss = [2.58, 0.9717555, 0.9886693]\n",
      "Batch 126/700: Discriminator loss = 1.1264533996582031, GAN loss = [2.647184, 0.971492, 1.0561246]\n",
      "Batch 127/700: Discriminator loss = 1.126725435256958, GAN loss = [2.6667218, 0.9471536, 1.0999942]\n",
      "Batch 128/700: Discriminator loss = 1.1583199501037598, GAN loss = [2.5091054, 0.9395929, 0.9499057]\n",
      "Batch 129/700: Discriminator loss = 1.1222114562988281, GAN loss = [2.5877721, 0.9878275, 0.98032266]\n",
      "Batch 130/700: Discriminator loss = 1.11383056640625, GAN loss = [2.6558464, 1.0227269, 1.0135146]\n",
      "Batch 131/700: Discriminator loss = 1.132702112197876, GAN loss = [2.620119, 0.94927233, 1.051291]\n",
      "Batch 132/700: Discriminator loss = 1.1479047536849976, GAN loss = [2.5835724, 1.0161834, 0.9478409]\n",
      "Batch 133/700: Discriminator loss = 1.1585979461669922, GAN loss = [2.5817175, 0.9769676, 0.9851948]\n",
      "Batch 134/700: Discriminator loss = 1.15934157371521, GAN loss = [2.5805202, 0.96733606, 0.99360293]\n",
      "Batch 135/700: Discriminator loss = 1.1606190204620361, GAN loss = [2.5090277, 0.9281851, 0.96122]\n",
      "Batch 136/700: Discriminator loss = 1.1536505222320557, GAN loss = [2.6128345, 0.95721173, 1.035979]\n",
      "Batch 137/700: Discriminator loss = 1.1690086126327515, GAN loss = [2.564589, 0.92842793, 1.0165071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 138/700: Discriminator loss = 1.1817089319229126, GAN loss = [2.5355592, 0.9111352, 1.0047657]\n",
      "Batch 139/700: Discriminator loss = 1.2028135061264038, GAN loss = [2.441265, 0.9062385, 0.9153282]\n",
      "Batch 140/700: Discriminator loss = 1.1758689880371094, GAN loss = [2.564597, 0.912052, 1.0327859]\n",
      "Batch 141/700: Discriminator loss = 1.218466877937317, GAN loss = [2.5003998, 0.9166276, 0.96398497]\n",
      "Batch 142/700: Discriminator loss = 1.1636998653411865, GAN loss = [2.65929, 0.9420529, 1.0974243]\n",
      "Batch 143/700: Discriminator loss = 1.1848822832107544, GAN loss = [2.5224798, 0.9341968, 0.96843016]\n",
      "Batch 144/700: Discriminator loss = 1.1711704730987549, GAN loss = [2.491173, 0.9166954, 0.9545996]\n",
      "Batch 145/700: Discriminator loss = 1.1659419536590576, GAN loss = [2.6534774, 0.985023, 1.0485581]\n",
      "Batch 146/700: Discriminator loss = 1.147939682006836, GAN loss = [2.4592106, 0.9423891, 0.8968495]\n",
      "Batch 147/700: Discriminator loss = 1.144761562347412, GAN loss = [2.6201324, 0.949306, 1.0508195]\n",
      "Batch 148/700: Discriminator loss = 1.1644777059555054, GAN loss = [2.416896, 0.94864553, 0.8482022]\n",
      "Batch 149/700: Discriminator loss = 1.1678025722503662, GAN loss = [2.6572273, 0.97408843, 1.0630531]\n",
      "Batch 150/700: Discriminator loss = 1.144653081893921, GAN loss = [2.5818605, 0.9430608, 1.0186435]\n",
      "Batch 151/700: Discriminator loss = 1.1416882276535034, GAN loss = [2.5264313, 0.96215385, 0.944095]\n",
      "Batch 152/700: Discriminator loss = 1.137067198753357, GAN loss = [2.6667461, 0.9870015, 1.0595509]\n",
      "Batch 153/700: Discriminator loss = 1.1437408924102783, GAN loss = [2.5369034, 0.9628738, 0.9537973]\n",
      "Batch 154/700: Discriminator loss = 1.121291995048523, GAN loss = [2.7057052, 0.99879014, 1.0866342]\n",
      "Batch 155/700: Discriminator loss = 1.1094388961791992, GAN loss = [2.6728125, 1.0011096, 1.0513928]\n",
      "Batch 156/700: Discriminator loss = 1.1388227939605713, GAN loss = [2.6721551, 0.9888622, 1.0629023]\n",
      "Batch 157/700: Discriminator loss = 1.0928665399551392, GAN loss = [2.7013993, 1.0048105, 1.0761566]\n",
      "Batch 158/700: Discriminator loss = 1.1321053504943848, GAN loss = [2.6630778, 0.97034156, 1.0722992]\n",
      "Batch 159/700: Discriminator loss = 1.1025688648223877, GAN loss = [2.7329988, 0.9927126, 1.119838]\n",
      "Batch 160/700: Discriminator loss = 1.0982316732406616, GAN loss = [2.5590205, 0.98519135, 0.9533853]\n",
      "Batch 161/700: Discriminator loss = 1.1114070415496826, GAN loss = [2.645785, 0.9581361, 1.067215]\n",
      "Batch 162/700: Discriminator loss = 1.1084914207458496, GAN loss = [2.699162, 0.991743, 1.0869749]\n",
      "Batch 163/700: Discriminator loss = 1.0834691524505615, GAN loss = [2.6759503, 1.009857, 1.0456702]\n",
      "Batch 164/700: Discriminator loss = 1.085719347000122, GAN loss = [2.5859528, 1.0039326, 0.96157336]\n",
      "Batch 165/700: Discriminator loss = 1.1149874925613403, GAN loss = [2.6567805, 0.9757396, 1.0605786]\n",
      "Batch 166/700: Discriminator loss = 1.1475458145141602, GAN loss = [2.556395, 0.9446161, 0.99128103]\n",
      "Batch 167/700: Discriminator loss = 1.1219053268432617, GAN loss = [2.7517083, 1.0008235, 1.1303172]\n",
      "Batch 168/700: Discriminator loss = 1.129783272743225, GAN loss = [2.609894, 0.9575032, 1.0317829]\n",
      "Batch 169/700: Discriminator loss = 1.1125484704971313, GAN loss = [2.687511, 0.987991, 1.0788832]\n",
      "Batch 170/700: Discriminator loss = 1.0943892002105713, GAN loss = [2.6938326, 0.99351466, 1.0796385]\n",
      "Batch 171/700: Discriminator loss = 1.0921287536621094, GAN loss = [2.7196388, 1.0046263, 1.0942864]\n",
      "Batch 172/700: Discriminator loss = 1.093414068222046, GAN loss = [2.653777, 1.0031273, 1.0299072]\n",
      "Batch 173/700: Discriminator loss = 1.0866827964782715, GAN loss = [2.6436777, 0.97816294, 1.044757]\n",
      "Batch 174/700: Discriminator loss = 1.068925142288208, GAN loss = [2.7375596, 1.020433, 1.096372]\n",
      "Batch 175/700: Discriminator loss = 1.075024962425232, GAN loss = [2.7930033, 0.99772096, 1.1745415]\n",
      "Batch 176/700: Discriminator loss = 1.0848606824874878, GAN loss = [2.7315438, 1.0051777, 1.1056435]\n",
      "Batch 177/700: Discriminator loss = 1.1038405895233154, GAN loss = [2.6397111, 0.98053515, 1.0384637]\n",
      "Batch 178/700: Discriminator loss = 1.1055423021316528, GAN loss = [2.7045395, 0.98192906, 1.1019084]\n",
      "Batch 179/700: Discriminator loss = 1.1064759492874146, GAN loss = [2.647151, 0.97821635, 1.0482386]\n",
      "Batch 180/700: Discriminator loss = 1.0842149257659912, GAN loss = [2.7292178, 1.0119513, 1.0965725]\n",
      "Batch 181/700: Discriminator loss = 1.0801808834075928, GAN loss = [2.733989, 1.0136335, 1.0996543]\n",
      "Batch 182/700: Discriminator loss = 1.1006206274032593, GAN loss = [2.7046816, 0.97008765, 1.1138818]\n",
      "Batch 183/700: Discriminator loss = 1.10005784034729, GAN loss = [2.6690419, 0.9847341, 1.0635793]\n",
      "Batch 184/700: Discriminator loss = 1.0897833108901978, GAN loss = [2.6357305, 1.0246288, 0.99035674]\n",
      "Batch 185/700: Discriminator loss = 1.0860706567764282, GAN loss = [2.8402808, 1.0230855, 1.1964431]\n",
      "Batch 186/700: Discriminator loss = 1.108811616897583, GAN loss = [2.7298899, 1.0374589, 1.0716344]\n",
      "Batch 187/700: Discriminator loss = 1.0957146883010864, GAN loss = [2.6622221, 0.9841684, 1.0572382]\n",
      "Batch 188/700: Discriminator loss = 1.1298189163208008, GAN loss = [2.6278923, 0.9854507, 1.0216014]\n",
      "Batch 189/700: Discriminator loss = 1.141806721687317, GAN loss = [2.6364722, 0.9675045, 1.0481106]\n",
      "Batch 190/700: Discriminator loss = 1.1463762521743774, GAN loss = [2.5799434, 0.93871516, 1.020349]\n",
      "Batch 191/700: Discriminator loss = 1.125549077987671, GAN loss = [2.5830984, 0.97933584, 0.98288816]\n",
      "Batch 192/700: Discriminator loss = 1.1166386604309082, GAN loss = [2.7402031, 0.9681808, 1.1511577]\n",
      "Batch 193/700: Discriminator loss = 1.1300147771835327, GAN loss = [2.5655653, 0.96506137, 0.97963715]\n",
      "Batch 194/700: Discriminator loss = 1.142609715461731, GAN loss = [2.6238039, 0.9928479, 1.0101159]\n",
      "Batch 195/700: Discriminator loss = 1.1318541765213013, GAN loss = [2.5884826, 0.97021276, 0.99744964]\n",
      "Batch 196/700: Discriminator loss = 1.1204689741134644, GAN loss = [2.657023, 0.95530236, 1.0809284]\n",
      "Batch 197/700: Discriminator loss = 1.0922753810882568, GAN loss = [2.6146946, 0.95930105, 1.0346254]\n",
      "Batch 198/700: Discriminator loss = 1.1344329118728638, GAN loss = [2.5504715, 0.89866567, 1.0310593]\n",
      "Batch 199/700: Discriminator loss = 1.1145861148834229, GAN loss = [2.6335447, 0.96769273, 1.0451373]\n",
      "Batch 200/700: Discriminator loss = 1.0899953842163086, GAN loss = [2.7424405, 0.97603846, 1.1457425]\n",
      "Batch 201/700: Discriminator loss = 1.1041492223739624, GAN loss = [2.6398418, 0.9422093, 1.0770171]\n",
      "Batch 202/700: Discriminator loss = 1.1105724573135376, GAN loss = [2.6407638, 0.94253075, 1.0776554]\n",
      "Batch 203/700: Discriminator loss = 1.1237071752548218, GAN loss = [2.629091, 0.9292897, 1.0792338]\n",
      "Batch 204/700: Discriminator loss = 1.1159781217575073, GAN loss = [2.5178232, 0.9514545, 0.94579536]\n",
      "Batch 205/700: Discriminator loss = 1.1142950057983398, GAN loss = [2.5588293, 0.9239771, 1.0142791]\n",
      "Batch 206/700: Discriminator loss = 1.1150239706039429, GAN loss = [2.6137319, 0.91483927, 1.0783238]\n",
      "Batch 207/700: Discriminator loss = 1.116919755935669, GAN loss = [2.699233, 0.9234756, 1.1552025]\n",
      "Batch 208/700: Discriminator loss = 1.1208066940307617, GAN loss = [2.7247944, 0.91925704, 1.1850011]\n",
      "Batch 209/700: Discriminator loss = 1.1139709949493408, GAN loss = [2.6566374, 0.95657885, 1.0795336]\n",
      "Batch 210/700: Discriminator loss = 1.101175308227539, GAN loss = [2.736215, 0.9631393, 1.1525257]\n",
      "Batch 211/700: Discriminator loss = 1.0855419635772705, GAN loss = [2.6058514, 0.9594974, 1.0258147]\n",
      "Batch 212/700: Discriminator loss = 1.115132212638855, GAN loss = [2.5726924, 0.9441676, 1.0080099]\n",
      "Batch 213/700: Discriminator loss = 1.0960665941238403, GAN loss = [2.586806, 0.9265603, 1.0397321]\n",
      "Batch 214/700: Discriminator loss = 1.0967381000518799, GAN loss = [2.6686518, 0.9438646, 1.1042749]\n",
      "Batch 215/700: Discriminator loss = 1.1164002418518066, GAN loss = [2.566104, 0.9227458, 1.022857]\n",
      "Batch 216/700: Discriminator loss = 1.0899783372879028, GAN loss = [2.6229842, 0.94134104, 1.0611495]\n",
      "Batch 217/700: Discriminator loss = 1.1044520139694214, GAN loss = [2.665489, 0.9703982, 1.0746293]\n",
      "Batch 218/700: Discriminator loss = 1.1084316968917847, GAN loss = [2.6375113, 0.96597266, 1.0511131]\n",
      "Batch 219/700: Discriminator loss = 1.0953185558319092, GAN loss = [2.5837219, 0.94436854, 1.0189449]\n",
      "Batch 220/700: Discriminator loss = 1.092516303062439, GAN loss = [2.6506689, 0.93553907, 1.0947433]\n",
      "Batch 221/700: Discriminator loss = 1.0911189317703247, GAN loss = [2.7387164, 0.9734274, 1.1449183]\n",
      "Batch 222/700: Discriminator loss = 1.0917575359344482, GAN loss = [2.5887506, 0.9270257, 1.041358]\n",
      "Batch 223/700: Discriminator loss = 1.1010940074920654, GAN loss = [2.6647105, 0.97835803, 1.0660001]\n",
      "Batch 224/700: Discriminator loss = 1.0906991958618164, GAN loss = [2.6805267, 0.9501023, 1.1100798]\n",
      "Batch 225/700: Discriminator loss = 1.0893356800079346, GAN loss = [2.671064, 0.98433554, 1.0663724]\n",
      "Batch 226/700: Discriminator loss = 1.0946733951568604, GAN loss = [2.6128554, 0.9619781, 1.0305097]\n",
      "Batch 227/700: Discriminator loss = 1.1110750436782837, GAN loss = [2.576214, 0.95798576, 0.9978592]\n",
      "Batch 228/700: Discriminator loss = 1.1199079751968384, GAN loss = [2.6070518, 0.91957384, 1.0671335]\n",
      "Batch 229/700: Discriminator loss = 1.1081407070159912, GAN loss = [2.6055136, 0.9682239, 1.0169731]\n",
      "Batch 230/700: Discriminator loss = 1.113638162612915, GAN loss = [2.5747724, 0.93167925, 1.0227889]\n",
      "Batch 231/700: Discriminator loss = 1.1197710037231445, GAN loss = [2.588771, 0.9126521, 1.0558456]\n",
      "Batch 232/700: Discriminator loss = 1.1307094097137451, GAN loss = [2.5820467, 0.9199922, 1.0417876]\n",
      "Batch 233/700: Discriminator loss = 1.1112688779830933, GAN loss = [2.6639187, 0.9412738, 1.1023936]\n",
      "Batch 234/700: Discriminator loss = 1.1267027854919434, GAN loss = [2.5738254, 0.9374205, 1.0161757]\n",
      "Batch 235/700: Discriminator loss = 1.1253803968429565, GAN loss = [2.6567643, 0.9633903, 1.0731528]\n",
      "Batch 236/700: Discriminator loss = 1.1096595525741577, GAN loss = [2.7001565, 0.99941367, 1.0805284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 237/700: Discriminator loss = 1.0921216011047363, GAN loss = [2.6913881, 0.97452426, 1.0966299]\n",
      "Batch 238/700: Discriminator loss = 1.112987995147705, GAN loss = [2.6931083, 0.9755458, 1.0973095]\n",
      "Batch 239/700: Discriminator loss = 1.0990557670593262, GAN loss = [2.6418386, 0.9736589, 1.0479149]\n",
      "Batch 240/700: Discriminator loss = 1.0980504751205444, GAN loss = [2.5961783, 0.96371436, 1.0121734]\n",
      "Batch 241/700: Discriminator loss = 1.0780571699142456, GAN loss = [2.6487246, 0.9686512, 1.0597625]\n",
      "Batch 242/700: Discriminator loss = 1.0938773155212402, GAN loss = [2.7055528, 0.9979132, 1.087348]\n",
      "Batch 243/700: Discriminator loss = 1.083457112312317, GAN loss = [2.8216107, 1.030977, 1.1703285]\n",
      "Batch 244/700: Discriminator loss = 1.123982548713684, GAN loss = [2.5953996, 0.9921816, 0.9828687]\n",
      "Batch 245/700: Discriminator loss = 1.1308369636535645, GAN loss = [2.6440334, 0.9773537, 1.0462842]\n",
      "Batch 246/700: Discriminator loss = 1.0789977312088013, GAN loss = [2.6315193, 1.0151052, 0.9959799]\n",
      "Batch 247/700: Discriminator loss = 1.1231988668441772, GAN loss = [2.5260901, 0.9439812, 0.9616628]\n",
      "Batch 248/700: Discriminator loss = 1.1438077688217163, GAN loss = [2.5008695, 0.93614125, 0.9442705]\n",
      "Batch 249/700: Discriminator loss = 1.1234182119369507, GAN loss = [2.6419, 0.96298516, 1.0584258]\n",
      "Batch 250/700: Discriminator loss = 1.116324543952942, GAN loss = [2.5445087, 0.9363071, 0.9876522]\n",
      "Batch 251/700: Discriminator loss = 1.1181561946868896, GAN loss = [2.6172388, 0.96834075, 1.0283091]\n",
      "Batch 252/700: Discriminator loss = 1.0695980787277222, GAN loss = [2.7076073, 1.0009555, 1.0860248]\n",
      "Batch 253/700: Discriminator loss = 1.1271456480026245, GAN loss = [2.504486, 0.9185693, 0.9652288]\n",
      "Batch 254/700: Discriminator loss = 1.1172974109649658, GAN loss = [2.6144319, 0.95766366, 1.0360249]\n",
      "Batch 255/700: Discriminator loss = 1.155596375465393, GAN loss = [2.603505, 0.94851303, 1.0341938]\n",
      "Batch 256/700: Discriminator loss = 1.1094112396240234, GAN loss = [2.7224753, 0.9982935, 1.1033705]\n",
      "Batch 257/700: Discriminator loss = 1.106044054031372, GAN loss = [2.7012255, 1.0005442, 1.0798355]\n",
      "Batch 258/700: Discriminator loss = 1.1067750453948975, GAN loss = [2.7096643, 0.9795451, 1.1092316]\n",
      "Batch 259/700: Discriminator loss = 1.110291600227356, GAN loss = [2.6561162, 0.98732513, 1.0478553]\n",
      "Batch 260/700: Discriminator loss = 1.0672776699066162, GAN loss = [2.7930405, 1.0394883, 1.1325821]\n",
      "Batch 261/700: Discriminator loss = 1.1187869310379028, GAN loss = [2.6290405, 0.9828372, 1.0251822]\n",
      "Batch 262/700: Discriminator loss = 1.0941463708877563, GAN loss = [2.66546, 0.9899899, 1.0544057]\n",
      "Batch 263/700: Discriminator loss = 1.0906047821044922, GAN loss = [2.6777973, 0.9952466, 1.061454]\n",
      "Batch 264/700: Discriminator loss = 1.1048800945281982, GAN loss = [2.6613748, 0.9689285, 1.0712987]\n",
      "Batch 265/700: Discriminator loss = 1.113169550895691, GAN loss = [2.6100981, 0.99586654, 0.9930798]\n",
      "Batch 266/700: Discriminator loss = 1.0716990232467651, GAN loss = [2.8888698, 1.0195009, 1.2481694]\n",
      "Batch 267/700: Discriminator loss = 1.061043381690979, GAN loss = [2.7512984, 1.0231305, 1.1069057]\n",
      "Batch 268/700: Discriminator loss = 1.087522268295288, GAN loss = [2.6838732, 1.0195549, 1.0430429]\n",
      "Batch 269/700: Discriminator loss = 1.0915498733520508, GAN loss = [2.7369585, 1.0215183, 1.0941449]\n",
      "Batch 270/700: Discriminator loss = 1.1047335863113403, GAN loss = [2.8054788, 1.0325938, 1.1514966]\n",
      "Batch 271/700: Discriminator loss = 1.0728205442428589, GAN loss = [2.669423, 1.0055488, 1.0424365]\n",
      "Batch 272/700: Discriminator loss = 1.0975096225738525, GAN loss = [2.5926356, 0.97357917, 0.99762857]\n",
      "Batch 273/700: Discriminator loss = 1.0892870426177979, GAN loss = [2.6325538, 0.9852533, 1.0258842]\n",
      "Batch 274/700: Discriminator loss = 1.0988924503326416, GAN loss = [2.760318, 1.0407724, 1.0981339]\n",
      "Batch 275/700: Discriminator loss = 1.1026294231414795, GAN loss = [2.8248618, 1.0268602, 1.1765478]\n",
      "Batch 276/700: Discriminator loss = 1.096708059310913, GAN loss = [2.698776, 0.9848019, 1.0924687]\n",
      "Batch 277/700: Discriminator loss = 1.1008968353271484, GAN loss = [2.6910865, 0.96922517, 1.1003076]\n",
      "Batch 278/700: Discriminator loss = 1.1114531755447388, GAN loss = [2.6521804, 0.9809449, 1.0496846]\n",
      "Batch 279/700: Discriminator loss = 1.1411088705062866, GAN loss = [2.656598, 0.9939235, 1.0411052]\n",
      "Batch 280/700: Discriminator loss = 1.102846622467041, GAN loss = [2.6099627, 1.0080107, 0.9802961]\n",
      "Batch 281/700: Discriminator loss = 1.0852265357971191, GAN loss = [2.7125552, 1.0109608, 1.0798837]\n",
      "Batch 282/700: Discriminator loss = 1.0998589992523193, GAN loss = [2.7612646, 1.0265023, 1.1129881]\n",
      "Batch 283/700: Discriminator loss = 1.0980509519577026, GAN loss = [2.6444073, 0.9732296, 1.0493166]\n",
      "Batch 284/700: Discriminator loss = 1.0894253253936768, GAN loss = [2.7149475, 0.99640757, 1.0966294]\n",
      "Batch 285/700: Discriminator loss = 1.0946232080459595, GAN loss = [2.6763623, 0.99351585, 1.0608994]\n",
      "Batch 286/700: Discriminator loss = 1.093252182006836, GAN loss = [2.736335, 0.99623674, 1.1181386]\n",
      "Batch 287/700: Discriminator loss = 1.107258915901184, GAN loss = [2.642536, 0.9852573, 1.035321]\n",
      "Batch 288/700: Discriminator loss = 1.0954073667526245, GAN loss = [2.723445, 0.9916501, 1.1097845]\n",
      "Batch 289/700: Discriminator loss = 1.0805448293685913, GAN loss = [2.738649, 1.030666, 1.085916]\n",
      "Batch 290/700: Discriminator loss = 1.0671199560165405, GAN loss = [2.8338583, 1.0444313, 1.1673372]\n",
      "Batch 291/700: Discriminator loss = 1.0741384029388428, GAN loss = [2.722501, 0.9976509, 1.1027824]\n",
      "Batch 292/700: Discriminator loss = 1.0704782009124756, GAN loss = [2.762085, 1.0016204, 1.1384003]\n",
      "Batch 293/700: Discriminator loss = 1.0878746509552002, GAN loss = [2.6979487, 1.0162832, 1.0595894]\n",
      "Batch 294/700: Discriminator loss = 1.0970531702041626, GAN loss = [2.6539748, 0.976663, 1.0552613]\n",
      "Batch 295/700: Discriminator loss = 1.088944911956787, GAN loss = [2.6101973, 0.97142184, 1.0167232]\n",
      "Batch 296/700: Discriminator loss = 1.1011228561401367, GAN loss = [2.6378171, 0.97582513, 1.0399237]\n",
      "Batch 297/700: Discriminator loss = 1.080033302307129, GAN loss = [2.7295418, 0.9894805, 1.117981]\n",
      "Batch 298/700: Discriminator loss = 1.1055325269699097, GAN loss = [2.7241714, 1.0315834, 1.070496]\n",
      "Batch 299/700: Discriminator loss = 1.0545430183410645, GAN loss = [2.716266, 1.0359782, 1.0582068]\n",
      "Batch 300/700: Discriminator loss = 1.042541265487671, GAN loss = [2.8728569, 1.0600471, 1.1907169]\n",
      "Batch 301/700: Discriminator loss = 1.0831950902938843, GAN loss = [2.7931676, 1.002407, 1.1686268]\n",
      "Batch 302/700: Discriminator loss = 1.077660083770752, GAN loss = [2.7613654, 1.0394658, 1.0997158]\n",
      "Batch 303/700: Discriminator loss = 1.075623869895935, GAN loss = [2.8101876, 1.0553536, 1.1326303]\n",
      "Batch 304/700: Discriminator loss = 1.0763955116271973, GAN loss = [2.7487528, 1.0299554, 1.0965776]\n",
      "Batch 305/700: Discriminator loss = 1.049976110458374, GAN loss = [2.8511972, 1.0512507, 1.177668]\n",
      "Batch 306/700: Discriminator loss = 1.052903652191162, GAN loss = [2.7790911, 1.0458614, 1.1109161]\n",
      "Batch 307/700: Discriminator loss = 1.0693296194076538, GAN loss = [2.7407, 1.042283, 1.0761155]\n",
      "Batch 308/700: Discriminator loss = 1.0505884885787964, GAN loss = [2.9123542, 1.0737721, 1.2162694]\n",
      "Batch 309/700: Discriminator loss = 1.0706521272659302, GAN loss = [2.8569846, 1.0633954, 1.1712277]\n",
      "Batch 310/700: Discriminator loss = 1.050373911857605, GAN loss = [2.860199, 1.0845059, 1.1532863]\n",
      "Batch 311/700: Discriminator loss = 1.063086986541748, GAN loss = [2.7854438, 1.0438162, 1.1192186]\n",
      "Batch 312/700: Discriminator loss = 1.0596734285354614, GAN loss = [2.7765765, 1.0471498, 1.1069988]\n",
      "Batch 313/700: Discriminator loss = 1.0802185535430908, GAN loss = [2.7816358, 1.0226426, 1.136574]\n",
      "Batch 314/700: Discriminator loss = 1.0176302194595337, GAN loss = [2.981984, 1.1097093, 1.2498364]\n",
      "Batch 315/700: Discriminator loss = 1.064417839050293, GAN loss = [2.6913939, 1.0437692, 1.025143]\n",
      "Batch 316/700: Discriminator loss = 1.072100281715393, GAN loss = [2.8258216, 1.0386112, 1.1647286]\n",
      "Batch 317/700: Discriminator loss = 1.0242462158203125, GAN loss = [2.91855, 1.1185669, 1.1774684]\n",
      "Batch 318/700: Discriminator loss = 1.0511233806610107, GAN loss = [2.759808, 1.0578413, 1.0794346]\n",
      "Batch 319/700: Discriminator loss = 1.0321558713912964, GAN loss = [2.9179251, 1.0774546, 1.217946]\n",
      "Batch 320/700: Discriminator loss = 1.0483133792877197, GAN loss = [2.8349566, 1.0670025, 1.1454184]\n",
      "Batch 321/700: Discriminator loss = 1.053597331047058, GAN loss = [2.854261, 1.0671802, 1.1645411]\n",
      "Batch 322/700: Discriminator loss = 1.018572211265564, GAN loss = [2.9809022, 1.1105795, 1.2477912]\n",
      "Batch 323/700: Discriminator loss = 1.0638364553451538, GAN loss = [2.8640628, 1.0684667, 1.1730788]\n",
      "Batch 324/700: Discriminator loss = 1.0060776472091675, GAN loss = [2.9473693, 1.1104048, 1.2144128]\n",
      "Batch 325/700: Discriminator loss = 1.041620135307312, GAN loss = [2.844194, 1.1567988, 1.064783]\n",
      "Batch 326/700: Discriminator loss = 1.0336247682571411, GAN loss = [2.8617556, 1.1096772, 1.129432]\n",
      "Batch 327/700: Discriminator loss = 1.0715941190719604, GAN loss = [2.7994995, 1.037724, 1.139119]\n",
      "Batch 328/700: Discriminator loss = 1.0485345125198364, GAN loss = [2.7954755, 1.0940529, 1.0787611]\n",
      "Batch 329/700: Discriminator loss = 1.0424010753631592, GAN loss = [2.9590685, 1.1255782, 1.2108613]\n",
      "Batch 330/700: Discriminator loss = 1.0395700931549072, GAN loss = [2.8353565, 1.0759866, 1.1367466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 331/700: Discriminator loss = 1.0578800439834595, GAN loss = [2.7535102, 1.0647811, 1.0660933]\n",
      "Batch 332/700: Discriminator loss = 1.0471910238265991, GAN loss = [2.8384907, 1.0735334, 1.1423157]\n",
      "Batch 333/700: Discriminator loss = 1.087122917175293, GAN loss = [2.6860287, 1.0224361, 1.0409545]\n",
      "Batch 334/700: Discriminator loss = 1.072474479675293, GAN loss = [2.9626822, 1.0677665, 1.2722809]\n",
      "Batch 335/700: Discriminator loss = 1.056099534034729, GAN loss = [2.8587875, 1.0581878, 1.1779797]\n",
      "Batch 336/700: Discriminator loss = 1.080712080001831, GAN loss = [3.0257037, 1.093306, 1.3097442]\n",
      "Batch 337/700: Discriminator loss = 1.0503767728805542, GAN loss = [2.852411, 1.1024498, 1.127248]\n",
      "Batch 338/700: Discriminator loss = 1.0839027166366577, GAN loss = [2.8382463, 1.0233111, 1.1921772]\n",
      "Batch 339/700: Discriminator loss = 1.087592363357544, GAN loss = [2.9838345, 1.0794704, 1.2815608]\n",
      "Batch 340/700: Discriminator loss = 1.020649790763855, GAN loss = [3.0156536, 1.1316555, 1.2612096]\n",
      "Batch 341/700: Discriminator loss = 1.1060681343078613, GAN loss = [2.7269664, 1.0373847, 1.0667868]\n",
      "Batch 342/700: Discriminator loss = 1.0981700420379639, GAN loss = [2.8031645, 1.0268768, 1.1534829]\n",
      "Batch 343/700: Discriminator loss = 1.1036723852157593, GAN loss = [2.8435688, 1.0263997, 1.1943383]\n",
      "Batch 344/700: Discriminator loss = 1.0918734073638916, GAN loss = [2.7549589, 1.0183448, 1.113782]\n",
      "Batch 345/700: Discriminator loss = 1.1155648231506348, GAN loss = [2.7973578, 0.9938455, 1.1806885]\n",
      "Batch 346/700: Discriminator loss = 1.1174663305282593, GAN loss = [2.8428524, 0.9528406, 1.267203]\n",
      "Batch 347/700: Discriminator loss = 1.1051682233810425, GAN loss = [2.811621, 1.025718, 1.1631334]\n",
      "Batch 348/700: Discriminator loss = 1.0958501100540161, GAN loss = [2.8166692, 1.0331771, 1.1607611]\n",
      "Batch 349/700: Discriminator loss = 1.1297935247421265, GAN loss = [2.6103024, 0.9741883, 1.0134009]\n",
      "Batch 350/700: Discriminator loss = 1.1329874992370605, GAN loss = [2.6013877, 0.9659881, 1.0126845]\n",
      "Batch 351/700: Discriminator loss = 1.111732840538025, GAN loss = [2.7818384, 0.9791516, 1.1799769]\n",
      "Batch 352/700: Discriminator loss = 1.1377418041229248, GAN loss = [2.774157, 0.96233565, 1.1891166]\n",
      "Batch 353/700: Discriminator loss = 1.117998480796814, GAN loss = [2.7287176, 0.95464385, 1.1513472]\n",
      "Batch 354/700: Discriminator loss = 1.1066792011260986, GAN loss = [2.7702525, 1.0170815, 1.130432]\n",
      "Batch 355/700: Discriminator loss = 1.0815978050231934, GAN loss = [3.0424352, 1.0074475, 1.412238]\n",
      "Batch 356/700: Discriminator loss = 1.0875264406204224, GAN loss = [2.6431863, 1.0133668, 1.0070835]\n",
      "Batch 357/700: Discriminator loss = 1.0738860368728638, GAN loss = [2.8271222, 1.0156964, 1.1886865]\n",
      "Batch 358/700: Discriminator loss = 1.0926729440689087, GAN loss = [2.850393, 1.0062691, 1.2213877]\n",
      "Batch 359/700: Discriminator loss = 1.0929558277130127, GAN loss = [2.848009, 1.0215211, 1.2037463]\n",
      "Batch 360/700: Discriminator loss = 1.096181869506836, GAN loss = [2.8410594, 0.96445817, 1.2538352]\n",
      "Batch 361/700: Discriminator loss = 1.0761196613311768, GAN loss = [2.9327037, 0.99381983, 1.3160971]\n",
      "Batch 362/700: Discriminator loss = 1.0972908735275269, GAN loss = [2.8089013, 0.99905074, 1.1870612]\n",
      "Batch 363/700: Discriminator loss = 1.1091605424880981, GAN loss = [2.737983, 0.98282874, 1.1323581]\n",
      "Batch 364/700: Discriminator loss = 1.1277976036071777, GAN loss = [2.7069752, 0.95279795, 1.1313604]\n",
      "Batch 365/700: Discriminator loss = 1.1079612970352173, GAN loss = [2.9156303, 0.98929524, 1.3034893]\n",
      "Batch 366/700: Discriminator loss = 1.1226606369018555, GAN loss = [2.7522564, 0.96741843, 1.1619538]\n",
      "Batch 367/700: Discriminator loss = 1.1154654026031494, GAN loss = [2.8007889, 0.96852803, 1.2093494]\n",
      "Batch 368/700: Discriminator loss = 1.119296908378601, GAN loss = [2.8025568, 0.98957944, 1.1900173]\n",
      "Batch 369/700: Discriminator loss = 1.1146472692489624, GAN loss = [2.8503773, 0.98004746, 1.247335]\n",
      "Batch 370/700: Discriminator loss = 1.1159573793411255, GAN loss = [2.7049067, 0.99637383, 1.0855417]\n",
      "Batch 371/700: Discriminator loss = 1.088716745376587, GAN loss = [2.888723, 1.0535135, 1.2121998]\n",
      "Batch 372/700: Discriminator loss = 1.111081838607788, GAN loss = [2.8617697, 1.0479051, 1.1908528]\n",
      "Batch 373/700: Discriminator loss = 1.0931061506271362, GAN loss = [2.6743643, 1.0112145, 1.0401253]\n",
      "Batch 374/700: Discriminator loss = 1.1084671020507812, GAN loss = [2.796501, 1.0034066, 1.1700594]\n",
      "Batch 375/700: Discriminator loss = 1.112465262413025, GAN loss = [2.744717, 1.0250224, 1.0966415]\n",
      "Batch 376/700: Discriminator loss = 1.0972615480422974, GAN loss = [2.8035088, 1.0136245, 1.166805]\n",
      "Batch 377/700: Discriminator loss = 1.0760343074798584, GAN loss = [2.9607568, 1.0814513, 1.2562013]\n",
      "Batch 378/700: Discriminator loss = 1.10491144657135, GAN loss = [2.845203, 1.0149437, 1.207118]\n",
      "Batch 379/700: Discriminator loss = 1.1084017753601074, GAN loss = [2.8522203, 1.0490388, 1.1800323]\n",
      "Batch 380/700: Discriminator loss = 1.1009905338287354, GAN loss = [2.810954, 1.0277085, 1.1600887]\n",
      "Batch 381/700: Discriminator loss = 1.0933910608291626, GAN loss = [2.8976693, 1.0387744, 1.2357267]\n",
      "Batch 382/700: Discriminator loss = 1.079372763633728, GAN loss = [2.8478258, 1.0265582, 1.1980609]\n",
      "Batch 383/700: Discriminator loss = 1.090772032737732, GAN loss = [2.8795078, 1.0628619, 1.1934009]\n",
      "Batch 384/700: Discriminator loss = 1.1401437520980835, GAN loss = [2.660489, 0.9770296, 1.0601773]\n",
      "Batch 385/700: Discriminator loss = 1.1119084358215332, GAN loss = [2.788026, 0.9964319, 1.1682847]\n",
      "Batch 386/700: Discriminator loss = 1.0985571146011353, GAN loss = [2.8716993, 1.0243608, 1.2240047]\n",
      "Batch 387/700: Discriminator loss = 1.1147575378417969, GAN loss = [2.8060713, 1.054741, 1.1279633]\n",
      "Batch 388/700: Discriminator loss = 1.1171005964279175, GAN loss = [2.685652, 0.9974514, 1.0648246]\n",
      "Batch 389/700: Discriminator loss = 1.1062794923782349, GAN loss = [2.7282534, 1.007225, 1.0976739]\n",
      "Batch 390/700: Discriminator loss = 1.110690951347351, GAN loss = [2.7547035, 0.9771755, 1.1541826]\n",
      "Batch 391/700: Discriminator loss = 1.0917154550552368, GAN loss = [2.8851001, 1.0325664, 1.2292018]\n",
      "Batch 392/700: Discriminator loss = 1.0699424743652344, GAN loss = [2.8998618, 1.0290178, 1.247477]\n",
      "Batch 393/700: Discriminator loss = 1.099357008934021, GAN loss = [2.7568834, 1.0035834, 1.1299073]\n",
      "Batch 394/700: Discriminator loss = 1.1155425310134888, GAN loss = [2.7023818, 1.0145828, 1.0643883]\n",
      "Batch 395/700: Discriminator loss = 1.0912774801254272, GAN loss = [2.8707645, 1.0413308, 1.2059906]\n",
      "Batch 396/700: Discriminator loss = 1.1236392259597778, GAN loss = [2.7006917, 0.9788286, 1.0983756]\n",
      "Batch 397/700: Discriminator loss = 1.1072713136672974, GAN loss = [2.7864797, 0.9958802, 1.1670713]\n",
      "Batch 398/700: Discriminator loss = 1.1276781558990479, GAN loss = [2.735141, 0.9767225, 1.1348412]\n",
      "Batch 399/700: Discriminator loss = 1.1149121522903442, GAN loss = [2.6798666, 1.0041567, 1.0521032]\n",
      "Batch 400/700: Discriminator loss = 1.0878300666809082, GAN loss = [2.8616657, 1.0372326, 1.2008145]\n",
      "Batch 401/700: Discriminator loss = 1.1206953525543213, GAN loss = [2.7477624, 0.9832553, 1.1408764]\n",
      "Batch 402/700: Discriminator loss = 1.1447551250457764, GAN loss = [2.594146, 0.94231606, 1.0282308]\n",
      "Batch 403/700: Discriminator loss = 1.1104099750518799, GAN loss = [2.7504292, 0.9897598, 1.1370744]\n",
      "Batch 404/700: Discriminator loss = 1.114429235458374, GAN loss = [2.8028822, 0.9946185, 1.1846707]\n",
      "Batch 405/700: Discriminator loss = 1.1185883283615112, GAN loss = [2.7383995, 0.9841744, 1.1306038]\n",
      "Batch 406/700: Discriminator loss = 1.1513341665267944, GAN loss = [2.788452, 0.9955234, 1.1692894]\n",
      "Batch 407/700: Discriminator loss = 1.070162057876587, GAN loss = [2.8859327, 1.0834395, 1.1788714]\n",
      "Batch 408/700: Discriminator loss = 1.0727334022521973, GAN loss = [2.7473962, 1.0342392, 1.0895268]\n",
      "Batch 409/700: Discriminator loss = 1.1164350509643555, GAN loss = [2.8607132, 0.99931806, 1.2377846]\n",
      "Batch 410/700: Discriminator loss = 1.086126446723938, GAN loss = [2.932836, 1.0573806, 1.2519045]\n",
      "Batch 411/700: Discriminator loss = 1.0665889978408813, GAN loss = [2.9116278, 1.0918198, 1.1963028]\n",
      "Batch 412/700: Discriminator loss = 1.0949596166610718, GAN loss = [2.9702253, 1.0419526, 1.3047519]\n",
      "Batch 413/700: Discriminator loss = 1.1091431379318237, GAN loss = [2.7907114, 1.0677108, 1.0994667]\n",
      "Batch 414/700: Discriminator loss = 1.0743728876113892, GAN loss = [2.93701, 1.0407043, 1.2728143]\n",
      "Batch 415/700: Discriminator loss = 1.0957432985305786, GAN loss = [2.9530766, 1.0744865, 1.2551216]\n",
      "Batch 416/700: Discriminator loss = 1.107057809829712, GAN loss = [2.7640872, 1.0042933, 1.1363295]\n",
      "Batch 417/700: Discriminator loss = 1.1333845853805542, GAN loss = [2.7218688, 0.9893801, 1.1090076]\n",
      "Batch 418/700: Discriminator loss = 1.1263819932937622, GAN loss = [2.6576018, 0.97359926, 1.0604845]\n",
      "Batch 419/700: Discriminator loss = 1.1225252151489258, GAN loss = [2.7784212, 1.0051928, 1.1496879]\n",
      "Batch 420/700: Discriminator loss = 1.1009373664855957, GAN loss = [2.8672667, 1.0227747, 1.220967]\n",
      "Batch 421/700: Discriminator loss = 1.102524995803833, GAN loss = [2.7748256, 1.0077492, 1.1435562]\n",
      "Batch 422/700: Discriminator loss = 1.108388900756836, GAN loss = [2.7962632, 1.0202767, 1.1524485]\n",
      "Batch 423/700: Discriminator loss = 1.1244540214538574, GAN loss = [2.8178928, 1.0154223, 1.1789529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 424/700: Discriminator loss = 1.1265681982040405, GAN loss = [2.67806, 0.98352724, 1.0710428]\n",
      "Batch 425/700: Discriminator loss = 1.0909067392349243, GAN loss = [2.8113394, 0.99337506, 1.1944923]\n",
      "Batch 426/700: Discriminator loss = 1.1368706226348877, GAN loss = [2.7254713, 0.940454, 1.161571]\n",
      "Batch 427/700: Discriminator loss = 1.1127163171768188, GAN loss = [2.7908075, 1.000056, 1.1673219]\n",
      "Batch 428/700: Discriminator loss = 1.1230589151382446, GAN loss = [2.7326217, 0.9924549, 1.1167797]\n",
      "Batch 429/700: Discriminator loss = 1.125461459159851, GAN loss = [2.7737272, 0.98981255, 1.1605852]\n",
      "Batch 430/700: Discriminator loss = 1.105159044265747, GAN loss = [2.8086605, 1.0182879, 1.1670779]\n",
      "Batch 431/700: Discriminator loss = 1.1148784160614014, GAN loss = [2.7534473, 0.9879621, 1.1422352]\n",
      "Batch 432/700: Discriminator loss = 1.0923503637313843, GAN loss = [2.7408679, 1.0406756, 1.0769714]\n",
      "Batch 433/700: Discriminator loss = 1.1176775693893433, GAN loss = [2.7783406, 1.005446, 1.1497134]\n",
      "Batch 434/700: Discriminator loss = 1.1384201049804688, GAN loss = [2.622929, 0.98832506, 1.0114707]\n",
      "Batch 435/700: Discriminator loss = 1.0957084894180298, GAN loss = [2.7441058, 0.9983746, 1.122639]\n",
      "Batch 436/700: Discriminator loss = 1.1664440631866455, GAN loss = [2.737526, 1.0012108, 1.1132761]\n",
      "Batch 437/700: Discriminator loss = 1.1469556093215942, GAN loss = [2.6687949, 1.0111761, 1.0346098]\n",
      "Batch 438/700: Discriminator loss = 1.1463209390640259, GAN loss = [2.7512176, 1.0081618, 1.1200802]\n",
      "Batch 439/700: Discriminator loss = 1.1332980394363403, GAN loss = [2.7177477, 1.0259274, 1.0688808]\n",
      "Batch 440/700: Discriminator loss = 1.1469330787658691, GAN loss = [2.696206, 1.0127244, 1.0605671]\n",
      "Batch 441/700: Discriminator loss = 1.109665036201477, GAN loss = [2.6662538, 1.0081962, 1.035179]\n",
      "Batch 442/700: Discriminator loss = 1.1489801406860352, GAN loss = [2.6742814, 1.0138097, 1.0376389]\n",
      "Batch 443/700: Discriminator loss = 1.1331628561019897, GAN loss = [2.6790218, 1.0184561, 1.037767]\n",
      "Batch 444/700: Discriminator loss = 1.0993106365203857, GAN loss = [2.6884494, 1.0568073, 1.0088747]\n",
      "Batch 445/700: Discriminator loss = 1.0961087942123413, GAN loss = [2.7292268, 1.0314943, 1.0749953]\n",
      "Batch 446/700: Discriminator loss = 1.126624584197998, GAN loss = [2.7724864, 1.0528227, 1.096966]\n",
      "Batch 447/700: Discriminator loss = 1.1161590814590454, GAN loss = [2.6770067, 1.0470874, 1.0072465]\n",
      "Batch 448/700: Discriminator loss = 1.078510046005249, GAN loss = [2.7111685, 1.0582832, 1.0302526]\n",
      "Batch 449/700: Discriminator loss = 1.0675348043441772, GAN loss = [2.8188272, 1.0655255, 1.1307229]\n",
      "Batch 450/700: Discriminator loss = 1.0905256271362305, GAN loss = [2.8045418, 1.0977035, 1.0843191]\n",
      "Batch 451/700: Discriminator loss = 1.1119526624679565, GAN loss = [2.6967425, 1.0273062, 1.046964]\n",
      "Batch 452/700: Discriminator loss = 1.099133014678955, GAN loss = [2.8255215, 1.0651661, 1.1379148]\n",
      "Batch 453/700: Discriminator loss = 1.063747525215149, GAN loss = [2.7925034, 1.0855767, 1.0845199]\n",
      "Batch 454/700: Discriminator loss = 1.106304407119751, GAN loss = [2.8446429, 1.0491997, 1.1730834]\n",
      "Batch 455/700: Discriminator loss = 1.1187704801559448, GAN loss = [2.751338, 1.0361701, 1.0928392]\n",
      "Batch 456/700: Discriminator loss = 1.089429497718811, GAN loss = [2.7053106, 1.023926, 1.0590456]\n",
      "Batch 457/700: Discriminator loss = 1.1026997566223145, GAN loss = [2.644667, 1.0277143, 0.99463236]\n",
      "Batch 458/700: Discriminator loss = 1.0644986629486084, GAN loss = [2.795557, 1.0653191, 1.107949]\n",
      "Batch 459/700: Discriminator loss = 1.0869594812393188, GAN loss = [2.7042785, 1.0319409, 1.0500995]\n",
      "Batch 460/700: Discriminator loss = 1.091210126876831, GAN loss = [2.742659, 1.0161481, 1.1043305]\n",
      "Batch 461/700: Discriminator loss = 1.1015774011611938, GAN loss = [2.6446261, 0.9945021, 1.0279915]\n",
      "Batch 462/700: Discriminator loss = 1.117390751838684, GAN loss = [2.6714473, 0.9782195, 1.0711122]\n",
      "Batch 463/700: Discriminator loss = 1.087167501449585, GAN loss = [2.7576835, 1.000781, 1.1347854]\n",
      "Batch 464/700: Discriminator loss = 1.0591990947723389, GAN loss = [2.8090715, 1.0638039, 1.1231792]\n",
      "Batch 465/700: Discriminator loss = 1.096032977104187, GAN loss = [2.7369087, 1.0084562, 1.1063782]\n",
      "Batch 466/700: Discriminator loss = 1.0903745889663696, GAN loss = [2.720241, 1.0131589, 1.0850242]\n",
      "Batch 467/700: Discriminator loss = 1.0645158290863037, GAN loss = [2.7905717, 1.04141, 1.1271383]\n",
      "Batch 468/700: Discriminator loss = 1.1199896335601807, GAN loss = [2.7402856, 1.0034508, 1.1148189]\n",
      "Batch 469/700: Discriminator loss = 1.0873429775238037, GAN loss = [2.762523, 1.0344439, 1.1060658]\n",
      "Batch 470/700: Discriminator loss = 1.074114203453064, GAN loss = [2.9619415, 1.0983248, 1.2416023]\n",
      "Batch 471/700: Discriminator loss = 1.0753017663955688, GAN loss = [2.8028786, 1.0417558, 1.1391001]\n",
      "Batch 472/700: Discriminator loss = 1.0664016008377075, GAN loss = [2.8381648, 1.0754654, 1.1406649]\n",
      "Batch 473/700: Discriminator loss = 1.0663810968399048, GAN loss = [2.8154132, 1.0735083, 1.1198611]\n",
      "Batch 474/700: Discriminator loss = 1.062840461730957, GAN loss = [2.848732, 1.1192188, 1.1074545]\n",
      "Batch 475/700: Discriminator loss = 1.0971784591674805, GAN loss = [2.7816072, 1.0132505, 1.1462791]\n",
      "Batch 476/700: Discriminator loss = 1.1033881902694702, GAN loss = [2.743927, 0.9909195, 1.1309227]\n",
      "Batch 477/700: Discriminator loss = 1.0862265825271606, GAN loss = [2.7586002, 1.0026189, 1.1339108]\n",
      "Batch 478/700: Discriminator loss = 1.0836470127105713, GAN loss = [2.8029962, 1.0726124, 1.1083322]\n",
      "Batch 479/700: Discriminator loss = 1.0782825946807861, GAN loss = [2.7901812, 1.0446831, 1.1234748]\n",
      "Batch 480/700: Discriminator loss = 1.1010699272155762, GAN loss = [2.8074558, 1.02787, 1.1575608]\n",
      "Batch 481/700: Discriminator loss = 1.0892443656921387, GAN loss = [2.7660775, 1.0248524, 1.1191614]\n",
      "Batch 482/700: Discriminator loss = 1.1086088418960571, GAN loss = [2.7179568, 1.0157347, 1.080148]\n",
      "Batch 483/700: Discriminator loss = 1.1075379848480225, GAN loss = [2.718205, 1.0597206, 1.0363836]\n",
      "Batch 484/700: Discriminator loss = 1.1103286743164062, GAN loss = [2.8366978, 1.0267714, 1.187799]\n",
      "Batch 485/700: Discriminator loss = 1.0963095426559448, GAN loss = [2.7049115, 1.0203197, 1.0624583]\n",
      "Batch 486/700: Discriminator loss = 1.105753779411316, GAN loss = [2.7032037, 1.0049832, 1.0760807]\n",
      "Batch 487/700: Discriminator loss = 1.134339451789856, GAN loss = [2.7623003, 0.9892561, 1.1508949]\n",
      "Batch 488/700: Discriminator loss = 1.1336870193481445, GAN loss = [2.6378608, 0.983777, 1.0318887]\n",
      "Batch 489/700: Discriminator loss = 1.1079084873199463, GAN loss = [2.7261987, 1.0071359, 1.0968401]\n",
      "Batch 490/700: Discriminator loss = 1.1550180912017822, GAN loss = [2.657955, 0.9709339, 1.0647703]\n",
      "Batch 491/700: Discriminator loss = 1.1125215291976929, GAN loss = [2.6788998, 0.9855091, 1.0711185]\n",
      "Batch 492/700: Discriminator loss = 1.1131317615509033, GAN loss = [2.8120718, 1.0118729, 1.1778972]\n",
      "Batch 493/700: Discriminator loss = 1.123092532157898, GAN loss = [2.6990898, 1.0133591, 1.0633837]\n",
      "Batch 494/700: Discriminator loss = 1.11867094039917, GAN loss = [2.671265, 0.98512316, 1.0637275]\n",
      "Batch 495/700: Discriminator loss = 1.1169732809066772, GAN loss = [2.6761746, 0.99452543, 1.059193]\n",
      "Batch 496/700: Discriminator loss = 1.121480107307434, GAN loss = [2.7057693, 1.0180537, 1.065204]\n",
      "Batch 497/700: Discriminator loss = 1.0877676010131836, GAN loss = [2.7793949, 1.0511857, 1.1056705]\n",
      "Batch 498/700: Discriminator loss = 1.118026614189148, GAN loss = [2.748362, 1.0799319, 1.0458931]\n",
      "Batch 499/700: Discriminator loss = 1.120282530784607, GAN loss = [2.7535563, 1.0669248, 1.0640608]\n",
      "Batch 500/700: Discriminator loss = 1.1079412698745728, GAN loss = [2.752272, 1.055012, 1.0746636]\n",
      "Batch 501/700: Discriminator loss = 1.0978659391403198, GAN loss = [2.6414707, 1.0489286, 0.96990174]\n",
      "Batch 502/700: Discriminator loss = 1.1022239923477173, GAN loss = [2.746858, 1.029134, 1.0950599]\n",
      "Batch 503/700: Discriminator loss = 1.117564082145691, GAN loss = [2.6808023, 1.0341558, 1.0239844]\n",
      "Batch 504/700: Discriminator loss = 1.089848518371582, GAN loss = [2.8569841, 1.0588821, 1.1754353]\n",
      "Batch 505/700: Discriminator loss = 1.1254571676254272, GAN loss = [2.7055101, 1.010102, 1.0727584]\n",
      "Batch 506/700: Discriminator loss = 1.0959678888320923, GAN loss = [2.686019, 1.031565, 1.0318087]\n",
      "Batch 507/700: Discriminator loss = 1.1461124420166016, GAN loss = [2.5875878, 0.96393836, 1.000997]\n",
      "Batch 508/700: Discriminator loss = 1.1259630918502808, GAN loss = [2.6242292, 1.0010908, 1.000492]\n",
      "Batch 509/700: Discriminator loss = 1.148795247077942, GAN loss = [2.5709558, 0.97927344, 0.96902376]\n",
      "Batch 510/700: Discriminator loss = 1.1229603290557861, GAN loss = [2.683464, 1.02182, 1.0389655]\n",
      "Batch 511/700: Discriminator loss = 1.1518120765686035, GAN loss = [2.630929, 0.98599726, 1.0222341]\n",
      "Batch 512/700: Discriminator loss = 1.1550276279449463, GAN loss = [2.6019201, 0.9504707, 1.028728]\n",
      "Batch 513/700: Discriminator loss = 1.1545482873916626, GAN loss = [2.6778333, 1.0060211, 1.0490974]\n",
      "Batch 514/700: Discriminator loss = 1.14363431930542, GAN loss = [2.5413613, 0.9987905, 0.91985285]\n",
      "Batch 515/700: Discriminator loss = 1.1509588956832886, GAN loss = [2.656287, 1.0113717, 1.022184]\n",
      "Batch 516/700: Discriminator loss = 1.1016721725463867, GAN loss = [2.7522657, 1.0487267, 1.0807877]\n",
      "Batch 517/700: Discriminator loss = 1.088250994682312, GAN loss = [2.837618, 1.0278344, 1.1869911]\n",
      "Batch 518/700: Discriminator loss = 1.0890603065490723, GAN loss = [2.6375208, 1.019461, 0.9952455]\n",
      "Batch 519/700: Discriminator loss = 1.1133724451065063, GAN loss = [2.6092064, 0.98221153, 1.0041857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 520/700: Discriminator loss = 1.1097038984298706, GAN loss = [2.682785, 1.0047812, 1.0551996]\n",
      "Batch 521/700: Discriminator loss = 1.1252657175064087, GAN loss = [2.660744, 0.980559, 1.0573769]\n",
      "Batch 522/700: Discriminator loss = 1.1073919534683228, GAN loss = [2.746697, 1.0187751, 1.1051149]\n",
      "Batch 523/700: Discriminator loss = 1.0661641359329224, GAN loss = [2.7046418, 1.0394716, 1.0423536]\n",
      "Batch 524/700: Discriminator loss = 1.080053448677063, GAN loss = [2.649813, 1.020181, 1.0068148]\n",
      "Batch 525/700: Discriminator loss = 1.076124668121338, GAN loss = [2.7670045, 1.0398494, 1.1043391]\n",
      "Batch 526/700: Discriminator loss = 1.0453249216079712, GAN loss = [2.8380225, 1.0412986, 1.1739148]\n",
      "Batch 527/700: Discriminator loss = 1.0615390539169312, GAN loss = [2.727809, 1.0481218, 1.0569028]\n",
      "Batch 528/700: Discriminator loss = 1.0779167413711548, GAN loss = [2.7891772, 1.0315849, 1.1348269]\n",
      "Batch 529/700: Discriminator loss = 1.0901974439620972, GAN loss = [2.761674, 1.0454298, 1.0934902]\n",
      "Batch 530/700: Discriminator loss = 1.072591781616211, GAN loss = [2.830771, 1.0377702, 1.1702383]\n",
      "Batch 531/700: Discriminator loss = 1.0562208890914917, GAN loss = [2.8662112, 1.0573912, 1.1860781]\n",
      "Batch 532/700: Discriminator loss = 1.0663175582885742, GAN loss = [2.7274146, 1.0493125, 1.0553814]\n",
      "Batch 533/700: Discriminator loss = 1.076103925704956, GAN loss = [2.9367697, 1.0368372, 1.2772638]\n",
      "Batch 534/700: Discriminator loss = 1.0505701303482056, GAN loss = [2.8138704, 1.0605999, 1.130616]\n",
      "Batch 535/700: Discriminator loss = 1.062467098236084, GAN loss = [2.734267, 1.0762023, 1.0354198]\n",
      "Batch 536/700: Discriminator loss = 1.0801830291748047, GAN loss = [2.833026, 1.0423734, 1.1680076]\n",
      "Batch 537/700: Discriminator loss = 1.08335542678833, GAN loss = [2.7887962, 1.0485024, 1.1176627]\n",
      "Batch 538/700: Discriminator loss = 1.0988249778747559, GAN loss = [2.725837, 1.0167633, 1.0864365]\n",
      "Batch 539/700: Discriminator loss = 1.073913812637329, GAN loss = [2.8360422, 1.06735, 1.1460812]\n",
      "Batch 540/700: Discriminator loss = 1.0895498991012573, GAN loss = [2.6484618, 0.9926665, 1.033189]\n",
      "Batch 541/700: Discriminator loss = 1.1020081043243408, GAN loss = [2.6915286, 0.9937564, 1.0751872]\n",
      "Batch 542/700: Discriminator loss = 1.0764734745025635, GAN loss = [2.927008, 1.0392773, 1.2651821]\n",
      "Batch 543/700: Discriminator loss = 1.0601555109024048, GAN loss = [2.7849584, 1.0286231, 1.1338235]\n",
      "Batch 544/700: Discriminator loss = 1.0742669105529785, GAN loss = [2.8305535, 1.0702525, 1.1378399]\n",
      "Batch 545/700: Discriminator loss = 1.0987361669540405, GAN loss = [2.6106825, 0.98829764, 0.9999226]\n",
      "Batch 546/700: Discriminator loss = 1.105012059211731, GAN loss = [2.781296, 1.0073078, 1.1515377]\n",
      "Batch 547/700: Discriminator loss = 1.0665006637573242, GAN loss = [2.803963, 1.0363557, 1.1451638]\n",
      "Batch 548/700: Discriminator loss = 1.0974280834197998, GAN loss = [2.7459078, 0.99856627, 1.1249037]\n",
      "Batch 549/700: Discriminator loss = 1.0860111713409424, GAN loss = [2.7563949, 1.0025254, 1.1314344]\n",
      "Batch 550/700: Discriminator loss = 1.104563593864441, GAN loss = [2.8504186, 1.0682623, 1.1597286]\n",
      "Batch 551/700: Discriminator loss = 1.0584322214126587, GAN loss = [2.7829025, 1.0218873, 1.13862]\n",
      "Batch 552/700: Discriminator loss = 1.0398743152618408, GAN loss = [2.9225821, 1.0964558, 1.2037686]\n",
      "Batch 553/700: Discriminator loss = 1.0848093032836914, GAN loss = [2.7905998, 1.0042385, 1.1640105]\n",
      "Batch 554/700: Discriminator loss = 1.0376297235488892, GAN loss = [2.9321563, 1.1365912, 1.1732113]\n",
      "Batch 555/700: Discriminator loss = 1.0645266771316528, GAN loss = [2.7694979, 1.0928531, 1.0543053]\n",
      "Batch 556/700: Discriminator loss = 1.0633432865142822, GAN loss = [2.8459897, 1.0695735, 1.1541114]\n",
      "Batch 557/700: Discriminator loss = 1.0551680326461792, GAN loss = [2.9514747, 1.1170083, 1.2121714]\n",
      "Batch 558/700: Discriminator loss = 1.0355441570281982, GAN loss = [3.0102355, 1.1433834, 1.2445647]\n",
      "Batch 559/700: Discriminator loss = 1.0499764680862427, GAN loss = [2.8952656, 1.05501, 1.217994]\n",
      "Batch 560/700: Discriminator loss = 1.040805459022522, GAN loss = [2.8583481, 1.0843316, 1.1518083]\n",
      "Batch 561/700: Discriminator loss = 1.045195460319519, GAN loss = [2.8853323, 1.0747644, 1.1883874]\n",
      "Batch 562/700: Discriminator loss = 1.0409377813339233, GAN loss = [3.0389228, 1.0885634, 1.3282068]\n",
      "Batch 563/700: Discriminator loss = 1.0452460050582886, GAN loss = [3.016244, 1.1021774, 1.2919544]\n",
      "Batch 564/700: Discriminator loss = 1.0258805751800537, GAN loss = [3.1167097, 1.1572174, 1.3374196]\n",
      "Batch 565/700: Discriminator loss = 1.0474936962127686, GAN loss = [2.9848995, 1.0901341, 1.272716]\n",
      "Batch 566/700: Discriminator loss = 1.0451961755752563, GAN loss = [2.9519148, 1.0860132, 1.2438604]\n",
      "Batch 567/700: Discriminator loss = 1.0612621307373047, GAN loss = [2.9345822, 1.0797143, 1.2328725]\n",
      "Batch 568/700: Discriminator loss = 1.0916460752487183, GAN loss = [2.891256, 1.0561969, 1.2130835]\n",
      "Batch 569/700: Discriminator loss = 1.057451844215393, GAN loss = [3.051756, 1.0914229, 1.3383813]\n",
      "Batch 570/700: Discriminator loss = 1.042375087738037, GAN loss = [2.9978008, 1.1041121, 1.2717746]\n",
      "Batch 571/700: Discriminator loss = 1.075227975845337, GAN loss = [2.8744493, 1.080251, 1.1723021]\n",
      "Batch 572/700: Discriminator loss = 1.0593037605285645, GAN loss = [2.910919, 1.074734, 1.2143173]\n",
      "Batch 573/700: Discriminator loss = 1.0596686601638794, GAN loss = [2.9547648, 1.0665165, 1.2664305]\n",
      "Batch 574/700: Discriminator loss = 1.0706233978271484, GAN loss = [3.0134785, 1.1007959, 1.2909226]\n",
      "Batch 575/700: Discriminator loss = 1.0668630599975586, GAN loss = [2.8831458, 1.0993901, 1.1620686]\n",
      "Batch 576/700: Discriminator loss = 1.1013145446777344, GAN loss = [2.8542247, 1.0566446, 1.1759304]\n",
      "Batch 577/700: Discriminator loss = 1.073060154914856, GAN loss = [2.927635, 1.0666109, 1.2394131]\n",
      "Batch 578/700: Discriminator loss = 1.0948927402496338, GAN loss = [2.847705, 1.0441803, 1.1819535]\n",
      "Batch 579/700: Discriminator loss = 1.1178678274154663, GAN loss = [2.9006445, 1.0716655, 1.2074556]\n",
      "Batch 580/700: Discriminator loss = 1.0650380849838257, GAN loss = [2.8176527, 1.0492601, 1.1469126]\n",
      "Batch 581/700: Discriminator loss = 1.0927927494049072, GAN loss = [2.9413264, 1.0624497, 1.2574235]\n",
      "Batch 582/700: Discriminator loss = 1.0795161724090576, GAN loss = [2.8635564, 1.0636504, 1.1784672]\n",
      "Batch 583/700: Discriminator loss = 1.100541353225708, GAN loss = [2.9781432, 1.0870278, 1.2696904]\n",
      "Batch 584/700: Discriminator loss = 1.1117651462554932, GAN loss = [2.8620749, 1.082657, 1.1580013]\n",
      "Batch 585/700: Discriminator loss = 1.1098264455795288, GAN loss = [2.6938164, 1.0629712, 1.0094388]\n",
      "Batch 586/700: Discriminator loss = 1.0878217220306396, GAN loss = [3.0139825, 1.0937891, 1.2987838]\n",
      "Batch 587/700: Discriminator loss = 1.0844676494598389, GAN loss = [2.8381224, 1.0886581, 1.1280469]\n",
      "Batch 588/700: Discriminator loss = 1.1378986835479736, GAN loss = [2.7469857, 1.0173801, 1.1081755]\n",
      "Batch 589/700: Discriminator loss = 1.0935792922973633, GAN loss = [3.0360935, 1.1112893, 1.3033823]\n",
      "Batch 590/700: Discriminator loss = 1.1311274766921997, GAN loss = [2.7971663, 1.0864568, 1.0892707]\n",
      "Batch 591/700: Discriminator loss = 1.1116868257522583, GAN loss = [2.868373, 1.1173648, 1.1295376]\n",
      "Batch 592/700: Discriminator loss = 1.1032288074493408, GAN loss = [2.747868, 1.0705917, 1.0557557]\n",
      "Batch 593/700: Discriminator loss = 1.1028550863265991, GAN loss = [2.6440787, 1.1045556, 0.9179777]\n",
      "Batch 594/700: Discriminator loss = 1.1784666776657104, GAN loss = [2.749146, 1.0566974, 1.0708829]\n",
      "Batch 595/700: Discriminator loss = 1.096725583076477, GAN loss = [2.7605205, 1.0837281, 1.0552181]\n",
      "Batch 596/700: Discriminator loss = 1.1226943731307983, GAN loss = [2.7092957, 1.0680224, 1.0197177]\n",
      "Batch 597/700: Discriminator loss = 1.0972108840942383, GAN loss = [2.7520726, 1.0686339, 1.061923]\n",
      "Batch 598/700: Discriminator loss = 1.1122395992279053, GAN loss = [2.7263553, 1.078269, 1.0265977]\n",
      "Batch 599/700: Discriminator loss = 1.1079707145690918, GAN loss = [2.6935968, 1.0460122, 1.0260994]\n",
      "Batch 600/700: Discriminator loss = 1.1148301362991333, GAN loss = [2.7745497, 1.1082392, 1.044821]\n",
      "Batch 601/700: Discriminator loss = 1.1047011613845825, GAN loss = [2.7362082, 1.067059, 1.0476816]\n",
      "Batch 602/700: Discriminator loss = 1.107756495475769, GAN loss = [2.7672656, 1.0631602, 1.0826787]\n",
      "Batch 603/700: Discriminator loss = 1.1360065937042236, GAN loss = [2.6381986, 1.0080266, 1.0087633]\n",
      "Batch 604/700: Discriminator loss = 1.1366785764694214, GAN loss = [2.708366, 1.040613, 1.0463673]\n",
      "Batch 605/700: Discriminator loss = 1.072065830230713, GAN loss = [2.7911217, 1.0717263, 1.0980364]\n",
      "Batch 606/700: Discriminator loss = 1.0807653665542603, GAN loss = [2.8123355, 1.0832845, 1.1077263]\n",
      "Batch 607/700: Discriminator loss = 1.1018548011779785, GAN loss = [2.7341912, 1.0374333, 1.0754726]\n",
      "Batch 608/700: Discriminator loss = 1.090474009513855, GAN loss = [2.724131, 1.0508933, 1.0519842]\n",
      "Batch 609/700: Discriminator loss = 1.090293526649475, GAN loss = [2.7541485, 1.01213, 1.1207721]\n",
      "Batch 610/700: Discriminator loss = 1.1069258451461792, GAN loss = [2.723688, 1.0096251, 1.0928361]\n",
      "Batch 611/700: Discriminator loss = 1.0776571035385132, GAN loss = [2.8178976, 1.0777681, 1.1189193]\n",
      "Batch 612/700: Discriminator loss = 1.0958876609802246, GAN loss = [2.6318455, 1.0272723, 0.9833788]\n",
      "Batch 613/700: Discriminator loss = 1.075852870941162, GAN loss = [2.7471435, 1.0648075, 1.06114]\n",
      "Batch 614/700: Discriminator loss = 1.1291786432266235, GAN loss = [2.7700999, 1.0005846, 1.1483376]\n",
      "Batch 615/700: Discriminator loss = 1.053862452507019, GAN loss = [2.7660193, 1.0332661, 1.1115927]\n",
      "Batch 616/700: Discriminator loss = 1.0966689586639404, GAN loss = [2.7317939, 1.008129, 1.1025071]\n",
      "Batch 617/700: Discriminator loss = 1.0884166955947876, GAN loss = [2.7638712, 1.0227714, 1.1199397]\n",
      "Batch 618/700: Discriminator loss = 1.082605242729187, GAN loss = [2.804488, 1.0561303, 1.1271974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 619/700: Discriminator loss = 1.1150346994400024, GAN loss = [2.6864908, 0.98629016, 1.0790063]\n",
      "Batch 620/700: Discriminator loss = 1.0864708423614502, GAN loss = [2.7688785, 1.0163921, 1.1313021]\n",
      "Batch 621/700: Discriminator loss = 1.0871765613555908, GAN loss = [2.7454228, 1.0058708, 1.1183755]\n",
      "Batch 622/700: Discriminator loss = 1.1034915447235107, GAN loss = [2.7322886, 0.9834591, 1.1276344]\n",
      "Batch 623/700: Discriminator loss = 1.106684684753418, GAN loss = [2.6820834, 0.97260386, 1.0882674]\n",
      "Batch 624/700: Discriminator loss = 1.0959856510162354, GAN loss = [2.782425, 0.9837655, 1.1774515]\n",
      "Batch 625/700: Discriminator loss = 1.0680218935012817, GAN loss = [2.815336, 1.0365252, 1.1575894]\n",
      "Batch 626/700: Discriminator loss = 1.0694438219070435, GAN loss = [2.7321126, 1.0160774, 1.0948161]\n",
      "Batch 627/700: Discriminator loss = 1.085098147392273, GAN loss = [2.7414052, 1.0356628, 1.0845379]\n",
      "Batch 628/700: Discriminator loss = 1.076171875, GAN loss = [2.858462, 1.0360627, 1.2012143]\n",
      "Batch 629/700: Discriminator loss = 1.0735313892364502, GAN loss = [2.781602, 1.0315104, 1.128928]\n",
      "Batch 630/700: Discriminator loss = 1.066599726676941, GAN loss = [2.766455, 1.038416, 1.1068805]\n",
      "Batch 631/700: Discriminator loss = 1.0556328296661377, GAN loss = [2.960515, 1.0507021, 1.2886419]\n",
      "Batch 632/700: Discriminator loss = 1.0995092391967773, GAN loss = [2.761815, 1.0199344, 1.1206685]\n",
      "Batch 633/700: Discriminator loss = 1.0749133825302124, GAN loss = [2.7858021, 1.0885568, 1.0760077]\n",
      "Batch 634/700: Discriminator loss = 1.0814083814620972, GAN loss = [2.8035066, 1.0132147, 1.1690179]\n",
      "Batch 635/700: Discriminator loss = 1.0904054641723633, GAN loss = [2.7271485, 1.0235562, 1.0822968]\n",
      "Batch 636/700: Discriminator loss = 1.1090389490127563, GAN loss = [2.6933303, 1.0077196, 1.0643042]\n",
      "Batch 637/700: Discriminator loss = 1.103949785232544, GAN loss = [2.8999119, 1.0153503, 1.2632405]\n",
      "Batch 638/700: Discriminator loss = 1.1035478115081787, GAN loss = [2.7948697, 1.0826958, 1.0908332]\n",
      "Batch 639/700: Discriminator loss = 1.1165467500686646, GAN loss = [2.9311113, 1.0957968, 1.213967]\n",
      "Batch 640/700: Discriminator loss = 1.0575478076934814, GAN loss = [2.727097, 1.0652598, 1.0404675]\n",
      "Batch 641/700: Discriminator loss = 1.1053383350372314, GAN loss = [2.7400472, 1.0852518, 1.0334091]\n",
      "Batch 642/700: Discriminator loss = 1.09494149684906, GAN loss = [2.6674953, 1.0380677, 1.0080076]\n",
      "Batch 643/700: Discriminator loss = 1.135943055152893, GAN loss = [2.7127364, 1.018618, 1.0726768]\n",
      "Batch 644/700: Discriminator loss = 1.1119905710220337, GAN loss = [2.7571762, 1.0637152, 1.0719918]\n",
      "Batch 645/700: Discriminator loss = 1.13555908203125, GAN loss = [2.8397026, 1.0487653, 1.1694567]\n",
      "Batch 646/700: Discriminator loss = 1.077358603477478, GAN loss = [2.7625713, 1.0675019, 1.07359]\n",
      "Batch 647/700: Discriminator loss = 1.1002877950668335, GAN loss = [2.7936966, 1.0811505, 1.0910432]\n",
      "Batch 648/700: Discriminator loss = 1.0950098037719727, GAN loss = [2.8077025, 1.0719947, 1.1141307]\n",
      "Batch 649/700: Discriminator loss = 1.092112421989441, GAN loss = [2.8767378, 1.0811034, 1.1740217]\n",
      "Batch 650/700: Discriminator loss = 1.092233657836914, GAN loss = [2.941402, 1.1562524, 1.1634978]\n",
      "Batch 651/700: Discriminator loss = 1.1082407236099243, GAN loss = [2.6911743, 1.0145029, 1.054959]\n",
      "Batch 652/700: Discriminator loss = 1.1010340452194214, GAN loss = [2.868624, 1.0056294, 1.241254]\n",
      "Batch 653/700: Discriminator loss = 1.0937182903289795, GAN loss = [2.868733, 1.042014, 1.2049527]\n",
      "Batch 654/700: Discriminator loss = 1.0950714349746704, GAN loss = [2.8443675, 1.0502607, 1.172334]\n",
      "Batch 655/700: Discriminator loss = 1.1084012985229492, GAN loss = [2.8947172, 1.0916231, 1.1813115]\n",
      "Batch 656/700: Discriminator loss = 1.08240807056427, GAN loss = [2.8278193, 1.0768797, 1.1291618]\n",
      "Batch 657/700: Discriminator loss = 1.1219868659973145, GAN loss = [2.8164668, 1.0401174, 1.1545781]\n",
      "Batch 658/700: Discriminator loss = 1.1166538000106812, GAN loss = [2.8695543, 1.0860933, 1.1616672]\n",
      "Batch 659/700: Discriminator loss = 1.0932590961456299, GAN loss = [2.829583, 1.0516351, 1.1561264]\n",
      "Batch 660/700: Discriminator loss = 1.1020069122314453, GAN loss = [2.7446682, 1.0448174, 1.0780245]\n",
      "Batch 661/700: Discriminator loss = 1.0993376970291138, GAN loss = [2.9287863, 1.0696968, 1.237222]\n",
      "Batch 662/700: Discriminator loss = 1.0625109672546387, GAN loss = [3.0319648, 1.0675921, 1.3424829]\n",
      "Batch 663/700: Discriminator loss = 1.0961227416992188, GAN loss = [2.867334, 1.0345902, 1.2108129]\n",
      "Batch 664/700: Discriminator loss = 1.0961664915084839, GAN loss = [2.986056, 1.0607182, 1.3033911]\n",
      "Batch 665/700: Discriminator loss = 1.0729718208312988, GAN loss = [3.1827579, 1.1363926, 1.4244049]\n",
      "Batch 666/700: Discriminator loss = 1.1247451305389404, GAN loss = [2.8800538, 1.0747025, 1.1833404]\n",
      "Batch 667/700: Discriminator loss = 1.1184667348861694, GAN loss = [2.8801274, 1.0561444, 1.2019408]\n",
      "Batch 668/700: Discriminator loss = 1.1245741844177246, GAN loss = [2.7893379, 1.0223564, 1.144907]\n",
      "Batch 669/700: Discriminator loss = 1.1443349123001099, GAN loss = [2.6633558, 0.98360306, 1.0576675]\n",
      "Batch 670/700: Discriminator loss = 1.1406495571136475, GAN loss = [2.864102, 1.0744147, 1.1676087]\n",
      "Batch 671/700: Discriminator loss = 1.1294453144073486, GAN loss = [2.84785, 1.0304301, 1.1953597]\n",
      "Batch 672/700: Discriminator loss = 1.1606818437576294, GAN loss = [2.7230804, 1.0013611, 1.0996555]\n",
      "Batch 673/700: Discriminator loss = 1.0820521116256714, GAN loss = [2.9293983, 1.0831516, 1.2241893]\n",
      "Batch 674/700: Discriminator loss = 1.16741144657135, GAN loss = [2.7173743, 1.0129592, 1.0823792]\n",
      "Batch 675/700: Discriminator loss = 1.1293706893920898, GAN loss = [2.8775992, 1.0800849, 1.1754918]\n",
      "Batch 676/700: Discriminator loss = 1.1123863458633423, GAN loss = [2.8927872, 1.0483953, 1.2223771]\n",
      "Batch 677/700: Discriminator loss = 1.1457324028015137, GAN loss = [2.8487284, 1.0311328, 1.1955891]\n",
      "Batch 678/700: Discriminator loss = 1.1002681255340576, GAN loss = [2.8726342, 1.0688902, 1.181734]\n",
      "Batch 679/700: Discriminator loss = 1.1030596494674683, GAN loss = [2.9214966, 1.0773969, 1.2220763]\n",
      "Batch 680/700: Discriminator loss = 1.1511677503585815, GAN loss = [2.6571832, 1.0140244, 1.0211104]\n",
      "Batch 681/700: Discriminator loss = 1.136053204536438, GAN loss = [2.7125893, 1.0286003, 1.0618812]\n",
      "Batch 682/700: Discriminator loss = 1.1602418422698975, GAN loss = [2.7597349, 1.0169176, 1.120664]\n",
      "Batch 683/700: Discriminator loss = 1.184821605682373, GAN loss = [2.7728941, 1.0323907, 1.1183367]\n",
      "Batch 684/700: Discriminator loss = 1.1599041223526, GAN loss = [2.5445538, 0.98627394, 0.9361021]\n",
      "Batch 685/700: Discriminator loss = 1.1238594055175781, GAN loss = [2.7807195, 1.0587636, 1.0997418]\n",
      "Batch 686/700: Discriminator loss = 1.1307724714279175, GAN loss = [2.775936, 1.0426129, 1.1110724]\n",
      "Batch 687/700: Discriminator loss = 1.126137614250183, GAN loss = [2.8079567, 1.0657974, 1.119862]\n",
      "Batch 688/700: Discriminator loss = 1.1546097993850708, GAN loss = [2.641812, 1.0114254, 1.0080214]\n",
      "Batch 689/700: Discriminator loss = 1.1348670721054077, GAN loss = [2.7429044, 1.0215544, 1.0989205]\n",
      "Batch 690/700: Discriminator loss = 1.126917839050293, GAN loss = [2.828049, 1.1152185, 1.090387]\n",
      "Batch 691/700: Discriminator loss = 1.1050313711166382, GAN loss = [2.763459, 1.0293256, 1.1116811]\n",
      "Batch 692/700: Discriminator loss = 1.1003180742263794, GAN loss = [2.7325616, 1.049956, 1.0601557]\n",
      "Batch 693/700: Discriminator loss = 1.0880175828933716, GAN loss = [2.8499897, 1.078542, 1.148995]\n",
      "Batch 694/700: Discriminator loss = 1.0923019647598267, GAN loss = [2.8915362, 1.0949005, 1.1741686]\n",
      "Batch 695/700: Discriminator loss = 1.0914028882980347, GAN loss = [2.782596, 1.1267292, 1.0334162]\n",
      "Batch 696/700: Discriminator loss = 1.0966132879257202, GAN loss = [2.7063584, 1.1020839, 0.9818402]\n",
      "Batch 697/700: Discriminator loss = 1.082348346710205, GAN loss = [2.8399088, 1.0859071, 1.1316067]\n",
      "Batch 698/700: Discriminator loss = 1.086702823638916, GAN loss = [2.7820776, 1.0805553, 1.079156]\n",
      "Batch 699/700: Discriminator loss = 1.0875145196914673, GAN loss = [2.7804074, 1.0871564, 1.070939]\n",
      "Batch 700/700: Discriminator loss = 1.0654925107955933, GAN loss = [3.002616, 1.1180403, 1.2623204]\n"
     ]
    }
   ],
   "source": [
    "# Simple example of conditional GAN in Keras\n",
    "# Generates MNIST numbers of one's choice, not at random as in standard GANs\n",
    "# \n",
    "# author: Alejandro Pozas-Kerstjens\n",
    "#\n",
    "# Note: tricks displayed refer to those mentioned in https://github.com/soumith/ganhacks\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import LeakyReLU, Activation, Input, Dense, Dropout, Concatenate, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "\n",
    "def build_gan(generator, discriminator, name=\"gan\"):\n",
    "    '''Build the GAN from a generator and a discriminator'''\n",
    "    yfake = Activation(\"linear\", name=\"yfake\")(discriminator(generator(generator.inputs)))\n",
    "    yreal = Activation(\"linear\", name=\"yreal\")(discriminator(discriminator.inputs))\n",
    "    model = Model(generator.inputs + discriminator.inputs, [yfake, yreal], name=name)\n",
    "    return model\n",
    "    \n",
    "\n",
    "def disc(image_dim, label_dim, layer_dim=1024, reg=lambda: l1_l2(1e-5, 1e-5)):\n",
    "    '''Discriminator network'''\n",
    "    x      = (Input(shape=(image_dim,), name='discriminator_input'))\n",
    "    label  = (Input(shape=(label_dim,), name='discriminator_label'))\n",
    "    inputs = (Concatenate(name='input_concatenation'))([x, label])\n",
    "    a = (Dense(layer_dim, name=\"discriminator_h1\", kernel_regularizer=reg()))(inputs)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(int(layer_dim / 2), name=\"discriminator_h2\", kernel_regularizer=reg()))(a)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(int(layer_dim / 4), name=\"discriminator_h3\", kernel_regularizer=reg()))(a)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(1, name=\"discriminator_y\", kernel_regularizer=reg()))(a)\n",
    "    a = (Activation('sigmoid'))(a)\n",
    "    model = Model(inputs=[x, label], outputs=a, name=\"discriminator\")\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def gen(noise_dim, label_dim, image_dim, layer_dim=1024, activ='tanh', reg=lambda: l1_l2(1e-5, 1e-5)):\n",
    "    '''Generator network'''\n",
    "    z      = (Input(shape=(noise_dim,), name='generator_input'))\n",
    "    label  = (Input(shape=(label_dim,), name='generator_label'))\n",
    "    inputs = (Concatenate(name='input_concatenation'))([z, label])\n",
    "    a = (Dense(int(layer_dim / 4), name=\"generator_h1\", kernel_regularizer=reg()))(inputs)\n",
    "    a = (LeakyReLU(0.2))(a)    # Trick 5\n",
    "    a = (Dense(int(layer_dim / 2), name=\"generator_h2\", kernel_regularizer=reg()))(a)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(layer_dim, name=\"generator_h3\", kernel_regularizer=reg()))(a)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(np.prod(image_dim), name=\"generator_x_flat\", kernel_regularizer=reg()))(a)\n",
    "    a = (Activation(activ))(a)    \n",
    "    model = Model(inputs=[z, label], outputs=[a, label], name=\"generator\")\n",
    "    return model\n",
    "\n",
    "    \n",
    "def make_trainable(net, val):\n",
    "    '''Changes the trainable property of a model as a whole and layer by layer'''\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "    \n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Data preparation\n",
    "# ------------------------------------------------------------------------------\n",
    "(x_train, l_train), (x_test, l_test) = mnist.load_data()\n",
    "x_train = np.concatenate((x_train, x_test))\n",
    "l_train = np.concatenate((l_train, l_test))\n",
    "\n",
    "# Normalization according to Trick 1\n",
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_train = (x_train - 127.5) / 127.5\n",
    "l_train = to_categorical(l_train)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Parameter choice\n",
    "# ------------------------------------------------------------------------------    \n",
    "# Dimension of noise to be fed to the generator\n",
    "noise_dim = 100\n",
    "# Dimension of images generated\n",
    "image_dim = 28 * 28\n",
    "# Dimension of labels\n",
    "label_dim = 10\n",
    "\n",
    "batch_size  = 100\n",
    "num_batches = int(x_train.shape[0] / batch_size)\n",
    "num_epochs  = 30\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Network creation\n",
    "# ------------------------------------------------------------------------------\n",
    "# Create generator ((z, l) -> (x, l))\n",
    "generator = gen(noise_dim, label_dim, image_dim)\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam)    # Trick 9\n",
    "\n",
    "# Create discriminator ((x, l) -> y)\n",
    "discriminator = disc(image_dim, label_dim)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='SGD')    # Trick 9\n",
    "\n",
    "# Build GAN. Note how the discriminator is set to be not trainable since the beginning\n",
    "make_trainable(discriminator, False)\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Training\n",
    "# ------------------------------------------------------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "    for index in range(num_batches):\n",
    "        # Train the discriminator. It looks like training works best if it is trained first on only real data, and then only\n",
    "        # on fake data, so let's do that. This is Trick 4.\n",
    "        make_trainable(discriminator, True)\n",
    "        # Train dicriminator on real data\n",
    "        batch       = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
    "        image_batch = x_train[batch]\n",
    "        label_batch = l_train[batch]\n",
    "        y_real      = np.ones(batch_size) + 0.2 * np.random.uniform(-1, 1, size=batch_size)    # Label smoothing. Trick 6\n",
    "        discriminator.train_on_batch([image_batch, label_batch], y_real)\n",
    "        # Train the discriminator on fake data\n",
    "        noise_batch      = np.random.normal(0, 1, (batch_size, noise_dim))    # Trick 3\n",
    "        generated_images = generator.predict([noise_batch, label_batch])\n",
    "        y_fake           = np.zeros(batch_size) + 0.2 * np.random.uniform(0, 1, size=batch_size)    # Label smoothing\n",
    "        d_loss = discriminator.train_on_batch(generated_images, y_fake)   # Recall that generated_images already contains the labels\n",
    "        # Train the generator. We train it through the whole model. There is a very subtle point here. We want to minimize the error\n",
    "        # of the discriminator, but on the other hand we want to have the generator maximizing the loss of the discriminator (make him\n",
    "        # not capable of distinguishing which images are real). One way to achieve this is to change the loss function of the generator\n",
    "        # by some kind of \"negative loss\", which in practice is implemented by switching the labels of the real and the fake\n",
    "        # images. Note that when training the discriminator we were doing the assignment real_image->1, fake_image->0, so now\n",
    "        # we will do real_image->0, fake_image->1. The order of the outputs is [fake, real], as given by build_gan(). This is Trick 2.\n",
    "        make_trainable(discriminator, False)\n",
    "        gan_loss = gan.train_on_batch([noise_batch, label_batch, image_batch, label_batch], [y_real, y_fake])\n",
    "\n",
    "        print(\n",
    "            \"Batch {}/{}: Discriminator loss = {}, GAN loss = {}\".format(index + 1, num_batches, d_loss,\n",
    "                                                                         gan_loss))\n",
    "# Save weights. Just saving the whole GAN should work as well\n",
    "generator.save_weights('generator_cGAN.h5')\n",
    "discriminator.save_weights('discriminator_cGAN.h5')\n",
    "gan.save_weights('gan_cGAN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-32fb5c091c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'label_dim' is not defined"
     ]
    }
   ],
   "source": [
    "label_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1a3982994650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_dim' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x144 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Plotting\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(label_dim):\n",
    "    im = generator.predict([np.random.uniform(-1, 1, (1, noise_dim)), to_categorical(i, label_dim)])[0].reshape((28, 28))\n",
    "    plt.subplot(1, label_dim, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(im, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
